[
{"stack_question_id": "20109391", "question_title": "How to make good reproducible pandas examples", "question_content": "\r\n                Having spent a decent amount of time watching both the r and pandas tags on SO, the impression that I get is that pandas questions are less likely to contain reproducible data. This is something that ...\r\n", "question_url": "/questions/20109391/how-to-make-good-reproducible-pandas-examples", "date_posted": "Nov 20, 2013 at 23:31", "upvote": "2", "view": "4", "tags": ["python", "pandas"], "answers_count": "5", "answers": [{"stack_answer_id": "20159305", "answer_content": "\r\n Note: The ideas here are pretty generic for Stack Overflow, indeed  questions . \n Disclaimer: Writing a good question is  hard . \n The Good: \n \n do include small* example DataFrame, either as runnable code: \n In [1]: df = pd.DataFrame([[1, 2], [1, 3], [4, 6]], columns=['A', 'B'])\n \n or make it \"copy and pasteable\" using  pd.read_clipboard(sep='\\s\\s+') , you can format the text for Stack Overflow highlight and use  Ctrl + K  (or prepend four spaces to each line), or place three backticks (```) above and below your code with your code unindented: \n In [2]: df\nOut[2]:\n   A  B\n0  1  2\n1  1  3\n2  4  6\n \n test  pd.read_clipboard(sep='\\s\\s+')  yourself. \n *  I really do mean  small . The vast majority of example DataFrames could be fewer than 6 rows  [citation needed] , and  I bet I can do it in 5 rows.  Can you reproduce the error with  df = df.head() ? If not, fiddle around to see if you can make up a small DataFrame which exhibits the issue you are facing. \n *  Every rule has an exception, the obvious one is for performance issues  ( in which case definitely use %timeit and possibly %prun ), where you should generate:  df = pd.DataFrame(np.random.randn(100000000, 10)) . Consider using  np.random.seed  so we have the exact same frame. Saying that, \"make this code fast for me\" is not strictly on topic for the site. \n \n write out the outcome you desire (similarly to above) \n In [3]: iwantthis\nOut[3]:\n   A  B\n0  1  5\n1  4  6\n \n Explain what the numbers come from: the 5 is sum of the B column for the rows where A is 1. \n \n do show  the code  you've tried: \n In [4]: df.groupby('A').sum()\nOut[4]:\n   B\nA\n1  5\n4  6\n \n But say what's incorrect: the A column is in the index rather than a column. \n \n do show you've done some research ( search the documentation ,  search Stack\u00a0Overflow ), and give a summary: \n \n The docstring for sum simply states \"Compute sum of group values\" \n \n \n The  groupby documentation  doesn't give any examples for this. \n \n Aside: the answer here is to use  df.groupby('A', as_index=False).sum() . \n \n if it's relevant that you have Timestamp columns, e.g. you're resampling or something, then be explicit and apply  pd.to_datetime  to them for good measure**. \n df['date'] = pd.to_datetime(df['date']) # this column ought to be date..\n \n **  Sometimes this is the issue itself: they were strings. \n \n \n The Bad: \n \n don't include a MultiIndex, which  we can't copy and paste  (see above). This is kind of a grievance with Pandas' default display, but nonetheless annoying: \n In [11]: df\nOut[11]:\n     C\nA B\n1 2  3\n  2  6\n \n The correct way is to include an ordinary DataFrame with a  set_index  call: \n In [12]: df = pd.DataFrame([[1, 2, 3], [1, 2, 6]], columns=['A', 'B', 'C']).set_index(['A', 'B'])\n\nIn [13]: df\nOut[13]:\n     C\nA B\n1 2  3\n  2  6\n \n \n do provide insight to what it is when giving the outcome you want: \n    B\nA\n1  1\n5  0\n \n Be specific about how you got the numbers (what are they)... double check they're correct. \n \n If your code throws an error, do include the entire stack trace (this can be edited out later if it's too noisy). Show the line number (and the corresponding line of your code which it's raising against). \n \n \n The Ugly: \n \n don't link to a  CSV  file we don't have access to (ideally don't link to an external source at all...) \n df = pd.read_csv('my_secret_file.csv')  # ideally with lots of parsing options\n \n Most data is proprietary  we get that: Make up similar data and see if you can reproduce the problem (something small). \n \n don't explain the situation vaguely in words, like you have a DataFrame which is \"large\", mention some of the column names in passing (be sure not to mention their dtypes). Try and go into lots of detail about something which is completely meaningless without seeing the actual context. Presumably no one is even going to read to the end of this paragraph. \n Essays are bad, it's easier with small examples. \n \n don't include 10+ (100+??) lines of data munging before getting to your actual question. \n Please, we see enough of this in our day jobs. We want to help, but  not like this... . \n Cut the intro, and just show the relevant DataFrames (or small versions of them) in the step which is causing you trouble. \n \n \n Anyway, have fun learning Python, NumPy and Pandas! \n    ", "date_posted": "2022-04-03 17:29:39Z", "upvote": "\r\n            451\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "4518341", "name": "wjandrea", "reputation_score": "24.1k"}, "answer_comments": [{"stack_answer_id": "20159305", "stack_answer_comment_id": "60808128", "comment_content": "+1 for the ", "user_id": "None"}, {"stack_answer_id": "20159305", "stack_answer_comment_id": "69339225", "comment_content": "the ", "user_id": "None"}, {"stack_answer_id": "20159305", "stack_answer_comment_id": "94715719", "comment_content": "Why ", "user_id": "None"}, {"stack_answer_id": "20159305", "stack_answer_comment_id": "94739875", "comment_content": "@MarianD the reason that \\s\\s+ is so popular is that there is often one e.g. in a column name, but multiple is rarer, and pandas output nicely puts in at least two between columns. Since this is just for toy/small datasets it's pretty powerful/majority of cases. Note: tabs separated would be a different story, though stackoverflow replaces tabs with spaces, but if you have a tsv then just use \\t.", "user_id": "None"}, {"stack_answer_id": "20159305", "stack_answer_comment_id": "99634737", "comment_content": "Ugh, i always use ", "user_id": "None"}]}, {"stack_answer_id": "30424537", "answer_content": "\r\n How to create sample datasets \n This is to mainly to expand on  AndyHayden's answer  by providing examples of how you can create sample dataframes.  Pandas and (especially) NumPy give you a variety of tools for this such that you can generally create a reasonable facsimile of any real dataset with just a few lines of code. \n After importing NumPy and Pandas, be sure to provide a random seed if you want folks to be able to exactly reproduce your data and results. \n import numpy as np\nimport pandas as pd\n\nnp.random.seed(123)\n \n A kitchen sink example \n Here's an example showing a variety of things you can do.  All kinds of useful sample dataframes could be created from a subset of this: \n df = pd.DataFrame({\n\n    # some ways to create random data\n    'a':np.random.randn(6),\n    'b':np.random.choice( [5,7,np.nan], 6),\n    'c':np.random.choice( ['panda','python','shark'], 6),\n\n    # some ways to create systematic groups for indexing or groupby\n    # this is similar to R's expand.grid(), see note 2 below\n    'd':np.repeat( range(3), 2 ),\n    'e':np.tile(   range(2), 3 ),\n\n    # a date range and set of random dates\n    'f':pd.date_range('1/1/2011', periods=6, freq='D'),\n    'g':np.random.choice( pd.date_range('1/1/2011', periods=365,\n                          freq='D'), 6, replace=False)\n    })\n \n This produces: \n           a   b       c  d  e          f          g\n0 -1.085631 NaN   panda  0  0 2011-01-01 2011-08-12\n1  0.997345   7   shark  0  1 2011-01-02 2011-11-10\n2  0.282978   5   panda  1  0 2011-01-03 2011-10-30\n3 -1.506295   7  python  1  1 2011-01-04 2011-09-07\n4 -0.578600 NaN   shark  2  0 2011-01-05 2011-02-27\n5  1.651437   7  python  2  1 2011-01-06 2011-02-03\n \n Some notes: \n \n np.repeat  and  np.tile  (columns  d  and  e ) are very useful for creating groups and indices in a very regular way.  For 2 columns, this can be used to easily duplicate r's  expand.grid()  but is also more flexible in ability to provide a subset of all permutations.  However, for 3 or more columns the syntax quickly becomes unwieldy. \n For a more direct replacement for R's  expand.grid()  see the  itertools  solution in the  pandas cookbook  or the  np.meshgrid  solution shown  here .  Those will allow any number of dimensions. \n You can do quite a bit with  np.random.choice .  For example, in column  g , we have a random selection of six dates from 2011.  Additionally, by setting  replace=False  we can assure these dates are unique -- very handy if we want to use this as an index with unique values. \n \n Fake stock market data \n In addition to taking subsets of the above code, you can further combine the techniques to do just about anything.  For example, here's a short example that combines  np.tile  and  date_range  to create sample ticker data for 4 stocks covering the same dates: \n stocks = pd.DataFrame({\n    'ticker':np.repeat( ['aapl','goog','yhoo','msft'], 25 ),\n    'date':np.tile( pd.date_range('1/1/2011', periods=25, freq='D'), 4 ),\n    'price':(np.random.randn(100).cumsum() + 10) })\n \n Now we have a sample dataset with 100 lines (25 dates per ticker), but we have only used 4 lines to do it, making it easy for everyone else to reproduce without copying and pasting 100 lines of code.  You can then display subsets of the data if it helps to explain your question: \n >>> stocks.head(5)\n\n        date      price ticker\n0 2011-01-01   9.497412   aapl\n1 2011-01-02  10.261908   aapl\n2 2011-01-03   9.438538   aapl\n3 2011-01-04   9.515958   aapl\n4 2011-01-05   7.554070   aapl\n\n>>> stocks.groupby('ticker').head(2)\n\n         date      price ticker\n0  2011-01-01   9.497412   aapl\n1  2011-01-02  10.261908   aapl\n25 2011-01-01   8.277772   goog\n26 2011-01-02   7.714916   goog\n50 2011-01-01   5.613023   yhoo\n51 2011-01-02   6.397686   yhoo\n75 2011-01-01  11.736584   msft\n76 2011-01-02  11.944519   msft\n \n    ", "date_posted": "2021-07-24 21:01:22Z", "upvote": "\r\n            84\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "30424537", "stack_answer_comment_id": "48943556", "comment_content": "Great answer. After writing this question I actually did write a very short, simple implementation of ", "user_id": "1222578"}, {"stack_answer_id": "30424537", "stack_answer_comment_id": "114458561", "comment_content": "This is a really useful example and I'll be using it as a base for examples. Many thanks!", "user_id": "None"}]}, {"stack_answer_id": "38466059", "answer_content": "\r\n Diary of an Answerer \n\n My best advice for asking questions would be to play on the psychology of the people who answer questions.  Being one of those people, I can give insight into why I answer certain questions and why I don't answer others. \n\n Motivations \n\n I'm motivated to answer questions for several reasons \n\n \n Stackoverflow.com has been a tremendously valuable resource to me.  I wanted to give back. \n In my efforts to give back, I've found this site to be an even more powerful resource than before.  Answering questions is a learning experience for me and I like to learn.   Read this answer and comment from another vet .  This kind of interaction makes me happy. \n I like points! \n See #3. \n I like interesting problems. \n \n\n All my purest intentions are great and all, but I get that satisfaction if I answer 1 question or 30.   What drives my choices  for which questions to answer has a huge component of point maximization. \n\n I'll also spend time on interesting problems but that is few and far between and doesn't help an asker who needs a solution to a non-interesting question.  Your best bet to get me to answer a question is to serve that question up on a platter ripe for me to answer it with as little effort as possible.  If I'm looking at two questions and one has code I can copy paste to create all the variables I need... I'm taking that one!  I'll come back to the other one if I have time, maybe. \n\n Main Advice \n\n Make it easy for the people answering questions. \n\n \n Provide code that creates variables that are needed. \n Minimize that code.  If my eyes glaze over as I look at the post, I'm on to the next question or getting back to whatever else I'm doing. \n Think about what you're asking and be specific.  We want to see what you've done because natural languages (English) are inexact and confusing.  Code samples of what you've tried help resolve inconsistencies in a natural language description. \n PLEASE show what you expect!!!  I have to sit down and try things.  I almost never know the answer to a question without trying some things out.  If I don't see an example of what you're looking for, I might pass on the question because I don't feel like guessing. \n \n\n Your reputation is more than just your reputation. \n\n I like points (I mentioned that above).  But those points aren't really really my reputation.  My real reputation is an amalgamation of what others on the site think of me.  I strive to be fair and honest and I hope others can see that.  What that means for an asker is, we remember the behaviors of askers.  If you don't select answers and upvote good answers, I remember.  If you behave in ways I don't like or in ways I do like, I remember.  This also plays into which questions I'll answer. \n\n \n\n Anyway, I can probably go on, but I'll spare all of you who actually read this. \n    ", "date_posted": "2018-01-01 09:39:28Z", "upvote": "\r\n            59\r\n        ", "accepted": "No", "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "answer_comments": []}, {"stack_answer_id": "32536193", "answer_content": "\r\n The Challenge  One of the most challenging aspects of responding to SO questions is the time it takes to recreate the problem (including the data).  Questions which don't have a clear way to reproduce the data are less likely to be answered.  Given that you are taking the time to write a question and you have an issue that you'd like help with, you can easily help yourself by providing data that others can then use to help solve your problem. \n The instructions provided by @Andy for writing good Pandas questions are an excellent place to start.  For more information, refer to  how to ask  and how to create  Minimal, Complete, and Verifiable examples . \n Please clearly state your question upfront.   After taking the time to write your question and any sample code, try to read it and provide an 'Executive Summary' for your reader which summarizes the problem and clearly states the question. \n Original question : \n \n I have this data... \n I want to do this... \n I want my result to look like this... \n However, when I try to do [this], I get the following problem... \n I've tried to find solutions by doing [this] and [that]. \n How do I fix it? \n \n Depending on the amount of data, sample code and error stacks provided, the reader needs to go a long way before understanding what the problem is.  Try restating your question so that the question itself is on top, and then provide the necessary details. \n Revised Question : \n \n Qustion:   How can I do [this]? \n I've tried to find solutions by doing [this] and [that]. \n When I've tried to do [this], I get the following problem... \n I'd like my final results to look like this... \n Here is some minimal code that can reproduce my problem... \n And here is how to recreate my sample data:\n df = pd.DataFrame({'A': [...], 'B': [...], ...}) \n \n PROVIDE SAMPLE DATA IF NEEDED!!! \n Sometimes just the head or tail of the DataFrame is all that is needed.  You can also use the methods proposed by @JohnE to create larger datasets that can be reproduced by others.  Using his example to generate a 100 row DataFrame of stock prices: \n stocks = pd.DataFrame({ \n    'ticker':np.repeat( ['aapl','goog','yhoo','msft'], 25 ),\n    'date':np.tile( pd.date_range('1/1/2011', periods=25, freq='D'), 4 ),\n    'price':(np.random.randn(100).cumsum() + 10) })\n \n If this was your actual data, you may just want to include the head and/or tail of the dataframe as follows (be sure to anonymize any sensitive data): \n >>> stocks.head(5).to_dict()\n{'date': {0: Timestamp('2011-01-01 00:00:00'),\n  1: Timestamp('2011-01-01 00:00:00'),\n  2: Timestamp('2011-01-01 00:00:00'),\n  3: Timestamp('2011-01-01 00:00:00'),\n  4: Timestamp('2011-01-02 00:00:00')},\n 'price': {0: 10.284260107718254,\n  1: 11.930300761831457,\n  2: 10.93741046217319,\n  3: 10.884574289565609,\n  4: 11.78005850418319},\n 'ticker': {0: 'aapl', 1: 'aapl', 2: 'aapl', 3: 'aapl', 4: 'aapl'}}\n\n>>> pd.concat([stocks.head(), stocks.tail()], ignore_index=True).to_dict()\n{'date': {0: Timestamp('2011-01-01 00:00:00'),\n  1: Timestamp('2011-01-01 00:00:00'),\n  2: Timestamp('2011-01-01 00:00:00'),\n  3: Timestamp('2011-01-01 00:00:00'),\n  4: Timestamp('2011-01-02 00:00:00'),\n  5: Timestamp('2011-01-24 00:00:00'),\n  6: Timestamp('2011-01-25 00:00:00'),\n  7: Timestamp('2011-01-25 00:00:00'),\n  8: Timestamp('2011-01-25 00:00:00'),\n  9: Timestamp('2011-01-25 00:00:00')},\n 'price': {0: 10.284260107718254,\n  1: 11.930300761831457,\n  2: 10.93741046217319,\n  3: 10.884574289565609,\n  4: 11.78005850418319,\n  5: 10.017209045035006,\n  6: 10.57090128181566,\n  7: 11.442792747870204,\n  8: 11.592953372130493,\n  9: 12.864146419530938},\n 'ticker': {0: 'aapl',\n  1: 'aapl',\n  2: 'aapl',\n  3: 'aapl',\n  4: 'aapl',\n  5: 'msft',\n  6: 'msft',\n  7: 'msft',\n  8: 'msft',\n  9: 'msft'}}\n \n You may also want to provide a description of the DataFrame (using only the relevant columns).  This makes it easier for others to check the data types of each column and identify other common errors (e.g. dates as string vs. datetime64 vs. object): \n stocks.info()\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 100 entries, 0 to 99\nData columns (total 3 columns):\ndate      100 non-null datetime64[ns]\nprice     100 non-null float64\nticker    100 non-null object\ndtypes: datetime64[ns](1), float64(1), object(1)\n \n NOTE:  If your DataFrame has a MultiIndex: \n If your DataFrame has a multiindex, you must first reset before calling  to_dict .  You then need to recreate the index using  set_index : \n # MultiIndex example.  First create a MultiIndex DataFrame.\ndf = stocks.set_index(['date', 'ticker'])\n>>> df\n                       price\ndate       ticker           \n2011-01-01 aapl    10.284260\n           aapl    11.930301\n           aapl    10.937410\n           aapl    10.884574\n2011-01-02 aapl    11.780059\n...\n\n# After resetting the index and passing the DataFrame to `to_dict`, make sure to use \n# `set_index` to restore the original MultiIndex.  This DataFrame can then be restored.\n\nd = df.reset_index().to_dict()\ndf_new = pd.DataFrame(d).set_index(['date', 'ticker'])\n>>> df_new.head()\n                       price\ndate       ticker           \n2011-01-01 aapl    10.284260\n           aapl    11.930301\n           aapl    10.937410\n           aapl    10.884574\n2011-01-02 aapl    11.780059\n \n    ", "date_posted": "2020-06-20 09:12:55Z", "upvote": "\r\n            38\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}, {"stack_answer_id": "41189949", "answer_content": "\r\n Here is my version of  dput  - the standard R tool to produce reproducible reports - for Pandas  DataFrame s.\nIt will probably fail for more complex frames, but it seems to do the job in simple cases: \n import pandas as pd\ndef dput(x):\n    if isinstance(x,pd.Series):\n        return \"pd.Series(%s,dtype='%s',index=pd.%s)\" % (list(x),x.dtype,x.index)\n    if isinstance(x,pd.DataFrame):\n        return \"pd.DataFrame({\" + \", \".join([\n            \"'%s': %s\" % (c,dput(x[c])) for c in x.columns]) + (\n                \"}, index=pd.%s)\" % (x.index))\n    raise NotImplementedError(\"dput\",type(x),x)\n \n now, \n df = pd.DataFrame({'a':[1,2,3,4,2,1,3,1]})\nassert df.equals(eval(dput(df)))\ndu = pd.get_dummies(df.a,\"foo\")\nassert du.equals(eval(dput(du)))\ndi = df\ndi.index = list('abcdefgh')\nassert di.equals(eval(dput(di)))\n \n Note  that this produces a much more verbose output than  DataFrame.to_dict , e.g., \n \n pd.DataFrame({\n  'foo_1':pd.Series([1, 0, 0, 0, 0, 1, 0, 1],dtype='uint8',index=pd.RangeIndex(start=0, stop=8, step=1)),\n  'foo_2':pd.Series([0, 1, 0, 0, 1, 0, 0, 0],dtype='uint8',index=pd.RangeIndex(start=0, stop=8, step=1)),\n  'foo_3':pd.Series([0, 0, 1, 0, 0, 0, 1, 0],dtype='uint8',index=pd.RangeIndex(start=0, stop=8, step=1)),\n  'foo_4':pd.Series([0, 0, 0, 1, 0, 0, 0, 0],dtype='uint8',index=pd.RangeIndex(start=0, stop=8, step=1))},\n  index=pd.RangeIndex(start=0, stop=8, step=1))\n \n \n vs \n \n {'foo_1': {0: 1, 1: 0, 2: 0, 3: 0, 4: 0, 5: 1, 6: 0, 7: 1}, \n 'foo_2': {0: 0, 1: 1, 2: 0, 3: 0, 4: 1, 5: 0, 6: 0, 7: 0}, \n 'foo_3': {0: 0, 1: 0, 2: 1, 3: 0, 4: 0, 5: 0, 6: 1, 7: 0}, \n 'foo_4': {0: 0, 1: 0, 2: 0, 3: 1, 4: 0, 5: 0, 6: 0, 7: 0}}\n \n \n for  du  above, but it  preserves column types .\nE.g., in the above test case, \n du.equals(pd.DataFrame(du.to_dict()))\n==> False\n \n because  du.dtypes  is  uint8  and  pd.DataFrame(du.to_dict()).dtypes  is  int64 . \n    ", "date_posted": "2020-11-08 03:20:49Z", "upvote": "\r\n            21\r\n        ", "accepted": "No", "user": {"stack_user_id": "50065", "name": "BioGeek", "reputation_score": "21.1k"}, "answer_comments": [{"stack_answer_id": "41189949", "stack_answer_comment_id": "71988989", "comment_content": "it is clearer, though i admit i don't see why i would want to use it over ", "user_id": "None"}, {"stack_answer_id": "41189949", "stack_answer_comment_id": "71989097", "comment_content": "Because it preserves column types. More specifically, ", "user_id": "None"}, {"stack_answer_id": "41189949", "stack_answer_comment_id": "124382725", "comment_content": "I like this. I have a more modern version with interpolated strings, which also breaks up the output with line breaks: ", "user_id": "None"}]}], "user": {"stack_user_id": "1222578", "name": "Marius", "reputation_score": "55.5k"}, "question_comments": [{"stack_question_id": "20109391", "stack_question_comment_id": "29965074", "comment_content": "If you copy the output of printing, most of the time answerers can use read_clipboard()... except for MultiIndex :s. Saying that, dict is good addition", "user_id": "None"}, {"stack_question_id": "20109391", "stack_question_comment_id": "29965293", "comment_content": "In addition to what Andy said, I think copy-pasting ", "user_id": "None"}]},
{"stack_question_id": "1132941", "question_title": "\"Least Astonishment\" and the Mutable Default Argument", "question_content": "\r\n                Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:\ndef foo(a=[]):\n    a.append(5)\n    return a\n\nPython novices would expect this function called with ...\r\n", "question_url": "/questions/1132941/least-astonishment-and-the-mutable-default-argument", "date_posted": "Jul 15, 2009 at 18:00", "upvote": "3", "view": "2", "tags": ["python", "language-design", "default-parameters", "least-astonishment"], "answers_count": "3", "answers": [{"stack_answer_id": "1145781", "answer_content": "\r\n Actually, this is not a design flaw, and it is not because of internals or performance. It comes simply from the fact that functions in Python are first-class objects, and not only a piece of code. \n As soon as you think of it this way, then it completely makes sense: a function is an object being evaluated on its definition; default parameters are kind of \"member data\" and therefore their state may change from one call to the other - exactly as in any other object. \n In any case, the effbot (Fredrik Lundh) has a very nice explanation of the reasons for this behavior in  Default Parameter Values in Python .\nI found it very clear, and I really suggest reading it for a better knowledge of how function objects work. \n    ", "date_posted": "2022-06-10 08:20:18Z", "upvote": "\r\n            1836\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "355230", "name": "martineau", "reputation_score": "115k"}, "answer_comments": [{"stack_answer_id": "1145781", "stack_answer_comment_id": "9448792", "comment_content": "To anyone reading the above answer, I strongly recommend you take the time to read through the linked Effbot article. As well as all the other useful info, the part on how this language feature can be used for result caching/memoisation is very handy to know!", "user_id": "None"}, {"stack_answer_id": "1145781", "stack_answer_comment_id": "19820636", "comment_content": "Even if it's a first-class object, one might still envision a design where the ", "user_id": "None"}, {"stack_answer_id": "1145781", "stack_answer_comment_id": "24551066", "comment_content": "Sorry, but anything considered \"The biggest WTF in Python\" is ", "user_id": "None"}, {"stack_answer_id": "1145781", "stack_answer_comment_id": "31573411", "comment_content": "Whether or not it's a design flaw, your answer seems to imply that this behaviour is somehow necessary, natural and obvious given that functions are first-class objects, and that simply isn't the case. Python has closures. If you replace the default argument with an assignment on the first line of the function, it evaluates the expression each call (potentially using names declared in an enclosing scope). There is no reason at all that it wouldn't be possible or reasonable to have default arguments evaluated each time the function is called in exactly the same way.", "user_id": "None"}, {"stack_answer_id": "1145781", "stack_answer_comment_id": "35944779", "comment_content": "The design doesn't directly follow from ", "user_id": "None"}]}, {"stack_answer_id": "1133013", "answer_content": "\r\n Suppose you have the following code \n fruits = (\"apples\", \"bananas\", \"loganberries\")\n\ndef eat(food=fruits):\n    ...\n \n When I see the declaration of eat, the least astonishing thing is to think that if the first parameter is not given, that it will be equal to the tuple  (\"apples\", \"bananas\", \"loganberries\") \n However, suppose later on in the code, I do something like \n def some_random_function():\n    global fruits\n    fruits = (\"blueberries\", \"mangos\")\n \n then if default parameters were bound at function execution rather than function declaration, I would be astonished (in a very bad way) to discover that fruits had been changed. This would be more astonishing IMO than discovering that your  foo  function above was mutating the list. \n The real problem lies with mutable variables, and all languages have this problem to some extent. Here's a question: suppose in Java I have the following code: \n StringBuffer s = new StringBuffer(\"Hello World!\");\nMap<StringBuffer,Integer> counts = new HashMap<StringBuffer,Integer>();\ncounts.put(s, 5);\ns.append(\"!!!!\");\nSystem.out.println( counts.get(s) );  // does this work?\n \n Now, does my map use the value of the  StringBuffer  key when it was placed into the map, or does it store the key by reference? Either way, someone is astonished; either the person who tried to get the object out of the  Map  using a value identical to the one they put it in with, or the person who can't seem to retrieve their object even though the key they're using is literally the same object that was used to put it into the map (this is actually why Python doesn't allow its mutable built-in data types to be used as dictionary keys). \n Your example is a good one of a case where Python newcomers will be surprised and bitten. But I'd argue that if we \"fixed\" this, then that would only create a different situation where they'd be bitten instead, and that one would be even less intuitive. Moreover, this is always the case when dealing with mutable variables; you always run into cases where someone could intuitively expect one or the opposite behavior depending on what code they're writing. \n I personally like Python's current approach: default function arguments are evaluated when the function is defined and that object is always the default. I suppose they could special-case using an empty list, but that kind of special casing would cause even more astonishment, not to mention be backwards incompatible. \n    ", "date_posted": "2021-07-30 23:44:28Z", "upvote": "\r\n            319\r\n        ", "accepted": "No", "user": {"stack_user_id": "7487335", "name": "Josh Correia", "reputation_score": "2,999"}, "answer_comments": [{"stack_answer_id": "1133013", "stack_answer_comment_id": "950511", "comment_content": "I think it's a matter of debate. You are acting on a global variable. Any evaluation performed anywhere in your code involving your global variable will now (correctly) refer to (\"blueberries\", \"mangos\"). the default parameter could just be like any other case.", "user_id": "78374"}, {"stack_answer_id": "1133013", "stack_answer_comment_id": "950592", "comment_content": "Actually, I don't think I agree with your first example.  I'm not sure I like the idea of modifying an initializer like that in the first place, but if I did, I'd expect it to behave exactly as you describe \u2014 changing the default value to ", "user_id": "None"}, {"stack_answer_id": "1133013", "stack_answer_comment_id": "950800", "comment_content": "The default parameter ", "user_id": "None"}, {"stack_answer_id": "1133013", "stack_answer_comment_id": "41236608", "comment_content": "I find the example misleading rather than brilliant. If ", "user_id": "None"}, {"stack_answer_id": "1133013", "stack_answer_comment_id": "44679235", "comment_content": "You just explicitly declared ", "user_id": "None"}]}, {"stack_answer_id": "11416002", "answer_content": "\r\n The relevant part of the  documentation : \n\n \n   Default parameter values are evaluated from left to right when the function definition is executed.  This means that the expression is evaluated once, when the function is defined, and that the same \u201cpre-computed\u201d value is used for each call. This is especially important to understand when a default parameter is a mutable object, such as a list or a dictionary: if the function modifies the object (e.g. by appending an item to a list), the default value is in effect modified. This is generally not what was intended. A way around this is to use  None  as the default, and explicitly test for it in the body of the function, e.g.: \n\n def whats_on_the_telly(penguin=None):\n    if penguin is None:\n        penguin = []\n    penguin.append(\"property of the zoo\")\n    return penguin\n \n \n    ", "date_posted": "2020-01-30 18:00:14Z", "upvote": "\r\n            295\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": [{"stack_answer_id": "11416002", "stack_answer_comment_id": "35944900", "comment_content": "The phrases \"this is not generally what was intended\" and \"a way around this is\" smell like they're documenting a design flaw.", "user_id": "None"}, {"stack_answer_id": "11416002", "stack_answer_comment_id": "37577356", "comment_content": "@bukzor: Pitfalls need to be noted and documented, which is why this question is good and has received so many upvotes. At the same time, pitfalls don't necessarily need to be removed. How many Python beginners have passed a list to a function that modified it, and were shocked to see the changes show up in the original variable? Yet mutable object types are wonderful, when you understand how to use them. I guess it just boils down to opinion on this particular pitfall.", "user_id": "None"}, {"stack_answer_id": "11416002", "stack_answer_comment_id": "43555974", "comment_content": "The phrase \"this is not generally what was intended\" means \"not what the programmer actually wanted to happen,\" not \"not what Python is supposed to do.\"", "user_id": "None"}, {"stack_answer_id": "11416002", "stack_answer_comment_id": "80032999", "comment_content": "@holdenweb Wow, I'm mega-late to the party. Given the context, bukzor is completely right: they're documenting behavior/consequence that was not \"intended\" when they they decided the language should exec the function's definition. Since it's an unintended consequence of their design choice, it's a design flaw. If it were not a design flaw, there'd be no need to even offer \"a way around this\".", "user_id": "None"}, {"stack_answer_id": "11416002", "stack_answer_comment_id": "80051888", "comment_content": "We could take it to chat and discuss how else it could be, but the semantics have been thoroughly debated and nobody could come up with a sensible mechanism for create-default-value-on-call. One serious issue is that the scope on call is often entirely different from that on definition, making name resolution uncertain if defaults were evaluated at call time. A \"way around\" means \"you can achieve your desired end in the following way,\" not \"this is a mistake in Python's design.\"", "user_id": "None"}]}, {"stack_answer_id": "1134623", "answer_content": "\r\n I know nothing about the Python interpreter inner workings (and I'm not an expert in compilers and interpreters either) so don't blame me if I propose anything unsensible or impossible. \n\n Provided that python objects  are mutable  I think that this should be taken into account when designing the default arguments stuff.\nWhen you instantiate a list: \n\n a = []\n \n\n you expect to get a  new  list referenced by  a . \n\n Why should the  a=[]  in \n\n def x(a=[]):\n \n\n instantiate a new list on function definition and not on invocation?\nIt's just like you're asking \"if the user doesn't provide the argument then  instantiate  a new list and use it as if it was produced by the caller\".\nI think this is ambiguous instead: \n\n def x(a=datetime.datetime.now()):\n \n\n user, do you want  a  to default to the datetime corresponding to when you're defining or executing  x ?\nIn this case, as in the previous one, I'll keep the same behaviour as if the default argument \"assignment\" was the first instruction of the function ( datetime.now()  called on function invocation).\nOn the other hand, if the user wanted the definition-time mapping he could write: \n\n b = datetime.datetime.now()\ndef x(a=b):\n \n\n I know, I know: that's a closure. Alternatively Python might provide a keyword to force definition-time binding: \n\n def x(static a=b):\n \n    ", "date_posted": "2019-05-09 09:15:36Z", "upvote": "\r\n            139\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "1134623", "stack_answer_comment_id": "952595", "comment_content": "You could do: def x(a=None): And then, if a is None, set a=datetime.datetime.now()", "user_id": "None"}, {"stack_answer_id": "1134623", "stack_answer_comment_id": "6587169", "comment_content": "Thank you for this. I couldn't really put my finger on why this  irks me to no end. You have done it beautifully with a minimum of fuzz and confusion. As someone comming from systems programming in C++ and sometimes naively \"translating\" language features, this false friend kicked me in the in the soft of the head big time, just like class attributes. I understand why things are this way, but I cannot help but dislike it, no matter what positive might come of it. At least it is so contrary to my experience, that I'll probably (hopefully) never forget it...", "user_id": "None"}, {"stack_answer_id": "1134623", "stack_answer_comment_id": "8065966", "comment_content": "@Andreas once you use Python for long enough, you begin to see how logical it is for Python to interpret things as class attributes the way it does - it is only because of the particular quirks and limitations of languages like C++ (and Java, and C#...) that it makes any sense for contents of the ", "user_id": "None"}, {"stack_answer_id": "1134623", "stack_answer_comment_id": "8112414", "comment_content": "Normative structure is no quirk or limitation in my book. I know it can be clumsy and ugly, but you can call it a \"definition\" of something. The dynamic languages seem a bit like anarchists to me: Sure everybody is free, but you need structure to get someone to empty the trash and pave the road. Guess I'm old... :)", "user_id": "None"}, {"stack_answer_id": "1134623", "stack_answer_comment_id": "46876103", "comment_content": "The function ", "user_id": "None"}]}, {"stack_answer_id": "1133255", "answer_content": "\r\n Well, the reason is quite simply that bindings are done when code is executed, and the function definition is executed, well... when the functions is defined. \n\n Compare this: \n\n class BananaBunch:\n    bananas = []\n\n    def addBanana(self, banana):\n        self.bananas.append(banana)\n \n\n This code suffers from the exact same unexpected happenstance. bananas is a class attribute, and hence, when you add things to it, it's added to all instances of that class. The reason is exactly the same. \n\n It's just \"How It Works\", and making it work differently in the function case would probably be complicated, and in the class case likely impossible, or at least slow down object instantiation a lot, as you would have to keep the class code around and execute it when objects are created. \n\n Yes, it is unexpected. But once the penny drops, it fits in perfectly with how Python works in general. In fact, it's a good teaching aid, and once you understand why this happens, you'll grok python much better. \n\n That said it should feature prominently in any good Python tutorial. Because as you mention, everyone runs into this problem sooner or later. \n    ", "date_posted": "2014-12-19 22:53:35Z", "upvote": "\r\n            93\r\n        ", "accepted": "No", "user": {"stack_user_id": "126214", "name": "Lennart Regebro", "reputation_score": "161k"}, "answer_comments": [{"stack_answer_id": "1133255", "stack_answer_comment_id": "950835", "comment_content": "How do you define a class attribute that is different for each instance of a class?", "user_id": "None"}, {"stack_answer_id": "1133255", "stack_answer_comment_id": "950938", "comment_content": "If it's different for each instance it's not a class attribute. Class attributes are attributes on the CLASS. Hence the name. Hence they are the same for all instances.", "user_id": "None"}, {"stack_answer_id": "1133255", "stack_answer_comment_id": "955561", "comment_content": "How do you define an attribute in a class that is different for each instance of a class? (Re-defined for those who could not determine that a person not familiar with Python's naming convenctions might be asking about normal member variables of a class).", "user_id": "None"}, {"stack_answer_id": "1133255", "stack_answer_comment_id": "955627", "comment_content": "@Kievieli: You ARE talking about normal member variables of a class. :-)  You define instance attributes by saying self.attribute = value in any method. For example __init__().", "user_id": "None"}, {"stack_answer_id": "1133255", "stack_answer_comment_id": "10928164", "comment_content": "@Kieveli: Two answers:  you can't, because any thing you define at a class level will be a class attribute, and any instance that accesses that attribute will access the same class attribute; you can, /sort of/, by using ", "user_id": "None"}]}, {"stack_answer_id": "34172768", "answer_content": "\r\n Why don't you introspect? \n\n I'm  really  surprised no one has performed the insightful introspection offered by Python ( 2  and  3  apply) on callables.  \n\n Given a simple little function  func  defined as: \n\n >>> def func(a = []):\n...    a.append(5)\n \n\n When Python encounters it, the first thing it will do is compile it in order to create a  code  object for this function. While this compilation step is done,  Python  evaluates * and then  stores  the default arguments (an empty list  []  here) in the function object itself . As the top answer mentioned: the list  a  can now be considered a  member  of the function  func . \n\n So, let's do some introspection, a before and after to examine how the list gets expanded  inside  the function object. I'm using  Python 3.x  for this, for Python 2 the same applies (use  __defaults__  or  func_defaults  in Python 2; yes, two names for the same thing). \n\n Function Before Execution: \n\n >>> def func(a = []):\n...     a.append(5)\n...     \n \n\n After Python executes this definition it will take any default parameters specified ( a = []  here) and  cram them in the  __defaults__  attribute for the function object  (relevant section: Callables):      \n\n >>> func.__defaults__\n([],)\n \n\n O.k, so an empty list as the single entry in  __defaults__ , just as expected.  \n\n Function After Execution: \n\n Let's now execute this function: \n\n >>> func()\n \n\n Now, let's see those  __defaults__  again:  \n\n >>> func.__defaults__\n([5],)\n \n\n Astonished?  The value inside the object changes! Consecutive calls to the function will now simply append to that embedded  list  object: \n\n >>> func(); func(); func()\n>>> func.__defaults__\n([5, 5, 5, 5],)\n \n\n So, there you have it, the reason why this  'flaw'  happens, is because default arguments are part of the function object. There's nothing weird going on here, it's all just a bit surprising. \n\n The common solution to combat this is to use  None  as the default and then initialize in the function body: \n\n def func(a = None):\n    # or: a = [] if a is None else a\n    if a is None:\n        a = []\n \n\n Since the function body is executed anew each time, you always get a fresh new empty list if no argument was passed for  a . \n\n \n\n To further verify that the list in  __defaults__  is the same as that used in the function  func  you can just change your function to return the  id  of the list  a  used inside the function body. Then, compare it to the list in  __defaults__  (position  [0]  in  __defaults__ ) and you'll see how these are indeed refering to the same list instance: \n\n >>> def func(a = []): \n...     a.append(5)\n...     return id(a)\n>>>\n>>> id(func.__defaults__[0]) == func()\nTrue\n \n\n All with the power of introspection!  \n\n \n\n *  To verify that Python evaluates the default arguments during compilation of the function, try executing the following: \n\n def bar(a=input('Did you just see me without calling the function?')): \n    pass  # use raw_input in Py2\n \n\n as you'll notice,  input()  is called before the process of building the function and binding it to the name  bar  is made. \n    ", "date_posted": "2018-10-11 16:33:49Z", "upvote": "\r\n            81\r\n        ", "accepted": "No", "user": {"stack_user_id": "4850040", "name": "Toby Speight", "reputation_score": "25.5k"}, "answer_comments": [{"stack_answer_id": "34172768", "stack_answer_comment_id": "59433843", "comment_content": "Is ", "user_id": "None"}, {"stack_answer_id": "34172768", "stack_answer_comment_id": "59434204", "comment_content": "@das-g ", "user_id": "None"}, {"stack_answer_id": "34172768", "stack_answer_comment_id": "103227664", "comment_content": "Using ", "user_id": "None"}]}, {"stack_answer_id": "1136611", "answer_content": "\r\n I used to think that creating the objects at runtime would be the better approach.  I'm less certain now, since you do lose some useful features, though it may be worth it regardless simply to prevent newbie confusion.  The disadvantages of doing so are: \n\n 1. Performance \n\n def foo(arg=something_expensive_to_compute())):\n    ...\n \n\n If call-time evaluation is used, then the expensive function is called every time your function is used without an argument.  You'd either pay an expensive price on each call, or need to manually cache the value externally, polluting your namespace and adding verbosity. \n\n 2. Forcing bound parameters \n\n A useful trick is to bind parameters of a lambda to the  current  binding of a variable when the lambda is created.  For example: \n\n funcs = [ lambda i=i: i for i in range(10)]\n \n\n This returns a list of functions that return 0,1,2,3... respectively.  If the behaviour is changed, they will instead bind  i  to the  call-time  value of i, so you would get a list of functions that all returned  9 . \n\n The only way to implement this otherwise would be to create a further closure with the i bound, ie: \n\n def make_func(i): return lambda: i\nfuncs = [make_func(i) for i in range(10)]\n \n\n 3. Introspection \n\n Consider the code: \n\n def foo(a='test', b=100, c=[]):\n   print a,b,c\n \n\n We can get information about the arguments and defaults using the  inspect  module, which  \n\n >>> inspect.getargspec(foo)\n(['a', 'b', 'c'], None, None, ('test', 100, []))\n \n\n This information is very useful for things like document generation, metaprogramming, decorators etc. \n\n Now, suppose the behaviour of defaults could be changed so that this is the equivalent of: \n\n _undefined = object()  # sentinel value\n\ndef foo(a=_undefined, b=_undefined, c=_undefined)\n    if a is _undefined: a='test'\n    if b is _undefined: b=100\n    if c is _undefined: c=[]\n \n\n However, we've lost the ability to introspect, and see what the default arguments  are .  Because the objects haven't been constructed, we can't ever get hold of them without actually calling the function.  The best we could do is to store off the source code and return that as a string. \n    ", "date_posted": "2009-07-16 19:13:35Z", "upvote": "\r\n            65\r\n        ", "accepted": "No", "user": {"stack_user_id": "9493", "name": "Brian", "reputation_score": "114k"}, "answer_comments": [{"stack_answer_id": "1136611", "stack_answer_comment_id": "954490", "comment_content": "you could achieve introspection also if for each there was a function to create the default argument instead of a value. the inspect module will just call that function.", "user_id": "None"}, {"stack_answer_id": "1136611", "stack_answer_comment_id": "954611", "comment_content": "@SilentGhost:  I'm talking about if the behaviour was changed to recreate it - creating it once is the current behaviour, and why the mutable default problem exists.", "user_id": "None"}, {"stack_answer_id": "1136611", "stack_answer_comment_id": "954628", "comment_content": "@yairchu: That assumes the construction is safe to so (ie has no side effects).  Introspecting the args shouldn't ", "user_id": "None"}, {"stack_answer_id": "1136611", "stack_answer_comment_id": "957188", "comment_content": "A different language design often just means writing things differently.  Your first example could easily be written as: _expensive = expensive(); def foo(arg=_expensive), if you specifically ", "user_id": "None"}, {"stack_answer_id": "1136611", "stack_answer_comment_id": "957359", "comment_content": "@Glenn - that's what I was referring to with \"cache the variable externally\" - it is a bit more verbose, and you end up with extra variables in your namespace though.", "user_id": "None"}]}, {"stack_answer_id": "29344819", "answer_content": "\r\n 5 points in defense of Python \n \n Simplicity : The behavior is simple in the following sense:\nMost people fall into this trap only once, not several times. \n \n Consistency : Python  always  passes objects, not names.\nThe default parameter is, obviously, part of the function\nheading (not the function body). It therefore ought to be evaluated\nat module load time (and only at module load time, unless nested), not\nat function call time. \n \n Usefulness : As Frederik Lundh points out in his explanation\nof  \"Default Parameter Values in Python\" , the\ncurrent behavior can be quite useful for advanced programming.\n(Use sparingly.) \n \n Sufficient documentation : In the most basic Python documentation,\nthe tutorial, the issue is loudly announced as\nan  \"Important warning\"  in the  first  subsection of Section\n \"More on Defining Functions\" .\nThe warning even uses boldface,\nwhich is rarely applied outside of headings.\nRTFM: Read the fine manual. \n \n Meta-learning : Falling into the trap is actually a very\nhelpful moment (at least if you are a reflective learner),\nbecause you will subsequently better understand the point\n\"Consistency\" above and that will\nteach you a great deal about Python. \n \n \n    ", "date_posted": "2021-01-21 12:41:46Z", "upvote": "\r\n            65\r\n        ", "accepted": "No", "user": {"stack_user_id": "13367995", "name": "jakubde", "reputation_score": "27"}, "answer_comments": [{"stack_answer_id": "29344819", "stack_answer_comment_id": "52693997", "comment_content": "It took me a year to find this behavior is messing up my code on production, ended up removing a complete feature until I bumped into this design flaw by chance.  I'm using Django.  Since the staging environment did not have many requests, this bug never had any impact on QA.  When we went live and received many simultaneous requests - some utility functions started overwriting each other's parameters!  Making security holes, bugs and what not.", "user_id": "None"}, {"stack_answer_id": "29344819", "stack_answer_comment_id": "65774123", "comment_content": "@oriadam, no offense, but I wonder how you learned Python without running into this before.  I am just learning Python now and this possible pitfall is ", "user_id": "None"}, {"stack_answer_id": "29344819", "stack_answer_comment_id": "65920805", "comment_content": "Also, it would be surprising (to me) if a function of unknown complexity was called in addition to the function call I am making.", "user_id": "None"}, {"stack_answer_id": "29344819", "stack_answer_comment_id": "115930547", "comment_content": "@oriadam, your company needs code review and actual expert coders in the language they write in by the time they have development, staging and production environments. Newbie bugs and bad code habits should not make it to production code", "user_id": "None"}]}, {"stack_answer_id": "1133375", "answer_content": "\r\n This behavior is easy explained by: \n\n \n function (class etc.) declaration is executed only once, creating all default value objects \n everything is passed by reference \n \n\n So: \n\n def x(a=0, b=[], c=[], d=0):\n    a = a + 1\n    b = b + [1]\n    c.append(1)\n    print a, b, c\n \n\n \n a  doesn't change - every assignment call creates new int object - new object is printed \n b  doesn't change - new array is build from default value and printed \n c  changes - operation is performed on same object - and it is printed \n \n    ", "date_posted": "2017-10-24 06:34:34Z", "upvote": "\r\n            57\r\n        ", "accepted": "No", "user": {"stack_user_id": "4952130", "name": "Dimitris Fasarakis Hilliard", "reputation_score": "139k"}, "answer_comments": [{"stack_answer_id": "1133375", "stack_answer_comment_id": "952500", "comment_content": "(Actually, ", "user_id": "None"}, {"stack_answer_id": "1133375", "stack_answer_comment_id": "952539", "comment_content": "Realized it to my chagrin after checking to see that, with b set to [], b.__add__([1]) returns [1] but also leaves b still [] even though lists are mutable.  My bad.", "user_id": "None"}, {"stack_answer_id": "1133375", "stack_answer_comment_id": "36118858", "comment_content": "@ANon: there is ", "user_id": "None"}]}, {"stack_answer_id": "13518071", "answer_content": "\r\n 1)  The so-called problem of \"Mutable Default Argument\" is in general a special example demonstrating that: \n\"All functions with this problem  suffer also from similar side effect problem on the actual parameter ,\" \nThat is against the rules of functional programming, usually undesiderable and should be fixed both together. \n\n Example: \n\n def foo(a=[]):                 # the same problematic function\n    a.append(5)\n    return a\n\n>>> somevar = [1, 2]           # an example without a default parameter\n>>> foo(somevar)\n[1, 2, 5]\n>>> somevar\n[1, 2, 5]                      # usually expected [1, 2]\n \n\n Solution :  a  copy \nAn absolutely safe solution is to  copy  or  deepcopy  the input object first and then to do whatever with the copy. \n\n def foo(a=[]):\n    a = a[:]     # a copy\n    a.append(5)\n    return a     # or everything safe by one line: \"return a + [5]\"\n \n\n Many builtin mutable types have a copy method like  some_dict.copy()  or  some_set.copy()  or can be copied easy like  somelist[:]  or  list(some_list) . Every object can be also copied by  copy.copy(any_object)  or more thorough by  copy.deepcopy()  (the latter useful if the mutable object is composed from mutable objects). Some objects are fundamentally based on side effects like \"file\" object and can not be meaningfully reproduced by copy.  copying \n\n Example problem for  a similar SO question \n\n class Test(object):            # the original problematic class\n  def __init__(self, var1=[]):\n    self._var1 = var1\n\nsomevar = [1, 2]               # an example without a default parameter\nt1 = Test(somevar)\nt2 = Test(somevar)\nt1._var1.append([1])\nprint somevar                  # [1, 2, [1]] but usually expected [1, 2]\nprint t2._var1                 # [1, 2, [1]] but usually expected [1, 2]\n \n\n It shouldn't be neither saved in any  public  attribute of an instance returned by this function. (Assuming that  private  attributes of instance should not be modified from outside of this class or subclasses by convention. i.e.  _var1  is a private attribute ) \n\n Conclusion: \nInput parameters objects shouldn't be modified in place (mutated) nor they should not be binded into an object returned by the function. (If we prefere programming without side effects which is strongly recommended. see  Wiki about \"side effect\"  (The first two paragraphs are relevent in this context.)\n.) \n\n 2) \nOnly if the side effect on the actual parameter is required but unwanted on the default parameter then the useful solution is  def ...(var1=None):   if var1 is None:   var1 = []   More.. \n\n 3) In some cases is  the mutable behavior of default parameters useful . \n    ", "date_posted": "2017-05-23 11:47:32Z", "upvote": "\r\n            39\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": [{"stack_answer_id": "13518071", "stack_answer_comment_id": "36118939", "comment_content": "I hope you're aware that Python is ", "user_id": "None"}, {"stack_answer_id": "13518071", "stack_answer_comment_id": "36126140", "comment_content": "Yes, Python is a multi-paragigm language with some functional features. (\"Don't make every problem look like a nail just because you have a hammer.\") Many of them are in Python best practicies. Python has an interesting ", "user_id": "None"}, {"stack_answer_id": "13518071", "stack_answer_comment_id": "83550760", "comment_content": "I'd also add, at this late stage, that Python's assignment semantics have been designed explicitly to avoid data copying where necessary, so the creation of copies (and especially of deep copies) will affect both run-time and memory usage adversely. They should therefore be used only when necessary, but newcomers often have difficulty understanding when that is.", "user_id": "None"}, {"stack_answer_id": "13518071", "stack_answer_comment_id": "83606638", "comment_content": "@holdenweb I agree. A temporary copy is the most usual way and sometimes the only possible way how to protect the original mutable data from an extraneous function that modifies them potentially. Fortunately a function that unreasonably modifies data is considered a bug and therefore uncommon.", "user_id": "None"}, {"stack_answer_id": "13518071", "stack_answer_comment_id": "84665509", "comment_content": "I agree with this answer. And I don't understand why the ", "user_id": "None"}]}, {"stack_answer_id": "1133737", "answer_content": "\r\n What you're asking is why this: \n\n def func(a=[], b = 2):\n    pass\n \n\n isn't internally equivalent to this: \n\n def func(a=None, b = None):\n    a_default = lambda: []\n    b_default = lambda: 2\n    def actual_func(a=None, b=None):\n        if a is None: a = a_default()\n        if b is None: b = b_default()\n    return actual_func\nfunc = func()\n \n\n except for the case of explicitly calling func(None, None), which we'll ignore. \n\n In other words, instead of evaluating default parameters, why not store each of them, and evaluate them when the function is called? \n\n One answer is probably right there--it would effectively turn every function with default parameters into a closure.  Even if it's all hidden away in the interpreter and not a full-blown closure, the data's got to be stored somewhere.  It'd be slower and use more memory. \n    ", "date_posted": "2009-07-15 20:18:14Z", "upvote": "\r\n            38\r\n        ", "accepted": "No", "user": {"stack_user_id": "136829", "name": "Glenn Maynard", "reputation_score": "54k"}, "answer_comments": [{"stack_answer_id": "1133737", "stack_answer_comment_id": "954338", "comment_content": "It wouldn't need to be a closure - a better way to think of it would simply to make the bytecode creating defaults the first line of code - after all you're compiling the body at that point anyway - there's no real difference between code in the arguments and code in the body.", "user_id": "None"}, {"stack_answer_id": "1133737", "stack_answer_comment_id": "954824", "comment_content": "True, but it would still slow Python down, and it would actually be quite surprising, unless you do the same for class definitions, which would make it stupidly slow as you would have to re-run the whole class definition each time you instantiate a class.  As mentioned, the fix would be more surprising than the problem.", "user_id": "None"}, {"stack_answer_id": "1133737", "stack_answer_comment_id": "955297", "comment_content": "Agreed with Lennart.  As Guido is fond of saying, for every language feature or standard library, there's ", "user_id": "None"}, {"stack_answer_id": "1133737", "stack_answer_comment_id": "957116", "comment_content": "Changing it now would be insanity--we're just exploring why it is the way it is.  If it did late default evaluation to begin with, it wouldn't necessarily be surprising.  It's definitely true that such a core a difference of parsing would have sweeping, and probably many obscure, effects on the language as a whole.", "user_id": "None"}]}, {"stack_answer_id": "6092808", "answer_content": "\r\n This actually has nothing to do with default values, other than that it often comes up as an unexpected behaviour when you write functions with mutable default values. \n\n >>> def foo(a):\n    a.append(5)\n    print a\n\n>>> a  = [5]\n>>> foo(a)\n[5, 5]\n>>> foo(a)\n[5, 5, 5]\n>>> foo(a)\n[5, 5, 5, 5]\n>>> foo(a)\n[5, 5, 5, 5, 5]\n \n\n No default values in sight in this code, but you get exactly the same problem. \n\n The problem is that  foo  is  modifying  a mutable variable passed in from the caller, when the caller doesn't expect this. Code like this would be fine if the function was called something like  append_5 ; then the caller would be calling the function in order to modify the value they pass in, and the behaviour would be expected. But such a function would be very unlikely to take a default argument, and probably wouldn't return the list (since the caller already has a reference to that list; the one it just passed in). \n\n Your original  foo , with a default argument, shouldn't be modifying  a  whether it was explicitly passed in or got the default value. Your code should leave mutable arguments alone unless it is clear from the context/name/documentation that the arguments are supposed to be modified. Using mutable values passed in as arguments as local temporaries is an extremely bad idea, whether we're in Python or not and whether there are default arguments involved or not. \n\n If you need to destructively manipulate a local temporary in the course of computing something, and you need to start your manipulation from an argument value, you need to make a copy. \n    ", "date_posted": "2011-05-23 04:24:30Z", "upvote": "\r\n            30\r\n        ", "accepted": "No", "user": {"stack_user_id": "450128", "name": "Ben", "reputation_score": "63.9k"}, "answer_comments": [{"stack_answer_id": "6092808", "stack_answer_comment_id": "16186544", "comment_content": "Although related, I think this is distinct behaviour (as we expect ", "user_id": "None"}, {"stack_answer_id": "6092808", "stack_answer_comment_id": "80529225", "comment_content": "@AndyHayden if the function is ", "user_id": "None"}, {"stack_answer_id": "6092808", "stack_answer_comment_id": "80539521", "comment_content": "@AndyHayden I left my own answer here with an expansion of that sentiment. Let me know what you think. I might add your example of ", "user_id": "None"}, {"stack_answer_id": "6092808", "stack_answer_comment_id": "80546281", "comment_content": "@AndyHayden The point of my answer is that if you are ever astonished by accidentally mutating the default value of an argument, then you have another bug, which is that your code can accidentally mutate a caller's value when the default ", "user_id": "None"}, {"stack_answer_id": "6092808", "stack_answer_comment_id": "80548974", "comment_content": "@AndyHayden That's the subtle thing though, what happens in the case you describe if the caller of the constructor provides a value instead of using the default? Now you've gone and aliased your object's internal attribute to an external value owned by the caller! That sort of thing is a very rich source of hard-to-track-down bugs; it's almost ", "user_id": "None"}]}, {"stack_answer_id": "36968932", "answer_content": "\r\n Python: The Mutable Default Argument \n\n Default arguments get evaluated at the time the function is compiled into a function object. When used by the function, multiple times by that function, they are and remain the same object.  \n\n When they are mutable, when mutated (for example, by adding an element to it) they remain mutated on consecutive calls. \n\n They stay mutated because they are the same object each time. \n\n Equivalent code: \n\n Since the list is bound to the function when the function object is compiled and instantiated, this: \n\n def foo(mutable_default_argument=[]): # make a list the default argument\n    \"\"\"function that uses a list\"\"\"\n \n\n is almost exactly equivalent to this: \n\n _a_list = [] # create a list in the globals\n\ndef foo(mutable_default_argument=_a_list): # make it the default argument\n    \"\"\"function that uses a list\"\"\"\n\ndel _a_list # remove globals name binding\n \n\n Demonstration \n\n Here's a demonstration - you can verify that they are the same object each time they are referenced by  \n\n \n seeing that the list is created before the function has finished compiling to a function object, \n observing that the id is the same each time the list is referenced, \n observing that the list stays changed when the function that uses it is called a second time, \n observing the order in which the output is printed from the source (which I conveniently numbered for you): \n \n\n example.py \n\n print('1. Global scope being evaluated')\n\ndef create_list():\n    '''noisily create a list for usage as a kwarg'''\n    l = []\n    print('3. list being created and returned, id: ' + str(id(l)))\n    return l\n\nprint('2. example_function about to be compiled to an object')\n\ndef example_function(default_kwarg1=create_list()):\n    print('appending \"a\" in default default_kwarg1')\n    default_kwarg1.append(\"a\")\n    print('list with id: ' + str(id(default_kwarg1)) + \n          ' - is now: ' + repr(default_kwarg1))\n\nprint('4. example_function compiled: ' + repr(example_function))\n\n\nif __name__ == '__main__':\n    print('5. calling example_function twice!:')\n    example_function()\n    example_function()\n \n\n and running it with  python example.py : \n\n 1. Global scope being evaluated\n2. example_function about to be compiled to an object\n3. list being created and returned, id: 140502758808032\n4. example_function compiled: <function example_function at 0x7fc9590905f0>\n5. calling example_function twice!:\nappending \"a\" in default default_kwarg1\nlist with id: 140502758808032 - is now: ['a']\nappending \"a\" in default default_kwarg1\nlist with id: 140502758808032 - is now: ['a', 'a']\n \n\n Does this violate the principle of \"Least Astonishment\"? \n\n This order of execution is frequently confusing to new users of Python. If you understand the Python execution model, then it becomes quite expected.  \n\n The usual instruction to new Python users: \n\n But this is why the usual instruction to new users is to create their default arguments like this instead: \n\n def example_function_2(default_kwarg=None):\n    if default_kwarg is None:\n        default_kwarg = []\n \n\n This uses the None singleton as a sentinel object to tell the function whether or not we've gotten an argument other than the default. If we get no argument, then we actually want to use a new empty list,  [] , as the default. \n\n As the  tutorial section on control flow  says: \n\n \n   If you don\u2019t want the default to be shared between subsequent calls,\n  you can write the function like this instead: \n\n def f(a, L=None):\n    if L is None:\n        L = []\n    L.append(a)\n    return L\n \n \n    ", "date_posted": "2017-12-23 21:18:35Z", "upvote": "\r\n            28\r\n        ", "accepted": "No", "user": {"stack_user_id": "541136", "name": "Russia Must Remove Putin", "reputation_score": "347k"}, "answer_comments": []}, {"stack_answer_id": "1137164", "answer_content": "\r\n The shortest answer would probably be \"definition is execution\", therefore the whole argument makes no strict sense. As a more contrived example, you may cite this: \n\n def a(): return []\n\ndef b(x=a()):\n    print x\n \n\n Hopefully it's enough to show that not executing the default argument expressions at the execution time of the  def  statement isn't easy or doesn't make sense, or both. \n\n I agree it's a gotcha when you try to use default constructors, though. \n    ", "date_posted": "2018-05-20 23:22:19Z", "upvote": "\r\n            28\r\n        ", "accepted": "No", "user": {"stack_user_id": "3951861", "name": "Ashraf.Shk786", "reputation_score": "600"}, "answer_comments": []}, {"stack_answer_id": "29290566", "answer_content": "\r\n Already busy topic, but from what I read here, the following helped me realizing how it's working internally: \n\n def bar(a=[]):\n     print id(a)\n     a = a + [1]\n     print id(a)\n     return a\n\n>>> bar()\n4484370232\n4484524224\n[1]\n>>> bar()\n4484370232\n4484524152\n[1]\n>>> bar()\n4484370232 # Never change, this is 'class property' of the function\n4484523720 # Always a new object \n[1]\n>>> id(bar.func_defaults[0])\n4484370232\n \n    ", "date_posted": "2015-03-26 23:14:01Z", "upvote": "\r\n            27\r\n        ", "accepted": "No", "user": {"stack_user_id": "554374", "name": "St\u00e9phane", "reputation_score": "1,947"}, "answer_comments": [{"stack_answer_id": "29290566", "stack_answer_comment_id": "73656522", "comment_content": "actually this might be a bit confusing for newcomers as ", "user_id": "None"}]}, {"stack_answer_id": "1134613", "answer_content": "\r\n It's a performance optimization.  As a result of this functionality, which of these two function calls do you think is faster? \n\n def print_tuple(some_tuple=(1,2,3)):\n    print some_tuple\n\nprint_tuple()        #1\nprint_tuple((1,2,3)) #2\n \n\n I'll give you a hint.  Here's the disassembly (see  http://docs.python.org/library/dis.html ): \n\n # 1 \n\n 0 LOAD_GLOBAL              0 (print_tuple)\n3 CALL_FUNCTION            0\n6 POP_TOP\n7 LOAD_CONST               0 (None)\n10 RETURN_VALUE\n \n\n # 2 \n\n  0 LOAD_GLOBAL              0 (print_tuple)\n 3 LOAD_CONST               4 ((1, 2, 3))\n 6 CALL_FUNCTION            1\n 9 POP_TOP\n10 LOAD_CONST               0 (None)\n13 RETURN_VALUE\n \n\n \n   I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs ?) \n \n\n As you can see, there  is  a performance benefit when using immutable default arguments.  This can make a difference if it's a frequently called function or the default argument takes a long time to construct.  Also, bear in mind that Python isn't C.  In C you have constants that are pretty much free.  In Python you don't have this benefit. \n    ", "date_posted": "2013-04-02 21:52:30Z", "upvote": "\r\n            26\r\n        ", "accepted": "No", "user": {"stack_user_id": "2147", "name": "Jason Baker", "reputation_score": "184k"}, "answer_comments": []}, {"stack_answer_id": "10304917", "answer_content": "\r\n This behavior is not surprising if you take the following into consideration: \n \n The behavior of read-only class attributes upon assignment attempts, and that \n Functions are objects (explained well in the accepted answer). \n \n The role of  (2)  has been covered extensively in this thread.  (1)  is likely the astonishment causing factor, as this behavior is not \"intuitive\" when coming from other languages. \n (1)  is described in the Python  tutorial on classes . In an attempt to assign a value to a read-only class attribute: \n \n ...all variables found outside of the innermost scope are\nread-only ( an attempt to write to such a variable will simply create a\nnew local variable in the innermost scope, leaving the identically\nnamed outer variable unchanged ). \n \n Look back to the original example and consider the above points: \n def foo(a=[]):\n    a.append(5)\n    return a\n \n Here  foo  is an object and  a  is an attribute of  foo  (available at  foo.func_defs[0] ). Since  a  is a list,  a  is mutable and is thus a read-write attribute of  foo . It is initialized to the empty list as specified by the signature when the function is instantiated, and is available for reading and writing as long as the function object exists. \n Calling  foo  without overriding a default uses that default's value from  foo.func_defs . In this case,  foo.func_defs[0]  is used for  a  within function object's code scope. Changes to  a  change  foo.func_defs[0] , which is part of the  foo  object and persists between execution of the code in  foo . \n Now, compare this to the example from the documentation on  emulating the default argument behavior of other languages , such that the function signature defaults are used every time the function is executed: \n def foo(a, L=None):\n    if L is None:\n        L = []\n    L.append(a)\n    return L\n \n Taking  (1)  and  (2)  into account, one can see why this accomplishes the desired behavior: \n \n When the  foo  function object is instantiated,  foo.func_defs[0]  is set to  None , an immutable object. \n When the function is executed with defaults (with no parameter specified for  L  in the function call),  foo.func_defs[0]  ( None ) is available in the local scope as  L . \n Upon  L = [] , the assignment cannot succeed at  foo.func_defs[0] , because that attribute is read-only. \n Per  (1) ,  a new local variable also named  L  is created in the local scope  and used for the remainder of the function call.  foo.func_defs[0]  thus remains unchanged for future invocations of  foo . \n \n    ", "date_posted": "2020-08-27 20:44:25Z", "upvote": "\r\n            22\r\n        ", "accepted": "No", "user": {"stack_user_id": "2430549", "name": "HoldOffHunger", "reputation_score": "16.2k"}, "answer_comments": []}, {"stack_answer_id": "15133978", "answer_content": "\r\n A simple workaround using None \n\n >>> def bar(b, data=None):\n...     data = data or []\n...     data.append(b)\n...     return data\n... \n>>> bar(3)\n[3]\n>>> bar(3)\n[3]\n>>> bar(3)\n[3]\n>>> bar(3, [34])\n[34, 3]\n>>> bar(3, [34])\n[34, 3]\n \n    ", "date_posted": "2013-02-28 11:10:16Z", "upvote": "\r\n            21\r\n        ", "accepted": "No", "user": {"stack_user_id": "252135", "name": "hugo24", "reputation_score": "1,071"}, "answer_comments": [{"stack_answer_id": "15133978", "stack_answer_comment_id": "126670851", "comment_content": "This isn't an answer to the question.", "user_id": "None"}]}, {"stack_answer_id": "1139730", "answer_content": "\r\n It may be true that: \n\n \n Someone is using every language/library feature, and \n Switching the behavior here would be ill-advised, but \n \n\n it is entirely consistent to hold to both of the features above and still make another point: \n\n \n It is a confusing feature and it is unfortunate in Python. \n \n\n The other answers, or at least some of them either make points 1 and 2 but not 3, or make point 3 and downplay points 1 and 2.  But all three are true. \n\n It may be true that switching horses in midstream here would be asking for significant breakage, and that there could be more problems created by changing Python to intuitively handle Stefano's opening snippet. And it may be true that someone who knew Python internals well could explain a minefield of consequences.  However, \n\n The existing behavior is not Pythonic, and Python is successful because very little about the language violates the principle of least astonishment anywhere  near  this badly. It is a real problem, whether or not it would be wise to uproot it. It is a design flaw. If you understand the language much better by trying to trace out the behavior, I can say that C++ does all of this and more; you learn a lot by navigating, for instance, subtle pointer errors. But this is not Pythonic: people who care about Python enough to persevere in the face of this behavior are people who are drawn to the language because Python has far fewer surprises than other language. Dabblers and the curious become Pythonistas when they are astonished at how little time it takes to get something working--not because of a design fl--I mean, hidden logic puzzle--that cuts against the intuitions of programmers who are drawn to Python because it  Just Works . \n    ", "date_posted": "2009-07-16 19:17:59Z", "upvote": "\r\n            20\r\n        ", "accepted": "No", "user": {"stack_user_id": "116906", "name": "Christos Hayward", "reputation_score": "5,621"}, "answer_comments": [{"stack_answer_id": "1139730", "stack_answer_comment_id": "14994287", "comment_content": "-1 Although a defensible perspective, this not an answer, ", "user_id": "None"}, {"stack_answer_id": "1139730", "stack_answer_comment_id": "19435546", "comment_content": "So then, it is \"amazingly ignorant\" to say that in Python it would make more sense for a default argument of [] to remain [] every time the function is called?", "user_id": "None"}, {"stack_answer_id": "1139730", "stack_answer_comment_id": "19435596", "comment_content": "And it is ignorant to consider as an unfortunate idiom setting a default argument to None, and then in the body of the body of the function setting if argument == None: argument = []? Is it ignorant to consider this idiom unfortunate as often people want what a naive newcomer would expect, that if you assign f(argument = []), argument will automatically default to a value of []?", "user_id": "None"}, {"stack_answer_id": "1139730", "stack_answer_comment_id": "19436087", "comment_content": "But in Python, part of the spirit of the language is that you don't have to take too many deep dives; array.sort() works, and works  regardless of how little you understand about sorting, big-O, and constants. The beauty of Python in the array sorting mechanism, to give one of innumerable examples, is that you are not required to take a deep dive into internals. And to say it differently, the beauty of Python is that one is not ordinarily required to take a deep dive into implementation to get something that Just Works. And there is a workaround (...if argument == None: argument = []), FAIL.", "user_id": "None"}, {"stack_answer_id": "1139730", "stack_answer_comment_id": "28401661", "comment_content": "As a standalone, the statement ", "user_id": "None"}]}, {"stack_answer_id": "32535706", "answer_content": "\r\n I am going to demonstrate an alternative structure to pass a default list value to a function (it works equally well with dictionaries).   \n\n As others have extensively commented, the list parameter is bound to the function when it is defined as opposed to when it is executed.  Because lists and dictionaries are mutable, any alteration to this parameter will affect other calls to this function.  As a result, subsequent calls to the function will receive this shared list which may have been altered by any other calls to the function.  Worse yet, two parameters are using this function's shared parameter at the same time oblivious to the changes made by the other. \n\n Wrong Method (probably...) : \n\n def foo(list_arg=[5]):\n    return list_arg\n\na = foo()\na.append(6)\n>>> a\n[5, 6]\n\nb = foo()\nb.append(7)\n# The value of 6 appended to variable 'a' is now part of the list held by 'b'.\n>>> b\n[5, 6, 7]  \n\n# Although 'a' is expecting to receive 6 (the last element it appended to the list),\n# it actually receives the last element appended to the shared list.\n# It thus receives the value 7 previously appended by 'b'.\n>>> a.pop()             \n7\n \n\n You can verify that they are one and the same object by using  id : \n\n >>> id(a)\n5347866528\n\n>>> id(b)\n5347866528\n \n\n Per Brett Slatkin's \"Effective Python: 59 Specific Ways to Write Better Python\",  Item 20: Use  None  and Docstrings to specify dynamic default arguments  (p. 48) \n\n \n   The convention for achieving the desired result in Python is to\n  provide a default value of  None  and to document the actual behaviour\n  in the docstring. \n \n\n This implementation ensures that each call to the function either receives the default list or else the list passed to the function. \n\n Preferred Method : \n\n def foo(list_arg=None):\n   \"\"\"\n   :param list_arg:  A list of input values. \n                     If none provided, used a list with a default value of 5.\n   \"\"\"\n   if not list_arg:\n       list_arg = [5]\n   return list_arg\n\na = foo()\na.append(6)\n>>> a\n[5, 6]\n\nb = foo()\nb.append(7)\n>>> b\n[5, 7]\n\nc = foo([10])\nc.append(11)\n>>> c\n[10, 11]\n \n\n There may be legitimate use cases for the 'Wrong Method' whereby the programmer intended the default list parameter to be shared, but this is more likely the exception than the rule. \n    ", "date_posted": "2015-09-12 20:41:53Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "2411802", "name": "Alexander", "reputation_score": "98.5k"}, "answer_comments": []}, {"stack_answer_id": "9791799", "answer_content": "\r\n The solutions here are: \n\n \n Use  None  as your default value (or a nonce  object ), and switch on that to create your values at runtime; or \n Use a  lambda  as your default parameter, and call it within a try block to get the default value (this is the sort of thing that lambda abstraction is for). \n \n\n The second option is nice because users of the function can pass in a callable, which may be already existing (such as a  type ) \n    ", "date_posted": "2013-06-30 16:20:35Z", "upvote": "\r\n            17\r\n        ", "accepted": "No", "user": {"stack_user_id": "21640", "name": "Marcin", "reputation_score": "47.1k"}, "answer_comments": [{"stack_answer_id": "9791799", "stack_answer_comment_id": "126670870", "comment_content": "This doesn't answer the question.", "user_id": "None"}]}, {"stack_answer_id": "14336301", "answer_content": "\r\n You can get round this by replacing the object (and therefore the tie with the scope): \n\n def foo(a=[]):\n    a = list(a)\n    a.append(5)\n    return a\n \n\n Ugly, but it works. \n    ", "date_posted": "2013-01-15 11:02:03Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "734463", "name": "joedborg", "reputation_score": "16.6k"}, "answer_comments": [{"stack_answer_id": "14336301", "stack_answer_comment_id": "20074742", "comment_content": "This is a nice solution in cases where you're using automatic documentation generation software to document the types of arguments expected by the function.  Putting a=None and then setting a to [] if a is None doesn't help a reader understand at a glance what is expected.", "user_id": "None"}, {"stack_answer_id": "14336301", "stack_answer_comment_id": "83550838", "comment_content": "Cool idea: rebinding that name guarantees it can never be modified. I really like that.", "user_id": "None"}, {"stack_answer_id": "14336301", "stack_answer_comment_id": "88079491", "comment_content": "This is exactly the way to do it. Python doesn't make a copy of the parameter, so it's up to you to make the copy explicitly. Once you have a copy, it's yours to modify as you please without any unexpected side effects.", "user_id": "None"}, {"stack_answer_id": "14336301", "stack_answer_comment_id": "126670875", "comment_content": "This doesn't answer the question, though.", "user_id": "None"}]}, {"stack_answer_id": "25797695", "answer_content": "\r\n When we do this: \n\n def foo(a=[]):\n    ...\n \n\n ... we assign the argument  a  to an  unnamed  list, if the caller does not pass the value of a. \n\n To make things simpler for this discussion, let's temporarily give the unnamed list a name. How about  pavlo  ? \n\n def foo(a=pavlo):\n   ...\n \n\n At any time, if the caller doesn't tell us what  a  is, we reuse  pavlo . \n\n If  pavlo  is mutable (modifiable), and  foo  ends up modifying it, an effect we notice the next time  foo  is called without specifying  a . \n\n So this is what you see (Remember,  pavlo  is initialized to []): \n\n  >>> foo()\n [5]\n \n\n Now,  pavlo  is [5]. \n\n Calling  foo()  again modifies  pavlo  again: \n\n >>> foo()\n[5, 5]\n \n\n Specifying  a  when calling  foo()  ensures  pavlo  is not touched. \n\n >>> ivan = [1, 2, 3, 4]\n>>> foo(a=ivan)\n[1, 2, 3, 4, 5]\n>>> ivan\n[1, 2, 3, 4, 5]\n \n\n So,  pavlo  is still  [5, 5] . \n\n >>> foo()\n[5, 5, 5]\n \n    ", "date_posted": "2014-09-11 22:05:43Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "1639436", "name": "Saish", "reputation_score": "501"}, "answer_comments": []}, {"stack_answer_id": "28354667", "answer_content": "\r\n I sometimes exploit this behavior as an alternative to the following pattern: \n\n singleton = None\n\ndef use_singleton():\n    global singleton\n\n    if singleton is None:\n        singleton = _make_singleton()\n\n    return singleton.use_me()\n \n\n If  singleton  is only used by  use_singleton , I like the following pattern as a replacement: \n\n # _make_singleton() is called only once when the def is executed\ndef use_singleton(singleton=_make_singleton()):\n    return singleton.use_me()\n \n\n I've used this for instantiating client classes that access external resources, and also for creating dicts or lists for memoization. \n\n Since I don't think this pattern is well known, I do put a short comment in to guard against future misunderstandings. \n    ", "date_posted": "2015-02-06 12:56:53Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "4513367", "name": "bgreen-litl", "reputation_score": "414"}, "answer_comments": [{"stack_answer_id": "28354667", "stack_answer_comment_id": "45063880", "comment_content": "I prefer to add a decorator for memoization, and put the memoization cache onto the function object itself.", "user_id": "78374"}, {"stack_answer_id": "28354667", "stack_answer_comment_id": "81702357", "comment_content": "This example doesn't replace the more complex pattern you show, because you call ", "user_id": "None"}]}, {"stack_answer_id": "54018161", "answer_content": "\r\n Every other answer explains why this is actually a nice and desired behavior, or why you shouldn't be needing this anyway. Mine is for those stubborn ones who want to exercise their right to bend the language to their will, not the other way around. \n We will \"fix\" this behavior with a decorator that will copy the default value instead of reusing the same instance for each positional argument left at its default value. \n\n import inspect\nfrom copy import deepcopy  # copy would fail on deep arguments like nested dicts\n\ndef sanify(function):\n    def wrapper(*a, **kw):\n        # store the default values\n        defaults = inspect.getargspec(function).defaults # for python2\n        # construct a new argument list\n        new_args = []\n        for i, arg in enumerate(defaults):\n            # allow passing positional arguments\n            if i in range(len(a)):\n                new_args.append(a[i])\n            else:\n                # copy the value\n                new_args.append(deepcopy(arg))\n        return function(*new_args, **kw)\n    return wrapper\n \n Now let's redefine our function using this decorator: \n @sanify\ndef foo(a=[]):\n    a.append(5)\n    return a\n\nfoo() # '[5]'\nfoo() # '[5]' -- as desired\n \n This is particularly neat for functions that take multiple arguments. Compare: \n # the 'correct' approach\ndef bar(a=None, b=None, c=None):\n    if a is None:\n        a = []\n    if b is None:\n        b = []\n    if c is None:\n        c = []\n    # finally do the actual work\n \n with \n # the nasty decorator hack\n@sanify\ndef bar(a=[], b=[], c=[]):\n    # wow, works right out of the box!\n \n It's important to note that the above solution breaks if you try to use keyword args, like so: \n foo(a=[4])\n \n The decorator could be adjusted to allow for that, but we leave this as an exercise for the reader ;) \n    ", "date_posted": "2022-03-31 10:09:47Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "6919631", "name": "Przemek D", "reputation_score": "624"}, "answer_comments": [{"stack_answer_id": "54018161", "stack_answer_comment_id": "126670698", "comment_content": "This also breaks if the default argument is deep, like ", "user_id": "None"}, {"stack_answer_id": "54018161", "stack_answer_comment_id": "126698761", "comment_content": "@Flimm I find your phrase \"this breaks\" rather unfair as it seems to suggests the entire concept is somehow flawed, while it is in fact only a minor detail of the implementation. But thank you for the comment nonetheless, I shall edit and improve my answer.", "user_id": "None"}]}, {"stack_answer_id": "17782210", "answer_content": "\r\n This \"bug\" gave me a lot of overtime work hours! But I'm beginning to see a potential use of it (but I would have liked it to be at the execution time, still) \n\n I'm gonna give you what I see as a useful example. \n\n def example(errors=[]):\n    # statements\n    # Something went wrong\n    mistake = True\n    if mistake:\n        tryToFixIt(errors)\n        # Didn't work.. let's try again\n        tryToFixItAnotherway(errors)\n        # This time it worked\n    return errors\n\ndef tryToFixIt(err):\n    err.append('Attempt to fix it')\n\ndef tryToFixItAnotherway(err):\n    err.append('Attempt to fix it by another way')\n\ndef main():\n    for item in range(2):\n        errors = example()\n    print '\\n'.join(errors)\n\nmain()\n \n\n prints the following \n\n Attempt to fix it\nAttempt to fix it by another way\nAttempt to fix it\nAttempt to fix it by another way\n \n    ", "date_posted": "2013-07-23 10:07:58Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "618099", "name": "Norfeldt", "reputation_score": "6,648"}, "answer_comments": [{"stack_answer_id": "17782210", "stack_answer_comment_id": "119658319", "comment_content": "Your example doesn't seem very realistic.  Why would you pass ", "user_id": "None"}]}, {"stack_answer_id": "46796007", "answer_content": "\r\n This is not a design flaw . Anyone who trips over this is doing something wrong. \n\n There are 3 cases I see where you might run into this problem: \n\n \n You intend to modify the argument as a side effect of the function. In this case it  never makes sense  to have a default argument. The only exception is when you're abusing the argument list to have function attributes, e.g.  cache={} , and you wouldn't be expected to call the function with an actual argument at all. \n You intend to leave the argument unmodified, but you accidentally  did  modify it. That's a bug, fix it. \n You intend to modify the argument for use inside the function, but didn't expect the modification to be viewable outside of the function. In that case you need to make a  copy  of the argument, whether it was the default or not! Python is not a call-by-value language so it doesn't make the copy for you, you need to be explicit about it. \n \n\n The example in the question could fall into category 1 or 3. It's odd that it both modifies the passed list and returns it; you should pick one or the other. \n    ", "date_posted": "2017-10-17 18:04:59Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "5987", "name": "Mark Ransom", "reputation_score": "289k"}, "answer_comments": [{"stack_answer_id": "46796007", "stack_answer_comment_id": "80540093", "comment_content": "\"Doing something wrong\" is the diagnosis. That said, I think there are times were =None pattern is useful, but generally you don't want to modify if passed a mutable in that case (2). The ", "user_id": "None"}, {"stack_answer_id": "46796007", "stack_answer_comment_id": "119639032", "comment_content": "Totally disagree, its absolutely a design flaw in many cases and not the programmer doing something wong", "user_id": "None"}, {"stack_answer_id": "46796007", "stack_answer_comment_id": "119654728", "comment_content": "I have never run into the problem of the OP even though it is so highly upvoted, because having a default argument be mutable is weird design to me.", "user_id": "None"}, {"stack_answer_id": "46796007", "stack_answer_comment_id": "119879935", "comment_content": "@MarkRansom If we take it as given that side effects are OK, there's nothing wrong with modifying a default argument as part of a side-effect-ful function. Let's say you have a function that does ", "user_id": "None"}, {"stack_answer_id": "46796007", "stack_answer_comment_id": "119970601", "comment_content": "@MarkRansom No, they're not; for example, ", "user_id": "None"}]}, {"stack_answer_id": "30447095", "answer_content": "\r\n Just change the function to be: \n\n def notastonishinganymore(a = []): \n    '''The name is just a joke :)'''\n    a = a[:]\n    a.append(5)\n    return a\n \n    ", "date_posted": "2018-09-06 21:29:08Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "4785185", "name": "Prune", "reputation_score": "75.6k"}, "answer_comments": [{"stack_answer_id": "30447095", "stack_answer_comment_id": "126670893", "comment_content": "This doesn't answer the question, though.", "user_id": "None"}]}, {"stack_answer_id": "53792207", "answer_content": "\r\n TLDR: Define-time defaults are consistent and strictly more expressive. \n\n \n\n Defining a function affects two scopes: the defining scope  containing  the function, and the execution  scope  contained by  the function. While it is pretty clear how blocks map to scopes, the question is where  def <name>(<args=defaults>):  belongs to: \n\n ...                           # defining scope\ndef name(parameter=default):  # ???\n    ...                       # execution scope\n \n\n The  def name  part  must  evaluate in the defining scope - we want  name  to be available there, after all. Evaluating the function only inside itself would make it inaccessible. \n\n Since  parameter  is a constant name, we can \"evaluate\" it at the same time as  def name . This also has the advantage it produces the function with a known signature as  name(parameter=...): , instead of a bare  name(...): . \n\n Now, when to evaluate  default ? \n\n Consistency already says \"at definition\": everything else of  def <name>(<args=defaults>):  is best evaluated at definition as well. Delaying parts of it would be the astonishing choice. \n\n The two choices are not equivalent, either: If  default  is evaluated at definition time, it  can still  affect execution time. If  default  is evaluated at execution time, it  cannot  affect definition time. Choosing \"at definition\" allows expressing both cases, while choosing \"at execution\" can express only one: \n\n def name(parameter=defined):  # set default at definition time\n    ...\n\ndef name(parameter=default):     # delay default until execution time\n    parameter = default if parameter is None else parameter\n    ...\n \n    ", "date_posted": "2019-08-08 07:39:43Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "5349916", "name": "MisterMiyagi", "reputation_score": "38.6k"}, "answer_comments": [{"stack_answer_id": "53792207", "stack_answer_comment_id": "102525948", "comment_content": "\"Consistency already says \"at definition\": everything else of ", "user_id": "None"}, {"stack_answer_id": "53792207", "stack_answer_comment_id": "102527403", "comment_content": "@LarsH Function definitions are ", "user_id": "None"}, {"stack_answer_id": "53792207", "stack_answer_comment_id": "102560686", "comment_content": "OK, creating a function means evaluation in some sense, but obviously not in the sense that every expression within it is evaluated at the time of definition. Most aren't. It's not clear to me in what sense the signature is especially \"evaluated\" at definition time any more than the function body is \"evaluated\" (parsed into a suitable representation); whereas expressions in the function body are clearly not evaluated in the full sense. From this point of view, consistency would say that expressions in the signature shouldn't be \"fully\" evaluated either.", "user_id": "None"}, {"stack_answer_id": "53792207", "stack_answer_comment_id": "102560689", "comment_content": "I don't mean that you're wrong, only that your conclusion doesn't follow from consistency alone.", "user_id": "None"}, {"stack_answer_id": "53792207", "stack_answer_comment_id": "102560884", "comment_content": "@LarsH Defaults are neither part of the body, nor am I claiming that consistency is the only criteria. Can you make a suggestion how to clarify the answer?", "user_id": "None"}]}, {"stack_answer_id": "18372696", "answer_content": "\r\n I think the answer to this question lies in how python pass data to parameter (pass by value or by reference), not mutability or how python handle the \"def\" statement. \n\n A brief introduction. First, there are two type of data types in python, one is simple elementary data type, like numbers, and another data type is objects. Second, when passing data to parameters, python pass elementary data type by value, i.e., make a local copy of the value to a local variable, but pass object by reference, i.e., pointers to the object. \n\n Admitting the above two points, let's explain what happened to the python code. It's only because of passing by reference for objects, but has nothing to do with mutable/immutable, or arguably the fact that \"def\" statement is executed only once when it is defined. \n\n [] is an object, so python pass the reference of [] to  a , i.e.,  a  is only a pointer to [] which lies in memory as an object. There is only one copy of [] with, however, many references to it. For the first foo(), the list [] is changed to  1  by append method. But Note that there is only one copy of the list object and this object now becomes  1 . When running the second foo(), what effbot webpage says (items is not evaluated any more) is wrong.  a  is evaluated to be the list object, although now the content of the object is  1 . This is the effect of passing by reference! The result of foo(3) can be easily derived in the same way. \n\n To further validate my answer, let's take a look at two additional codes. \n\n ====== No. 2 ======== \n\n def foo(x, items=None):\n    if items is None:\n        items = []\n    items.append(x)\n    return items\n\nfoo(1)  #return [1]\nfoo(2)  #return [2]\nfoo(3)  #return [3]\n \n\n []  is an object, so is  None  (the former is mutable while the latter is immutable. But the mutability has nothing to do with the question). None is somewhere in the space but we know it's there and there is only one copy of None there. So every time foo is invoked, items is evaluated (as opposed to some answer that it is only evaluated once) to be None, to be clear, the reference (or the address) of None. Then in the foo, item is changed to [], i.e., points to another object which has a different address.  \n\n ====== No. 3 ======= \n\n def foo(x, items=[]):\n    items.append(x)\n    return items\n\nfoo(1)    # returns [1]\nfoo(2,[]) # returns [2]\nfoo(3)    # returns [1,3]\n \n\n The invocation of foo(1) make items point to a list object [] with an address, say, 11111111. the content of the list is changed to  1  in the foo function in the sequel, but the address is not changed, still 11111111. Then foo(2,[]) is coming. Although the [] in foo(2,[]) has the same content as the default parameter [] when calling foo(1), their address are different! Since we provide the parameter explicitly,  items  has to take the address of this new  [] , say 2222222, and return it after making some change. Now foo(3) is executed. since only  x  is provided, items has to take its default value again. What's the default value? It is set when defining the foo function: the list object located in 11111111. So the items is evaluated to be the address 11111111 having an element 1. The list located at 2222222 also contains one element 2, but it is not pointed by items any more. Consequently, An append of 3 will make  items  [1,3].  \n\n From the above explanations, we can see that the  effbot  webpage recommended in the accepted answer failed to give a relevant answer to this question. What is more, I think a point in the effbot webpage is wrong. I think the code regarding the UI.Button is correct: \n\n for i in range(10):\n    def callback():\n        print \"clicked button\", i\n    UI.Button(\"button %s\" % i, callback)\n \n\n Each button can hold a distinct callback function which will display different value of  i . I can provide an example to show this: \n\n x=[]\nfor i in range(10):\n    def callback():\n        print(i)\n    x.append(callback) \n \n\n If we execute  x[7]()  we'll get 7 as expected, and  x[9]()  will gives 9, another value of  i . \n    ", "date_posted": "2013-08-22 05:58:41Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "2384994", "name": "user2384994", "reputation_score": "1,669"}, "answer_comments": [{"stack_answer_id": "18372696", "stack_answer_comment_id": "28304217", "comment_content": "Your last point is wrong. Try it and you'll see that ", "user_id": "None"}, {"stack_answer_id": "18372696", "stack_answer_comment_id": "42551885", "comment_content": "\"python pass elementary data type by value, i.e., make a local copy of the value to a local variable\" is completely incorrect. I am astonished that someone can obviously know Python very well, yet have such horrible misunderstanding of fundamentals. :-(", "user_id": "None"}]}], "user": {"stack_user_id": "78374", "name": "Stefano Borini", "reputation_score": "133k"}, "question_comments": [{"stack_question_id": "1132941", "stack_question_comment_id": "11530621", "comment_content": "Complementary question - ", "user_id": "None"}, {"stack_question_id": "1132941", "stack_question_comment_id": "73589342", "comment_content": "I have not doubt mutable arguments violate least astonishment principle for an average person, and I have seen beginners stepping there, then heroically replacing mailing lists with mailing tuples. Nevertheless mutable arguments are still in line with Python Zen (Pep 20) and falls into \"obvious for Dutch\" (understood/exploited by hard core python programmers) clause.  The recommended  workaround with doc string is the best, yet resistance to doc strings and any (written) docs is not so uncommon nowadays. Personally, I would prefer a decorator (say @fixed_defaults).", "user_id": "None"}, {"stack_question_id": "1132941", "stack_question_comment_id": "75640338", "comment_content": "My argument when I come across this is:  \"Why do you need to create a function that returns a mutable that could optionally be a mutable you would pass to the function?  Either it alters a mutable or creates a new one.  Why do you need to do both with one function?  And why should the interpreter be rewritten to allow you to do that without adding three lines to your code?\" Because we are talking about rewriting the way the interpreter handles function definitions and evocations here.  That's a lot to do for a barely necessary use case.", "user_id": "None"}, {"stack_question_id": "1132941", "stack_question_comment_id": "76883169", "comment_content": "\"Python novices would expect this function to always return a list with only one element: ", "user_id": "None"}, {"stack_question_id": "1132941", "stack_question_comment_id": "98233496", "comment_content": "This question asks ", "user_id": "None"}]},
{"stack_question_id": "240178", "question_title": "List of lists changes reflected across sublists unexpectedly", "question_content": "\r\n                I created a list of lists:\nxs = [[1] * 4] * 3\n\n# xs == [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]  \n\nThen, I changed one of the innermost values:\nxs[0][0] = 5\n\n# xs == [[5, 1, 1, 1], [5, 1, 1, 1], [5, ...\r\n", "question_url": "/questions/240178/list-of-lists-changes-reflected-across-sublists-unexpectedly", "date_posted": "Oct 27, 2008 at 14:57", "upvote": "8", "view": "6", "tags": ["python", "list", "nested-lists", "mutable"], "answers_count": "1", "answers": [{"stack_answer_id": "240205", "answer_content": "\r\n When you write  [x]*3  you get, essentially, the list  [x, x, x] . That is, a list with 3 references to the same  x . When you then modify this single  x  it is visible via all three references to it: \n x = [1] * 4\nxs = [x] * 3\nprint(f\"id(x): {id(x)}\")\n# id(x): 140560897920048\nprint(\n    f\"id(xs[0]): {id(xs[0])}\\n\"\n    f\"id(xs[1]): {id(xs[1])}\\n\"\n    f\"id(xs[2]): {id(xs[2])}\"\n)\n# id(xs[0]): 140560897920048\n# id(xs[1]): 140560897920048\n# id(xs[2]): 140560897920048\n\nx[0] = 42\nprint(f\"x: {x}\")\n# x: [42, 1, 1, 1]\nprint(f\"xs: {xs}\")\n# xs: [[42, 1, 1, 1], [42, 1, 1, 1], [42, 1, 1, 1]]\n \n To fix it, you need to make sure that you create a new list at each position. One way to do it is \n [[1]*4 for _ in range(3)]\n \n which will reevaluate  [1]*4  each time instead of evaluating it once and making 3 references to 1 list. \n \n You might wonder why  *  can't make independent objects the way the list comprehension does. That's because the multiplication operator  *  operates on objects, without seeing expressions. When you use  *  to multiply  [[1] * 4]  by 3,  *  only sees the 1-element list  [[1] * 4]  evaluates to, not the  [[1] * 4  expression text.  *  has no idea how to make copies of that element, no idea how to reevaluate  [[1] * 4] , and no idea you even want copies, and in general, there might not even be a way to copy the element. \n The only option  *  has is to make new references to the existing sublist instead of trying to make new sublists. Anything else would be inconsistent or require major redesigning of fundamental language design decisions. \n In contrast, a list comprehension reevaluates the element expression on every iteration.  [[1] * 4 for n in range(3)]  reevaluates  [1] * 4  every time for the same reason  [x**2 for x in range(3)]  reevaluates  x**2  every time. Every evaluation of  [1] * 4  generates a new list, so the list comprehension does what you wanted. \n Incidentally,  [1] * 4  also doesn't copy the elements of  [1] , but that doesn't matter, since integers are immutable. You can't do something like  1.value = 2  and turn a 1 into a 2. \n    ", "date_posted": "2022-05-22 19:55:56Z", "upvote": "\r\n            754\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": [{"stack_answer_id": "240205", "stack_answer_comment_id": "48862076", "comment_content": "I am surprised that no body points out  that, the answer here is misleading. ", "user_id": "None"}, {"stack_answer_id": "240205", "stack_answer_comment_id": "48871095", "comment_content": "Technically, it's still correct. ", "user_id": "None"}, {"stack_answer_id": "240205", "stack_answer_comment_id": "60950287", "comment_content": "@Allanqunzi you are wrong. Do ", "user_id": "None"}, {"stack_answer_id": "240205", "stack_answer_comment_id": "126691081", "comment_content": "can anyone find documents about the ", "user_id": "None"}, {"stack_answer_id": "240205", "stack_answer_comment_id": "127789351", "comment_content": "@LeiYang It's listed under ", "user_id": "None"}]}, {"stack_answer_id": "18454568", "answer_content": "\r\n size = 3\nmatrix_surprise = [[0] * size] * size\nmatrix = [[0]*size for _ in range(size)]\n \n Live visualization  using Python Tutor: \n \n    ", "date_posted": "2021-06-18 17:12:23Z", "upvote": "\r\n            168\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": [{"stack_answer_id": "18454568", "stack_answer_comment_id": "76707168", "comment_content": "So, why if we write matrix= [[x] * 2] doesn't make 2 elemnts for the same object like the example you describe, it seems to be the same concept, what am i missing?", "user_id": "None"}, {"stack_answer_id": "18454568", "stack_answer_comment_id": "76720889", "comment_content": "@AhmedMohamed Indeed it does make a list with two elements of the exact same object that ", "user_id": "None"}, {"stack_answer_id": "18454568", "stack_answer_comment_id": "76721203", "comment_content": "@nadrimajstor so why the change in matrix[0] doesn't affect matrix[1] like the example above with 2d matrix.", "user_id": "None"}, {"stack_answer_id": "18454568", "stack_answer_comment_id": "76723575", "comment_content": "@AhmedMohamed Surprise come when you make a \"copy\" of mutable sequence (in our example it is a ", "user_id": "None"}, {"stack_answer_id": "18454568", "stack_answer_comment_id": "76724009", "comment_content": "@AhmedMohamed Take a look at ", "user_id": "None"}]}, {"stack_answer_id": "240215", "answer_content": "\r\n Actually, this is exactly what you would expect. Let's decompose what is happening here: \n You write \n lst = [[1] * 4] * 3\n \n This is equivalent to: \n lst1 = [1]*4\nlst = [lst1]*3\n \n This means  lst  is a list with 3 elements all pointing to  lst1 . This means the two following lines are equivalent: \n lst[0][0] = 5\nlst1[0] = 5\n \n As  lst[0]  is nothing but  lst1 . \n To obtain the desired behavior, you can use a list comprehension: \n lst = [ [1]*4 for n in range(3) ]\n \n In this case, the expression is re-evaluated for each  n , leading to a different list. \n    ", "date_posted": "2021-06-18 16:49:18Z", "upvote": "\r\n            70\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": [{"stack_answer_id": "240215", "stack_answer_comment_id": "75062949", "comment_content": "Just a small addition to the nice answer here: it's evident that you're dealing with same object if you do ", "user_id": "None"}, {"stack_answer_id": "240215", "stack_answer_comment_id": "128207126", "comment_content": "Doesn't explain why modifying a 1d list causes a copy while a 2d list doesn't cause any copy", "user_id": "None"}]}, {"stack_answer_id": "240202", "answer_content": "\r\n [[1] * 4] * 3\n \n\n or even: \n\n [[1, 1, 1, 1]] * 3\n \n\n Creates a list that references the internal  [1,1,1,1]  3 times - not three copies of the inner list, so any time you modify the list (in any position), you'll see the change three times. \n\n It's the same as this example: \n\n >>> inner = [1,1,1,1]\n>>> outer = [inner]*3\n>>> outer\n[[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]\n>>> inner[0] = 5\n>>> outer\n[[5, 1, 1, 1], [5, 1, 1, 1], [5, 1, 1, 1]]\n \n\n where it's probably a little less surprising. \n    ", "date_posted": "2017-01-14 07:54:00Z", "upvote": "\r\n            47\r\n        ", "accepted": "No", "user": {"stack_user_id": "4952130", "name": "Dimitris Fasarakis Hilliard", "reputation_score": "139k"}, "answer_comments": [{"stack_answer_id": "240202", "stack_answer_comment_id": "103503", "comment_content": "You can use the \"is\" operator to discover this. ls[0] is ls[1] returns True.", "user_id": "None"}]}, {"stack_answer_id": "43246520", "answer_content": "\r\n my_list = [[1]*4] * 3  creates one list object  [1,1,1,1]  in memory and copies its reference 3 times over. This is equivalent to  obj = [1,1,1,1]; my_list = [obj]*3 . Any modification to  obj  will be reflected at three places, wherever  obj  is referenced in the list.\nThe right statement would be: \n my_list = [[1]*4 for _ in range(3)]\n \n or \n my_list = [[1 for __ in range(4)] for _ in range(3)]\n \n Important thing to note here  is that the  *  operator is  mostly  used to create a  list of literals . Although  1  is immutable,  obj = [1]*4  will still create a list of  1  repeated 4 times over to form  [1,1,1,1] . But if any reference to an immutable object is made, the object is overwritten with a new one. \n This means if we do  obj[1] = 42 , then  obj  will become  [1,42,1,1]   not   [42,42,42,42]  as some may assume. This can also be verified: \n >>> my_list = [1]*4\n>>> my_list\n[1, 1, 1, 1]\n\n>>> id(my_list[0])\n4522139440\n>>> id(my_list[1])  # Same as my_list[0]\n4522139440\n \n \n >>> my_list[1] = 42  # Since my_list[1] is immutable, this operation overwrites my_list[1] with a new object changing its id.\n>>> my_list\n[1, 42, 1, 1]\n\n>>> id(my_list[0])\n4522139440\n>>> id(my_list[1])  # id changed\n4522140752\n>>> id(my_list[2])  # id still same as my_list[0], still referring to value `1`.\n4522139440\n \n    ", "date_posted": "2021-06-18 16:32:37Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": [{"stack_answer_id": "43246520", "stack_answer_comment_id": "90015086", "comment_content": "It's not about literals. ", "user_id": "None"}]}, {"stack_answer_id": "30898048", "answer_content": "\r\n Alongside the accepted answer that explained the problem correctly, instead of creating a list with duplicated elements using following code: \n [[1]*4 for _ in range(3)]\n \n Also, you can use  itertools.repeat()  to create an iterator object of repeated elements: \n >>> a = list(repeat(1,4))\n[1, 1, 1, 1]\n>>> a[0] = 5\n>>> a\n[5, 1, 1, 1]\n \n P.S. If you're using NumPy and you only want to create an array of ones or zeroes you can use  np.ones  and  np.zeros  and/or for other numbers use  np.repeat : \n >>> import numpy as np\n>>> np.ones(4)\narray([1., 1., 1., 1.])\n>>> np.ones((4, 2))\narray([[1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.]])\n>>> np.zeros((4, 2))\narray([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]])\n>>> np.repeat([7], 10)\narray([7, 7, 7, 7, 7, 7, 7, 7, 7, 7])\n \n    ", "date_posted": "2021-06-18 17:26:13Z", "upvote": "\r\n            10\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": []}, {"stack_answer_id": "36452923", "answer_content": "\r\n Python containers contain references to other objects. See this example: \n\n >>> a = []\n>>> b = [a]\n>>> b\n[[]]\n>>> a.append(1)\n>>> b\n[[1]]\n \n\n In this  b  is a list that contains one item that is a reference to list  a . The list  a  is mutable. \n\n The multiplication of a list by an integer is equivalent to adding the list to itself multiple times (see  common sequence operations ). So continuing with the example: \n\n >>> c = b + b\n>>> c\n[[1], [1]]\n>>>\n>>> a[0] = 2\n>>> c\n[[2], [2]]\n \n\n We can see that the list  c  now contains two references to list  a  which is equivalent to  c = b * 2 . \n\n Python FAQ also contains explanation of this behavior:  How do I create a multidimensional list? \n    ", "date_posted": "2016-04-06 13:40:43Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "3185929", "name": "Zbyn\u011bk Winkler", "reputation_score": "1,043"}, "answer_comments": []}, {"stack_answer_id": "30759580", "answer_content": "\r\n Let's rewrite your code in the following way: \n x = 1\ny = [x]\nz = y * 4\n\nmy_list = [z] * 3\n \n Then having this, run the following code to make everything more clear. What the code does is basically print the  id s of the obtained objects, which \n \n Return[s] the \u201cidentity\u201d of an object \n \n and will help us identify them and analyse what happens: \n print(\"my_list:\")\nfor i, sub_list in enumerate(my_list):\n    print(\"\\t[{}]: {}\".format(i, id(sub_list)))\n    for j, elem in enumerate(sub_list):\n        print(\"\\t\\t[{}]: {}\".format(j, id(elem)))\n \n And you will get the following output: \n x: 1\ny: [1]\nz: [1, 1, 1, 1]\nmy_list:\n    [0]: 4300763792\n        [0]: 4298171528\n        [1]: 4298171528\n        [2]: 4298171528\n        [3]: 4298171528\n    [1]: 4300763792\n        [0]: 4298171528\n        [1]: 4298171528\n        [2]: 4298171528\n        [3]: 4298171528\n    [2]: 4300763792\n        [0]: 4298171528\n        [1]: 4298171528\n        [2]: 4298171528\n        [3]: 4298171528\n \n \n So now let's go step-by-step. You have  x  which is  1 , and a single element list  y  containing  x . Your first step is  y * 4  which will get you a new list  z , which is basically  [x, x, x, x] , i.e. it creates a new list which will have 4 elements, which are references to the initial  x  object. The next step is pretty similar. You basically do  z * 3 , which is  [[x, x, x, x]] * 3  and returns  [[x, x, x, x], [x, x, x, x], [x, x, x, x]] , for the same reason as for the first step. \n    ", "date_posted": "2021-06-18 16:36:25Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": []}, {"stack_answer_id": "62497944", "answer_content": "\r\n I am adding my answer to explain the same diagrammatically. \n The way you created the 2D, creates a shallow list \n arr = [[0]*cols]*row\n \n Instead, if you want to update the elements of the list, you should use \n rows, cols = (5, 5) \narr = [[0 for i in range(cols)] for j in range(rows)] \n \n Explanation : \n One can create a list using: \n arr = [0]*N \n \n or \n arr = [0 for i in range(N)] \n \n In the first case all the indices of the array point to the same integer object \n \n and when you assign a value to a particular index, a new int object is created, for example  arr[4] = 5  creates \n \n Now let us see what happens when we create a list of list, in this case, all the elements of our top list will point to the same list \n \n And if you update the value of any index a new int object will be created. But since all the top-level list indexes are pointing at the same list, all the rows will look the same. And you will get the feeling that updating an element is updating all the elements in that column. \n \n Credits:  Thanks to  Pranav Devarakonda  for the easy explanation  here \n    ", "date_posted": "2022-05-19 09:56:29Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "4621513", "name": "mkrieger1", "reputation_score": "15.4k"}, "answer_comments": []}, {"stack_answer_id": "37804636", "answer_content": "\r\n In simple words this is happening because in python everything works  by reference , so when you create a list of list that way you basically end up with such problems. \n\n To solve your issue you can do either one of them:\n1. Use numpy array  documentation for numpy.empty \n2. Append the list as you get to a list.\n3. You can also use dictionary if you want   \n    ", "date_posted": "2016-06-14 06:36:52Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "5801215", "name": "Neeraj Komuravalli", "reputation_score": "176"}, "answer_comments": []}, {"stack_answer_id": "36823796", "answer_content": "\r\n Everyone is explaining what is happening. I'll suggest one way to solve it: \n my_list = [[1 for i in range(4)] for j in range(3)]\n\nmy_list[0][0] = 5\nprint(my_list)\n \n And then you get: \n [[5, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]\n \n    ", "date_posted": "2021-06-18 16:39:24Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": []}, {"stack_answer_id": "57426328", "answer_content": "\r\n @spelchekr from  Python list multiplication: [[...]]*3 makes 3 lists which mirror each other when modified  and I had the same question about\n\"Why does only the outer  *3  create more references while the inner one doesn't? Why isn't it all 1s?\" \n li = [0] * 3\nprint([id(v) for v in li])  # [140724141863728, 140724141863728, 140724141863728]\nli[0] = 1\nprint([id(v) for v in li])  # [140724141863760, 140724141863728, 140724141863728]\nprint(id(0))  # 140724141863728\nprint(id(1))  # 140724141863760\nprint(li)     # [1, 0, 0]\n\nma = [[0]*3] * 3  # mainly discuss inner & outer *3 here\nprint([id(li) for li in ma])  # [1987013355080, 1987013355080, 1987013355080]\nma[0][0] = 1\nprint([id(li) for li in ma])  # [1987013355080, 1987013355080, 1987013355080]\nprint(ma)  # [[1, 0, 0], [1, 0, 0], [1, 0, 0]]\n \n Here is my explanation after trying the code above: \n \n The inner  *3  also creates references, but its references are immutable, something like  [&0, &0, &0] , then when you change  li[0] , you can't change any underlying reference of const int  0 , so you can just change the reference address into the new one  &1 ; \n while  ma = [&li, &li, &li]  and  li  is mutable, so when you call  ma[0][0] = 1 ,  ma[0][0]  is equal to  &li[0] , so all the  &li  instances will change its 1st address into  &1 . \n \n    ", "date_posted": "2021-06-18 17:02:12Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": []}, {"stack_answer_id": "38866487", "answer_content": "\r\n Trying to explain it more descriptively, \n\n Operation 1: \n\n x = [[0, 0], [0, 0]]\nprint(type(x)) # <class 'list'>\nprint(x) # [[0, 0], [0, 0]]\n\nx[0][0] = 1\nprint(x) # [[1, 0], [0, 0]]\n \n\n Operation 2: \n\n y = [[0] * 2] * 2\nprint(type(y)) # <class 'list'>\nprint(y) # [[0, 0], [0, 0]]\n\ny[0][0] = 1\nprint(y) # [[1, 0], [1, 0]]\n \n\n Noticed why doesn't modifying the first element of the first list didn't modify the second element of each list? That's because  [0] * 2  really is a list of two numbers, and a reference to 0 cannot be modified. \n\n If you want to create clone copies, try Operation 3: \n\n import copy\ny = [0] * 2   \nprint(y)   # [0, 0]\n\ny = [y, copy.deepcopy(y)]  \nprint(y) # [[0, 0], [0, 0]]\n\ny[0][0] = 1\nprint(y) # [[1, 0], [0, 0]]\n \n\n another interesting way to create clone copies, Operation 4: \n\n import copy\ny = [0] * 2\nprint(y) # [0, 0]\n\ny = [copy.deepcopy(y) for num in range(1,5)]\nprint(y) # [[0, 0], [0, 0], [0, 0], [0, 0]]\n\ny[0][0] = 5\nprint(y) # [[5, 0], [0, 0], [0, 0], [0, 0]]\n \n    ", "date_posted": "2016-08-10 07:29:38Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "2285848", "name": "Adil Abbasi", "reputation_score": "3,101"}, "answer_comments": []}, {"stack_answer_id": "38397772", "answer_content": "\r\n By using the inbuilt list function you can do like this \n\n a\nout:[[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]\n#Displaying the list\n\na.remove(a[0])\nout:[[1, 1, 1, 1], [1, 1, 1, 1]]\n# Removed the first element of the list in which you want altered number\n\na.append([5,1,1,1])\nout:[[1, 1, 1, 1], [1, 1, 1, 1], [5, 1, 1, 1]]\n# append the element in the list but the appended element as you can see is appended in last but you want that in starting\n\na.reverse()\nout:[[5, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]\n#So at last reverse the whole list to get the desired list\n \n    ", "date_posted": "2016-07-25 09:09:59Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "5230702", "name": "Anand Tripathi", "reputation_score": "12.4k"}, "answer_comments": [{"stack_answer_id": "38397772", "stack_answer_comment_id": "92685565", "comment_content": "Note, fourth step can be dropped if you make second step: ", "user_id": "None"}]}, {"stack_answer_id": "64489659", "answer_content": "\r\n I arrived here because I was looking to see how I could nest an arbitrary number of lists. There are a lot of explanations and specific examples above, but you can generalize N dimensional list of lists of lists of ... with the following recursive function: \n import copy\n\ndef list_ndim(dim, el=None, init=None):\n    if init is None:\n        init = el\n\n    if len(dim)> 1:\n        return list_ndim(dim[0:-1], None, [copy.copy(init) for x in range(dim[-1])])\n\n    return [copy.deepcopy(init) for x in range(dim[0])]\n \n You make your first call to the function like this: \n dim = (3,5,2)\nel = 1.0\nl = list_ndim(dim, el)\n \n where  (3,5,2)  is a tuple of the dimensions of the structure (similar to numpy  shape  argument), and  1.0  is the element you want the structure to be initialized with (works with None as well). Note that the  init  argument is only provided by the recursive call to carry forward the nested child lists \n output of above: \n [[[1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0]],\n [[1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0]],\n [[1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0]]]\n \n set specific elements: \n l[1][3][1] = 56\nl[2][2][0] = 36.0+0.0j\nl[0][1][0] = 'abc'\n \n resulting output: \n [[[1.0, 1.0], ['abc', 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0]],\n [[1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 56.0], [1.0, 1.0]],\n [[1.0, 1.0], [1.0, 1.0], [(36+0j), 1.0], [1.0, 1.0], [1.0, 1.0]]]\n \n the non-typed nature of lists is demonstrated above \n    ", "date_posted": "2020-10-22 19:57:45Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "8126390", "name": "Brian", "reputation_score": "533"}, "answer_comments": []}, {"stack_answer_id": "65616429", "answer_content": "\r\n While the original question constructed the  sublists  with the multiplication operator, I'll add an example that uses the  same  list for the sublists. Adding this answer for completeness as this question is often used as a canonical for the issue \n node_count = 4\ncolors = [0,1,2,3]\nsol_dict = {node:colors for node in range(0,node_count)}\n \n The list in each dictionary value is the same object, trying to change one of the dictionaries values will be seen in all. \n >>> sol_dict\n{0: [0, 1, 2, 3], 1: [0, 1, 2, 3], 2: [0, 1, 2, 3], 3: [0, 1, 2, 3]}\n>>> [v is colors for v in sol_dict.values()]\n[True, True, True, True]\n>>> sol_dict[0].remove(1)\n>>> sol_dict\n{0: [0, 2, 3], 1: [0, 2, 3], 2: [0, 2, 3], 3: [0, 2, 3]}\n \n The correct way to construct the dictionary would be to use a copy of the list for each value. \n >>> colors = [0,1,2,3]\n>>> sol_dict = {node:colors[:] for node in range(0,node_count)}\n>>> sol_dict\n{0: [0, 1, 2, 3], 1: [0, 1, 2, 3], 2: [0, 1, 2, 3], 3: [0, 1, 2, 3]}\n>>> sol_dict[0].remove(1)\n>>> sol_dict\n{0: [0, 2, 3], 1: [0, 1, 2, 3], 2: [0, 1, 2, 3], 3: [0, 1, 2, 3]}\n \n    ", "date_posted": "2021-01-07 16:39:52Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "65616429", "name": "\r\n        wwii\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "64958758", "answer_content": "\r\n Note that items in the sequence are not copied; they are referenced multiple times . This often haunts new Python programmers; consider: \n >>> lists = [[]] * 3\n>>> lists\n[[], [], []]\n>>> lists[0].append(3)\n>>> lists\n[[3], [3], [3]]\n \n What has happened is that  [[]]  is a one-element list containing an empty list, so all three elements of  [[]] * 3  are references to this single empty list. Modifying any of the elements of lists modifies this single list. \n Another example to explain this is using  multi-dimensional arrays . \n You probably tried to make a multidimensional array like this: \n >>> A = [[None] * 2] * 3\n \n This looks correct if you print it: \n >>> A\n[[None, None], [None, None], [None, None]]\n \n But when you assign a value, it shows up in multiple places: \n >>> A[0][0] = 5\n>>> A\n[[5, None], [5, None], [5, None]]\n \n The reason is that replicating a list with\u00a0 * \u00a0doesn\u2019t create copies, it only creates references to the existing objects. The\u00a03\u00a0creates a list containing 3 references to the same list of length two. Changes to one row will show in all rows, which is almost certainly not what you want. \n    ", "date_posted": "2021-03-20 14:25:08Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "7841468", "name": "mishsx", "reputation_score": "1,275"}, "answer_comments": []}], "user": {"stack_user_id": "11677", "name": "Charles Anderson", "reputation_score": "18.3k"}, "question_comments": [{"stack_question_id": "240178", "stack_question_comment_id": "124422290", "comment_content": "Note that the same logic applies to a list of dicts, because of the same fundamental problem of aliasing a mutable object. See ", "user_id": "None"}, {"stack_question_id": "240178", "stack_question_comment_id": "127396210", "comment_content": "Are there more specific questions for when the list of lists is created in other ways (but has the same problem)? For example, by using ", "user_id": "None"}, {"stack_question_id": "240178", "stack_question_comment_id": "128071922", "comment_content": "See also ", "user_id": "None"}, {"stack_question_id": "240178", "stack_question_comment_id": "128430067", "comment_content": "Related: ", "user_id": "None"}]},
{"stack_question_id": "509211", "question_title": "Understanding slicing", "question_content": "\r\n                I need a good explanation (references are a plus) on Python slicing.\r\n", "question_url": "/questions/509211/understanding-slicing", "date_posted": "Feb 3, 2009 at 22:31", "upvote": "4", "view": "2", "tags": ["python", "slice", "sequence"], "answers_count": "3", "answers": [{"stack_answer_id": "509295", "answer_content": "\r\n The syntax is: \n a[start:stop]  # items start through stop-1\na[start:]      # items start through the rest of the array\na[:stop]       # items from the beginning through stop-1\na[:]           # a copy of the whole array\n \n There is also the  step  value, which can be used with any of the above: \n a[start:stop:step] # start through not past stop, by step\n \n The key point to remember is that the  :stop  value represents the first value that is  not  in the selected slice. So, the difference between  stop  and  start  is the number of elements selected (if  step  is 1, the default). \n The other feature is that  start  or  stop  may be a  negative  number, which means it counts from the end of the array instead of the beginning. So: \n a[-1]    # last item in the array\na[-2:]   # last two items in the array\na[:-2]   # everything except the last two items\n \n Similarly,  step  may be a negative number: \n a[::-1]    # all items in the array, reversed\na[1::-1]   # the first two items, reversed\na[:-3:-1]  # the last two items, reversed\na[-3::-1]  # everything except the last two items, reversed\n \n Python is kind to the programmer if there are fewer items than you ask for. For example, if you ask for  a[:-2]  and  a  only contains one element, you get an empty list instead of an error. Sometimes you would prefer the error, so you have to be aware that this may happen. \n Relationship with the  slice  object \n A  slice  object  can represent a slicing operation, i.e.: \n a[start:stop:step]\n \n is equivalent to: \n a[slice(start, stop, step)]\n \n Slice objects also behave slightly differently depending on the number of arguments, similarly to  range() , i.e. both  slice(stop)  and  slice(start, stop[, step])  are supported.\nTo skip specifying a given argument, one might use  None , so that e.g.  a[start:]  is equivalent to  a[slice(start, None)]  or  a[::-1]  is equivalent to  a[slice(None, None, -1)] . \n While the  : -based notation is very helpful for simple slicing, the explicit use of  slice()  objects simplifies the programmatic generation of slicing. \n    ", "date_posted": "2022-05-22 19:33:18Z", "upvote": "\r\n            6103\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": [{"stack_answer_id": "509295", "stack_answer_comment_id": "27984940", "comment_content": "Slicing builtin types returns a copy but that's not universal.  Notably, ", "user_id": "None"}, {"stack_answer_id": "509295", "stack_answer_comment_id": "95272803", "comment_content": "This is a beautiful answer with the votes to prove it, but it misses one thing: you can substitute ", "user_id": "None"}, {"stack_answer_id": "509295", "stack_answer_comment_id": "99325528", "comment_content": "Note that contrary to usual Python slices (see above), in Pandas Dataframes both the start and the stop are included when present in the index. For further info see the ", "user_id": "None"}, {"stack_answer_id": "509295", "stack_answer_comment_id": "100203161", "comment_content": "What really annoys me is that python says that when you don't set the start and the end, they default to 0 and the length of sequence. So, in theory, when you use \"abcdef\"[::-1] it should be transformed to \"abcdef\"[0:6:-1], but these two expressions does not get the same output. I feel that something is missing in python documentation since the creation of the language.", "user_id": "None"}, {"stack_answer_id": "509295", "stack_answer_comment_id": "100203434", "comment_content": "And I know that \"abcdef\"[::-1] is transformed to \"abcdef\"[6:-7:-1], so, the best way to explain would be: let ", "user_id": "None"}]}, {"stack_answer_id": "509297", "answer_content": "\r\n The  Python tutorial  talks about it (scroll down a bit until you get to the part about slicing). \n\n The ASCII art diagram is helpful too for remembering how slices work: \n\n  +---+---+---+---+---+---+\n | P | y | t | h | o | n |\n +---+---+---+---+---+---+\n 0   1   2   3   4   5   6\n-6  -5  -4  -3  -2  -1\n \n\n \n   One way to remember how slices work is to think of the indices as pointing  between  characters, with the left edge of the first character numbered 0. Then the right edge of the last character of a string of  n  characters has index  n . \n \n    ", "date_posted": "2017-09-18 11:02:56Z", "upvote": "\r\n            662\r\n        ", "accepted": "No", "user": {"stack_user_id": "55075", "name": "kenorb", "reputation_score": "141k"}, "answer_comments": [{"stack_answer_id": "509297", "stack_answer_comment_id": "99270489", "comment_content": "This suggestion works for positive stride, but does not for a negative stride. From the diagram, I expect ", "user_id": "None"}, {"stack_answer_id": "509297", "stack_answer_comment_id": "100377224", "comment_content": "But there's no way to collapse to an empty set starting from the end (like ", "user_id": "None"}, {"stack_answer_id": "509297", "stack_answer_comment_id": "118360396", "comment_content": "@aguadopd You are absolutely right. The solution is to have the indices shifted to the right, centered just below the characters, and notice that the stop is always excluded. See another response just below.", "user_id": "None"}, {"stack_answer_id": "509297", "stack_answer_comment_id": "118606940", "comment_content": "Addendum to my comment: see my answer with diagrams below: ", "user_id": "None"}]}, {"stack_answer_id": "509377", "answer_content": "\r\n Enumerating the possibilities allowed by the grammar for the sequence  x : \n >>> x[:]                # [x[0],   x[1],          ..., x[-1]    ]\n>>> x[low:]             # [x[low], x[low+1],      ..., x[-1]    ]\n>>> x[:high]            # [x[0],   x[1],          ..., x[high-1]]\n>>> x[low:high]         # [x[low], x[low+1],      ..., x[high-1]]\n>>> x[::stride]         # [x[0],   x[stride],     ..., x[-1]    ]\n>>> x[low::stride]      # [x[low], x[low+stride], ..., x[-1]    ]\n>>> x[:high:stride]     # [x[0],   x[stride],     ..., x[high-1]]\n>>> x[low:high:stride]  # [x[low], x[low+stride], ..., x[high-1]]\n \n Of course, if  (high-low)%stride != 0 , then the end point will be a little lower than  high-1 . \n If  stride  is negative, the ordering is changed a bit since we're counting down: \n >>> x[::-stride]        # [x[-1],   x[-1-stride],   ..., x[0]    ]\n>>> x[high::-stride]    # [x[high], x[high-stride], ..., x[0]    ]\n>>> x[:low:-stride]     # [x[-1],   x[-1-stride],   ..., x[low+1]]\n>>> x[high:low:-stride] # [x[high], x[high-stride], ..., x[low+1]]\n \n Extended slicing (with commas and ellipses) are mostly used only by special data structures (like NumPy); the basic sequences don't support them. \n >>> class slicee:\n...     def __getitem__(self, item):\n...         return repr(item)\n...\n>>> slicee()[0, 1:2, ::5, ...]\n'(0, slice(1, 2, None), slice(None, None, 5), Ellipsis)'\n \n    ", "date_posted": "2022-05-22 19:38:32Z", "upvote": "\r\n            498\r\n        ", "accepted": "No", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": [{"stack_answer_id": "509377", "stack_answer_comment_id": "83074550", "comment_content": "Actually there is still something left out e.g. if I type 'apple'[4:-4:-1] I get 'elp', python is translating the -4 to a 1 maybe?", "user_id": "None"}, {"stack_answer_id": "509377", "stack_answer_comment_id": "95581586", "comment_content": "note that backticks are deprecated in favour of ", "user_id": "None"}, {"stack_answer_id": "509377", "stack_answer_comment_id": "102170688", "comment_content": "@liyuan The type implementing ", "user_id": "None"}, {"stack_answer_id": "509377", "stack_answer_comment_id": "124476274", "comment_content": "The first two tables are pure gold.", "user_id": "None"}]}, {"stack_answer_id": "4729334", "answer_content": "\r\n The answers above don't discuss slice assignment. To understand slice assignment, it's helpful to add another concept to the ASCII art: \n\n                 +---+---+---+---+---+---+\n                | P | y | t | h | o | n |\n                +---+---+---+---+---+---+\nSlice position: 0   1   2   3   4   5   6\nIndex position:   0   1   2   3   4   5\n\n>>> p = ['P','y','t','h','o','n']\n# Why the two sets of numbers:\n# indexing gives items, not lists\n>>> p[0]\n 'P'\n>>> p[5]\n 'n'\n\n# Slicing gives lists\n>>> p[0:1]\n ['P']\n>>> p[0:2]\n ['P','y']\n \n\n One heuristic is, for a slice from zero to n, think: \"zero is the beginning, start at the beginning and take n items in a list\". \n\n >>> p[5] # the last of six items, indexed from zero\n 'n'\n>>> p[0:5] # does NOT include the last item!\n ['P','y','t','h','o']\n>>> p[0:6] # not p[0:5]!!!\n ['P','y','t','h','o','n']\n \n\n Another heuristic is, \"for any slice, replace the start by zero, apply the previous heuristic to get the end of the list, then count the first number back up to chop items off the beginning\" \n\n >>> p[0:4] # Start at the beginning and count out 4 items\n ['P','y','t','h']\n>>> p[1:4] # Take one item off the front\n ['y','t','h']\n>>> p[2:4] # Take two items off the front\n ['t','h']\n# etc.\n \n\n The first rule of slice assignment is that since slicing  returns  a list, slice assignment  requires  a list (or other iterable): \n\n >>> p[2:3]\n ['t']\n>>> p[2:3] = ['T']\n>>> p\n ['P','y','T','h','o','n']\n>>> p[2:3] = 't'\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: can only assign an iterable\n \n\n The second rule of slice assignment, which you can also see above, is that whatever portion of the list is returned by slice indexing, that's the same portion that is changed by slice assignment: \n\n >>> p[2:4]\n ['T','h']\n>>> p[2:4] = ['t','r']\n>>> p\n ['P','y','t','r','o','n']\n \n\n The third rule of slice assignment is, the assigned list (iterable) doesn't have to have the same length; the indexed slice is simply sliced out and replaced en masse by whatever is being assigned: \n\n >>> p = ['P','y','t','h','o','n'] # Start over\n>>> p[2:4] = ['s','p','a','m']\n>>> p\n ['P','y','s','p','a','m','o','n']\n \n\n The trickiest part to get used to is assignment to empty slices. Using heuristic 1 and 2 it's easy to get your head around  indexing  an empty slice: \n\n >>> p = ['P','y','t','h','o','n']\n>>> p[0:4]\n ['P','y','t','h']\n>>> p[1:4]\n ['y','t','h']\n>>> p[2:4]\n ['t','h']\n>>> p[3:4]\n ['h']\n>>> p[4:4]\n []\n \n\n And then once you've seen that, slice assignment to the empty slice makes sense too: \n\n >>> p = ['P','y','t','h','o','n']\n>>> p[2:4] = ['x','y'] # Assigned list is same length as slice\n>>> p\n ['P','y','x','y','o','n'] # Result is same length\n>>> p = ['P','y','t','h','o','n']\n>>> p[3:4] = ['x','y'] # Assigned list is longer than slice\n>>> p\n ['P','y','t','x','y','o','n'] # The result is longer\n>>> p = ['P','y','t','h','o','n']\n>>> p[4:4] = ['x','y']\n>>> p\n ['P','y','t','h','x','y','o','n'] # The result is longer still\n \n\n Note that, since we are not changing the second number of the slice (4), the inserted items always stack right up against the 'o', even when we're assigning to the empty slice. So the position for the empty slice assignment is the logical extension of the positions for the non-empty slice assignments. \n\n Backing up a little bit, what happens when you keep going with our procession of counting up the slice beginning? \n\n >>> p = ['P','y','t','h','o','n']\n>>> p[0:4]\n ['P','y','t','h']\n>>> p[1:4]\n ['y','t','h']\n>>> p[2:4]\n ['t','h']\n>>> p[3:4]\n ['h']\n>>> p[4:4]\n []\n>>> p[5:4]\n []\n>>> p[6:4]\n []\n \n\n With slicing, once you're done, you're done; it doesn't start slicing backwards. In Python you don't get negative strides unless you explicitly ask for them by using a negative number. \n\n >>> p[5:3:-1]\n ['n','o']\n \n\n There are some weird consequences to the \"once you're done, you're done\" rule: \n\n >>> p[4:4]\n []\n>>> p[5:4]\n []\n>>> p[6:4]\n []\n>>> p[6]\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nIndexError: list index out of range\n \n\n In fact, compared to indexing, Python slicing is bizarrely error-proof: \n\n >>> p[100:200]\n []\n>>> p[int(2e99):int(1e99)]\n []\n \n\n This can come in handy sometimes, but it can also lead to somewhat strange behavior: \n\n >>> p\n ['P', 'y', 't', 'h', 'o', 'n']\n>>> p[int(2e99):int(1e99)] = ['p','o','w','e','r']\n>>> p\n ['P', 'y', 't', 'h', 'o', 'n', 'p', 'o', 'w', 'e', 'r']\n \n\n Depending on your application, that might... or might not... be what you were hoping for there! \n\n \n\n Below is the text of my original answer. It has been useful to many people, so I didn't want to delete it. \n\n >>> r=[1,2,3,4]\n>>> r[1:1]\n[]\n>>> r[1:1]=[9,8]\n>>> r\n[1, 9, 8, 2, 3, 4]\n>>> r[1:1]=['blah']\n>>> r\n[1, 'blah', 9, 8, 2, 3, 4]\n \n\n This may also clarify the difference between slicing and indexing. \n    ", "date_posted": "2019-01-02 16:44:22Z", "upvote": "\r\n            418\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "4729334", "stack_answer_comment_id": "129107053", "comment_content": "If I wanted to remove the 1st x elements of a list, what will be better: ", "user_id": "None"}, {"stack_answer_id": "4729334", "stack_answer_comment_id": "129131819", "comment_content": "The first way works for a list or a string; the second way only works for a list, because slice assignment isn't allowed for strings. Other than that I think the only difference is speed: it looks like it's a little faster the first way. Try it yourself with timeit.timeit() or preferably  timeit.repeat(). They are ", "user_id": "None"}]}, {"stack_answer_id": "24713353", "answer_content": "\r\n \n Explain Python's slice notation \n \n In short, the colons ( : ) in subscript notation ( subscriptable[subscriptarg] ) make slice notation, which has the optional arguments  start ,  stop , and  step : \n sliceable[start:stop:step]\n \n Python slicing is a computationally fast way to methodically access parts of your data. In my opinion, to be even an intermediate Python programmer, it's one aspect of the language that it is necessary to be familiar with. \n Important Definitions \n To begin with, let's define a few terms: \n \n start :  the beginning index of the slice, it will include the element at this index unless it is the same as  stop , defaults to 0, i.e. the first index. If it's negative, it means to start  n  items from the end. \n stop :  the ending index of the slice, it does  not  include the element at this index, defaults to length of the sequence being sliced, that is, up to and including the end. \n step :  the amount by which the index increases, defaults to 1. If it's negative, you're slicing over the iterable in reverse. \n \n How Indexing Works \n You can make any of these positive or negative numbers. The meaning of the positive numbers is straightforward, but for negative numbers, just like indexes in Python, you count backwards from the end for the  start  and  stop , and for the  step , you simply decrement your index. This example is  from the documentation's tutorial , but I've modified it slightly to indicate which item in a sequence each index references: \n  +---+---+---+---+---+---+\n | P | y | t | h | o | n |\n +---+---+---+---+---+---+\n   0   1   2   3   4   5 \n  -6  -5  -4  -3  -2  -1\n \n How Slicing Works \n To use slice notation with a sequence that supports it, you must include at least one colon in the square brackets that follow the sequence (which actually  implement the  __getitem__  method of the sequence, according to the Python data model .) \n Slice notation works like this: \n sequence[start:stop:step]\n \n And recall that there are defaults for  start ,  stop , and  step , so to access the defaults, simply leave out the argument. \n Slice notation to get the last nine elements from a list (or any other sequence that supports it, like a string) would look like this: \n my_list[-9:]\n \n When I see this, I read the part in the brackets as \"9th from the end, to the end.\" (Actually, I abbreviate it mentally as \"-9, on\") \n Explanation: \n The full notation is \n my_list[-9:None:None]\n \n and to substitute the defaults (actually when  step  is negative,  stop 's default is  -len(my_list) - 1 , so  None  for stop really just means it goes to whichever end step takes it to): \n my_list[-9:len(my_list):1]\n \n The  colon ,  : ,  is what tells Python you're giving it a slice and not a regular index. That's why the idiomatic way of making a shallow copy of lists in Python 2 is \n list_copy = sequence[:]\n \n And clearing them is with: \n del my_list[:]\n \n (Python 3 gets a  list.copy  and  list.clear  method.) \n When  step  is negative, the defaults for  start  and  stop  change \n By default, when the  step  argument is empty (or  None ), it is assigned to  +1 . \n But you can pass in a negative integer, and the list (or most other standard sliceables) will be sliced from the end to the beginning. \n Thus a negative slice will change the defaults for  start  and  stop ! \n Confirming this in the source \n I like to encourage users to read the source as well as the documentation. The  source code for slice objects and this logic is found here . First we determine if  step  is negative: \n \n step_is_negative = step_sign < 0;\n \n \n If so, the lower bound is  -1   meaning we slice all the way up to and including the beginning, and the upper bound is the length minus 1, meaning we start at the end. (Note that the semantics of this  -1  is  different  from a  -1  that users may pass indexes in Python indicating the last item.) \n \n if (step_is_negative) {\n    lower = PyLong_FromLong(-1L);\n    if (lower == NULL)\n        goto error;\n\n    upper = PyNumber_Add(length, lower);\n    if (upper == NULL)\n        goto error;\n}\n \n \n Otherwise  step  is positive, and the lower bound will be zero and the upper bound (which we go up to but not including) the length of the sliced list. \n \n else {\n    lower = _PyLong_Zero;\n    Py_INCREF(lower);\n    upper = length;\n    Py_INCREF(upper);\n}\n \n \n Then, we may need to apply the defaults for  start  and  stop \u2014the default then for  start  is calculated as the upper bound when  step  is negative: \n \n if (self->start == Py_None) {\n    start = step_is_negative ? upper : lower;\n    Py_INCREF(start);\n}\n \n \n and  stop , the lower bound: \n \n if (self->stop == Py_None) {\n    stop = step_is_negative ? lower : upper;\n    Py_INCREF(stop);\n}\n \n \n Give your slices a descriptive name! \n You may find it useful to separate forming the slice from passing it to the  list.__getitem__  method ( that's what the square brackets do ). Even if you're not new to it, it keeps your code more readable so that others that may have to read your code can more readily understand what you're doing. \n However, you can't just assign some integers separated by colons to a variable. You need to use the slice object: \n last_nine_slice = slice(-9, None)\n \n The second argument,  None , is required, so that the first argument is interpreted as the  start  argument  otherwise it would be the  stop  argument . \n You can then pass the slice object to your sequence: \n >>> list(range(100))[last_nine_slice]\n[91, 92, 93, 94, 95, 96, 97, 98, 99]\n \n It's interesting that ranges also take slices: \n >>> range(100)[last_nine_slice]\nrange(91, 100)\n \n Memory Considerations: \n Since slices of Python lists create new objects in memory, another important function to be aware of is  itertools.islice . Typically you'll want to iterate over a slice, not just have it created statically in memory.  islice  is perfect for this. A caveat, it doesn't support negative arguments to  start ,  stop , or  step , so if that's an issue you may need to calculate indices or reverse the iterable in advance. \n length = 100\nlast_nine_iter = itertools.islice(list(range(length)), length-9, None, 1)\nlist_last_nine = list(last_nine_iter)\n \n and now: \n >>> list_last_nine\n[91, 92, 93, 94, 95, 96, 97, 98, 99]\n \n The fact that list slices make a copy is a feature of lists themselves. If you're slicing advanced objects like a Pandas DataFrame, it may return a view on the original, and not a copy. \n    ", "date_posted": "2022-04-30 17:20:06Z", "upvote": "\r\n            282\r\n        ", "accepted": "No", "user": {"stack_user_id": "241211", "name": "Michael", "reputation_score": "7,466"}, "answer_comments": [{"stack_answer_id": "24713353", "stack_answer_comment_id": "113402270", "comment_content": "I like the idea of naming slices. I would suggest ", "user_id": "None"}, {"stack_answer_id": "24713353", "stack_answer_comment_id": "113403311", "comment_content": "@WinEunuuchs2Unix that's great feedback - this is a standard Python behavior, but it could be made clearer in that sort of way, so I'll consider updating my material to include this semantic.", "user_id": "None"}]}, {"stack_answer_id": "509415", "answer_content": "\r\n And a couple of things that weren't immediately obvious to me when I first saw the slicing syntax: \n\n >>> x = [1,2,3,4,5,6]\n>>> x[::-1]\n[6,5,4,3,2,1]\n \n\n Easy way to reverse sequences! \n\n And if you wanted, for some reason, every second item in the reversed sequence: \n\n >>> x = [1,2,3,4,5,6]\n>>> x[::-2]\n[6,4,2]\n \n    ", "date_posted": "2009-02-03 23:15:02Z", "upvote": "\r\n            157\r\n        ", "accepted": "No", "user": {"stack_user_id": "7856", "name": "Dana", "reputation_score": "30.8k"}, "answer_comments": []}, {"stack_answer_id": "13005464", "answer_content": "\r\n In Python 2.7 \n\n Slicing in Python \n\n [a:b:c]\n\nlen = length of string, tuple or list\n\nc -- default is +1. The sign of c indicates forward or backward, absolute value of c indicates steps. Default is forward with step size 1. Positive means forward, negative means backward.\n\na --  When c is positive or blank, default is 0. When c is negative, default is -1.\n\nb --  When c is positive or blank, default is len. When c is negative, default is -(len+1).\n \n\n Understanding index assignment is very important. \n\n In forward direction, starts at 0 and ends at len-1\n\nIn backward direction, starts at -1 and ends at -len\n \n\n When you say [a:b:c], you are saying depending on the sign of c (forward or backward), start at a and end at b (excluding element at bth index). Use the indexing rule above and remember you will only find elements in this range: \n\n -len, -len+1, -len+2, ..., 0, 1, 2,3,4 , len -1\n \n\n But this range continues in both directions infinitely: \n\n ...,-len -2 ,-len-1,-len, -len+1, -len+2, ..., 0, 1, 2,3,4 , len -1, len, len +1, len+2 , ....\n \n\n For example: \n\n              0    1    2   3    4   5   6   7   8   9   10   11\n             a    s    t   r    i   n   g\n    -9  -8  -7   -6   -5  -4   -3  -2  -1\n \n\n If your choice of a, b, and c allows overlap with the range above as you traverse using rules for a,b,c above you will either get a list with elements (touched during traversal) or you will get an empty list. \n\n One last thing: if a and b are equal, then also you get an empty list: \n\n >>> l1\n[2, 3, 4]\n\n>>> l1[:]\n[2, 3, 4]\n\n>>> l1[::-1] # a default is -1 , b default is -(len+1)\n[4, 3, 2]\n\n>>> l1[:-4:-1] # a default is -1\n[4, 3, 2]\n\n>>> l1[:-3:-1] # a default is -1\n[4, 3]\n\n>>> l1[::] # c default is +1, so a default is 0, b default is len\n[2, 3, 4]\n\n>>> l1[::-1] # c is -1 , so a default is -1 and b default is -(len+1)\n[4, 3, 2]\n\n\n>>> l1[-100:-200:-1] # Interesting\n[]\n\n>>> l1[-1:-200:-1] # Interesting\n[4, 3, 2]\n\n\n>>> l1[-1:-1:1]\n[]\n\n\n>>> l1[-1:5:1] # Interesting\n[4]\n\n\n>>> l1[1:-7:1]\n[]\n\n>>> l1[1:-7:-1] # Interesting\n[3, 2]\n\n>>> l1[:-2:-2] # a default is -1, stop(b) at -2 , step(c) by 2 in reverse direction\n[4]\n \n    ", "date_posted": "2017-07-10 16:59:26Z", "upvote": "\r\n            109\r\n        ", "accepted": "No", "user": {"stack_user_id": "494074", "name": "Ankur Agarwal", "reputation_score": "22.2k"}, "answer_comments": [{"stack_answer_id": "13005464", "stack_answer_comment_id": "77001814", "comment_content": "another one interesting example: ", "user_id": "None"}]}, {"stack_answer_id": "7315935", "answer_content": "\r\n Found this great table at  http://wiki.python.org/moin/MovingToPythonFromOtherLanguages \n\n Python indexes and slices for a six-element list.\nIndexes enumerate the elements, slices enumerate the spaces between the elements.\n\nIndex from rear:    -6  -5  -4  -3  -2  -1      a=[0,1,2,3,4,5]    a[1:]==[1,2,3,4,5]\nIndex from front:    0   1   2   3   4   5      len(a)==6          a[:5]==[0,1,2,3,4]\n                   +---+---+---+---+---+---+    a[0]==0            a[:-2]==[0,1,2,3]\n                   | a | b | c | d | e | f |    a[5]==5            a[1:2]==[1]\n                   +---+---+---+---+---+---+    a[-1]==5           a[1:-1]==[1,2,3,4]\nSlice from front:  :   1   2   3   4   5   :    a[-2]==4\nSlice from rear:   :  -5  -4  -3  -2  -1   :\n                                                b=a[:]\n                                                b==[0,1,2,3,4,5] (shallow copy of a) \n    ", "date_posted": "2011-09-06 06:50:08Z", "upvote": "\r\n            101\r\n        ", "accepted": "No", "user": {"stack_user_id": "43769", "name": "AdrianoFerrari", "reputation_score": "2,110"}, "answer_comments": []}, {"stack_answer_id": "567094", "answer_content": "\r\n After using it a bit I realise that the simplest description is that it is exactly the same as the arguments in a  for  loop... \n\n (from:to:step)\n \n\n Any of them are optional: \n\n (:to:step)\n(from::step)\n(from:to)\n \n\n Then the negative indexing just needs you to add the length of the string to the negative indices to understand it. \n\n This works for me anyway... \n    ", "date_posted": "2019-01-02 16:40:20Z", "upvote": "\r\n            70\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "9923354", "answer_content": "\r\n I find it easier to remember how it works, and then I can figure out any specific start/stop/step combination. \n\n It's instructive to understand  range()  first: \n\n def range(start=0, stop, step=1):  # Illegal syntax, but that's the effect\n    i = start\n    while (i < stop if step > 0 else i > stop):\n        yield i\n        i += step\n \n\n Begin from  start , increment by  step , do not reach  stop .  Very simple. \n\n The thing to remember about negative step is that  stop  is always the excluded end, whether it's higher or lower. If you want same slice in opposite order, it's much cleaner to do the reversal separately: e.g.  'abcde'[1:-2][::-1]  slices off one char from left, two from right, then reverses. (See also  reversed() .) \n\n Sequence slicing is same, except it first normalizes negative indexes, and it can never go outside the sequence: \n\n TODO : The code below had a bug with \"never go outside the sequence\" when abs(step)>1; I  think  I patched it to be correct, but it's hard to understand. \n\n def this_is_how_slicing_works(seq, start=None, stop=None, step=1):\n    if start is None:\n        start = (0 if step > 0 else len(seq)-1)\n    elif start < 0:\n        start += len(seq)\n    if not 0 <= start < len(seq):  # clip if still outside bounds\n        start = (0 if step > 0 else len(seq)-1)\n    if stop is None:\n        stop = (len(seq) if step > 0 else -1)  # really -1, not last element\n    elif stop < 0:\n        stop += len(seq)\n    for i in range(start, stop, step):\n        if 0 <= i < len(seq):\n            yield seq[i]\n \n\n Don't worry about the  is None  details - just remember that omitting  start  and/or  stop  always does the right thing to give you the whole sequence. \n\n Normalizing negative indexes first allows start and/or stop to be counted from the end independently:  'abcde'[1:-2] == 'abcde'[1:3] == 'bc'  despite  range(1,-2) == [] .\nThe normalization is sometimes thought of as \"modulo the length\", but note it adds the length just once: e.g.  'abcde'[-53:42]  is just the whole string. \n    ", "date_posted": "2019-01-02 16:46:18Z", "upvote": "\r\n            54\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "9923354", "stack_answer_comment_id": "67894582", "comment_content": "The ", "user_id": "None"}, {"stack_answer_id": "9923354", "stack_answer_comment_id": "67913261", "comment_content": "@Eastsun Oops, you're right!  A clearer case: ", "user_id": "None"}]}, {"stack_answer_id": "522212", "answer_content": "\r\n I use the \"an index points between elements\" method of thinking about it myself, but one way of describing it which sometimes helps others get it is this: \n\n mylist[X:Y]\n \n\n X is the index of the first element you want. \nY is the index of the first element you  don't  want. \n    ", "date_posted": "2009-02-06 21:16:28Z", "upvote": "\r\n            43\r\n        ", "accepted": "No", "user": {"stack_user_id": "13498", "name": "Steve Losh", "reputation_score": "19.4k"}, "answer_comments": []}, {"stack_answer_id": "14682039", "answer_content": "\r\n Index:\n      ------------>\n  0   1   2   3   4\n+---+---+---+---+---+\n| a | b | c | d | e |\n+---+---+---+---+---+\n  0  -4  -3  -2  -1\n      <------------\n\nSlice:\n    <---------------|\n|--------------->\n:   1   2   3   4   :\n+---+---+---+---+---+\n| a | b | c | d | e |\n+---+---+---+---+---+\n:  -4  -3  -2  -1   :\n|--------------->\n    <---------------|\n \n\n I hope this will help you to model the list in Python. \n\n Reference:  http://wiki.python.org/moin/MovingToPythonFromOtherLanguages \n    ", "date_posted": "2017-02-11 19:56:15Z", "upvote": "\r\n            43\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "29237560", "answer_content": "\r\n This is how I teach slices to newbies: \n\n Understanding the difference between indexing and slicing: \n\n Wiki Python has this amazing picture which clearly distinguishes indexing and slicing. \n\n \n\n It is a list with six elements in it. To understand slicing better, consider that list as a set of six boxes placed together. Each box has an alphabet in it. \n\n Indexing is like dealing with the contents of box. You can check contents of any box. But you can't check the contents of multiple boxes at once. You can even replace the contents of the box. But you can't place two balls in one box or replace two balls at a time. \n\n In [122]: alpha = ['a', 'b', 'c', 'd', 'e', 'f']\n\nIn [123]: alpha\nOut[123]: ['a', 'b', 'c', 'd', 'e', 'f']\n\nIn [124]: alpha[0]\nOut[124]: 'a'\n\nIn [127]: alpha[0] = 'A'\n\nIn [128]: alpha\nOut[128]: ['A', 'b', 'c', 'd', 'e', 'f']\n\nIn [129]: alpha[0,1]\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n<ipython-input-129-c7eb16585371> in <module>()\n----> 1 alpha[0,1]\n\nTypeError: list indices must be integers, not tuple\n \n\n Slicing is like dealing with boxes themselves. You can pick up the first box and place it on another table. To pick up the box, all you need to know is the position of beginning and ending of the box. \n\n You can even pick up the first three boxes or the last two boxes or all boxes between 1 and 4. So, you can pick any set of boxes if you know the beginning and ending. These positions are called start and stop positions. \n\n The interesting thing is that you can replace multiple boxes at once. Also you can place multiple boxes wherever you like. \n\n In [130]: alpha[0:1]\nOut[130]: ['A']\n\nIn [131]: alpha[0:1] = 'a'\n\nIn [132]: alpha\nOut[132]: ['a', 'b', 'c', 'd', 'e', 'f']\n\nIn [133]: alpha[0:2] = ['A', 'B']\n\nIn [134]: alpha\nOut[134]: ['A', 'B', 'c', 'd', 'e', 'f']\n\nIn [135]: alpha[2:2] = ['x', 'xx']\n\nIn [136]: alpha\nOut[136]: ['A', 'B', 'x', 'xx', 'c', 'd', 'e', 'f']\n \n\n Slicing With Step: \n\n Till now you have picked boxes continuously. But sometimes you need to pick up discretely. For example, you can pick up every second box. You can even pick up every third box from the end. This value is called step size. This represents the gap between your successive pickups. The step size should be positive if You are picking boxes from the beginning to end and vice versa. \n\n In [137]: alpha = ['a', 'b', 'c', 'd', 'e', 'f']\n\nIn [142]: alpha[1:5:2]\nOut[142]: ['b', 'd']\n\nIn [143]: alpha[-1:-5:-2]\nOut[143]: ['f', 'd']\n\nIn [144]: alpha[1:5:-2]\nOut[144]: []\n\nIn [145]: alpha[-1:-5:2]\nOut[145]: []\n \n\n How Python Figures Out Missing Parameters: \n\n When slicing, if you leave out any parameter, Python tries to figure it out automatically. \n\n If you check the source code of  CPython , you will find a function called PySlice_GetIndicesEx() which figures out indices to a slice for any given parameters. Here is the logical equivalent code in Python. \n\n This function takes a Python object and optional parameters for slicing and returns the start, stop, step, and slice length for the requested slice. \n\n def py_slice_get_indices_ex(obj, start=None, stop=None, step=None):\n\n    length = len(obj)\n\n    if step is None:\n        step = 1\n    if step == 0:\n        raise Exception(\"Step cannot be zero.\")\n\n    if start is None:\n        start = 0 if step > 0 else length - 1\n    else:\n        if start < 0:\n            start += length\n        if start < 0:\n            start = 0 if step > 0 else -1\n        if start >= length:\n            start = length if step > 0 else length - 1\n\n    if stop is None:\n        stop = length if step > 0 else -1\n    else:\n        if stop < 0:\n            stop += length\n        if stop < 0:\n            stop = 0 if step > 0 else -1\n        if stop >= length:\n            stop = length if step > 0 else length - 1\n\n    if (step < 0 and stop >= start) or (step > 0 and start >= stop):\n        slice_length = 0\n    elif step < 0:\n        slice_length = (stop - start + 1)/(step) + 1\n    else:\n        slice_length = (stop - start - 1)/(step) + 1\n\n    return (start, stop, step, slice_length)\n \n\n This is the intelligence that is present behind slices. Since Python has an built-in function called slice, you can pass some parameters and check how smartly it calculates missing parameters. \n\n In [21]: alpha = ['a', 'b', 'c', 'd', 'e', 'f']\n\nIn [22]: s = slice(None, None, None)\n\nIn [23]: s\nOut[23]: slice(None, None, None)\n\nIn [24]: s.indices(len(alpha))\nOut[24]: (0, 6, 1)\n\nIn [25]: range(*s.indices(len(alpha)))\nOut[25]: [0, 1, 2, 3, 4, 5]\n\nIn [26]: s = slice(None, None, -1)\n\nIn [27]: range(*s.indices(len(alpha)))\nOut[27]: [5, 4, 3, 2, 1, 0]\n\nIn [28]: s = slice(None, 3, -1)\n\nIn [29]: range(*s.indices(len(alpha)))\nOut[29]: [5, 4]\n \n\n Note:  This post was originally written in my blog,  The Intelligence Behind Python Slices . \n    ", "date_posted": "2019-09-26 07:58:01Z", "upvote": "\r\n            39\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "29237560", "stack_answer_comment_id": "125358697", "comment_content": "At last, I found here some explanation on why the slicing parameters ", "user_id": "None"}]}, {"stack_answer_id": "16267103", "answer_content": "\r\n Python slicing notation: \n\n a[start:end:step]\n \n\n \n For  start  and  end , negative values are interpreted as being relative to the end of the sequence. \n Positive indices for  end  indicate the position  after  the last element to be included. \n Blank values are defaulted as follows:  [+0:-0:1] . \n Using a negative step reverses the interpretation of  start  and  end \n \n\n The notation extends to (numpy) matrices and multidimensional arrays.  For example, to slice entire columns you can use: \n\n m[::,0:2:] ## slice the first two columns\n \n\n Slices hold references, not copies, of the array elements.  If you want to make a separate copy an array, you can use  deepcopy() . \n    ", "date_posted": "2017-05-23 12:34:44Z", "upvote": "\r\n            38\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}, {"stack_answer_id": "15824717", "answer_content": "\r\n You can also use slice assignment to remove one or more elements from a list: \n\n r = [1, 'blah', 9, 8, 2, 3, 4]\n>>> r[1:4] = []\n>>> r\n[1, 2, 3, 4]\n \n    ", "date_posted": "2013-04-19 16:28:16Z", "upvote": "\r\n            34\r\n        ", "accepted": "No", "user": {"stack_user_id": "1355221", "name": "dansalmo", "reputation_score": "11.1k"}, "answer_comments": []}, {"stack_answer_id": "9827284", "answer_content": "\r\n This is just for some extra info...\nConsider the list below  \n\n >>> l=[12,23,345,456,67,7,945,467]\n \n\n Few other tricks for reversing the list: \n\n >>> l[len(l):-len(l)-1:-1]\n[467, 945, 7, 67, 456, 345, 23, 12]\n\n>>> l[:-len(l)-1:-1]\n[467, 945, 7, 67, 456, 345, 23, 12]\n\n>>> l[len(l)::-1]\n[467, 945, 7, 67, 456, 345, 23, 12]\n\n>>> l[::-1]\n[467, 945, 7, 67, 456, 345, 23, 12]\n\n>>> l[-1:-len(l)-1:-1]\n[467, 945, 7, 67, 456, 345, 23, 12]\n \n    ", "date_posted": "2019-05-08 08:35:55Z", "upvote": "\r\n            33\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": []}, {"stack_answer_id": "41548529", "answer_content": "\r\n 1. Slice Notation \n\n To make it simple, remember  slice has only one form\uff1a \n\n s[start:end:step]\n \n\n and here is how it works: \n\n \n s : an object that can be sliced \n start : first index to start iteration \n end : last index,  NOTE that  end  index will not be included in the resulted slice \n step : pick element every  step  index \n \n\n Another import thing:  all  start , end ,  step  can be omitted!  And if they are omitted, their default value will be used:  0 , len(s) , 1  accordingly. \n\n So possible variations are: \n\n # Mostly used variations\ns[start:end]\ns[start:]\ns[:end]\n\n# Step-related variations\ns[:end:step]\ns[start::step]\ns[::step]\n\n# Make a copy\ns[:]\n \n\n NOTE: If  start >= end  (considering only when  step>0 ), Python will return a empty slice  [] . \n\n 2. Pitfalls \n\n The above part explains the core features on how slice works, and it will work on most occasions. However, there can be pitfalls you should watch out, and this part explains them. \n\n Negative indexes \n\n The very first thing that confuses Python learners is that  an index can be negative! \nDon't panic:  a negative index means count backwards. \n\n For example: \n\n s[-5:]    # Start at the 5th index from the end of array,\n          # thus returning the last 5 elements.\ns[:-5]    # Start at index 0, and end until the 5th index from end of array,\n          # thus returning s[0:len(s)-5].\n \n\n Negative step \n\n Making things more confusing is that  step  can be negative too! \n\n A negative step means iterate the array backwards: from the end to start, with the end index included, and the start index excluded from the result. \n\n NOTE : when step is negative, the default value for  start  is  len(s)  (while  end  does not equal to  0 , because  s[::-1]  contains  s[0] ). For example: \n\n s[::-1]            # Reversed slice\ns[len(s)::-1]      # The same as above, reversed slice\ns[0:len(s):-1]     # Empty list\n \n\n Out of range error? \n\n Be surprised:  slice does not raise an IndexError when the index is out of range! \n\n If the index is out of range, Python will try its best to set the index to  0  or  len(s)  according to the situation. For example: \n\n s[:len(s)+5]      # The same as s[:len(s)]\ns[-len(s)-5::]    # The same as s[0:]\ns[len(s)+5::-1]   # The same as s[len(s)::-1], and the same as s[::-1]\n \n\n 3. Examples \n\n Let's finish this answer with examples, explaining everything we have discussed: \n\n # Create our array for demonstration\nIn [1]: s = [i for i in range(10)]\n\nIn [2]: s\nOut[2]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\nIn [3]: s[2:]   # From index 2 to last index\nOut[3]: [2, 3, 4, 5, 6, 7, 8, 9]\n\nIn [4]: s[:8]   # From index 0 up to index 8\nOut[4]: [0, 1, 2, 3, 4, 5, 6, 7]\n\nIn [5]: s[4:7]  # From index 4 (included) up to index 7(excluded)\nOut[5]: [4, 5, 6]\n\nIn [6]: s[:-2]  # Up to second last index (negative index)\nOut[6]: [0, 1, 2, 3, 4, 5, 6, 7]\n\nIn [7]: s[-2:]  # From second last index (negative index)\nOut[7]: [8, 9]\n\nIn [8]: s[::-1] # From last to first in reverse order (negative step)\nOut[8]: [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n\nIn [9]: s[::-2] # All odd numbers in reversed order\nOut[9]: [9, 7, 5, 3, 1]\n\nIn [11]: s[-2::-2] # All even numbers in reversed order\nOut[11]: [8, 6, 4, 2, 0]\n\nIn [12]: s[3:15]   # End is out of range, and Python will set it to len(s).\nOut[12]: [3, 4, 5, 6, 7, 8, 9]\n\nIn [14]: s[5:1]    # Start > end; return empty list\nOut[14]: []\n\nIn [15]: s[11]     # Access index 11 (greater than len(s)) will raise an IndexError\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\n<ipython-input-15-79ffc22473a3> in <module>()\n----> 1 s[11]\n\nIndexError: list index out of range\n \n    ", "date_posted": "2019-09-26 08:04:23Z", "upvote": "\r\n            30\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "20443928", "answer_content": "\r\n As a general rule, writing code with a lot of hardcoded index values leads to a readability\nand maintenance mess. For example, if you come back to the code a year later, you\u2019ll\nlook at it and wonder what you were thinking when you wrote it. The solution shown\nis simply a way of more clearly stating what your code is actually doing.\nIn general, the built-in slice() creates a slice object that can be used anywhere a slice\nis allowed. For example: \n\n >>> items = [0, 1, 2, 3, 4, 5, 6]\n>>> a = slice(2, 4)\n>>> items[2:4]\n[2, 3]\n>>> items[a]\n[2, 3]\n>>> items[a] = [10,11]\n>>> items\n[0, 1, 10, 11, 4, 5, 6]\n>>> del items[a]\n>>> items\n[0, 1, 4, 5, 6]\n \n\n If you have a slice instance s, you can get more information about it by looking at its\ns.start, s.stop, and s.step attributes, respectively. For example: \n\n \n >>> a = slice(10, 50, 2)\n>>> a.start\n10\n>>> a.stop\n50\n>>> a.step\n2\n>>>\n \n \n    ", "date_posted": "2013-12-07 16:52:45Z", "upvote": "\r\n            29\r\n        ", "accepted": "No", "user": {"stack_user_id": "3048166", "name": "Python_Dude", "reputation_score": "507"}, "answer_comments": []}, {"stack_answer_id": "42522149", "answer_content": "\r\n The previous answers don't discuss multi-dimensional array slicing which is possible using the famous  NumPy  package: \n\n Slicing can also be applied to multi-dimensional arrays. \n\n # Here, a is a NumPy array\n\n>>> a\narray([[ 1,  2,  3,  4],\n       [ 5,  6,  7,  8],\n       [ 9, 10, 11, 12]])\n>>> a[:2, 0:3:2]\narray([[1, 3],\n       [5, 7]])\n \n\n The \" :2 \" before the comma operates on the first dimension and the \" 0:3:2 \" after the comma operates on the second dimension. \n    ", "date_posted": "2019-09-26 08:08:54Z", "upvote": "\r\n            29\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "42522149", "stack_answer_comment_id": "100958827", "comment_content": "Just a friendly reminder that you cannot do this on Python ", "user_id": "None"}]}, {"stack_answer_id": "63047385", "answer_content": "\r\n The rules of slicing are as follows: \n [lower bound : upper bound : step size]\n \n I-  Convert  upper bound   and  lower bound  into common signs. \n II-  Then check if the  step size  is a  positive  or a  negative  value. \n (i)  If the  step size  is a  positive value ,  upper bound  should be  greater than   lower bound , otherwise  empty string  is printed.  For example : \n s=\"Welcome\"\ns1=s[0:3:1]\nprint(s1)\n \n The output: \n Wel\n \n However if we run the following code: \n s=\"Welcome\"\ns1=s[3:0:1]\nprint(s1)\n \n It will return an  empty string . \n (ii)  If the  step size  if a  negative value ,  upper bound  should be  lesser than   lower bound , otherwise  empty string  will be printed. For example: \n s=\"Welcome\"\ns1=s[3:0:-1]\nprint(s1)\n \n The output: \n cle\n \n But if we run the following code: \n s=\"Welcome\"\ns1=s[0:5:-1]\nprint(s1)\n \n The output will be an  empty string . \n Thus in the code: \n str = 'abcd'\nl = len(str)\nstr2 = str[l-1:0:-1]    #str[3:0:-1] \nprint(str2)\nstr2 = str[l-1:-1:-1]    #str[3:-1:-1]\nprint(str2)\n \n In the first  str2=str[l-1:0:-1] , the  upper bound  is  lesser than  the  lower bound , thus  dcb  is printed. \n However in  str2=str[l-1:-1:-1] , the  upper bound  is  not less than  the  lower bound  (upon converting  lower bound  into  negative value  which is  -1 : since  index  of last element is -1 as well as 3). \n    ", "date_posted": "2020-07-23 05:22:23Z", "upvote": "\r\n            20\r\n        ", "accepted": "No", "user": {"stack_user_id": "13737990", "name": "Anshika Singh", "reputation_score": "866"}, "answer_comments": []}, {"stack_answer_id": "47765245", "answer_content": "\r\n In my opinion, you will understand and memorize better the Python string slicing notation if you look at it the following way (read on). \n\n Let's work with the following string ... \n\n azString = \"abcdefghijklmnopqrstuvwxyz\"\n \n\n For those who don't know, you can create any substring from  azString  using the notation  azString[x:y] \n\n Coming from other programming languages, that's when the common sense gets compromised. What are x and y? \n\n I had to sit down and run several scenarios in my quest for a memorization technique that will help me remember what x and y are and help me slice strings properly at the first attempt. \n\n My conclusion is that x and y should be seen as the boundary indexes that are surrounding the strings that we want to extra. So we should see the expression as  azString[index1, index2]  or even more clearer as  azString[index_of_first_character, index_after_the_last_character] . \n\n Here is an example visualization of that ... \n\n Letters   a b c d e f g h i j ...\n         \u2191 \u2191 \u2191 \u2191 \u2191 \u2191 \u2191 \u2191 \u2191 \u2191\n             \u250a           \u250a\nIndexes  0 1 2 3 4 5 6 7 8 9 ...\n             \u250a           \u250a\ncdefgh    index1       index2\n \n\n So all you have to do is setting index1 and index2 to the values that will surround the desired substring. For instance, to get the substring \"cdefgh\", you can use  azString[2:8] , because the index on the left side of \"c\" is 2 and the one on the right size of \"h\" is 8. \n\n Remember that we are setting the boundaries. And those boundaries are the positions where you could place some brackets that will be wrapped around the substring like this ... \n\n a b  [  c d e f g h  ]  i j \n\n That trick works all the time and is easy to memorize. \n    ", "date_posted": "2020-01-08 16:12:41Z", "upvote": "\r\n            18\r\n        ", "accepted": "No", "user": {"stack_user_id": "609862", "name": "asiby", "reputation_score": "2,909"}, "answer_comments": []}, {"stack_answer_id": "57628026", "answer_content": "\r\n I personally think about it like a  for  loop: \n\n a[start:end:step]\n# for(i = start; i < end; i += step)\n \n\n Also, note that negative values for  start  and  end  are relative to the end of the list and computed in the example above by  given_index + a.shape[0] . \n    ", "date_posted": "2020-01-15 12:29:43Z", "upvote": "\r\n            18\r\n        ", "accepted": "No", "user": {"stack_user_id": "806202", "name": "Arsen Khachaturyan", "reputation_score": "7,445"}, "answer_comments": []}, {"stack_answer_id": "26442691", "answer_content": "\r\n #!/usr/bin/env python\n\ndef slicegraphical(s, lista):\n\n    if len(s) > 9:\n        print \"\"\"Enter a string of maximum 9 characters,\n    so the printig would looki nice\"\"\"\n        return 0;\n    # print \" \",\n    print '  '+'+---' * len(s) +'+'\n    print ' ',\n    for letter in s:\n        print '| {}'.format(letter),\n    print '|'\n    print \" \",; print '+---' * len(s) +'+'\n\n    print \" \",\n    for letter in range(len(s) +1):\n        print '{}  '.format(letter),\n    print \"\"\n    for letter in range(-1*(len(s)), 0):\n        print ' {}'.format(letter),\n    print ''\n    print ''\n\n\n    for triada in lista:\n        if len(triada) == 3:\n            if triada[0]==None and triada[1] == None and triada[2] == None:\n                # 000\n                print s+'[   :   :   ]' +' = ', s[triada[0]:triada[1]:triada[2]]\n            elif triada[0] == None and triada[1] == None and triada[2] != None:\n                # 001\n                print s+'[   :   :{0:2d} ]'.format(triada[2], '','') +' = ', s[triada[0]:triada[1]:triada[2]]\n            elif triada[0] == None and triada[1] != None and triada[2] == None:\n                # 010\n                print s+'[   :{0:2d} :   ]'.format(triada[1]) +' = ', s[triada[0]:triada[1]:triada[2]]\n            elif triada[0] == None and triada[1] != None and triada[2] != None:\n                # 011\n                print s+'[   :{0:2d} :{1:2d} ]'.format(triada[1], triada[2]) +' = ', s[triada[0]:triada[1]:triada[2]]\n            elif triada[0] != None and triada[1] == None and triada[2] == None:\n                # 100\n                print s+'[{0:2d} :   :   ]'.format(triada[0]) +' = ', s[triada[0]:triada[1]:triada[2]]\n            elif triada[0] != None and triada[1] == None and triada[2] != None:\n                # 101\n                print s+'[{0:2d} :   :{1:2d} ]'.format(triada[0], triada[2]) +' = ', s[triada[0]:triada[1]:triada[2]]\n            elif triada[0] != None and triada[1] != None and triada[2] == None:\n                # 110\n                print s+'[{0:2d} :{1:2d} :   ]'.format(triada[0], triada[1]) +' = ', s[triada[0]:triada[1]:triada[2]]\n            elif triada[0] != None and triada[1] != None and triada[2] != None:\n                # 111\n                print s+'[{0:2d} :{1:2d} :{2:2d} ]'.format(triada[0], triada[1], triada[2]) +' = ', s[triada[0]:triada[1]:triada[2]]\n\n        elif len(triada) == 2:\n            if triada[0] == None and triada[1] == None:\n                # 00\n                print s+'[   :   ]    ' + ' = ', s[triada[0]:triada[1]]\n            elif triada[0] == None and triada[1] != None:\n                # 01\n                print s+'[   :{0:2d} ]    '.format(triada[1]) + ' = ', s[triada[0]:triada[1]]\n            elif triada[0] != None and triada[1] == None:\n                # 10\n                print s+'[{0:2d} :   ]    '.format(triada[0]) + ' = ', s[triada[0]:triada[1]]\n            elif triada[0] != None and triada[1] != None:\n                # 11\n                print s+'[{0:2d} :{1:2d} ]    '.format(triada[0],triada[1]) + ' = ', s[triada[0]:triada[1]]\n\n        elif len(triada) == 1:\n            print s+'[{0:2d} ]        '.format(triada[0]) + ' = ', s[triada[0]]\n\n\nif __name__ == '__main__':\n    # Change \"s\" to what ever string you like, make it 9 characters for\n    # better representation.\n    s = 'COMPUTERS'\n\n    # add to this list different lists to experement with indexes\n    # to represent ex. s[::], use s[None, None,None], otherwise you get an error\n    # for s[2:] use s[2:None]\n\n    lista = [[4,7],[2,5,2],[-5,1,-1],[4],[-4,-6,-1], [2,-3,1],[2,-3,-1], [None,None,-1],[-5,None],[-5,0,-1],[-5,None,-1],[-1,1,-2]]\n\n    slicegraphical(s, lista)\n \n\n You can run this script and experiment with it, below is some samples that I got from the script. \n\n   +---+---+---+---+---+---+---+---+---+\n  | C | O | M | P | U | T | E | R | S |\n  +---+---+---+---+---+---+---+---+---+\n  0   1   2   3   4   5   6   7   8   9   \n -9  -8  -7  -6  -5  -4  -3  -2  -1 \n\nCOMPUTERS[ 4 : 7 ]     =  UTE\nCOMPUTERS[ 2 : 5 : 2 ] =  MU\nCOMPUTERS[-5 : 1 :-1 ] =  UPM\nCOMPUTERS[ 4 ]         =  U\nCOMPUTERS[-4 :-6 :-1 ] =  TU\nCOMPUTERS[ 2 :-3 : 1 ] =  MPUT\nCOMPUTERS[ 2 :-3 :-1 ] =  \nCOMPUTERS[   :   :-1 ] =  SRETUPMOC\nCOMPUTERS[-5 :   ]     =  UTERS\nCOMPUTERS[-5 : 0 :-1 ] =  UPMO\nCOMPUTERS[-5 :   :-1 ] =  UPMOC\nCOMPUTERS[-1 : 1 :-2 ] =  SEUM\n[Finished in 0.9s]\n \n\n When using a negative step, notice that the answer is shifted to the right by 1. \n    ", "date_posted": "2014-10-18 17:40:45Z", "upvote": "\r\n            17\r\n        ", "accepted": "No", "user": {"stack_user_id": "1471004", "name": "mahmoh", "reputation_score": "792"}, "answer_comments": []}, {"stack_answer_id": "37455246", "answer_content": "\r\n My brain seems happy to accept that  lst[start:end]  contains the  start -th item. I might even say that it is a 'natural assumption'. \n\n But occasionally a doubt creeps in and my brain asks for reassurance that it does not contain the  end -th element. \n\n In these moments I rely on this simple theorem: \n\n for any n,    lst = lst[:n] + lst[n:]\n \n\n This pretty property tells me that  lst[start:end]  does not contain the  end -th item because it is in  lst[end:] . \n\n Note that this theorem is true for any  n  at all. For example, you can check that \n\n lst = range(10)\nlst[:-42] + lst[-42:] == lst\n \n\n returns  True . \n    ", "date_posted": "2016-05-26 08:16:54Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "1243435", "name": "Robert", "reputation_score": "1,402"}, "answer_comments": []}, {"stack_answer_id": "46040689", "answer_content": "\r\n In Python, the most basic form for slicing is the following: \n\n l[start:end]\n \n\n where  l  is some collection,  start  is an inclusive index, and  end  is an exclusive index. \n\n In [1]: l = list(range(10))\n\nIn [2]: l[:5] # First five elements\nOut[2]: [0, 1, 2, 3, 4]\n\nIn [3]: l[-5:] # Last five elements\nOut[3]: [5, 6, 7, 8, 9]\n \n\n When slicing from the start, you can omit the zero index, and when slicing to the end, you can omit the final index since it is redundant, so do not be verbose: \n\n In [5]: l[:3] == l[0:3]\nOut[5]: True\n\nIn [6]: l[7:] == l[7:len(l)]\nOut[6]: True\n \n\n Negative integers are useful when doing offsets relative to the end of a collection: \n\n In [7]: l[:-1] # Include all elements but the last one\nOut[7]: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n\nIn [8]: l[-3:] # Take the last three elements\nOut[8]: [7, 8, 9]\n \n\n It is possible to provide indices that are out of bounds when slicing such as: \n\n In [9]: l[:20] # 20 is out of index bounds, and l[20] will raise an IndexError exception\nOut[9]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\nIn [11]: l[-20:] # -20 is out of index bounds, and l[-20] will raise an IndexError exception\nOut[11]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n \n\n Keep in mind that the result of slicing a collection is a whole new collection. In addition, when using slice notation in assignments, the length of the slice assignments do not need to be the same. The values before and after the assigned slice will be kept, and the collection will shrink or grow to contain the new values: \n\n In [16]: l[2:6] = list('abc') # Assigning fewer elements than the ones contained in the sliced collection l[2:6]\n\nIn [17]: l\nOut[17]: [0, 1, 'a', 'b', 'c', 6, 7, 8, 9]\n\nIn [18]: l[2:5] = list('hello') # Assigning more elements than the ones contained in the sliced collection l [2:5]\n\nIn [19]: l\nOut[19]: [0, 1, 'h', 'e', 'l', 'l', 'o', 6, 7, 8, 9]\n \n\n If you omit the start and end index, you will make a copy of the collection: \n\n In [14]: l_copy = l[:]\n\nIn [15]: l == l_copy and l is not l_copy\nOut[15]: True\n \n\n If the start and end indexes are omitted when performing an assignment operation, the entire content of the collection will be replaced with a copy of what is referenced: \n\n In [20]: l[:] = list('hello...')\n\nIn [21]: l\nOut[21]: ['h', 'e', 'l', 'l', 'o', '.', '.', '.']\n \n\n Besides basic slicing, it is also possible to apply the following notation: \n\n l[start:end:step]\n \n\n where  l  is a collection,  start  is an inclusive index,  end  is an exclusive index, and  step  is a stride that can be used to take every  nth  item in  l . \n\n In [22]: l = list(range(10))\n\nIn [23]: l[::2] # Take the elements which indexes are even\nOut[23]: [0, 2, 4, 6, 8]\n\nIn [24]: l[1::2] # Take the elements which indexes are odd\nOut[24]: [1, 3, 5, 7, 9]\n \n\n Using  step  provides a useful trick to reverse a collection in Python: \n\n In [25]: l[::-1]\nOut[25]: [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n \n\n It is also possible to use negative integers for  step  as the following example: \n\n In[28]:  l[::-2]\nOut[28]: [9, 7, 5, 3, 1]\n \n\n However, using a negative value for  step  could become very confusing. Moreover, in order to be  Pythonic , you should avoid using  start ,  end , and  step  in a single slice. In case this is required, consider doing this in two assignments (one to slice, and the other to stride). \n\n In [29]: l = l[::2] # This step is for striding\n\nIn [30]: l\nOut[30]: [0, 2, 4, 6, 8]\n\nIn [31]: l = l[1:-1] # This step is for slicing\n\nIn [32]: l\nOut[32]: [2, 4, 6]\n \n    ", "date_posted": "2019-09-26 08:16:53Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "49647978", "answer_content": "\r\n I want to add one  Hello, World!  example that explains the basics of slices for the very beginners. It helped me a lot. \n\n Let's have a list with six values  ['P', 'Y', 'T', 'H', 'O', 'N'] : \n\n +---+---+---+---+---+---+\n| P | Y | T | H | O | N |\n+---+---+---+---+---+---+\n  0   1   2   3   4   5\n \n\n Now the simplest slices of that list are its sublists. The notation is  [<index>:<index>]  and the key is to read it like this: \n\n [ start cutting before this index : end cutting before this index ]\n \n\n Now if you make a slice  [2:5]  of the list above, this will happen: \n\n         |           |\n+---+---|---+---+---|---+\n| P | Y | T | H | O | N |\n+---+---|---+---+---|---+\n  0   1 | 2   3   4 | 5\n \n\n You made a cut  before  the element with index  2  and another cut  before  the element with index  5 . So the result will be a slice between those two cuts, a list  ['T', 'H', 'O'] . \n    ", "date_posted": "2019-09-26 08:23:54Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "46614773", "answer_content": "\r\n Most of the previous answers clears up questions about slice notation. \n\n The extended indexing syntax used for slicing is  aList[start:stop:step] , and basic examples are: \n\n : \n\n More slicing examples:  15 Extended Slices \n    ", "date_posted": "2019-09-26 08:19:02Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "45370737", "answer_content": "\r\n The below is the example of an index of a string: \n\n  +---+---+---+---+---+\n | H | e | l | p | A |\n +---+---+---+---+---+\n 0   1   2   3   4   5\n-5  -4  -3  -2  -1\n\nstr=\"Name string\"\n \n\n Slicing example: [start:end:step] \n\n str[start:end] # Items start through end-1\nstr[start:]    # Items start through the rest of the array\nstr[:end]      # Items from the beginning through end-1\nstr[:]         # A copy of the whole array\n \n\n Below is the example usage: \n\n print str[0] = N\nprint str[0:2] = Na\nprint str[0:7] = Name st\nprint str[0:7:2] = Nm t\nprint str[0:-1:2] = Nm ti\n \n    ", "date_posted": "2019-09-26 08:10:54Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "47880987", "answer_content": "\r\n If you feel negative indices in slicing is confusing, here's a very easy way to think about it: just replace the negative index with  len - index . So for example, replace -3 with  len(list) - 3 . \n\n The best way to illustrate what slicing does internally is just show it in code that implements this operation: \n\n def slice(list, start = None, end = None, step = 1):\n  # Take care of missing start/end parameters\n  start = 0 if start is None else start\n  end = len(list) if end is None else end\n\n  # Take care of negative start/end parameters\n  start = len(list) + start if start < 0 else start\n  end = len(list) + end if end < 0 else end\n\n  # Now just execute a for-loop with start, end and step\n  return [list[i] for i in range(start, end, step)]\n \n    ", "date_posted": "2019-09-26 08:22:50Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "51479594", "answer_content": "\r\n The basic slicing technique is to define the starting point, the stopping point, and the step size\u2014also known as stride. \n First, we will create a list of values to use in our slicing. \n Create two lists to slice. The first is a numeric list from 1 to 9 (List A). The second is also a numeric list, from 0 to 9 (List B): \n A = list(range(1, 10, 1)) # Start, stop, and step\nB = list(range(9))\n\nprint(\"This is List A:\", A)\nprint(\"This is List B:\", B)\n \n Index the number 3 from A and the number 6 from B. \n print(A[2])\nprint(B[6])\n \n Basic Slicing \n Extended indexing syntax used for slicing is  aList[start:stop:step] . The start argument and the step argument both default to  None \u2014the only required argument is stop. Did you notice this is similar to how range was used to define lists A and B? This is because the slice object represents the set of indices specified by  range(start, stop, step) . \n As you can see, defining only stop returns one element. Since the start defaults to none, this translates into retrieving only one element. \n It is important to note, the first element is index 0,  not  index 1. This is why we are using 2 lists for this exercise. List A's elements are numbered according to the ordinal position (the first element is 1, the second element is 2, etc.) while List B's elements are the numbers that would be used to index them ( [0]  for the first element, 0, etc.). \n With extended indexing syntax, we retrieve a range of values. For example, all values are retrieved with a colon. \n A[:]\n \n To retrieve a subset of elements, the start and stop positions need to be defined. \n Given the pattern  aList[start:stop] , retrieve the first two elements from List A. \n    ", "date_posted": "2022-04-30 17:09:16Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "241211", "name": "Michael", "reputation_score": "7,466"}, "answer_comments": []}], "user": {"stack_user_id": "24039", "name": "Simon", "reputation_score": "76.1k"}, "question_comments": []},
{"stack_question_id": "1373164", "question_title": "How do I create variable variables?", "question_content": "\r\n                How do I create the equivalent of PHP variable variable names in Python?\nI hear this is a bad idea, in general, though. Is that true?\n\nIf you are just trying to look up an existing variable by its ...\r\n", "question_url": "/questions/1373164/how-do-i-create-variable-variables", "date_posted": "Sep 3, 2009 at 12:37", "upvote": "5", "view": "2", "tags": ["python", "variable-variables"], "answers_count": "1", "answers": [{"stack_answer_id": "1373185", "answer_content": "\r\n You can use  dictionaries  to accomplish this. Dictionaries are stores of keys and values. \n >>> dct = {'x': 1, 'y': 2, 'z': 3}\n>>> dct\n{'y': 2, 'x': 1, 'z': 3}\n>>> dct[\"y\"]\n2\n \n You can use variable key names to achieve the effect of variable variables without the security risk. \n >>> x = \"spam\"\n>>> z = {x: \"eggs\"}\n>>> z[\"spam\"]\n'eggs'\n \n For cases where you're thinking of doing something like \n var1 = 'foo'\nvar2 = 'bar'\nvar3 = 'baz'\n...\n \n a  list  may be more appropriate than a dict. A list represents an ordered sequence of objects, with integer indices: \n lst = ['foo', 'bar', 'baz']\nprint(lst[1])           # prints bar, because indices start at 0\nlst.append('potatoes')  # lst is now ['foo', 'bar', 'baz', 'potatoes']\n \n For ordered sequences, lists are more convenient than dicts with integer keys, because lists support iteration in index order,  slicing ,  append , and other operations that would require awkward key management with a dict. \n    ", "date_posted": "2022-06-04 20:15:44Z", "upvote": "\r\n            404\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "4518341", "name": "wjandrea", "reputation_score": "24.1k"}, "answer_comments": []}, {"stack_answer_id": "1373198", "answer_content": "\r\n Use the built-in  getattr  function to get an attribute on an object by name.  Modify the name as needed. \n\n obj.spam = 'eggs'\nname = 'spam'\ngetattr(obj, name)  # returns 'eggs'\n \n    ", "date_posted": "2016-04-21 15:23:52Z", "upvote": "\r\n            109\r\n        ", "accepted": "No", "user": {"stack_user_id": "400617", "name": "davidism", "reputation_score": "112k"}, "answer_comments": []}, {"stack_answer_id": "1373201", "answer_content": "\r\n It's not a good idea. If you are accessing a global variable you can use  globals() . \n\n >>> a = 10\n>>> globals()['a']\n10\n \n\n If you want to access a variable in the local scope you can use  locals() , but you cannot assign values to the returned dict. \n\n A better solution  is to use  getattr  or store your variables in a dictionary and then access them by name. \n    ", "date_posted": "2017-04-24 02:03:14Z", "upvote": "\r\n            86\r\n        ", "accepted": "No", "user": {"stack_user_id": "2470818", "name": "vallentin", "reputation_score": "21.7k"}, "answer_comments": [{"stack_answer_id": "1373201", "stack_answer_comment_id": "107489989", "comment_content": " works just fine for me in Python 3.7.6; so I'm not sure what you mean when you say you cannot assign values through it.", "user_id": "None"}, {"stack_answer_id": "1373201", "stack_answer_comment_id": "107816343", "comment_content": "Given ", "user_id": "None"}, {"stack_answer_id": "1373201", "stack_answer_comment_id": "120374898", "comment_content": "The documentation of ", "user_id": "None"}, {"stack_answer_id": "1373201", "stack_answer_comment_id": "123583256", "comment_content": "@JimDennis`locals()`` provides a dictionary ", "user_id": "None"}, {"stack_answer_id": "1373201", "stack_answer_comment_id": "124099678", "comment_content": "The reason it doesn't work, at least on CPython, is that CPython allocates a fixed size array for locals, and the size of said array is determined when the function is defined, not when its run, and can't be changed (access to true locals doesn't even use the name; the name is replaced with the index into the array at function compile time). ", "user_id": "None"}]}, {"stack_answer_id": "38972761", "answer_content": "\r\n New coders sometimes write code like this: \n\n my_calculator.button_0 = tkinter.Button(root, text=0)\nmy_calculator.button_1 = tkinter.Button(root, text=1)\nmy_calculator.button_2 = tkinter.Button(root, text=2)\n...\n \n\n The coder is then left with a pile of named variables, with a coding effort of O( m  *  n ), where  m  is the number of named variables and  n  is the number of times that group of variables needs to be accessed (including creation). The more astute beginner observes that the only difference in each of those lines is a number that changes based on a rule, and decides to use a loop. However, they get stuck on how to dynamically create those variable names, and may try something like this: \n\n for i in range(10):\n    my_calculator.('button_%d' % i) = tkinter.Button(root, text=i)\n \n\n They soon find that this does not work. \n\n If the program requires arbitrary variable \"names,\" a dictionary is the best choice, as explained in other answers. However, if you're simply trying to create many variables and you don't mind referring to them with a sequence of integers, you're probably looking for a  list . This is particularly true if your data are homogeneous, such as daily temperature readings, weekly quiz scores, or a grid of graphical widgets. \n\n This can be assembled as follows: \n\n my_calculator.buttons = []\nfor i in range(10):\n    my_calculator.buttons.append(tkinter.Button(root, text=i))\n \n\n This  list  can also be created in one line with a comprehension: \n\n my_calculator.buttons = [tkinter.Button(root, text=i) for i in range(10)]\n \n\n The result in either case is a populated  list , with the first element accessed with  my_calculator.buttons[0] , the next with  my_calculator.buttons[1] , and so on. The \"base\" variable name becomes the name of the  list  and the varying identifier is used to access it. \n\n Finally, don't forget other data structures, such as the  set  - this is similar to a dictionary, except that each \"name\" doesn't have a value attached to it. If you simply need a \"bag\" of objects, this can be a great choice. Instead of something like this: \n\n keyword_1 = 'apple'\nkeyword_2 = 'banana'\n\nif query == keyword_1 or query == keyword_2:\n    print('Match.')\n \n\n You will have this: \n\n keywords = {'apple', 'banana'}\nif query in keywords:\n    print('Match.')\n \n\n Use a  list  for a sequence of similar objects, a  set  for an arbitrarily-ordered bag of objects, or a  dict  for a bag of names with associated values. \n    ", "date_posted": "2016-08-16 10:41:07Z", "upvote": "\r\n            67\r\n        ", "accepted": "No", "user": {"stack_user_id": "2617068", "name": "TigerhawkT3", "reputation_score": "47.3k"}, "answer_comments": []}, {"stack_answer_id": "1373192", "answer_content": "\r\n Whenever you want to use variable variables, it's probably better to use a dictionary. So instead of writing \n\n $foo = \"bar\"\n$$foo = \"baz\"\n \n\n you write  \n\n mydict = {}\nfoo = \"bar\"\nmydict[foo] = \"baz\"\n \n\n This way you won't accidentally overwrite previously existing variables (which is the security aspect) and you can have different \"namespaces\". \n    ", "date_posted": "2009-09-03 12:42:00Z", "upvote": "\r\n            43\r\n        ", "accepted": "No", "user": {"stack_user_id": "149392", "name": "sepp2k", "reputation_score": "356k"}, "answer_comments": []}, {"stack_answer_id": "53503041", "answer_content": "\r\n Use  globals()  (disclaimer: this is a bad practice, but is the most straightforward answer to your question, please use other data structure as in the accepted answer). \n You can actually assign variables to global scope dynamically, for instance, if you want 10 variables that can be accessed on a global scope  i_1 ,  i_2  ...  i_10 : \n for i in range(10):\n    globals()['i_{}'.format(i)] = 'a'\n \n This will assign 'a' to all of these 10 variables, of course you can change the value dynamically as well. All of these variables can be accessed now like other globally declared variable: \n >>> i_5\n'a'\n \n    ", "date_posted": "2022-08-07 18:16:34Z", "upvote": "\r\n            22\r\n        ", "accepted": "No", "user": {"stack_user_id": "8046232", "name": "Rocky Li", "reputation_score": "5,197"}, "answer_comments": [{"stack_answer_id": "53503041", "stack_answer_comment_id": "129164890", "comment_content": "Thanks for putting it in a minimal yet well explained form.", "user_id": "None"}]}, {"stack_answer_id": "37971967", "answer_content": "\r\n Instead of a dictionary you can also use  namedtuple  from the collections module, which makes access easier. \n\n For example: \n\n # using dictionary\nvariables = {}\nvariables[\"first\"] = 34\nvariables[\"second\"] = 45\nprint(variables[\"first\"], variables[\"second\"])\n\n# using namedtuple\nVariables = namedtuple('Variables', ['first', 'second'])\nvars = Variables(34, 45)\nprint(vars.first, vars.second)\n \n    ", "date_posted": "2019-05-13 14:39:12Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "37971967", "stack_answer_comment_id": "113874390", "comment_content": "Keep in mind ", "user_id": "None"}]}, {"stack_answer_id": "46269502", "answer_content": "\r\n The  SimpleNamespace  class could be used to create new attributes with  setattr , or subclass  SimpleNamespace  and create your own function to add new attribute names (variables).  \n\n from types import SimpleNamespace\n\nvariables = {\"b\":\"B\",\"c\":\"C\"}\na = SimpleNamespace(**variables)\nsetattr(a,\"g\",\"G\")\na.g = \"G+\"\nsomething = a.a\n \n    ", "date_posted": "2019-05-24 13:22:33Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "7212665", "name": "Demi-Lune", "reputation_score": "1,738"}, "answer_comments": []}, {"stack_answer_id": "46897025", "answer_content": "\r\n If you don't want to use any object, you can still use  setattr()  inside your current module: \n\n import sys\ncurrent_module = module = sys.modules[__name__]  # i.e the \"file\" where your code is written\nsetattr(current_module, 'variable_name', 15)  # 15 is the value you assign to the var\nprint(variable_name)  # >>> 15, created from a string\n \n    ", "date_posted": "2017-10-23 19:24:10Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "5823489", "name": "Guillaume Lebreton", "reputation_score": "2,178"}, "answer_comments": [{"stack_answer_id": "46897025", "stack_answer_comment_id": "84051166", "comment_content": "This does not work with ", "user_id": "None"}, {"stack_answer_id": "46897025", "stack_answer_comment_id": "84068764", "comment_content": " can do this", "user_id": "None"}]}, {"stack_answer_id": "37725729", "answer_content": "\r\n You have to use  globals()  built in method   to achieve that behaviour: \n def var_of_var(k, v):\n    globals()[k] = v\n\nprint variable_name # NameError: name 'variable_name' is not defined\nsome_name = 'variable_name'\nglobals()[some_name] = 123\nprint(variable_name) # 123\n\nsome_name = 'variable_name2'\nvar_of_var(some_name, 456)\nprint(variable_name2) # 456\n \n    ", "date_posted": "2020-10-17 07:06:59Z", "upvote": "\r\n            10\r\n        ", "accepted": "No", "user": {"stack_user_id": "2067976", "name": "Andriy Ivaneyko", "reputation_score": "18.9k"}, "answer_comments": []}, {"stack_answer_id": "40384282", "answer_content": "\r\n I'm am answering the question:  How to get the value of a variable given its name in a string? \nwhich is closed as a duplicate with a link to this question.  \n\n If the variables in question are part of an object (part of a class for example) then some useful functions to achieve exactly that are  hasattr ,  getattr , and  setattr .  \n\n So for example you can have: \n\n class Variables(object):\n    def __init__(self):\n        self.foo = \"initial_variable\"\n    def create_new_var(self,name,value):\n        setattr(self,name,value)\n    def get_var(self,name):\n        if hasattr(self,name):\n            return getattr(self,name)\n        else:\n            raise(\"Class does not have a variable named: \"+name)\n \n\n Then you can do: \n\n v = Variables()\nv.get_var(\"foo\")\n \n\n \n   \"initial_variable\" \n \n\n v.create_new_var(v.foo,\"is actually not initial\")\nv.initial_variable\n \n\n \n   \"is actually not initial\" \n \n    ", "date_posted": "2017-05-23 12:10:47Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}, {"stack_answer_id": "65673959", "answer_content": "\r\n # Python 3.8.2 (default, Feb 26 2020, 02:56:10)\n \n Variable variables in Python \n \"\"\"\n<?php\n$a = 'hello';\n$e = 'wow'\n?>\n<?php\n$$a = 'world';\n?>\n<?php\necho \"$a ${$a}\\n\";\necho \"$a ${$a[1]}\\n\";\n?>\n<?php\necho \"$a $hello\";\n?>\n\"\"\"\n\na = 'hello'  #<?php $a = 'hello'; ?>\ne = 'wow'   #<?php $e = 'wow'; ?>\nvars()[a] = 'world' #<?php $$a = 'world'; ?>\nprint(a, vars()[a]) #<?php echo \"$a ${$a}\\n\"; ?>\nprint(a, vars()[vars()['a'][1]]) #<?php echo \"$a ${$a[1]}\\n\"; ?>\nprint(a, hello) #<?php echo \"$a $hello\"; ?>\n \n Output: \n hello world\nhello wow\nhello world\n \n \n Using globals(), locals(), or vars() will produce the same results \n # Python 3.8.2 (default, Feb 26 2020, 02:56:10)\n\n#<?php $a = 'hello'; ?>\n#<?php $e = 'wow'; ?>\n#<?php $$a = 'world'; ?>\n#<?php echo \"$a ${$a}\\n\"; ?>\n#<?php echo \"$a ${$a[1]}\\n\"; ?>\n#<?php echo \"$a $hello\"; ?>\n\nprint('locals():\\n')\na = 'hello'\ne = 'wow'\nlocals()[a] = 'world'\nprint(a, locals()[a])\nprint(a, locals()[locals()['a'][1]])\nprint(a, hello)\n\nprint('\\n\\nglobals():\\n')\na = 'hello'\ne = 'wow'\nglobals()[a] = 'world'\nprint(a, globals()[a])\nprint(a, globals()[globals()['a'][1]])\nprint(a, hello)\n \n Output: \n locals():\n\nhello world\nhello wow\nhello world\n\n\nglobals():\n\nhello world\nhello wow\nhello world\n \n \n Bonus (creating variables from strings) \n # Python 2.7.16 (default, Jul 13 2019, 16:01:51)\n# [GCC 8.3.0] on linux2\n \n Creating variables and unpacking tuple: \n g = globals()\nlistB = []\nfor i in range(10):\n    g[\"num%s\" % i] = i ** 10\n    listB.append(\"num{0}\".format(i))\n\ndef printNum():\n    print \"Printing num0 to num9:\"\n    for i in range(10):\n        print \"num%s = \" % i, \n        print g[\"num%s\" % i]\n\nprintNum()\n\nlistA = []\nfor i in range(10):\n    listA.append(i)\n\nlistA = tuple(listA)\nprint listA, '\"Tuple to unpack\"'\n\nlistB = str(str(listB).strip(\"[]\").replace(\"'\", \"\") + \" = listA\")\n\nprint listB\n\nexec listB\n\nprintNum()\n \n Output: \n Printing num0 to num9:\nnum0 =  0\nnum1 =  1\nnum2 =  1024\nnum3 =  59049\nnum4 =  1048576\nnum5 =  9765625\nnum6 =  60466176\nnum7 =  282475249\nnum8 =  1073741824\nnum9 =  3486784401\n(0, 1, 2, 3, 4, 5, 6, 7, 8, 9) \"Tuple to unpack\"\nnum0, num1, num2, num3, num4, num5, num6, num7, num8, num9 = listA\nPrinting num0 to num9:\nnum0 =  0\nnum1 =  1\nnum2 =  2\nnum3 =  3\nnum4 =  4\nnum5 =  5\nnum6 =  6\nnum7 =  7\nnum8 =  8\nnum9 =  9\n \n    ", "date_posted": "2021-03-09 16:18:44Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "14916988", "name": "mOmOney", "reputation_score": "175"}, "answer_comments": []}, {"stack_answer_id": "59333920", "answer_content": "\r\n I have tried both in python 3.7.3, you can use either globals() or vars() \n\n >>> food #Error\n>>> milkshake #Error\n>>> food=\"bread\"\n>>> drink=\"milkshake\"\n>>> globals()[food] = \"strawberry flavor\"\n>>> vars()[drink] = \"chocolate flavor\"\n>>> bread\n'strawberry flavor'\n>>> milkshake\n'chocolate flavor'\n>>> globals()[drink]\n'chocolate flavor'\n>>> vars()[food]\n'strawberry flavor'\n \n\n \n\n Reference: \n https://www.daniweb.com/programming/software-development/threads/111526/setting-a-string-as-a-variable-name#post548936 \n    ", "date_posted": "2019-12-14 09:39:02Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "7069108", "name": "Hzzkygcs", "reputation_score": "1,091"}, "answer_comments": []}, {"stack_answer_id": "37725113", "answer_content": "\r\n The consensus is to use a dictionary for this - see the other answers. This is a good idea for most cases, however, there are many aspects arising from this: \n\n \n you'll yourself be responsible for this dictionary, including garbage collection (of in-dict variables) etc. \n there's either no locality or globality for variable variables, it depends on the globality of the dictionary \n if you want to rename a variable name, you'll have to do it manually \n however, you are much more flexible, e.g. \n\n \n you can decide to overwrite existing variables or  ... \n ... choose to implement const variables \n to raise an exception on overwriting for different types \n etc. \n \n \n\n That said, I've implemented a  variable variables manager -class which provides some of the above ideas. It works for python 2 and 3. \n\n You'd use  the class  like this: \n\n from variableVariablesManager import VariableVariablesManager\n\nmyVars = VariableVariablesManager()\nmyVars['test'] = 25\nprint(myVars['test'])\n\n# define a const variable\nmyVars.defineConstVariable('myconst', 13)\ntry:\n    myVars['myconst'] = 14 # <- this raises an error, since 'myconst' must not be changed\n    print(\"not allowed\")\nexcept AttributeError as e:\n    pass\n\n# rename a variable\nmyVars.renameVariable('myconst', 'myconstOther')\n\n# preserve locality\ndef testLocalVar():\n    myVars = VariableVariablesManager()\n    myVars['test'] = 13\n    print(\"inside function myVars['test']:\", myVars['test'])\ntestLocalVar()\nprint(\"outside function myVars['test']:\", myVars['test'])\n\n# define a global variable\nmyVars.defineGlobalVariable('globalVar', 12)\ndef testGlobalVar():\n    myVars = VariableVariablesManager()\n    print(\"inside function myVars['globalVar']:\", myVars['globalVar'])\n    myVars['globalVar'] = 13\n    print(\"inside function myVars['globalVar'] (having been changed):\", myVars['globalVar'])\ntestGlobalVar()\nprint(\"outside function myVars['globalVar']:\", myVars['globalVar'])\n \n\n If you wish to allow overwriting of variables with the same type only: \n\n myVars = VariableVariablesManager(enforceSameTypeOnOverride = True)\nmyVars['test'] = 25\nmyVars['test'] = \"Cat\" # <- raises Exception (different type on overwriting)\n \n    ", "date_posted": "2016-06-09 12:10:59Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "1150303", "name": "DomTomCat", "reputation_score": "7,753"}, "answer_comments": []}, {"stack_answer_id": "45643867", "answer_content": "\r\n Any set of variables can also be wrapped up in a class. \n\"Variable\" variables may be added to the class instance during runtime by directly accessing the built-in dictionary through __dict__ attribute.  \n\n The following code defines Variables class, which adds variables (in this case attributes) to its instance during the construction. Variable names are taken from a specified list (which, for example, could have been generated by program code): \n\n # some list of variable names\nL = ['a', 'b', 'c']\n\nclass Variables:\n    def __init__(self, L):\n        for item in L:\n            self.__dict__[item] = 100\n\nv = Variables(L)\nprint(v.a, v.b, v.c)\n#will produce 100 100 100\n \n    ", "date_posted": "2017-08-11 21:13:57Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "8418961", "name": "ru13r", "reputation_score": "174"}, "answer_comments": []}, {"stack_answer_id": "65963716", "answer_content": "\r\n It should be extremely risky...\nbut you can use exec(): \n a = 'b=5'\nexec(a)\nc = b*2\nprint (c)\n \n Result:\n10 \n    ", "date_posted": "2021-01-30 01:15:36Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "5832844", "name": "Ruben Medrano", "reputation_score": "141"}, "answer_comments": [{"stack_answer_id": "65963716", "stack_answer_comment_id": "122682749", "comment_content": "This won't work inside a function. It's essentially equivalent to the safer ", "user_id": "None"}, {"stack_answer_id": "65963716", "stack_answer_comment_id": "127047992", "comment_content": "@benrg Do you know how to get around Rubens failed suggestion because I'm stuck with the same situation? I have a file containing a long list of variable assignments as a collective string. I need to turn them into python assignments but eval() and exec() both fails.", "user_id": "None"}]}, {"stack_answer_id": "71715887", "answer_content": "\r\n The  setattr()  method sets the value of the specified attribute of the specified object. \n Syntax goes like this \u2013 \n setattr(object, name, value)\nExample \u2013\n\nsetattr(self,id,123)\n \n which is equivalent to  self.id = 123 \n As you might have observed, setattr() expects an object to be passed along with the value to generate/modify a new attribute. \n We can use setattr() with a workaround to be able to use within modules. Here\u2019 how \u2013 \n import sys\nx = \"pikachu\"\nvalue = 46\nthismodule = sys.modules[__name__]\nsetattr(thismodule, x, value)\nprint(pikachu)\n \n    ", "date_posted": "2022-04-02 08:12:48Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "14399724", "name": "kannappan", "reputation_score": "199"}, "answer_comments": []}], "user": {"stack_user_id": null, "name": null, "reputation_score": 0}, "question_comments": [{"stack_question_id": "1373164", "stack_question_comment_id": "1212436", "comment_content": "it's the maintainance and debugging aspects that cause the horror. Imagine trying to find out where variable 'foo' changed when there's no place in your code where you actually change 'foo'. Imagine further that it's someone else's code that you have to maintain... OK, you can go to your happy place now.", "user_id": "None"}, {"stack_question_id": "1373164", "stack_question_comment_id": "43554197", "comment_content": "A further pitfall that hasn't been mentioned so far is if such a dynamically-created variable has the same name as a variable used in your logic. You essentially open up your software as a hostage to the input it is given.", "user_id": "None"}, {"stack_question_id": "1373164", "stack_question_comment_id": "107490205", "comment_content": "You can modify your global and local variables by accessing the underlying dictionaries for them; it's a horrible idea from a maintenance perspective ... but it can be done via ", "user_id": "None"}, {"stack_question_id": "1373164", "stack_question_comment_id": "109448744", "comment_content": "@JimDennis actually, no it can't. Modifications to the dict returned by ", "user_id": "None"}, {"stack_question_id": "1373164", "stack_question_comment_id": "109570795", "comment_content": "@juanpa.arrivillaga: I had tried testing this in an IPython shell, but did so at the top level (where locals() behaves like globsls()).  Redoing that test within a nested code (within the definition of a function) does show that I can't modify locals() from within that.  As you say, the help for locals (3.7.6) does warn: ", "user_id": "None"}]},
{"stack_question_id": "23294658", "question_title": "Asking the user for input until they give a valid response", "question_content": "\r\n                I am writing a program that accepts user input.\n#note: Python 2.7 users should use `raw_input`, the equivalent of 3.X's `input`\nage = int(input(\"Please enter your age: \"))\nif age >= 18: \n ...\r\n", "question_url": "/questions/23294658/asking-the-user-for-input-until-they-give-a-valid-response", "date_posted": null, "upvote": "7", "view": "8", "tags": ["python", "validation", "input"], "answers_count": "2", "answers": [{"stack_answer_id": "23294659", "answer_content": "\r\n The simplest way to accomplish this is to put the  input  method in a while loop. Use  continue  when you get bad input, and  break  out of the loop when you're satisfied. \n\n When Your Input Might Raise an Exception \n\n Use  try  and  except  to detect when the user enters data that can't be parsed. \n\n while True:\n    try:\n        # Note: Python 2.x users should use raw_input, the equivalent of 3.x's input\n        age = int(input(\"Please enter your age: \"))\n    except ValueError:\n        print(\"Sorry, I didn't understand that.\")\n        #better try again... Return to the start of the loop\n        continue\n    else:\n        #age was successfully parsed!\n        #we're ready to exit the loop.\n        break\nif age >= 18: \n    print(\"You are able to vote in the United States!\")\nelse:\n    print(\"You are not able to vote in the United States.\")\n \n\n Implementing Your Own Validation Rules \n\n If you want to reject values that Python can successfully parse, you can add your own validation logic. \n\n while True:\n    data = input(\"Please enter a loud message (must be all caps): \")\n    if not data.isupper():\n        print(\"Sorry, your response was not loud enough.\")\n        continue\n    else:\n        #we're happy with the value given.\n        #we're ready to exit the loop.\n        break\n\nwhile True:\n    data = input(\"Pick an answer from A to D:\")\n    if data.lower() not in ('a', 'b', 'c', 'd'):\n        print(\"Not an appropriate choice.\")\n    else:\n        break\n \n\n Combining Exception Handling and Custom Validation \n\n Both of the above techniques can be combined into one loop. \n\n while True:\n    try:\n        age = int(input(\"Please enter your age: \"))\n    except ValueError:\n        print(\"Sorry, I didn't understand that.\")\n        continue\n\n    if age < 0:\n        print(\"Sorry, your response must not be negative.\")\n        continue\n    else:\n        #age was successfully parsed, and we're happy with its value.\n        #we're ready to exit the loop.\n        break\nif age >= 18: \n    print(\"You are able to vote in the United States!\")\nelse:\n    print(\"You are not able to vote in the United States.\")\n \n\n Encapsulating it All in a Function \n\n If you need to ask your user for a lot of different values, it might be useful to put this code in a function, so you don't have to retype it every time. \n\n def get_non_negative_int(prompt):\n    while True:\n        try:\n            value = int(input(prompt))\n        except ValueError:\n            print(\"Sorry, I didn't understand that.\")\n            continue\n\n        if value < 0:\n            print(\"Sorry, your response must not be negative.\")\n            continue\n        else:\n            break\n    return value\n\nage = get_non_negative_int(\"Please enter your age: \")\nkids = get_non_negative_int(\"Please enter the number of children you have: \")\nsalary = get_non_negative_int(\"Please enter your yearly earnings, in dollars: \")\n \n\n Putting It All Together \n\n You can extend this idea to make a very generic input function: \n\n def sanitised_input(prompt, type_=None, min_=None, max_=None, range_=None):\n    if min_ is not None and max_ is not None and max_ < min_:\n        raise ValueError(\"min_ must be less than or equal to max_.\")\n    while True:\n        ui = input(prompt)\n        if type_ is not None:\n            try:\n                ui = type_(ui)\n            except ValueError:\n                print(\"Input type must be {0}.\".format(type_.__name__))\n                continue\n        if max_ is not None and ui > max_:\n            print(\"Input must be less than or equal to {0}.\".format(max_))\n        elif min_ is not None and ui < min_:\n            print(\"Input must be greater than or equal to {0}.\".format(min_))\n        elif range_ is not None and ui not in range_:\n            if isinstance(range_, range):\n                template = \"Input must be between {0.start} and {0.stop}.\"\n                print(template.format(range_))\n            else:\n                template = \"Input must be {0}.\"\n                if len(range_) == 1:\n                    print(template.format(*range_))\n                else:\n                    expected = \" or \".join((\n                        \", \".join(str(x) for x in range_[:-1]),\n                        str(range_[-1])\n                    ))\n                    print(template.format(expected))\n        else:\n            return ui\n \n\n With usage such as: \n\n age = sanitised_input(\"Enter your age: \", int, 1, 101)\nanswer = sanitised_input(\"Enter your answer: \", str.lower, range_=('a', 'b', 'c', 'd'))\n \n\n Common Pitfalls, and Why you Should Avoid Them \n\n The Redundant Use of Redundant  input  Statements \n\n This method works but is generally considered poor style: \n\n data = input(\"Please enter a loud message (must be all caps): \")\nwhile not data.isupper():\n    print(\"Sorry, your response was not loud enough.\")\n    data = input(\"Please enter a loud message (must be all caps): \")\n \n\n It might look attractive initially because it's shorter than the  while True  method, but it violates the  Don't Repeat Yourself  principle of software development. This increases the likelihood of bugs in your system. What if you want to backport to 2.7 by changing  input  to  raw_input , but accidentally change only the first  input  above? It's a  SyntaxError  just waiting to happen. \n\n Recursion Will Blow Your Stack \n\n If you've just learned about recursion, you might be tempted to use it in  get_non_negative_int  so you can dispose of the while loop. \n\n def get_non_negative_int(prompt):\n    try:\n        value = int(input(prompt))\n    except ValueError:\n        print(\"Sorry, I didn't understand that.\")\n        return get_non_negative_int(prompt)\n\n    if value < 0:\n        print(\"Sorry, your response must not be negative.\")\n        return get_non_negative_int(prompt)\n    else:\n        return value\n \n\n This appears to work fine most of the time, but if the user enters invalid data enough times, the script will terminate with a  RuntimeError: maximum recursion depth exceeded . You may think \"no fool would make 1000 mistakes in a row\", but you're underestimating the ingenuity of fools! \n    ", "date_posted": "2020-06-06 17:56:58Z", "upvote": "\r\n            926\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "23294659", "name": "\r\n        9 revs, 7 users 73%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "23294659", "stack_answer_comment_id": "70076872", "comment_content": "Its fun reading it with many examples, kudos. Underrated lesson: \"Don't underestimate the ingenuity of fools!\"", "user_id": "None"}, {"stack_answer_id": "23294659", "stack_answer_comment_id": "84169769", "comment_content": "Not only would I have upvoted both the Q&A anyway, as they're great, but you sealed the deal with \"dickety six\". Well done, @Kevin.", "user_id": "None"}, {"stack_answer_id": "23294659", "stack_answer_comment_id": "98430983", "comment_content": "Don't estimate the ingenuity of fools... and clever attackers. A DOS attack would be easiest for this sort of thing, but others may be possible.", "user_id": "None"}, {"stack_answer_id": "23294659", "stack_answer_comment_id": "109126499", "comment_content": "@JArunMani I don't think it would be poor style, but might be a little less readable. You will indeed have only one ", "user_id": "None"}, {"stack_answer_id": "23294659", "stack_answer_comment_id": "111538982", "comment_content": "@laundmo,certainly I release the code blocks that I wrote into the public domain. Feel free to use them in any context, without my explicit permission or knowledge. Regarding the non-code-block segments, If you want to paste my entire answer into a \"Learn Python\" book you're writing, let's talk royalties ;-)", "user_id": "953482"}]}, {"stack_answer_id": "34789951", "answer_content": "\r\n Why would you do a  while True  and then break out of this loop while you can also just put your requirements in the while statement since all you want is to stop once you have the age? \n\n age = None\nwhile age is None:\n    input_value = input(\"Please enter your age: \")\n    try:\n        # try and convert the string input to a number\n        age = int(input_value)\n    except ValueError:\n        # tell the user off\n        print(\"{input} is not a number, please enter a number only\".format(input=input_value))\nif age >= 18:\n    print(\"You are able to vote in the United States!\")\nelse:\n    print(\"You are not able to vote in the United States.\")\n \n\n This would result in the following: \n\n Please enter your age: *potato*\npotato is not a number, please enter a number only\nPlease enter your age: *5*\nYou are not able to vote in the United States.\n \n\n this will work since age will never have a value that will not make sense and the code follows the logic of your \"business process\" \n    ", "date_posted": "2018-02-24 16:44:54Z", "upvote": "\r\n            56\r\n        ", "accepted": "No", "user": {"stack_user_id": "34789951", "name": "\r\n        2 revs, 2 users 96%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "34789951", "stack_answer_comment_id": "128352468", "comment_content": "A well-designed ", "user_id": "None"}]}, {"stack_answer_id": "31105868", "answer_content": "\r\n Though the accepted answer is amazing. I would also like to share a quick hack for this problem. (This takes care of the negative age problem as well.)  \n\n f=lambda age: (age.isdigit() and ((int(age)>=18  and \"Can vote\" ) or \"Cannot vote\")) or \\\nf(input(\"invalid input. Try again\\nPlease enter your age: \"))\nprint(f(input(\"Please enter your age: \")))\n \n\n P.S. This code is for python 3.x. \n    ", "date_posted": "2018-12-21 18:25:22Z", "upvote": "\r\n            28\r\n        ", "accepted": "No", "user": {"stack_user_id": "31105868", "name": "\r\n        2 revs, 2 users 78%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "31105868", "stack_answer_comment_id": "57944049", "comment_content": "Note that this code is recursive, but recursion isn't necessary here, and as Kevin said, it can blow your stack.", "user_id": "None"}, {"stack_answer_id": "31105868", "stack_answer_comment_id": "58062327", "comment_content": "@PM2Ring - you are right. But my purpose here was just to show how \"short circuiting\" can minimise (beautify) long pieces of code.", "user_id": "None"}, {"stack_answer_id": "31105868", "stack_answer_comment_id": "75053395", "comment_content": "Why would you assign a lambda to a variable, just use ", "user_id": "None"}, {"stack_answer_id": "31105868", "stack_answer_comment_id": "75054358", "comment_content": "In some cases, you may need the age just once and then there is no use of that function. One may want to use a function and throw it away after the job is done. Also, this may not be the best way, but it definitely is a different way of doing it (which was the purpose of my solution).", "user_id": "None"}, {"stack_answer_id": "31105868", "stack_answer_comment_id": "100333779", "comment_content": "@aaveg how would you turn this code to actually save the age provided by the user?", "user_id": "None"}]}, {"stack_answer_id": "56081775", "answer_content": "\r\n Functional approach  or \" look mum no loops! \": \n from itertools import chain, repeat\n\nprompts = chain([\"Enter a number: \"], repeat(\"Not a number! Try again: \"))\nreplies = map(input, prompts)\nvalid_response = next(filter(str.isdigit, replies))\nprint(valid_response)\n \n Enter a number:  a\nNot a number! Try again:  b\nNot a number! Try again:  1\n1\n \n or if you want to have a \"bad input\" message separated from an input prompt as in other answers: \n prompt_msg = \"Enter a number: \"\nbad_input_msg = \"Sorry, I didn't understand that.\"\nprompts = chain([prompt_msg], repeat('\\n'.join([bad_input_msg, prompt_msg])))\nreplies = map(input, prompts)\nvalid_response = next(filter(str.isdigit, replies))\nprint(valid_response)\n \n Enter a number:  a\nSorry, I didn't understand that.\nEnter a number:  b\nSorry, I didn't understand that.\nEnter a number:  1\n1\n \n How does it work? \n \n \n prompts = chain([\"Enter a number: \"], repeat(\"Not a number! Try again: \"))\n \nThis combination of  itertools.chain  and  itertools.repeat  will create an iterator\nwhich will yield strings  \"Enter a number: \"  once, and  \"Not a number! Try again: \"  an infinite number of times:\n for prompt in prompts:\n    print(prompt)\n \n Enter a number: \nNot a number! Try again: \nNot a number! Try again: \nNot a number! Try again: \n# ... and so on\n \n \n replies = map(input, prompts)  - here  map  will apply all the  prompts  strings from the previous step to the  input  function. E.g.:\n for reply in replies:\n    print(reply)\n \n Enter a number:  a\na\nNot a number! Try again:  1\n1\nNot a number! Try again:  it doesn't care now\nit doesn't care now\n# and so on...\n \n \n We use  filter  and  str.isdigit  to filter out those strings that contain only digits:\n only_digits = filter(str.isdigit, replies)\nfor reply in only_digits:\n    print(reply)\n \n Enter a number:  a\nNot a number! Try again:  1\n1\nNot a number! Try again:  2\n2\nNot a number! Try again:  b\nNot a number! Try again: # and so on...\n \nAnd to get only the first digits-only string we use  next . \n \n Other validation rules: \n \n String methods:  Of course you can use other string methods like  str.isalpha  to get only alphabetic strings, or  str.isupper  to get only uppercase. See  docs  for the full list. \n \n Membership testing: \nThere are several different ways to perform it. One of them is by using  __contains__  method: \n from itertools import chain, repeat\n\nfruits = {'apple', 'orange', 'peach'}\nprompts = chain([\"Enter a fruit: \"], repeat(\"I don't know this one! Try again: \"))\nreplies = map(input, prompts)\nvalid_response = next(filter(fruits.__contains__, replies))\nprint(valid_response)\n \n Enter a fruit:  1\nI don't know this one! Try again:  foo\nI don't know this one! Try again:  apple\napple\n \n \n Numbers comparison: \nThere are useful comparison methods which we can use here. For example, for  __lt__  ( < ): \n from itertools import chain, repeat\n\nprompts = chain([\"Enter a positive number:\"], repeat(\"I need a positive number! Try again:\"))\nreplies = map(input, prompts)\nnumeric_strings = filter(str.isnumeric, replies)\nnumbers = map(float, numeric_strings)\nis_positive = (0.).__lt__\nvalid_response = next(filter(is_positive, numbers))\nprint(valid_response)\n \n Enter a positive number: a\nI need a positive number! Try again: -5\nI need a positive number! Try again: 0\nI need a positive number! Try again: 5\n5.0\n \n Or, if you don't like using dunder methods (dunder = double-underscore), you can always define your own function, or use the ones from the  operator  module. \n \n Path existance: \nHere one can use  pathlib  library and its  Path.exists  method: \n from itertools import chain, repeat\nfrom pathlib import Path\n\nprompts = chain([\"Enter a path: \"], repeat(\"This path doesn't exist! Try again: \"))\nreplies = map(input, prompts)\npaths = map(Path, replies)\nvalid_response = next(filter(Path.exists, paths))\nprint(valid_response)\n \n Enter a path:  a b c\nThis path doesn't exist! Try again:  1\nThis path doesn't exist! Try again:  existing_file.txt\nexisting_file.txt\n \n \n \n Limiting number of tries: \n If you don't want to torture a user by asking him something an infinite number of times, you can specify a limit in a call of  itertools.repeat . This can be combined with providing a default value to the  next  function: \n from itertools import chain, repeat\n\nprompts = chain([\"Enter a number:\"], repeat(\"Not a number! Try again:\", 2))\nreplies = map(input, prompts)\nvalid_response = next(filter(str.isdigit, replies), None)\nprint(\"You've failed miserably!\" if valid_response is None else 'Well done!')\n \n Enter a number: a\nNot a number! Try again: b\nNot a number! Try again: c\nYou've failed miserably!\n \n Preprocessing input data: \n Sometimes we don't want to reject an input if the user accidentally supplied it  IN CAPS  or with a space in the beginning or an end of the string. To take these simple mistakes into account we can preprocess the input data by applying  str.lower  and  str.strip  methods. For example, for the case of membership testing the code will look like this: \n from itertools import chain, repeat\n\nfruits = {'apple', 'orange', 'peach'}\nprompts = chain([\"Enter a fruit: \"], repeat(\"I don't know this one! Try again: \"))\nreplies = map(input, prompts)\nlowercased_replies = map(str.lower, replies)\nstripped_replies = map(str.strip, lowercased_replies)\nvalid_response = next(filter(fruits.__contains__, stripped_replies))\nprint(valid_response)\n \n Enter a fruit:  duck\nI don't know this one! Try again:     Orange\norange\n \n In the case when you have many functions to use for preprocessing, it might be easier to use a function performing a  function composition . For example, using the one from  here : \n from itertools import chain, repeat\n\nfrom lz.functional import compose\n\nfruits = {'apple', 'orange', 'peach'}\nprompts = chain([\"Enter a fruit: \"], repeat(\"I don't know this one! Try again: \"))\nreplies = map(input, prompts)\nprocess = compose(str.strip, str.lower)  # you can add more functions here\nprocessed_replies = map(process, replies)\nvalid_response = next(filter(fruits.__contains__, processed_replies))\nprint(valid_response)\n \n Enter a fruit:  potato\nI don't know this one! Try again:   PEACH\npeach\n \n Combining validation rules: \n For a simple case, for example, when the program asks for age between 1 and 120, one can just add another  filter : \n from itertools import chain, repeat\n\nprompt_msg = \"Enter your age (1-120): \"\nbad_input_msg = \"Wrong input.\"\nprompts = chain([prompt_msg], repeat('\\n'.join([bad_input_msg, prompt_msg])))\nreplies = map(input, prompts)\nnumeric_replies = filter(str.isdigit, replies)\nages = map(int, numeric_replies)\npositive_ages = filter((0).__lt__, ages)\nnot_too_big_ages = filter((120).__ge__, positive_ages)\nvalid_response = next(not_too_big_ages)\nprint(valid_response)\n \n But in the case when there are many rules, it's better to implement a function performing a  logical conjunction . In the following example I will use a ready one from  here : \n from functools import partial\nfrom itertools import chain, repeat\n\nfrom lz.logical import conjoin\n\n\ndef is_one_letter(string: str) -> bool:\n    return len(string) == 1\n\n\nrules = [str.isalpha, str.isupper, is_one_letter, 'C'.__le__, 'P'.__ge__]\n\nprompt_msg = \"Enter a letter (C-P): \"\nbad_input_msg = \"Wrong input.\"\nprompts = chain([prompt_msg], repeat('\\n'.join([bad_input_msg, prompt_msg])))\nreplies = map(input, prompts)\nvalid_response = next(filter(conjoin(*rules), replies))\nprint(valid_response)\n \n Enter a letter (C-P):  5\nWrong input.\nEnter a letter (C-P):  f\nWrong input.\nEnter a letter (C-P):  CDE\nWrong input.\nEnter a letter (C-P):  Q\nWrong input.\nEnter a letter (C-P):  N\nN\n \n Unfortunately, if someone needs a custom message for each failed case, then, I'm afraid, there is no  pretty  functional way. Or, at least, I couldn't find one. \n    ", "date_posted": "2020-06-20 09:12:55Z", "upvote": "\r\n            28\r\n        ", "accepted": "No", "user": {"stack_user_id": "56081775", "name": "\r\n        3 revs", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "56081775", "stack_answer_comment_id": "102050848", "comment_content": "What a thorough and wonderful answer, the explanation breakdown was great.", "user_id": "None"}, {"stack_answer_id": "56081775", "stack_answer_comment_id": "102061971", "comment_content": "Using your style, how would one go about stripping whitespace and lower-casing the input for membership testing? I don't want to create a set that must include both upper and lowercase examples. I would also like to allow for whitespace input mistakes.", "user_id": "None"}, {"stack_answer_id": "56081775", "stack_answer_comment_id": "102075725", "comment_content": "@Austin I added a new section on preprocessing. Take a look.", "user_id": "None"}, {"stack_answer_id": "56081775", "stack_answer_comment_id": "110069223", "comment_content": "That reminds me of ReactiveX. But perhaps that was inspired by functional languages in the first place?", "user_id": "None"}]}, {"stack_answer_id": "56084305", "answer_content": "\r\n Using  Click : \n Click  is a library for command-line interfaces and it provides functionality for asking a valid response from a user. \n Simple example: \n import click\n\nnumber = click.prompt('Please enter a number', type=float)\nprint(number)\n \n Please enter a number: \n a\nError: a is not a valid floating point value\nPlease enter a number: \n 10\n10.0\n \n Note how it converted the string value to a float automatically. \n Checking if a value is within a range: \n There are different  custom types  provided. To get a number in a specific range we can use  IntRange : \n age = click.prompt(\"What's your age?\", type=click.IntRange(1, 120))\nprint(age)\n \n What's your age?: \n a\nError: a is not a valid integer\nWhat's your age?: \n 0\nError: 0 is not in the valid range of 1 to 120.\nWhat's your age?: \n 5\n5\n \n We can also specify just one of the limits,  min  or  max : \n age = click.prompt(\"What's your age?\", type=click.IntRange(min=14))\nprint(age)\n \n What's your age?: \n 0\nError: 0 is smaller than the minimum valid value 14.\nWhat's your age?: \n 18\n18\n \n Membership testing: \n Using  click.Choice  type. By default this check is case-sensitive. \n choices = {'apple', 'orange', 'peach'}\nchoice = click.prompt('Provide a fruit', type=click.Choice(choices, case_sensitive=False))\nprint(choice)\n \n Provide a fruit (apple, peach, orange): \n banana\nError: invalid choice: banana. (choose from apple, peach, orange)\nProvide a fruit (apple, peach, orange): \n OrAnGe\norange\n \n Working with paths and files: \n Using a  click.Path  type we can check for existing paths and also resolve them: \n path = click.prompt('Provide path', type=click.Path(exists=True, resolve_path=True))\nprint(path)\n \n Provide path: \n nonexistent\nError: Path \"nonexistent\" does not exist.\nProvide path: \n existing_folder\n'/path/to/existing_folder\n \n Reading and writing files can be done by  click.File : \n file = click.prompt('In which file to write data?', type=click.File('w'))\nwith file.open():\n    file.write('Hello!')\n# More info about `lazy=True` at:\n# https://click.palletsprojects.com/en/7.x/arguments/#file-opening-safety\nfile = click.prompt('Which file you wanna read?', type=click.File(lazy=True))\nwith file.open():\n    print(file.read())\n \n In which file to write data?: \n         # <-- provided an empty string, which is an illegal name for a file\nIn which file to write data?: \n some_file.txt\nWhich file you wanna read?: \n nonexistent.txt\nError: Could not open file: nonexistent.txt: No such file or directory\nWhich file you wanna read?: \n some_file.txt\nHello!\n \n Other examples: \n Password confirmation: \n password = click.prompt('Enter password', hide_input=True, confirmation_prompt=True)\nprint(password)\n \n Enter password: \n \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\nRepeat for confirmation: \n \u00b7\nError: the two entered values do not match\nEnter password: \n \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\nRepeat for confirmation: \n \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\nqwerty\n \n Default values: \n In this case, simply pressing  Enter  (or whatever key you use) without entering a value, will give you a default one: \n number = click.prompt('Please enter a number', type=int, default=42)\nprint(number)\n \n Please enter a number [42]: \n a\nError: a is not a valid integer\nPlease enter a number [42]: \n \n42\n \n    ", "date_posted": "2020-06-20 09:12:55Z", "upvote": "\r\n            20\r\n        ", "accepted": "No", "user": {"stack_user_id": "56084305", "name": "\r\n        2 revs", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "56084305", "stack_answer_comment_id": "110338437", "comment_content": "Thanks, this is perfect. Looping with a number selection in a valid range was exactly what i was looking for.", "user_id": "None"}]}, {"stack_answer_id": "35110110", "answer_content": "\r\n So, I was messing around with something similar to this recently, and I came up with the following solution, which uses a way of getting input that rejects junk, before it's even checked in any logical way. \n\n read_single_keypress()  courtesy  https://stackoverflow.com/a/6599441/4532996 \n\n def read_single_keypress() -> str:\n    \"\"\"Waits for a single keypress on stdin.\n    -- from :: https://stackoverflow.com/a/6599441/4532996\n    \"\"\"\n\n    import termios, fcntl, sys, os\n    fd = sys.stdin.fileno()\n    # save old state\n    flags_save = fcntl.fcntl(fd, fcntl.F_GETFL)\n    attrs_save = termios.tcgetattr(fd)\n    # make raw - the way to do this comes from the termios(3) man page.\n    attrs = list(attrs_save) # copy the stored version to update\n    # iflag\n    attrs[0] &= ~(termios.IGNBRK | termios.BRKINT | termios.PARMRK\n                  | termios.ISTRIP | termios.INLCR | termios. IGNCR\n                  | termios.ICRNL | termios.IXON )\n    # oflag\n    attrs[1] &= ~termios.OPOST\n    # cflag\n    attrs[2] &= ~(termios.CSIZE | termios. PARENB)\n    attrs[2] |= termios.CS8\n    # lflag\n    attrs[3] &= ~(termios.ECHONL | termios.ECHO | termios.ICANON\n                  | termios.ISIG | termios.IEXTEN)\n    termios.tcsetattr(fd, termios.TCSANOW, attrs)\n    # turn off non-blocking\n    fcntl.fcntl(fd, fcntl.F_SETFL, flags_save & ~os.O_NONBLOCK)\n    # read a single keystroke\n    try:\n        ret = sys.stdin.read(1) # returns a single character\n    except KeyboardInterrupt:\n        ret = 0\n    finally:\n        # restore old state\n        termios.tcsetattr(fd, termios.TCSAFLUSH, attrs_save)\n        fcntl.fcntl(fd, fcntl.F_SETFL, flags_save)\n    return ret\n\ndef until_not_multi(chars) -> str:\n    \"\"\"read stdin until !(chars)\"\"\"\n    import sys\n    chars = list(chars)\n    y = \"\"\n    sys.stdout.flush()\n    while True:\n        i = read_single_keypress()\n        _ = sys.stdout.write(i)\n        sys.stdout.flush()\n        if i not in chars:\n            break\n        y += i\n    return y\n\ndef _can_you_vote() -> str:\n    \"\"\"a practical example:\n    test if a user can vote based purely on keypresses\"\"\"\n    print(\"can you vote? age : \", end=\"\")\n    x = int(\"0\" + until_not_multi(\"0123456789\"))\n    if not x:\n        print(\"\\nsorry, age can only consist of digits.\")\n        return\n    print(\"your age is\", x, \"\\nYou can vote!\" if x >= 18 else \"Sorry! you can't vote\")\n\n_can_you_vote()\n \n\n You can find the complete module  here . \n\n Example: \n\n $ ./input_constrain.py\ncan you vote? age : a\nsorry, age can only consist of digits.\n$ ./input_constrain.py \ncan you vote? age : 23<RETURN>\nyour age is 23\nYou can vote!\n$ _\n \n\n Note that the nature of this implementation is it closes stdin as soon as something that isn't a digit is read. I didn't hit enter after  a , but I needed to after the numbers. \n\n You could merge this with the  thismany()  function in the same module to only allow, say, three digits. \n    ", "date_posted": "2017-05-23 12:34:45Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "35110110", "name": "\r\n        3 revs", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "35110110", "stack_answer_comment_id": "114263253", "comment_content": "If you're already detecting key strokes, why allow characters at all and throw errors around, when you can just silently ignore them, until you get the desired number?", "user_id": "None"}, {"stack_answer_id": "35110110", "stack_answer_comment_id": "114279945", "comment_content": "@Kebman you could do that but it might be less obvious to the user what they can type", "user_id": "None"}]}, {"stack_answer_id": "64604056", "answer_content": "\r\n I am a big fan of Unix philosophy \"Do one thing and do it well\". Capturing user input and validating it are two separate steps: \n \n prompting the user for input with  get_input  until the input is ok \n validating using a  validator  function that can be passed to  get_input \n \n It can be kept as simple as (Python 3.8+, with  the walrus operator): \n def get_input(\n    prompt=\"Enter a value: \",\n    validator=lambda x: True,\n    error_message=\"Invalid input. Please try again.\",\n):\n    while not validator(value := input(prompt)):\n        print(error_message)\n    return value\n\ndef is_positive_int(value):\n    try:\n        return int(value) >= 0\n    except ValueError:\n        return False\n\nif __name__ == \"__main__\":\n    val = get_input(\"Give a positive number: \", is_positive_int)\n    print(f\"OK, thanks for {val}\")\n \n Sample run: \n Give a positive number: -5\nInvalid input. Please try again.\nGive a positive number: asdf\nInvalid input. Please try again.\nGive a positive number:\nInvalid input. Please try again.\nGive a positive number: 42\nOK, thanks for 42\n \n \n In Python < 3.8 you could use  get_input  like this: \n def get_input(\n    prompt=\"Enter a value: \",\n    validator=lambda x: True,\n    error_message=\"Invalid input. Please try again.\",\n):\n    while True:\n        value = input(prompt)\n        if validator(value):\n            return value\n        print(error_message)\n \n You might also handle  KeyboardInterrupt  and print a friendly exit message before terminating the application. A counter can be used to limit the allowed retries if desired. \n    ", "date_posted": "2022-01-28 06:18:26Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "64604056", "name": "\r\n        3 revs, 2 users 73%", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "63811753", "answer_content": "\r\n Use try-except to handle the error and repeat it again: \n while True:\n    try:\n        age = int(input(\"Please enter your age: \"))\n        if age >= 18:\n            print(\"You are able to vote in the United States!\")\n        else:\n            print(\"You are not able to vote in the United States.\")\n    except Exception as e:\n        print(\"please enter number\")\n \n    ", "date_posted": "2020-09-11 14:11:56Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "63811753", "name": "\r\n        2 revs, 2 users 62%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "63811753", "stack_answer_comment_id": "112906023", "comment_content": "You are missing a ", "user_id": "None"}]}, {"stack_answer_id": "53522191", "answer_content": "\r\n Building upon Daniel Q's and Patrick Artner's excellent suggestions,\nhere is an even more generalized solution. \n\n # Assuming Python3\nimport sys\n\nclass ValidationError(ValueError):  # thanks Patrick Artner\n    pass\n\ndef validate_input(prompt, cast=str, cond=(lambda x: True), onerror=None):\n    if onerror==None: onerror = {}\n    while True:\n        try:\n            data = cast(input(prompt))\n            if not cond(data): raise ValidationError\n            return data\n        except tuple(onerror.keys()) as e:  # thanks Daniel Q\n            print(onerror[type(e)], file=sys.stderr)\n \n\n I opted for explicit  if  and  raise  statements instead of an  assert ,\nbecause assertion checking may be turned off,\nwhereas validation should always be on to provide robustness. \n\n This may be used to get different kinds of input,\nwith different validation conditions.\nFor example: \n\n # No validation, equivalent to simple input:\nanystr = validate_input(\"Enter any string: \")\n\n# Get a string containing only letters:\nletters = validate_input(\"Enter letters: \",\n    cond=str.isalpha,\n    onerror={ValidationError: \"Only letters, please!\"})\n\n# Get a float in [0, 100]:\npercentage = validate_input(\"Percentage? \",\n    cast=float, cond=lambda x: 0.0<=x<=100.0,\n    onerror={ValidationError: \"Must be between 0 and 100!\",\n             ValueError: \"Not a number!\"})\n \n\n Or, to answer the original question: \n\n age = validate_input(\"Please enter your age: \",\n        cast=int, cond=lambda a:0<=a<150,\n        onerror={ValidationError: \"Enter a plausible age, please!\",\n                 ValueError: \"Enter an integer, please!\"})\nif age >= 18: \n    print(\"You are able to vote in the United States!\")\nelse:\n    print(\"You are not able to vote in the United States.\")\n \n    ", "date_posted": "2018-12-01 11:17:14Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "53522191", "name": "\r\n        3 revs", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "37989154", "answer_content": "\r\n def validate_age(age):\n    if age >=0 :\n        return True\n    return False\n\nwhile True:\n    try:\n        age = int(raw_input(\"Please enter your age:\"))\n        if validate_age(age): break\n    except ValueError:\n        print \"Error: Invalid age.\"\n \n    ", "date_posted": "2016-06-23 10:34:14Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "37989154", "name": "\r\n        ojas mohril\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "43704910", "answer_content": "\r\n Try this one:-  \n\n def takeInput(required):\n  print 'ooo or OOO to exit'\n  ans = raw_input('Enter: ')\n\n  if not ans:\n      print \"You entered nothing...!\"\n      return takeInput(required) \n\n      ##  FOR Exit  ## \n  elif ans in ['ooo', 'OOO']:\n    print \"Closing instance.\"\n    exit()\n\n  else:\n    if ans.isdigit():\n      current = 'int'\n    elif set('[~!@#$%^&*()_+{}\":/\\']+$').intersection(ans):\n      current = 'other'\n    elif isinstance(ans,basestring):\n      current = 'str'        \n    else:\n      current = 'none'\n\n  if required == current :\n    return ans\n  else:\n    return takeInput(required)\n\n## pass the value in which type you want [str/int/special character(as other )]\nprint \"input: \", takeInput('str')\n \n    ", "date_posted": "2017-04-30 09:29:28Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "43704910", "name": "\r\n        Pratik Anand\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "53827366", "answer_content": "\r\n Good question! You can try the following code for this. =) \n\n This code uses  ast.literal_eval()  to  find the data type of the input  ( age ). Then it follows the following algorithm: \n\n \n   \n   Ask user to input her/his  age . \n  \n   1.1. If  age  is  float  or  int  data type: \n  \n   \n   Check if  age>=18 . If  age>=18 , print appropriate output and exit. \n   Check if  0<age<18 . If  0<age<18 , print appropriate output and exit. \n   If  age<=0 , ask the user to input a valid number for age again, ( i.e.  go back to step 1.)  \n   \n  \n   1.2. If  age  is not  float  or  int  data type, then ask user to input her/his age again ( i.e.  go back to step 1.)  \n   \n \n\n Here is the code. \n\n from ast import literal_eval\n\n''' This function is used to identify the data type of input data.'''\ndef input_type(input_data):\n    try:\n        return type(literal_eval(input_data))\n    except (ValueError, SyntaxError):\n        return str\n\nflag = True\n\nwhile(flag):\n    age = raw_input(\"Please enter your age: \")\n\n    if input_type(age)==float or input_type(age)==int:\n        if eval(age)>=18: \n            print(\"You are able to vote in the United States!\") \n            flag = False \n        elif eval(age)>0 and eval(age)<18: \n            print(\"You are not able to vote in the United States.\") \n            flag = False\n        else: print(\"Please enter a valid number as your age.\")\n\n    else: print(\"Sorry, I didn't understand that.\") \n \n    ", "date_posted": "2018-12-18 06:54:35Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "53827366", "name": "\r\n        4 revs", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "46903575", "answer_content": "\r\n Use \"while\" statement till user enter a true value and if the input value is not a number or it's a null value skip it and try to ask again and so on.\nIn example I tried to answer truly your question. If we suppose that our age is between 1 and 150 then input value accepted, else it's a wrong value.\nFor terminating program, the user can use 0 key and enter it as a value. \n \n Note: Read comments top of code. \n \n # If your input value is only a number then use \"Value.isdigit() == False\".\n# If you need an input that is a text, you should remove \"Value.isdigit() == False\".\ndef Input(Message):\n    Value = None\n    while Value == None or Value.isdigit() == False:\n        try:        \n            Value = str(input(Message)).strip()\n        except Exception:\n            Value = None\n    return Value\n\n# Example:\nage = 0\n# If we suppose that our age is between 1 and 150 then input value accepted,\n# else it's a wrong value.\nwhile age <=0 or age >150:\n    age = int(Input(\"Please enter your age: \"))\n    # For terminating program, the user can use 0 key and enter it as an a value.\n    if age == 0:\n        print(\"Terminating ...\")\n        exit(0)\n        \nif age >= 18 and age <=150: \n    print(\"You are able to vote in the United States!\")\nelse:\n    print(\"You are not able to vote in the United States.\")\n \n    ", "date_posted": "2022-05-15 21:23:27Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "46903575", "name": "\r\n        6 revs, 2 users 99%", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "56833260", "answer_content": "\r\n You can always apply simple if-else logic and add one more  if  logic to your code along with a  for  loop. \n\n while True:\n     age = int(input(\"Please enter your age: \"))\n     if (age >= 18)  : \n         print(\"You are able to vote in the United States!\")\n     if (age < 18) & (age > 0):\n         print(\"You are not able to vote in the United States.\")\n     else:\n         print(\"Wrong characters, the input must be numeric\")\n         continue\n \n\n This will be an infinite loo and you would be asked to enter the age, indefinitely. \n    ", "date_posted": "2019-07-01 14:17:43Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "56833260", "name": "\r\n        2 revs", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "56833260", "stack_answer_comment_id": "100220085", "comment_content": "This doesn't really answer the question. The question was about getting a user input ", "user_id": "None"}]}, {"stack_answer_id": "37533486", "answer_content": "\r\n While a  try / except  block will work, a much faster and cleaner way to accomplish this task would be to use  str.isdigit() . \n\n while True:\n    age = input(\"Please enter your age: \")\n    if age.isdigit():\n        age = int(age)\n        break\n    else:\n        print(\"Invalid number '{age}'. Try again.\".format(age=age))\n\nif age >= 18: \n    print(\"You are able to vote in the United States!\")\nelse:\n    print(\"You are not able to vote in the United States.\")\n \n    ", "date_posted": "2016-06-06 07:15:17Z", "upvote": "\r\n            -1\r\n        ", "accepted": "No", "user": {"stack_user_id": "37533486", "name": "\r\n        2 revs", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "40396280", "answer_content": "\r\n You can write more general logic to allow user to enter only specific number of times, as the same use-case arises in many real-world applications. \n\n def getValidInt(iMaxAttemps = None):\n  iCount = 0\n  while True:\n    # exit when maximum attempt limit has expired\n    if iCount != None and iCount > iMaxAttemps:\n       return 0     # return as default value\n\n    i = raw_input(\"Enter no\")\n    try:\n       i = int(i)\n    except ValueError as e:\n       print \"Enter valid int value\"\n    else:\n       break\n\n    return i\n\nage = getValidInt()\n# do whatever you want to do.\n \n    ", "date_posted": "2016-11-03 07:49:29Z", "upvote": "\r\n            -1\r\n        ", "accepted": "No", "user": {"stack_user_id": "40396280", "name": "\r\n        Mangu Singh Rajpurohit\r\n        ", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "40396280", "stack_answer_comment_id": "72189955", "comment_content": "you forget to increase the iCount value after each loop", "user_id": "None"}]}, {"stack_answer_id": "48069871", "answer_content": "\r\n You can make the input statement a while True loop so it repeatedly asks for the users input and then break that loop if the user enters the response you would like. And you can use try and except blocks to handle invalid responses. \n\n while True:\n\n    var = True\n\n    try:\n        age = int(input(\"Please enter your age: \"))\n\n    except ValueError:\n        print(\"Invalid input.\")\n        var = False\n\n    if var == True:\n        if age >= 18:\n                print(\"You are able to vote in the United States.\")\n                break\n        else:\n            print(\"You are not able to vote in the United States.\")\n \n\n The var variable is just so that if the user enters a string instead of a integer the program wont return \"You are not able to vote in the United States.\" \n    ", "date_posted": "2018-01-03 00:59:37Z", "upvote": "\r\n            -1\r\n        ", "accepted": "No", "user": {"stack_user_id": "48069871", "name": "\r\n        user9142415\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "53207215", "answer_content": "\r\n One more solution for using input validation using a customized  ValidationError  and a (optional) range validation for integer inputs: \n\n class ValidationError(ValueError): \n    \"\"\"Special validation error - its message is supposed to be printed\"\"\"\n    pass\n\ndef RangeValidator(text,num,r):\n    \"\"\"Generic validator - raises 'text' as ValidationError if 'num' not in range 'r'.\"\"\"\n    if num in r:\n        return num\n    raise ValidationError(text)\n\ndef ValidCol(c): \n    \"\"\"Specialized column validator providing text and range.\"\"\"\n    return RangeValidator(\"Columns must be in the range of 0 to 3 (inclusive)\", \n                          c, range(4))\n\ndef ValidRow(r): \n    \"\"\"Specialized row validator providing text and range.\"\"\"\n    return RangeValidator(\"Rows must be in the range of 5 to 15(exclusive)\",\n                          r, range(5,15))\n \n\n Usage: \n\n def GetInt(text, validator=None):\n    \"\"\"Aks user for integer input until a valid integer is given. If provided, \n    a 'validator' function takes the integer and either raises a \n    ValidationError to be printed or returns the valid number. \n    Non integers display a simple error message.\"\"\"\n    print()\n    while True:\n        n = input(text)\n        try:\n            n = int(n)\n\n            return n if validator is None else validator(n)\n\n        except ValueError as ve:\n            # prints ValidationErrors directly - else generic message:\n            if isinstance(ve, ValidationError):\n                print(ve)\n            else:\n                print(\"Invalid input: \", n)\n\n\ncolumn = GetInt(\"Pleased enter column: \", ValidCol)\nrow = GetInt(\"Pleased enter row: \", ValidRow)\nprint( row, column)\n \n\n Output: \n\n Pleased enter column: 22\nColumns must be in the range of 0 to 3 (inclusive)\nPleased enter column: -2\nColumns must be in the range of 0 to 3 (inclusive)\nPleased enter column: 2\nPleased enter row: a\nInvalid input:  a\nPleased enter row: 72\nRows must be in the range of 5 to 15(exclusive)\nPleased enter row: 9  \n\n9, 2\n \n    ", "date_posted": "2018-11-08 12:04:20Z", "upvote": "\r\n            -1\r\n        ", "accepted": "No", "user": {"stack_user_id": "53207215", "name": "\r\n        3 revs", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "55681134", "answer_content": "\r\n Persistent user input using  recursive function : \n\n String \n\n def askName():\n    return input(\"Write your name: \").strip() or askName()\n\nname = askName()\n \n\n Integer \n\n def askAge():\n    try: return int(input(\"Enter your age: \"))\n    except ValueError: return askAge()\n\nage = askAge()\n \n\n and finally, the question requirement: \n\n def askAge():\n    try: return int(input(\"Enter your age: \"))\n    except ValueError: return askAge()\n\nage = askAge()\n\nresponseAge = [\n    \"You are able to vote in the United States!\",\n    \"You are not able to vote in the United States.\",\n][int(age < 18)]\n\nprint(responseAge)\n \n    ", "date_posted": "2019-04-15 13:56:05Z", "upvote": "\r\n            -1\r\n        ", "accepted": "No", "user": {"stack_user_id": "55681134", "name": "\r\n        4 revs", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "71106291", "answer_content": "\r\n You can try to convert it to a integer, but ask the user to repeat if it doesn't work. \n while True:\n    age = input('Please enter your age: ')\n    try:\n        age_int = int(age)\n        if age_int >= 18:\n            print('You can vote in the United States!')\n        else:\n            print('You cannot vote in the United States.')\n        break\n    except:\n        print('Please enter a meaningful answer.')\n        \n \n The while loop runs as long as the user has not inputted a meaningful answer, but breaks if it makes sense. \n    ", "date_posted": "2022-02-14 01:28:25Z", "upvote": "\r\n            -1\r\n        ", "accepted": "No", "user": {"stack_user_id": "71106291", "name": "\r\n        Python\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "67387649", "answer_content": "\r\n Use  isdigit()  to check if a string represents a valid integer. \n You could use a recursive function. \n def ask():\n    answer = input(\"Please enter amount to convert: \")\n    if not answer.isdigit():\n        print(\"Invalid\")\n        return ask()\n\n    return int(answer)\n\nGdp = ask()\n \n Or a while loop \n while True:\n    answer = input(\"Please enter amount to convert: \")\n    if not answer.isdigit():\n        print(\"Invalid\")\n        continue\n\n    Gbp = int(answer)\n \n    ", "date_posted": "2021-06-30 00:03:48Z", "upvote": "\r\n            -2\r\n        ", "accepted": "No", "user": {"stack_user_id": "67387649", "name": "\r\n        3 revs, 2 users 96%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "67387649", "stack_answer_comment_id": "119116330", "comment_content": "You're missing a ", "user_id": "None"}, {"stack_answer_id": "67387649", "stack_answer_comment_id": "119141460", "comment_content": "@Tomerikoo It recursively asks until the answer is valid, which I think is what was asked. I meant to write it in a way where you can put any code ", "user_id": "None"}, {"stack_answer_id": "67387649", "stack_answer_comment_id": "119142515", "comment_content": "What I mean is that you should test your code with some scenarios. In the first case, the ", "user_id": "None"}]}, {"stack_answer_id": "63447176", "answer_content": "\r\n Below code may help. \n age=(lambda i,f: f(i,f))(input(\"Please enter your age: \"),lambda i,f: i if i.isdigit() else f(input(\"Please enter your age: \"),f))\nprint(\"You are able to vote in the united states\" if int(age)>=18 else \"You are not able to vote in the united states\",end='')\n \n If you want to have maximum tries, say 3, use below code \n age=(lambda i,n,f: f(i,n,f))(input(\"Please enter your age: \"),1,lambda i,n,f: i if i.isdigit() else (None if n==3 else f(input(\"Please enter your age: \"),n+1,f)))\nprint(\"You are able to vote in the united states\" if age and int(age)>=18 else \"You are not able to vote in the united states\",end='')\n \n Note: This uses recursion. \n    ", "date_posted": "2020-08-17 17:21:22Z", "upvote": "\r\n            -4\r\n        ", "accepted": "No", "user": {"stack_user_id": "63447176", "name": "\r\n        3 revs", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "63447176", "stack_answer_comment_id": "125313509", "comment_content": "Don't use recursion to collect user input. Given enough retries, the app crashes. I don't understand the golfed code. Why not make it comprehensible?", "user_id": "None"}, {"stack_answer_id": "63447176", "stack_answer_comment_id": "125637607", "comment_content": "Teaching this to new users instead of a simple while-loop is obfuscatory and confusing.", "user_id": "None"}]}], "user": {"stack_user_id": null, "name": null, "reputation_score": 0}, "question_comments": []},
{"stack_question_id": "15112125", "question_title": "How to test multiple variables for equality against a single value?", "question_content": "\r\n                I'm trying to make a function that will compare multiple variables to an integer and output a string of three letters. I was wondering if there was a way to translate this into Python. So say:\nx = 0\ny ...\r\n", "question_url": "/questions/15112125/how-to-test-multiple-variables-for-equality-against-a-single-value", "date_posted": "Feb 27, 2013 at 12:26", "upvote": "8", "view": "4", "tags": ["python", "if-statement", "comparison", "match", "boolean-logic"], "answers_count": "3", "answers": [{"stack_answer_id": "15112149", "answer_content": "\r\n You misunderstand how boolean expressions work; they don't work like an English sentence and guess that you are talking about the same comparison for all names here. You are looking for: \n if x == 1 or y == 1 or z == 1:\n \n x  and  y  are otherwise evaluated on their own ( False  if  0 ,  True  otherwise). \n You can shorten that using a containment test against  a tuple : \n if 1 in (x, y, z):\n \n or better still: \n if 1 in {x, y, z}:\n \n using  a  set  to take advantage of the constant-cost membership test (i.e.  in  takes a fixed amount of time whatever the left-hand operand is). \n Explanation \n When you use  or , python sees each side of the operator as  separate  expressions. The expression  x or y == 1  is treated as first a boolean test for  x , then if that is False, the expression  y == 1  is tested. \n This is due to  operator precedence . The  or  operator has a lower precedence than the  ==  test, so the latter is evaluated  first . \n However, even if this were  not  the case, and the expression  x or y or z == 1  was actually interpreted as  (x or y or z) == 1  instead, this would still not do what you expect it to do. \n x or y or z  would evaluate to the first argument that is 'truthy', e.g. not  False , numeric 0 or empty (see  boolean expressions  for details on what Python considers false in a boolean context). \n So for the values  x = 2; y = 1; z = 0 ,  x or y or z  would resolve to  2 , because that is the first true-like value in the arguments. Then  2 == 1  would be  False , even though  y == 1  would be  True . \n The same would apply to the inverse; testing multiple values against a single variable;  x == 1 or 2 or 3  would fail for the same reasons. Use  x == 1 or x == 2 or x == 3  or  x in {1, 2, 3} . \n    ", "date_posted": "2021-04-02 01:51:27Z", "upvote": "\r\n            1068\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "4518341", "name": "wjandrea", "reputation_score": "24.1k"}, "answer_comments": [{"stack_answer_id": "15112149", "stack_answer_comment_id": "29042397", "comment_content": "I wouldn't be so quick to go for the ", "user_id": "None"}, {"stack_answer_id": "15112149", "stack_answer_comment_id": "29042516", "comment_content": "@dequestarmappartialsetattr: In Python 3.3 and up, the set is stored as a constant, bypassing the creation time altogether, eliminating the creation time. Tuples ", "user_id": "None"}, {"stack_answer_id": "15112149", "stack_answer_comment_id": "29042794", "comment_content": "@dequestarmappartialsetattr: If you time ", "user_id": "None"}, {"stack_answer_id": "15112149", "stack_answer_comment_id": "65957961", "comment_content": "@MartijnPieters: Using the ", "user_id": "None"}, {"stack_answer_id": "15112149", "stack_answer_comment_id": "65961841", "comment_content": "@ShadowRanger: yes, peephole optimisation (be it for ", "user_id": "None"}]}, {"stack_answer_id": "17604212", "answer_content": "\r\n Your problem is more easily addressed with a dictionary structure like: \n\n x = 0\ny = 1\nz = 3\nd = {0: 'c', 1:'d', 2:'e', 3:'f'}\nmylist = [d[k] for k in [x, y, z]]\n \n    ", "date_posted": "2017-10-25 14:45:52Z", "upvote": "\r\n            116\r\n        ", "accepted": "No", "user": {"stack_user_id": "3745896", "name": "River", "reputation_score": "8,150"}, "answer_comments": [{"stack_answer_id": "17604212", "stack_answer_comment_id": "29042877", "comment_content": "Or even ", "user_id": "None"}, {"stack_answer_id": "17604212", "stack_answer_comment_id": "36122660", "comment_content": "or ", "user_id": "None"}, {"stack_answer_id": "17604212", "stack_answer_comment_id": "96927060", "comment_content": "Aside from the list comprehension which I'm not yet fully accustomed to, most of us had the same reflex: build that dict !", "user_id": "None"}]}, {"stack_answer_id": "32085628", "answer_content": "\r\n As stated by Martijn Pieters, the correct, and fastest, format is: \n\n if 1 in {x, y, z}:\n \n\n Using his advice you would now have separate if-statements so that Python will read each statement whether the former were  True  or  False . Such as: \n\n if 0 in {x, y, z}:\n    mylist.append(\"c\")\nif 1 in {x, y, z}:\n    mylist.append(\"d\")\nif 2 in {x, y, z}:\n    mylist.append(\"e\")\n...\n \n\n This will work, but  if  you are comfortable using dictionaries (see what I did there), you can clean this up by making an initial dictionary mapping the numbers to the letters you want, then just using a for-loop: \n\n num_to_letters = {0: \"c\", 1: \"d\", 2: \"e\", 3: \"f\"}\nfor number in num_to_letters:\n    if number in {x, y, z}:\n        mylist.append(num_to_letters[number])\n \n    ", "date_posted": "2019-05-07 09:30:20Z", "upvote": "\r\n            76\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "32085628", "stack_answer_comment_id": "115011428", "comment_content": "@VisioN You mean ", "user_id": "None"}, {"stack_answer_id": "32085628", "stack_answer_comment_id": "115018668", "comment_content": "@wjandrea Yes, you are right, it's my mistake! I completely forgot about the default behaviour. Unfortunately, I cannot edit my comment, so I have deleted it since you have highlighted the better approach in your comment.", "user_id": "None"}]}, {"stack_answer_id": "17603667", "answer_content": "\r\n The direct way to write  x or y or z == 0  is \n\n if any(map((lambda value: value == 0), (x,y,z))):\n    pass # write your logic.\n \n\n But I dont think, you like it. :)\nAnd this way is ugly. \n\n The other way (a better) is: \n\n 0 in (x, y, z)\n \n\n BTW lots of  if s could be written as something like this \n\n my_cases = {\n    0: Mylist.append(\"c\"),\n    1: Mylist.append(\"d\")\n    # ..\n}\n\nfor key in my_cases:\n    if key in (x,y,z):\n        my_cases[key]()\n        break\n \n    ", "date_posted": "2013-07-11 21:24:59Z", "upvote": "\r\n            53\r\n        ", "accepted": "No", "user": {"stack_user_id": "1243636", "name": "akaRem", "reputation_score": "6,886"}, "answer_comments": [{"stack_answer_id": "17603667", "stack_answer_comment_id": "32723572", "comment_content": "In your example of the ", "user_id": "None"}, {"stack_answer_id": "17603667", "stack_answer_comment_id": "97810895", "comment_content": "the dict instead of a key is wrong, you will get Mylist=['c', 'd'] when the dictionary get initialized even if you commented out \"for..loop\" part", "user_id": "None"}, {"stack_answer_id": "17603667", "stack_answer_comment_id": "102313779", "comment_content": "In your first example ", "user_id": "None"}, {"stack_answer_id": "17603667", "stack_answer_comment_id": "106339378", "comment_content": "A comprehension is much simpler than a map of a lambda: ", "user_id": "None"}]}, {"stack_answer_id": "30430962", "answer_content": "\r\n If you ARE very very lazy, you can put the values inside an array. Such as \n\n list = []\nlist.append(x)\nlist.append(y)\nlist.append(z)\nnums = [add numbers here]\nletters = [add corresponding letters here]\nfor index in range(len(nums)):\n    for obj in list:\n        if obj == num[index]:\n            MyList.append(letters[index])\n            break\n \n\n You can also put the numbers and letters in a dictionary and do it, but this is probably a LOT more complicated than simply if statements. That's what you get for trying to be extra lazy :) \n\n One more thing, your  \n\n if x or y or z == 0:\n \n\n will compile, but not in the way you want it to. When you simply put a variable in an if statement (example) \n\n if b\n \n\n the program will check if the variable is not null. Another way to write the above statement (which makes more sense) is  \n\n if bool(b)\n \n\n Bool is an inbuilt function in python which basically does the command of verifying a boolean statement (If you don't know what that is, it is what you are trying to make in your if statement right now :)) \n\n Another lazy way I found is : \n\n if any([x==0, y==0, z==0])\n \n    ", "date_posted": "2015-08-13 18:06:52Z", "upvote": "\r\n            34\r\n        ", "accepted": "No", "user": {"stack_user_id": "4871483", "name": "rassa45", "reputation_score": "3,406"}, "answer_comments": [{"stack_answer_id": "30430962", "stack_answer_comment_id": "106339486", "comment_content": "-1 There's a lot of bad practice here. ", "user_id": "None"}]}, {"stack_answer_id": "24043508", "answer_content": "\r\n To check if a value is contained within a set of variables you can use the inbuilt modules            itertools  and  operator . \n\n For example: \n\n Imports: \n\n from itertools import repeat\nfrom operator import contains\n \n\n Declare variables: \n\n x = 0\ny = 1\nz = 3\n \n\n Create mapping of values (in the order you want to check): \n\n check_values = (0, 1, 3)\n \n\n Use  itertools  to allow repetition of the variables: \n\n check_vars = repeat((x, y, z))\n \n\n Finally, use the  map  function to create an iterator: \n\n checker = map(contains, check_vars, check_values)\n \n\n Then, when checking for the values (in the original order), use  next() : \n\n if next(checker)  # Checks for 0\n    # Do something\n    pass\nelif next(checker)  # Checks for 1\n    # Do something\n    pass\n \n\n etc... \n\n This has an advantage over the  lambda x: x in (variables)  because  operator  is an inbuilt module and is faster and more efficient than using  lambda  which has to create a custom in-place function. \n\n Another option for checking if there is a non-zero (or False) value in a list: \n\n not (x and y and z)\n \n\n Equivalent: \n\n not all((x, y, z))\n \n    ", "date_posted": "2014-06-05 11:31:39Z", "upvote": "\r\n            33\r\n        ", "accepted": "No", "user": {"stack_user_id": "3551468", "name": "GuiltyDolphin", "reputation_score": "738"}, "answer_comments": [{"stack_answer_id": "24043508", "stack_answer_comment_id": "37069084", "comment_content": "This doesn't answer the OP's question.  It only covers the first case in the provided example.", "user_id": "None"}]}, {"stack_answer_id": "30742519", "answer_content": "\r\n Set is the good approach here, because it orders the variables, what seems to be your goal here.  {z,y,x}  is  {0,1,3}  whatever the order of the parameters. \n\n >>> [\"cdef\"[i] for i in {z,x,y}]\n['c', 'd', 'f']\n \n\n This way, the whole solution is O(n). \n    ", "date_posted": "2018-04-01 13:10:46Z", "upvote": "\r\n            31\r\n        ", "accepted": "No", "user": {"stack_user_id": "4016285", "name": "B. M.", "reputation_score": "17.6k"}, "answer_comments": []}, {"stack_answer_id": "27921870", "answer_content": "\r\n I think this will handle it better: \n\n my_dict = {0: \"c\", 1: \"d\", 2: \"e\", 3: \"f\"}\n\ndef validate(x, y, z):\n    for ele in [x, y, z]:\n        if ele in my_dict.keys():\n            return my_dict[ele]\n \n\n Output: \n\n print validate(0, 8, 9)\nc\nprint validate(9, 8, 9)\nNone\nprint validate(9, 8, 2)\ne\n \n    ", "date_posted": "2015-02-10 14:58:02Z", "upvote": "\r\n            30\r\n        ", "accepted": "No", "user": {"stack_user_id": "296460", "name": "shuttle87", "reputation_score": "14.9k"}, "answer_comments": []}, {"stack_answer_id": "29552841", "answer_content": "\r\n If you want to use if, else statements following is another solution: \n\n myList = []\naList = [0, 1, 3]\n\nfor l in aList:\n    if l==0: myList.append('c')\n    elif l==1: myList.append('d')\n    elif l==2: myList.append('e')\n    elif l==3: myList.append('f')\n\nprint(myList)\n \n    ", "date_posted": "2018-09-04 03:53:17Z", "upvote": "\r\n            30\r\n        ", "accepted": "No", "user": {"stack_user_id": "1794144", "name": "Vishvajit Pathak", "reputation_score": "2,963"}, "answer_comments": []}, {"stack_answer_id": "39427752", "answer_content": "\r\n All of the excellent answers provided here concentrate on the specific requirement of the original poster and concentrate on the  if 1 in {x,y,z}  solution put forward by Martijn Pieters. \nWhat they ignore is the broader implication of the question: \n How do I test one variable against multiple values? \nThe solution provided will not work for partial hits if using strings for example: \nTest if the string \"Wild\" is in multiple values \n\n >>> x = \"Wild things\"\n>>> y = \"throttle it back\"\n>>> z = \"in the beginning\"\n>>> if \"Wild\" in {x, y, z}: print (True)\n... \n \n\n or \n\n >>> x = \"Wild things\"\n>>> y = \"throttle it back\"\n>>> z = \"in the beginning\"\n>>> if \"Wild\" in [x, y, z]: print (True)\n... \n \n\n for this scenario it's easiest to convert to a string \n\n >>> [x, y, z]\n['Wild things', 'throttle it back', 'in the beginning']\n>>> {x, y, z}\n{'in the beginning', 'throttle it back', 'Wild things'}\n>>> \n\n>>> if \"Wild\" in str([x, y, z]): print (True)\n... \nTrue\n>>> if \"Wild\" in str({x, y, z}): print (True)\n... \nTrue\n \n\n It should be noted however, as mentioned by  @codeforester , that word boundries are lost with this method, as in:     \n\n >>> x=['Wild things', 'throttle it back', 'in the beginning']\n>>> if \"rot\" in str(x): print(True)\n... \nTrue\n \n\n the 3 letters  rot  do exist in combination in the list but not as an individual word. Testing for \" rot \" would fail but if one of the list items were \"rot in hell\", that would fail as well. \nThe upshot being, be careful with your search criteria if using this method and be aware that it does have this limitation. \n    ", "date_posted": "2018-09-04 11:59:05Z", "upvote": "\r\n            30\r\n        ", "accepted": "No", "user": {"stack_user_id": "1794144", "name": "Vishvajit Pathak", "reputation_score": "2,963"}, "answer_comments": []}, {"stack_answer_id": "28756031", "answer_content": "\r\n d = {0:'c', 1:'d', 2:'e', 3: 'f'}\nx, y, z = (0, 1, 3)\nprint [v for (k,v) in d.items() if x==k or y==k or z==k]\n \n    ", "date_posted": "2015-02-27 01:48:29Z", "upvote": "\r\n            26\r\n        ", "accepted": "No", "user": {"stack_user_id": "4596008", "name": "Saksham Varma", "reputation_score": "2,072"}, "answer_comments": []}, {"stack_answer_id": "31109647", "answer_content": "\r\n This code may be helpful \n\n L ={x, y, z}\nT= ((0,\"c\"),(1,\"d\"),(2,\"e\"),(3,\"f\"),)\nList2=[]\nfor t in T :\nif t[0] in L :\n    List2.append(t[1])\n    break;\n \n    ", "date_posted": "2015-06-29 07:03:58Z", "upvote": "\r\n            26\r\n        ", "accepted": "No", "user": {"stack_user_id": "4621874", "name": "michael zxc858", "reputation_score": "385"}, "answer_comments": []}, {"stack_answer_id": "53587823", "answer_content": "\r\n You can try the method shown below. In this method, you will have the freedom to specify/input the number of variables that you wish to enter. \n\n mydict = {0:\"c\", 1:\"d\", 2:\"e\", 3:\"f\"}\nmylist= []\n\nnum_var = int(raw_input(\"How many variables? \")) #Enter 3 when asked for input.\n\nfor i in range(num_var): \n    ''' Enter 0 as first input, 1 as second input and 3 as third input.'''\n    globals()['var'+str('i').zfill(3)] = int(raw_input(\"Enter an integer between 0 and 3 \"))\n    mylist += mydict[globals()['var'+str('i').zfill(3)]]\n\nprint mylist\n>>> ['c', 'd', 'f']\n \n    ", "date_posted": "2018-12-03 05:13:18Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "10626090", "name": "Siddharth Satpathy", "reputation_score": "2,513"}, "answer_comments": []}, {"stack_answer_id": "44363221", "answer_content": "\r\n One line solution: \n\n mylist = [{0: 'c', 1: 'd', 2: 'e', 3: 'f'}[i] for i in [0, 1, 2, 3] if i in (x, y, z)]\n \n\n Or: \n\n mylist = ['cdef'[i] for i in range(4) if i in (x, y, z)]\n \n    ", "date_posted": "2017-06-05 06:50:28Z", "upvote": "\r\n            10\r\n        ", "accepted": "No", "user": {"stack_user_id": "3857234", "name": "Vinayak Kaniyarakkal", "reputation_score": "1,052"}, "answer_comments": []}, {"stack_answer_id": "54736001", "answer_content": "\r\n Maybe you need direct formula for output bits set. \n\n x=0 or y=0 or z=0   is equivalent to x*y*z = 0\n\nx=1 or y=1 or z=1   is equivalent to (x-1)*(y-1)*(z-1)=0\n\nx=2 or y=2 or z=2   is equivalent to (x-2)*(y-2)*(z-2)=0\n \n\n Let's map to bits:  'c':1 'd':0xb10 'e':0xb100 'f':0xb1000 \n\n Relation of isc (is 'c'): \n\n if xyz=0 then isc=1 else isc=0\n \n\n Use math if formula  https://youtu.be/KAdKCgBGK0k?list=PLnI9xbPdZUAmUL8htSl6vToPQRRN3hhFp&t=315 \n\n [c]:  (xyz=0 and isc=1) or (((xyz=0 and isc=1) or (isc=0)) and (isc=0)) \n\n [d]:  ((x-1)(y-1)(z-1)=0 and isc=2) or (((xyz=0 and isd=2) or (isc=0)) and (isc=0)) \n\n ... \n\n Connect these formulas by following logic: \n\n \n logic  and  is the sum of squares of equations \n logic  or  is the product of equations \n \n\n and you'll have a total equation\nexpress sum and you have total formula of sum \n\n then sum&1 is c, sum&2 is d, sum&4 is e, sum&5 is f \n\n After this you may form predefined array where index of string elements would correspond to ready string. \n\n array[sum]  gives you the string. \n    ", "date_posted": "2019-04-10 17:49:04Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "874188", "name": "tripleee", "reputation_score": "162k"}, "answer_comments": []}, {"stack_answer_id": "51701671", "answer_content": "\r\n The most pythonic way of representing your pseudo-code in Python would be: \n x = 0\ny = 1\nz = 3\nmylist = []\n\nif any(v == 0 for v in (x, y, z)):\n    mylist.append(\"c\")\nif any(v == 1 for v in (x, y, z)):\n    mylist.append(\"d\")\nif any(v == 2 for v in (x, y, z)):\n    mylist.append(\"e\")\nif any(v == 3 for v in (x, y, z)):\n    mylist.append(\"f\")\n \n    ", "date_posted": "2020-07-11 00:08:50Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "1296256", "name": "rsalmei", "reputation_score": "2,573"}, "answer_comments": [{"stack_answer_id": "51701671", "stack_answer_comment_id": "98608899", "comment_content": "This approach is more universal than ` if 2 in (x, y, z): mylist.append('e')` because allows arbitrary comparisons (e.g. ", "user_id": "None"}]}, {"stack_answer_id": "53173901", "answer_content": "\r\n It can be done easily as  \n\n for value in [var1,var2,var3]:\n     li.append(\"targetValue\")\n \n    ", "date_posted": "2018-11-06 14:26:24Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "6489768", "name": "Seeni", "reputation_score": "1,384"}, "answer_comments": []}, {"stack_answer_id": "52416636", "answer_content": "\r\n To test multiple variables with one single value:  if 1 in {a,b,c}: \n\n To test multiple values with one variable:  if a in {1, 2, 3}: \n    ", "date_posted": "2018-09-20 02:18:55Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "4813600", "name": "alamin", "reputation_score": "2,269"}, "answer_comments": []}, {"stack_answer_id": "52036618", "answer_content": "\r\n Looks like you're building some kind of Caesar cipher. \n\n A much more generalized approach is this: \n\n input_values = (0, 1, 3)\norigo = ord('c')\n[chr(val + origo) for val in inputs]\n \n\n outputs \n\n ['c', 'd', 'f']\n \n\n Not sure if it's a desired side effect of your code, but the order of your output will always be sorted. \n\n If this is what you want, the final line can be changed to: \n\n sorted([chr(val + origo) for val in inputs])\n \n    ", "date_posted": "2018-08-27 09:45:00Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "3730397", "name": "firelynx", "reputation_score": "29.2k"}, "answer_comments": []}, {"stack_answer_id": "51618459", "answer_content": "\r\n You can use dictionary : \n\n x = 0\ny = 1\nz = 3\nlist=[]\ndict = {0: 'c', 1: 'd', 2: 'e', 3: 'f'}\nif x in dict:\n    list.append(dict[x])\nelse:\n    pass\n\nif y in dict:\n    list.append(dict[y])\nelse:\n    pass\nif z in dict:\n    list.append(dict[z])\nelse:\n    pass\n\nprint list\n \n    ", "date_posted": "2018-07-31 16:54:00Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "9010283", "name": "Rohit Gawas", "reputation_score": "237"}, "answer_comments": [{"stack_answer_id": "51618459", "stack_answer_comment_id": "96299106", "comment_content": "This may append same more then once this. Set?", "user_id": "None"}]}, {"stack_answer_id": "58341108", "answer_content": "\r\n Without dict, try this solution: \n\n x, y, z = 0, 1, 3    \noffset = ord('c')\n[chr(i + offset) for i in (x,y,z)]\n \n\n and gives: \n\n ['c', 'd', 'f']\n \n    ", "date_posted": "2019-10-11 12:17:15Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "9302488", "name": "Massifox", "reputation_score": "3,921"}, "answer_comments": []}, {"stack_answer_id": "55543926", "answer_content": "\r\n This will help you. \n\n def test_fun(val):\n    x = 0\n    y = 1\n    z = 2\n    myList = []\n    if val in (x, y, z) and val == 0:\n        myList.append(\"C\")\n    if val in (x, y, z) and val == 1:\n        myList.append(\"D\")\n    if val in (x, y, z) and val == 2:\n        myList.append(\"E\")\n\ntest_fun(2);\n \n    ", "date_posted": "2019-04-08 05:18:38Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "9896794", "name": "Karan Shah", "reputation_score": "91"}, "answer_comments": []}, {"stack_answer_id": "57859331", "answer_content": "\r\n You can unite this \n\n x = 0\ny = 1\nz = 3\n \n\n in one variable. \n\n In [1]: xyz = (0,1,3,) \nIn [2]: mylist = []\n \n\n Change our conditions as: \n\n In [3]: if 0 in xyz: \n    ...:     mylist.append(\"c\") \n    ...: if 1 in xyz: \n    ...:     mylist.append(\"d\") \n    ...: if 2 in xyz: \n    ...:     mylist.append(\"e\") \n    ...: if 3 in xyz:  \n    ...:     mylist.append(\"f\") \n \n\n Output: \n\n In [21]: mylist                                                                                \nOut[21]: ['c', 'd', 'f']\n \n    ", "date_posted": "2019-09-09 18:23:24Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "9093112", "name": "Serhii", "reputation_score": "1,033"}, "answer_comments": []}, {"stack_answer_id": "63811246", "answer_content": "\r\n you can develop it through two ways \n     def compareVariables(x,y,z):\n        mylist = []\n        if x==0 or y==0 or z==0:\n            mylist.append('c')\n        if  x==1 or y==1 or z==1:\n            mylist.append('d')\n        if  x==2 or y==2 or z==2:\n            mylist.append('e')\n        if  x==3 or y==3 or z==3:\n            mylist.append('f')\n        else:\n            print(\"wrong input value!\")\n        print('first:',mylist)\n\n        compareVariables(1, 3, 2)\n \n Or \n     def compareVariables(x,y,z):\n        mylist = []\n        if 0 in (x,y,z):\n             mylist.append('c')\n        if 1 in (x,y,z):\n             mylist.append('d')\n        if 2 in (x,y,z):\n             mylist.append('e')\n        if 3 in (x,y,z):\n             mylist.append('f')\n        else:\n             print(\"wrong input value!\")\n        print('second:',mylist)\n\n        compareVariables(1, 3, 2)\n \n    ", "date_posted": "2020-09-24 15:21:04Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "2308683", "name": "OneCricketeer", "reputation_score": "157k"}, "answer_comments": []}, {"stack_answer_id": "67049356", "answer_content": "\r\n The  or  does not work like that, as  explained by this answer . \n While the generic answer would be use \n if 0 in (x, y, z):\n    ...\n \n this is not the best one for the  specific  problem. In your case you're doing  repeated tests , therefore it is worthwhile to compose a  set  of these variables: \n values = {x, y, z}\n\nif 0 in values:\n    mylist.append(\"c\")\n\nif 1 in values:\n    mylist.append(\"d\")\n \n We can simplify this using a dictionary - this will result in the same values: \n mappings = {0: \"c\", 1: \"d\", ...}\nfor k in mappings:\n    if k in values:\n        mylist.append(mappings[k])\n \n Or if the ordering of the  mylist  is arbitrary, you can loop over the  values  instead and match them to the mappings: \n mappings = {0: \"c\", 1: \"d\", ...}\nfor v in (x, y, z):\n    if v in mappings:\n        mylist.append(mappings[v])\n \n    ", "date_posted": "2021-04-11 19:30:17Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "918959", "name": "Antti Haapala -- \u0421\u043b\u0430\u0432\u0430 \u0423\u043a\u0440\u0430\u0457\u043d\u0456", "reputation_score": "125k"}, "answer_comments": []}, {"stack_answer_id": "58728816", "answer_content": "\r\n Problem \n\n While the pattern for testing multiple values \n\n >>> 2 in {1, 2, 3}\nTrue\n>>> 5 in {1, 2, 3}\nFalse\n \n\n is very readable and is working in many situation, there is one pitfall: \n\n >>> 0 in {True, False}\nTrue\n \n\n But we want to have \n\n >>> (0 is True) or (0 is False)\nFalse\n \n\n Solution \n\n One generalization of the previous expression is based on the answer from  ytpillai : \n\n >>> any([0 is True, 0 is False])\nFalse\n \n\n which can be written as \n\n >>> any(0 is item for item in (True, False))\nFalse\n \n\n While this expression returns the right result it is not as readable as the first expression :-( \n    ", "date_posted": "2019-11-06 11:20:35Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "5599281", "name": "fhgd", "reputation_score": "392"}, "answer_comments": []}, {"stack_answer_id": "66398859", "answer_content": "\r\n Here is one more way to do it: \n x = 0\ny = 1\nz = 3\nmylist = []\n\nif any(i in [0] for i in[x,y,z]):\n    mylist.append(\"c\")\nif any(i in [1] for i in[x,y,z]):\n    mylist.append(\"d\")\nif any(i in [2] for i in[x,y,z]):\n    mylist.append(\"e\")\nif any(i in [3] for i in[x,y,z]):\n    mylist.append(\"f\")\n \n It is a mix of  list comprehension  and  any  keyword. \n    ", "date_posted": "2021-04-12 01:33:17Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "15127315", "name": "Abhishek Kumar Saw", "reputation_score": "349"}, "answer_comments": [{"stack_answer_id": "66398859", "stack_answer_comment_id": "118539367", "comment_content": "Why ", "user_id": "None"}, {"stack_answer_id": "66398859", "stack_answer_comment_id": "118547903", "comment_content": "For a single comparison like in this question, you can use \"==\" but if you want multiple comparisons with multiple variables, then you can use the \"in\" operator like: if any(i in [0,5,4,9,7] for i in[x,y,z] )", "user_id": "None"}]}, {"stack_answer_id": "70816486", "answer_content": "\r\n usage without if example: \n x,y,z = 0,1,3\nvalues = {0:\"c\",1:\"d\",2:\"e\",3:\"f\"} # => as if usage\nmy_list = [values[i] for i in (x,y,z)]\n\nprint(my_list)\n \n    ", "date_posted": "2022-01-22 19:40:34Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "15343205", "name": "SimoN SavioR", "reputation_score": "469"}, "answer_comments": []}, {"stack_answer_id": "72422109", "answer_content": "\r\n FIRST, A CORRECTION TO THE  OR  CONDITIONAL: \n You need to say: \n if x == 0 or y == 0 or z == 0:\n \n The reason is that \"or\" splits up the condition into separate logical parts. The way your original statement was written, those parts were: \n x\ny\nz == 0   // or 1, 2, 3 depending on the if statement\n \n The last part was fine --- checking to see if z == 0, for instance --- but the first two parts just said essentially  if x  and  if y . Since integers always evaluate to  True  unless they're 0, that means the first part of your condition was always  True  when  x  or  y  didn't equal 0 (which in the case of y was always, since you had  y = 1 , causing your whole condition (because of how  OR  works) to always be  True . \n To avoid that, you need to make sure all parts of your condition (each side of the  OR ) make sense on their own (you can do that by pretending that the other side(s) of the  OR  statement doesn't exist). That's how you can confirm whether or not your  OR  condition is correctly defined. \n You would write the statements individually like so: \n if x == 0\nif y == 0\nif z == 0\n \n which means the correct mergin with the  OR  keyword would be: \n if x == 0 or y == 0 or z == 0\n \n SECOND, HOW TO SOLVE THE PROBLEM: \n You're basically wanting to check to see if any of the variables match a given integer and if so, assign it a letter that matches it in a one-to-one mapping. You want to do that for a certain list of integers so that the output is a list of letters. You'd do that like this: \n def func(x, y, z):\n\n    result = []\n\n    for integer, letter in zip([0, 1, 2, 3], ['c', 'd', 'e', 'f']):\n        if x == integer or y == integer or z == integer:\n            result.append(letter)\n            \n    return result\n        \n \n Similarly, you could use LIST COMPREHENSION to achieve the same result faster: \n def func(x, y, z):\n\n    return [ \n                letter \n                for integer, letter in zip([0, 1, 2, 3], ['c', 'd', 'e', 'f'])\n                if x == integer or y == integer or z == integer\n           ]\n    \n    \n \n    ", "date_posted": "2022-05-29 08:35:13Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "5026136", "name": "Elliptica", "reputation_score": "3,266"}, "answer_comments": []}, {"stack_answer_id": "72539339", "answer_content": "\r\n #selection\n: a=np.array([0,1,3])                                                                                                                                                 \n\n#options\n: np.diag(['c','d','e','f']) \narray([['c', '', '', ''],\n       ['', 'd', '', ''],\n       ['', '', 'e', ''],\n       ['', '', '', 'f']], dtype='<U1')\n \n now we can use  a  as [row,col] selector, which acts as if any(...) condition : \n #list of options[sel,sel]\n: np.diag(['c','d','e','f'])[a,a]                                                                                                                                     \n\n array(['c', 'd', 'f'], dtype='<U1')\n \n    ", "date_posted": "2022-07-18 23:51:34Z", "upvote": "\r\n            -1\r\n        ", "accepted": "No", "user": {"stack_user_id": "1019129", "name": "sten", "reputation_score": "6,476"}, "answer_comments": [{"stack_answer_id": "72539339", "stack_answer_comment_id": "129689739", "comment_content": "I don't think the question is asking about numpy", "user_id": "None"}]}], "user": {"stack_user_id": "1877442", "name": "user1877442", "reputation_score": "8,201"}, "question_comments": [{"stack_question_id": "15112125", "stack_question_comment_id": "82285672", "comment_content": "use ", "user_id": "None"}, {"stack_question_id": "15112125", "stack_question_comment_id": "88379334", "comment_content": "When you want to evaluate a list of statements in a any/all manner you can use ", "user_id": "None"}, {"stack_question_id": "15112125", "stack_question_comment_id": "97914247", "comment_content": "This question is a very popular duplicate target, but I think it's suboptimal for that purpose. Most people try to do something like ", "user_id": "None"}, {"stack_question_id": "15112125", "stack_question_comment_id": "97914372", "comment_content": "Take extra care when comparing to \"falsey\" values like ", "user_id": "None"}, {"stack_question_id": "15112125", "stack_question_comment_id": "105448818", "comment_content": "For the opposite, see ", "user_id": "None"}]},
{"stack_question_id": "20449427", "question_title": "How can I read inputs as numbers?", "question_content": "\r\n                Why are x and y strings instead of ints in the below code?\n\n(Note: in Python 2.x use raw_input(). In Python 3.x use input(). raw_input() was renamed to input() in Python 3.x)\n\nplay = True\n\nwhile play:\n...\r\n", "question_url": "/questions/20449427/how-can-i-read-inputs-as-numbers", "date_posted": "Dec 8, 2013 at 3:08", "upvote": "2", "view": "1", "tags": ["python", "python-3.x", "python-2.7", "input", "int"], "answers_count": "1", "answers": [{"stack_answer_id": "20449433", "answer_content": "\r\n Solution \n Since Python 3,  input  returns a string which you have to explicitly convert to  int s, with  int , like this \n x = int(input(\"Enter a number: \"))\ny = int(input(\"Enter a number: \"))\n \n You can accept numbers of any base and convert them directly to base-10 with the  int  function, like this \n >>> data = int(input(\"Enter a number: \"), 8)\nEnter a number: 777\n>>> data\n511\n>>> data = int(input(\"Enter a number: \"), 16)\nEnter a number: FFFF\n>>> data\n65535\n>>> data = int(input(\"Enter a number: \"), 2)\nEnter a number: 10101010101\n>>> data\n1365\n \n The second parameter tells what is the base of the numbers entered and then internally it understands and converts it. If the entered data is wrong it will throw a  ValueError . \n >>> data = int(input(\"Enter a number: \"), 2)\nEnter a number: 1234\nTraceback (most recent call last):\n  File \"<input>\", line 1, in <module>\nValueError: invalid literal for int() with base 2: '1234'\n \n For values that can have a fractional component, the type would be  float  rather than  int : \n x = float(input(\"Enter a number:\"))\n \n Differences between Python 2 and 3 \n Summary \n \n Python 2's  input  function evaluated the received data, converting it to an integer implicitly (read the next section to understand the implication), but Python 3's  input  function does not do that anymore. \n Python 2's equivalent of Python 3's  input  is the  raw_input  function. \n \n Python 2.x \n There were two functions to get user input, called  input  and  raw_input . The difference between them is,  raw_input  doesn't evaluate the data and returns as it is, in string form. But,  input  will evaluate whatever you entered and the result of evaluation will be returned. For example, \n >>> import sys\n>>> sys.version\n'2.7.6 (default, Mar 22 2014, 22:59:56) \\n[GCC 4.8.2]'\n>>> data = input(\"Enter a number: \")\nEnter a number: 5 + 17\n>>> data, type(data)\n(22, <type 'int'>)\n \n The data  5 + 17  is evaluated and the result is  22 . When it evaluates the expression  5 + 17 , it detects that you are adding two numbers and so the result will also be of the same  int  type. So, the type conversion is done for free and  22  is returned as the result of  input  and stored in  data  variable. You can think of  input  as the  raw_input  composed with an  eval  call. \n >>> data = eval(raw_input(\"Enter a number: \"))\nEnter a number: 5 + 17\n>>> data, type(data)\n(22, <type 'int'>)\n \n Note:  you should be careful when you are using  input  in Python 2.x. I explained why one should be careful when using it, in  this answer . \n But,  raw_input  doesn't evaluate the input and returns as it is, as a string. \n >>> import sys\n>>> sys.version\n'2.7.6 (default, Mar 22 2014, 22:59:56) \\n[GCC 4.8.2]'\n>>> data = raw_input(\"Enter a number: \")\nEnter a number: 5 + 17\n>>> data, type(data)\n('5 + 17', <type 'str'>)\n \n Python 3.x \n Python 3.x's  input  and Python 2.x's  raw_input  are similar and  raw_input  is not available in Python 3.x. \n >>> import sys\n>>> sys.version\n'3.4.0 (default, Apr 11 2014, 13:05:11) \\n[GCC 4.8.2]'\n>>> data = input(\"Enter a number: \")\nEnter a number: 5 + 17\n>>> data, type(data)\n('5 + 17', <class 'str'>)\n \n    ", "date_posted": "2021-01-28 13:45:16Z", "upvote": "\r\n            376\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "4621513", "name": "mkrieger1", "reputation_score": "15.4k"}, "answer_comments": [{"stack_answer_id": "20449433", "stack_answer_comment_id": "60632844", "comment_content": "Is there any other way, like a function or something so that we dont need to convert to int in 3.x other than doing explicit conversion to int??", "user_id": "None"}, {"stack_answer_id": "20449433", "stack_answer_comment_id": "60633361", "comment_content": "@ShreyanMehta ", "user_id": "None"}, {"stack_answer_id": "20449433", "stack_answer_comment_id": "86398645", "comment_content": "@thefourtheye at least use ", "user_id": "None"}]}, {"stack_answer_id": "20449436", "answer_content": "\r\n In Python 3.x,  raw_input  was renamed to  input  and the Python 2.x  input  was removed.   \n\n This means that, just like  raw_input ,  input  in Python 3.x always returns a string object. \n\n To fix the problem, you need to explicitly make those inputs into integers by putting them in  int : \n\n x = int(input(\"Enter a number: \"))\ny = int(input(\"Enter a number: \"))\n \n    ", "date_posted": "2019-05-17 12:08:00Z", "upvote": "\r\n            50\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": []}, {"stack_answer_id": "26855555", "answer_content": "\r\n For multiple integer in a single line,  map  might be better. \n\n arr = map(int, raw_input().split())\n \n\n If the number is already known, (like 2 integers), you can use \n\n num1, num2 = map(int, raw_input().split())\n \n    ", "date_posted": "2019-05-17 12:11:57Z", "upvote": "\r\n            34\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": []}, {"stack_answer_id": "20449435", "answer_content": "\r\n input()  (Python 3) and  raw_input()  (Python 2)  always  return strings. Convert the result to integer explicitly with  int() . \n\n x = int(input(\"Enter a number: \"))\ny = int(input(\"Enter a number: \"))\n \n    ", "date_posted": "2019-05-17 12:12:35Z", "upvote": "\r\n            18\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": []}, {"stack_answer_id": "24621885", "answer_content": "\r\n Multiple questions require multiple integers to be entered on a single line. The best way is to enter the entire string of numbers line by line and split them into integers. Here is the Python 3 version: \n a = []\np = input()\np = p.split()      \nfor i in p:\n    a.append(int(i))\n \n You can also use list comprehensions: \n p = input().split(\"whatever the seperator is\")\n \n To convert all input from string to int we do the following: \n x = [int(i) for i in p]\nprint(x, end=' ')\n \n List elements should be printed in straight lines. \n    ", "date_posted": "2022-03-18 02:20:10Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "3750257", "name": "pppery", "reputation_score": "3,606"}, "answer_comments": []}, {"stack_answer_id": "36679044", "answer_content": "\r\n Convert to integers: \n\n my_number = int(input(\"enter the number\"))\n \n\n Similarly for floating point numbers: \n\n my_decimalnumber = float(input(\"enter the number\"))\n \n    ", "date_posted": "2017-01-26 04:28:51Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "885922", "name": "xlm", "reputation_score": "5,754"}, "answer_comments": []}, {"stack_answer_id": "51676769", "answer_content": "\r\n n=int(input())\nfor i in range(n):\n    n=input()\n    n=int(n)\n    arr1=list(map(int,input().split()))\n \n\n the for loop shall run 'n' number of times . the second 'n' is the length of the array.\nthe last statement maps the integers to a list and takes input in space separated form .\nyou can also return the array at the end of for loop. \n    ", "date_posted": "2018-08-03 16:30:31Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "6481925", "name": "ravi tanwar", "reputation_score": "572"}, "answer_comments": []}, {"stack_answer_id": "23828100", "answer_content": "\r\n I encountered a problem of taking integer input while solving a problem on  CodeChef , where two integers - separated by space - should be read from one line. \n While  int(input())  is sufficient for a single integer, I did not find a direct way to input two integers.  I tried this: \n num = input()\nnum1 = 0\nnum2 = 0\n\nfor i in range(len(num)):\n    if num[i] == ' ':\n        break\n\nnum1 = int(num[:i])\nnum2 = int(num[i+1:])\n \n Now I use  num1  and  num2  as integers. \n    ", "date_posted": "2021-12-02 02:35:17Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "10794031", "name": "bad_coder", "reputation_score": "9,051"}, "answer_comments": [{"stack_answer_id": "23828100", "stack_answer_comment_id": "36673308", "comment_content": "This looks very interesting.  However, isn't ", "user_id": "None"}, {"stack_answer_id": "23828100", "stack_answer_comment_id": "36696794", "comment_content": " When a loop is exited, the value of the index variable (here, ", "user_id": "None"}, {"stack_answer_id": "23828100", "stack_answer_comment_id": "89589223", "comment_content": "For this kind of input manipulation, you can either ", "user_id": "None"}]}, {"stack_answer_id": "31134209", "answer_content": "\r\n def dbz():\n    try:\n        r = raw_input(\"Enter number:\")\n        if r.isdigit():\n            i = int(raw_input(\"Enter divident:\"))\n            d = int(r)/i\n            print \"O/p is -:\",d\n        else:\n            print \"Not a number\"\n    except Exception ,e:\n        print \"Program halted incorrect data entered\",type(e)\ndbz()\n\nOr \n\nnum = input(\"Enter Number:\")#\"input\" will accept only numbers\n \n    ", "date_posted": "2019-04-04 08:47:19Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "4628770", "name": "Sanyal", "reputation_score": "836"}, "answer_comments": []}, {"stack_answer_id": "40764414", "answer_content": "\r\n While in your example,  int(input(...))  does the trick in any case,  python-future 's  builtins.input  is worth consideration since that makes sure your code works for both Python 2 and 3  and  disables Python2's default behaviour of  input  trying to be \"clever\" about the input data type ( builtins.input  basically just behaves like  raw_input ). \n    ", "date_posted": "2016-11-23 12:19:52Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "321973", "name": "Tobias Kienzler", "reputation_score": "24.1k"}, "answer_comments": []}], "user": {"stack_user_id": null, "name": null, "reputation_score": 0}, "question_comments": [{"stack_question_id": "20449427", "stack_question_comment_id": "91590863", "comment_content": " ", "user_id": "None"}]},
{"stack_question_id": "1207406", "question_title": "How to remove items from a list while iterating?", "question_content": "\r\n                I'm iterating over a list of tuples in Python, and am attempting to remove them if they meet certain criteria. \n\nfor tup in somelist:\n    if determine(tup):\n         code_to_remove_tup\r\nWhat should I ...\r\n", "question_url": "/questions/1207406/how-to-remove-items-from-a-list-while-iterating", "date_posted": "Jul 30, 2009 at 15:36", "upvote": "9", "view": "7", "tags": ["python", "iteration"], "answers_count": "2", "answers": [{"stack_answer_id": "1207461", "answer_content": "\r\n You can use a list comprehension to create a new list containing only the elements you don't want to remove: \n somelist = [x for x in somelist if not determine(x)]\n \n Or, by assigning to the slice  somelist[:] , you can mutate the existing list to contain only the items you want: \n somelist[:] = [x for x in somelist if not determine(x)]\n \n This approach could be useful if there are other references to  somelist  that need to reflect the changes. \n Instead of a comprehension, you could also use  itertools . In Python 2: \n from itertools import ifilterfalse\nsomelist[:] = ifilterfalse(determine, somelist)\n \n Or in Python 3: \n from itertools import filterfalse\nsomelist[:] = filterfalse(determine, somelist)\n \n    ", "date_posted": "2021-03-19 21:52:42Z", "upvote": "\r\n            1035\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "2357112", "name": "user2357112", "reputation_score": "240k"}, "answer_comments": [{"stack_answer_id": "1207461", "stack_answer_comment_id": "6561137", "comment_content": "Can you make it faster if you know only a few will be deleted, i.e., only delete those and leave the others in-place rather than re-writing them?", "user_id": "None"}, {"stack_answer_id": "1207461", "stack_answer_comment_id": "42444805", "comment_content": "What if my list is huge and can't afford making a copy?", "user_id": "None"}, {"stack_answer_id": "1207461", "stack_answer_comment_id": "48015591", "comment_content": "@jpcgt You should use ", "user_id": "None"}, {"stack_answer_id": "1207461", "stack_answer_comment_id": "48333544", "comment_content": "@RostislavKondratenko: ", "user_id": "None"}, {"stack_answer_id": "1207461", "stack_answer_comment_id": "91913010", "comment_content": "Would you care to explain what the differences are between assigning the list comprehension to the list and list clone please? Wouldn't the original list ", "user_id": "None"}]}, {"stack_answer_id": "1208792", "answer_content": "\r\n The answers suggesting list comprehensions are ALMOST correct -- except that they build a completely new list and then give it the same name the old list as, they do NOT modify the old list in place. That's different from what you'd be doing by selective removal, as in  @Lennart's suggestion  -- it's faster, but if your list is accessed via multiple references the fact that you're just reseating one of the references and NOT altering the list object itself can lead to subtle, disastrous bugs. \n\n Fortunately, it's extremely easy to get both the speed of list comprehensions AND the required semantics of in-place alteration -- just code: \n\n somelist[:] = [tup for tup in somelist if determine(tup)]\n \n\n Note the subtle difference with other answers: this one is NOT assigning to a barename - it's assigning to a list slice that just happens to be the entire list, thereby replacing the list  contents   within the same Python list object , rather than just reseating one reference (from previous list object to new list object) like the other answers. \n    ", "date_posted": "2019-05-17 06:05:40Z", "upvote": "\r\n            674\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": [{"stack_answer_id": "1208792", "stack_answer_comment_id": "6156944", "comment_content": "How do I do the same sliced assignment with a dict? In Python 2.6?", "user_id": "None"}, {"stack_answer_id": "1208792", "stack_answer_comment_id": "6269193", "comment_content": "@Paul: Since dicts are unordered, slices are meaningless for dicts.  If your want to replace the contents of dict ", "user_id": "None"}, {"stack_answer_id": "1208792", "stack_answer_comment_id": "8322580", "comment_content": "Why can 'reseating' one of the references by replacing what the variable refers to cause bugs?  It seems like that would only be a potential problem in multi-threaded applications, not single-threaded.", "user_id": "None"}, {"stack_answer_id": "1208792", "stack_answer_comment_id": "9992070", "comment_content": "@Derek ", "user_id": "None"}, {"stack_answer_id": "1208792", "stack_answer_comment_id": "64106747", "comment_content": "in fact, using ", "user_id": "None"}]}, {"stack_answer_id": "1207427", "answer_content": "\r\n You need to take a copy of the list and iterate over it first, or the iteration will fail with what may be unexpected results. \n\n For example (depends on what type of list): \n\n for tup in somelist[:]:\n    etc....\n \n\n An example: \n\n >>> somelist = range(10)\n>>> for x in somelist:\n...     somelist.remove(x)\n>>> somelist\n[1, 3, 5, 7, 9]\n\n>>> somelist = range(10)\n>>> for x in somelist[:]:\n...     somelist.remove(x)\n>>> somelist\n[]\n \n    ", "date_posted": "2019-12-02 14:50:05Z", "upvote": "\r\n            376\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "1207427", "stack_answer_comment_id": "37528195", "comment_content": "@Zen Because the second one iterates over a copy of the list. So when you modify the original list, you do not modify the copy that you iterate over.", "user_id": "None"}, {"stack_answer_id": "1207427", "stack_answer_comment_id": "44985743", "comment_content": "What's better in doing somelist[:] compared to list(somelist) ?", "user_id": "None"}, {"stack_answer_id": "1207427", "stack_answer_comment_id": "45032005", "comment_content": " will convert an iterable into a list. ", "user_id": "None"}, {"stack_answer_id": "1207427", "stack_answer_comment_id": "45258605", "comment_content": "Note to anyone reading this, this is VERY slow for lists. ", "user_id": "None"}, {"stack_answer_id": "1207427", "stack_answer_comment_id": "64982024", "comment_content": "Big O time doesn't matter when dealing with lists of only a dozen items.  Often clear and simple for future programmers to understand is far more valuable than performance.", "user_id": "None"}]}, {"stack_answer_id": "1207485", "answer_content": "\r\n for i in range(len(somelist) - 1, -1, -1):\n    if some_condition(somelist, i):\n        del somelist[i]\n \n\n You need to go backwards otherwise it's a bit like sawing off the tree-branch that you are sitting on :-) \n\n Python 2 users: replace  range  by  xrange  to avoid creating a hardcoded list \n    ", "date_posted": "2018-10-26 15:10:03Z", "upvote": "\r\n            174\r\n        ", "accepted": "No", "user": {"stack_user_id": "6451573", "name": "Jean-Fran\u00e7ois Fabre", "reputation_score": "133k"}, "answer_comments": [{"stack_answer_id": "1207485", "stack_answer_comment_id": "6110404", "comment_content": "In recent versions of Python, you can do this even more cleanly by using the ", "user_id": "None"}, {"stack_answer_id": "1207485", "stack_answer_comment_id": "45266349", "comment_content": "reversed() does not create a new list, it creates a reverse iterator over the supplied sequence. Like enumerate(), you have to wrap it in list() to actually get a list out of it.  You may be thinking of sorted(), which ", "user_id": "None"}, {"stack_answer_id": "1207485", "stack_answer_comment_id": "51485366", "comment_content": "@Mauris because ", "user_id": "None"}, {"stack_answer_id": "1207485", "stack_answer_comment_id": "53032679", "comment_content": "This is O(N*M) for arrays, it is very slow if you remove many items from a large list.  So not recommended.", "user_id": "None"}, {"stack_answer_id": "1207485", "stack_answer_comment_id": "58231194", "comment_content": "@SamWatkins Yeah, this answer is for when you're removing a couple of elements from a very large array. Less memory usage, but it can be ", "user_id": "None"}]}, {"stack_answer_id": "34238688", "answer_content": "\r\n Overview of workarounds \n Either: \n \n use a linked list implementation/roll your own. \n A linked list is the proper data structure to support efficient item removal, and does not force you to make space/time tradeoffs. \n A CPython  list  is implemented with  dynamic arrays  as  mentioned here , which is not a good data type to support removals. \n There doesn't seem to be a linked list in the standard library however: \n \n Is there a linked list predefined library in Python? \n https://github.com/ajakubek/python-llist \n \n \n start a new  list()  from scratch, and  .append()  back at the end as mentioned at:  https://stackoverflow.com/a/1207460/895245 \n This time efficient, but less space efficient because it keeps an extra copy of the array around during iteration. \n \n use  del  with an index as mentioned at:  https://stackoverflow.com/a/1207485/895245 \n This is more space efficient since it dispenses the array copy, but it is less time efficient, because removal from dynamic arrays requires shifting all following items back by one, which is O(N). \n \n \n Generally, if you are doing it quick and dirty and don't want to add a custom  LinkedList  class, you just want to go for the faster  .append()  option by default unless memory is a big concern. \n Official Python 2 tutorial 4.2. \"for Statements\" \n https://docs.python.org/2/tutorial/controlflow.html#for-statements \n This part of the docs makes it clear that: \n \n you need to make a copy of the iterated list to modify it \n one way to do it is with the slice notation  [:] \n \n \n If you need to modify the sequence you are iterating over while inside the loop (for example to duplicate selected items), it is recommended that you first make a copy. Iterating over a sequence does not implicitly make a copy. The slice notation makes this especially convenient: \n >>> words = ['cat', 'window', 'defenestrate']\n>>> for w in words[:]:  # Loop over a slice copy of the entire list.\n...     if len(w) > 6:\n...         words.insert(0, w)\n...\n>>> words\n['defenestrate', 'cat', 'window', 'defenestrate']\n \n \n Python 2 documentation 7.3. \"The for statement\" \n https://docs.python.org/2/reference/compound_stmts.html#for \n This part of the docs says once again that you have to make a copy, and gives an actual removal example: \n \n Note: There is a subtlety when the sequence is being modified by the loop (this can only occur for mutable sequences, i.e. lists). An internal counter is used to keep track of which item is used next, and this is incremented on each iteration. When this counter has reached the length of the sequence the loop terminates. This means that if the suite deletes the current (or a previous) item from the sequence, the next item will be skipped (since it gets the index of the current item which has already been treated). Likewise, if the suite inserts an item in the sequence before the current item, the current item will be treated again the next time through the loop. This can lead to nasty bugs that can be avoided by making a temporary copy using a slice of the whole sequence, e.g., \n for x in a[:]:\n \n \n     if x < 0: a.remove(x)\n \n However, I disagree with this implementation, since  .remove()  has to iterate the  entire list  to find the value. \n Could Python do this better? \n It seems like this particular Python API could be improved. Compare it, for instance, with: \n \n Java  ListIterator::remove  which documents \"This call can only be made once per call to next or previous\" \n C++  std::vector::erase  which returns a valid interator to the element after the one removed \n \n both of which make it crystal clear that you cannot modify a list being iterated except with the iterator itself, and gives you efficient ways to do so without copying the list. \n Perhaps the underlying rationale is that Python lists are assumed to be dynamic array backed, and therefore any type of removal will be time inefficient anyways, while Java has a nicer interface hierarchy with both  ArrayList  and  LinkedList  implementations of  ListIterator . \n There doesn't seem to be an explicit linked list type in the Python stdlib either:  Python Linked List \n    ", "date_posted": "2020-09-25 05:15:39Z", "upvote": "\r\n            66\r\n        ", "accepted": "No", "user": {"stack_user_id": "895245", "name": "Ciro Santilli \u041f\u0443\u0442\u043b\u0435\u0440 \u041a\u0430\u043f\u0443\u0442 \u516d\u56db\u4e8b", "reputation_score": "312k"}, "answer_comments": [{"stack_answer_id": "34238688", "stack_answer_comment_id": "120740698", "comment_content": "Finally someone pointed out the actual documentation. I couldn't understand any answers before this one.", "user_id": "None"}]}, {"stack_answer_id": "1207460", "answer_content": "\r\n Your best approach for such an example would be a  list comprehension \n\n somelist = [tup for tup in somelist if determine(tup)]\n \n\n In cases where you're doing something more complex than calling a  determine  function, I prefer constructing a new list and simply appending to it as I go.  For example \n\n newlist = []\nfor tup in somelist:\n    # lots of code here, possibly setting things up for calling determine\n    if determine(tup):\n        newlist.append(tup)\nsomelist = newlist\n \n\n Copying the list using  remove  might make your code look a little cleaner, as described in one of the answers below.  You should definitely not do this for extremely large lists, since this involves first copying the entire list, and also performing an  O(n)   remove  operation for each element being removed, making this an  O(n^2)  algorithm. \n\n for tup in somelist[:]:\n    # lots of code here, possibly setting things up for calling determine\n    if determine(tup):\n        newlist.append(tup)\n \n    ", "date_posted": "2009-07-30 17:30:54Z", "upvote": "\r\n            51\r\n        ", "accepted": "No", "user": {"stack_user_id": "1694", "name": "Eli Courtwright", "reputation_score": "178k"}, "answer_comments": []}, {"stack_answer_id": "1207500", "answer_content": "\r\n For those that like functional programming: \n\n somelist[:] = filter(lambda tup: not determine(tup), somelist)\n \n\n or \n\n from itertools import ifilterfalse\nsomelist[:] = list(ifilterfalse(determine, somelist))\n \n    ", "date_posted": "2016-05-24 12:50:20Z", "upvote": "\r\n            41\r\n        ", "accepted": "No", "user": {"stack_user_id": "1843331", "name": "Tim", "reputation_score": "40.2k"}, "answer_comments": [{"stack_answer_id": "1207500", "stack_answer_comment_id": "67641698", "comment_content": "1. List comprehension and generator expressions are borrowed from Haskell, a pure functional language; they're exactly as functional as ", "user_id": "None"}]}, {"stack_answer_id": "42773232", "answer_content": "\r\n I needed to do this with a huge list, and duplicating the list seemed expensive, especially since in my case the number of deletions would be few compared to the items that remain. I took this low-level approach. \n\n array = [lots of stuff]\narraySize = len(array)\ni = 0\nwhile i < arraySize:\n    if someTest(array[i]):\n        del array[i]\n        arraySize -= 1\n    else:\n        i += 1\n \n\n What I don't know is how efficient a couple of deletes are compared to copying a large list. Please comment if you have any insight. \n    ", "date_posted": "2017-03-13 20:54:41Z", "upvote": "\r\n            23\r\n        ", "accepted": "No", "user": {"stack_user_id": "1031265", "name": "Michael", "reputation_score": "499"}, "answer_comments": [{"stack_answer_id": "42773232", "stack_answer_comment_id": "74631480", "comment_content": "In my case I need to move those 'unwanted' elements into another list. Do you have any new comment about this solution? I also think that it is better to use some deletions instead of duplicate the list.", "user_id": "None"}, {"stack_answer_id": "42773232", "stack_answer_comment_id": "74646602", "comment_content": "This is the right answer if performance is an issue (although same as @Alexey). That said, the choice of ", "user_id": "None"}, {"stack_answer_id": "42773232", "stack_answer_comment_id": "74646698", "comment_content": "@GVelascoh why not create ", "user_id": "None"}, {"stack_answer_id": "42773232", "stack_answer_comment_id": "75747098", "comment_content": "Note that this is likely time inefficient: if ", "user_id": "None"}, {"stack_answer_id": "42773232", "stack_answer_comment_id": "115963470", "comment_content": "@CiroSantilli\u90dd\u6d77\u4e1c\u51a0\u72b6\u75c5\u516d\u56db\u4e8b\u4ef6\u6cd5\u8f6e\u529f : The pop(i) operation is still O(n). I'll take storage efficiency over incremental improvements in O(n), but I can see why someone might do this differently.", "user_id": "None"}]}, {"stack_answer_id": "52947607", "answer_content": "\r\n Most of the answers here want you to create a copy of the list. I had a use case where the list was quite long (110K items) and it was smarter to keep reducing the list instead. \n\n First of all you'll need to  replace foreach loop with while loop , \n\n i = 0\nwhile i < len(somelist):\n    if determine(somelist[i]):\n         del somelist[i]\n    else:\n        i += 1\n \n\n The value of  i  is not changed in the if block because you'll want to get value of the new item FROM THE SAME INDEX, once the old item is deleted. \n    ", "date_posted": "2018-10-23 11:13:00Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "4008392", "name": "Mujeeb", "reputation_score": "805"}, "answer_comments": [{"stack_answer_id": "52947607", "stack_answer_comment_id": "124290302", "comment_content": "I don't want to like this but I do :)", "user_id": "None"}, {"stack_answer_id": "52947607", "stack_answer_comment_id": "126884873", "comment_content": "I think this is very creative! I would like to see more community input on this algorithm. It's easy to understand and appears to be overlooked by the contributors!", "user_id": "None"}, {"stack_answer_id": "52947607", "stack_answer_comment_id": "126900456", "comment_content": "@tonysepia glad to see this solution is still helpful :)", "user_id": "None"}, {"stack_answer_id": "52947607", "stack_answer_comment_id": "126900474", "comment_content": "@Mujeeb oh Yes, you can see me using it in my algo here: ", "user_id": "None"}]}, {"stack_answer_id": "36096883", "answer_content": "\r\n It might be smart to also just create a new list if the current list item meets the desired criteria.  \n\n so: \n\n for item in originalList:\n   if (item != badValue):\n        newList.append(item)\n \n\n and to avoid having to re-code the entire project with the new lists name: \n\n originalList[:] = newList\n \n\n note, from Python documentation:  \n\n \n   copy.copy(x) \n  Return a shallow copy of x. \n  \n   copy.deepcopy(x) \n  Return a deep copy of x. \n \n    ", "date_posted": "2016-10-23 02:33:13Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "5425664", "name": "ntk4", "reputation_score": "1,199"}, "answer_comments": [{"stack_answer_id": "36096883", "stack_answer_comment_id": "63359622", "comment_content": "This adds no new information that wasn't in the accepted answer years earlier.", "user_id": "None"}, {"stack_answer_id": "36096883", "stack_answer_comment_id": "63408517", "comment_content": "It's simple and just another way to look at a problem @MarkAmery. It's less condensed for those people that don't like compressed coding syntax.", "user_id": "None"}]}, {"stack_answer_id": "40177544", "answer_content": "\r\n This answer was originally written in response to a question which has since been marked as duplicate:\n Removing coordinates from list on python \n\n There are two problems in your code: \n\n 1) When using remove(), you attempt to remove integers whereas you need to remove a tuple. \n\n 2) The for loop will skip items in your list. \n\n Let's run through what happens when we execute your code: \n\n >>> L1 = [(1,2), (5,6), (-1,-2), (1,-2)]\n>>> for (a,b) in L1:\n...   if a < 0 or b < 0:\n...     L1.remove(a,b)\n... \nTraceback (most recent call last):\n  File \"<stdin>\", line 3, in <module>\nTypeError: remove() takes exactly one argument (2 given)\n \n\n The first problem is that you are passing both 'a' and 'b' to remove(), but remove() only accepts a single argument. So how can we get remove() to work properly with your list? We need to figure out what each element of your list is. In this case, each one is a tuple. To see this, let's access one element of the list (indexing starts at 0): \n\n >>> L1[1]\n(5, 6)\n>>> type(L1[1])\n<type 'tuple'>\n \n\n Aha! Each element of L1 is actually a tuple. So that's what we need to be passing to remove(). Tuples in python are very easy, they're simply made by enclosing values in parentheses. \"a, b\" is not a tuple, but \"(a, b)\" is a tuple. So we modify your code and run it again: \n\n # The remove line now includes an extra \"()\" to make a tuple out of \"a,b\"\nL1.remove((a,b))\n \n\n This code runs without any error, but let's look at the list it outputs:  \n\n L1 is now: [(1, 2), (5, 6), (1, -2)]\n \n\n Why is (1,-2) still in your list? It turns out modifying the list while using a loop to iterate over it is a very bad idea without special care. The reason that (1, -2) remains in the list is that the locations of each item within the list changed between iterations of the for loop. Let's look at what happens if we feed the above code a longer list: \n\n L1 = [(1,2),(5,6),(-1,-2),(1,-2),(3,4),(5,7),(-4,4),(2,1),(-3,-3),(5,-1),(0,6)]\n### Outputs:\nL1 is now: [(1, 2), (5, 6), (1, -2), (3, 4), (5, 7), (2, 1), (5, -1), (0, 6)]\n \n\n As you can infer from that result, every time that the conditional statement evaluates to true and a list item is removed, the next iteration of the loop will skip evaluation of the next item in the list because its values are now located at different indices. \n\n The most intuitive solution is to copy the list, then iterate over the original list and only modify the copy. You can try doing so like this: \n\n L2 = L1\nfor (a,b) in L1:\n    if a < 0 or b < 0 :\n        L2.remove((a,b))\n# Now, remove the original copy of L1 and replace with L2\nprint L2 is L1\ndel L1\nL1 = L2; del L2\nprint (\"L1 is now: \", L1)\n \n\n However, the output will be identical to before: \n\n 'L1 is now: ', [(1, 2), (5, 6), (1, -2), (3, 4), (5, 7), (2, 1), (5, -1), (0, 6)]\n \n\n This is because when we created L2, python did not actually create a new object. Instead, it merely referenced L2 to the same object as L1. We can verify this with 'is' which is different from merely \"equals\" (==). \n\n >>> L2=L1\n>>> L1 is L2\nTrue\n \n\n We can make a true copy using copy.copy(). Then everything works as expected: \n\n import copy\nL1 = [(1,2), (5,6),(-1,-2), (1,-2),(3,4),(5,7),(-4,4),(2,1),(-3,-3),(5,-1),(0,6)]\nL2 = copy.copy(L1)\nfor (a,b) in L1:\n    if a < 0 or b < 0 :\n        L2.remove((a,b))\n# Now, remove the original copy of L1 and replace with L2\ndel L1\nL1 = L2; del L2\n>>> L1 is now: [(1, 2), (5, 6), (3, 4), (5, 7), (2, 1), (0, 6)]\n \n\n Finally, there is one cleaner solution than having to make an entirely new copy of L1. The reversed() function: \n\n L1 = [(1,2), (5,6),(-1,-2), (1,-2),(3,4),(5,7),(-4,4),(2,1),(-3,-3),(5,-1),(0,6)]\nfor (a,b) in reversed(L1):\n    if a < 0 or b < 0 :\n        L1.remove((a,b))\nprint (\"L1 is now: \", L1)\n>>> L1 is now: [(1, 2), (5, 6), (3, 4), (5, 7), (2, 1), (0, 6)]\n \n\n Unfortunately, I cannot adequately describe how reversed() works. It returns a 'listreverseiterator' object when a list is passed to it. For practical purposes, you can think of it as creating a reversed copy of its argument. This is the solution I recommend. \n    ", "date_posted": "2017-05-23 12:18:24Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}, {"stack_answer_id": "58314595", "answer_content": "\r\n If you want to delete elements from a list while iterating, use a while-loop so you can alter the current index and end index after each deletion. \n\n Example: \n\n i = 0\nlength = len(list1)\n\nwhile i < length:\n    if condition:\n        list1.remove(list1[i])\n        i -= 1\n        length -= 1\n\n    i += 1\n \n    ", "date_posted": "2019-10-10 02:24:59Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "2619038", "name": "NoName", "reputation_score": "9,114"}, "answer_comments": []}, {"stack_answer_id": "25363359", "answer_content": "\r\n If you want to do anything else during the iteration, it may be nice to get both the index (which guarantees you being able to reference it, for example if you have a list of dicts) and the actual list item contents. \n\n inlist = [{'field1':10, 'field2':20}, {'field1':30, 'field2':15}]    \nfor idx, i in enumerate(inlist):\n    do some stuff with i['field1']\n    if somecondition:\n        xlist.append(idx)\nfor i in reversed(xlist): del inlist[i]\n \n\n enumerate  gives you access to the item and the index at once.  reversed  is so that the indices that you're going to later delete don't change on you.  \n    ", "date_posted": "2014-08-18 12:30:16Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "3427777", "name": "fantabolous", "reputation_score": "19.5k"}, "answer_comments": [{"stack_answer_id": "25363359", "stack_answer_comment_id": "63359580", "comment_content": "Why is getting the index any more relevant in the case where you have a list of dicts than in the case of any other kind of list? This doesn't make sense as far as I can tell.", "user_id": "None"}]}, {"stack_answer_id": "39293411", "answer_content": "\r\n One possible solution, useful if you want not only remove some things, but also do something with all elements in a single loop: \n\n alist = ['good', 'bad', 'good', 'bad', 'good']\ni = 0\nfor x in alist[:]:\n    if x == 'bad':\n        alist.pop(i)\n        i -= 1\n    # do something cool with x or just print x\n    print(x)\n    i += 1\n \n    ", "date_posted": "2018-06-13 19:38:52Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "6740698", "name": "Xenolion", "reputation_score": "11.1k"}, "answer_comments": [{"stack_answer_id": "39293411", "stack_answer_comment_id": "85623994", "comment_content": "You should really just use comprehensions. They're much easier to understand.", "user_id": "None"}, {"stack_answer_id": "39293411", "stack_answer_comment_id": "85632089", "comment_content": "What if I want to remove ", "user_id": "None"}, {"stack_answer_id": "39293411", "stack_answer_comment_id": "86135096", "comment_content": "Actually, I realized there's some cleverness here in that you make a copy of the list with an open slice (", "user_id": "None"}]}, {"stack_answer_id": "55915047", "answer_content": "\r\n for loop will be iterate through index.. \n\n consider you have a list, \n\n [5, 7, 13, 29, 65, 91]\n \n\n you have using list variable called  lis . and you using same to remove.. \n\n your variable  \n\n lis = [5, 7, 13, 29, 35, 65, 91]\n       0  1   2   3   4   5   6\n \n\n during 5th iteration, \n\n your  number 35  was not a prime so you removed it from a list. \n\n lis.remove(y)\n \n\n and then  next value (65)  move on to previous index. \n\n lis = [5, 7, 13, 29, 65, 91]\n       0  1   2   3   4   5\n \n\n so 4th iteration done pointer moved onto 5th..  \n\n thats why your loop doesnt cover 65 since its moved into previous index. \n\n so you shouldn't reference list into another variable which still reference original instead of copy. \n\n ite = lis #dont do it will reference instead copy\n \n\n so do copy of list using  list[::] \n\n now you it will give, \n\n [5, 7, 13, 29]\n \n\n Problem is you removed a value from a list during iteration then your list index will collapse. \n\n so you can try comprehension instead. \n\n which supports all the iterable like, list, tuple, dict, string etc  \n    ", "date_posted": "2019-04-30 06:25:49Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "4453737", "name": "Mohideen bin Mohammed", "reputation_score": "17.2k"}, "answer_comments": [{"stack_answer_id": "55915047", "stack_answer_comment_id": "128054348", "comment_content": "To put in a simpler way: do ", "user_id": "None"}]}, {"stack_answer_id": "49311061", "answer_content": "\r\n The other answers are correct that it is usually a bad idea to delete from a list that you're iterating. Reverse iterating avoids some of the pitfalls, but it is much more difficult to follow code that does that, so usually you're better off using a list comprehension or  filter . \n There is, however, one case where it is safe to remove elements from a sequence that you are iterating: if you're only removing one item while you're iterating. This can be ensured using a  return  or a  break . For example: \n for i, item in enumerate(lst):\n    if item % 4 == 0:\n        foo(item)\n        del lst[i]\n        break\n \n This is often easier to understand than a list comprehension when you're doing some operations with side effects on the first item in a list that meets some condition and then removing that item from the list immediately after. \n    ", "date_posted": "2022-05-16 21:25:13Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "5079779", "name": "Beefster", "reputation_score": "665"}, "answer_comments": []}, {"stack_answer_id": "4639072", "answer_content": "\r\n You might want to use  filter()  available as the built-in. \n\n For more details  check here \n    ", "date_posted": "2017-07-27 07:40:53Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "5872484", "name": "Bharat Mane", "reputation_score": "296"}, "answer_comments": []}, {"stack_answer_id": "31350162", "answer_content": "\r\n You can try for-looping in reverse so for some_list you'll do something like: \n\n list_len = len(some_list)\nfor i in range(list_len):\n    reverse_i = list_len - 1 - i\n    cur = some_list[reverse_i]\n\n    # some logic with cur element\n\n    if some_condition:\n        some_list.pop(reverse_i)\n \n\n This way the index is aligned and doesn't suffer from the list updates (regardless whether you pop cur element or not). \n    ", "date_posted": "2015-07-10 20:58:49Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "975975", "name": "Queequeg", "reputation_score": "939"}, "answer_comments": [{"stack_answer_id": "31350162", "stack_answer_comment_id": "63359845", "comment_content": "Looping over ", "user_id": "None"}, {"stack_answer_id": "31350162", "stack_answer_comment_id": "63603723", "comment_content": "@MarkAmery don't think you can alter the list this way.", "user_id": "None"}]}, {"stack_answer_id": "53236774", "answer_content": "\r\n The most effective method is list comprehension, many people show their case, of course, it is also a good way to get an  iterator  through  filter . \n\n \n   Filter  receives a function and a sequence.  Filter  applies the passed function to each element in turn, and then decides whether to retain or discard the element depending on whether the function return value is  True  or  False . \n \n\n There is an example  (get the odds in the tuple): \n\n list(filter(lambda x:x%2==1, (1, 2, 4, 5, 6, 9, 10, 15)))  \n# result: [1, 5, 9, 15]\n \n\n Caution: You can also not handle iterators. Iterators are sometimes better than sequences. \n    ", "date_posted": "2018-11-10 07:05:16Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "10599390", "name": "chseng", "reputation_score": "116"}, "answer_comments": [{"stack_answer_id": "53236774", "stack_answer_comment_id": "121449764", "comment_content": "I probably think this is the most idiomatic way of removing the items from list. This behaviour will also be thread safe since your application is not mutating the variable.", "user_id": "None"}]}, {"stack_answer_id": "34310158", "answer_content": "\r\n I needed to do something similar and in my case the problem was memory - I needed to merge multiple dataset objects within a list, after doing some stuff with them, as a new object, and needed to get rid of each entry I was merging to avoid duplicating all of them and blowing up memory. In my case having the objects in a dictionary instead of a list worked fine: \n\n ``` \n\n k = range(5)\nv = ['a','b','c','d','e']\nd = {key:val for key,val in zip(k, v)}\n\nprint d\nfor i in range(5):\n    print d[i]\n    d.pop(i)\nprint d\n \n\n ``` \n    ", "date_posted": "2015-12-16 11:05:41Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "4577738", "name": "rafa", "reputation_score": "205"}, "answer_comments": []}, {"stack_answer_id": "37277264", "answer_content": "\r\n TLDR: \n\n I wrote a library that allows you to do this: \n\n from fluidIter import FluidIterable\nfSomeList = FluidIterable(someList)  \nfor tup in fSomeList:\n    if determine(tup):\n        # remove 'tup' without \"breaking\" the iteration\n        fSomeList.remove(tup)\n        # tup has also been removed from 'someList'\n        # as well as 'fSomeList'\n \n\n It's best to use another method if possible that doesn't require modifying your iterable while iterating over it, but for some algorithms it might not be that straight forward. And so if you are sure that you really do want the code pattern described in the original question, it is possible. \n\n Should work on all mutable sequences not just lists. \n\n \n\n Full answer: \n\n Edit: The last code example in this answer gives a use case for  why  you might sometimes want to modify a list in place rather than use a list comprehension. The first part of the answers serves as tutorial of  how  an array can be modified in place. \n\n The solution follows on from  this  answer (for a related question) from senderle. Which explains how the the array index is updated while iterating through a list that has been modified. The solution below is designed to correctly track the array index even if the list is modified. \n\n Download  fluidIter.py  from  here   https://github.com/alanbacon/FluidIterator , it is just a single file so no need to install git. There is no installer so you will need to make sure that the file is in the python path your self. The code has been written for python 3 and is untested on python 2. \n\n from fluidIter import FluidIterable\nl = [0,1,2,3,4,5,6,7,8]  \nfluidL = FluidIterable(l)                       \nfor i in fluidL:\n    print('initial state of list on this iteration: ' + str(fluidL)) \n    print('current iteration value: ' + str(i))\n    print('popped value: ' + str(fluidL.pop(2)))\n    print(' ')\n\nprint('Final List Value: ' + str(l))\n \n\n This will produce the following output: \n\n initial state of list on this iteration: [0, 1, 2, 3, 4, 5, 6, 7, 8]\ncurrent iteration value: 0\npopped value: 2\n\ninitial state of list on this iteration: [0, 1, 3, 4, 5, 6, 7, 8]\ncurrent iteration value: 1\npopped value: 3\n\ninitial state of list on this iteration: [0, 1, 4, 5, 6, 7, 8]\ncurrent iteration value: 4\npopped value: 4\n\ninitial state of list on this iteration: [0, 1, 5, 6, 7, 8]\ncurrent iteration value: 5\npopped value: 5\n\ninitial state of list on this iteration: [0, 1, 6, 7, 8]\ncurrent iteration value: 6\npopped value: 6\n\ninitial state of list on this iteration: [0, 1, 7, 8]\ncurrent iteration value: 7\npopped value: 7\n\ninitial state of list on this iteration: [0, 1, 8]\ncurrent iteration value: 8\npopped value: 8\n\nFinal List Value: [0, 1]\n \n\n Above we have used the  pop  method on the fluid list object. Other common iterable methods are also implemented such as  del fluidL[i] ,  .remove ,  .insert ,  .append ,  .extend . The list can also be modified using slices ( sort  and  reverse  methods are not implemented). \n\n The only condition is that you must only modify the list in place, if at any point  fluidL  or  l  were reassigned to a different list object the code would not work. The original  fluidL  object would still be used by the for loop but would become out of scope for us to modify. \n\n i.e. \n\n fluidL[2] = 'a'   # is OK\nfluidL = [0, 1, 'a', 3, 4, 5, 6, 7, 8]  # is not OK\n \n\n If we want to access the current index value of the list we cannot use enumerate, as this only counts how many times the for loop has run. Instead we will use the iterator object directly. \n\n fluidArr = FluidIterable([0,1,2,3])\n# get iterator first so can query the current index\nfluidArrIter = fluidArr.__iter__()\nfor i, v in enumerate(fluidArrIter):\n    print('enum: ', i)\n    print('current val: ', v)\n    print('current ind: ', fluidArrIter.currentIndex)\n    print(fluidArr)\n    fluidArr.insert(0,'a')\n    print(' ')\n\nprint('Final List Value: ' + str(fluidArr))\n \n\n This will output the following: \n\n enum:  0\ncurrent val:  0\ncurrent ind:  0\n[0, 1, 2, 3]\n\nenum:  1\ncurrent val:  1\ncurrent ind:  2\n['a', 0, 1, 2, 3]\n\nenum:  2\ncurrent val:  2\ncurrent ind:  4\n['a', 'a', 0, 1, 2, 3]\n\nenum:  3\ncurrent val:  3\ncurrent ind:  6\n['a', 'a', 'a', 0, 1, 2, 3]\n\nFinal List Value: ['a', 'a', 'a', 'a', 0, 1, 2, 3]\n \n\n The  FluidIterable  class just provides a wrapper for the original list object. The original object can be accessed as a property of the fluid object like so: \n\n originalList = fluidArr.fixedIterable\n \n\n More examples / tests can be found in the  if __name__ is \"__main__\":  section at the bottom of  fluidIter.py . These are worth looking at because they explain what happens in various situations. Such as: Replacing a large sections of the list using a slice. Or using (and modifying) the same iterable in nested for loops. \n\n As I stated to start with: this is a complicated solution that will hurt the readability of your code and make it more difficult to debug. Therefore other solutions such as the list comprehensions mentioned in David Raznick's  answer  should be considered first. That being said, I have found times where this class has been useful to me and has been easier to use than keeping track of the indices of elements that need deleting. \n\n \n\n Edit: As mentioned in the comments, this answer does not really present a problem for which this approach provides a solution. I will try to address that here: \n\n List comprehensions provide a way to generate a new list but these approaches tend to look at each element in isolation rather than the current state of the list as a whole. \n\n i.e. \n\n newList = [i for i in oldList if testFunc(i)]\n \n\n But what if the result of the  testFunc  depends on the elements that have been added to  newList  already? Or the elements still in  oldList  that might be added next? There might still be a way to use a list comprehension but it will begin to lose it's elegance, and for me it feels easier to modify a list in place. \n\n The code below is one example of an algorithm that suffers from the above problem. The algorithm will reduce a list so that no element is a multiple of any other element. \n\n randInts = [70, 20, 61, 80, 54, 18, 7, 18, 55, 9]\nfRandInts = FluidIterable(randInts)\nfRandIntsIter = fRandInts.__iter__()\n# for each value in the list (outer loop)\n# test against every other value in the list (inner loop)\nfor i in fRandIntsIter:\n    print(' ')\n    print('outer val: ', i)\n    innerIntsIter = fRandInts.__iter__()\n    for j in innerIntsIter:\n        innerIndex = innerIntsIter.currentIndex\n        # skip the element that the outloop is currently on\n        # because we don't want to test a value against itself\n        if not innerIndex == fRandIntsIter.currentIndex:\n            # if the test element, j, is a multiple \n            # of the reference element, i, then remove 'j'\n            if j%i == 0:\n                print('remove val: ', j)\n                # remove element in place, without breaking the\n                # iteration of either loop\n                del fRandInts[innerIndex]\n            # end if multiple, then remove\n        # end if not the same value as outer loop\n    # end inner loop\n# end outerloop\n\nprint('')\nprint('final list: ', randInts)\n \n\n The output and the final reduced list are shown below \n\n outer val:  70\n\nouter val:  20\nremove val:  80\n\nouter val:  61\n\nouter val:  54\n\nouter val:  18\nremove val:  54\nremove val:  18\n\nouter val:  7\nremove val:  70\n\nouter val:  55\n\nouter val:  9\nremove val:  18\n\nfinal list:  [20, 61, 7, 55, 9]\n \n    ", "date_posted": "2017-05-23 12:18:24Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": [{"stack_answer_id": "37277264", "stack_answer_comment_id": "63359804", "comment_content": "It's hard to tell whether this is over-engineered because it's unclear what problem it's trying to solve; what does removing elements using this approach achieve that ", "user_id": "None"}, {"stack_answer_id": "37277264", "stack_answer_comment_id": "63591681", "comment_content": "@MarkAmery. The main use case for when this is when trying to determine if an item should be removed (or added or moved) based not on just the item itself, but on the state of another item in the list or the state of the list as a whole. For example, it is not possible with list comprehensions to write something like ", "user_id": "None"}]}, {"stack_answer_id": "52447608", "answer_content": "\r\n In some situations, where you're doing more than simply filtering a list one item at time, you want your iteration to change while iterating. \n\n Here is an example where copying the list beforehand is incorrect, reverse iteration is impossible and a list comprehension is also not an option. \n\n \"\"\" Sieve of Eratosthenes \"\"\"\n\ndef generate_primes(n):\n    \"\"\" Generates all primes less than n. \"\"\"\n    primes = list(range(2,n))\n    idx = 0\n    while idx < len(primes):\n        p = primes[idx]\n        for multiple in range(p+p, n, p):\n            try:\n                primes.remove(multiple)\n            except ValueError:\n                pass #EAFP\n        idx += 1\n        yield p\n \n    ", "date_posted": "2018-09-21 16:14:52Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "2780179", "name": "MathKid", "reputation_score": "1,513"}, "answer_comments": []}, {"stack_answer_id": "53600740", "answer_content": "\r\n I can think of three approaches to solve your problem. As an example, I will create a random list of tuples  somelist = [(1,2,3), (4,5,6), (3,6,6), (7,8,9), (15,0,0), (10,11,12)] . The condition that I choose is  sum of elements of a tuple = 15 . In the final list we will only have those tuples whose sum is not equal to 15.  \n\n What I have chosen is a randomly chosen example.  Feel free to change  the  list of tuples  and the  condition  that I have chosen.   \n\n Method 1.>  Use the framework that you had suggested (where one fills in a code inside a for loop). I use a small code with  del  to delete a tuple that meets the said condition. However, this method will miss a tuple (which satisfies the said condition) if two consecutively placed tuples meet the given condition.  \n\n for tup in somelist:\n    if ( sum(tup)==15 ): \n        del somelist[somelist.index(tup)]\n\nprint somelist\n>>> [(1, 2, 3), (3, 6, 6), (7, 8, 9), (10, 11, 12)]\n \n\n Method 2.>  Construct a new list which contains elements (tuples) where the given condition is not met (this is the same thing as removing elements of list where the given condition is met). Following is the code for that: \n\n newlist1 = [somelist[tup] for tup in range(len(somelist)) if(sum(somelist[tup])!=15)]\n\nprint newlist1\n>>>[(1, 2, 3), (7, 8, 9), (10, 11, 12)]\n \n\n Method 3.>  Find indices where the given condition is met, and then use remove elements (tuples) corresponding to those indices. Following is the code for that. \n\n indices = [i for i in range(len(somelist)) if(sum(somelist[i])==15)]\nnewlist2 = [tup for j, tup in enumerate(somelist) if j not in indices]\n\nprint newlist2\n>>>[(1, 2, 3), (7, 8, 9), (10, 11, 12)]\n \n\n Method 1 and method 2 are faster than method 3 . Method2 and method3 are more efficient than method1. I  prefer method2 . For the aforementioned example,  time(method1) : time(method2) : time(method3) = 1 : 1 : 1.7 \n    ", "date_posted": "2018-12-03 21:04:05Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "10626090", "name": "Siddharth Satpathy", "reputation_score": "2,513"}, "answer_comments": []}, {"stack_answer_id": "55704504", "answer_content": "\r\n If you will use the new list later, you can simply set the elem to None, and then judge it in the later loop, like this \n\n for i in li:\n    i = None\n\nfor elem in li:\n    if elem is None:\n        continue\n \n\n In this way, you dont't need copy the list and it's easier to understand.  \n    ", "date_posted": "2019-04-16 09:08:13Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "2899160", "name": "Mark Zhang", "reputation_score": "918"}, "answer_comments": []}, {"stack_answer_id": "51976515", "answer_content": "\r\n For anything that has the potential to be really big, I use the following.  \n\n import numpy as np\n\norig_list = np.array([1, 2, 3, 4, 5, 100, 8, 13])\n\nremove_me = [100, 1]\n\ncleaned = np.delete(orig_list, remove_me)\nprint(cleaned)\n \n\n That should be significantly faster than anything else.  \n    ", "date_posted": "2018-08-22 23:36:31Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "5893677", "name": "CENTURION", "reputation_score": "325"}, "answer_comments": [{"stack_answer_id": "51976515", "stack_answer_comment_id": "98893393", "comment_content": "From what I measured, NumPy starts to be faster for lists of more than 20 elements, and reaches >12x faster filtering for big lists of 1000 elements and more.", "user_id": "None"}]}], "user": {"stack_user_id": "90777", "name": "lfaraone", "reputation_score": "48.3k"}, "question_comments": [{"stack_question_id": "1207406", "stack_question_comment_id": "104658488", "comment_content": "Most answers on this page don't really explain why removing elements while iterating over a list produces strange results, but the ", "user_id": "None"}]},
{"stack_question_id": "53645882", "question_title": "Pandas Merging 101", "question_content": "\r\n                How can I perform a (INNER| (LEFT|RIGHT|FULL) OUTER) JOIN with pandas?\nHow do I add NaNs for missing rows after a merge?\nHow do I get rid of NaNs after merging?\nCan I merge on the index?\nHow do I ...\r\n", "question_url": "/questions/53645882/pandas-merging-101", "date_posted": "Dec 6, 2018 at 6:41", "upvote": "7", "view": "3", "tags": ["python", "pandas", "join", "merge", "concatenation"], "answers_count": "8", "answers": [{"stack_answer_id": "53645883", "answer_content": "\r\n This post aims to give readers a primer on SQL-flavored merging with Pandas, how to use it, and when not to use it. \n In particular, here's what this post will go through: \n \n The basics - types of joins (LEFT, RIGHT, OUTER, INNER) \n \n merging with different column names \n merging with multiple columns \n avoiding duplicate merge key column in output \n \n \n \n What this post (and other posts by me on this thread) will not go through: \n \n Performance-related discussions and timings (for now). Mostly notable mentions of better alternatives, wherever appropriate. \n Handling suffixes, removing extra columns, renaming outputs, and other specific use cases. There are other (read: better) posts that deal with that, so figure it out! \n \n \n Note \nMost examples default to INNER JOIN operations while demonstrating various features, unless otherwise specified. \n Furthermore, all the DataFrames here can be copied and replicated so\nyou can play with them. Also, see  this\npost \non how to read DataFrames from your clipboard. \n Lastly, all visual representation of JOIN operations have been hand-drawn using Google Drawings. Inspiration from  here . \n \n \n \n Enough talk - just show me how to use  merge ! \n Setup & Basics \n np.random.seed(0)\nleft = pd.DataFrame({'key': ['A', 'B', 'C', 'D'], 'value': np.random.randn(4)})\nright = pd.DataFrame({'key': ['B', 'D', 'E', 'F'], 'value': np.random.randn(4)})\n\nleft\n\n  key     value\n0   A  1.764052\n1   B  0.400157\n2   C  0.978738\n3   D  2.240893\n\nright\n\n  key     value\n0   B  1.867558\n1   D -0.977278\n2   E  0.950088\n3   F -0.151357\n \n For the sake of simplicity, the key column has the same name (for now). \n An  INNER JOIN  is represented by \n \n \n Note \nThis, along with the forthcoming figures all follow this convention: \n \n blue  indicates rows that are present in the merge result \n red  indicates rows that are excluded from the result (i.e., removed) \n green  indicates missing values that are replaced with  NaN s in the result \n \n \n To perform an INNER JOIN, call  merge  on the left DataFrame, specifying the right DataFrame and the join key (at the very least) as arguments. \n left.merge(right, on='key')\n# Or, if you want to be explicit\n# left.merge(right, on='key', how='inner')\n\n  key   value_x   value_y\n0   B  0.400157  1.867558\n1   D  2.240893 -0.977278\n \n This returns only rows from  left  and  right  which share a common key (in this example, \"B\" and \"D). \n A  LEFT OUTER JOIN , or LEFT JOIN  is represented by \n \n This can be performed by specifying  how='left' . \n left.merge(right, on='key', how='left')\n\n  key   value_x   value_y\n0   A  1.764052       NaN\n1   B  0.400157  1.867558\n2   C  0.978738       NaN\n3   D  2.240893 -0.977278\n \n Carefully note the placement of NaNs here. If you specify  how='left' , then only keys from  left  are used, and missing data from  right  is replaced by NaN. \n And similarly, for a  RIGHT OUTER JOIN , or RIGHT JOIN which is... \n \n ...specify  how='right' : \n left.merge(right, on='key', how='right')\n\n  key   value_x   value_y\n0   B  0.400157  1.867558\n1   D  2.240893 -0.977278\n2   E       NaN  0.950088\n3   F       NaN -0.151357\n \n Here, keys from  right  are used, and missing data from  left  is replaced by NaN. \n Finally, for the  FULL OUTER JOIN , given by \n \n specify  how='outer' . \n left.merge(right, on='key', how='outer')\n\n  key   value_x   value_y\n0   A  1.764052       NaN\n1   B  0.400157  1.867558\n2   C  0.978738       NaN\n3   D  2.240893 -0.977278\n4   E       NaN  0.950088\n5   F       NaN -0.151357\n \n This uses the keys from both frames, and NaNs are inserted for missing rows in both. \n The documentation summarizes these various merges nicely: \n \n \n Other JOINs - LEFT-Excluding, RIGHT-Excluding, and FULL-Excluding/ANTI JOINs \n If you need  LEFT-Excluding JOINs  and  RIGHT-Excluding JOINs  in two steps. \n For LEFT-Excluding JOIN, represented as \n \n Start by performing a LEFT OUTER JOIN and then filtering to rows coming from  left  only (excluding everything from the right), \n (left.merge(right, on='key', how='left', indicator=True)\n     .query('_merge == \"left_only\"')\n     .drop('_merge', 1))\n\n  key   value_x  value_y\n0   A  1.764052      NaN\n2   C  0.978738      NaN\n \n Where, \n left.merge(right, on='key', how='left',  indicator=True )\n\n  key   value_x   value_y     _merge\n0   A  1.764052       NaN  left_only\n1   B  0.400157  1.867558       both\n2   C  0.978738       NaN  left_only\n3   D  2.240893 -0.977278       both \n And similarly, for a RIGHT-Excluding JOIN, \n \n (left.merge(right, on='key', how='right',  indicator=True )\n     .query('_merge == \"right_only\"')\n     .drop('_merge', 1))\n\n  key  value_x   value_y\n2   E      NaN  0.950088\n3   F      NaN -0.151357 \n Lastly, if you are required to do a merge that only retains keys from the left or right, but not both (IOW, performing an  ANTI-JOIN ), \n \n You can do this in similar fashion\u2014 \n (left.merge(right, on='key', how='outer', indicator=True)\n     .query('_merge != \"both\"')\n     .drop('_merge', 1))\n\n  key   value_x   value_y\n0   A  1.764052       NaN\n2   C  0.978738       NaN\n4   E       NaN  0.950088\n5   F       NaN -0.151357\n \n \n Different names for key columns \n If the key columns are named differently\u2014for example,  left  has  keyLeft , and  right  has  keyRight  instead of  key \u2014then you will have to specify  left_on  and  right_on  as arguments instead of  on : \n left2 = left.rename({'key':'keyLeft'}, axis=1)\nright2 = right.rename({'key':'keyRight'}, axis=1)\n\nleft2\n\n  keyLeft     value\n0       A  1.764052\n1       B  0.400157\n2       C  0.978738\n3       D  2.240893\n\nright2\n\n  keyRight     value\n0        B  1.867558\n1        D -0.977278\n2        E  0.950088\n3        F -0.151357\n \n\n left2.merge(right2, left_on='keyLeft', right_on='keyRight', how='inner')\n\n  keyLeft   value_x keyRight   value_y\n0       B  0.400157        B  1.867558\n1       D  2.240893        D -0.977278\n \n \n Avoiding duplicate key column in output \n When merging on  keyLeft  from  left  and  keyRight  from  right , if you only want either of the  keyLeft  or  keyRight  (but not both) in the output, you can start by setting the index as a preliminary step. \n left3 = left2.set_index('keyLeft')\nleft3.merge(right2, left_index=True, right_on='keyRight')\n\n    value_x keyRight   value_y\n0  0.400157        B  1.867558\n1  2.240893        D -0.977278\n \n Contrast this with the output of the command just before (that is, the output of  left2.merge(right2, left_on='keyLeft', right_on='keyRight', how='inner') ), you'll notice  keyLeft  is missing. You can figure out what column to keep based on which frame's index is set as the key. This may matter when, say, performing some OUTER JOIN operation. \n \n Merging only a single column from one of the  DataFrames \n For example, consider \n right3 = right.assign(newcol=np.arange(len(right)))\nright3\n  key     value  newcol\n0   B  1.867558       0\n1   D -0.977278       1\n2   E  0.950088       2\n3   F -0.151357       3\n \n If you are required to merge only \"newcol\" (without any of the other columns), you can usually just subset columns before merging: \n left.merge(right3[['key', 'newcol']], on='key')\n\n  key     value  newcol\n0   B  0.400157       0\n1   D  2.240893       1\n \n If you're doing a LEFT OUTER JOIN, a more performant solution would involve  map : \n # left['newcol'] = left['key'].map(right3.set_index('key')['newcol']))\nleft.assign(newcol=left['key'].map(right3.set_index('key')['newcol']))\n\n  key     value  newcol\n0   A  1.764052     NaN\n1   B  0.400157     0.0\n2   C  0.978738     NaN\n3   D  2.240893     1.0\n \n As mentioned, this is similar to, but faster than \n left.merge(right3[['key', 'newcol']], on='key', how='left')\n\n  key     value  newcol\n0   A  1.764052     NaN\n1   B  0.400157     0.0\n2   C  0.978738     NaN\n3   D  2.240893     1.0\n \n \n Merging on multiple columns \n To join on more than one column, specify a list for  on  (or  left_on  and  right_on , as appropriate). \n left.merge(right, on=['key1', 'key2'] ...)\n \n Or, in the event the names are different, \n left.merge(right, left_on=['lkey1', 'lkey2'], right_on=['rkey1', 'rkey2'])\n \n \n Other useful  merge*  operations and functions \n \n Merging a DataFrame with Series on index: See  this answer . \n \n Besides  merge ,  DataFrame.update  and  DataFrame.combine_first  are also used in certain cases to update one DataFrame with another. \n \n pd.merge_ordered  is a useful function for ordered JOINs. \n \n pd.merge_asof  (read: merge_asOf) is useful for  approximate  joins. \n \n \n This section only covers the very basics, and is designed to only whet your appetite. For more examples and cases, see the  documentation on  merge ,  join , and  concat  as well as the links to the function specifications. \n \n \n Continue Reading \n Jump to other topics in Pandas Merging 101 to continue learning: \n \n Merging basics - basic types of joins   * \n \n Index-based joins \n \n Generalizing to multiple DataFrames \n \n Cross join \n \n \n *You are here. \n    ", "date_posted": "2022-07-01 21:01:48Z", "upvote": "\r\n            1112\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "7967588", "name": "creanion", "reputation_score": "1,821"}, "answer_comments": [{"stack_answer_id": "53645883", "stack_answer_comment_id": "115512450", "comment_content": "If anyone is confused by the table of contents at the end of each post, I split up this massive answer into 4 separate ones, 3 on this question and 1 on another. The way it was setup previously made it harder to reference folks to specific topics. This allows you to bookmark separate topics easily now!", "user_id": "4909087"}, {"stack_answer_id": "53645883", "stack_answer_comment_id": "118452869", "comment_content": "This is an awesome resource! The only question I still have is why call it merge instead of join, and join instead of merge?", "user_id": "None"}]}, {"stack_answer_id": "55858991", "answer_content": "\r\n A supplemental visual view of  pd.concat([df0, df1], kwargs) . \nNotice that, kwarg  axis=0  or  axis=1  's meaning is not as intuitive as  df.mean()  or  df.apply(func) \n\n \n\n \n    ", "date_posted": "2019-10-11 17:36:29Z", "upvote": "\r\n            89\r\n        ", "accepted": "No", "user": {"stack_user_id": "11884237", "name": "ansev", "reputation_score": "29.3k"}, "answer_comments": [{"stack_answer_id": "55858991", "stack_answer_comment_id": "99071795", "comment_content": "This is a nice diagram. May I ask how you produced it?", "user_id": "4909087"}, {"stack_answer_id": "55858991", "stack_answer_comment_id": "99107100", "comment_content": "google doc's built-in \"insert ==> drawing... ==> new\" (as of 2019-May). But, to be clear: the only reason I used google doc for this picture  is because my notes is stored in google doc, and I would like a picture that can be modified quickly within google doc itself. Actually now you mentioned it, the google doc's drawing tool is pretty neat.", "user_id": "None"}, {"stack_answer_id": "55858991", "stack_answer_comment_id": "101107976", "comment_content": "Wow, this is great. Coming from the SQL world, \"vertical\" join is not a join in my head, as the table's structure is always fixed. Now even think pandas should consolidate ", "user_id": "None"}, {"stack_answer_id": "55858991", "stack_answer_comment_id": "101246910", "comment_content": "@Ufos Isn't that exactly what ", "user_id": "4909087"}, {"stack_answer_id": "55858991", "stack_answer_comment_id": "101569956", "comment_content": "yes, there're now ", "user_id": "None"}]}, {"stack_answer_id": "69115959", "answer_content": "\r\n Joins 101 \n These animations might be better to explain you visually.\nCredits:  Garrick Aden-Buie tidyexplain repo \n Inner Join \n \n Outer Join or Full Join \n \n Right Join \n \n Left Join \n \n    ", "date_posted": "2021-09-18 04:58:49Z", "upvote": "\r\n            54\r\n        ", "accepted": "No", "user": {"stack_user_id": "8277795", "name": "Anurag Dhadse", "reputation_score": "1,340"}, "answer_comments": [{"stack_answer_id": "69115959", "stack_answer_comment_id": "124057875", "comment_content": "These are awesome!", "user_id": "None"}, {"stack_answer_id": "69115959", "stack_answer_comment_id": "125963015", "comment_content": "I appreciate the effort put in to achieve this. Beautifully done.", "user_id": "None"}]}, {"stack_answer_id": "63338203", "answer_content": "\r\n In this answer, I will consider practical examples. \n The first one, is of  pandas.concat . \n The second one, of merging dataframes from the index of one and the column of another one. \n \n 1 .  pandas.concat \n Considering the following  DataFrames  with the same column names: \n Preco2018  with size (8784, 5) \n \n Preco 2019  with size (8760, 5) \n \n That have the same column names. \n You can combine them using  pandas.concat , by simply \n import pandas as pd\n\nframes = [Preco2018, Preco2019]\n\ndf_merged = pd.concat(frames)\n \n Which results in a DataFrame with the following size (17544, 5) \n \n If you want to visualize, it ends up working like this \n \n ( Source ) \n \n 2 . Merge by Column and Index \n In this part, I will consider a specific case: If one wants to merge the index of one dataframe and the column of another dataframe. \n Let's say one has the dataframe  Geo  with 54 columns, being one of the columns the Date  Data , which is of type  datetime64[ns] . \n \n And the dataframe  Price  that has one column with the price and the index corresponds to the dates \n \n In this specific case, to merge them, one uses  pd.merge \n merged = pd.merge(Price, Geo, left_index=True, right_on='Data')\n \n Which results in the following dataframe \n \n    ", "date_posted": "2021-01-24 00:26:49Z", "upvote": "\r\n            22\r\n        ", "accepted": "No", "user": {"stack_user_id": "7109869", "name": "Gon\u00e7alo Peres", "reputation_score": "6,422"}, "answer_comments": []}, {"stack_answer_id": "65167356", "answer_content": "\r\n This post will go through the following topics: \n \n Merging with index under different conditions\n \n options for index-based joins:  merge ,  join ,  concat \n merging on indexes \n merging on index of one, column of other \n \n \n effectively using named indexes to simplify merging syntax \n \n BACK TO TOP \n \n \n Index-based joins \n TL;DR \n \n There are a few options, some simpler than others depending on the use\ncase. \n \n DataFrame.merge  with  left_index  and  right_index  (or  left_on  and  right_on  using named indexes)\n \n supports inner/left/right/full \n can only join two at a time \n supports column-column, index-column, index-index joins \n \n \n DataFrame.join  (join on index)\n \n supports inner/left (default)/right/full \n can join multiple DataFrames at a time \n supports index-index joins \n \n \n pd.concat  (joins on index)\n \n supports inner/full (default) \n can join multiple DataFrames at a time \n supports index-index joins \n \n \n \n \n \n Index to index joins \n Setup & Basics \n import pandas as pd\nimport numpy as np\n\nnp.random.seed([3, 14])\nleft = pd.DataFrame(data={'value': np.random.randn(4)}, \n                    index=['A', 'B', 'C', 'D'])    \nright = pd.DataFrame(data={'value': np.random.randn(4)},  \n                     index=['B', 'D', 'E', 'F'])\nleft.index.name = right.index.name = 'idxkey'\n\nleft\n           value\nidxkey          \nA      -0.602923\nB      -0.402655\nC       0.302329\nD      -0.524349\n\nright\n \n           value\nidxkey          \nB       0.543843\nD       0.013135\nE      -0.326498\nF       1.385076\n \n Typically, an  inner join on index  would look like this: \n left.merge(right, left_index=True, right_index=True)\n\n         value_x   value_y\nidxkey                    \nB      -0.402655  0.543843\nD      -0.524349  0.013135\n \n Other joins follow similar syntax. \n Notable Alternatives \n \n DataFrame.join  defaults to joins on the index.  DataFrame.join  does a LEFT OUTER JOIN by default, so  how='inner'  is necessary here. \n  left.join(right, how='inner', lsuffix='_x', rsuffix='_y')\n\n          value_x   value_y\n idxkey                    \n B      -0.402655  0.543843\n D      -0.524349  0.013135\n \n Note that I needed to specify the  lsuffix  and  rsuffix  arguments since  join  would otherwise error out: \n  left.join(right)\n ValueError: columns overlap but no suffix specified: Index(['value'], dtype='object')\n \n Since the column names are the same. This would not be a problem if they were differently named. \n  left.rename(columns={'value':'leftvalue'}).join(right, how='inner')\n\n         leftvalue     value\n idxkey                     \n B       -0.402655  0.543843\n D       -0.524349  0.013135\n \n \n pd.concat  joins on the index and can join two or more DataFrames at once. It does a full outer join by default, so  how='inner'  is required here.. \n  pd.concat([left, right], axis=1, sort=False, join='inner')\n\n            value     value\n idxkey                    \n B      -0.402655  0.543843\n D      -0.524349  0.013135\n \n For more information on  concat , see  this post . \n \n \n \n Index to Column joins \n To perform an inner join using index of left, column of right, you will use  DataFrame.merge  a combination of  left_index=True  and  right_on=... . \n right2 = right.reset_index().rename({'idxkey' : 'colkey'}, axis=1)\nright2\n \n  colkey     value\n0      B  0.543843\n1      D  0.013135\n2      E -0.326498\n3      F  1.385076\n\nleft.merge(right2, left_index=True, right_on='colkey')\n\n    value_x colkey   value_y\n0 -0.402655      B  0.543843\n1 -0.524349      D  0.013135\n \n Other joins follow a similar structure. Note that only  merge  can perform index to column joins. You can join on multiple columns, provided the number of index levels on the left equals the number of columns on the right. \n join  and  concat  are not capable of mixed merges. You will need to set the index as a pre-step using  DataFrame.set_index . \n \n Effectively using Named Index [pandas >= 0.23] \n If your index is named, then from pandas >= 0.23,  DataFrame.merge  allows you to specify the index name to  on  (or  left_on  and  right_on  as necessary). \n left.merge(right, on='idxkey')\n\n         value_x   value_y\nidxkey                    \nB      -0.402655  0.543843\nD      -0.524349  0.013135\n \n For the previous example of merging with the index of left, column of right, you can use  left_on  with the index name of left: \n left.merge(right2, left_on='idxkey', right_on='colkey')\n\n    value_x colkey   value_y\n0 -0.402655      B  0.543843\n1 -0.524349      D  0.013135\n \n \n \n Continue Reading \n Jump to other topics in Pandas Merging 101 to continue learning: \n \n Merging basics - basic types of joins \n \n Index-based joins * \n \n Generalizing to multiple DataFrames \n \n Cross join \n \n \n * you are here  \n    ", "date_posted": "2022-06-05 19:09:34Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "65167356", "name": "\r\n        6 revs, 2 users 100%", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "65167327", "answer_content": "\r\n This post will go through the following topics: \n \n how to correctly generalize to multiple DataFrames (and why  merge  has shortcomings here) \n merging on unique keys \n merging on non-unqiue keys \n \n BACK TO TOP \n \n \n Generalizing to multiple DataFrames \n Oftentimes, the situation arises when multiple DataFrames are to be merged together. Naively, this can be done by chaining  merge  calls: \n df1.merge(df2, ...).merge(df3, ...)\n \n However, this quickly gets out of hand for many DataFrames. Furthermore, it may be necessary to generalise for an unknown number of DataFrames. \n Here I introduce  pd.concat  for multi-way joins on  unique  keys, and  DataFrame.join  for multi-way joins on  non-unique  keys. First, the setup. \n # Setup.\nnp.random.seed(0)\nA = pd.DataFrame({'key': ['A', 'B', 'C', 'D'], 'valueA': np.random.randn(4)})    \nB = pd.DataFrame({'key': ['B', 'D', 'E', 'F'], 'valueB': np.random.randn(4)})\nC = pd.DataFrame({'key': ['D', 'E', 'J', 'C'], 'valueC': np.ones(4)})\ndfs = [A, B, C] \n\n# Note: the \"key\" column values are unique, so the index is unique.\nA2 = A.set_index('key')\nB2 = B.set_index('key')\nC2 = C.set_index('key')\n\ndfs2 = [A2, B2, C2]\n \n \n Multiway merge on unique keys \n If your keys (here, the key could either be a column or an index) are unique, then you can use  pd.concat . Note that  pd.concat  joins DataFrames on the index . \n # Merge on `key` column. You'll need to set the index before concatenating\npd.concat(\n    [df.set_index('key') for df in dfs], axis=1, join='inner'\n).reset_index()\n\n  key    valueA    valueB  valueC\n0   D  2.240893 -0.977278     1.0\n\n# Merge on `key` index.\npd.concat(dfs2, axis=1, sort=False, join='inner')\n\n       valueA    valueB  valueC\nkey                            \nD    2.240893 -0.977278     1.0\n \n Omit  join='inner'  for a FULL OUTER JOIN. Note that you cannot specify LEFT or RIGHT OUTER joins (if you need these, use  join , described below). \n \n Multiway merge on keys with duplicates \n concat  is fast, but has its shortcomings. It cannot handle duplicates. \n A3 = pd.DataFrame({'key': ['A', 'B', 'C', 'D', 'D'], 'valueA': np.random.randn(5)})\npd.concat([df.set_index('key') for df in [A3, B, C]], axis=1, join='inner')\n \n ValueError: Shape of passed values is (3, 4), indices imply (3, 2)\n \n In this situation, we can use  join  since it can handle non-unique keys (note that  join  joins DataFrames on their index; it calls  merge  under the hood and does a LEFT OUTER JOIN unless otherwise specified). \n # Join on `key` column. Set as the index first.\n# For inner join. For left join, omit the \"how\" argument.\nA.set_index('key').join([B2, C2], how='inner').reset_index()\n\n  key    valueA    valueB  valueC\n0   D  2.240893 -0.977278     1.0\n\n# Join on `key` index.\nA3.set_index('key').join([B2, C2], how='inner')\n\n       valueA    valueB  valueC\nkey                            \nD    1.454274 -0.977278     1.0\nD    0.761038 -0.977278     1.0\n \n \n \n Continue Reading \n Jump to other topics in Pandas Merging 101 to continue learning: \n \n Merging basics - basic types of joins \n \n Index-based joins \n \n Generalizing to multiple DataFrames   * \n \n Cross join \n \n \n * you are here  \n    ", "date_posted": "2022-06-05 19:24:17Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "65167327", "name": "\r\n        6 revs, 2 users 87%", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "73285069", "answer_content": "\r\n Pandas at the moment does not support inequality joins within the merge syntax; one option is with the  conditional_join  function from  pyjanitor  - I am a contributor to this library: \n # pip install pyjanitor\nimport pandas as pd\nimport janitor \n\nleft.conditional_join(right, ('value', 'value', '>'))\n\n   left           right\n    key     value   key     value\n0     A  1.764052     D -0.977278\n1     A  1.764052     F -0.151357\n2     A  1.764052     E  0.950088\n3     B  0.400157     D -0.977278\n4     B  0.400157     F -0.151357\n5     C  0.978738     D -0.977278\n6     C  0.978738     F -0.151357\n7     C  0.978738     E  0.950088\n8     D  2.240893     D -0.977278\n9     D  2.240893     F -0.151357\n10    D  2.240893     E  0.950088\n11    D  2.240893     B  1.867558\n\nleft.conditional_join(right, ('value', 'value', '<'))\n\n  left           right\n   key     value   key     value\n0    A  1.764052     B  1.867558\n1    B  0.400157     E  0.950088\n2    B  0.400157     B  1.867558\n3    C  0.978738     B  1.867558\n \n The columns are passed as a variable argument of tuples, each tuple comprising of a column from the left dataframe, column from the right dataframe, and the join operator, which can be any of  (>, <, >=, <=, !=) . In the example above, a MultiIndex column is returned, because of overlaps in the column names. \n Performance wise, this is better than a naive cross join: \n np.random.seed(0)\ndd = pd.DataFrame({'value':np.random.randint(100000, size=50_000)})\ndf = pd.DataFrame({'start':np.random.randint(100000, size=1_000), \n                   'end':np.random.randint(100000, size=1_000)})\n\ndd.head()\n\n   value\n0  68268\n1  43567\n2  42613\n3  45891\n4  21243\n\ndf.head()\n\n   start    end\n0  71915  47005\n1  64284  44913\n2  13377  96626\n3  75823  38673\n4  29151    575\n\n\n%%timeit\nout = df.merge(dd, how='cross')\nout.loc[(out.start < out.value) & (out.end > out.value)]\n5.12 s \u00b1 19 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n\n%timeit df.conditional_join(dd, ('start', 'value' ,'<'), ('end', 'value' ,'>'))\n280 ms \u00b1 5.56 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n\nout = df.merge(dd, how='cross')\nout = out.loc[(out.start < out.value) & (out.end > out.value)]\nA = df.conditional_join(dd, ('start', 'value' ,'<'), ('end', 'value' ,'>'))\ncolumns = A.columns.tolist()\nA = A.sort_values(columns, ignore_index = True)\nout = out.sort_values(columns, ignore_index = True)\n\nA.equals(out)\nTrue\n \n    ", "date_posted": "2022-08-08 23:35:35Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "7175713", "name": "sammywemmy", "reputation_score": "23.6k"}, "answer_comments": []}, {"stack_answer_id": "53787691", "answer_content": "\r\n I think you should include this in your explanation as it is a relevant merge that I see fairly often, which is termed  cross-join  I believe. This is a merge that occurs when unique df's share no columns, and it simply merging 2 dfs side-by-side: \n The setup: \n names1 = [{'A':'Jack', 'B':'Jill'}]\n\nnames2 = [{'C':'Tommy', 'D':'Tammy'}]\n\ndf1=pd.DataFrame(names1)\ndf2=pd.DataFrame(names2)\ndf_merged= pd.merge(df1.assign(X=1), df2.assign(X=1), on='X').drop('X', 1)\n \n This creates a dummy X column, merges on the X, and then drops it to produce \n df_merged: \n       A     B      C      D\n0  Jack  Jill  Tommy  Tammy\n \n    ", "date_posted": "2022-08-09 07:20:23Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "6296561", "name": "Zoe stands with Ukraine", "reputation_score": "25.5k"}, "answer_comments": [{"stack_answer_id": "53787691", "stack_answer_comment_id": "94427861", "comment_content": "Please check the second comment under the question. Cross join was initially a part of this (see edit history) but was later edited out into it's own post for volume.", "user_id": "4909087"}, {"stack_answer_id": "53787691", "stack_answer_comment_id": "94427874", "comment_content": "I see! do you want me to delete this so it is not convoluted?", "user_id": "None"}, {"stack_answer_id": "53787691", "stack_answer_comment_id": "94427904", "comment_content": "Seeing as cross join was not meant to be covered here, yes... However I appreciate your intent to contribute in good faith :)", "user_id": "4909087"}]}], "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "question_comments": []},
{"stack_question_id": "47152691", "question_title": "How can I pivot a dataframe?", "question_content": "\r\n                What is pivot?\nHow do I pivot?\nIs this a pivot?\nLong format to wide format?\n\nI've seen a lot of questions that ask about pivot tables.  Even if they don't know that they are asking about pivot tables, ...\r\n", "question_url": "/questions/47152691/how-can-i-pivot-a-dataframe", "date_posted": "Nov 7, 2017 at 8:00", "upvote": "5", "view": "5", "tags": ["python", "pandas", "group-by", "pivot", "pandas-groupby"], "answers_count": "4", "answers": [{"stack_answer_id": "47152692", "answer_content": "\r\n We start by answering the first question: \n Question 1 \n \n Why do I get  ValueError: Index contains duplicate entries, cannot reshape \n \n This occurs because pandas is attempting to reindex either a  columns  or  index  object with duplicate entries.  There are varying methods to use that can perform a pivot.  Some of them are not well suited to when there are duplicates of the keys in which it is being asked to pivot on.  For example.  Consider  pd.DataFrame.pivot .  I know there are duplicate entries that share the  row  and  col  values: \n df.duplicated(['row', 'col']).any()\n\nTrue\n \n So when I  pivot  using \n df.pivot(index='row', columns='col', values='val0')\n \n I get the error mentioned above.  In fact, I get the same error when I try to perform the same task with: \n df.set_index(['row', 'col'])['val0'].unstack()\n \n Here is a list of idioms we can use to pivot \n \n pd.DataFrame.groupby  +  pd.DataFrame.unstack \n \n Good general approach for doing just about any type of pivot \n You specify all columns that will constitute the pivoted row levels and column levels in one group by.  You follow that by selecting the remaining columns you want to aggregate and the function(s) you want to perform the aggregation.  Finally, you  unstack  the levels that you want to be in the column index. \n \n \n pd.DataFrame.pivot_table \n \n A glorified version of  groupby  with more intuitive API.  For many people, this is the preferred approach.  And is the intended approach by the developers. \n Specify row level, column levels, values to be aggregated, and function(s) to perform aggregations. \n \n \n pd.DataFrame.set_index  +  pd.DataFrame.unstack \n \n Convenient and intuitive for some (myself included).  Cannot handle duplicate grouped keys. \n Similar to the  groupby  paradigm, we specify all columns that will eventually be either row or column levels and set those to be the index.  We then  unstack  the levels we want in the columns.  If either the remaining index levels or column levels are not unique, this method will fail. \n \n \n pd.DataFrame.pivot \n \n Very similar to  set_index  in that it shares the duplicate key limitation.  The API is very limited as well.  It only takes scalar values for  index ,  columns ,  values . \n Similar to the  pivot_table  method in that we select rows, columns, and values on which to pivot.  However, we cannot aggregate and if either rows or columns are not unique, this method will fail. \n \n \n pd.crosstab \n \n This a specialized version of  pivot_table  and in its purest form is the most intuitive way to perform several tasks. \n \n \n pd.factorize  +  np.bincount \n \n This is a highly advanced technique that is very obscure but is very fast.  It cannot be used in all circumstances, but when it can be used and you are comfortable using it, you will reap the performance rewards. \n \n \n pd.get_dummies  +  pd.DataFrame.dot \n \n I use this for cleverly performing cross tabulation. \n \n \n \n \n Examples \n What I'm going to do for each subsequent answer and question is to answer it using  pd.DataFrame.pivot_table .  Then I'll provide alternatives to perform the same task. \n Question 3 \n \n How do I pivot  df  such that the  col  values are columns,  row  values are the index, mean of  val0  are the values, and missing values are  0 ? \n \n \n pd.DataFrame.pivot_table \n \n fill_value  is not set by default.  I tend to set it appropriately.  In this case I set it to  0 .  Notice I skipped  question 2  as it's the same as this answer without the  fill_value \n \n aggfunc='mean'  is the default and I didn't have to set it.  I included it to be explicit. \n     df.pivot_table(\n        values='val0', index='row', columns='col',\n        fill_value=0, aggfunc='mean')\n\n    col   col0   col1   col2   col3  col4\n    row\n    row0  0.77  0.605  0.000  0.860  0.65\n    row2  0.13  0.000  0.395  0.500  0.25\n    row3  0.00  0.310  0.000  0.545  0.00\n    row4  0.00  0.100  0.395  0.760  0.24\n \n \n \n \n pd.DataFrame.groupby \n   df.groupby(['row', 'col'])['val0'].mean().unstack(fill_value=0)\n \n \n pd.crosstab \n   pd.crosstab(\n      index=df['row'], columns=df['col'],\n      values=df['val0'], aggfunc='mean').fillna(0)\n \n \n \n \n Question 4 \n \n Can I get something other than  mean , like maybe  sum ? \n \n \n pd.DataFrame.pivot_table \n   df.pivot_table(\n      values='val0', index='row', columns='col',\n      fill_value=0, aggfunc='sum')\n\n  col   col0  col1  col2  col3  col4\n  row\n  row0  0.77  1.21  0.00  0.86  0.65\n  row2  0.13  0.00  0.79  0.50  0.50\n  row3  0.00  0.31  0.00  1.09  0.00\n  row4  0.00  0.10  0.79  1.52  0.24\n \n \n pd.DataFrame.groupby \n   df.groupby(['row', 'col'])['val0'].sum().unstack(fill_value=0)\n \n \n pd.crosstab \n   pd.crosstab(\n      index=df['row'], columns=df['col'],\n      values=df['val0'], aggfunc='sum').fillna(0)\n \n \n \n \n Question 5 \n \n Can I do more that one aggregation at a time? \n \n Notice that for  pivot_table  and  crosstab  I needed to pass list of callables.  On the other hand,  groupby.agg  is able to take strings for a limited number of special functions.   groupby.agg  would also have taken the same callables we passed to the others, but it is often more efficient to leverage the string function names as there are efficiencies to be gained. \n \n pd.DataFrame.pivot_table \n   df.pivot_table(\n      values='val0', index='row', columns='col',\n      fill_value=0, aggfunc=[np.size, np.mean])\n\n       size                      mean\n  col  col0 col1 col2 col3 col4  col0   col1   col2   col3  col4\n  row\n  row0    1    2    0    1    1  0.77  0.605  0.000  0.860  0.65\n  row2    1    0    2    1    2  0.13  0.000  0.395  0.500  0.25\n  row3    0    1    0    2    0  0.00  0.310  0.000  0.545  0.00\n  row4    0    1    2    2    1  0.00  0.100  0.395  0.760  0.24\n \n \n pd.DataFrame.groupby \n   df.groupby(['row', 'col'])['val0'].agg(['size', 'mean']).unstack(fill_value=0)\n \n \n pd.crosstab \n   pd.crosstab(\n      index=df['row'], columns=df['col'],\n      values=df['val0'], aggfunc=[np.size, np.mean]).fillna(0, downcast='infer')\n \n \n \n \n Question 6 \n \n Can I aggregate over multiple value columns? \n \n \n pd.DataFrame.pivot_table  we pass  values=['val0', 'val1']  but we could've left that off completely \n   df.pivot_table(\n      values=['val0', 'val1'], index='row', columns='col',\n      fill_value=0, aggfunc='mean')\n\n        val0                             val1\n  col   col0   col1   col2   col3  col4  col0   col1  col2   col3  col4\n  row\n  row0  0.77  0.605  0.000  0.860  0.65  0.01  0.745  0.00  0.010  0.02\n  row2  0.13  0.000  0.395  0.500  0.25  0.45  0.000  0.34  0.440  0.79\n  row3  0.00  0.310  0.000  0.545  0.00  0.00  0.230  0.00  0.075  0.00\n  row4  0.00  0.100  0.395  0.760  0.24  0.00  0.070  0.42  0.300  0.46\n \n \n pd.DataFrame.groupby \n   df.groupby(['row', 'col'])['val0', 'val1'].mean().unstack(fill_value=0)\n \n \n \n \n Question 7 \n \n Can Subdivide by multiple columns? \n \n \n pd.DataFrame.pivot_table \n   df.pivot_table(\n      values='val0', index='row', columns=['item', 'col'],\n      fill_value=0, aggfunc='mean')\n\n  item item0             item1                         item2\n  col   col2  col3  col4  col0  col1  col2  col3  col4  col0   col1  col3  col4\n  row\n  row0  0.00  0.00  0.00  0.77  0.00  0.00  0.00  0.00  0.00  0.605  0.86  0.65\n  row2  0.35  0.00  0.37  0.00  0.00  0.44  0.00  0.00  0.13  0.000  0.50  0.13\n  row3  0.00  0.00  0.00  0.00  0.31  0.00  0.81  0.00  0.00  0.000  0.28  0.00\n  row4  0.15  0.64  0.00  0.00  0.10  0.64  0.88  0.24  0.00  0.000  0.00  0.00\n \n \n pd.DataFrame.groupby \n   df.groupby(\n      ['row', 'item', 'col']\n  )['val0'].mean().unstack(['item', 'col']).fillna(0).sort_index(1)\n \n \n \n \n Question 8 \n \n Can Subdivide by multiple columns? \n \n \n pd.DataFrame.pivot_table \n   df.pivot_table(\n      values='val0', index=['key', 'row'], columns=['item', 'col'],\n      fill_value=0, aggfunc='mean')\n\n  item      item0             item1                         item2\n  col        col2  col3  col4  col0  col1  col2  col3  col4  col0  col1  col3  col4\n  key  row\n  key0 row0  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.86  0.00\n       row2  0.00  0.00  0.37  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.50  0.00\n       row3  0.00  0.00  0.00  0.00  0.31  0.00  0.81  0.00  0.00  0.00  0.00  0.00\n       row4  0.15  0.64  0.00  0.00  0.00  0.00  0.00  0.24  0.00  0.00  0.00  0.00\n  key1 row0  0.00  0.00  0.00  0.77  0.00  0.00  0.00  0.00  0.00  0.81  0.00  0.65\n       row2  0.35  0.00  0.00  0.00  0.00  0.44  0.00  0.00  0.00  0.00  0.00  0.13\n       row3  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.28  0.00\n       row4  0.00  0.00  0.00  0.00  0.10  0.00  0.00  0.00  0.00  0.00  0.00  0.00\n  key2 row0  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.40  0.00  0.00\n       row2  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.13  0.00  0.00  0.00\n       row4  0.00  0.00  0.00  0.00  0.00  0.64  0.88  0.00  0.00  0.00  0.00  0.00\n \n \n pd.DataFrame.groupby \n   df.groupby(\n      ['key', 'row', 'item', 'col']\n  )['val0'].mean().unstack(['item', 'col']).fillna(0).sort_index(1)\n \n \n pd.DataFrame.set_index  because the set of keys are unique for both rows and columns \n   df.set_index(\n      ['key', 'row', 'item', 'col']\n  )['val0'].unstack(['item', 'col']).fillna(0).sort_index(1)\n \n \n \n \n Question 9 \n \n Can I aggregate the frequency in which the column and rows occur together, aka \"cross tabulation\"? \n \n \n pd.DataFrame.pivot_table \n   df.pivot_table(index='row', columns='col', fill_value=0, aggfunc='size')\n\n      col   col0  col1  col2  col3  col4\n  row\n  row0     1     2     0     1     1\n  row2     1     0     2     1     2\n  row3     0     1     0     2     0\n  row4     0     1     2     2     1\n \n \n pd.DataFrame.groupby \n   df.groupby(['row', 'col'])['val0'].size().unstack(fill_value=0)\n \n \n pd.crosstab \n   pd.crosstab(df['row'], df['col'])\n \n \n pd.factorize  +  np.bincount \n   # get integer factorization `i` and unique values `r`\n  # for column `'row'`\n  i, r = pd.factorize(df['row'].values)\n  # get integer factorization `j` and unique values `c`\n  # for column `'col'`\n  j, c = pd.factorize(df['col'].values)\n  # `n` will be the number of rows\n  # `m` will be the number of columns\n  n, m = r.size, c.size\n  # `i * m + j` is a clever way of counting the\n  # factorization bins assuming a flat array of length\n  # `n * m`.  Which is why we subsequently reshape as `(n, m)`\n  b = np.bincount(i * m + j, minlength=n * m).reshape(n, m)\n  # BTW, whenever I read this, I think 'Bean, Rice, and Cheese'\n  pd.DataFrame(b, r, c)\n\n        col3  col2  col0  col1  col4\n  row3     2     0     0     1     0\n  row2     1     2     1     0     2\n  row0     1     0     1     2     1\n  row4     2     2     0     1     1\n \n \n pd.get_dummies \n   pd.get_dummies(df['row']).T.dot(pd.get_dummies(df['col']))\n\n        col0  col1  col2  col3  col4\n  row0     1     2     0     1     1\n  row2     1     0     2     1     2\n  row3     0     1     0     2     0\n  row4     0     1     2     2     1\n \n \n \n \n Question 10 \n \n How do I convert a DataFrame from long to wide by pivoting on ONLY two\ncolumns? \n \n \n DataFrame.pivot \n The first step is to assign a number to each row - this number will be the row index of that value in the pivoted result. This is done using  GroupBy.cumcount : \n   df2.insert(0, 'count', df2.groupby('A').cumcount())\n  df2\n\n     count  A   B\n  0      0  a   0\n  1      1  a  11\n  2      2  a   2\n  3      3  a  11\n  4      0  b  10\n  5      1  b  10\n  6      2  b  14\n  7      0  c   7\n \n The second step is to use the newly created column as the index to call  DataFrame.pivot . \n   df2.pivot(*df2)\n  # df2.pivot(index='count', columns='A', values='B')\n\n  A         a     b    c\n  count\n  0       0.0  10.0  7.0\n  1      11.0  10.0  NaN\n  2       2.0  14.0  NaN\n  3      11.0   NaN  NaN\n \n \n DataFrame.pivot_table \n Whereas  DataFrame.pivot  only accepts columns,  DataFrame.pivot_table  also accepts arrays, so the  GroupBy.cumcount  can be passed directly as the  index  without creating an explicit column. \n   df2.pivot_table(index=df2.groupby('A').cumcount(), columns='A', values='B')\n\n  A         a     b    c\n  0       0.0  10.0  7.0\n  1      11.0  10.0  NaN\n  2       2.0  14.0  NaN\n  3      11.0   NaN  NaN\n \n \n \n \n Question 11 \n \n How do I flatten the multiple index to single index after  pivot \n \n If  columns  type  object  with string  join \n df.columns = df.columns.map('|'.join)\n \n else  format \n df.columns = df.columns.map('{0[0]}|{0[1]}'.format)\n \n    ", "date_posted": "2021-08-07 11:42:55Z", "upvote": "\r\n            415\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "13138364", "name": "tdy", "reputation_score": "28.3k"}, "answer_comments": [{"stack_answer_id": "47152692", "stack_answer_comment_id": "82623451", "comment_content": "Could you please consider extending ", "user_id": "None"}, {"stack_answer_id": "47152692", "stack_answer_comment_id": "102665493", "comment_content": "what happened with the answer to Question #10? I get ", "user_id": "None"}, {"stack_answer_id": "47152692", "stack_answer_comment_id": "107880395", "comment_content": "it is not necessary to insert the column in question 10, it can be passed directly as an argument in the pivot table", "user_id": "None"}, {"stack_answer_id": "47152692", "stack_answer_comment_id": "108269681", "comment_content": "@MonicaHeddneck I believe the references to ", "user_id": "None"}, {"stack_answer_id": "47152692", "stack_answer_comment_id": "124327698", "comment_content": "When I would want to pivot a DataFrame, my first question would not be \"Why do I get some error\", but rather: given some input and some desired pivoted output, what function do I need to call and which parameters do I need to pass to get that output? If you already know it's called \"pivot\", that probably isn't too difficult to figure out, but a basic example can still help and perhaps the bigger problem is when questions that just ask ", "user_id": "None"}]}, {"stack_answer_id": "62219652", "answer_content": "\r\n To extend  @piRSquared's answer  another version of  Question 10 \n\n Question 10.1 \n\n DataFrame: \n\n d = data = {'A': {0: 1, 1: 1, 2: 1, 3: 2, 4: 2, 5: 3, 6: 5},\n 'B': {0: 'a', 1: 'b', 2: 'c', 3: 'a', 4: 'b', 5: 'a', 6: 'c'}}\ndf = pd.DataFrame(d)\n\n   A  B\n0  1  a\n1  1  b\n2  1  c\n3  2  a\n4  2  b\n5  3  a\n6  5  c\n \n\n Output: \n\n    0     1     2\nA\n1  a     b     c\n2  a     b  None\n3  a  None  None\n5  c  None  None\n \n\n \n\n Using  df.groupby  and  pd.Series.tolist \n\n t = df.groupby('A')['B'].apply(list)\nout = pd.DataFrame(t.tolist(),index=t.index)\nout\n   0     1     2\nA\n1  a     b     c\n2  a     b  None\n3  a  None  None\n5  c  None  None\n \n\n Or \nA much better alternative using  pd.pivot_table  with  df.squeeze. \n\n t = df.pivot_table(index='A',values='B',aggfunc=list).squeeze()\nout = pd.DataFrame(t.tolist(),index=t.index)\n \n    ", "date_posted": "2020-06-05 20:59:49Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "12416453", "name": "Ch3steR", "reputation_score": "19.3k"}, "answer_comments": []}, {"stack_answer_id": "66237613", "answer_content": "\r\n To better understand how  pivot  works you can look at the  example  from Pandas documentation: \n \n df = pd.DataFrame({\n    'foo': ['one', 'one', 'one', 'two', 'two', 'two'],\n    'bar': ['A', 'B', 'C', 'A', 'B', 'C'],\n    'baz': [1, 2, 3, 4, 5, 6],\n    'zoo': ['x', 'y', 'z', 'q', 'w', 't']\n})\n \n Input Table: \n    foo bar  baz zoo\n0  one   A    1   x\n1  one   B    2   y\n2  one   C    3   z\n3  two   A    4   q\n4  two   B    5   w\n5  two   C    6   t\n \n Pivot : \n pd.pivot(\n    data=df,        \n    index='foo',    # Column to use to make new frame\u2019s index. If None, uses existing index.\n    columns='bar',  # Column to use to make new frame\u2019s columns.\n    values='baz'    # Column(s) to use for populating new frame\u2019s values.\n)\n \n Output table: \n bar  A  B  C\nfoo         \none  1  2  3\ntwo  4  5  6\n \n    ", "date_posted": "2021-02-17 07:42:14Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "8973620", "name": "Mykola Zotko", "reputation_score": "12.6k"}, "answer_comments": []}, {"stack_answer_id": "73060100", "answer_content": "\r\n You can use list of column names as  index ,  columns  and  values  arguments. \n rows, cols, vals, aggfuncs = ['row', 'key'], ['col', 'item'], ['val0', 'val1'], ['mean', 'sum']\n\ndf.groupby(rows+cols)[vals].agg(aggfuncs).unstack(cols)\n# equivalently,\ndf.pivot_table(vals, rows, cols, aggfuncs)\n\n\ndf.set_index(rows+cols)[vals].unstack(cols)\n# equivalently, \ndf.pivot(rows, cols, vals)\n \n You can also apply the insight from Question 10 to multi-column pivot operation as well. Simply append the auxiliary index from  groupby().cumcount()  to either  rows  or  cols  depending on how you want your result to be (appending it to  rows  makes the result \"long\", and appending it to  cols  makes it \"wide\"). Additionally, calling  droplevel().reset_index()  fixes the surplus and duplicate index issue. \n # for \"long\" result\ndf.assign(ix=df.groupby(rows+cols).cumcount()).pivot(rows+['ix'], cols, vals).droplevel(-1).reset_index()\n\n# for \"wide\" result\ndf.assign(ix=df.groupby(rows+cols).cumcount()).pivot(rows, cols+['ix'], vals).droplevel(-1, axis=1).reset_index()\n \n For example, the following doesn't work. \n df = pd.DataFrame({'A': [1, 1, 2], 'B': ['a', 'a', 'b'], 'C': range(3)})\ndf.pivot('A','B','C')\n \n But the following work: \n # long\n(\n    df.assign(ix=df.groupby(['A','B']).cumcount())\n    .pivot(['A','ix'], 'B', 'C')\n    .droplevel(-1).reset_index()\n)\n\nB  A    a    b\n0  1  0.0  NaN\n1  1  1.0  NaN\n2  2  NaN  2.0\n\n\n\n# wide\n(\n    df.assign(ix=df.groupby(['A','B']).cumcount())\n    .pivot('A', ['B', 'ix'], 'C')\n    .droplevel(-1, axis=1).reset_index()\n)\n\nB  A    a    a    b\n0  1  0.0  1.0  NaN\n1  2  NaN  NaN  2.0\n \n \n pivot_table()  with  aggfunc  results in aggregated data, which is very similar to a  groupby.agg() .  pivot()  is simply reshaping and/or stacking data (reminiscent of numpy reshape and stack methods), so naturally, it's related to their pandas cousins,  unstack()  and  stack() . \n In fact, if we check the  source code , internally, each method pair are the same. \n \n pivot_table = groupby + unstack \n pivot = set_index + unstack \n crosstab = pivot_table \n \n Using the setup in the OP: \n from numpy.core.defchararray import add\nnp.random.seed([3,1415])\nn = 20\n\ncols = np.array(['key', 'row', 'item', 'col'])\narr1 = (np.random.randint(5, size=(n, 4)) // [2, 1, 2, 1]).astype(str)\n\ndf = pd.DataFrame(add(cols, arr1), columns=cols).join(pd.DataFrame(np.random.rand(n, 2).round(2)).add_prefix('val'))\n\nrows, cols, vals, aggfuncs = ['row', 'key'], ['col', 'val1'], ['val0'], ['mean', 'sum']\n \n \n pivot_table()  aggregates the values and unstacks it. Specifically, it creates a single flat list out of index and columns, calls  groupby()  with this list as the grouper and aggregates using the passed aggregator methods (the default is  mean ). Then after aggregation, it calls  unstack()  by the list of columns. So internally,  pivot_table = groupby + unstack . Moreover, if  fill_value  is passed,  fillna()  is called. \n In other words, the method that produces  pv_1  is the same as the method that produces  gb_1  in the example below. \n \n \n pv_1 = df.pivot_table(index=rows, columns=cols, values=vals, aggfunc=aggfuncs, fill_value=0)\n# internal operation of `pivot_table()`\ngb_1 = df.groupby(rows+cols)[vals].agg(aggfuncs).unstack(cols).fillna(0, downcast=\"infer\")\npv_1.equals(gb_1) # True\n \n \n pivot()  creates a MultiIndex from the column values passed as index and columns, builds a MultiIndex DataFrame and calls  unstack()  by the list of columns. So internally,  pivot = set_index + unstack . \n In other words, all of the following are True: \n \n \n # if the entire df needs to be pivoted\npv_2 = df.pivot(index=rows, columns=cols)\n# internal operation of `pivot()`\nsu_2 = df.set_index(rows+cols).unstack(cols)\npv_2.equals(su_2) # True\n\n# if only subset of df.columns need to be considered for pivot, specify so\npv_3 = df.pivot(index=rows, columns=cols, values=vals)\nsu_3 = df.set_index(rows+cols)[vals].unstack(cols)\npv_3.equals(su_3) # True\n\n# this is the precise method used internally (building a new DF seems to be faster than set_index of an existing one)\npv_4 = df.pivot(index=rows, columns=cols, values=vals)\nsu_4 = pd.DataFrame(df[vals].values, index=pd.MultiIndex.from_arrays([df[c] for c in rows+cols]), columns=vals).unstack(cols)\npv_4.equals(su_4) # True\n \n \n crosstab()  calls  pivot_table() , i.e.,  crosstab = pivot_table . Specifically, it builds a DataFrame out of the passed arrays of values, filters it by the common indices and calls  pivot_table() . It's more limited than  pivot_table()  because it only allows a one-dimensional array-like as  values , unlike  pivot_table()  that can have multiple columns as  values . \n In other words, the following is True. \n \n \n indexes, columns, values = [df[r] for r in rows], [df[c] for c in cols], next(df[v] for v in vals)\n# crosstab\nct_5 = pd.crosstab(indexes, columns, values, aggfunc=aggfuncs)\n# internal operation (abbreviated)\nfrom functools import reduce\ndata = pd.DataFrame({f'row_{i}': r for i, r in enumerate(indexes)} | {f'col_{i}': c for i, c in enumerate(columns)} | {'v': values}, \n                    index = reduce(lambda x, y: x.intersection(y.index), indexes[1:]+columns, indexes[0].index)\n                   )\npv_5 = data.pivot_table('v', [k for k in data if k[:4]=='row_'], [k for k in data if k[:4]=='col_'], aggfuncs)\nct_5.equals(pv_5) # True\n \n    ", "date_posted": "2022-07-21 02:41:29Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "19123103", "name": "not a robot", "reputation_score": "4,023"}, "answer_comments": []}], "user": {"stack_user_id": "2336654", "name": "piRSquared", "reputation_score": "270k"}, "question_comments": []},
{"stack_question_id": "2612802", "question_title": "How do I clone a list so that it doesn't change unexpectedly after assignment?", "question_content": "\r\n                While using new_list = my_list, any modifications to new_list changes my_list every time. Why is this, and how can I clone or copy the list to prevent it?\r\n", "question_url": "/questions/2612802/how-do-i-clone-a-list-so-that-it-doesnt-change-unexpectedly-after-assignment", "date_posted": "Apr 10, 2010 at 8:49", "upvote": "3", "view": "2", "tags": ["python", "list", "reference", "copy", "clone"], "answers_count": "2", "answers": [{"stack_answer_id": "2612815", "answer_content": "\r\n new_list = my_list  doesn't actually create a second list. The assignment just copies the reference to the list, not the actual list, so both  new_list  and  my_list  refer to the same list after the assignment. \n To actually copy the list, you have several options: \n \n You can use the builtin  list.copy()  method (available since Python 3.3): \n new_list = old_list.copy()\n \n \n You can slice it: \n new_list = old_list[:]\n \n Alex Martelli 's opinion (at least  back in 2007 ) about this is, that  it is a weird syntax and it does not make sense to use it ever . ;) (In his opinion, the next one is more readable). \n \n You can use the built in  list()  constructor: \n new_list = list(old_list)\n \n \n You can use generic  copy.copy() : \n import copy\nnew_list = copy.copy(old_list)\n \n This is a little slower than  list()  because it has to find out the datatype of  old_list  first. \n \n If you need to copy the elements of the list as well, use generic  copy.deepcopy() : \n import copy\nnew_list = copy.deepcopy(old_list)\n \n Obviously the slowest and most memory-needing method, but sometimes unavoidable. This operates recursively; it will handle any number of levels of nested lists (or other containers). \n \n \n Example: \n import copy\n\nclass Foo(object):\n    def __init__(self, val):\n         self.val = val\n\n    def __repr__(self):\n        return f'Foo({self.val!r})'\n\nfoo = Foo(1)\n\na = ['foo', foo]\nb = a.copy()\nc = a[:]\nd = list(a)\ne = copy.copy(a)\nf = copy.deepcopy(a)\n\n# edit orignal list and instance \na.append('baz')\nfoo.val = 5\n\nprint(f'original: {a}\\nlist.copy(): {b}\\nslice: {c}\\nlist(): {d}\\ncopy: {e}\\ndeepcopy: {f}')\n \n Result: \n original: ['foo', Foo(5), 'baz']\nlist.copy(): ['foo', Foo(5)]\nslice: ['foo', Foo(5)]\nlist(): ['foo', Foo(5)]\ncopy: ['foo', Foo(5)]\ndeepcopy: ['foo', Foo(1)]\n \n    ", "date_posted": "2022-08-16 00:48:58Z", "upvote": "\r\n            3875\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "4518341", "name": "wjandrea", "reputation_score": "24.1k"}, "answer_comments": [{"stack_answer_id": "2612815", "stack_answer_comment_id": "115618926", "comment_content": "As @Georgy points out correctly in the answer below, any changes to the new_list values will also change the values in my_list. So actually the copy.deepcopy() method is the only real copy without reference to the original list and it's values.", "user_id": "None"}, {"stack_answer_id": "2612815", "stack_answer_comment_id": "129567928", "comment_content": "@moojen If ", "user_id": "None"}, {"stack_answer_id": "2612815", "stack_answer_comment_id": "129602871", "comment_content": "@wjandrea Why copy a list of immutable objects?", "user_id": "None"}, {"stack_answer_id": "2612815", "stack_answer_comment_id": "129605566", "comment_content": "@moojen Because the list itself is mutable, and a new assignment only creates a reference. E.g. ", "user_id": "None"}]}, {"stack_answer_id": "2612990", "answer_content": "\r\n Felix already provided an excellent answer, but I thought I'd do a speed comparison of the various methods: \n \n 10.59 sec (105.9 \u00b5s/itn) -   copy.deepcopy(old_list) \n 10.16 sec (101.6 \u00b5s/itn) - pure Python  Copy()  method copying classes with deepcopy \n 1.488 sec (14.88 \u00b5s/itn) - pure Python  Copy()  method not copying classes (only dicts/lists/tuples) \n 0.325 sec (3.25 \u00b5s/itn) -  for item in old_list: new_list.append(item) \n 0.217 sec (2.17 \u00b5s/itn) -  [i for i in old_list]  (a  list comprehension ) \n 0.186 sec (1.86 \u00b5s/itn) -  copy.copy(old_list) \n 0.075 sec (0.75 \u00b5s/itn) -  list(old_list) \n 0.053 sec (0.53 \u00b5s/itn) -  new_list = []; new_list.extend(old_list) \n 0.039 sec (0.39 \u00b5s/itn) -  old_list[:]  ( list slicing ) \n \n So the fastest is list slicing. But be aware that  copy.copy() ,  list[:]  and  list(list) , unlike  copy.deepcopy()  and the python version don't copy any lists, dictionaries and class instances in the list, so if the originals change, they will change in the copied list too and vice versa. \n (Here's the script if anyone's interested or wants to raise any issues:) \n from copy import deepcopy\n\nclass old_class:\n    def __init__(self):\n        self.blah = 'blah'\n\nclass new_class(object):\n    def __init__(self):\n        self.blah = 'blah'\n\ndignore = {str: None, unicode: None, int: None, type(None): None}\n\ndef Copy(obj, use_deepcopy=True):\n    t = type(obj)\n\n    if t in (list, tuple):\n        if t == tuple:\n            # Convert to a list if a tuple to\n            # allow assigning to when copying\n            is_tuple = True\n            obj = list(obj)\n        else:\n            # Otherwise just do a quick slice copy\n            obj = obj[:]\n            is_tuple = False\n\n        # Copy each item recursively\n        for x in xrange(len(obj)):\n            if type(obj[x]) in dignore:\n                continue\n            obj[x] = Copy(obj[x], use_deepcopy)\n\n        if is_tuple:\n            # Convert back into a tuple again\n            obj = tuple(obj)\n\n    elif t == dict:\n        # Use the fast shallow dict copy() method and copy any\n        # values which aren't immutable (like lists, dicts etc)\n        obj = obj.copy()\n        for k in obj:\n            if type(obj[k]) in dignore:\n                continue\n            obj[k] = Copy(obj[k], use_deepcopy)\n\n    elif t in dignore:\n        # Numeric or string/unicode?\n        # It's immutable, so ignore it!\n        pass\n\n    elif use_deepcopy:\n        obj = deepcopy(obj)\n    return obj\n\nif __name__ == '__main__':\n    import copy\n    from time import time\n\n    num_times = 100000\n    L = [None, 'blah', 1, 543.4532,\n         ['foo'], ('bar',), {'blah': 'blah'},\n         old_class(), new_class()]\n\n    t = time()\n    for i in xrange(num_times):\n        Copy(L)\n    print 'Custom Copy:', time()-t\n\n    t = time()\n    for i in xrange(num_times):\n        Copy(L, use_deepcopy=False)\n    print 'Custom Copy Only Copying Lists/Tuples/Dicts (no classes):', time()-t\n\n    t = time()\n    for i in xrange(num_times):\n        copy.copy(L)\n    print 'copy.copy:', time()-t\n\n    t = time()\n    for i in xrange(num_times):\n        copy.deepcopy(L)\n    print 'copy.deepcopy:', time()-t\n\n    t = time()\n    for i in xrange(num_times):\n        L[:]\n    print 'list slicing [:]:', time()-t\n\n    t = time()\n    for i in xrange(num_times):\n        list(L)\n    print 'list(L):', time()-t\n\n    t = time()\n    for i in xrange(num_times):\n        [i for i in L]\n    print 'list expression(L):', time()-t\n\n    t = time()\n    for i in xrange(num_times):\n        a = []\n        a.extend(L)\n    print 'list extend:', time()-t\n\n    t = time()\n    for i in xrange(num_times):\n        a = []\n        for y in L:\n            a.append(y)\n    print 'list append:', time()-t\n\n    t = time()\n    for i in xrange(num_times):\n        a = []\n        a.extend(i for i in L)\n    print 'generator expression extend:', time()-t\n \n    ", "date_posted": "2021-05-11 21:36:34Z", "upvote": "\r\n            732\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "2612990", "stack_answer_comment_id": "119115083", "comment_content": "Does it mean that append and list comprehension are the best options?", "user_id": "None"}, {"stack_answer_id": "2612990", "stack_answer_comment_id": "124242121", "comment_content": "I keep on coming back to this answer to make sure that I am using the most efficient method. What is the easiest way to test this? Or is there a database with all of the best ways to minimise run time?", "user_id": "None"}, {"stack_answer_id": "2612990", "stack_answer_comment_id": "129567914", "comment_content": "These numbers might be outdated. I tried running ", "user_id": "None"}]}, {"stack_answer_id": "17810305", "answer_content": "\r\n I've  been told  that Python 3.3+  adds the  list.copy()  method, which should be as fast as slicing: \n newlist = old_list.copy()\n \n    ", "date_posted": "2021-05-11 21:37:30Z", "upvote": "\r\n            178\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "17810305", "stack_answer_comment_id": "91949096", "comment_content": "Yes, and as per docs ", "user_id": "None"}, {"stack_answer_id": "17810305", "stack_answer_comment_id": "108624099", "comment_content": "Actually it seems that currently, ", "user_id": "None"}, {"stack_answer_id": "17810305", "stack_answer_comment_id": "115053799", "comment_content": "@loved.by.Jesus: Yeah, they ", "user_id": "None"}, {"stack_answer_id": "17810305", "stack_answer_comment_id": "115053871", "comment_content": "Of course, they're working on ", "user_id": "None"}]}, {"stack_answer_id": "26562235", "answer_content": "\r\n \n   What are the options to clone or copy a list in Python? \n \n\n In Python 3, a shallow copy can be made with: \n\n a_copy = a_list.copy()\n \n\n In Python 2 and 3, you can get a shallow copy with a full slice of the original: \n\n a_copy = a_list[:]\n \n\n Explanation \n\n There are two semantic ways to copy a list. A shallow copy creates a new list of the same objects, a deep copy creates a new list containing new equivalent objects. \n\n Shallow list copy \n\n A shallow copy only copies the list itself, which is a container of references to the objects in the list. If the objects contained themselves are mutable and one is changed, the change will be reflected in both lists.  \n\n There are different ways to do this in Python 2 and 3. The Python 2 ways will also work in Python 3. \n\n Python 2 \n\n In Python 2, the idiomatic way of making a shallow copy of a list is with a complete slice of the original: \n\n a_copy = a_list[:]\n \n\n You can also accomplish the same thing by passing the list through the list constructor,  \n\n a_copy = list(a_list)\n \n\n but using the constructor is less efficient: \n\n >>> timeit\n>>> l = range(20)\n>>> min(timeit.repeat(lambda: l[:]))\n0.30504298210144043\n>>> min(timeit.repeat(lambda: list(l)))\n0.40698814392089844\n \n\n Python 3 \n\n In Python 3, lists get the  list.copy  method: \n\n a_copy = a_list.copy()\n \n\n In Python 3.5: \n\n >>> import timeit\n>>> l = list(range(20))\n>>> min(timeit.repeat(lambda: l[:]))\n0.38448613602668047\n>>> min(timeit.repeat(lambda: list(l)))\n0.6309100328944623\n>>> min(timeit.repeat(lambda: l.copy()))\n0.38122922903858125\n \n\n Making another pointer does  not  make a copy \n\n \n   Using new_list = my_list then modifies new_list every time my_list changes. Why is this? \n \n\n my_list  is just a name that points to the actual list in memory. When you say  new_list = my_list  you're not making a copy, you're just adding another name that points at that original list in memory. We can have similar issues when we make copies of lists.  \n\n >>> l = [[], [], []]\n>>> l_copy = l[:]\n>>> l_copy\n[[], [], []]\n>>> l_copy[0].append('foo')\n>>> l_copy\n[['foo'], [], []]\n>>> l\n[['foo'], [], []]\n \n\n The list is just an array of pointers to the contents, so a shallow copy just copies the pointers, and so you have two different lists, but they have the same contents. To make copies of the contents, you need a deep copy. \n\n Deep copies \n\n To make a  deep copy of a list, in Python 2 or 3, use  deepcopy  in the  copy  module : \n\n import copy\na_deep_copy = copy.deepcopy(a_list)\n \n\n To demonstrate how this allows us to make new sub-lists: \n\n >>> import copy\n>>> l\n[['foo'], [], []]\n>>> l_deep_copy = copy.deepcopy(l)\n>>> l_deep_copy[0].pop()\n'foo'\n>>> l_deep_copy\n[[], [], []]\n>>> l\n[['foo'], [], []]\n \n\n And so we see that the deep copied list is an entirely different list from the original. You could roll your own function - but don't. You're likely to create bugs you otherwise wouldn't have by using the standard library's deepcopy function. \n\n Don't use  eval \n\n You may see this used as a way to deepcopy, but don't do it: \n\n problematic_deep_copy = eval(repr(a_list))\n \n\n \n It's dangerous, particularly if you're evaluating something from a source you don't trust. \n It's not reliable, if a subelement you're copying doesn't have a representation that can be eval'd to reproduce an equivalent element. \n It's also less performant.  \n \n\n In 64 bit Python 2.7: \n\n >>> import timeit\n>>> import copy\n>>> l = range(10)\n>>> min(timeit.repeat(lambda: copy.deepcopy(l)))\n27.55826997756958\n>>> min(timeit.repeat(lambda: eval(repr(l))))\n29.04534101486206\n \n\n on 64 bit Python 3.5: \n\n >>> import timeit\n>>> import copy\n>>> l = list(range(10))\n>>> min(timeit.repeat(lambda: copy.deepcopy(l)))\n16.84255409205798\n>>> min(timeit.repeat(lambda: eval(repr(l))))\n34.813894678023644\n \n    ", "date_posted": "2018-01-09 15:33:11Z", "upvote": "\r\n            148\r\n        ", "accepted": "No", "user": {"stack_user_id": "541136", "name": "Russia Must Remove Putin", "reputation_score": "347k"}, "answer_comments": [{"stack_answer_id": "26562235", "stack_answer_comment_id": "95089106", "comment_content": "You don't need a deepcopy if the list is 2D. If it is a list of lists, and those lists don't have lists inside of them, you can use a for loop. Presently, I am using   ", "user_id": "None"}]}, {"stack_answer_id": "47258728", "answer_content": "\r\n Let's start from the beginning and explore this question. \n So let's suppose you have two lists: \n list_1 = ['01', '98']\nlist_2 = [['01', '98']]\n \n And we have to copy both lists, now starting from the first list: \n So first let's try by setting the variable  copy  to our original list,  list_1 : \n copy = list_1\n \n Now if you are thinking copy copied the  list_1 , then you are wrong. The  id  function can show us if two variables can point to the same object. Let's try this: \n print(id(copy))\nprint(id(list_1))\n \n The output is: \n 4329485320\n4329485320\n \n Both variables are the exact same argument. Are you surprised? \n So as we know, Python doesn't store anything in a variable, Variables are just referencing to the object and object store the value. Here object is a  list  but we created two references to that same object by two different variable names. This means that both variables are pointing to the same object, just with different names. \n When you do  copy = list_1 , it is actually doing: \n \n Here in the image  list_1  and  copy  are two variable names, but the object is same for both variable which is  list . \n So if you try to modify copied list then it will modify the original list too because the list is only one there, you will modify that list no matter you do from the copied list or from the original list: \n copy[0] = \"modify\"\n\nprint(copy)\nprint(list_1)\n \n Output: \n ['modify', '98']\n['modify', '98']\n \n So it modified the original list: \n Now let's move onto a Pythonic method for copying lists. \n copy_1 = list_1[:]\n \n This method fixes the first issue we had: \n print(id(copy_1))\nprint(id(list_1))\n\n4338792136\n4338791432\n \n So as we can see our both list having different id and it means that both variables are pointing to different objects. So what actually going on here is: \n \n Now let's try to modify the list and let's see if we still face the previous problem: \n copy_1[0] = \"modify\"\n\nprint(list_1)\nprint(copy_1)\n \n The output is: \n ['01', '98']\n['modify', '98']\n \n As you can see, it only modified the copied list. That means it worked. \n Do you think we're done? No. Let's try to copy our nested list. \n copy_2 = list_2[:]\n \n list_2  should reference to another object which is copy of  list_2 . Let's check: \n print(id((list_2)), id(copy_2))\n \n We get the output: \n 4330403592 4330403528\n \n Now we can assume both lists are pointing different object, so now let's try to modify it and let's see it is giving what we want: \n copy_2[0][1] = \"modify\"\n\nprint(list_2, copy_2)\n \n This gives us the output: \n [['01', 'modify']] [['01', 'modify']]\n \n This may seem a little bit confusing, because the same method we previously used worked. Let's try to understand this. \n When you do: \n copy_2 = list_2[:]\n \n You're only copying the outer list, not the inside list. We can use the  id  function once again to check this. \n print(id(copy_2[0]))\nprint(id(list_2[0]))\n \n The output is: \n 4329485832\n4329485832\n \n When we do  copy_2 = list_2[:] , this happens: \n \n It creates the copy of list, but only outer list copy, not the nested list copy. The nested list is same for both variable, so if you try to modify the nested list then it will modify the original list too as the nested list object is same for both lists. \n What is the solution? The solution is the  deepcopy  function. \n from copy import deepcopy\ndeep = deepcopy(list_2)\n \n Let's check this: \n print(id((list_2)), id(deep))\n\n4322146056 4322148040\n \n Both outer lists have different IDs. Let's try this on the inner nested lists. \n print(id(deep[0]))\nprint(id(list_2[0]))\n \n The output is: \n 4322145992\n4322145800\n \n As you can see both IDs are different, meaning we can assume that both nested lists are pointing different object now. \n This means when you do  deep = deepcopy(list_2)  what actually happens: \n \n Both nested lists are pointing different object and they have separate copy of nested list now. \n Now let's try to modify the nested list and see if it solved the previous issue or not: \n deep[0][1] = \"modify\"\nprint(list_2, deep)\n \n It outputs: \n [['01', '98']] [['01', 'modify']]\n \n As you can see, it didn't modify the original nested list, it only modified the copied list. \n    ", "date_posted": "2021-05-11 21:53:58Z", "upvote": "\r\n            71\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "27091494", "answer_content": "\r\n There are many answers already that tell you how to make a proper copy, but none of them say why your original 'copy' failed.  \n\n Python doesn't store values in variables; it binds names to objects. Your original assignment took the object referred to by  my_list  and bound it to  new_list  as well. No matter which name you use there is still only one list, so changes made when referring to it as  my_list  will persist when referring to it as  new_list . Each of the other answers to this question give you different ways of creating a new object to bind to  new_list .  \n\n Each element of a list acts like a name, in that each element binds non-exclusively to an object. A shallow copy creates a new list whose elements bind to the same objects as before. \n\n new_list = list(my_list)  # or my_list[:], but I prefer this syntax\n# is simply a shorter way of:\nnew_list = [element for element in my_list]\n \n\n To take your list copy one step further, copy each object that your list refers to, and bind those element copies to a new list.  \n\n import copy  \n# each element must have __copy__ defined for this...\nnew_list = [copy.copy(element) for element in my_list]\n \n\n This is not yet a deep copy, because each element of a list may refer to other objects, just like the list is bound to its elements. To recursively copy every element in the list, and then each other object referred to by each element, and so on: perform a deep copy.  \n\n import copy\n# each element must have __deepcopy__ defined for this...\nnew_list = copy.deepcopy(my_list)\n \n\n See  the documentation  for more information about corner cases in copying. \n    ", "date_posted": "2020-06-05 16:01:12Z", "upvote": "\r\n            65\r\n        ", "accepted": "No", "user": {"stack_user_id": "894381", "name": "jack", "reputation_score": "1,984"}, "answer_comments": []}, {"stack_answer_id": "2612808", "answer_content": "\r\n Use  thing[:] \n\n >>> a = [1,2]\n>>> b = a[:]\n>>> a += [3]\n>>> a\n[1, 2, 3]\n>>> b\n[1, 2]\n>>> \n \n    ", "date_posted": "2010-04-10 08:53:06Z", "upvote": "\r\n            48\r\n        ", "accepted": "No", "user": {"stack_user_id": "90025", "name": "Paul Tarjan", "reputation_score": "47.3k"}, "answer_comments": []}, {"stack_answer_id": "43220129", "answer_content": "\r\n Python 3.6 Timings \n Here are the timing results using Python 3.6.8. Keep in mind these times are relative to one another, not absolute. \n I stuck to only doing shallow copies, and also added some new methods that weren't possible in Python\u00a02, such as  list.copy()  (the Python\u00a03  slice equivalent ) and two forms of  list unpacking  ( *new_list, = list  and  new_list = [*list] ): \n METHOD                TIME TAKEN\nb = [*a]               2.75180600000021\nb = a * 1              3.50215399999990\nb = a[:]               3.78278899999986  # Python 2 winner (see above)\nb = a.copy()           4.20556500000020  # Python 3 \"slice equivalent\" (see above)\nb = []; b.extend(a)    4.68069800000012\nb = a[0:len(a)]        6.84498999999959\n*b, = a                7.54031799999984\nb = list(a)            7.75815899999997\nb = [i for i in a]    18.4886440000000\nb = copy.copy(a)      18.8254879999999\nb = []\nfor item in a:\n  b.append(item)      35.4729199999997\n \n We can see the Python 2 winner still does well, but doesn't edge out Python 3  list.copy()  by much, especially considering the superior readability of the latter. \n The dark horse is the unpacking and repacking method ( b = [*a] ), which is ~25% faster than raw slicing, and more than twice as fast as the other unpacking method ( *b, = a ). \n b = a * 1  also does surprisingly well. \n Note that these methods do  not  output equivalent results for any input other than lists.  They all work for sliceable objects, a few work for any iterable, but only  copy.copy()  works for more general Python objects. \n \n Here is the testing code for interested parties ( Template from here ): \n import timeit\n\nCOUNT = 50000000\nprint(\"Array duplicating. Tests run\", COUNT, \"times\")\nsetup = 'a = [0,1,2,3,4,5,6,7,8,9]; import copy'\n\nprint(\"b = list(a)\\t\\t\", timeit.timeit(stmt='b = list(a)', setup=setup, number=COUNT))\nprint(\"b = copy.copy(a)\\t\", timeit.timeit(stmt='b = copy.copy(a)', setup=setup, number=COUNT))\nprint(\"b = a.copy()\\t\\t\", timeit.timeit(stmt='b = a.copy()', setup=setup, number=COUNT))\nprint(\"b = a[:]\\t\\t\", timeit.timeit(stmt='b = a[:]', setup=setup, number=COUNT))\nprint(\"b = a[0:len(a)]\\t\\t\", timeit.timeit(stmt='b = a[0:len(a)]', setup=setup, number=COUNT))\nprint(\"*b, = a\\t\\t\\t\", timeit.timeit(stmt='*b, = a', setup=setup, number=COUNT))\nprint(\"b = []; b.extend(a)\\t\", timeit.timeit(stmt='b = []; b.extend(a)', setup=setup, number=COUNT))\nprint(\"b = []; for item in a: b.append(item)\\t\", timeit.timeit(stmt='b = []\\nfor item in a:  b.append(item)', setup=setup, number=COUNT))\nprint(\"b = [i for i in a]\\t\", timeit.timeit(stmt='b = [i for i in a]', setup=setup, number=COUNT))\nprint(\"b = [*a]\\t\\t\", timeit.timeit(stmt='b = [*a]', setup=setup, number=COUNT))\nprint(\"b = a * 1\\t\\t\", timeit.timeit(stmt='b = a * 1', setup=setup, number=COUNT))\n \n    ", "date_posted": "2021-05-11 21:40:12Z", "upvote": "\r\n            42\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "43220129", "stack_answer_comment_id": "106994593", "comment_content": "Can confirm still a similar story on 3.8 ", "user_id": "None"}, {"stack_answer_id": "43220129", "stack_answer_comment_id": "114824554", "comment_content": "Some of these timing comparisons aren't particularly meaningful when copying such tiny lists. It would be more informative to test with a range of list lengths (including some very large ones).", "user_id": "None"}, {"stack_answer_id": "43220129", "stack_answer_comment_id": "119298412", "comment_content": "The timing numbers ought to rounded to the appropriate number of significant digits. 15 significant digits do not make any sense.", "user_id": "None"}, {"stack_answer_id": "43220129", "stack_answer_comment_id": "119447900", "comment_content": "I've essentially just pasted the raw output of the timing code here. Seems like your gripe is more about how ", "user_id": "None"}, {"stack_answer_id": "43220129", "stack_answer_comment_id": "128722434", "comment_content": "Is the ", "user_id": "None"}]}, {"stack_answer_id": "2612810", "answer_content": "\r\n Python's idiom for doing this is  newList = oldList[:] \n    ", "date_posted": "2010-04-10 08:53:19Z", "upvote": "\r\n            36\r\n        ", "accepted": "No", "user": {"stack_user_id": "260584", "name": "erisco", "reputation_score": "13.9k"}, "answer_comments": []}, {"stack_answer_id": "31332158", "answer_content": "\r\n All of the other contributors gave  great  answers, which work when you have a single dimension (leveled) list, however of the methods mentioned so far, only  copy.deepcopy()  works to clone/copy a list and not have it point to the nested  list  objects when you are working with multidimensional, nested lists (list of lists). While  Felix Kling  refers to it in his answer, there is a little bit more to the issue and possibly a workaround using built-ins that might prove a faster alternative to  deepcopy . \n While  new_list = old_list[:] ,  copy.copy(old_list)'  and for Py3k  old_list.copy()  work for single-leveled lists, they revert to pointing at the  list  objects nested within the  old_list  and the  new_list , and changes to one of the  list  objects are perpetuated in the other. \n Edit: New information brought to light \n \n As was pointed out by both  Aaron Hall  and  PM 2Ring   using  eval()  is not only a bad idea, it is also much slower than  copy.deepcopy() . \n This means that for multidimensional lists, the only option is  copy.deepcopy() . With that being said, it really isn't an option as the performance goes way south when you try to use it on a moderately sized multidimensional array.  I tried to  timeit  using a 42x42 array, not unheard of or even that large for bioinformatics applications, and I gave up on waiting for a response and just started typing my edit to this post. \n It would seem that the only real option then is to initialize multiple lists and work on them independently. If anyone has any other suggestions, for how to handle multidimensional list copying, it would be appreciated. \n \n As others have stated, there   are significant  performance issues using the  copy  module and  copy.deepcopy   for multidimensional lists . \n    ", "date_posted": "2020-06-20 09:12:55Z", "upvote": "\r\n            21\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": [{"stack_answer_id": "31332158", "stack_answer_comment_id": "50671649", "comment_content": "This won't always work, since there's no guarantee that the string returned by ", "user_id": "None"}, {"stack_answer_id": "31332158", "stack_answer_comment_id": "50675773", "comment_content": "Fair point. Though I think that Batchelder's point is that the having the ", "user_id": "None"}, {"stack_answer_id": "31332158", "stack_answer_comment_id": "50676956", "comment_content": "As @AaronHall has pointed out, there is likely a significant performance issue to using ", "user_id": "None"}]}, {"stack_answer_id": "48980683", "answer_content": "\r\n It surprises me that this hasn't been mentioned yet, so for the sake of completeness... \n\n You can perform list unpacking with the \"splat operator\":  * , which will also copy elements of your list. \n\n old_list = [1, 2, 3]\n\nnew_list = [*old_list]\n\nnew_list.append(4)\nold_list == [1, 2, 3]\nnew_list == [1, 2, 3, 4]\n \n\n The obvious downside to this method is that it is only available in Python 3.5+. \n\n Timing wise though, this appears to perform better than other common methods. \n\n x = [random.random() for _ in range(1000)]\n\n%timeit a = list(x)\n%timeit a = x.copy()\n%timeit a = x[:]\n\n%timeit a = [*x]\n\n#: 2.47 \u00b5s \u00b1 38.1 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n#: 2.47 \u00b5s \u00b1 54.6 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n#: 2.39 \u00b5s \u00b1 58.2 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n\n#: 2.22 \u00b5s \u00b1 43.2 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n \n    ", "date_posted": "2018-02-26 02:33:47Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "1112586", "name": "SCB", "reputation_score": "5,501"}, "answer_comments": [{"stack_answer_id": "48980683", "stack_answer_comment_id": "91902477", "comment_content": "How does this method behave when modifying copies?", "user_id": "None"}, {"stack_answer_id": "48980683", "stack_answer_comment_id": "91940819", "comment_content": "@not2qubit do you mean appending to or editing elements of the new list. In the example ", "user_id": "None"}]}, {"stack_answer_id": "44768652", "answer_content": "\r\n new_list = my_list[:]\n \n new_list = my_list \n Try to understand this. Let's say that  my_list  is in the heap memory at location X, i.e.,  my_list  is pointing to the X. Now by assigning  new_list = my_list  you're letting  new_list  point to the X. This is known as a  shallow copy . \n Now if you assign  new_list = my_list[:] , you're simply copying each object of  my_list  to  new_list . This is known as a  deep copy . \n The  other  ways you can do this are: \n \n \n new_list = list(old_list)\n \n \n \n import copy\nnew_list = copy.deepcopy(old_list)\n \n \n \n    ", "date_posted": "2021-11-19 17:44:52Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "1871033", "name": "CherryDT", "reputation_score": "21.9k"}, "answer_comments": [{"stack_answer_id": "44768652", "stack_answer_comment_id": "125710533", "comment_content": "Technically, ", "user_id": "None"}]}, {"stack_answer_id": "47050612", "answer_content": "\r\n A very simple approach independent of python version was missing in already-given answers which you can use most of the time (at least I do): \n new_list = my_list * 1       # Solution 1 when you are not using nested lists\n \n However,  if   my_list  contains other containers (for example, nested lists) you must use  deepcopy  as others suggested in the answers above from the copy library. For example: \n import copy\nnew_list = copy.deepcopy(my_list)   # Solution 2 when you are using nested lists\n \n . Bonus : If you don't want to copy elements use (AKA shallow copy): \n new_list = my_list[:]\n \n \n Let's understand difference between solution #1 and solution #2 \n >>> a = range(5)\n>>> b = a*1\n>>> a,b\n([0, 1, 2, 3, 4], [0, 1, 2, 3, 4])\n>>> a[2] = 55\n>>> a,b\n([0, 1, 55, 3, 4], [0, 1, 2, 3, 4])\n \n As you can see, solution #1 worked perfectly when we were not using the nested lists. Let's check what will happen when we apply solution #1 to nested lists. \n >>> from copy import deepcopy\n>>> a = [range(i,i+4) for i in range(3)]\n>>> a\n[[0, 1, 2, 3], [1, 2, 3, 4], [2, 3, 4, 5]]\n>>> b = a*1\n>>> c = deepcopy(a)\n>>> for i in (a, b, c): print i\n[[0, 1, 2, 3], [1, 2, 3, 4], [2, 3, 4, 5]]\n[[0, 1, 2, 3], [1, 2, 3, 4], [2, 3, 4, 5]]\n[[0, 1, 2, 3], [1, 2, 3, 4], [2, 3, 4, 5]]\n>>> a[2].append('99')\n>>> for i in (a, b, c): print i\n[[0, 1, 2, 3], [1, 2, 3, 4], [2, 3, 4, 5, 99]]\n[[0, 1, 2, 3], [1, 2, 3, 4], [2, 3, 4, 5, 99]]   # Solution #1 didn't work in nested list\n[[0, 1, 2, 3], [1, 2, 3, 4], [2, 3, 4, 5]]       # Solution #2 - DeepCopy worked in nested list\n \n    ", "date_posted": "2021-05-11 21:48:59Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "57838754", "answer_content": "\r\n I wanted to post something a bit different than some of the other answers. Even though this is most likely not the most understandable, or fastest option, it provides a bit of an inside view of how deep copy works, as well as being another alternative option for deep copying. It doesn't really matter if my function has bugs, since the point of this is to show a way to copy objects like the question answers, but also to use this as a point to explain how deepcopy works at its core. \n At the core of any deep copy function is way to make a shallow copy. How? Simple. Any deep copy function only duplicates the containers of immutable objects. When you deepcopy a nested list, you are only duplicating the outer lists, not the mutable objects inside of the lists. You are only duplicating the containers. The same works for classes, too. When you deepcopy a class, you deepcopy all of its mutable attributes. So, how? How come you only have to copy the containers, like lists, dicts, tuples, iters, classes, and class instances? \n It's simple. A mutable object can't really be duplicated. It can never be changed, so it is only a single value. That means you never have to duplicate strings, numbers, bools, or any of those. But how would you duplicate the containers? Simple. You make just initialize a new container with all of the values. Deepcopy relies on recursion. It duplicates all the containers, even ones with containers inside of them, until no containers are left. A container is an immutable object. \n Once you know that, completely duplicating an object without any references is pretty easy. Here's a function for deepcopying basic data-types (wouldn't work for custom classes but you could always add that) \n def deepcopy(x):\n  immutables = (str, int, bool, float)\n  mutables = (list, dict, tuple)\n  if isinstance(x, immutables):\n    return x\n  elif isinstance(x, mutables):\n    if isinstance(x, tuple):\n      return tuple(deepcopy(list(x)))\n    elif isinstance(x, list):\n      return [deepcopy(y) for y in x]\n    elif isinstance(x, dict):\n      values = [deepcopy(y) for y in list(x.values())]\n      keys = list(x.keys())\n      return dict(zip(keys, values))\n \n Python's own built-in deepcopy is based around that example. The only difference is it supports other types, and also supports user-classes by duplicating the attributes into a new duplicate class, and also blocks infinite-recursion with a reference to an object it's already seen using a memo list or dictionary. And that's really it for making deep copies. At its core, making a deep copy is just making shallow copies. I hope this answer adds something to the question. \n EXAMPLES \n Say you have this list:  [1, 2, 3] . The immutable numbers cannot be duplicated, but the other layer can. You can duplicate it using a list comprehension:  [x for x in [1, 2, 3]] \n Now, imagine you have this list:  [[1, 2], [3, 4], [5, 6]] . This time, you want to make a function, which uses recursion to deep copy all layers of the list. Instead of the previous list comprehension: \n [x for x in _list]\n \n It uses a new one for lists: \n [deepcopy_list(x) for x in _list]\n \n And  deepcopy_list  looks like this: \n def deepcopy_list(x):\n  if isinstance(x, (str, bool, float, int)):\n    return x\n  else:\n    return [deepcopy_list(y) for y in x]\n \n Then now you have a function which can deepcopy any list of  strs, bools, floast, ints  and even  lists  to infinitely many layers using recursion. And there you have it, deepcopying. \n TLDR : Deepcopy uses recursion to duplicate objects, and merely returns the same immutable objects as before, as immutable objects cannot be duplicated. However, it deepcopies the most inner layers of mutable objects until it reaches the outermost mutable layer of an object. \n    ", "date_posted": "2021-08-26 16:10:55Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "11741338", "name": "Corman", "reputation_score": "669"}, "answer_comments": []}, {"stack_answer_id": "50373643", "answer_content": "\r\n Note that there are some cases where if you have defined your own custom class and you want to keep the attributes then you should use  copy.copy()  or  copy.deepcopy()  rather than the alternatives, for example in Python 3: \n\n import copy\n\nclass MyList(list):\n    pass\n\nlst = MyList([1,2,3])\n\nlst.name = 'custom list'\n\nd = {\n'original': lst,\n'slicecopy' : lst[:],\n'lstcopy' : lst.copy(),\n'copycopy': copy.copy(lst),\n'deepcopy': copy.deepcopy(lst)\n}\n\n\nfor k,v in d.items():\n    print('lst: {}'.format(k), end=', ')\n    try:\n        name = v.name\n    except AttributeError:\n        name = 'NA'\n    print('name: {}'.format(name))\n \n\n Outputs: \n\n lst: original, name: custom list\nlst: slicecopy, name: NA\nlst: lstcopy, name: NA\nlst: copycopy, name: custom list\nlst: deepcopy, name: custom list\n \n    ", "date_posted": "2018-05-16 14:31:22Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "6260170", "name": "Chris_Rands", "reputation_score": "35.9k"}, "answer_comments": []}, {"stack_answer_id": "60352267", "answer_content": "\r\n Remember that in Python when you do: \n\n     list1 = ['apples','bananas','pineapples']\n    list2 = list1\n \n\n List2 isn't storing the actual list, but a reference to list1. So when you do anything to list1, list2 changes as well. use the copy module (not default, download on pip) to make an original copy of the list( copy.copy()  for simple lists,  copy.deepcopy()  for nested ones). This makes a copy that doesn't change with the first list. \n    ", "date_posted": "2020-02-22 12:44:40Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "12908850", "name": "Dr. Hippo", "reputation_score": "61"}, "answer_comments": []}, {"stack_answer_id": "59011118", "answer_content": "\r\n A slight practical perspective to look into memory through id and gc.  \n\n >>> b = a = ['hell', 'word']\n>>> c = ['hell', 'word']\n\n>>> id(a), id(b), id(c)\n(4424020872, 4424020872, 4423979272) \n     |           |\n      -----------\n\n>>> id(a[0]), id(b[0]), id(c[0])\n(4424018328, 4424018328, 4424018328) # all referring to same 'hell'\n     |           |           |\n      -----------------------\n\n>>> id(a[0][0]), id(b[0][0]), id(c[0][0])\n(4422785208, 4422785208, 4422785208) # all referring to same 'h'\n     |           |           |\n      -----------------------\n\n>>> a[0] += 'o'\n>>> a,b,c\n(['hello', 'word'], ['hello', 'word'], ['hell', 'word'])  # b changed too\n>>> id(a[0]), id(b[0]), id(c[0])\n(4424018384, 4424018384, 4424018328) # augmented assignment changed a[0],b[0]\n     |           |\n      -----------\n\n>>> b = a = ['hell', 'word']\n>>> id(a[0]), id(b[0]), id(c[0])\n(4424018328, 4424018328, 4424018328) # the same hell\n     |           |           |\n      -----------------------\n\n>>> import gc\n>>> gc.get_referrers(a[0]) \n[['hell', 'word'], ['hell', 'word']]  # one copy belong to a,b, the another for c\n>>> gc.get_referrers(('hell'))\n[['hell', 'word'], ['hell', 'word'], ('hell', None)] # ('hello', None) \n \n    ", "date_posted": "2019-11-23 19:01:46Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "1953475", "name": "B.Mr.W.", "reputation_score": "17.9k"}, "answer_comments": []}, {"stack_answer_id": "62716254", "answer_content": "\r\n There is another way of copying a list that was not listed until now: adding an empty list:  l2 = l + [] . \n I tested it with Python 3.8: \n l = [1,2,3]\nl2 = l + []\nprint(l,l2)\nl[0] = 'a'\nprint(l,l2)\n \n It is not the best answer, but it works. \n    ", "date_posted": "2021-11-19 23:13:45Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "6296561", "name": "Zoe stands with Ukraine", "reputation_score": "25.5k"}, "answer_comments": [{"stack_answer_id": "62716254", "stack_answer_comment_id": "128722772", "comment_content": "This works and, in my testing, is as fast as the fastest options for longer lists, and only slightly worse than ", "user_id": "None"}]}, {"stack_answer_id": "61155939", "answer_content": "\r\n The deepcopy option is the only method that works for me: \n\n from copy import deepcopy\n\na = [   [ list(range(1, 3)) for i in range(3) ]   ]\nb = deepcopy(a)\nb[0][1]=[3]\nprint('Deep:')\nprint(a)\nprint(b)\nprint('-----------------------------')\na = [   [ list(range(1, 3)) for i in range(3) ]   ]\nb = a*1\nb[0][1]=[3]\nprint('*1:')\nprint(a)\nprint(b)\nprint('-----------------------------')\na = [   [ list(range(1, 3)) for i in range(3) ] ]\nb = a[:]\nb[0][1]=[3]\nprint('Vector copy:')\nprint(a)\nprint(b)\nprint('-----------------------------')\na = [   [ list(range(1, 3)) for i in range(3) ]  ]\nb = list(a)\nb[0][1]=[3]\nprint('List copy:')\nprint(a)\nprint(b)\nprint('-----------------------------')\na = [   [ list(range(1, 3)) for i in range(3) ]  ]\nb = a.copy()\nb[0][1]=[3]\nprint('.copy():')\nprint(a)\nprint(b)\nprint('-----------------------------')\na = [   [ list(range(1, 3)) for i in range(3) ]  ]\nb = a\nb[0][1]=[3]\nprint('Shallow:')\nprint(a)\nprint(b)\nprint('-----------------------------')\n \n\n leads to output of: \n\n Deep:\n[[[1, 2], [1, 2], [1, 2]]]\n[[[1, 2], [3], [1, 2]]]\n-----------------------------\n*1:\n[[[1, 2], [3], [1, 2]]]\n[[[1, 2], [3], [1, 2]]]\n-----------------------------\nVector copy:\n[[[1, 2], [3], [1, 2]]]\n[[[1, 2], [3], [1, 2]]]\n-----------------------------\nList copy:\n[[[1, 2], [3], [1, 2]]]\n[[[1, 2], [3], [1, 2]]]\n-----------------------------\n.copy():\n[[[1, 2], [3], [1, 2]]]\n[[[1, 2], [3], [1, 2]]]\n-----------------------------\nShallow:\n[[[1, 2], [3], [1, 2]]]\n[[[1, 2], [3], [1, 2]]]\n-----------------------------\n \n    ", "date_posted": "2020-04-11 11:19:40Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "662770", "name": "shahar_m", "reputation_score": "3,236"}, "answer_comments": [{"stack_answer_id": "61155939", "stack_answer_comment_id": "114764971", "comment_content": "deepcopy must be used only when needed and one should be aware of what it really does.", "user_id": "None"}]}, {"stack_answer_id": "62192645", "answer_content": "\r\n This is because, the line  new_list = my_list  assigns a new reference to the variable  my_list  which is  new_list \nThis is similar to the  C  code given below, \n\n int my_list[] = [1,2,3,4];\nint *new_list;\nnew_list = my_list;\n \n\n You should use the copy module to create a new list by \n\n import copy\nnew_list = copy.deepcopy(my_list)\n \n    ", "date_posted": "2020-06-04 10:40:28Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "13328195", "name": "Roshin Raphel", "reputation_score": "2,506"}, "answer_comments": []}, {"stack_answer_id": "65972710", "answer_content": "\r\n The method to use depends on the contents of the list being copied. If the list contains nested  dicts  than deepcopy is the only method that works, otherwise most of the methods listed in the answers (slice, loop [for], copy, extend, combine, or unpack) will work and execute in similar time (except for loop and deepcopy, which preformed the worst). \n Script \n from random import randint\nfrom time import time\nimport copy\n\nitem_count = 100000\n\ndef copy_type(l1: list, l2: list):\n  if l1 == l2:\n    return 'shallow'\n  return 'deep'\n\ndef run_time(start, end):\n  run = end - start\n  return int(run * 1000000)\n\ndef list_combine(data):\n  l1 = [data for i in range(item_count)]\n  start = time()\n  l2 = [] + l1\n  end = time()\n  if type(data) == dict:\n    l2[0]['test'].append(1)\n  elif type(data) == list:\n    l2.append(1)\n  return {'method': 'combine', 'copy_type': copy_type(l1, l2), \n          'time_\u00b5s': run_time(start, end)}\n\ndef list_extend(data):\n  l1 = [data for i in range(item_count)]\n  start = time()\n  l2 = []\n  l2.extend(l1)\n  end = time()\n  if type(data) == dict:\n    l2[0]['test'].append(1)\n  elif type(data) == list:\n    l2.append(1)\n  return {'method': 'extend', 'copy_type': copy_type(l1, l2), \n          'time_\u00b5s': run_time(start, end)}\n\ndef list_unpack(data):\n  l1 = [data for i in range(item_count)]\n  start = time()\n  l2 = [*l1]\n  end = time()\n  if type(data) == dict:\n    l2[0]['test'].append(1)\n  elif type(data) == list:\n    l2.append(1)\n  return {'method': 'unpack', 'copy_type': copy_type(l1, l2), \n          'time_\u00b5s': run_time(start, end)}\n\ndef list_deepcopy(data):\n  l1 = [data for i in range(item_count)]\n  start = time()\n  l2 = copy.deepcopy(l1)\n  end = time()\n  if type(data) == dict:\n    l2[0]['test'].append(1)\n  elif type(data) == list:\n    l2.append(1)\n  return {'method': 'deepcopy', 'copy_type': copy_type(l1, l2), \n          'time_\u00b5s': run_time(start, end)}\n\ndef list_copy(data):\n  l1 = [data for i in range(item_count)]\n  start = time()\n  l2 = list.copy(l1)\n  end = time()\n  if type(data) == dict:\n    l2[0]['test'].append(1)\n  elif type(data) == list:\n    l2.append(1)\n  return {'method': 'copy', 'copy_type': copy_type(l1, l2), \n          'time_\u00b5s': run_time(start, end)}\n\ndef list_slice(data):\n  l1 = [data for i in range(item_count)]\n  start = time()\n  l2 = l1[:]\n  end = time()\n  if type(data) == dict:\n    l2[0]['test'].append(1)\n  elif type(data) == list:\n    l2.append(1)\n  return {'method': 'slice', 'copy_type': copy_type(l1, l2), \n          'time_\u00b5s': run_time(start, end)}\n\ndef list_loop(data):\n  l1 = [data for i in range(item_count)]\n  start = time()\n  l2 = []\n  for i in range(len(l1)):\n    l2.append(l1[i])\n  end = time()\n  if type(data) == dict:\n    l2[0]['test'].append(1)\n  elif type(data) == list:\n    l2.append(1)\n  return {'method': 'loop', 'copy_type': copy_type(l1, l2), \n          'time_\u00b5s': run_time(start, end)}\n\ndef list_list(data):\n  l1 = [data for i in range(item_count)]\n  start = time()\n  l2 = list(l1)\n  end = time()\n  if type(data) == dict:\n    l2[0]['test'].append(1)\n  elif type(data) == list:\n    l2.append(1)\n  return {'method': 'list()', 'copy_type': copy_type(l1, l2), \n          'time_\u00b5s': run_time(start, end)}\n\nif __name__ == '__main__':\n  list_type = [{'list[dict]': {'test': [1, 1]}}, \n          {'list[list]': [1, 1]}]\n  store = []\n  for data in list_type:\n    key = list(data.keys())[0]\n    store.append({key: [list_unpack(data[key]), list_extend(data[key]), \n                list_combine(data[key]), list_deepcopy(data[key]), \n                list_copy(data[key]), list_slice(data[key]),           \n                list_loop(data[key])]})\n  print(store)\n \n Results \n [{\"list[dict]\": [\n  {\"method\": \"unpack\", \"copy_type\": \"shallow\", \"time_\u00b5s\": 56149},\n  {\"method\": \"extend\", \"copy_type\": \"shallow\", \"time_\u00b5s\": 52991},\n  {\"method\": \"combine\", \"copy_type\": \"shallow\", \"time_\u00b5s\": 53726},\n  {\"method\": \"deepcopy\", \"copy_type\": \"deep\", \"time_\u00b5s\": 2702616},\n  {\"method\": \"copy\", \"copy_type\": \"shallow\", \"time_\u00b5s\": 52204},\n  {\"method\": \"slice\", \"copy_type\": \"shallow\", \"time_\u00b5s\": 52223},\n  {\"method\": \"loop\", \"copy_type\": \"shallow\", \"time_\u00b5s\": 836928}]},\n{\"list[list]\": [\n  {\"method\": \"unpack\", \"copy_type\": \"deep\", \"time_\u00b5s\": 52313},\n  {\"method\": \"extend\", \"copy_type\": \"deep\", \"time_\u00b5s\": 52550},\n  {\"method\": \"combine\", \"copy_type\": \"deep\", \"time_\u00b5s\": 53203},\n  {\"method\": \"deepcopy\", \"copy_type\": \"deep\", \"time_\u00b5s\": 2608560},\n  {\"method\": \"copy\", \"copy_type\": \"deep\", \"time_\u00b5s\": 53210},\n  {\"method\": \"slice\", \"copy_type\": \"deep\", \"time_\u00b5s\": 52937},\n  {\"method\": \"loop\", \"copy_type\": \"deep\", \"time_\u00b5s\": 834774}\n]}]\n \n    ", "date_posted": "2021-01-30 20:17:42Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "10773184", "name": "fjemi", "reputation_score": "11"}, "answer_comments": []}], "user": {"stack_user_id": "187730", "name": "aF.", "reputation_score": "63.1k"}, "question_comments": [{"stack_question_id": "2612802", "stack_question_comment_id": "123683957", "comment_content": " just assigns the name ", "user_id": "None"}, {"stack_question_id": "2612802", "stack_question_comment_id": "125187420", "comment_content": "See the ", "user_id": "None"}, {"stack_question_id": "2612802", "stack_question_comment_id": "128071906", "comment_content": "See also: ", "user_id": "None"}, {"stack_question_id": "2612802", "stack_question_comment_id": "128097571", "comment_content": "Related: ", "user_id": "None"}]},
{"stack_question_id": "20002503", "question_title": "Why does \"a == x or y or z\" always evaluate to True? How can I compare \"a\" to all of those?", "question_content": "\r\n                I am writing a security system that denies access to unauthorized users.\nname = input(\"Hello. Please enter your name: \")\nif name == \"Kevin\" or \"Jon\" or \"Inbar\":\n...\r\n", "question_url": "/questions/20002503/why-does-a-x-or-y-or-z-always-evaluate-to-true-how-can-i-compare-a-to-al", "date_posted": "Nov 15, 2013 at 13:45", "upvote": "1", "view": "3", "tags": ["python", "boolean", "boolean-expression"], "answers_count": "6", "answers": [{"stack_answer_id": "20002504", "answer_content": "\r\n In many cases, Python looks and behaves like natural English, but this is one case where that abstraction fails. People can use context clues to determine that \"Jon\" and \"Inbar\" are objects joined to the verb \"equals\", but the Python interpreter is more literal minded. \n if name == \"Kevin\" or \"Jon\" or \"Inbar\":\n \n is logically equivalent to: \n if (name == \"Kevin\") or (\"Jon\") or (\"Inbar\"):\n \n Which, for user Bob, is equivalent to: \n if (False) or (\"Jon\") or (\"Inbar\"):\n \n The  or  operator chooses the first argument with a positive  truth value : \n if \"Jon\":\n \n And since \"Jon\" has a positive truth value, the  if  block executes. That is what causes \"Access granted\" to be printed regardless of the name given. \n All of this reasoning also applies to the expression  if \"Kevin\" or \"Jon\" or \"Inbar\" == name . the first value,  \"Kevin\" , is true, so the  if  block executes. \n \n There are two common ways to properly construct this conditional. \n \n Use multiple  ==  operators to explicitly check against each value: \n if name == \"Kevin\" or name == \"Jon\" or name == \"Inbar\":\n \n \n Compose a collection of valid values (a set, a list or a tuple for example), and use the  in  operator to test for membership: \n if name in {\"Kevin\", \"Jon\", \"Inbar\"}:\n \n \n \n In general of the two the second should be preferred as it's easier to read and also faster: \n >>> import timeit\n>>> timeit.timeit('name == \"Kevin\" or name == \"Jon\" or name == \"Inbar\"',\n    setup=\"name='Inbar'\")\n0.4247764749999945\n>>> timeit.timeit('name in {\"Kevin\", \"Jon\", \"Inbar\"}', setup=\"name='Inbar'\")\n0.18493307199999265\n \n \n For those who may want proof that  if a == b or c or d or e: ...  is indeed parsed like this. The built-in  ast  module provides an answer: \n >>> import ast\n>>> ast.parse(\"a == b or c or d or e\", \"<string>\", \"eval\")\n<ast.Expression object at 0x7f929c898220>\n>>> print(ast.dump(_, indent=4))\nExpression(\n    body=BoolOp(\n        op=Or(),\n        values=[\n            Compare(\n                left=Name(id='a', ctx=Load()),\n                ops=[\n                    Eq()],\n                comparators=[\n                    Name(id='b', ctx=Load())]),\n            Name(id='c', ctx=Load()),\n            Name(id='d', ctx=Load()),\n            Name(id='e', ctx=Load())]))\n \n As one can see, it's the boolean operator  or  applied to four sub-expressions: comparison  a == b ; and simple expressions  c ,  d , and  e . \n    ", "date_posted": "2021-04-11 18:47:35Z", "upvote": "\r\n            198\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "20002504", "name": "\r\n        7 revs, 5 users 42%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "20002504", "stack_answer_comment_id": "99771573", "comment_content": "Is there a specific reason to choose a tuple ", "user_id": "None"}, {"stack_answer_id": "20002504", "stack_answer_comment_id": "99771840", "comment_content": "Not really, since both work if the values are all hashable. Set membership testing has better big-O complexity than tuple membership testing, but constructing a set is a little more expensive than constructing a tuple. I think it's largely a wash for small collections like these. Playing around with timeit, ", "user_id": "953482"}, {"stack_answer_id": "20002504", "stack_answer_comment_id": "99772058", "comment_content": " recommends set literals for membership testing. I'll update my post.", "user_id": "953482"}, {"stack_answer_id": "20002504", "stack_answer_comment_id": "109380603", "comment_content": "In modern Python, it recognizes that the set is a constant and makes it a ", "user_id": "None"}]}, {"stack_answer_id": "62545337", "answer_content": "\r\n There are 3 condition checks in  if name == \"Kevin\" or \"Jon\" or \"Inbar\": \n \n name == \"Kevin\" \n \"Jon\" \n \"Inbar\" \n \n and this if statement is equivalent to \n if name == \"Kevin\":\n    print(\"Access granted.\")\nelif \"Jon\":\n    print(\"Access granted.\")\nelif \"Inbar\":\n    print(\"Access granted.\")\nelse:\n    print(\"Access denied.\")\n \n Since  elif \"Jon\"  will always be true so access to any user is granted \n Solution \n \n You can use any one method below \n Fast \n if name in [\"Kevin\", \"Jon\", \"Inbar\"]:\n    print(\"Access granted.\")\nelse:\n    print(\"Access denied.\")\n \n Slow \n if name == \"Kevin\" or name == \"Jon\" or name == \"Inbar\":\n    print(\"Access granted.\")\nelse:\n    print(\"Access denied.\")\n \n Slow + Unnecessary code \n if name == \"Kevin\":\n    print(\"Access granted.\")\nelif name == \"Jon\":\n    print(\"Access granted.\")\nelif name == \"Inbar\":\n    print(\"Access granted.\")\nelse:\n    print(\"Access denied.\")\n \n    ", "date_posted": "2020-06-24 00:30:08Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "13751567", "name": "7u5h4r", "reputation_score": "439"}, "answer_comments": []}, {"stack_answer_id": "71188001", "answer_content": "\r\n Summarising all existing answers \n (And adding a few of my points) \n Explanation : \n if name == \"Kevin\" or \"Jon\" or \"Inbar\":\n \n is logically equivalent to: \n if (name == \"Kevin\") or (\"Jon\") or (\"Inbar\"):\n \n Which, for user Bob, is equivalent to: \n if (False) or (\"Jon\") or (\"Inbar\"):\n \n NOTE : Python evaluates the logical value of any non-zero integer as  True . Therefore, all Non-empty lists, sets, strings, etc. are evaluable and return  True \n The  or  operator chooses the first argument with a positive truth value. \n Therefore, \"Jon\" has a positive truth value and the if block executes, since it is now equivalent to \n if (False) or (True) or (True):\n \n That is what causes \"Access granted\" to be printed regardless of the name input. \n Solutions : \n Solution 1 :  Use multiple  ==  operators to explicitly check against each value \n if name == \"Kevin\" or name == \"Jon\" or name == \"Inbar\":\n    print(\"Access granted.\")\nelse:\n    print(\"Access denied.\")\n \n Solution 2 :  Compose a collection of valid values (a set, a list or a tuple for example), and use the  in  operator to test for membership  (faster, preferred method) \n if name in {\"Kevin\", \"Jon\", \"Inbar\"}:\n    print(\"Access granted.\")\nelse:\n    print(\"Access denied.\")\n \n OR \n if name in [\"Kevin\", \"Jon\", \"Inbar\"]:\n    print(\"Access granted.\")\nelse:\n    print(\"Access denied.\")\n \n Solution 3 :  Use the basic  (and not very efficient)   if-elif-else  structure \n if name == \"Kevin\":\n    print(\"Access granted.\")\nelif name == \"Jon\":\n    print(\"Access granted.\")\nelif name == \"Inbar\":\n    print(\"Access granted.\")\nelse:\n    print(\"Access denied.\")\n \n    ", "date_posted": "2022-02-25 06:21:43Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "17112163", "name": "Deepthi Tabitha Bennet", "reputation_score": "534"}, "answer_comments": []}, {"stack_answer_id": "56186060", "answer_content": "\r\n Simple engineering problem, let's simply it a bit further. \n\n In [1]: a,b,c,d=1,2,3,4\nIn [2]: a==b\nOut[2]: False\n \n\n But, inherited from the language C, Python evaluates the logical value of a non zero integer as True. \n\n In [11]: if 3:\n    ...:     print (\"yey\")\n    ...:\nyey\n \n\n Now, Python builds on that logic and let you use logic literals such as or on integers, and so  \n\n In [9]: False or 3\nOut[9]: 3\n \n\n Finally \n\n In [4]: a==b or c or d\nOut[4]: 3\n \n\n The proper way to write it would be: \n\n In [13]: if a in (b,c,d):\n    ...:     print('Access granted')\n \n\n For safety I'd also suggest you don't hard code passwords. \n    ", "date_posted": "2019-05-17 12:05:58Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "1854182", "name": "user1854182", "reputation_score": "641"}, "answer_comments": []}, {"stack_answer_id": "65071388", "answer_content": "\r\n Not-empty lists, sets, strings, etc. are evaluable and, therefore, return True. \n Therefore, when you say: \n a = \"Raul\"\nif a == \"Kevin\" or \"John\" or \"Inbar\":\n    pass\n \n You are actually saying: \n if \"Raul\" == \"Kevin\" or \"John\" != \"\" or \"Inbar\" != \"\":\n    pass\n \n Since at least one of \"John\" and \"Inbar\" is not an empty string, the whole expression always returns True! \n The solution: \n a = \"Raul\"\nif a == \"Kevin\" or a == \"John\" or a == \"Inbar\":\n    pass\n \n or: \n a = \"Raul\"\nif a in {\"Kevin\", \"John\", \"Inbar\"}:\n    pass\n \n    ", "date_posted": "2020-11-30 13:23:54Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "6251742", "name": "Dorian Turba", "reputation_score": "1,847"}, "answer_comments": [{"stack_answer_id": "65071388", "stack_answer_comment_id": "118514393", "comment_content": "good otherwise but \"You are actually saying:\" is ", "user_id": "None"}]}, {"stack_answer_id": "65199768", "answer_content": "\r\n Approaches \n How a data scientist approaches this problem \n The simplest way possible is to eliminate the need for comparison operators and use a list. This looks impressive on security systems because you learn to access ORMs. \n user = input(\"Enter name: \")\n\nif user in {\"Bob\", \"Kevin\", \"Joe\"}:\n   print(\"Access granted, \" + str(user) + \".\")\nelse:\n   print(\"Access denied.\")\n \n Or, you can resemble the  exact  same code above, just put the list of registered users in their own list: \n user = input(\"Enter name: \")\nusers = {\"Bob\", \"Kevin\", \"Joe\", \"a million more users if you like\"}\n\nif user in users:\n   print(\"Access granted, \" + str(user) + \".\")\nelse:\n   print(\"Access denied.\")\n \n If you wanted to complete this protocol safely without the risk of attack, set up double parameters. This would check your mini-ORM for  first  and  last  name fields, as well as a  password  or  secret question  key. Objects can be sorted like this if you want to efficiently lazy-load user credentials without hashing: \n def lazy(i):\n   j = 0 # For example\n   while j < i:\n      yield j\n      j += 1\n \n The loop will consume  only  the yielded values to save time and energy on your system: \n You can then do something with the iterated list: \n for j in lazy_range(10):\n   do_something_here(j)\n \n This problem can be approached from any angle: memory management, security, or simply by an organic list or packaged ORM. \n    ", "date_posted": "2022-01-02 09:47:13Z", "upvote": "\r\n            -1\r\n        ", "accepted": "No", "user": {"stack_user_id": "4621513", "name": "mkrieger1", "reputation_score": "15.4k"}, "answer_comments": []}], "user": {"stack_user_id": "953482", "name": "Kevin", "reputation_score": "72.8k"}, "question_comments": [{"stack_question_id": "20002503", "stack_question_comment_id": "97948491", "comment_content": "Variations of this problem include ", "user_id": "None"}]},
{"stack_question_id": "423379", "question_title": "Using global variables in a function", "question_content": "\r\n                How do I create or use a global variable inside a function?\nHow do I use a global variable that was defined in one function inside other functions?\r\n", "question_url": "/questions/423379/using-global-variables-in-a-function", "date_posted": "Jan 8, 2009 at 5:45", "upvote": "3", "view": "3", "tags": ["python", "global-variables", "scope"], "answers_count": "2", "answers": [{"stack_answer_id": "423596", "answer_content": "\r\n You can use a global variable within other functions by declaring it as  global  within each function that assigns a value to it: \n globvar = 0\n\ndef set_globvar_to_one():\n    global globvar    # Needed to modify global copy of globvar\n    globvar = 1\n\ndef print_globvar():\n    print(globvar)     # No need for global declaration to read value of globvar\n\nset_globvar_to_one()\nprint_globvar()       # Prints 1\n \n Since it's unclear whether  globvar = 1  is creating a local variable or changing a global variable, Python defaults to creating a local variable, and makes you explicitly choose the other behavior with the  global  keyword. \n See other answers if you want to share a global variable across modules. \n    ", "date_posted": "2022-01-28 21:03:06Z", "upvote": "\r\n            4936\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "128023", "name": "Zarel", "reputation_score": "2,201"}, "answer_comments": [{"stack_answer_id": "423596", "stack_answer_comment_id": "19339130", "comment_content": "It's extreme exaggeration to refer to globals as \"so dangerous.\" Globals are perfectly fine in every language that has ever existed and ever will exist. They have their place. What you should have said is they can cause issues if you have no clue how to program.", "user_id": "None"}, {"stack_answer_id": "423596", "stack_answer_comment_id": "20143828", "comment_content": "I think they are fairly dangerous. However in python \"global\" variables are actually module-level, which solves a lot of issues.", "user_id": "None"}]}, {"stack_answer_id": "423668", "answer_content": "\r\n If I'm understanding your situation correctly, what you're seeing is the result of how Python handles local (function) and global (module) namespaces. \n Say you've got a module like this: \n # sample.py\n_my_global = 5\n\ndef func1():\n    _my_global = 42\n\ndef func2():\n    print _my_global\n\nfunc1()\nfunc2()\n \n You might expecting this to print 42, but instead it prints 5.  As has already been mentioned, if you add a ' global ' declaration to  func1() , then  func2()  will print 42. \n def func1():\n    global _my_global \n    _my_global = 42\n \n What's going on here is that Python assumes that any name that is  assigned to , anywhere within a function, is local to that function unless explicitly told otherwise.  If it is only  reading  from a name, and the name doesn't exist locally, it will try to look up the name in any containing scopes (e.g. the module's global scope). \n When you assign 42 to the name  _my_global , therefore, Python creates a local variable that shadows the global variable of the same name.  That local goes out of scope and is  garbage-collected  when  func1()  returns; meanwhile,  func2()  can never see anything other than the (unmodified) global name.  Note that this namespace decision happens at compile time, not at runtime -- if you were to read the value of  _my_global  inside  func1()  before you assign to it, you'd get an  UnboundLocalError , because Python has already decided that it must be a local variable but it has not had any value associated with it yet.  But by using the ' global ' statement, you tell Python that it should look elsewhere for the name instead of assigning to it locally. \n (I believe that this behavior originated largely through an optimization of local namespaces -- without this behavior,  Python's VM would need to perform at least three name lookups each time a new name is assigned to inside a function (to ensure that the name didn't already exist at module/builtin level), which would significantly slow down a very common operation.) \n    ", "date_posted": "2022-06-13 10:11:24Z", "upvote": "\r\n            861\r\n        ", "accepted": "No", "user": {"stack_user_id": "4298200", "name": "Neuron", "reputation_score": "4,509"}, "answer_comments": [{"stack_answer_id": "423668", "stack_answer_comment_id": "53998527", "comment_content": "You mentioned that the namespace decision happens at ", "user_id": "None"}, {"stack_answer_id": "423668", "stack_answer_comment_id": "83833173", "comment_content": "It is common to use a capital letter for global variables like ", "user_id": "None"}, {"stack_answer_id": "423668", "stack_answer_comment_id": "83890430", "comment_content": "@watashiSHUN: The namespace decision ", "user_id": "None"}, {"stack_answer_id": "423668", "stack_answer_comment_id": "83890525", "comment_content": "@Vassilis: It is common to upper case ", "user_id": "None"}]}, {"stack_answer_id": "423401", "answer_content": "\r\n You may want to explore the notion of  namespaces . In Python, the  module  is the natural place for  global  data: \n \n Each module has its own private symbol table, which is used as the global symbol table by all functions defined in the module. Thus, the author of a module can use global variables in the module without worrying about accidental clashes with a user\u2019s global variables. On the other hand, if you know what you are doing you can touch a module\u2019s global variables with the same notation used to refer to its functions,  modname.itemname . \n \n A specific use of global-in-a-module is described here -  How do I share global variables across modules? , and for completeness the contents are shared here: \n \n The canonical way to share information across modules within a single program is to create a special configuration module (often called  config  or  cfg ). Just import the configuration module in all modules of your application; the module then becomes available as a global name. Because there is only one instance of each module, any changes made to the module object get reflected everywhere. For example: \n \n \n File: config.py \n \n \n x = 0   # Default value of the 'x' configuration setting\n \n \n \n File: mod.py \n \n import config\nconfig.x = 1\n \n \n File: main.py \n \n import config\nimport mod\nprint config.x\n \n    ", "date_posted": "2020-12-16 04:50:21Z", "upvote": "\r\n            262\r\n        ", "accepted": "No", "user": {"stack_user_id": "2038264", "name": "congusbongus", "reputation_score": "12.3k"}, "answer_comments": [{"stack_answer_id": "423401", "stack_answer_comment_id": "83098999", "comment_content": "for a reason I don't like the ", "user_id": "None"}, {"stack_answer_id": "423401", "stack_answer_comment_id": "94196170", "comment_content": "@vladosaurus does  ", "user_id": "None"}]}, {"stack_answer_id": "6664227", "answer_content": "\r\n Python uses a simple heuristic to decide which scope it should load a variable from, between local and global.  If a variable name appears on the left hand side of an assignment, but is not declared global, it is assumed to be local.  If it does not appear on the left hand side of an assignment, it is assumed to be global.   \n\n >>> import dis\n>>> def foo():\n...     global bar\n...     baz = 5\n...     print bar\n...     print baz\n...     print quux\n... \n>>> dis.disassemble(foo.func_code)\n  3           0 LOAD_CONST               1 (5)\n              3 STORE_FAST               0 (baz)\n\n  4           6 LOAD_GLOBAL              0 (bar)\n              9 PRINT_ITEM          \n             10 PRINT_NEWLINE       \n\n  5          11 LOAD_FAST                0 (baz)\n             14 PRINT_ITEM          \n             15 PRINT_NEWLINE       \n\n  6          16 LOAD_GLOBAL              1 (quux)\n             19 PRINT_ITEM          \n             20 PRINT_NEWLINE       \n             21 LOAD_CONST               0 (None)\n             24 RETURN_VALUE        \n>>> \n \n\n See how baz, which appears on the left side of an assignment in  foo() , is the only  LOAD_FAST  variable. \n    ", "date_posted": "2011-07-12 12:35:08Z", "upvote": "\r\n            109\r\n        ", "accepted": "No", "user": {"stack_user_id": "65696", "name": "SingleNegationElimination", "reputation_score": "146k"}, "answer_comments": [{"stack_answer_id": "6664227", "stack_answer_comment_id": "51714387", "comment_content": "The heuristic looks for ", "user_id": "None"}, {"stack_answer_id": "6664227", "stack_answer_comment_id": "106317214", "comment_content": "@MartijnPieters For the name after ", "user_id": "None"}, {"stack_answer_id": "6664227", "stack_answer_comment_id": "106317485", "comment_content": "@Robert: not to save memory, but to avoid creating a circular reference, which can lead to memory leaks. That's because an exception references a traceback, and the traceback references every local and global namespace along the whole call stack, including the ", "user_id": "None"}]}, {"stack_answer_id": "423641", "answer_content": "\r\n If you want to refer to a global variable in a function, you can use the  global  keyword to declare which variables are global. You don't have to use it in all cases (as someone here incorrectly claims) - if the name referenced in an expression cannot be found in local scope or scopes in the functions in which this function is defined, it is looked up among global variables. \n\n However, if you assign to a new variable not declared as global in the function, it is implicitly declared as local, and it can overshadow any existing global variable with the same name. \n\n Also, global variables are useful, contrary to some OOP zealots who claim otherwise - especially for smaller scripts, where OOP is overkill. \n    ", "date_posted": "2017-03-04 22:00:48Z", "upvote": "\r\n            70\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "423641", "stack_answer_comment_id": "102505940", "comment_content": "Absolutely re. zealots.  Most Python users use it for scripting and create little functions to separate out small bits of code.", "user_id": "None"}]}, {"stack_answer_id": "34559513", "answer_content": "\r\n \n   If I create a global variable in one function, how can I use that variable in another function? \n \n\n We can create a global with the following function: \n\n def create_global_variable():\n    global global_variable # must declare it to be a global first\n    # modifications are thus reflected on the module's global scope\n    global_variable = 'Foo' \n \n\n Writing a function does not actually run its code. So we call the  create_global_variable  function: \n\n >>> create_global_variable()\n \n\n Using globals without modification \n\n You can just use it, so long as you don't expect to change which object it points to:  \n\n For example,  \n\n def use_global_variable():\n    return global_variable + '!!!'\n \n\n and now we can use the global variable: \n\n >>> use_global_variable()\n'Foo!!!'\n \n\n Modification of the global variable from inside a function \n\n To point the global variable at a different object, you are required to use the global keyword again: \n\n def change_global_variable():\n    global global_variable\n    global_variable = 'Bar'\n \n\n Note that after writing this function, the code actually changing it has still not run: \n\n >>> use_global_variable()\n'Foo!!!'\n \n\n So after calling the function: \n\n >>> change_global_variable()\n \n\n we can see that the global variable has been changed. The  global_variable  name now points to  'Bar' : \n\n >>> use_global_variable()\n'Bar!!!'\n \n\n Note that \"global\" in Python is not truly global - it's only global to the module level. So it is only available to functions written in the modules in which it is global. Functions remember the module in which they are written, so when they are exported into other modules, they still look in the module in which they were created to find global variables. \n\n Local variables with the same name \n\n If you create a local variable with the same name, it will overshadow a global variable: \n\n def use_local_with_same_name_as_global():\n    # bad name for a local variable, though.\n    global_variable = 'Baz' \n    return global_variable + '!!!'\n\n>>> use_local_with_same_name_as_global()\n'Baz!!!'\n \n\n But using that misnamed local variable does not change the global variable: \n\n >>> use_global_variable()\n'Bar!!!'\n \n\n Note that you should avoid using the local variables with the same names as globals unless you know precisely what you are doing and have a very good reason to do so. I have not yet encountered such a reason. \n\n We get the same behavior in classes \n\n A follow on comment asks: \n\n \n   what to do if I want to create a global variable inside a function inside a class and want to use that variable inside another function inside another class? \n \n\n Here I demonstrate we get the same behavior in methods as we do in regular functions: \n\n class Foo:\n    def foo(self):\n        global global_variable\n        global_variable = 'Foo'\n\nclass Bar:\n    def bar(self):\n        return global_variable + '!!!'\n\nFoo().foo()\n \n\n And now: \n\n >>> Bar().bar()\n'Foo!!!'\n \n\n But I would suggest instead of using global variables you use class attributes, to avoid cluttering the module namespace. Also note we don't use  self  arguments here - these could be class methods (handy if mutating the class attribute from the usual  cls  argument) or static methods (no  self  or  cls ). \n    ", "date_posted": "2020-01-19 14:41:24Z", "upvote": "\r\n            65\r\n        ", "accepted": "No", "user": {"stack_user_id": "541136", "name": "Russia Must Remove Putin", "reputation_score": "347k"}, "answer_comments": [{"stack_answer_id": "34559513", "stack_answer_comment_id": "105760662", "comment_content": "Cool, but what to do if I want to create a global variable inside a function inside a class and want to use that variable inside another function inside another class? Kinda stuck here", "user_id": "None"}, {"stack_answer_id": "34559513", "stack_answer_comment_id": "105760720", "comment_content": "@anonmanx I don't know why you're stuck, it's the same behavior in a method as in a regular function. But I'll update my answer with your remark and some demo code, ok?", "user_id": "None"}, {"stack_answer_id": "34559513", "stack_answer_comment_id": "105760875", "comment_content": "okay, got it. So I will have to explicitly call that function for using that global variable.", "user_id": "None"}]}, {"stack_answer_id": "24572187", "answer_content": "\r\n In addition to already existing answers and to make this more confusing: \n\n \n   In Python, variables that are only referenced inside a function are\n   implicitly global . If a variable is assigned a new value anywhere\n  within the function\u2019s body, it\u2019s assumed to be a  local . If a variable\n  is ever assigned a new value inside the function, the variable is\n  implicitly local, and you need to explicitly declare it as \u2018global\u2019. \n  \n   Though a bit surprising at first, a moment\u2019s consideration explains\n  this. On one hand, requiring global for assigned variables provides a\n  bar against unintended side-effects. On the other hand, if global was\n  required for all global references, you\u2019d be using global all the\n  time. You\u2019d have to declare as global every reference to a built-in\n  function or to a component of an imported module. This clutter would\n  defeat the usefulness of the global declaration for identifying\n  side-effects. \n \n\n Source:  What are the rules for local and global variables in Python? . \n    ", "date_posted": "2014-07-20 10:36:29Z", "upvote": "\r\n            54\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "19151605", "answer_content": "\r\n With parallel execution, global variables can cause unexpected results if you don't understand what is happening. Here is an example of using a global variable within multiprocessing. We can clearly see that each process works with its own copy of the variable: \n\n import multiprocessing\nimport os\nimport random\nimport sys\nimport time\n\ndef worker(new_value):\n    old_value = get_value()\n    set_value(random.randint(1, 99))\n    print('pid=[{pid}] '\n          'old_value=[{old_value:2}] '\n          'new_value=[{new_value:2}] '\n          'get_value=[{get_value:2}]'.format(\n          pid=str(os.getpid()),\n          old_value=old_value,\n          new_value=new_value,\n          get_value=get_value()))\n\ndef get_value():\n    global global_variable\n    return global_variable\n\ndef set_value(new_value):\n    global global_variable\n    global_variable = new_value\n\nglobal_variable = -1\n\nprint('before set_value(), get_value() = [%s]' % get_value())\nset_value(new_value=-2)\nprint('after  set_value(), get_value() = [%s]' % get_value())\n\nprocessPool = multiprocessing.Pool(processes=5)\nprocessPool.map(func=worker, iterable=range(15))\n \n\n Output: \n\n before set_value(), get_value() = [-1]\nafter  set_value(), get_value() = [-2]\npid=[53970] old_value=[-2] new_value=[ 0] get_value=[23]\npid=[53971] old_value=[-2] new_value=[ 1] get_value=[42]\npid=[53970] old_value=[23] new_value=[ 4] get_value=[50]\npid=[53970] old_value=[50] new_value=[ 6] get_value=[14]\npid=[53971] old_value=[42] new_value=[ 5] get_value=[31]\npid=[53972] old_value=[-2] new_value=[ 2] get_value=[44]\npid=[53973] old_value=[-2] new_value=[ 3] get_value=[94]\npid=[53970] old_value=[14] new_value=[ 7] get_value=[21]\npid=[53971] old_value=[31] new_value=[ 8] get_value=[34]\npid=[53972] old_value=[44] new_value=[ 9] get_value=[59]\npid=[53973] old_value=[94] new_value=[10] get_value=[87]\npid=[53970] old_value=[21] new_value=[11] get_value=[21]\npid=[53971] old_value=[34] new_value=[12] get_value=[82]\npid=[53972] old_value=[59] new_value=[13] get_value=[ 4]\npid=[53973] old_value=[87] new_value=[14] get_value=[70]\n \n    ", "date_posted": "2017-01-03 02:34:20Z", "upvote": "\r\n            39\r\n        ", "accepted": "No", "user": {"stack_user_id": "875915", "name": "Rob Bednark", "reputation_score": "23.5k"}, "answer_comments": []}, {"stack_answer_id": "19347254", "answer_content": "\r\n As it turns out the answer is always simple. \n\n Here is a small sample module with a simple way to show it in a  main  definition: \n\n def five(enterAnumber,sumation):\n    global helper\n    helper  = enterAnumber + sumation\n\ndef isTheNumber():\n    return helper\n \n\n Here is how to show it in a  main  definition: \n\n import TestPy\n\ndef main():\n    atest  = TestPy\n    atest.five(5,8)\n    print(atest.isTheNumber())\n\nif __name__ == '__main__':\n    main()\n \n\n This simple code works just like that, and it will execute. I hope it helps. \n    ", "date_posted": "2018-09-28 11:34:54Z", "upvote": "\r\n            32\r\n        ", "accepted": "No", "user": {"stack_user_id": "6664578", "name": "AEF", "reputation_score": "5,143"}, "answer_comments": [{"stack_answer_id": "19347254", "stack_answer_comment_id": "28873293", "comment_content": "thanks, i'm new to python, but know a bit of java.  what you said worked for me. and writing global a<ENTER> within the class.. seems to make more sense to me than within a function writing 'global a'..  I notice you can't say  global a=4", "user_id": "None"}, {"stack_answer_id": "19347254", "stack_answer_comment_id": "40543494", "comment_content": "This is probably the simplest yet very useful python trick for me. I name this module ", "user_id": "None"}, {"stack_answer_id": "19347254", "stack_answer_comment_id": "47268475", "comment_content": "What if there are many many global variables and I don't want to have to list them one-by-one after a global statement?", "user_id": "None"}]}, {"stack_answer_id": "27287648", "answer_content": "\r\n What you are saying is to use the method like this: \n globvar = 5\n\ndef f():\n    var = globvar\n    print(var)\n\nf()  # Prints 5\n \n But the better way is to use the global variable like this: \n globvar = 5\ndef f():\n    global globvar\n    print(globvar)\nf()   #prints 5\n \n Both give the same output. \n    ", "date_posted": "2020-12-01 07:45:16Z", "upvote": "\r\n            31\r\n        ", "accepted": "No", "user": {"stack_user_id": "8873143", "name": "funie200", "reputation_score": "3,384"}, "answer_comments": []}, {"stack_answer_id": "27580376", "answer_content": "\r\n You need to reference the global variable in every function you want to use. \n\n As follows: \n\n var = \"test\"\n\ndef printGlobalText():\n    global var #wWe are telling to explicitly use the global version\n    var = \"global from printGlobalText fun.\"\n    print \"var from printGlobalText: \" + var\n\ndef printLocalText():\n    #We are NOT telling to explicitly use the global version, so we are creating a local variable\n    var = \"local version from printLocalText fun\"\n    print \"var from printLocalText: \" + var\n\nprintGlobalText()\nprintLocalText()\n\"\"\"\nOutput Result:\nvar from printGlobalText: global from printGlobalText fun.\nvar from printLocalText: local version from printLocalText\n[Finished in 0.1s]\n\"\"\"\n \n    ", "date_posted": "2015-02-04 18:45:42Z", "upvote": "\r\n            29\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "27580376", "stack_answer_comment_id": "46534476", "comment_content": "'in every function you want to use' is subtly incorrect, should be closer to: 'in every function where you want to ", "user_id": "None"}]}, {"stack_answer_id": "28329600", "answer_content": "\r\n Try this: \n def x1():\n    global x\n    x += 1\n    print('x1: ', x)\n\ndef x2():\n    global x\n    x = x+1\n    print('x2: ', x)\n\nx = 5\nprint('x:  ', x)\nx1()\nx2()\n\n# Output:\n# x:   5\n# x1:  6\n# x2:  7\n \n    ", "date_posted": "2020-11-27 17:41:31Z", "upvote": "\r\n            28\r\n        ", "accepted": "No", "user": {"stack_user_id": "1147688", "name": "not2qubit", "reputation_score": "12.4k"}, "answer_comments": [{"stack_answer_id": "28329600", "stack_answer_comment_id": "114987502", "comment_content": "Congratulations! Finally someone who got the most important point of using ", "user_id": "None"}]}, {"stack_answer_id": "427818", "answer_content": "\r\n You're not actually storing the global in a local variable, just creating a local reference to the same object that your original global reference refers to. Remember that pretty much everything in Python is a name referring to an object, and nothing gets copied in usual operation. \n\n If you didn't have to explicitly specify when an identifier was to refer to a predefined global, then you'd presumably have to explicitly specify when an identifier is a new local variable instead (for example, with something like the 'var' command seen in JavaScript). Since local variables are more common than global variables in any serious and non-trivial system, Python's system makes more sense in most cases. \n\n You  could  have a language which attempted to guess, using a global variable if it existed or creating a local variable if it didn't. However, that would be very error-prone. For example, importing another module could inadvertently introduce a global variable by that name, changing the behaviour of your program. \n    ", "date_posted": "2011-05-30 21:09:51Z", "upvote": "\r\n            26\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "43285234", "answer_content": "\r\n In case you have a local variable with the same name, you might want to use the  globals()  function . \n\n globals()['your_global_var'] = 42\n \n    ", "date_posted": "2017-04-07 19:15:55Z", "upvote": "\r\n            21\r\n        ", "accepted": "No", "user": {"stack_user_id": "562769", "name": "Martin Thoma", "reputation_score": "111k"}, "answer_comments": []}, {"stack_answer_id": "33320055", "answer_content": "\r\n Following on and as an add on, use a file to contain all global variables all declared locally and then  import as : \n\n File  initval.py : \n\n Stocksin = 300\nPrices = []\n \n\n File  getstocks.py : \n\n import initval as iv\n\ndef getmystocks(): \n    iv.Stocksin = getstockcount()\n\n\ndef getmycharts():\n    for ic in range(iv.Stocksin):\n \n    ", "date_posted": "2019-05-21 10:59:46Z", "upvote": "\r\n            18\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "33320055", "stack_answer_comment_id": "75306337", "comment_content": "What is the advantage to move the global variables to another file? Is it just to group together the global variables in a tiny file? And why using the statement ", "user_id": "None"}, {"stack_answer_id": "33320055", "stack_answer_comment_id": "75306618", "comment_content": "Ah... I have finally understood the advantage: No need to use the keyword ", "user_id": "None"}]}, {"stack_answer_id": "34664752", "answer_content": "\r\n Writing to explicit elements of a global array does not apparently need the global declaration, though writing to it \"wholesale\" does have that requirement: \n\n import numpy as np\n\nhostValue = 3.14159\nhostArray = np.array([2., 3.])\nhostMatrix = np.array([[1.0, 0.0],[ 0.0, 1.0]])\n\ndef func1():\n    global hostValue    # mandatory, else local.\n    hostValue = 2.0\n\ndef func2():\n    global hostValue    # mandatory, else UnboundLocalError.\n    hostValue += 1.0\n\ndef func3():\n    global hostArray    # mandatory, else local.\n    hostArray = np.array([14., 15.])\n\ndef func4():            # no need for globals\n    hostArray[0] = 123.4\n\ndef func5():            # no need for globals\n    hostArray[1] += 1.0\n\ndef func6():            # no need for globals\n    hostMatrix[1][1] = 12.\n\ndef func7():            # no need for globals\n    hostMatrix[0][0] += 0.33\n\nfunc1()\nprint \"After func1(), hostValue = \", hostValue\nfunc2()\nprint \"After func2(), hostValue = \", hostValue\nfunc3()\nprint \"After func3(), hostArray = \", hostArray\nfunc4()\nprint \"After func4(), hostArray = \", hostArray\nfunc5()\nprint \"After func5(), hostArray = \", hostArray\nfunc6()\nprint \"After func6(), hostMatrix = \\n\", hostMatrix\nfunc7()\nprint \"After func7(), hostMatrix = \\n\", hostMatrix\n \n    ", "date_posted": "2016-01-08 22:35:22Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "5266381", "name": "Mike Lampton", "reputation_score": "181"}, "answer_comments": []}, {"stack_answer_id": "46058078", "answer_content": "\r\n I'm adding this as I haven't seen it in any of the other answers and it might be useful for someone struggling with something similar. The  globals()  function returns a mutable global symbol dictionary where you can \"magically\" make data available for the rest of your code. \nFor example: \n\n from pickle import load\ndef loaditem(name):\n    with open(r\"C:\\pickle\\file\\location\"+\"\\{}.dat\".format(name), \"rb\") as openfile:\n        globals()[name] = load(openfile)\n    return True\n \n\n and  \n\n from pickle import dump\ndef dumpfile(name):\n    with open(name+\".dat\", \"wb\") as outfile:\n        dump(globals()[name], outfile)\n    return True\n \n\n Will just let you dump/load variables out of and into the global namespace. Super convenient, no muss, no fuss. Pretty sure it's Python 3 only. \n    ", "date_posted": "2019-05-21 12:08:51Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "46058078", "stack_answer_comment_id": "98710279", "comment_content": " always returns globals available in the local context, so a mutation here may not reflect in another module.", "user_id": "None"}]}, {"stack_answer_id": "45769568", "answer_content": "\r\n Reference the class namespace where you want the change to show up.   \n\n In this example, runner is using  max  from the file config. I want my test to change the value of  max  when runner is using it. \n\n main/config.py \n\n max = 15000\n \n\n main/runner.py \n\n from main import config\ndef check_threads():\n    return max < thread_count \n \n\n tests/runner_test.py \n\n from main import runner                # <----- 1. add file\nfrom main.runner import check_threads\nclass RunnerTest(unittest):\n   def test_threads(self):\n       runner.max = 0                  # <----- 2. set global \n       check_threads()\n \n    ", "date_posted": "2017-08-19 08:48:27Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "1303587", "name": "llewellyn falco", "reputation_score": "2,181"}, "answer_comments": []}, {"stack_answer_id": "61992762", "answer_content": "\r\n Globals are fine - Except with Multiprocessing \n\n Globals in connection with multiprocessing on different platforms/envrionments \nas Windows/Mac OS on the one side and Linux on the other are troublesome. \n\n I will show you this with a simple example pointing out a problem which I run into some time ago.  \n\n If you want to understand, why things are different on Windows/MacOs and Linux you \nneed to know that, the default mechanism to start a new process on ... \n\n \n Windows/MacOs is 'spawn' \n Linux is 'fork' \n \n\n They are different in Memory allocation an initialisation ... (but I don't go into this\nhere).  \n\n Let's have a look at the problem/example ... \n\n import multiprocessing\n\ncounter = 0\n\ndef do(task_id):\n    global counter\n    counter +=1\n    print(f'task {task_id}: counter = {counter}')\n\nif __name__ == '__main__':\n\n    pool = multiprocessing.Pool(processes=4)\n    task_ids = list(range(4))\n    pool.map(do, task_ids)\n \n\n Windows \n\n If you run this on Windows (And I suppose on MacOS too), you get the following output ... \n\n task 0: counter = 1\ntask 1: counter = 2\ntask 2: counter = 3\ntask 3: counter = 4\n \n\n Linux \n\n If you run this on Linux, you get the following instead.  \n\n task 0: counter = 1\ntask 1: counter = 1\ntask 2: counter = 1\ntask 3: counter = 1\n \n    ", "date_posted": "2020-05-24 21:41:53Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "6229784", "name": "thomas", "reputation_score": "259"}, "answer_comments": []}, {"stack_answer_id": "63629668", "answer_content": "\r\n There are 2 ways to declare a variable as global: \n 1. assign variable inside functions and use global line \n def declare_a_global_variable():\n    global global_variable_1\n    global_variable_1 = 1\n\n# Note to use the function to global variables\ndeclare_a_global_variable() \n \n 2. assign variable outside functions: \n global_variable_2 = 2\n \n Now we can use these declared global variables in the other functions: \n def declare_a_global_variable():\n    global global_variable_1\n    global_variable_1 = 1\n\n# Note to use the function to global variables\ndeclare_a_global_variable() \nglobal_variable_2 = 2\n\ndef print_variables():\n    print(global_variable_1)\n    print(global_variable_2)\nprint_variables() # prints 1 & 2\n \n Note 1: \n If you want to change a global variable inside another function like  update_variables()  you should use global line in that function before assigning the variable: \n global_variable_1 = 1\nglobal_variable_2 = 2\n\ndef update_variables():\n    global global_variable_1\n    global_variable_1 = 11\n    global_variable_2 = 12 # will update just locally for this function\n\nupdate_variables()\nprint(global_variable_1) # prints 11\nprint(global_variable_2) # prints 2\n \n Note 2: \n There is a exception for note 1 for list and dictionary variables while not using global line inside a function: \n # declaring some global variables\nvariable = 'peter'\nlist_variable_1 = ['a','b']\nlist_variable_2 = ['c','d']\n\ndef update_global_variables():\n    \"\"\"without using global line\"\"\"\n    variable = 'PETER' # won't update in global scope\n    list_variable_1 = ['A','B'] # won't update in global scope\n    list_variable_2[0] = 'C' # updated in global scope surprisingly this way\n    list_variable_2[1] = 'D' # updated in global scope surprisingly this way\n\nupdate_global_variables()\n\nprint('variable is: %s'%variable) # prints peter\nprint('list_variable_1 is: %s'%list_variable_1) # prints ['a', 'b']\nprint('list_variable_2 is: %s'%list_variable_2) # prints ['C', 'D']\n \n    ", "date_posted": "2020-09-12 09:23:03Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "6756530", "name": "Mohsen Haddadi", "reputation_score": "1,198"}, "answer_comments": []}, {"stack_answer_id": "67339244", "answer_content": "\r\n Though this has been answered, I am giving solution again as I prefer single line\nThis is if you wish to create global variable within function \n def someFunc():\n    x=20\n    globals()['y']=50\nsomeFunc() # invoking function so that variable Y is created globally \nprint(y) # output 50\nprint(x) #NameError: name 'x' is not defined as x was defined locally within function\n \n    ", "date_posted": "2021-04-30 19:26:17Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "15132261", "name": "Pavn", "reputation_score": "123"}, "answer_comments": []}, {"stack_answer_id": "71663780", "answer_content": "\r\n global_var = 10  # will be considered as a global variable\n\n\ndef func_1():\n    global global_var  # access variable using variable keyword\n    global_var += 1\n\n\ndef func_2():\n    global global_var\n    global_var *= 2\n    print(f\"func_2: {global_var}\")\n\n\nfunc_1()\nfunc_2()\nprint(\"Global scope:\", global_var) # will print 22\n \n Explanation: \n global_var  is a global variable and all functions and classes can access that variable. \n The  func_1()  accessed that global variable using the keyword  global  which points to the variable which is written in the global scope. If I didn't write the global keyword the variable  global_var  inside  func_1  is considered a local variable that is only usable inside the function. Then inside  func_1 , I have incremented that global variable by 1. \n The same happened in  func_2() . \n After calling  func_1  and  func_2 , you'll see the  global_var  is changed \n    ", "date_posted": "2022-04-04 14:58:25Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "15531189", "name": "SHIVAM SINGH", "reputation_score": "65"}, "answer_comments": [{"stack_answer_id": "71663780", "stack_answer_comment_id": "126780096", "comment_content": " is a global variable and all functions and classes can access that variable.  The func_1() accessed that global variable using the keyword ", "user_id": "None"}]}, {"stack_answer_id": "71074895", "answer_content": "\r\n Like this code: \n myVar = 12\n\ndef myFunc():\n  myVar += 12\n \n Key: \n If you declare a variable outside the strings, it become global. \n If you declare a variable inside the strings, it become local. \n If you want to declare a global variable inside the strings, use the keyword  global  before the variable you want to declare: \n myVar = 124\ndef myFunc():\n  global myVar2\n  myVar2 = 100\nmyFunc()\nprint(myVar2)\n \n and then you have 100 in the document. \n    ", "date_posted": "2022-02-22 09:19:20Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "17754099", "name": "Oscar Nguyen", "reputation_score": "43"}, "answer_comments": []}, {"stack_answer_id": "71883300", "answer_content": "\r\n Initialized = 0  #Here This Initialized is global variable  \n\ndef Initialize():\n     print(\"Initialized!\")\n     Initialized = 1  #This is local variable and assigning 1 to local variable\nwhile Initialized == 0:  \n \n Here we are comparing global variable Initialized that 0, so while loop condition got true \n      Initialize()\n \n Function will get called.Loop will be infinite \n #if we do Initialized=1 then loop will terminate  \n\nelse:\n    print(\"Lets do something else now!\")\n \n    ", "date_posted": "2022-04-15 11:10:50Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "15512418", "name": "zeeshan12396", "reputation_score": "378"}, "answer_comments": []}], "user": {"stack_user_id": "46646", "name": "user46646", "reputation_score": "146k"}, "question_comments": [{"stack_question_id": "423379", "stack_question_comment_id": "129288933", "comment_content": "No matter where you mentioned 'global' before variable name, it can be used anywhere  like normal local variable, once the python read it as with 'global' keyword. But it is a very bad idea to unless the variable is common to the entire project. For example, project_name, database_url", "user_id": "None"}]},
{"stack_question_id": "20625582", "question_title": "How to deal with SettingWithCopyWarning in Pandas", "question_content": "\r\n                Background\nI just upgraded my Pandas from 0.11 to 0.13.0rc1. Now, the application is popping out many new warnings. One of them like this:\nE:\\FinReporter\\FM_EXT.py:449: SettingWithCopyWarning: A value ...\r\n", "question_url": "/questions/20625582/how-to-deal-with-settingwithcopywarning-in-pandas", "date_posted": "Dec 17, 2013 at 3:48", "upvote": "1", "view": "1", "tags": ["python", "pandas", "dataframe", "chained-assignment"], "answers_count": "2", "answers": [{"stack_answer_id": "20627316", "answer_content": "\r\n The  SettingWithCopyWarning  was created to flag potentially confusing \"chained\" assignments, such as the following, which does not always work as expected, particularly when the first selection returns a  copy .  [see  GH5390  and  GH5597  for background discussion.] \n df[df['A'] > 2]['B'] = new_val  # new_val not set in df\n \n The warning offers a suggestion to rewrite as follows: \n df.loc[df['A'] > 2, 'B'] = new_val\n \n However, this doesn't fit your usage, which is equivalent to: \n df = df[df['A'] > 2]\ndf['B'] = new_val\n \n While it's clear that you don't care about writes making it back to the original frame (since you are overwriting the reference to it), unfortunately this pattern cannot be differentiated from the first chained assignment example. Hence the (false positive) warning. The potential for false positives is addressed in the  docs on indexing , if you'd like to read further.  You can safely disable this new warning with the following assignment. \n import pandas as pd\npd.options.mode.chained_assignment = None  # default='warn'\n \n \n Other Resources \n \n pandas User Guide: Indexing and selecting data \n Python Data Science Handbook: Data Indexing and Selection \n Real Python: SettingWithCopyWarning in Pandas: Views vs Copies \n Dataquest: SettingwithCopyWarning: How to Fix This Warning in Pandas \n Towards Data Science: Explaining the SettingWithCopyWarning in pandas \n \n    ", "date_posted": "2022-07-28 19:28:08Z", "upvote": "\r\n            1416\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "7758804", "name": "Trenton McKinney", "reputation_score": "46.5k"}, "answer_comments": [{"stack_answer_id": "20627316", "stack_answer_comment_id": "119156609", "comment_content": "I was using a slice of a dataframe, doing modifications in that slice and was getting this error. I created this slice by doing a ", "user_id": "None"}, {"stack_answer_id": "20627316", "stack_answer_comment_id": "121147727", "comment_content": "How should I deal with ", "user_id": "None"}]}, {"stack_answer_id": "53954986", "answer_content": "\r\n \n How to deal with  SettingWithCopyWarning  in Pandas? \n \n This post is meant for readers who, \n \n Would like to understand what this warning means \n Would like to understand different ways of suppressing this warning \n Would like to understand how to improve their code and follow good practices to avoid this warning in the future. \n \n Setup \n np.random.seed(0)\ndf = pd.DataFrame(np.random.choice(10, (3, 5)), columns=list('ABCDE'))\ndf\n   A  B  C  D  E\n0  5  0  3  3  7\n1  9  3  5  2  4\n2  7  6  8  8  1\n \n \n What is the  SettingWithCopyWarning ? \n To know how to deal with this warning, it is important to understand what it means and why it is raised in the first place. \n When filtering DataFrames, it is possible slice/index a frame to return either a  view , or a  copy , depending on the internal layout and various implementation details. A \"view\" is, as the term suggests, a view into the original data, so modifying the view may modify the original object. On the other hand, a \"copy\" is a replication of data from the original, and modifying the copy has no effect on the original. \n As mentioned by other answers, the  SettingWithCopyWarning  was created to flag \"chained assignment\" operations. Consider  df  in the setup above. Suppose you would like to select all values in column \"B\" where values in column \"A\" is > 5. Pandas allows you to do this in different ways, some more correct than others. For example, \n df[df.A > 5]['B']\n \n1    3\n2    6\nName: B, dtype: int64\n \n And, \n df.loc[df.A > 5, 'B']\n\n1    3\n2    6\nName: B, dtype: int64\n \n These return the same result, so if you are only reading these values, it makes no difference. So, what is the issue? The problem with chained assignment, is that it is generally difficult to predict whether a view or a copy is returned,  so this largely becomes an issue when you are attempting to assign values back.  To build on the earlier example, consider how this code is executed by the interpreter: \n df.loc[df.A > 5, 'B'] = 4\n# becomes\ndf.__setitem__((df.A > 5, 'B'), 4)\n \n With a single  __setitem__  call to  df . OTOH, consider this code: \n df[df.A > 5]['B'] = 4\n# becomes\ndf.__getitem__(df.A > 5).__setitem__('B', 4)\n \n Now, depending on whether  __getitem__  returned a view or a copy, the  __setitem__  operation  may not work . \n In general, you should use  loc  for label-based assignment, and  iloc  for integer/positional based assignment, as the spec guarantees that they always operate on the original. Additionally, for setting a single cell, you should use  at  and  iat . \n More can be found in the  documentation . \n \n Note \nAll boolean indexing operations done with  loc  can also be done with  iloc . The only difference is that  iloc  expects either\nintegers/positions for index or a numpy array of boolean values, and\ninteger/position indexes for the columns. \n For example, \n df.loc[df.A > 5, 'B'] = 4\n \n Can be written nas \n df.iloc[(df.A > 5).values, 1] = 4\n \n And, \n df.loc[1, 'A'] = 100\n \n Can be written as \n df.iloc[1, 0] = 100\n \n And so on. \n \n \n Just tell me how to suppress the warning! \n Consider a simple operation on the \"A\" column of  df . Selecting \"A\" and dividing by 2 will raise the warning, but the operation will work. \n df2 = df[['A']]\ndf2['A'] /= 2\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/__main__.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\ndf2\n     A\n0  2.5\n1  4.5\n2  3.5\n \n There are a couple ways of directly silencing this warning: \n \n (recommended)  Use  loc  to slice subsets : \n  df2 = df.loc[:, ['A']]\n df2['A'] /= 2     # Does not raise \n \n \n Change  pd.options.mode.chained_assignment \nCan be set to  None ,  \"warn\" , or  \"raise\" .  \"warn\"  is the default.  None  will suppress the warning entirely, and  \"raise\"  will throw a  SettingWithCopyError , preventing the operation from going through. \n  pd.options.mode.chained_assignment = None\n df2['A'] /= 2\n \n \n Make a  deepcopy \n  df2 = df[['A']].copy(deep=True)\n df2['A'] /= 2\n \n \n \n @Peter Cotton  in the comments, came up with a nice way of non-intrusively changing the mode (modified from  this gist ) using a context manager, to set the mode only as long as it is required, and the reset it back to the original state when finished. \n \n class ChainedAssignent:\n    def __init__(self, chained=None):\n        acceptable = [None, 'warn', 'raise']\n        assert chained in acceptable, \"chained must be in \" + str(acceptable)\n        self.swcw = chained\n\n    def __enter__(self):\n        self.saved_swcw = pd.options.mode.chained_assignment\n        pd.options.mode.chained_assignment = self.swcw\n        return self\n\n    def __exit__(self, *args):\n        pd.options.mode.chained_assignment = self.saved_swcw\n \n \n The usage is as follows: \n # some code here\nwith ChainedAssignent():\n    df2['A'] /= 2\n# more code follows\n \n Or, to raise the exception \n with ChainedAssignent(chained='raise'):\n    df2['A'] /= 2\n\nSettingWithCopyError: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n \n \n The \"XY Problem\": What am I doing wrong? \n A lot of the time, users attempt to look for ways of suppressing this exception without fully understanding why it was raised in the first place. This is a good example of an  XY problem , where users attempt to solve a problem \"Y\" that is actually a symptom of a deeper rooted problem \"X\". Questions will be raised based on common problems that encounter this warning, and solutions will then be presented. \n \n Question 1 \nI have a DataFrame \n df\n       A  B  C  D  E\n    0  5  0  3  3  7\n    1  9  3  5  2  4\n    2  7  6  8  8  1\n \n I want to assign values in col \"A\" > 5 to 1000. My expected output is \n       A  B  C  D  E\n0     5  0  3  3  7\n1  1000  3  5  2  4\n2  1000  6  8  8  1\n \n \n Wrong way to do this: \n df.A[df.A > 5] = 1000         # works, because df.A returns a view\ndf[df.A > 5]['A'] = 1000      # does not work\ndf.loc[df.A > 5]['A'] = 1000   # does not work\n \n Right way using  loc : \n df.loc[df.A > 5, 'A'] = 1000\n \n \n \n Question 2 1 \nI am trying to set the value in cell (1, 'D') to 12345. My expected output is \n    A  B  C      D  E\n0  5  0  3      3  7\n1  9  3  5  12345  4\n2  7  6  8      8  1\n \n I have tried different ways of accessing this cell, such as\n df['D'][1] . What is the best way to do this? \n 1. This question isn't specifically related to the warning, but\nit is good to understand how to do this particular operation correctly\nso as to avoid situations where the warning could potentially arise in\nfuture. \n \n You can use any of the following methods to do this. \n df.loc[1, 'D'] = 12345\ndf.iloc[1, 3] = 12345\ndf.at[1, 'D'] = 12345\ndf.iat[1, 3] = 12345\n \n \n \n Question 3 \nI am trying to subset values based on some condition. I have a\nDataFrame \n    A  B  C  D  E\n1  9  3  5  2  4\n2  7  6  8  8  1\n \n I would like to assign values in \"D\" to 123 such that \"C\" == 5. I\ntried \n df2.loc[df2.C == 5, 'D'] = 123\n \n Which seems fine but I am  still  getting the\n SettingWithCopyWarning ! How do I fix this? \n \n This is actually probably because of code higher up in your pipeline. Did you create  df2  from something larger, like \n df2 = df[df.A > 5]\n \n ? In this case, boolean indexing will return a view, so  df2  will reference the original. What you'd need to do is assign  df2  to a  copy : \n df2 = df[df.A > 5].copy()\n# Or,\n# df2 = df.loc[df.A > 5, :]\n \n \n \n Question 4 \nI'm trying to drop column \"C\" in-place from \n \n \n    A  B  C  D  E\n1  9  3  5  2  4\n2  7  6  8  8  1\n \n But using \n df2.drop('C', axis=1, inplace=True)\n \n Throws  SettingWithCopyWarning . Why is this happening? \n \n This is because  df2  must have been created as a view from some other slicing operation, such as \n df2 = df[df.A > 5]\n \n The solution here is to either make a  copy()  of  df , or use  loc , as before. \n\n    ", "date_posted": "2021-11-07 08:54:25Z", "upvote": "\r\n            691\r\n        ", "accepted": "No", "user": {"stack_user_id": "155137", "name": "Martijn Courteaux", "reputation_score": "66k"}, "answer_comments": [{"stack_answer_id": "53954986", "stack_answer_comment_id": "97716054", "comment_content": "P.S.: Let me know if your situation is not covered under section 3's list of questions. I will amend my post.", "user_id": "None"}, {"stack_answer_id": "53954986", "stack_answer_comment_id": "113259726", "comment_content": "I think it would be helpful for Question 2 to link to a question addressing the differences between loc, iloc, at, and iat.  You are probably more aware of such a question than I am, but I'm happy to seek one if it would be helpful.", "user_id": "None"}, {"stack_answer_id": "53954986", "stack_answer_comment_id": "113259845", "comment_content": " address the case where you want to use loc and iloc at the same time, iloc for rows and loc for columns", "user_id": "None"}, {"stack_answer_id": "53954986", "stack_answer_comment_id": "114720974", "comment_content": "@cs95: Could you add  an XY description around the case where you are trying to create a new column based on simple math operations on an existing one. As in df['new_col'] = df['old_col']/2. Where 'new_col' does not yet exist. Thx", "user_id": "None"}, {"stack_answer_id": "53954986", "stack_answer_comment_id": "114723885", "comment_content": "@BryanP unless I'm mistaken that should more or less be covered under the \"Just tell me how to suppress the warning!\" section.", "user_id": "None"}]}, {"stack_answer_id": "20644369", "answer_content": "\r\n In general the point of the  SettingWithCopyWarning  is to show users (and especially new users) that they  may  be operating on a copy and not the original as they think. There  are  false positives (IOW if you know what you are doing it could be  ok ). One possibility is simply to turn off the (by default  warn ) warning as @Garrett suggest. \n\n Here is another option: \n\n In [1]: df = DataFrame(np.random.randn(5, 2), columns=list('AB'))\n\nIn [2]: dfa = df.ix[:, [1, 0]]\n\nIn [3]: dfa.is_copy\nOut[3]: True\n\nIn [4]: dfa['A'] /= 2\n/usr/local/bin/ipython:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_index,col_indexer] = value instead\n  #!/usr/local/bin/python\n \n\n You can set the  is_copy  flag to  False , which will effectively turn off the check,  for that object : \n\n In [5]: dfa.is_copy = False\n\nIn [6]: dfa['A'] /= 2\n \n\n If you explicitly copy then no further warning will happen: \n\n In [7]: dfa = df.ix[:, [1, 0]].copy()\n\nIn [8]: dfa['A'] /= 2\n \n\n The code the OP is showing above, while legitimate, and probably something I do as well, is technically a case for this warning, and not a false positive. Another way to  not  have the warning would be to do the selection operation via  reindex , e.g. \n\n quote_df = quote_df.reindex(columns=['STK', ...])\n \n\n Or,  \n\n quote_df = quote_df.reindex(['STK', ...], axis=1)  # v.0.21\n \n    ", "date_posted": "2018-11-09 19:23:22Z", "upvote": "\r\n            170\r\n        ", "accepted": "No", "user": {"stack_user_id": "1840471", "name": "Max Ghenis", "reputation_score": "13.3k"}, "answer_comments": [{"stack_answer_id": "20644369", "stack_answer_comment_id": "119840558", "comment_content": "I think it's an understatement to say that there are false positives. I don't think I've ever had this warning help me, and the number of times I've had it clog up my output is insane. It's also bad programming practice: if you start ignoring the warnings in your output because you know they are pure rubbish, you can start to miss real problems. It's also annoying to have to turn off the same warnings all the time.", "user_id": "None"}]}, {"stack_answer_id": "40214434", "answer_content": "\r\n Pandas dataframe copy warning \n When you go and do something like this: \n quote_df = quote_df.ix[:,[0,3,2,1,4,5,8,9,30,31]]\n \n pandas.ix   in this case  returns a new, stand alone dataframe. \n Any values you decide to change in this dataframe, will not change the original dataframe. \n This is what pandas tries to warn you about. \n \n Why  .ix  is a bad idea \n The  .ix  object tries to do more than one thing, and for anyone who has read anything about clean code, this is a strong smell. \n Given this dataframe: \n df = pd.DataFrame({\"a\": [1,2,3,4], \"b\": [1,1,2,2]})\n \n Two behaviors: \n dfcopy = df.ix[:,[\"a\"]]\ndfcopy.a.ix[0] = 2\n \n Behavior one:  dfcopy  is now a stand alone dataframe. Changing it will not change  df \n df.ix[0, \"a\"] = 3\n \n Behavior two: This changes the original dataframe. \n \n Use  .loc  instead \n The pandas developers recognized that the  .ix  object was quite smelly[speculatively] and thus created two new objects which helps in the accession and assignment of data. (The other being  .iloc ) \n .loc  is faster, because it does not try to create a copy of the data. \n .loc  is meant to modify your existing dataframe inplace, which is more memory efficient. \n .loc  is predictable, it has one behavior. \n \n The solution \n What you are doing in your code example is loading a big file with lots of columns, then modifying it to be smaller. \n The  pd.read_csv  function can help you out with a lot of this and also make the loading of the file a lot faster. \n So instead of doing this \n quote_df = pd.read_csv(StringIO(str_of_all), sep=',', names=list('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefg')) #dtype={'A': object, 'B': object, 'C': np.float64}\nquote_df.rename(columns={'A':'STK', 'B':'TOpen', 'C':'TPCLOSE', 'D':'TPrice', 'E':'THigh', 'F':'TLow', 'I':'TVol', 'J':'TAmt', 'e':'TDate', 'f':'TTime'}, inplace=True)\nquote_df = quote_df.ix[:,[0,3,2,1,4,5,8,9,30,31]]\n \n Do this \n columns = ['STK', 'TPrice', 'TPCLOSE', 'TOpen', 'THigh', 'TLow', 'TVol', 'TAmt', 'TDate', 'TTime']\ndf = pd.read_csv(StringIO(str_of_all), sep=',', usecols=[0,3,2,1,4,5,8,9,30,31])\ndf.columns = columns\n \n This will only read the columns you are interested in, and name them properly. No need for using the evil  .ix  object to do magical stuff. \n    ", "date_posted": "2020-06-20 09:12:55Z", "upvote": "\r\n            47\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}, {"stack_answer_id": "54914752", "answer_content": "\r\n Here I answer the question directly. How to deal with it? \n\n Make a  .copy(deep=False)  after you slice. See  pandas.DataFrame.copy . \n\n Wait, doesn't a slice return a copy? After all, this is what the warning message is attempting to say? Read the long answer: \n\n import pandas as pd\ndf = pd.DataFrame({'x':[1,2,3]})\n \n\n This gives a warning: \n\n df0 = df[df.x>2]\ndf0['foo'] = 'bar'\n \n\n This does not: \n\n df1 = df[df.x>2].copy(deep=False)\ndf1['foo'] = 'bar'\n \n\n Both  df0  and  df1  are  DataFrame  objects, but something about them is different that enables pandas to print the warning. Let's find out what it is. \n\n import inspect\nslice= df[df.x>2]\nslice_copy = df[df.x>2].copy(deep=False)\ninspect.getmembers(slice)\ninspect.getmembers(slice_copy)\n \n\n Using your diff tool of choice, you will see that beyond a couple of addresses, the only material difference is this: \n\n |          | slice   | slice_copy |\n| _is_copy | weakref | None       |\n \n\n The method that decides whether to warn is  DataFrame._check_setitem_copy  which checks  _is_copy . So here you go. Make a  copy  so that your DataFrame is not  _is_copy . \n\n The warning is suggesting to use  .loc , but if you use  .loc  on a frame that  _is_copy , you will still get the same warning. Misleading? Yes. Annoying? You bet. Helpful? Potentially, when chained assignment is used. But it cannot correctly detect chain assignment and prints the warning indiscriminately. \n    ", "date_posted": "2019-05-24 18:36:09Z", "upvote": "\r\n            47\r\n        ", "accepted": "No", "user": {"stack_user_id": "443854", "name": "user443854", "reputation_score": "6,574"}, "answer_comments": [{"stack_answer_id": "54914752", "stack_answer_comment_id": "119747857", "comment_content": "Good sleuthing.  FWIW I also found that ", "user_id": "None"}, {"stack_answer_id": "54914752", "stack_answer_comment_id": "124723865", "comment_content": "This answer surely deserves a separate badge for writing style.", "user_id": "None"}, {"stack_answer_id": "54914752", "stack_answer_comment_id": "125406269", "comment_content": "Hands-down the most concrete and direct answer to the question. Very well put.", "user_id": "None"}]}, {"stack_answer_id": "56507986", "answer_content": "\r\n This topic is really confusing with Pandas. Luckily, it has a relatively simple solution. \n The problem is that it is not always clear whether data filtering operations (e.g. loc) return a copy or a view of the DataFrame. Further use of such filtered DataFrame could therefore be confusing. \n The simple solution is (unless you need to work with very large sets of data): \n Whenever you need to update any values, always make sure that you explicitly copy the DataFrame before the assignment. \n df  # Some DataFrame\ndf = df.loc[:, 0:2]  # Some filtering (unsure whether a view or copy is returned)\ndf = df.copy()  # Ensuring a copy is made\ndf[df[\"Name\"] == \"John\"] = \"Johny\"  # Assignment can be done now (no warning)\n \n    ", "date_posted": "2020-12-09 17:57:58Z", "upvote": "\r\n            29\r\n        ", "accepted": "No", "user": {"stack_user_id": "832230", "name": "Asclepius", "reputation_score": "51.5k"}, "answer_comments": [{"stack_answer_id": "56507986", "stack_answer_comment_id": "115403288", "comment_content": "For large datasets you can make a shallow (deep=False) copy. Still it seems too much to suppress a warning.", "user_id": "None"}]}, {"stack_answer_id": "60885847", "answer_content": "\r\n I had been getting this issue with  .apply()  when assigning a new dataframe from a pre-existing dataframe on which i've used the  .query()  method. For instance: \n\n prop_df = df.query('column == \"value\"')\nprop_df['new_column'] = prop_df.apply(function, axis=1)\n \n\n Would return this error. The fix that seems to resolve the error in this case is by changing this to: \n\n prop_df = df.copy(deep=True)\nprop_df = prop_df.query('column == \"value\"')\nprop_df['new_column'] = prop_df.apply(function, axis=1)\n \n\n However, this is NOT efficient especially when using large dataframes, due to having to make a new copy. \n\n If you're using the  .apply()  method in generating a new column and its values, a fix that resolves the error and is more efficient is by adding  .reset_index(drop=True) : \n\n prop_df = df.query('column == \"value\"').reset_index(drop=True)\nprop_df['new_column'] = prop_df.apply(function, axis=1)\n \n    ", "date_posted": "2020-03-27 12:46:02Z", "upvote": "\r\n            18\r\n        ", "accepted": "No", "user": {"stack_user_id": "3604584", "name": "Zilbert97", "reputation_score": "442"}, "answer_comments": []}, {"stack_answer_id": "45361923", "answer_content": "\r\n To remove any doubt, my solution was to make a deep copy of the slice instead of a regular copy.\nThis may not be applicable depending on your context (Memory constraints / size of the slice, potential for performance degradation - especially if the copy occurs in a loop like it did for me, etc...) \n To be clear, here is the warning I received: \n /opt/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:54:\nSettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame\nSee the caveats in the documentation:\nhttp://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n \n Illustration \n I had doubts that the warning was thrown because of a column I was dropping on a copy of the slice. While not technically trying to set a value in the copy of the slice, that was still a modification of the copy of the slice.\nBelow are the (simplified) steps I have taken to confirm the suspicion, I hope it will help those of us who are trying to understand the warning. \n Example 1: dropping a column on the original affects the copy \n We knew that already but this is a healthy reminder. This is  NOT  what the warning is about. \n >> data1 = {'A': [111, 112, 113], 'B':[121, 122, 123]}\n>> df1 = pd.DataFrame(data1)\n>> df1\n\n    A   B\n0   111 121\n1   112 122\n2   113 123\n\n\n>> df2 = df1\n>> df2\n\nA   B\n0   111 121\n1   112 122\n2   113 123\n\n# Dropping a column on df1 affects df2\n>> df1.drop('A', axis=1, inplace=True)\n>> df2\n    B\n0   121\n1   122\n2   123\n \n It is possible to avoid changes made on df1 to affect df2. Note: you can avoid importing  copy.deepcopy  by doing  df.copy()  instead. \n >> data1 = {'A': [111, 112, 113], 'B':[121, 122, 123]}\n>> df1 = pd.DataFrame(data1)\n>> df1\n\nA   B\n0   111 121\n1   112 122\n2   113 123\n\n>> import copy\n>> df2 = copy.deepcopy(df1)\n>> df2\nA   B\n0   111 121\n1   112 122\n2   113 123\n\n# Dropping a column on df1 does not affect df2\n>> df1.drop('A', axis=1, inplace=True)\n>> df2\n    A   B\n0   111 121\n1   112 122\n2   113 123\n \n Example 2: dropping a column on the copy may affect the original \n This actually illustrates the warning. \n >> data1 = {'A': [111, 112, 113], 'B':[121, 122, 123]}\n>> df1 = pd.DataFrame(data1)\n>> df1\n\n    A   B\n0   111 121\n1   112 122\n2   113 123\n\n>> df2 = df1\n>> df2\n\n    A   B\n0   111 121\n1   112 122\n2   113 123\n\n# Dropping a column on df2 can affect df1\n# No slice involved here, but I believe the principle remains the same?\n# Let me know if not\n>> df2.drop('A', axis=1, inplace=True)\n>> df1\n\nB\n0   121\n1   122\n2   123\n \n It is possible to avoid changes made on df2 to affect df1 \n >> data1 = {'A': [111, 112, 113], 'B':[121, 122, 123]}\n>> df1 = pd.DataFrame(data1)\n>> df1\n\n    A   B\n0   111 121\n1   112 122\n2   113 123\n\n>> import copy\n>> df2 = copy.deepcopy(df1)\n>> df2\n\nA   B\n0   111 121\n1   112 122\n2   113 123\n\n>> df2.drop('A', axis=1, inplace=True)\n>> df1\n\nA   B\n0   111 121\n1   112 122\n2   113 123\n \n Cheers! \n    ", "date_posted": "2021-02-05 19:57:52Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "5009287", "name": "Raphvanns", "reputation_score": "1,536"}, "answer_comments": []}, {"stack_answer_id": "69595276", "answer_content": "\r\n For me worked: \n import pandas as pd\n# ...\npd.set_option('mode.chained_assignment', None)\n \n    ", "date_posted": "2021-10-16 11:43:25Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "13947931", "name": "mikolaj semeniuk", "reputation_score": "1,288"}, "answer_comments": []}, {"stack_answer_id": "49190903", "answer_content": "\r\n This should work: \n\n quote_df.loc[:,'TVol'] = quote_df['TVol']/TVOL_SCALE\n \n    ", "date_posted": "2018-03-09 09:48:49Z", "upvote": "\r\n            10\r\n        ", "accepted": "No", "user": {"stack_user_id": "1315131", "name": "jrouquie", "reputation_score": "4,255"}, "answer_comments": []}, {"stack_answer_id": "56183831", "answer_content": "\r\n Some may want to simply suppress the warning: \n\n class SupressSettingWithCopyWarning:\n    def __enter__(self):\n        pd.options.mode.chained_assignment = None\n\n    def __exit__(self, *args):\n        pd.options.mode.chained_assignment = 'warn'\n\nwith SupressSettingWithCopyWarning():\n    #code that produces warning\n \n    ", "date_posted": "2019-05-17 09:47:34Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "7027346", "name": "delica", "reputation_score": "1,557"}, "answer_comments": []}, {"stack_answer_id": "54664893", "answer_content": "\r\n Followup beginner question / remark \n\n Maybe a clarification for other beginners like me (I come from R which seems to work a bit differently under the hood). The following harmless-looking and functional code kept producing the SettingWithCopy warning, and I couldn't figure out why. I had both read and understood the issued with \"chained indexing\", but my code doesn't contain any: \n\n def plot(pdb, df, title, **kw):\n    df['target'] = (df['ogg'] + df['ugg']) / 2\n    # ...\n \n\n But then, later, much too late, I looked at where the plot() function is called: \n\n     df = data[data['anz_emw'] > 0]\n    pixbuf = plot(pdb, df, title)\n \n\n So \"df\" isn't a data frame but an object that somehow remembers that it was created by indexing a data frame (so is that a view?) which would make the line in plot() \n\n  df['target'] = ...\n \n\n equivalent to \n\n  data[data['anz_emw'] > 0]['target'] = ...\n \n\n which is a chained indexing. Did I get that right? \n\n Anyway,  \n\n def plot(pdb, df, title, **kw):\n    df.loc[:,'target'] = (df['ogg'] + df['ugg']) / 2\n \n\n fixed it. \n    ", "date_posted": "2019-02-13 07:39:54Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "9940188", "name": "musbur", "reputation_score": "499"}, "answer_comments": [{"stack_answer_id": "54664893", "stack_answer_comment_id": "117318843", "comment_content": "A tad late to the party, but the ", "user_id": "None"}, {"stack_answer_id": "54664893", "stack_answer_comment_id": "117864677", "comment_content": "This explanation was the only one that got through to me (maybe because I'm also coming from R). Thanks!", "user_id": "None"}]}, {"stack_answer_id": "60040464", "answer_content": "\r\n As this question is already fully explained and discussed in existing answers I will just provide a neat  pandas  approach to the context manager using  pandas.option_context  (links to  docs  and  example ) - there is absolutely no need to create a custom class with all the dunder methods and other bells and whistles. \n\n First the context manager code itself: \n\n from contextlib import contextmanager\n\n@contextmanager\ndef SuppressPandasWarning():\n    with pd.option_context(\"mode.chained_assignment\", None):\n        yield\n \n\n Then an example: \n\n import pandas as pd\nfrom string import ascii_letters\n\na = pd.DataFrame({\"A\": list(ascii_letters[0:4]), \"B\": range(0,4)})\n\nmask = a[\"A\"].isin([\"c\", \"d\"])\n# Even shallow copy below is enough to not raise the warning, but why is a mystery to me.\nb = a.loc[mask]  # .copy(deep=False)\n\n# Raises the `SettingWithCopyWarning`\nb[\"B\"] = b[\"B\"] * 2\n\n# Does not!\nwith SuppressPandasWarning():\n    b[\"B\"] = b[\"B\"] * 2\n \n\n Worth noticing is that both approches do not modify  a , which is a bit surprising to me, and even a shallow df copy with  .copy(deep=False)  would prevent this warning to be raised (as far as I understand shallow copy should at least modify  a  as well, but it doesn't.  pandas  magic.). \n    ", "date_posted": "2020-02-03 13:41:12Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "4272484", "name": "m-dz", "reputation_score": "2,282"}, "answer_comments": []}, {"stack_answer_id": "46732545", "answer_content": "\r\n You could avoid the whole problem like this, I believe: \n\n return (\n    pd.read_csv(StringIO(str_of_all), sep=',', names=list('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefg')) #dtype={'A': object, 'B': object, 'C': np.float64}\n    .rename(columns={'A':'STK', 'B':'TOpen', 'C':'TPCLOSE', 'D':'TPrice', 'E':'THigh', 'F':'TLow', 'I':'TVol', 'J':'TAmt', 'e':'TDate', 'f':'TTime'}, inplace=True)\n    .ix[:,[0,3,2,1,4,5,8,9,30,31]]\n    .assign(\n        TClose=lambda df: df['TPrice'],\n        RT=lambda df: 100 * (df['TPrice']/quote_df['TPCLOSE'] - 1),\n        TVol=lambda df: df['TVol']/TVOL_SCALE,\n        TAmt=lambda df: df['TAmt']/TAMT_SCALE,\n        STK_ID=lambda df: df['STK'].str.slice(13,19),\n        STK_Name=lambda df: df['STK'].str.slice(21,30)#.decode('gb2312'),\n        TDate=lambda df: df.TDate.map(lambda x: x[0:4]+x[5:7]+x[8:10]),\n    )\n)\n \n\n Using Assign. From the  documentation : Assign new columns to a DataFrame, returning a new object (a copy) with all the original columns in addition to the new ones.  \n\n See Tom Augspurger's article on method chaining in pandas:  https://tomaugspurger.github.io/method-chaining \n    ", "date_posted": "2018-01-16 21:27:38Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "6238102", "name": "Halee", "reputation_score": "473"}, "answer_comments": []}, {"stack_answer_id": "44731898", "answer_content": "\r\n If you have assigned the slice to a variable and want to set using the variable as in the following: \n\n df2 = df[df['A'] > 2]\ndf2['B'] = value\n \n\n And you do not want to use Jeffs solution because your condition computing  df2  is to long or for some other reason, then you can use the following: \n\n df.loc[df2.index.tolist(), 'B'] = value\n \n\n df2.index.tolist()  returns the indices from all entries in df2, which will then be used to set column B in the original dataframe. \n    ", "date_posted": "2017-06-24 01:30:48Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "2128832", "name": "Steohan", "reputation_score": "446"}, "answer_comments": [{"stack_answer_id": "44731898", "stack_answer_comment_id": "88721524", "comment_content": "this is 9 time more expensive then df[\"B\"] = value", "user_id": "None"}, {"stack_answer_id": "44731898", "stack_answer_comment_id": "91880924", "comment_content": "Can you explain this more deeply @ClaudiuCreanga?", "user_id": "None"}]}, {"stack_answer_id": "70545685", "answer_content": "\r\n this might apply to numpy only, which means you might need to import it,  but the data i used for my examples numpy was not essential with the calculations, but you can simply stop this settingwithcopy warning message, by using this 1 Line of Code below, \n np.warnings.filterwarnings('ignore')\n \n    ", "date_posted": "2021-12-31 21:12:04Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "5315363", "name": "Calculate", "reputation_score": "171"}, "answer_comments": [{"stack_answer_id": "70545685", "stack_answer_comment_id": "127376857", "comment_content": "This one is the best one! Thanks. The copy warning is really annoying!", "user_id": "None"}]}, {"stack_answer_id": "47507827", "answer_content": "\r\n For me this issue occured in a following >simplified< example. And I was also able to solve it (hopefully with a correct solution): \n\n old code with warning: \n\n def update_old_dataframe(old_dataframe, new_dataframe):\n    for new_index, new_row in new_dataframe.iterrorws():\n        old_dataframe.loc[new_index] = update_row(old_dataframe.loc[new_index], new_row)\n\ndef update_row(old_row, new_row):\n    for field in [list_of_columns]:\n        # line with warning because of chain indexing old_dataframe[new_index][field]\n        old_row[field] = new_row[field]  \n    return old_row\n \n\n This printed the warning for the line  old_row[field] = new_row[field] \n\n Since the rows in update_row method are actually type  Series , I replaced the line with: \n\n old_row.at[field] = new_row.at[field]\n \n\n i.e.  method  for accessing/lookups for a  Series . Eventhough both works just fine and the result is same, this way I don't have to disable the warnings (=keep them for other chain indexing issues somewhere else). \n\n I hope this may help someone. \n    ", "date_posted": "2017-11-27 09:39:57Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "7920758", "name": "Petr Szturc", "reputation_score": "784"}, "answer_comments": []}, {"stack_answer_id": "68362289", "answer_content": "\r\n I was facing the same warning, while I executed this  part of my code: \n     def scaler(self, numericals):\n        scaler = MinMaxScaler()\n        self.data.loc[:, numericals[0]] = scaler.fit_transform(self.data.loc[:, numericals[0]])\n        self.data.loc[:, numericals[1]] = scaler.fit_transform(self.data.loc[:, numericals[1]])\n \n which  scaler  is a MinMaxScaler and  numericals[0]   contains names of 3 of my numerical columns.\nthe  warning was removed as I changed the code to: \n     def scaler(self, numericals):\n        scaler = MinMaxScaler()\n        self.data.loc[:][numericals[0]] = scaler.fit_transform(self.data.loc[:][numericals[0]])\n        self.data.loc[:][numericals[1]] = scaler.fit_transform(self.data.loc[:][numericals[1]])\n \n So, Just change  [:, ~]  to  [:][~] \n    ", "date_posted": "2021-07-13 12:19:16Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "13046916", "name": "mossishahi", "reputation_score": "68"}, "answer_comments": []}, {"stack_answer_id": "71089974", "answer_content": "\r\n In my case, I would create a new column based on the index but I got this warning as you: \n df_temp[\"Quarter\"] = df_temp.index.quarter\n \n I use insert() instead of direct assignment and it works for me: \n df_temp.insert(loc=0, column='Quarter', value=df_temp.index.quarter)\n \n    ", "date_posted": "2022-02-12 07:54:18Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "16733101", "name": "Phoenix", "reputation_score": "2,121"}, "answer_comments": []}, {"stack_answer_id": "69558039", "answer_content": "\r\n Just create a copy of your dataframe(s) using  .copy()  method before the warning appears, to remove all of your warnings. This happens because we do not want to make changes to the original quote_df. In other words, we do not want to play with the reference of the object of the quote_df which we have created for quote_df. \n quote_df = quote_df.copy()\n \n    ", "date_posted": "2021-10-13 15:13:50Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "3874009", "name": "Vaibhav Hiwase", "reputation_score": "171"}, "answer_comments": [{"stack_answer_id": "69558039", "stack_answer_comment_id": "124723905", "comment_content": "This is needlessly a deep copy (default option is ", "user_id": "None"}]}], "user": {"stack_user_id": "1072888", "name": "bigbug", "reputation_score": "50.9k"}, "question_comments": [{"stack_question_id": "20625582", "stack_question_comment_id": "62589711", "comment_content": "Here's a context manager to temporarily set the warning level ", "user_id": "None"}, {"stack_question_id": "20625582", "stack_question_comment_id": "88200031", "comment_content": " official document explain in detail", "user_id": "None"}, {"stack_question_id": "20625582", "stack_question_comment_id": "95242599", "comment_content": "@leonprou ", "user_id": "None"}, {"stack_question_id": "20625582", "stack_question_comment_id": "112079428", "comment_content": "Using ", "user_id": "None"}, {"stack_question_id": "20625582", "stack_question_comment_id": "121588951", "comment_content": "Does this answer your question? ", "user_id": "None"}]},
{"stack_question_id": "48054321", "question_title": "Of the many findElement(s)/By functions in Selenium, when would you use one over the other?", "question_content": "\r\n                Selenium includes findElement functions, like so... \n\n.find_element_by_\n\nid\nlink_text\npartial_link_text\nname\nclass_name\ntag_name\ncss_selector\nxpath\r\nIt's apparent that some are limited by design due ...\r\n", "question_url": "/questions/48054321/of-the-many-findelements-by-functions-in-selenium-when-would-you-use-one-over", "date_posted": "Jan 2, 2018 at 0:20", "upvote": "0", "view": "1", "tags": ["python", "python-3.x", "selenium", "selenium-webdriver", "css-selectors"], "answers_count": "2", "answers": [{"stack_answer_id": "48067003", "answer_content": "\r\n In my experience  CSS  is the preferable selector because it can be concise, is well documented and web developers are likely to have more experience and exposure to it. \n\n id ,  name ,  tag_name  and  class_name  can all be easily reproduced with simple CSS so I would avoid explicitly using those. \n\n e.g.  \n\n id  ;  #my_id \n\n name ;  [name=\"my_name\"] \n\n tag_name ;  my_tag \n\n class_name ;  .my_class \n\n The use of  XPath  is often much maligned; labeled as slow and unstable.  However I disagree with this view point. \n\n When I interview people I cringe when they say they avoid Xpath because it is slow and brittle. The speed is no longer a concern, and xpath is only as brittle as the person who wrote it.  However, I prefer the syntax of CSS Selectors so that is why I would choose over XPath for the majority of use cases. \n\n There are 3 scenarios in which XPath is the better choice; \n\n \n Multiple CSS Selectors may be replaced with one XPath query (e.g find element then iterate through sub elements can be performed in one xpath) \n XPath can select based on Text where as CSS Selector cannot \n XPath allows you walk up the DOM Tree which can be really useful if you can only identify a control by its child \n \n\n I would always avoid selecting by text if possible, but if I had to, I would prefer to use XPath over the built in  Link Text  and  Partial Link Text  methods because the Xpath query woudl allow me to be more expressive and allow me to select more than just anchor tags. \n\n Finally, once gotcha when using XPath is that \"class\" is treated as a literal string rather than an array of class names as supported in CSS selectors; \n\n HTML: <div class=\"ab cd\">\n\nCSS matches: div.ab\nCSS matches: div.cd\nCSS matches: div.cd.ab\nCSS matches: div.ab.cd\n\nXPath matches: //div[@class=\"ab cd\"]\nXPath matches: //div[contains(@class, \"ab\")]\nXPath matches: //div[contains(@class, \"cd\")]\nXPath matches: //div[contains(@class, \"ab\") and contains(@class, \"cd\")]\n\nXPath DOES NOT match: //div[@class=\"cd\"]\nXPath DOES NOT match: //div[@class=\"ab\"]\nXPath DOES NOT match: //div[@class=\"cd ab\"]\n \n    ", "date_posted": "2018-01-04 14:30:37Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "1644596", "name": "Robbie Wareham", "reputation_score": "3,277"}, "answer_comments": [{"stack_answer_id": "48067003", "stack_answer_comment_id": "83188957", "comment_content": "Hmm, this was a very interesting read. I appreciate the info! When you say that xpath is only as brittle as the person who wrote it, how would I know if i'm using the correct path or not(assuming this is the weak point)?", "user_id": "6402048"}, {"stack_answer_id": "48067003", "stack_answer_comment_id": "83202051", "comment_content": "There is no \"correct path\" for xpath, but that is true for CSS Selectors too.  As an example take this page and your signature image.  The following XPATH would work;  //body/div[3]/div[1]/div[1]/div[1]/div[2]/div[1]/table/tbody/tr[1]/td[2]/div[1]/table[1]/tbody/tr/td[2]/div[1]/div[2]/a/div/img  It would find your image everytime BUT if there was a small change in the HTML layout, it could easily break.  I would call this a brittle XPATH.  It is important to appreciate that I could just as easily write this in CSS just as bad!", "user_id": "None"}, {"stack_answer_id": "48067003", "stack_answer_comment_id": "83202157", "comment_content": "A better xpath could be '//div[contains(@class, \"question\")]//a[@href=\"/users/6402048/matt-i\"]//img'.  This will more resilient to structural changes.  NB. In this case I would probably use CSS as it could be clearer; '.question a[href=\"/users/6402048/matt-i\"] >img'  However, to create the Xpath (or indeed CSS selctor) you need to understand the AUT and what your are trying to test", "user_id": "None"}, {"stack_answer_id": "48067003", "stack_answer_comment_id": "86132359", "comment_content": "@MattI Feel free to mark this as an answer if you think it addresses your question", "user_id": "None"}]}, {"stack_answer_id": "48056120", "answer_content": "\r\n This question have been asked and answered in numerous forums in different formats. Considering them all if we prioritize the locators the list would be as follows : \n \n id : Select element with the specified  id  attribute. \n name : Select first element with the specified  name  attribute. \n link_text : Select link (anchor tag) element which contains  text  matching the specified  LinkText . \n partial_link_text : Select link (anchor tag) element which contains  text  matching the specified  PartialLinkText . \n tag_name : Locate Element using a  Tag Name . \n class_name : Locate Element using a  ClassName . \n css_selector : Select the element using  CssSelectors . \n xpath : Locate an element using an  XPath  expression. \n \n So the question now is  Whats New ? \n The answer is  Selenium have evolved a lot recently .  WebDriver  is now a  W3C Recommendation Candidate . Things within  Selenium  are changing pretty fast. It's no more only about choosing the locator. We need to use a locator which will : \n \n Uniquely identify an element . \n The performance of the locator must be optimized. \n \n Keeping these two factors in mind, the best strategy would be to  Mock the DOM . The  W3C Recommendation Candidate  does mentions the list of the locators as per the below : \n \n So the verdict is clear and concise. \n    ", "date_posted": "2021-03-08 12:47:05Z", "upvote": "\r\n            4\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "7429447", "name": "undetected Selenium", "reputation_score": "160k"}, "answer_comments": [{"stack_answer_id": "48056120", "stack_answer_comment_id": "83088740", "comment_content": "Obviously you have not read my question correctly. I know what these functions do, but i'm wondering why one would choose one over the other. Would there be a certain instance where xpaths would be more beneficial to use than css_selector, and vice versa.", "user_id": "6402048"}, {"stack_answer_id": "48056120", "stack_answer_comment_id": "83088832", "comment_content": "Definitely you haven't read the full verbatim of my ", "user_id": "None"}, {"stack_answer_id": "48056120", "stack_answer_comment_id": "83089044", "comment_content": "I did read it, but that line doesn't specify anything. All you did was post what each tag does and some info that barely gets into what i'm looking for.   How about this. When you go to a web page and inspect the HTML doc, when would you want to use xpath over css_selector, or vice versa? Is one more stable than the other, in terms of clicking the elements that I so desire to click on?", "user_id": "6402048"}, {"stack_answer_id": "48056120", "stack_answer_comment_id": "83089358", "comment_content": "Stability depends on how effectively you write the automation code which I have detailed out in my Answer. To achieve the optimum performance I did provide you the sequential options starting with ", "user_id": "None"}]}], "user": {"stack_user_id": "6402048", "name": "Matt I", "reputation_score": "155"}, "question_comments": [{"stack_question_id": "48054321", "stack_question_comment_id": "83081056", "comment_content": "I use the function whichever gives me ", "user_id": "None"}, {"stack_question_id": "48054321", "stack_question_comment_id": "83081163", "comment_content": "This discussion might be relevant: ", "user_id": "None"}, {"stack_question_id": "48054321", "stack_question_comment_id": "83082781", "comment_content": "I pretty much only use xpaths if I need to find something by text, or if the only way to find the element I want is to find another element, traverse back up the dom tree to some shared element, and then back down to the element I want. In my experience css selectors end up being cleaner and easier to read. You'll find people arguing that xpaths are also slower, but in practice you'll probably not notice a difference.", "user_id": "None"}, {"stack_question_id": "48054321", "stack_question_comment_id": "83092905", "comment_content": "@Matt Yes, mostly they are unique. If I see id, I use findelementbyid; if that's missing, I use xpath/CSS selector. I do however have trust issues with findelementbyclass, as class names can be used in multiple places. I don't worry about performance in the beginning, will chose the easy path. If performance is bad, only then I think about optimization. Hope it helps!", "user_id": "None"}, {"stack_question_id": "48054321", "stack_question_comment_id": "83104090", "comment_content": "@MattI let's say you have a bunch of similar looking rows that all have some button in it you want to click. There is no way to directly uniquely get the button you want because all the rows have similar buttons with similar attributes. However, there is some other element in the row that is unique. So I could get that element, traverse back up the dom tree to get the row that contains it, and back down to get the button using xpath.", "user_id": "None"}]},
{"stack_question_id": "1680528", "question_title": "How to avoid having class data shared among instances?", "question_content": "\r\n                What I want is this behavior:\n\nclass a:\n    list = []\n\nx = a()\ny = a()\n\nx.list.append(1)\ny.list.append(2)\nx.list.append(3)\ny.list.append(4)\n\nprint(x.list) # prints [1, 3]\nprint(y.list) # prints [2, 4]\r...\r\n", "question_url": "/questions/1680528/how-to-avoid-having-class-data-shared-among-instances", "date_posted": "Nov 5, 2009 at 13:19", "upvote": "1", "view": "3", "tags": ["python", "class"], "answers_count": "7", "answers": [{"stack_answer_id": "1680555", "answer_content": "\r\n You want this: \n\n class a:\n    def __init__(self):\n        self.list = []\n \n\n Declaring the variables inside the class declaration makes them \"class\" members and not instance members. Declaring them inside the  __init__  method makes sure that a new instance of the members is created alongside every new instance of the object, which is the behavior you're looking for. \n    ", "date_posted": "2009-11-05 13:28:53Z", "upvote": "\r\n            175\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "573", "name": "abyx", "reputation_score": "66.6k"}, "answer_comments": [{"stack_answer_id": "1680555", "stack_answer_comment_id": "1554819", "comment_content": "An added clarification: if you were to reassign the list property in one of the instances, it would not affect the others. So if you did something like ", "user_id": "None"}, {"stack_answer_id": "1680555", "stack_answer_comment_id": "48776247", "comment_content": "But why does this happens only for list? When i declared an integer or string outside the ", "user_id": "None"}, {"stack_answer_id": "1680555", "stack_answer_comment_id": "57726690", "comment_content": "@AmalTs It looks like you don't understand how assignment in python works. See ", "user_id": "None"}, {"stack_answer_id": "1680555", "stack_answer_comment_id": "57727008", "comment_content": "@AmalTs Note: it's considered a bad practice to use class attributes as \"lazy\" default values for instance attributes. Even if the attributes are of an immutable type it's better to assign them inside ", "user_id": "None"}, {"stack_answer_id": "1680555", "stack_answer_comment_id": "119016248", "comment_content": "I \"wow\" more every day I program in Python.", "user_id": "None"}]}, {"stack_answer_id": "15590354", "answer_content": "\r\n The accepted answer works but a little more explanation does not hurt.  \n\n Class attributes do not become instance attributes when an instance is created. They become instance attributes when a value is assigned to them. \n\n In the original code no value is assigned to  list  attribute after instantiation; so it remains a class attribute. Defining list inside  __init__  works because  __init__  is called after instantiation. Alternatively, this code would also produce the desired output: \n\n >>> class a:\n    list = []\n\n>>> y = a()\n>>> x = a()\n>>> x.list = []\n>>> y.list = []\n>>> x.list.append(1)\n>>> y.list.append(2)\n>>> x.list.append(3)\n>>> y.list.append(4)\n>>> print(x.list)\n[1, 3]\n>>> print(y.list)\n[2, 4]\n \n\n However, the confusing scenario in the question will never happen to immutable objects such as numbers and strings, because their value cannot be changed without assignment. For example a code similar to the original with string attribute type works without any problem: \n\n >>> class a:\n    string = ''\n\n\n>>> x = a()\n>>> y = a()\n>>> x.string += 'x'\n>>> y.string += 'y'\n>>> x.string\n'x'\n>>> y.string\n'y'\n \n\n So to summarize:  class attributes become instance attributes if and only if a value is assigned to them after instantiation, being in the  __init__  method or not . This is a good thing because this way you can have static attributes if you never assign a value to an attribute after instantiation. \n    ", "date_posted": "2013-03-23 18:12:40Z", "upvote": "\r\n            27\r\n        ", "accepted": "No", "user": {"stack_user_id": "1988148", "name": "jurgenreza", "reputation_score": "5,606"}, "answer_comments": [{"stack_answer_id": "15590354", "stack_answer_comment_id": "123884694", "comment_content": "I know this is an old answer, but... disagree with ", "user_id": "None"}]}, {"stack_answer_id": "41683345", "answer_content": "\r\n Although the accepted anwer is spot on, I would like to add a bit description. \n\n Let's do a small exercise  \n\n first of all define a class as follows: \n\n class A:\n    temp = 'Skyharbor'\n\n    def __init__(self, x):\n        self.x = x\n\n    def change(self, y):\n        self.temp = y\n \n\n So what do we have here? \n\n \n We have a very simple class which has an attribute  temp  which is a string \n An  __init__  method which sets  self.x   \n A change method sets  self.temp \n \n\n Pretty straight forward so far yeah? Now let's start playing around with this class. Let's initialize  this class first: \n\n a = A('Tesseract')\n \n\n Now do the following: \n\n >>> print(a.temp)\nSkyharbor\n>>> print(A.temp)\nSkyharbor\n \n\n Well,  a.temp  worked as expected but how the hell did  A.temp  work? Well it worked because temp is a class attribute. Everything in python is an object. Here A is also an object of class  type . Thus the attribute temp is an attribute held by the  A  class and if you change the value of temp through  A  (and not through an instance of  a ), the changed value is going to be reflected in all the instance of  A  class.\nLet's go ahead and do that: \n\n >>> A.temp = 'Monuments'\n>>> print(A.temp)\nMonuments\n>>> print(a.temp)\nMonuments\n \n\n Interesting isn't it? And  note that  id(a.temp)  and  id(A.temp)  are still the same . \n\n Any Python object is automatically given a  __dict__  attribute, which contains its list of attributes. Let's investigate what this dictionary contains for our example objects: \n\n >>> print(A.__dict__)\n{\n    'change': <function change at 0x7f5e26fee6e0>,\n    '__module__': '__main__',\n    '__init__': <function __init__ at 0x7f5e26fee668>,\n    'temp': 'Monuments',\n    '__doc__': None\n}\n>>> print(a.__dict__)\n{x: 'Tesseract'}\n \n\n Note that  temp  attribute is listed among  A  class's attributes while  x  is listed for the instance. \n\n So how come that we get a defined value of  a.temp  if it is not even listed for the instance  a . Well that's the magic of  __getattribute__()  method. In Python the dotted syntax automatically invokes this method so when we write  a.temp , Python executes  a.__getattribute__('temp') . That method performs the attribute lookup action, i.e. finds the value of the attribute by looking in different places. \n\n The standard implementation of  __getattribute__()  searches first the internal dictionary ( dict ) of an object, then the type of the object itself. In this case  a.__getattribute__('temp')  executes first  a.__dict__['temp']  and then  a.__class__.__dict__['temp'] \n\n Okay now let's use our  change  method: \n\n >>> a.change('Intervals')\n>>> print(a.temp)\nIntervals\n>>> print(A.temp)\nMonuments\n \n\n Well now that we have used  self ,  print(a.temp)  gives us a different value from  print(A.temp) .  \n\n Now if we compare  id(a.temp)  and  id(A.temp) , they will be different. \n    ", "date_posted": "2019-02-15 11:34:35Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "1222951", "name": "Aran-Fey", "reputation_score": "36.4k"}, "answer_comments": []}, {"stack_answer_id": "1680545", "answer_content": "\r\n You declared \"list\" as a \"class level property\" and not \"instance level property\".  In order to have properties scoped at the instance level, you need to initialize them through referencing with the \"self\" parameter in the  __init__  method (or elsewhere depending on the situation). \n\n You don't strictly have to initialize the instance properties in the  __init__  method but it makes for easier understanding. \n    ", "date_posted": "2009-11-05 13:27:29Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "171461", "name": "jldupont", "reputation_score": "89.2k"}, "answer_comments": []}, {"stack_answer_id": "21492237", "answer_content": "\r\n So nearly every response here seems to miss a particular point.  Class variables  never  become instance variables as demonstrated by the code below.  By utilizing a metaclass to intercept variable assignment at the class level, we can see that when a.myattr is reassigned, the field assignment magic method on the class is not called.  This is because the assignment  creates a new instance variable .  This behavior has  absolutely nothing  to do with the class variable as demonstrated by the second class which has no class variables and yet still allows field assignment. \n\n class mymeta(type):\n    def __init__(cls, name, bases, d):\n        pass\n\n    def __setattr__(cls, attr, value):\n        print(\"setting \" + attr)\n        super(mymeta, cls).__setattr__(attr, value)\n\nclass myclass(object):\n    __metaclass__ = mymeta\n    myattr = []\n\na = myclass()\na.myattr = []           #NOTHING IS PRINTED\nmyclass.myattr = [5]    #change is printed here\nb = myclass()\nprint(b.myattr)         #pass through lookup on the base class\n\nclass expando(object):\n    pass\n\na = expando()\na.random = 5            #no class variable required\nprint(a.random)         #but it still works\n \n\n IN SHORT  Class variables have NOTHING to do with instance variables. \n\n More clearly  They just happen to be in the scope for lookups on instances. Class variables are in fact  instance variables  on the class object itself.  You can also have  metaclass variables  if you want as well because metaclasses themselves are objects too.  Everything is an object whether it is used to create other objects or not, so do not get bound up in the semantics of other languages usage of the word class.  In python, a class is really just an object that is used to determine how to create other objects and what their behaviors will be.  Metaclasses are classes that create classes, just to further illustrate this point.  \n    ", "date_posted": "2014-01-31 23:52:55Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "2735812", "name": "TheQabalist", "reputation_score": "51"}, "answer_comments": []}, {"stack_answer_id": "1680581", "answer_content": "\r\n Yes you must declare in the \"constructor\" if you want that the list becomes an object property and not a class property. \n    ", "date_posted": "2009-11-05 13:27:04Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "201847", "name": "osanchezmon", "reputation_score": "544"}, "answer_comments": []}, {"stack_answer_id": "51728891", "answer_content": "\r\n To protect your variable shared by other instance you need to create new instance variable each time you create an instance. When you are declaring a variable inside a class it's class variable and shared by all instance. If you want to make it for instance wise need to use the  init  method to reinitialize the variable as  refer to the instance   \n\n From  Python Objects and Class  by Programiz.com : \n\n \n   __init__()  function. This special function gets called whenever a new object of that class is instantiated. \n  \n   This type of function is also called constructors in Object Oriented\n  Programming (OOP). We normally use it to initialize all the variables. \n \n\n For example: \n\n class example:\n    list=[] #This is class variable shared by all instance\n    def __init__(self):\n        self.list = [] #This is instance variable referred to specific instance\n \n    ", "date_posted": "2018-08-24 16:24:57Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "100297", "name": "Martijn Pieters", "reputation_score": "979k"}, "answer_comments": []}], "user": {"stack_user_id": "150564", "name": "8steve8", "reputation_score": "2,173"}, "question_comments": [{"stack_question_id": "1680528", "stack_question_comment_id": "48173061", "comment_content": "Please, do not use ", "user_id": "None"}]},
{"stack_question_id": "36921951", "question_title": "Truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()", "question_content": "\r\n                I want to filter my dataframe with an or condition to keep rows with a particular column's values that are outside the range [-0.25, 0.25]. I tried:\ndf = df[(df['col'] < -0.25) or (df['col'] > 0....\r\n", "question_url": "/questions/36921951/truth-value-of-a-series-is-ambiguous-use-a-empty-a-bool-a-item-a-any-o", "date_posted": "Apr 28, 2016 at 17:46", "upvote": "7", "view": "1", "tags": ["python", "pandas", "dataframe", "boolean", "filtering"], "answers_count": "1", "answers": [{"stack_answer_id": "36922103", "answer_content": "\r\n The  or  and  and  python statements require  truth -values. For  pandas , these are considered ambiguous so you should use \"bitwise\"  |  (or) or  &  (and) operations: \n df = df[(df['col'] < -0.25) | (df['col'] > 0.25)]\n \n These are overloaded for these kinds of data structures to yield the element-wise  or  or  and . \n \n Just to add some more explanation to this statement: \n The exception is thrown when you want to get the  bool  of a  pandas.Series : \n >>> import pandas as pd\n>>> x = pd.Series([1])\n>>> bool(x)\nValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n \n What you hit was a place where the operator  implicitly  converted the operands to  bool  (you used  or  but it also happens for  and ,  if  and  while ): \n >>> x or x\nValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n>>> x and x\nValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n>>> if x:\n...     print('fun')\nValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n>>> while x:\n...     print('fun')\nValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n \n Besides these 4 statements there are several python functions that hide some  bool  calls (like  any ,  all ,  filter , ...) these are normally not problematic with  pandas.Series  but for completeness I wanted to mention these. \n \n In your case, the exception isn't really helpful, because it doesn't mention the  right alternatives . For  and  and  or , if you want element-wise comparisons, you can use: \n \n numpy.logical_or : \n   >>> import numpy as np\n  >>> np.logical_or(x, y)\n \n or simply the  |  operator: \n   >>> x | y\n \n \n numpy.logical_and : \n   >>> np.logical_and(x, y)\n \n or simply the  &  operator: \n   >>> x & y\n \n \n \n If you're using the operators, then be sure to set your parentheses correctly because of  operator precedence . \n There are  several logical numpy functions  which  should  work on  pandas.Series . \n \n The alternatives mentioned in the Exception are more suited if you encountered it when doing  if  or  while . I'll shortly explain each of these: \n \n If you want to check if your Series is  empty : \n   >>> x = pd.Series([])\n  >>> x.empty\n  True\n  >>> x = pd.Series([1])\n  >>> x.empty\n  False\n \n Python normally interprets the  len gth of containers (like  list ,  tuple , ...) as truth-value if it has no explicit boolean interpretation. So if you want the python-like check, you could do:  if x.size  or  if not x.empty  instead of  if x . \n \n If your  Series  contains  one and only one  boolean value: \n   >>> x = pd.Series([100])\n  >>> (x > 50).bool()\n  True\n  >>> (x < 50).bool()\n  False\n \n \n If you want to check the  first and only item  of your Series (like  .bool()  but works even for not boolean contents): \n   >>> x = pd.Series([100])\n  >>> x.item()\n  100\n \n \n If you want to check if  all  or  any  item is not-zero, not-empty or not-False: \n   >>> x = pd.Series([0, 1, 2])\n  >>> x.all()   # because one element is zero\n  False\n  >>> x.any()   # because one (or more) elements are non-zero\n  True\n \n \n \n    ", "date_posted": "2022-05-31 16:32:35Z", "upvote": "\r\n            981\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": []}, {"stack_answer_id": "57897625", "answer_content": "\r\n Well pandas use bitwise  &   |  and each condition should be wrapped in a  () \n For example following works \n data_query = data[(data['year'] >= 2005) & (data['year'] <= 2010)]\n \n But the same query without proper brackets does not \n data_query = data[(data['year'] >= 2005 & data['year'] <= 2010)]\n \n    ", "date_posted": "2020-10-14 15:37:22Z", "upvote": "\r\n            105\r\n        ", "accepted": "No", "user": {"stack_user_id": "7403431", "name": "Stefan", "reputation_score": "1,427"}, "answer_comments": [{"stack_answer_id": "57897625", "stack_answer_comment_id": "122452906", "comment_content": "Wonderful, the only answer mentioning the importance of wrapping conditions in parenthesis. The only problem with my syntax. But why is this mandatory?", "user_id": "None"}, {"stack_answer_id": "57897625", "stack_answer_comment_id": "123087979", "comment_content": "Yes, wrapping with parens was the key!", "user_id": "None"}]}, {"stack_answer_id": "36922486", "answer_content": "\r\n For boolean logic, use  &  and  | . \n np.random.seed(0)\ndf = pd.DataFrame(np.random.randn(5,3), columns=list('ABC'))\n\n>>> df\n          A         B         C\n0  1.764052  0.400157  0.978738\n1  2.240893  1.867558 -0.977278\n2  0.950088 -0.151357 -0.103219\n3  0.410599  0.144044  1.454274\n4  0.761038  0.121675  0.443863\n\n>>> df.loc[(df.C > 0.25) | (df.C < -0.25)]\n          A         B         C\n0  1.764052  0.400157  0.978738\n1  2.240893  1.867558 -0.977278\n3  0.410599  0.144044  1.454274\n4  0.761038  0.121675  0.443863\n \n To see what is happening, you get a column of booleans for each comparison, e.g. \n df.C > 0.25\n0     True\n1    False\n2    False\n3     True\n4     True\nName: C, dtype: bool\n \n When you have multiple criteria, you will get multiple columns returned.  This is why the join logic is ambiguous.  Using  and  or  or  treats each column separately, so you first need to reduce that column to a single boolean value.  For example, to see if any value or all values in each of the columns is True. \n # Any value in either column is True?\n(df.C > 0.25).any() or (df.C < -0.25).any()\nTrue\n\n# All values in either column is True?\n(df.C > 0.25).all() or (df.C < -0.25).all()\nFalse\n \n One convoluted way to achieve the same thing is to zip all of these columns together, and perform the appropriate logic. \n >>> df[[any([a, b]) for a, b in zip(df.C > 0.25, df.C < -0.25)]]\n          A         B         C\n0  1.764052  0.400157  0.978738\n1  2.240893  1.867558 -0.977278\n3  0.410599  0.144044  1.454274\n4  0.761038  0.121675  0.443863\n \n For more details, refer to  Boolean Indexing  in the docs. \n    ", "date_posted": "2020-08-27 20:44:10Z", "upvote": "\r\n            61\r\n        ", "accepted": "No", "user": {"stack_user_id": "2430549", "name": "HoldOffHunger", "reputation_score": "16.2k"}, "answer_comments": []}, {"stack_answer_id": "41736427", "answer_content": "\r\n Or, alternatively, you could use Operator module. More detailed information is here  Python docs \n\n import operator\nimport numpy as np\nimport pandas as pd\nnp.random.seed(0)\ndf = pd.DataFrame(np.random.randn(5,3), columns=list('ABC'))\ndf.loc[operator.or_(df.C > 0.25, df.C < -0.25)]\n\n          A         B         C\n0  1.764052  0.400157  0.978738\n1  2.240893  1.867558 -0.977278\n3  0.410599  0.144044  1.454274\n4  0.761038  0.121675  0.4438\n \n    ", "date_posted": "2017-01-19 07:48:25Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "2464237", "name": "C\u1ea3nh To\u00e0n Nguy\u1ec5n", "reputation_score": "440"}, "answer_comments": []}, {"stack_answer_id": "47073907", "answer_content": "\r\n This excellent answer  explains very well what is happening and provides a solution. I would like to add another solution that might be suitable in similar cases: using the  query  method: \n df = df.query(\"(col > 0.25) or (col < -0.25)\")\n \n See also  http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-query . \n (Some tests with a dataframe I'm currently working with suggest that this method is a bit slower than using the bitwise operators on series of booleans: 2 ms vs. 870 \u00b5s) \n A piece of warning : At least one situation where this is not straightforward is when column names happen to be python expressions. I had columns named  WT_38hph_IP_2 ,  WT_38hph_input_2  and  log2(WT_38hph_IP_2/WT_38hph_input_2)  and wanted to perform the following query:  \"(log2(WT_38hph_IP_2/WT_38hph_input_2) > 1) and (WT_38hph_IP_2 > 20)\" \n I obtained the following exception cascade: \n \n KeyError: 'log2' \n UndefinedVariableError: name 'log2' is not defined \n ValueError: \"log2\" is not a supported function \n \n I guess this happened because the query parser was trying to make something from the first two columns instead of identifying the expression with the name of the third column. \n A possible workaround is proposed  here . \n    ", "date_posted": "2022-03-30 05:01:29Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": []}, {"stack_answer_id": "71956180", "answer_content": "\r\n This is quite a common question for beginners when making multiple conditions in Pandas. Generally speaking, there are two possible conditions causing this error: \n Condition 1: Python Operator Precedence \n There is a paragraph of  Boolean indexing | Indexing and selecting data \u2014 pandas documentation  explains this \n \n Another common operation is the use of boolean vectors to filter the data. The operators are:  |  for  or ,  &  for  and , and  ~  for  not . These  must  be grouped by using  parentheses . \n By default Python will evaluate an expression such as  df['A'] > 2 & df['B'] < 3  as  df['A'] > (2 & df['B']) < 3 , while the desired evaluation order is  (df['A'] > 2) & (df['B'] < 3) . \n \n # Wrong\ndf['col'] < -0.25 | df['col'] > 0.25\n\n# Right\n(df['col'] < -0.25) | (df['col'] > 0.25)\n \n There are some possible ways to get rid off the parentheses, I will cover this later. \n \n Condition 2: Improper Operator/Statement \n As is explained in previous quotation, you need use  |  for  or ,  &  for  and , and  ~  for  not \n # Wrong\n(df['col'] < -0.25) or (df['col'] > 0.25)\n\n# Right\n(df['col'] < -0.25) | (df['col'] > 0.25)\n \n \n Another possible situation is that you are using a boolean Series in  if  statement. \n # Wrong\nif pd.Series([True, False]):\n    pass\n \n It's clear that Python  if  statement accepts boolean like expression rather than Pandas Series. You should use  pandas.Series.any  or methods listed in the error message to convert the Series to a value according to your need. \n For example: \n # Right\nif df['col'].eq(0).all():\n    # If you want all column values equal to zero\n    print('do something')\n\n# Right\nif df['col'].eq(0).any():\n    # If you want at least one column value equal to zero\n    print('do something')\n \n \n Let's talk about ways to escape the parentheses in the first situation. \n \n Use Pandas mathematical functions \n \n Pandas has defined a lot of mathematical functions including comparison as follows: \n \n pandas.Series.lt()  for  less than ; \n pandas.Series.gt()  for  greater than ; \n pandas.Series.le()  for  less and equal ; \n pandas.Series.ge()  for  greater and equal ; \n pandas.Series.ne()  for  not equal ; \n pandas.Series.eq()  for  equal ; \n \n As a result, you can use \n df = df[(df['col'] < -0.25) | (df['col'] > 0.25)]\n\n# is equal to\n\ndf = df[df['col'].lt(-0.25) | df['col'].gt(0.25)]\n \n \n Use  pandas.Series.between() \n \n If you want to select rows in between two values, you can use  pandas.Series.between \n \n df['col].between(left, right)  is equal to  \n (left <= df['col']) & (df['col'] <= right) ; \n df['col].between(left, right, inclusive='left)  is equal to  \n (left <= df['col']) & (df['col'] < right) ; \n df['col].between(left, right, inclusive='right')  is equal to  \n (left < df['col']) & (df['col'] <= right) ; \n df['col].between(left, right, inclusive='neither')  is equal to  \n (left < df['col']) & (df['col'] < right) ; \n \n df = df[(df['col'] > -0.25) & (df['col'] < 0.25)]\n\n# is equal to\n\ndf = df[df['col'].between(-0.25, 0.25, inclusive='neither')]\n \n \n Use  pandas.DataFrame.query() \n \n Document referenced before has a chapter  The  query()  Method  explains this well. \n pandas.DataFrame.query()  can help you select a DataFrame with a condition string. Within the query string, you can use both bitwise operators( &  and  | ) and their boolean cousins( and  and  or ). Moreover, you can omit the parentheses, but I don't recommend for readable reason. \n df = df[(df['col'] < -0.25) | (df['col'] > 0.25)]\n\n# is equal to\n\ndf = df.query('col < -0.25 or col > 0.25')\n \n \n Use  pandas.DataFrame.eval() \n \n pandas.DataFrame.eval()  evaluates a string describing operations on DataFrame columns. Thus, we can use this method to build our multiple condition. The syntax is same with  pandas.DataFrame.query() . \n df = df[(df['col'] < -0.25) | (df['col'] > 0.25)]\n\n# is equal to\n\ndf = df[df.eval('col < -0.25 or col > 0.25')]\n \n pandas.DataFrame.query()  and  pandas.DataFrame.eval()  can do more things than I describe here, you are recommended to read their documentation and have fun with them. \n    ", "date_posted": "2022-05-14 05:47:41Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "10315163", "name": "Ynjxsjmh", "reputation_score": "22.9k"}, "answer_comments": []}, {"stack_answer_id": "69256931", "answer_content": "\r\n If you have more than one value: \n df['col'].all()\n \n If its only a single value: \n df['col'].item()\n \n    ", "date_posted": "2022-03-30 05:01:04Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": []}, {"stack_answer_id": "68258741", "answer_content": "\r\n I was getting error in this command: \n if df != '':\n    pass\n \n But it worked when I changed it to this: \n if df is not '':\n    pass\n \n    ", "date_posted": "2022-04-17 02:42:29Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "6153082", "name": "Mehdi Rostami", "reputation_score": "119"}, "answer_comments": []}, {"stack_answer_id": "62929797", "answer_content": "\r\n You need to use bitwise operators  |  instead of  or  and  &  instead of  and  in pandas, you can't simply use the bool statements from python. \n \nFor much complex filtering create a  mask  and apply the mask on the dataframe. \nPut all your query in the mask and apply it. \nSuppose, \n mask = (df[\"col1\"]>=df[\"col2\"]) & (stock[\"col1\"]<=df[\"col2\"])\ndf_new = df[mask]\n \n    ", "date_posted": "2020-07-16 07:39:08Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "11534375", "name": "Hemanth Kollipara", "reputation_score": "692"}, "answer_comments": []}, {"stack_answer_id": "64504183", "answer_content": "\r\n I'll try to give the benchmark of the three most common way (also mentioned above): \n from timeit import repeat\n\nsetup = \"\"\"\nimport numpy as np;\nimport random;\nx = np.linspace(0,100);\nlb, ub = np.sort([random.random() * 100, random.random() * 100]).tolist()\n\"\"\"\nstmts = 'x[(x > lb) * (x <= ub)]', 'x[(x > lb) & (x <= ub)]', 'x[np.logical_and(x > lb, x <= ub)]'\n\nfor _ in range(3):\n    for stmt in stmts:\n        t = min(repeat(stmt, setup, number=100_000))\n        print('%.4f' % t, stmt)\n    print()\n \n result: \n 0.4808 x[(x > lb) * (x <= ub)]\n0.4726 x[(x > lb) & (x <= ub)]\n0.4904 x[np.logical_and(x > lb, x <= ub)]\n\n0.4725 x[(x > lb) * (x <= ub)]\n0.4806 x[(x > lb) & (x <= ub)]\n0.5002 x[np.logical_and(x > lb, x <= ub)]\n\n0.4781 x[(x > lb) * (x <= ub)]\n0.4336 x[(x > lb) & (x <= ub)]\n0.4974 x[np.logical_and(x > lb, x <= ub)]\n \n But,  *  is not supported in Panda Series, and NumPy Array is faster than pandas data frame (arround 1000 times slower, see number): \n from timeit import repeat\n\nsetup = \"\"\"\nimport numpy as np;\nimport random;\nimport pandas as pd;\nx = pd.DataFrame(np.linspace(0,100));\nlb, ub = np.sort([random.random() * 100, random.random() * 100]).tolist()\n\"\"\"\nstmts = 'x[(x > lb) & (x <= ub)]', 'x[np.logical_and(x > lb, x <= ub)]'\n\nfor _ in range(3):\n    for stmt in stmts:\n        t = min(repeat(stmt, setup, number=100))\n        print('%.4f' % t, stmt)\n    print()\n \n result: \n 0.1964 x[(x > lb) & (x <= ub)]\n0.1992 x[np.logical_and(x > lb, x <= ub)]\n\n0.2018 x[(x > lb) & (x <= ub)]\n0.1838 x[np.logical_and(x > lb, x <= ub)]\n\n0.1871 x[(x > lb) & (x <= ub)]\n0.1883 x[np.logical_and(x > lb, x <= ub)]\n \n Note: adding one line of code  x = x.to_numpy()  will need about 20 \u00b5s. \n For those who prefer  %timeit : \n import numpy as np\nimport random\nlb, ub = np.sort([random.random() * 100, random.random() * 100]).tolist()\nlb, ub\nx = pd.DataFrame(np.linspace(0,100))\n\ndef asterik(x):\n    x = x.to_numpy()\n    return x[(x > lb) * (x <= ub)]\n\ndef and_symbol(x):\n    x = x.to_numpy()\n    return x[(x > lb) & (x <= ub)]\n\ndef numpy_logical(x):\n    x = x.to_numpy()\n    return x[np.logical_and(x > lb, x <= ub)]\n\nfor i in range(3):\n    %timeit asterik(x)\n    %timeit and_symbol(x)\n    %timeit numpy_logical(x)\n    print('\\n')\n \n result: \n 23 \u00b5s \u00b1 3.62 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\n35.6 \u00b5s \u00b1 9.53 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n31.3 \u00b5s \u00b1 8.9 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n\n\n21.4 \u00b5s \u00b1 3.35 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\n21.9 \u00b5s \u00b1 1.02 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n21.7 \u00b5s \u00b1 500 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n\n\n25.1 \u00b5s \u00b1 3.71 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n36.8 \u00b5s \u00b1 18.3 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n28.2 \u00b5s \u00b1 5.97 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\n \n    ", "date_posted": "2020-10-23 16:49:37Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "11671779", "name": "Muhammad Yasirroni", "reputation_score": "779"}, "answer_comments": []}, {"stack_answer_id": "61719230", "answer_content": "\r\n I encountered the same error and got stalled with a pyspark dataframe for few days,  I was able to resolve it successfully by filling na values with 0  since I was comparing integer values from 2 fields. \n    ", "date_posted": "2020-05-10 21:54:06Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "7901426", "name": "iretex", "reputation_score": "43"}, "answer_comments": []}, {"stack_answer_id": "64277449", "answer_content": "\r\n One minor thing, which wasted my time. \n Put the conditions(if comparing using \" = \", \" != \") in parenthesis, failing to do so also raises this exception.\nThis will work \n df[(some condition) conditional operator (some conditions)]\n \n This will not \n df[some condition conditional-operator some condition]\n \n    ", "date_posted": "2020-10-09 09:37:01Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "8486505", "name": "satinder singh", "reputation_score": "160"}, "answer_comments": []}], "user": {"stack_user_id": "6267003", "name": "obabs", "reputation_score": "7,611"}, "question_comments": [{"stack_question_id": "36921951", "stack_question_comment_id": "61405699", "comment_content": "use ", "user_id": "None"}, {"stack_question_id": "36921951", "stack_question_comment_id": "94761896", "comment_content": "Here's a workaround: ", "user_id": "None"}, {"stack_question_id": "36921951", "stack_question_comment_id": "96891030", "comment_content": "Related: ", "user_id": "None"}, {"stack_question_id": "36921951", "stack_question_comment_id": "116738206", "comment_content": "I ran into the same error message using the standard ", "user_id": "None"}]},
{"stack_question_id": "1436703", "question_title": "What is the difference between __str__ and __repr__?", "question_content": "\r\n                What is the difference between __str__ and __repr__ in Python?\r\n", "question_url": "/questions/1436703/what-is-the-difference-between-str-and-repr", "date_posted": "Sep 17, 2009 at 4:27", "upvote": "3", "view": "8", "tags": ["python", "magic-methods", "repr"], "answers_count": "2", "answers": [{"stack_answer_id": "2626364", "answer_content": "\r\n Alex  summarized well but, surprisingly, was too succinct. \n First, let me reiterate the main points in  Alex\u2019s post : \n \n The default implementation is useless (it\u2019s hard to think of one which wouldn\u2019t be, but yeah) \n __repr__  goal is to be unambiguous \n __str__  goal is to be readable \n Container\u2019s  __str__  uses contained objects\u2019  __repr__ \n \n Default implementation is useless \n This is mostly a surprise because Python\u2019s defaults tend to be fairly useful. However, in this case, having a default for  __repr__  which would act like: \n return \"%s(%r)\" % (self.__class__, self.__dict__)\n \n would have been too dangerous (for example, too easy to get into infinite recursion if objects reference each other). So Python cops out. Note that there is one default which is true: if  __repr__  is defined, and  __str__  is not, the object will behave as though  __str__=__repr__ . \n This means, in simple terms: almost every object you implement should have a functional  __repr__  that\u2019s usable for understanding the object. Implementing  __str__  is optional: do that if you need a \u201cpretty print\u201d functionality (for example, used by a report generator). \n The goal of  __repr__  is to be unambiguous \n Let me come right out and say it \u2014 I do not believe in debuggers. I don\u2019t really know how to use any debugger, and have never used one seriously. Furthermore, I believe that the big fault in debuggers is their basic nature \u2014 most failures I debug happened a long long time ago, in a galaxy far far away. This means that I do believe, with religious fervor, in logging. Logging is the lifeblood of any decent fire-and-forget server system. Python makes it easy to log: with maybe some project specific wrappers, all you need is a \n log(INFO, \"I am in the weird function and a is\", a, \"and b is\", b, \"but I got a null C \u2014 using default\", default_c)\n \n But you have to do the last step \u2014 make sure every object you implement has a useful repr, so code like that can just work. This is why the \u201ceval\u201d thing comes up: if you have enough information so  eval(repr(c))==c , that means you know everything there is to know about  c . If that\u2019s easy enough, at least in a fuzzy way, do it. If not, make sure you have enough information about  c  anyway. I usually use an eval-like format:  \"MyClass(this=%r,that=%r)\" % (self.this,self.that) . It does not mean that you can actually construct MyClass, or that those are the right constructor arguments \u2014 but it is a useful form to express \u201cthis is everything you need to know about this instance\u201d. \n Note: I used  %r  above, not  %s . You always want to use  repr()  [or  %r  formatting character, equivalently] inside  __repr__  implementation, or you\u2019re defeating the goal of repr. You want to be able to differentiate  MyClass(3)  and  MyClass(\"3\") . \n The goal of  __str__  is to be readable \n Specifically, it is not intended to be unambiguous \u2014 notice that  str(3)==str(\"3\") . Likewise, if you implement an IP abstraction, having the str of it look like 192.168.1.1 is just fine. When implementing a date/time abstraction, the str can be \"2010/4/12 15:35:22\", etc. The goal is to represent it in a way that a user, not a programmer, would want to read it. Chop off useless digits, pretend to be some other class \u2014 as long is it supports readability, it is an improvement. \n Container\u2019s  __str__  uses contained objects\u2019  __repr__ \n This seems surprising, doesn\u2019t it? It is a little, but how readable would it be if it used their  __str__ ? \n [moshe is, 3, hello\nworld, this is a list, oh I don't know, containing just 4 elements]\n \n Not very. Specifically, the strings in a container would find it way too easy to disturb its string representation. In the face of ambiguity, remember, Python resists the temptation to guess. If you want the above behavior when you\u2019re printing a list, just \n print(\"[\" + \", \".join(l) + \"]\")\n \n (you can probably also figure out what to do about dictionaries. \n Summary \n Implement  __repr__  for any class you implement. This should be second nature. Implement  __str__  if you think it would be useful to have a string version which errs on the side of readability. \n    ", "date_posted": "2021-12-23 06:11:33Z", "upvote": "\r\n            3281\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "1192111", "name": "Francisco", "reputation_score": "10.3k"}, "answer_comments": [{"stack_answer_id": "2626364", "stack_answer_comment_id": "45597487", "comment_content": "Definitely disagree with your opinion that debugging isn't the way to go. For development use a debugger (and/or logging), for production use logging. With a debugger you have a view of everything that went wrong when the problem occurred. You can see the full picture. Unless you are logging EVERYTHING you can't get that. Plus if you are logging everything you're going have to wade through tons of data to get at what you want.", "user_id": "None"}, {"stack_answer_id": "2626364", "stack_answer_comment_id": "46649638", "comment_content": "Great answer (except the bit about not using debuggers). I'd just like to add a link to this ", "user_id": "None"}, {"stack_answer_id": "2626364", "stack_answer_comment_id": "100485156", "comment_content": "I heard that a variable ", "user_id": "None"}, {"stack_answer_id": "2626364", "stack_answer_comment_id": "101141471", "comment_content": "on debugger vs no debugger: don't get such entrenched opinions. In some applications debugging is not realistic, typically when real-time is involved, or when your code only executes remotely on a platform with little access or no console. In most other cases it will be much quicker to stop at an exception to investigate, or to set a breakpoint, because you don't have to go through thousands of lines of logging (which will clutter your disk and slow down the application). Finally, it's not always possible to log, for example on embedded devices, there debugger is your friend too.", "user_id": "None"}, {"stack_answer_id": "2626364", "stack_answer_comment_id": "105654853", "comment_content": "About debuggging vs logging, they are both useful. If a bug is reproducible, debugging is more simple. If the bug is randomic, logging is essential.", "user_id": "None"}]}, {"stack_answer_id": "1438297", "answer_content": "\r\n My rule of thumb:   __repr__  is for developers,  __str__  is for customers. \n    ", "date_posted": "2009-09-17 11:35:13Z", "upvote": "\r\n            730\r\n        ", "accepted": "No", "user": {"stack_user_id": "14343", "name": "Ned Batchelder", "reputation_score": "350k"}, "answer_comments": [{"stack_answer_id": "1438297", "stack_answer_comment_id": "98926405", "comment_content": "This is true because for obj = uuid.uuid1(), obj.__str__() is \"2d7fc7f0-7706-11e9-94ae-0242ac110002\" and obj.__repr__() is \"UUID('2d7fc7f0-7706-11e9-94ae-0242ac110002')\". Developers need (value + origin) whereas customers need a value and they don't care how they got it!", "user_id": "None"}, {"stack_answer_id": "1438297", "stack_answer_comment_id": "105488427", "comment_content": "Here ", "user_id": "None"}, {"stack_answer_id": "1438297", "stack_answer_comment_id": "124456934", "comment_content": "@NarenYellavula if you're exposing a UUID to a customer you're probably doing something wrong.", "user_id": "None"}, {"stack_answer_id": "1438297", "stack_answer_comment_id": "126975289", "comment_content": "@MarkRansom why is that?", "user_id": "None"}, {"stack_answer_id": "1438297", "stack_answer_comment_id": "126982587", "comment_content": "@AbdessabourMtk they're overly complex, and there's no protection against typing them wrong.  Maybe in certain contexts like as part of a QR code they would be OK.", "user_id": "None"}]}, {"stack_answer_id": "1436756", "answer_content": "\r\n Unless you specifically act to ensure otherwise, most classes don't have helpful results for either: \n >>> class Sic(object): pass\n... \n>>> print(str(Sic()))\n<__main__.Sic object at 0x8b7d0>\n>>> print(repr(Sic()))\n<__main__.Sic object at 0x8b7d0>\n>>> \n \n As you see -- no difference, and no info beyond the class and object's  id .  If you only override one of the two...: \n >>> class Sic(object): \n...   def __repr__(self): return 'foo'\n... \n>>> print(str(Sic()))\nfoo\n>>> print(repr(Sic()))\nfoo\n>>> class Sic(object):\n...   def __str__(self): return 'foo'\n... \n>>> print(str(Sic()))\nfoo\n>>> print(repr(Sic()))\n<__main__.Sic object at 0x2617f0>\n>>> \n \n as you see, if you override  __repr__ , that's ALSO used for  __str__ , but not vice versa. \n Other crucial tidbits to know:  __str__  on a built-on container uses the  __repr__ , NOT the  __str__ , for the items it contains. And, despite the words on the subject found in typical docs, hardly anybody bothers making the  __repr__  of objects be a string that  eval  may use to build an equal object (it's just too hard, AND not knowing how the relevant module was actually imported makes it actually flat out impossible). \n So, my advice: focus on making  __str__  reasonably human-readable, and  __repr__  as unambiguous as you possibly can, even if that interferes with the fuzzy unattainable goal of making  __repr__ 's returned value acceptable as input to  __eval__ ! \n    ", "date_posted": "2022-02-09 22:35:24Z", "upvote": "\r\n            484\r\n        ", "accepted": "No", "user": {"stack_user_id": "2311167", "name": "Adrian W", "reputation_score": "4,163"}, "answer_comments": [{"stack_answer_id": "1436756", "stack_answer_comment_id": "9992427", "comment_content": "In my unit tests I always check that ", "user_id": "None"}, {"stack_answer_id": "1436756", "stack_answer_comment_id": "40619938", "comment_content": "I always try to make sure that either ", "user_id": "None"}, {"stack_answer_id": "1436756", "stack_answer_comment_id": "83919034", "comment_content": "Why would not containers (lists, tuples) use  ", "user_id": "None"}, {"stack_answer_id": "1436756", "stack_answer_comment_id": "95167441", "comment_content": "Just ran into an annoying bug related to the fact that ", "user_id": "None"}, {"stack_answer_id": "1436756", "stack_answer_comment_id": "115164858", "comment_content": "@abarnert: for a custom ", "user_id": "None"}]}, {"stack_answer_id": "1436721", "answer_content": "\r\n __repr__ : representation of python object usually eval will convert it back to that object \n\n __str__ : is whatever you think is that object in text form \n\n e.g. \n\n >>> s=\"\"\"w'o\"w\"\"\"\n>>> repr(s)\n'\\'w\\\\\\'o\"w\\''\n>>> str(s)\n'w\\'o\"w'\n>>> eval(str(s))==s\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"<string>\", line 1\n    w'o\"w\n       ^\nSyntaxError: EOL while scanning single-quoted string\n>>> eval(repr(s))==s\nTrue\n \n    ", "date_posted": "2012-08-15 19:40:17Z", "upvote": "\r\n            203\r\n        ", "accepted": "No", "user": {"stack_user_id": "505154", "name": "Andrew Clark", "reputation_score": "194k"}, "answer_comments": [{"stack_answer_id": "1436721", "stack_answer_comment_id": "124693632", "comment_content": "__repr__() : used to create \"constructor-like expression\" in string, so that eval() can re-construct an object back from this string representation   __str__() : used to create string containing a printable representation of an object", "user_id": "None"}]}, {"stack_answer_id": "19597196", "answer_content": "\r\n \n   In short, the goal of  __repr__  is to be unambiguous and  __str__  is to be\n  readable. \n \n\n Here is a good example: \n\n >>> import datetime\n>>> today = datetime.datetime.now()\n>>> str(today)\n'2012-03-14 09:21:58.130922'\n>>> repr(today)\n'datetime.datetime(2012, 3, 14, 9, 21, 58, 130922)'\n \n\n Read this documentation for repr: \n\n \n   repr(object) \n  \n   Return a string containing a printable representation of an object. This is the same value yielded by conversions (reverse\n  quotes). It is sometimes useful to be able to access this operation as\n  an ordinary function. For many types, this function makes an attempt\n  to return a string that would yield an object with the same value when\n  passed to  eval() , otherwise the representation is a string enclosed in\n  angle brackets that contains the name of the type of the object\n  together with additional information often including the name and\n  address of the object. A class can control what this function returns\n  for its instances by defining a  __repr__()  method. \n \n\n Here is the documentation for str: \n\n \n   str(object='') \n  \n   Return a string containing a nicely printable\n  representation of an object. For strings, this returns the string\n  itself. The difference with  repr(object)  is that  str(object)  does not\n  always attempt to return a string that is acceptable to  eval() ; its\n  goal is to return a printable string. If no argument is given, returns\n  the empty string,  '' . \n \n    ", "date_posted": "2013-10-28 00:23:46Z", "upvote": "\r\n            196\r\n        ", "accepted": "No", "user": {"stack_user_id": "1442342", "name": "deadly", "reputation_score": "1,198"}, "answer_comments": [{"stack_answer_id": "19597196", "stack_answer_comment_id": "90779593", "comment_content": "What is the meaning of printable string here? Can you explain it please?", "user_id": "None"}, {"stack_answer_id": "19597196", "stack_answer_comment_id": "111199240", "comment_content": "building upon the above example  by \"bitoffdev\" and  @deadly we can see how ", "user_id": "None"}]}, {"stack_answer_id": "28132458", "answer_content": "\r\n \n What is the difference between  __str__  and  __repr__  in Python? \n \n __str__  (read as \"dunder (double-underscore) string\") and  __repr__  (read as \"dunder-repper\" (for \"representation\")) are both special methods that return strings based on the state of the object. \n __repr__  provides backup behavior if  __str__  is missing. \n So one should first write a  __repr__  that allows you to reinstantiate an equivalent object from the string it returns e.g. using  eval  or by typing it in character-for-character in a Python shell. \n At any time later, one can write a  __str__  for a user-readable string representation of the instance, when one believes it to be necessary. \n __str__ \n If you print an object, or pass it to  format ,  str.format , or  str , then if a  __str__  method is defined, that method will be called, otherwise,  __repr__  will be used. \n __repr__ \n The  __repr__  method is called by the builtin function  repr  and is what is echoed on your python shell when it evaluates an expression that returns an object. \n Since it provides a backup for  __str__ , if you can only write one, start with  __repr__ \n Here's the builtin help on  repr : \n repr(...)\n    repr(object) -> string\n    \n    Return the canonical string representation of the object.\n    For most object types, eval(repr(object)) == object.\n \n That is, for most objects, if you type in what is printed by  repr , you should be able to create an equivalent object.  But this is not the default implementation. \n Default Implementation of  __repr__ \n The default object  __repr__  is ( C Python source ) something like: \n def __repr__(self):\n    return '<{0}.{1} object at {2}>'.format(\n      type(self).__module__, type(self).__qualname__, hex(id(self)))\n \n That means by default you'll print the module the object is from, the class name, and the hexadecimal representation of its location in memory - for example: \n <__main__.Foo object at 0x7f80665abdd0>\n \n This information isn't very useful, but there's no way to derive how one might accurately create a canonical representation of any given instance, and it's better than nothing, at least telling us how we might uniquely identify it in memory. \n How can  __repr__  be useful? \n Let's look at how useful it can be, using the Python shell and  datetime  objects. First we need to import the  datetime  module: \n import datetime\n \n If we call  datetime.now  in the shell, we'll see everything we need to recreate an equivalent datetime object. This is created by the datetime  __repr__ : \n >>> datetime.datetime.now()\ndatetime.datetime(2015, 1, 24, 20, 5, 36, 491180)\n \n If we print a datetime object, we see a nice human readable (in fact, ISO) format. This is implemented by datetime's  __str__ : \n >>> print(datetime.datetime.now())\n2015-01-24 20:05:44.977951\n \n It is a simple matter to recreate the object we lost because we didn't assign it to a variable by copying and pasting from the  __repr__  output, and then printing it, and we get it in the same human readable output as the other object: \n >>> the_past = datetime.datetime(2015, 1, 24, 20, 5, 36, 491180)\n>>> print(the_past)\n2015-01-24 20:05:36.491180\n \n #How do I implement them? \n As you're developing, you'll want to be able to reproduce objects in the same state, if possible. This, for example, is how the datetime object defines  __repr__  ( Python source ). It is fairly complex, because of all of the attributes needed to reproduce such an object: \n def __repr__(self):\n    \"\"\"Convert to formal string, for repr().\"\"\"\n    L = [self._year, self._month, self._day,  # These are never zero\n         self._hour, self._minute, self._second, self._microsecond]\n    if L[-1] == 0:\n        del L[-1]\n    if L[-1] == 0:\n        del L[-1]\n    s = \"%s.%s(%s)\" % (self.__class__.__module__,\n                       self.__class__.__qualname__,\n                       \", \".join(map(str, L)))\n    if self._tzinfo is not None:\n        assert s[-1:] == \")\"\n        s = s[:-1] + \", tzinfo=%r\" % self._tzinfo + \")\"\n    if self._fold:\n        assert s[-1:] == \")\"\n        s = s[:-1] + \", fold=1)\"\n    return s\n \n If you want your object to have a more human readable representation, you can implement  __str__  next. Here's how the datetime object ( Python source ) implements  __str__ , which it easily does because it already has a function to display it in ISO format: \n def __str__(self):\n    \"Convert to string, for str().\"\n    return self.isoformat(sep=' ')\n \n Set  __repr__ = __str__ ? \n This is a critique of another answer here that suggests setting  __repr__ = __str__ . \n Setting  __repr__ = __str__  is silly -  __repr__  is a fallback for  __str__  and a  __repr__ , written for developers usage in debugging, should be written before you write a  __str__ . \n You need a  __str__  only when you need a textual representation of the object. \n Conclusion \n Define  __repr__  for objects you write so you and other developers have a reproducible example when using it as you develop. Define  __str__  when you need a human readable string representation of it. \n    ", "date_posted": "2022-03-31 17:05:03Z", "upvote": "\r\n            162\r\n        ", "accepted": "No", "user": {"stack_user_id": "2326961", "name": "Maggyero", "reputation_score": "4,880"}, "answer_comments": [{"stack_answer_id": "28132458", "stack_answer_comment_id": "93999470", "comment_content": "Shouldn't it be something along the lines of ", "user_id": "None"}, {"stack_answer_id": "28132458", "stack_answer_comment_id": "94014066", "comment_content": "@SolomonUcko yes in Python 3, that would seem to be the case - I've been hunting down the source code where this is implemented and I'll update my answer with that information when I get it together.", "user_id": "None"}, {"stack_answer_id": "28132458", "stack_answer_comment_id": "125520621", "comment_content": "This answer will be more helpful for beginners. Nice explanation!!", "user_id": "None"}, {"stack_answer_id": "28132458", "stack_answer_comment_id": "126709060", "comment_content": "I have changed ", "user_id": "None"}]}, {"stack_answer_id": "44099267", "answer_content": "\r\n On page 358 of the book  Python scripting for computational science  by Hans Petter Langtangen, it clearly states that  \n\n \n The  __repr__  aims at a complete string representation of the object; \n The  __str__  is to return a nice string for printing. \n \n\n So, I prefer to understand them as \n\n \n repr = reproduce \n str = string (representation) \n \n\n from the user's point of view\nalthough this is a misunderstanding I made when learning python. \n\n A small but good example is also given on the same page as follows: \n\n Example \n\n In [38]: str('s')\nOut[38]: 's'\n\nIn [39]: repr('s')\nOut[39]: \"'s'\"\n\nIn [40]: eval(str('s'))\nTraceback (most recent call last):\n\n  File \"<ipython-input-40-abd46c0c43e7>\", line 1, in <module>\n    eval(str('s'))\n\n  File \"<string>\", line 1, in <module>\n\nNameError: name 's' is not defined\n\n\nIn [41]: eval(repr('s'))\nOut[41]: 's'\n \n    ", "date_posted": "2019-06-19 07:47:15Z", "upvote": "\r\n            47\r\n        ", "accepted": "No", "user": {"stack_user_id": "10323798", "name": "NelsonGon", "reputation_score": "12.7k"}, "answer_comments": [{"stack_answer_id": "44099267", "stack_answer_comment_id": "94617094", "comment_content": "It is at pg. #351.", "user_id": "None"}, {"stack_answer_id": "44099267", "stack_answer_comment_id": "99893843", "comment_content": "It's kind of misleading to refer to ", "user_id": "None"}]}, {"stack_answer_id": "39382137", "answer_content": "\r\n Apart from all the answers given, I would like to add few points :- \n\n 1)  __repr__()  is invoked when you simply write object's name on interactive python console and press enter. \n\n 2)  __str__()  is invoked when you use object with print statement. \n\n 3) In case, if  __str__  is missing, then print and any function using  str()  invokes  __repr__()  of object. \n\n 4)  __str__()  of containers, when invoked will execute  __repr__()  method of its contained elements. \n\n 5)  str()  called within  __str__()  could potentially recurse without a base case, and error on maximum recursion depth. \n\n 6)  __repr__()  can call  repr()  which will attempt to avoid infinite recursion automatically, replacing an already represented object with  ... . \n    ", "date_posted": "2018-06-05 07:47:41Z", "upvote": "\r\n            46\r\n        ", "accepted": "No", "user": {"stack_user_id": "9542308", "name": "David Augusto Villa", "reputation_score": "63"}, "answer_comments": []}, {"stack_answer_id": "63464185", "answer_content": "\r\n (2020 entry) \n Q:  What's the difference between  __str__()  and  __repr__() ? \n TL;DR: \n \n LONG \n This question has been around a long time, and there are a variety of answers of which most are correct (not to mention from several Python community legends[!]). However when it comes down to the nitty-gritty, this question is analogous to asking the difference between the  str()  and  repr()  built-in functions. I'm going to describe the differences in my own words (which means I may be \"borrowing\" liberally from  Core Python Programming  so pls forgive me). \n Both   str()  and  repr()  have the same basic job: their goal is to return a string representation of a Python object. What  kind  of string representation is what differentiates them. \n \n str()  &  __str__()  return a  printable  string representation of\nan object... something human-readable/for human consumption \n repr()  &  __repr__()  return a string representation of an object that is a  valid Python expression , an object you can pass to  eval()  or type into the Python shell without getting an error. \n \n For example, let's assign a string to  x  and an  int  to  y , and simply showing human-readable string versions of each: \n >>> x, y = 'foo', 123\n>>> str(x), str(y)\n('foo', '123')\n \n Can we take  what is inside the quotes  in both cases and enter them verbatim into the Python interpreter? Let's give it a try: \n >>> 123\n123\n>>> foo\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'foo' is not defined\n \n Clearly you can for an  int  but not necessarily for a  str . Similarly, while I can pass  '123'  to  eval() , that doesn't work for  'foo' : \n >>> eval('123')\n123\n>>> eval('foo')\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"<string>\", line 1, in <module>\nNameError: name 'foo' is not defined\n \n So this tells you the Python shell just  eval() s what you give it. Got it? Now, let's  repr()  both expressions and see what we get. More specifically, take its output and dump  those  out in the interpreter (there's a point to this which we'll address afterwards): \n >>> repr(x), repr(y)\n(\"'foo'\", '123')\n>>> 123\n123\n>>> 'foo'\n'foo'\n \n Wow, they  both  work? That's because  'foo' , while a printable string representation of that string, it's  not  evaluatable, but  \"'foo'\"  is.  123  is a valid Python  int  called by either  str()  or  repr() . What happens when we call  eval()  with these? \n >>> eval('123')\n123\n>>> eval(\"'foo'\")\n'foo'\n \n It works because  123  and  'foo'  are valid Python objects. Another key takeaway is that while sometimes both return the same thing (the same string representation), that's not always the case. (And yes, yes, I can go create a variable  foo  where the  eval()  works, but that's not the point.) \n More factoids about both pairs \n \n Sometimes,  str()  and  repr()  are called  implicitly , meaning they're called on behalf of users: when users execute  print  (Py1/Py2) or call  print()  (Py3+), even if users don't call  str()  explicitly, such a call is made on their behalf before the object is displayed. \n In the Python shell (interactive interpreter), if you enter a variable at the  >>>  prompt and press RETURN, the interpreter displays the results of  repr()  implicitly called on that object. \n To connect  str()  and  repr()  to  __str__()  and  __repr__() , realize that calls to the built-in functions, i.e.,  str(x)  or  repr(y)  result in calling their object's corresponding special methods:  x.__str__()  or  y.__repr()__ \n By implementing  __str__()  and  __repr__()  for  your  Python classes, you overload the built-in functions ( str()  and  repr() ), allowing instances of your classes to be passed in to  str()  and  repr() . When such calls are made, they turn around and call the class'  __str__()  and  __repr__()  (per #3). \n \n    ", "date_posted": "2022-02-03 06:36:55Z", "upvote": "\r\n            36\r\n        ", "accepted": "No", "user": {"stack_user_id": "305689", "name": "wescpy", "reputation_score": "10.1k"}, "answer_comments": []}, {"stack_answer_id": "34734815", "answer_content": "\r\n To put it simply: \n\n __str__  is used in to show a string representation of your object  to be read easily  by others. \n\n __repr__  is used to show a string representation of  the  object. \n\n Let's say I want to create a  Fraction  class where the string representation of a fraction is '(1/2)' and the object (Fraction class) is to be represented as 'Fraction (1,2)' \n\n So we can create a simple Fraction class: \n\n class Fraction:\n    def __init__(self, num, den):\n        self.__num = num\n        self.__den = den\n\n    def __str__(self):\n        return '(' + str(self.__num) + '/' + str(self.__den) + ')'\n\n    def __repr__(self):\n        return 'Fraction (' + str(self.__num) + ',' + str(self.__den) + ')'\n\n\n\nf = Fraction(1,2)\nprint('I want to represent the Fraction STRING as ' + str(f)) # (1/2)\nprint('I want to represent the Fraction OBJECT as ', repr(f)) # Fraction (1,2)\n \n    ", "date_posted": "2016-07-28 04:08:32Z", "upvote": "\r\n            15\r\n        ", "accepted": "No", "user": {"stack_user_id": "222758", "name": "user222758", "reputation_score": "12.6k"}, "answer_comments": []}, {"stack_answer_id": "1436706", "answer_content": "\r\n From  an (An Unofficial) Python Reference Wiki (archive copy)  by effbot: \n\n __str__  \" computes the \"informal\" string representation of an object. This differs from  __repr__  in that it does not have to be a valid Python expression: a more convenient or concise representation may be used instead. \" \n    ", "date_posted": "2019-05-29 12:51:25Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "1436706", "stack_answer_comment_id": "80631615", "comment_content": " is by no means required to return a vaild Python expression.", "user_id": "None"}]}, {"stack_answer_id": "13395755", "answer_content": "\r\n In all honesty,  eval(repr(obj))  is never used. If you find yourself using it, you should stop, because  eval  is dangerous, and strings are a very inefficient way to serialize your objects (use  pickle  instead). \n Therefore, I would recommend setting  __repr__ = __str__ . The reason is that  str(list)  calls  repr  on the elements (I consider this to be one of the biggest design flaws of Python that was not addressed by Python 3). An actual  repr  will probably not be very helpful as the output of  print([your, objects]) . \n To qualify this, in my experience, the most useful use case of the  repr  function is to put a string inside another string (using string formatting). This way, you don't have to worry about escaping quotes or anything. But note that there is no  eval  happening here. \n    ", "date_posted": "2021-12-23 06:13:22Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "1192111", "name": "Francisco", "reputation_score": "10.3k"}, "answer_comments": [{"stack_answer_id": "13395755", "stack_answer_comment_id": "37141861", "comment_content": "I think this misses the point. The use of ", "user_id": "None"}, {"stack_answer_id": "13395755", "stack_answer_comment_id": "59127770", "comment_content": " is not inherently dangerous. Is not more dangerous than ", "user_id": "None"}]}, {"stack_answer_id": "40960730", "answer_content": "\r\n str  - Creates a new string object from the given object. \n\n repr  - Returns the canonical string representation of the object. \n\n The differences: \n\n str(): \n\n \n makes object readable \n generates output for end-user \n \n\n repr(): \n\n \n needs code that reproduces object \n generates output for developer \n \n    ", "date_posted": "2016-12-04 16:18:48Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "5401681", "name": "Taufiq Rahman", "reputation_score": "5,453"}, "answer_comments": []}, {"stack_answer_id": "44201752", "answer_content": "\r\n One aspect that is missing in other answers. It's true that in general the pattern is: \n\n \n Goal of  __str__ : human-readable \n Goal of  __repr__ : unambiguous, possibly machine-readable via  eval \n \n\n Unfortunately, this differentiation is flawed, because the Python REPL and also IPython use  __repr__  for printing objects in a REPL console (see related questions for  Python  and  IPython ). Thus, projects which are targeted for interactive console work (e.g., Numpy or Pandas) have started to ignore above rules and provide a human-readable  __repr__  implementation instead. \n    ", "date_posted": "2017-05-26 12:33:51Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "1804173", "name": "bluenote10", "reputation_score": "20.5k"}, "answer_comments": []}, {"stack_answer_id": "43207419", "answer_content": "\r\n From the book  Fluent Python : \n\n \n   A basic requirement for a Python object is to provide usable \n       string   representations of itself, one used for debugging and\n       logging, another for presentation to end users. That is why the \n       special methods  __repr__  and  __str__  exist in the data model. \n \n    ", "date_posted": "2019-05-29 12:57:22Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": []}, {"stack_answer_id": "68665826", "answer_content": "\r\n You can get some insight from this code: \n class Foo():\n    def __repr__(self):\n        return(\"repr\")\n    def __str__(self):\n        return(\"str\")\n\nfoo = Foo()\nfoo #repr\nprint(foo) #str\n \n    ", "date_posted": "2021-08-05 11:36:27Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "1291302", "name": "JonnyRobbie", "reputation_score": "487"}, "answer_comments": []}, {"stack_answer_id": "56481986", "answer_content": "\r\n __str__  can be invoked on an object by calling  str(obj)  and should return a human readable string.  \n\n __repr__  can be invoked on an object by calling  repr(obj)  and should return internal object (object fields/attributes) \n\n This example may help: \n\n class C1:pass\n\nclass C2:        \n    def __str__(self):\n        return str(f\"{self.__class__.__name__} class str \")\n\nclass C3:        \n    def __repr__(self):        \n         return str(f\"{self.__class__.__name__} class repr\")\n\nclass C4:        \n    def __str__(self):\n        return str(f\"{self.__class__.__name__} class str \")\n    def __repr__(self):        \n         return str(f\"{self.__class__.__name__} class repr\")\n\n\nci1 = C1()    \nci2 = C2()  \nci3 = C3()  \nci4 = C4()\n\nprint(ci1)       #<__main__.C1 object at 0x0000024C44A80C18>\nprint(str(ci1))  #<__main__.C1 object at 0x0000024C44A80C18>\nprint(repr(ci1)) #<__main__.C1 object at 0x0000024C44A80C18>\nprint(ci2)       #C2 class str\nprint(str(ci2))  #C2 class str\nprint(repr(ci2)) #<__main__.C2 object at 0x0000024C44AE12E8>\nprint(ci3)       #C3 class repr\nprint(str(ci3))  #C3 class repr\nprint(repr(ci3)) #C3 class repr\nprint(ci4)       #C4 class str \nprint(str(ci4))  #C4 class str \nprint(repr(ci4)) #C4 class repr\n \n    ", "date_posted": "2019-06-06 16:53:43Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "5884955", "name": "prosti", "reputation_score": "36.9k"}, "answer_comments": []}, {"stack_answer_id": "33421226", "answer_content": "\r\n Excellent answers already cover the difference between  __str__  and  __repr__ , which for me boils down to the former being readable even by an end user, and the latter being as useful as possible to developers. Given that, I find that the default implementation of  __repr__  often fails to achieve this goal because it  omits  information useful to developers. \n\n For this reason, if I have a simple enough  __str__ , I generally just try to get the best of both worlds with something like: \n\n def __repr__(self):\n    return '{0} ({1})'.format(object.__repr__(self), str(self))\n \n    ", "date_posted": "2018-04-25 19:35:20Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "answer_comments": []}, {"stack_answer_id": "31427937", "answer_content": "\r\n >>> print(decimal.Decimal(23) / decimal.Decimal(\"1.05\"))\n21.90476190476190476190476190\n>>> decimal.Decimal(23) / decimal.Decimal(\"1.05\")\nDecimal('21.90476190476190476190476190')\n \n\n When  print()  is called on the result of  decimal.Decimal(23) / decimal.Decimal(\"1.05\")  the raw number is printed; this output is in  string form  which can be achieved with  __str__() . If we simply enter the expression we get a  decimal.Decimal  output \u2014 this output is in  representational form  which can be achieved with  __repr__() . All Python objects have two output forms. String form is designed to be human-readable. The representational form is designed to produce output that if fed to a Python interpreter would (when possible) reproduce the represented object. \n    ", "date_posted": "2019-05-29 12:58:50Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": []}, {"stack_answer_id": "33727876", "answer_content": "\r\n \n   One important thing to keep in mind is that container's  __str__  uses contained objects'  __repr__ . \n \n\n >>> from datetime import datetime\n>>> from decimal import Decimal\n>>> print (Decimal('52'), datetime.now())\n(Decimal('52'), datetime.datetime(2015, 11, 16, 10, 51, 26, 185000))\n>>> str((Decimal('52'), datetime.now()))\n\"(Decimal('52'), datetime.datetime(2015, 11, 16, 10, 52, 22, 176000))\"\n \n\n Python favors unambiguity over readability , the  __str__  call of a  tuple  calls the contained objects'  __repr__ , the  \"formal\"  representation of an object. Although the formal representation is harder to read than an informal one, it is unambiguous and more robust against bugs. \n    ", "date_posted": "2015-11-16 03:02:21Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "3011380", "name": "zangw", "reputation_score": "38.2k"}, "answer_comments": [{"stack_answer_id": "33727876", "stack_answer_comment_id": "94618177", "comment_content": "It uses ", "user_id": "None"}]}, {"stack_answer_id": "49447574", "answer_content": "\r\n In a nutshell: \n\n class Demo:\n  def __repr__(self):\n    return 'repr'\n  def __str__(self):\n    return 'str'\n\ndemo = Demo()\nprint(demo) # use __str__, output 'str' to stdout\n\ns = str(demo) # __str__ is used, return 'str'\nr = repr(demo) # __repr__ is used, return 'repr'\n\nimport logging\nlogger = logging.getLogger(logging.INFO)\nlogger.info(demo) # use __str__, output 'str' to stdout\n\nfrom pprint import pprint, pformat\npprint(demo) # use __repr__, output 'repr' to stdout\nresult = pformat(demo) # use __repr__, result is string which value is 'str'\n \n    ", "date_posted": "2018-04-16 09:28:38Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "50065", "name": "BioGeek", "reputation_score": "21.1k"}, "answer_comments": []}, {"stack_answer_id": "47690304", "answer_content": "\r\n Understand  __str__  and  __repr__  intuitively and permanently distinguish them at all. \n\n __str__  return the string disguised body of a given object for readable of eyes \n __repr__  return the real flesh body of a given object (return itself) for unambiguity to identify. \n\n See it in an example \n\n In [30]: str(datetime.datetime.now())\nOut[30]: '2017-12-07 15:41:14.002752'\nDisguised in string form\n \n\n As to  __repr__ \n\n In [32]: datetime.datetime.now()\nOut[32]: datetime.datetime(2017, 12, 7, 15, 43, 27, 297769)\nPresence in real body which allows to be manipulated directly.\n \n\n We can do arithmetic operation on  __repr__  results conveniently. \n\n In [33]: datetime.datetime.now()\nOut[33]: datetime.datetime(2017, 12, 7, 15, 47, 9, 741521)\nIn [34]: datetime.datetime(2017, 12, 7, 15, 47, 9, 741521) - datetime.datetime(2\n    ...: 017, 12, 7, 15, 43, 27, 297769)\nOut[34]: datetime.timedelta(0, 222, 443752)\n \n\n if apply the operation on  __str__ \n\n In [35]: '2017-12-07 15:43:14.002752' - '2017-12-07 15:41:14.002752'\nTypeError: unsupported operand type(s) for -: 'str' and 'str'\n \n\n Returns nothing but error. \n\n Another example. \n\n In [36]: str('string_body')\nOut[36]: 'string_body' # in string form\n\nIn [37]: repr('real_body')\nOut[37]: \"'real_body'\" #its real body hide inside\n \n\n Hope this help you build concrete grounds to explore more answers. \n    ", "date_posted": "2018-01-02 10:36:32Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "7301792", "name": "AbstProcDo", "reputation_score": "18.1k"}, "answer_comments": []}, {"stack_answer_id": "55744921", "answer_content": "\r\n \n __str__  must return string object whereas  __repr__  can return any python expression. \n If  __str__  implementation is missing then  __repr__  function is used as fallback. There is no fallback if  __repr__  function implementation is missing. \n If  __repr__  function is returning String representation of the object, we can skip implementation of  __str__  function. \n \n\n Source:  https://www.journaldev.com/22460/python-str-repr-functions \n    ", "date_posted": "2019-04-18 11:20:28Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "811625", "name": "Sampath", "reputation_score": "1,059"}, "answer_comments": []}, {"stack_answer_id": "50229578", "answer_content": "\r\n __repr__  is used everywhere, except by  print  and  str  methods (when a  __str__ is defined !) \n    ", "date_posted": "2019-04-14 07:50:40Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "7127824", "name": "techkuz", "reputation_score": "3,158"}, "answer_comments": []}, {"stack_answer_id": "65164408", "answer_content": "\r\n Every object inherits  __repr__   from the base class that all objects created. \n class Person:\n     pass\n\np=Person()\n \n if you call  repr(p)  you will get this as default: \n  <__main__.Person object at 0x7fb2604f03a0>\n \n But if you call  str(p)  you will get the same output. it is because when  __str__  does not exist, Python calls  __repr__ \n Let's implement our own  __str__ \n class Person:\n    def __init__(self,name,age):\n        self.name=name\n        self.age=age\n    def __repr__(self):\n        print(\"__repr__ called\")\n        return f\"Person(name='{self.name}',age={self.age})\"\n\np=Person(\"ali\",20)\n \n print(p)  and  str(p) will return \n  __repr__ called\n     Person(name='ali',age=20)\n \n let's add  __str__() \n class Person:\n    def __init__(self, name, age):\n        self.name = name\n        self.age = age\n        \n    def __repr__(self):\n        print('__repr__ called')\n        return f\"Person(name='{self.name}, age=self.age')\"\n    \n    def __str__(self):\n        print('__str__ called')\n        return self.name\n\np=Person(\"ali\",20)\n \n if we call  print(p)  and str(p), it will call  __str__()  so it will return \n __str__ called\nali\n \n repr(p)  will return \n repr  called\n\"Person(name='ali, age=self.age')\" \n Let's omit  __repr__  and just implement  __str__ . \n class Person:\ndef __init__(self, name, age):\n    self.name = name\n    self.age = age\n\ndef __str__(self):\n    print('__str__ called')\n    return self.name\n\np=Person('ali',20)\n \n print(p)  will look for the  __str__  and will return: \n __str__ called\nali\n \n NOTE= if we had  __repr__  and  __str__  defined,  f'name is {p}'  would call  __str__ \n    ", "date_posted": "2020-12-06 03:31:59Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "10262805", "name": "Yilmaz", "reputation_score": "16.9k"}, "answer_comments": []}, {"stack_answer_id": "72027825", "answer_content": "\r\n \n Programmers with prior experience in languages with a  toString  method tend to implement  __str__  and not  __repr__ .\nIf you only implement one of these special methods in Python, choose  __repr__ . \n \n From  Fluent Python  book, by Ramalho, Luciano. \n    ", "date_posted": "2022-04-27 11:19:34Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "30038", "name": "Vlad Bezden", "reputation_score": "74.9k"}, "answer_comments": []}, {"stack_answer_id": "72238659", "answer_content": "\r\n Basically  __str__  or  str()  is used for creating output that is human-readable are must be for end-users.\nOn the other hand,  repr()  or  __repr__  mainly returns canonical string representation of objects which serve the purpose of debugging and development helps the programmers. \n    ", "date_posted": "2022-05-14 08:47:49Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "13829776", "name": "barii", "reputation_score": "275"}, "answer_comments": []}], "user": {"stack_user_id": "165495", "name": "Casebash", "reputation_score": "109k"}, "question_comments": []},
{"stack_question_id": "370357", "question_title": "UnboundLocalError on local variable when reassigned after first use", "question_content": "\r\n                The following code works as expected in both Python 2.5 and 3.0:\n\na, b, c = (1, 2, 3)\n\nprint(a, b, c)\n\ndef test():\n    print(a)\n    print(b)\n    print(c)    # (A)\n    #c+=1       # (B)\ntest()\r\nHowever,...\r\n", "question_url": "/questions/370357/unboundlocalerror-on-local-variable-when-reassigned-after-first-use", "date_posted": "Dec 16, 2008 at 3:06", "upvote": "2", "view": "8", "tags": ["python", "variables", "scope"], "answers_count": "1", "answers": [{"stack_answer_id": "370363", "answer_content": "\r\n Python treats variables in functions differently depending on whether you assign values to them from inside or outside the function.  If a variable is assigned within a function, it is treated by default as a local variable.  Therefore, when you uncomment the line, you are trying to reference the local variable  c  before any value has been assigned to it. \n If you want the variable  c  to refer to the global  c = 3  assigned before the function, put \n global c\n \n as the first line of the function. \n As for python 3, there is now \n nonlocal c\n \n that you can use to refer to the nearest enclosing function scope that has a  c  variable. \n    ", "date_posted": "2022-01-03 18:12:36Z", "upvote": "\r\n            275\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "4518341", "name": "wjandrea", "reputation_score": "24.1k"}, "answer_comments": [{"stack_answer_id": "370363", "stack_answer_comment_id": "199343", "comment_content": "Thanks. Quick question. Does this imply that Python decides the scope of each variable before running a program? Before running a function?", "user_id": "46521"}, {"stack_answer_id": "370363", "stack_answer_comment_id": "199347", "comment_content": "The variable scope decision is made by the compiler, which normally runs once when you first start the program. However it is worth keeping in mind that the compiler might also run later if you have \"eval\" or \"exec\" statements in your program.", "user_id": "None"}, {"stack_answer_id": "370363", "stack_answer_comment_id": "199358", "comment_content": "Okay thank you. I guess \"interpreted language\" doesn't imply quite as much as I had thought.", "user_id": "46521"}, {"stack_answer_id": "370363", "stack_answer_comment_id": "1634018", "comment_content": "Ah that 'nonlocal' keyword was exactly what I was looking for, it seemed Python was missing this. Presumably this 'cascades' through each enclosing scope that imports the variable using this keyword?", "user_id": "None"}, {"stack_answer_id": "370363", "stack_answer_comment_id": "8941039", "comment_content": "@brainfsck: it is easiest to understand if you make the distinction between \"looking up\" and \"assigning\" a variable. Lookup falls back to a higher scope if the name is not found in the current scope. Assignment is always done in the local scope (unless you use ", "user_id": "None"}]}, {"stack_answer_id": "370380", "answer_content": "\r\n Python is a little weird in that it keeps everything in a dictionary for the various scopes.  The original a,b,c are in the uppermost scope and so in that uppermost dictionary.  The function has its own dictionary.  When you reach the  print(a)  and  print(b)  statements, there's nothing by that name in the dictionary, so Python looks up the list and finds them in the global dictionary. \n\n Now we get to  c+=1 , which is, of course, equivalent to  c=c+1 .  When Python scans that line, it says \"aha, there's a variable named c, I'll put it into my local scope dictionary.\"  Then when it goes looking for a value for c for the c on the right hand side of the assignment, it finds its  local variable named c , which has no value yet, and so throws the error. \n\n The statement  global c  mentioned above simply tells the parser that it uses the  c  from the global scope and so doesn't need a new one. \n\n The reason it says there's an issue on the line it does is because it is effectively looking for the names before it tries to generate code, and so in some sense doesn't think it's really doing that line yet.  I'd argue that is a usability bug, but it's generally a good practice to just learn not to take a compiler's messages  too  seriously. \n\n If it's any comfort, I spent probably a day digging and experimenting with this same issue before I found something Guido had written about the dictionaries that Explained Everything. \n\n Update, see comments: \n\n It doesn't scan the code twice, but it does scan the code in two phases, lexing and parsing. \n\n Consider how the parse of this line of code works.  The lexer reads the source text and breaks it into lexemes, the \"smallest components\" of the grammar.  So when it hits the line \n\n c+=1\n \n\n it breaks it up into something like \n\n SYMBOL(c) OPERATOR(+=) DIGIT(1)\n \n\n The parser eventually wants to make this into a parse tree and execute it, but since it's an assignment, before it does, it looks for the name c in the local dictionary, doesn't see it, and inserts it in the dictionary, marking it as uninitialized. In a fully compiled language, it would just go into the symbol table and wait for the parse, but since it WON'T have the luxury of a second pass, the lexer does a little extra work to make life easier later on.   Only, then it sees the OPERATOR, sees that the rules say \"if you have an operator += the left hand side must have been initialized\" and says \"whoops!\" \n\n The point here is that it  hasn't really started the parse of the line yet .  This is all happening sort of preparatory to the actual parse, so the line counter hasn't advanced to the next line.  Thus when it signals the error, it still thinks its on the previous line. \n\n As I say, you could argue it's a usability bug, but its actually a fairly common thing.  Some compilers are more honest about it and say \"error on or around line XXX\", but this one doesn't. \n    ", "date_posted": "2016-12-10 07:09:58Z", "upvote": "\r\n            87\r\n        ", "accepted": "No", "user": {"stack_user_id": "15168", "name": "Jonathan Leffler", "reputation_score": "704k"}, "answer_comments": [{"stack_answer_id": "370380", "stack_answer_comment_id": "199333", "comment_content": "Okay thank you for your response; it cleared some things up for me about scopes in python. However, I still don't understand why the error is raised at line (A) rather than line (B). Does Python create its variable scope dictionary BEFORE running the program?", "user_id": "46521"}, {"stack_answer_id": "370380", "stack_answer_comment_id": "199744", "comment_content": "No, it's on the expression level.  I'll add to the answer, I don't think I can fit this in a comment.", "user_id": "None"}, {"stack_answer_id": "370380", "stack_answer_comment_id": "60085042", "comment_content": "Note on implementation details: In CPython, the local scope isn't usually handled as a ", "user_id": "None"}]}, {"stack_answer_id": "370830", "answer_content": "\r\n Taking a look at the disassembly may clarify what is happening: \n\n >>> def f():\n...    print a\n...    print b\n...    a = 1\n\n>>> import dis\n>>> dis.dis(f)\n\n  2           0 LOAD_FAST                0 (a)\n              3 PRINT_ITEM\n              4 PRINT_NEWLINE\n\n  3           5 LOAD_GLOBAL              0 (b)\n              8 PRINT_ITEM\n              9 PRINT_NEWLINE\n\n  4          10 LOAD_CONST               1 (1)\n             13 STORE_FAST               0 (a)\n             16 LOAD_CONST               0 (None)\n             19 RETURN_VALUE\n \n\n As you can see, the bytecode for accessing a is  LOAD_FAST , and for b,  LOAD_GLOBAL .  This is because the compiler has identified that a is assigned to within the function, and classified it as a local variable.  The access mechanism for locals is fundamentally different for globals - they are statically assigned an offset in the frame's variables table, meaning lookup is a quick index, rather than the more expensive dict lookup as for globals.  Because of this, Python is reading the  print a  line as \"get the value of local variable 'a' held in slot 0, and print it\", and when it detects that this variable is still uninitialised, raises an exception. \n    ", "date_posted": "2008-12-16 09:49:28Z", "upvote": "\r\n            51\r\n        ", "accepted": "No", "user": {"stack_user_id": "9493", "name": "Brian", "reputation_score": "114k"}, "answer_comments": []}, {"stack_answer_id": "370364", "answer_content": "\r\n Python has rather interesting behavior when you try traditional global variable semantics.  I don't remember the details, but you can read the value of a variable declared in 'global' scope just fine, but if you want to modify it, you have to use the  global  keyword.  Try changing  test()  to this: \n\n def test():\n    global c\n    print(a)\n    print(b)\n    print(c)    # (A)\n    c+=1        # (B)\n \n\n Also, the reason you are getting this error is because you can also declare a new variable inside that function with the same name as a 'global' one, and it would be completely separate.  The interpreter thinks you are trying to make a new variable in this scope called  c  and modify it all in one operation, which isn't allowed in Python because this new  c  wasn't initialized. \n    ", "date_posted": "2016-12-10 06:53:57Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "15168", "name": "Jonathan Leffler", "reputation_score": "704k"}, "answer_comments": [{"stack_answer_id": "370364", "stack_answer_comment_id": "199334", "comment_content": "Thanks for your response, but I don't think it explains why the error is thrown at line (A), where I'm merely trying to print a variable. The program never gets to line (B) where it is trying to modify an un-initialized variable.", "user_id": "46521"}, {"stack_answer_id": "370364", "stack_answer_comment_id": "199708", "comment_content": "Python will read, parse and turn the whole function into internal bytecode before it starts running the program, so the fact that the \"turn c to local variable\" happens textually after the printing of the value doesn't, as it were, matter.", "user_id": "None"}, {"stack_answer_id": "370364", "stack_answer_comment_id": "129046450", "comment_content": "Python lets you access global variables in a local scope for reading, but not for writing.  This answer has a nice work-around with explanation in comment below... +=1.", "user_id": "None"}]}, {"stack_answer_id": "24035261", "answer_content": "\r\n The best example that makes it clear is: \n\n bar = 42\ndef foo():\n    print bar\n    if False:\n        bar = 0\n \n\n when calling  foo()  , this also  raises   UnboundLocalError  although we will never reach to line  bar=0 , so logically local variable should never be created. \n\n The mystery lies in \" Python is an Interpreted Language \" and the declaration of the function  foo  is interpreted as a single statement (i.e. a compound statement), it just interprets it dumbly and creates local and global scopes. So  bar  is recognized in local scope before execution. \n\n For  more examples  like this Read this post:  http://blog.amir.rachum.com/blog/2013/07/09/python-common-newbie-mistakes-part-2/ \n\n This post provides a Complete Description and Analyses of the Python Scoping of variables: \n    ", "date_posted": "2014-06-04 10:39:21Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "1731648", "name": "Sahil kalra", "reputation_score": "7,578"}, "answer_comments": []}, {"stack_answer_id": "1745180", "answer_content": "\r\n Here are two links that may help \n\n 1:  docs.python.org/3.1/faq/programming.html?highlight=nonlocal#why-am-i-getting-an-unboundlocalerror-when-the-variable-has-a-value \n\n 2:  docs.python.org/3.1/faq/programming.html?highlight=nonlocal#how-do-i-write-a-function-with-output-parameters-call-by-reference \n\n link one describes the error UnboundLocalError.  Link two can help with with re-writing your test function.  Based on link two, the original problem could be rewritten as: \n\n >>> a, b, c = (1, 2, 3)\n>>> print (a, b, c)\n(1, 2, 3)\n>>> def test (a, b, c):\n...     print (a)\n...     print (b)\n...     print (c)\n...     c += 1\n...     return a, b, c\n...\n>>> a, b, c = test (a, b, c)\n1\n2\n3\n>>> print (a, b ,c)\n(1, 2, 4)\n \n    ", "date_posted": "2011-09-13 04:00:56Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "68210", "name": "Daniel X Moore", "reputation_score": "14.2k"}, "answer_comments": []}, {"stack_answer_id": "476123", "answer_content": "\r\n This is not a direct answer to your question, but it is closely related, as it's another gotcha caused by the relationship between augmented assignment and function scopes. \n\n In most cases, you tend to think of augmented assignment ( a += b ) as exactly equivalent to simple assignment ( a = a + b ). It is possible to get into some trouble with this though, in one corner case. Let me explain: \n\n The way Python's simple assignment works means that if  a  is passed into a function (like  func(a) ; note that Python is always pass-by-reference), then  a = a + b  will not modify the  a  that is passed in. Instead, it will just modify the local pointer to  a .  \n\n But if you use  a += b , then it is sometimes implemented as: \n\n a = a + b\n \n\n or sometimes (if the method exists) as: \n\n a.__iadd__(b)\n \n\n In the first case (as long as  a  is not declared global), there are no side-effects outside local scope, as the assignment to  a  is just a pointer update. \n\n In the second case,  a  will actually modify itself, so all references to  a  will point to the modified version. This is demonstrated by the following code: \n\n def copy_on_write(a):\n      a = a + a\ndef inplace_add(a):\n      a += a\na = [1]\ncopy_on_write(a)\nprint a # [1]\ninplace_add(a)\nprint a # [1, 1]\nb = 1\ncopy_on_write(b)\nprint b # [1]\ninplace_add(b)\nprint b # 1\n \n\n So the trick is to avoid augmented assignment on function arguments (I try to only use it for local/loop variables). Use simple assignment, and you will be safe from ambiguous behaviour.  \n    ", "date_posted": "2016-12-10 07:07:03Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "15168", "name": "Jonathan Leffler", "reputation_score": "704k"}, "answer_comments": []}, {"stack_answer_id": "370752", "answer_content": "\r\n The Python interpreter will read a function as a complete unit. I think of it as reading it in two passes, once to gather its closure (the local variables), then again to turn it into byte-code. \n\n As I'm sure you were already aware, any name used on the left of a '=' is implicitly a local variable. More than once I've been caught out by changing a variable access to a += and it's suddenly a different variable. \n\n I also wanted to point out it's not really anything to do with global scope specifically. You get the same behaviour with nested functions. \n    ", "date_posted": "2008-12-16 08:58:10Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "11828", "name": "James Hopkin", "reputation_score": "13.5k"}, "answer_comments": []}, {"stack_answer_id": "40409182", "answer_content": "\r\n c+=1  assigns  c , python assumes assigned variables are local, but in this case it hasn't been declared locally. \n\n Either use the  global  or  nonlocal  keywords.  \n\n nonlocal  works only in python 3, so if you're using python 2 and don't want to make your variable global, you can use a mutable object: \n\n my_variables = { # a mutable object\n    'c': 3\n}\n\ndef test():\n    my_variables['c'] +=1\n\ntest()\n \n    ", "date_posted": "2016-11-03 18:52:39Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "2392540", "name": "Colegram", "reputation_score": "106"}, "answer_comments": []}, {"stack_answer_id": "34153129", "answer_content": "\r\n The best way to reach class variable is directly accesing by class name \n\n class Employee:\n    counter=0\n\n    def __init__(self):\n        Employee.counter+=1\n \n    ", "date_posted": "2015-12-08 10:09:47Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "4104008", "name": "Harun ERGUL", "reputation_score": "5,446"}, "answer_comments": []}, {"stack_answer_id": "71914016", "answer_content": "\r\n You can also get this message if you define a variable with the same name as a method. \n For example: \n def teams():\n    ...\n\ndef some_other_method():\n    teams = teams()\n \n The solution, is to rename method  teams()  to something else like  get_teams() . \n Since it is only used locally, the Python message is rather misleading! \n You end up with something like this to get around it: \n def teams():\n    ...\n\ndef some_other_method():\n    teams = get_teams()\n \n    ", "date_posted": "2022-04-18 15:47:47Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "495157", "name": "JGFMK", "reputation_score": "7,889"}, "answer_comments": []}, {"stack_answer_id": "72633950", "answer_content": "\r\n This issue can also occur when the  del  keyword is utilized on the variable down the line, after initialization, typically in a loop or a conditional block. \n    ", "date_posted": "2022-06-15 15:21:05Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "221781", "name": "izilotti", "reputation_score": "4,659"}, "answer_comments": []}, {"stack_answer_id": "58002885", "answer_content": "\r\n The same problem bothers me. Using  nonlocal  and  global  can solve the problem. \nHowever, attention is needed for the usage of  nonlocal , it works for nested functions. However, at the module level, it does not work. See  examples  here. \n    ", "date_posted": "2020-12-06 21:16:23Z", "upvote": "\r\n            -1\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}], "user": {"stack_user_id": "46521", "name": "tba", "reputation_score": "5,881"}, "question_comments": [{"stack_question_id": "370357", "stack_question_comment_id": "110835190", "comment_content": "Does this answer your question? ", "user_id": "None"}, {"stack_question_id": "370357", "stack_question_comment_id": "123548687", "comment_content": "Same error but different cause: ", "user_id": "None"}]},
{"stack_question_id": "6260089", "question_title": "Strange result when removing item from a list while iterating over it", "question_content": "\r\n                I've got this piece of code:\nnumbers = list(range(1, 50))\n\nfor i in numbers:\n    if i < 20:\n        numbers.remove(i)\n\nprint(numbers)\n\nbut the result I'm getting is:\n[2, 4, 6, 8, 10, 12, 14, 16, 18,...\r\n", "question_url": "/questions/6260089/strange-result-when-removing-item-from-a-list-while-iterating-over-it", "date_posted": "Jun 7, 2011 at 2:29", "upvote": "7", "view": "1", "tags": ["python", "list", "loops"], "answers_count": "8", "answers": [{"stack_answer_id": "6260097", "answer_content": "\r\n You're modifying the list while you iterate over it. That means that the first time through the loop,  i == 1 , so 1 is removed from the list. Then the  for  loop goes to the second item in the list, which is not 2, but 3! Then that's removed from the list, and then the  for  loop goes on to the third item in the list, which is now 5. And so on. Perhaps it's easier to visualize like so, with a ^ pointing to the value of  i : \n\n [1, 2, 3, 4, 5, 6...]\n ^\n \n\n That's the state of the list initially; then 1 is removed and the loop goes to the second item in the list: \n\n [2, 3, 4, 5, 6...]\n    ^\n[2, 4, 5, 6...]\n       ^\n \n\n And so on.  \n\n There's no good way to alter a list's length while iterating over it. The best you can do is something like this: \n\n numbers = [n for n in numbers if n >= 20]\n \n\n or this, for in-place alteration (the thing in parens is a generator expression, which is implicitly converted into a tuple before slice-assignment): \n\n numbers[:] = (n for in in numbers if n >= 20)\n \n\n If you want to perform an operation on n before removing it, one trick you could try is this: \n\n for i, n in enumerate(numbers):\n    if n < 20 :\n        print(\"do something\")\n        numbers[i] = None\nnumbers = [n for n in numbers if n is not None]\n \n    ", "date_posted": "2020-05-28 12:59:52Z", "upvote": "\r\n            133\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "1398841", "name": "phoenix", "reputation_score": "6,278"}, "answer_comments": [{"stack_answer_id": "6260097", "stack_answer_comment_id": "125375319", "comment_content": "Related note on ", "user_id": "None"}, {"stack_answer_id": "6260097", "stack_answer_comment_id": "126368556", "comment_content": "This is a good answer, but with the final solution, \"if you want to perform an operation...\", is slightly unsatisfactory because 1) in fact there is no need to include that qualification: it is just a waste of effort to try and remove elements while iterating in a single operation, so this 2-stage solution applies in all cases, and 2) because there should be a warning that setting to ", "user_id": "None"}, {"stack_answer_id": "6260097", "stack_answer_comment_id": "126369014", "comment_content": "When I say that about the \"waste of effort\", I am referring to the \"general\" solution by the way, i.e. when random elements may need removing, rather than the \"specialist\" case of removing elements only at the start (or only at the end), which lends itself to something simple, like your list comprehension solution...", "user_id": "None"}]}, {"stack_answer_id": "8752528", "answer_content": "\r\n Begin at the list's end and go backwards: \n li = list(range(1, 15))\nprint(li)\n\nfor i in range(len(li) - 1, -1, -1):\n    if li[i] < 6:\n        del li[i]\n        \nprint(li)\n \n Result: \n [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14] \n[6, 7, 8, 9, 10, 11, 12, 13, 14]\n \n    ", "date_posted": "2022-04-07 11:47:31Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": [{"stack_answer_id": "8752528", "stack_answer_comment_id": "124218137", "comment_content": "How I wish I could +2 this answer!  Elegant, easy...not entirely obfuscated.", "user_id": "None"}, {"stack_answer_id": "8752528", "stack_answer_comment_id": "126368881", "comment_content": "This is a very specialised answer: it is not in fact clear whether we're meant to be looking for a general solution to the problem of how to remove elements while iterating, or how to do this exclusively when we just want to remove the first n elements of a list. The chosen answer provides the former, which is infinitely more helpful, but also the latter, in the shape of a one-line list comprehension solution.", "user_id": "None"}, {"stack_answer_id": "8752528", "stack_answer_comment_id": "126851697", "comment_content": "@mikerodent no it's not. It's pretty common when you want to modify a list while iterating over it that going backwards works", "user_id": "None"}, {"stack_answer_id": "8752528", "stack_answer_comment_id": "126853332", "comment_content": "@Boris you haven't understood my comment. The OP's question does not specify that we are removing contiguous elements (either from the start or end of the list).", "user_id": "None"}, {"stack_answer_id": "8752528", "stack_answer_comment_id": "126853360", "comment_content": "I still don't understand your comment then because it doesn't matter whether the list is shuffled or ordered, this code will still work.", "user_id": "None"}]}, {"stack_answer_id": "6260408", "answer_content": "\r\n @senderle's  answer is the way to go! \n Having said that to further illustrate even a bit more your problem, if you think about it, you will always want to remove the index 0 twenty times: \n [1,2,3,4,5............50]\n ^\n[2,3,4,5............50]\n ^\n[3,4,5............50]\n ^\n \n So you could actually go with something like this: \n aList = list(range(50))\ni = 0\nwhile i < 20:\n    aList.pop(0)\n    i += 1\n\nprint(aList) #[21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n \n I hope it helps. \n \n The ones below are  not  bad practices AFAIK. \n EDIT (Some more): \n lis = range(50)\nlis = lis[20:]\n \n Will do the job also. \n EDIT2 (I'm bored): \n functional = filter(lambda x: x> 20, range(50))\n \n    ", "date_posted": "2021-06-15 09:17:27Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "7496129", "name": "Sneha Valabailu", "reputation_score": "95"}, "answer_comments": []}, {"stack_answer_id": "64835673", "answer_content": "\r\n So I found a solution but it's really clumsy... \n First of all you make an index array, where you list all the index' you want to delete like in the following \n numbers = range(1, 50)\nindex_arr = []\n\nfor i in range(len(numbers):\n    if numbers[i] < 20:\n        index_arr.append(i)\n\n \n after that you want to delete all the entries from the numbers list with the index saved in the index_arr. The problem you will encounter is the same as before. Therefore you have to subtract 1 from every index in the index_arr after you just removed a number from the numbers arr, like in the following: \n numbers = range(1, 50)\nindex_arr = []\n\nfor i in range(len(numbers):\n    if numbers[i] < 20:\n        index_arr.append(i)\n\nfor del_index in index_list:\n    numbers.pop(del_index)\n\n    #the nasty part\n    for i in range(len(index_list)):\n        index_list[i] -= 1\n \n It will work, but I guess it's not the intended way to do it \n    ", "date_posted": "2020-11-14 15:44:33Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "13761698", "name": "Yassin Julian", "reputation_score": "39"}, "answer_comments": []}, {"stack_answer_id": "70269930", "answer_content": "\r\n Building on and simplying the answer by @eyquem ... \n The problem is that elements are being yanked out from under you as you iterate, skipping numbers as you progress to what  was  the next number. \n If you start from the end and go backwards, removing items on-the-go won't matter, because when it steps to the \"next\" item (actually the prior item), the deletion does not affect the first half of the list. \n Simply adding  reversed()  to your iterator solves the problem. A comment would be good form to preclude future developers from \"tidying up\" your code and breaking it mysteriously. \n for i in reversed(numbers): # `reversed` so removing doesn't foobar iteration\n  if i < 20:\n    numbers.remove(i)\n \n    ", "date_posted": "2021-12-08 04:24:02Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "4454732", "name": "David Hempy", "reputation_score": "4,434"}, "answer_comments": []}, {"stack_answer_id": "67652659", "answer_content": "\r\n As an additional information to @Senderle's answer, just for records,  I thought it's helpful to visualize the logic behind the scene when python sees  for  on a \" Sequence type \". \n Let's say we have : \n lst = [1, 2, 3, 4, 5]\n\nfor i in lst:\n    print(i ** 2)\n \n It is actually going to be : \n index = 0\nwhile True:\n    try:\n        i = lst.__getitem__(index)\n    except IndexError:\n        break\n    print(i ** 2)\n    index += 1\n \n That's what it is, there is a try-catch mechanism that  for  has when we use it on a Sequence types or Iterables(It's a little different though - calling  next()  and  StopIteration  Exception). \n *All I'm trying to say is, python will keep track of an independent variable here called  index , so no matter what happens to the list (removing or adding), python increments that variable and calls  __getitem__()  method with \"this variable\" and asks for item. \n    ", "date_posted": "2021-05-22 17:59:27Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "13944524", "name": "S.B", "reputation_score": "8,308"}, "answer_comments": []}, {"stack_answer_id": "67703510", "answer_content": "\r\n You could also use continue to  ignore the values less than 20 \n mylist = []\n\nfor i in range(51):\n    if i<20:\n        continue\n    else:\n        mylist.append(i)\nprint(mylist)\n \n    ", "date_posted": "2021-05-26 10:57:47Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "13734451", "name": "Moses", "reputation_score": "1,025"}, "answer_comments": []}, {"stack_answer_id": "71138926", "answer_content": "\r\n Since  Python 3.3  you may use the list  copy()  method as the iterator: \n numbers = list(range(1, 50))\n\nfor i in numbers.copy():\n    if i < 20:\n        numbers.remove(i)\nprint(numbers)\n\n[20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n \n    ", "date_posted": "2022-02-16 09:07:21Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "3474282", "name": "Cosmittus", "reputation_score": "622"}, "answer_comments": [{"stack_answer_id": "71138926", "stack_answer_comment_id": "126368658", "comment_content": "This looks like a neat suggestion to a classic problem, but I'm not sure that in practice it will prove better than the 2-stage solution suggested at the end of the chosen answer: firstly, what is the cost of the ", "user_id": "None"}]}], "user": {"stack_user_id": "415088", "name": "Finger twist", "reputation_score": "3,314"}, "question_comments": [{"stack_question_id": "6260089", "stack_question_comment_id": "129230071", "comment_content": "See also: ", "user_id": "None"}]},
{"stack_question_id": "38987", "question_title": "How do I merge two dictionaries in a single expression?", "question_content": "\r\n                I want to merge two dictionaries into a new dictionary.\nx = {'a': 1, 'b': 2}\ny = {'b': 3, 'c': 4}\nz = merge(x, y)\n\n>>> z\n{'a': 1, 'b': 3, 'c': 4}\n\nWhenever a key k is present in both ...\r\n", "question_url": "/questions/38987/how-do-i-merge-two-dictionaries-in-a-single-expression", "date_posted": "Sep 2, 2008 at 7:44", "upvote": "6", "view": "2", "tags": ["python", "dictionary", "merge"], "answers_count": "4", "answers": [{"stack_answer_id": "26853961", "answer_content": "\r\n How can I merge two Python dictionaries in a single expression? \n For dictionaries  x  and  y , their shallowly-merged dictionary  z  takes values from  y , replacing those from  x . \n \n In Python 3.9.0 or greater (released 17 October 2020,  PEP-584 ,  discussed here ): \n z = x | y\n \n \n In Python 3.5 or greater: \n z = {**x, **y}\n \n \n In Python 2, (or 3.4 or lower) write a function: \n def merge_two_dicts(x, y):\n    z = x.copy()   # start with keys and values of x\n    z.update(y)    # modifies z with keys and values of y\n    return z\n \n and now: \n z = merge_two_dicts(x, y)\n \n \n \n Explanation \n Say you have two dictionaries and you want to merge them into a new dictionary without altering the original dictionaries: \n x = {'a': 1, 'b': 2}\ny = {'b': 3, 'c': 4}\n \n The desired result is to get a new dictionary ( z ) with the values merged, and the second dictionary's values overwriting those from the first. \n >>> z\n{'a': 1, 'b': 3, 'c': 4}\n \n A new syntax for this, proposed in  PEP 448  and  available as of Python 3.5 , is \n z = {**x, **y}\n \n And it is indeed a single expression. \n Note that we can merge in with literal notation as well: \n z = {**x, 'foo': 1, 'bar': 2, **y}\n \n and now: \n >>> z\n{'a': 1, 'b': 3, 'foo': 1, 'bar': 2, 'c': 4}\n \n It is now showing as implemented in the  release schedule for 3.5, PEP 478 , and it has now made its way into the  What's New in Python 3.5  document. \n However, since many organizations are still on Python 2, you may wish to do this in a backward-compatible way. The classically Pythonic way, available in Python 2 and Python 3.0-3.4, is to do this as a two-step process: \n z = x.copy()\nz.update(y) # which returns None since it mutates z\n \n In both approaches,  y  will come second and its values will replace  x 's values, thus  b  will point to  3  in our final result. \n Not yet on Python 3.5, but want a  single expression \n If you are not yet on Python 3.5 or need to write backward-compatible code, and you want this in a  single expression , the most performant while the correct approach is to put it in a function: \n def merge_two_dicts(x, y):\n    \"\"\"Given two dictionaries, merge them into a new dict as a shallow copy.\"\"\"\n    z = x.copy()\n    z.update(y)\n    return z\n \n and then you have a single expression: \n z = merge_two_dicts(x, y)\n \n You can also make a function to merge an arbitrary number of dictionaries, from zero to a very large number: \n def merge_dicts(*dict_args):\n    \"\"\"\n    Given any number of dictionaries, shallow copy and merge into a new dict,\n    precedence goes to key-value pairs in latter dictionaries.\n    \"\"\"\n    result = {}\n    for dictionary in dict_args:\n        result.update(dictionary)\n    return result\n \n This function will work in Python 2 and 3 for all dictionaries. e.g. given dictionaries  a  to  g : \n z = merge_dicts(a, b, c, d, e, f, g) \n \n and key-value pairs in  g  will take precedence over dictionaries  a  to  f , and so on. \n Critiques of Other Answers \n Don't use what you see in the formerly accepted answer: \n z = dict(x.items() + y.items())\n \n In Python 2, you create two lists in memory for each dict, create a third list in memory with length equal to the length of the first two put together, and then discard all three lists to create the dict.  In Python 3, this will fail  because you're adding two  dict_items  objects together, not two lists - \n >>> c = dict(a.items() + b.items())\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: unsupported operand type(s) for +: 'dict_items' and 'dict_items'\n \n and you would have to explicitly create them as lists, e.g.  z = dict(list(x.items()) + list(y.items())) . This is a waste of resources and computation power. \n Similarly, taking the union of  items()  in Python 3 ( viewitems()  in Python 2.7) will also fail when values are unhashable objects (like lists, for example). Even if your values are hashable,  since sets are semantically unordered, the behavior is undefined in regards to precedence. So don't do this: \n >>> c = dict(a.items() | b.items())\n \n This example demonstrates what happens when values are unhashable: \n >>> x = {'a': []}\n>>> y = {'b': []}\n>>> dict(x.items() | y.items())\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: unhashable type: 'list'\n \n Here's an example where  y  should have precedence, but instead the value from  x  is retained due to the arbitrary order of sets: \n >>> x = {'a': 2}\n>>> y = {'a': 1}\n>>> dict(x.items() | y.items())\n{'a': 2}\n \n Another hack you should not use: \n z = dict(x, **y)\n \n This uses the  dict  constructor and is very fast and memory-efficient (even slightly more so than our two-step process) but unless you know precisely what is happening here (that is, the second dict is being passed as keyword arguments to the dict constructor), it's difficult to read, it's not the intended usage, and so it is not Pythonic. \n Here's an example of the usage being  remediated in django . \n Dictionaries are intended to take hashable keys (e.g.  frozenset s or tuples), but  this method fails in Python 3 when keys are not strings. \n >>> c = dict(a, **b)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: keyword arguments must be strings\n \n From the  mailing list , Guido van Rossum, the creator of the language, wrote: \n \n I am fine with\ndeclaring dict({}, **{1:3}) illegal, since after all it is abuse of\nthe ** mechanism. \n \n and \n \n Apparently dict(x, **y) is going around as \"cool hack\" for \"call\nx.update(y) and return x\". Personally, I find it more despicable than\ncool. \n \n It is my understanding (as well as the understanding of the  creator of the language ) that the intended usage for  dict(**y)  is for creating dictionaries for readability purposes, e.g.: \n dict(a=1, b=10, c=11)\n \n instead of \n {'a': 1, 'b': 10, 'c': 11}\n \n Response to comments \n \n Despite what Guido says,  dict(x, **y)  is in line with the dict specification, which btw. works for both Python 2 and 3. The fact that this only works for string keys is a direct consequence of how keyword parameters work and not a short-coming of dict. Nor is using the ** operator in this place an abuse of the mechanism, in fact, ** was designed precisely to pass dictionaries as keywords. \n \n Again, it doesn't work for 3 when keys are not strings. The implicit calling contract is that namespaces take ordinary dictionaries, while users must only pass keyword arguments that are strings. All other callables enforced it.  dict  broke this consistency in Python 2: \n >>> foo(**{('a', 'b'): None})\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: foo() keywords must be strings\n>>> dict(**{('a', 'b'): None})\n{('a', 'b'): None}\n \n This inconsistency was bad given other implementations of Python (PyPy, Jython, IronPython). Thus it was fixed in Python 3, as this usage could be a breaking change. \n I submit to you that it is malicious incompetence to intentionally write code that only works in one version of a language or that only works given certain arbitrary constraints. \n More comments: \n \n dict(x.items() + y.items())  is still the most readable solution for Python 2. Readability counts. \n \n My response:  merge_two_dicts(x, y)  actually seems much clearer to me, if we're actually concerned about readability. And it is not forward compatible, as Python 2 is increasingly deprecated. \n \n {**x, **y}  does not seem to handle nested dictionaries. the contents of nested keys are simply overwritten, not merged [...] I ended up being burnt by these answers that do not merge recursively and I was surprised no one mentioned it. In my interpretation of the word \"merging\" these answers describe \"updating one dict with another\", and not merging. \n \n Yes. I must refer you back to the question, which is asking for a  shallow  merge of  two  dictionaries, with the first's values being overwritten by the second's - in a single expression. \n Assuming two dictionaries of dictionaries, one might recursively merge them in a single function, but you should be careful not to modify the dictionaries from either source, and the surest way to avoid that is to make a copy when assigning values. As keys must be hashable and are usually therefore immutable, it is pointless to copy them: \n from copy import deepcopy\n\ndef dict_of_dicts_merge(x, y):\n    z = {}\n    overlapping_keys = x.keys() & y.keys()\n    for key in overlapping_keys:\n        z[key] = dict_of_dicts_merge(x[key], y[key])\n    for key in x.keys() - overlapping_keys:\n        z[key] = deepcopy(x[key])\n    for key in y.keys() - overlapping_keys:\n        z[key] = deepcopy(y[key])\n    return z\n \n Usage: \n >>> x = {'a':{1:{}}, 'b': {2:{}}}\n>>> y = {'b':{10:{}}, 'c': {11:{}}}\n>>> dict_of_dicts_merge(x, y)\n{'b': {2: {}, 10: {}}, 'a': {1: {}}, 'c': {11: {}}}\n \n Coming up with contingencies for other value types is far beyond the scope of this question, so I will point you at  my answer to the canonical question on a \"Dictionaries of dictionaries merge\" . \n Less Performant But Correct Ad-hocs \n These approaches are less performant, but they will provide correct behavior.\nThey will be  much less  performant than  copy  and  update  or the new unpacking because they iterate through each key-value pair at a higher level of abstraction, but they  do  respect the order of precedence (latter dictionaries have precedence) \n You can also chain the dictionaries manually inside a  dict comprehension : \n {k: v for d in dicts for k, v in d.items()} # iteritems in Python 2.7\n \n or in Python 2.6 (and perhaps as early as 2.4 when generator expressions were introduced): \n dict((k, v) for d in dicts for k, v in d.items()) # iteritems in Python 2\n \n itertools.chain  will chain the iterators over the key-value pairs in the correct order: \n from itertools import chain\nz = dict(chain(x.items(), y.items())) # iteritems in Python 2\n \n Performance Analysis \n I'm only going to do the performance analysis of the usages known to behave correctly. (Self-contained so you can copy and paste yourself.) \n from timeit import repeat\nfrom itertools import chain\n\nx = dict.fromkeys('abcdefg')\ny = dict.fromkeys('efghijk')\n\ndef merge_two_dicts(x, y):\n    z = x.copy()\n    z.update(y)\n    return z\n\nmin(repeat(lambda: {**x, **y}))\nmin(repeat(lambda: merge_two_dicts(x, y)))\nmin(repeat(lambda: {k: v for d in (x, y) for k, v in d.items()}))\nmin(repeat(lambda: dict(chain(x.items(), y.items()))))\nmin(repeat(lambda: dict(item for d in (x, y) for item in d.items())))\n \n In Python 3.8.1, NixOS: \n >>> min(repeat(lambda: {**x, **y}))\n1.0804965235292912\n>>> min(repeat(lambda: merge_two_dicts(x, y)))\n1.636518670246005\n>>> min(repeat(lambda: {k: v for d in (x, y) for k, v in d.items()}))\n3.1779992282390594\n>>> min(repeat(lambda: dict(chain(x.items(), y.items()))))\n2.740647904574871\n>>> min(repeat(lambda: dict(item for d in (x, y) for item in d.items())))\n4.266070580109954\n \n $ uname -a\nLinux nixos 4.19.113 #1-NixOS SMP Wed Mar 25 07:06:15 UTC 2020 x86_64 GNU/Linux\n \n Resources on Dictionaries \n \n My explanation of Python's  dictionary implementation , updated for 3.6. \n Answer on how to add new keys to a dictionary \n Mapping two lists into a dictionary \n The official Python docs on dictionaries \n The Dictionary Even Mightier  - talk by Brandon Rhodes at Pycon 2017 \n Modern Python Dictionaries, A Confluence of Great Ideas  - talk by Raymond Hettinger at Pycon 2017 \n \n    ", "date_posted": "2022-03-29 10:49:08Z", "upvote": "\r\n            8286\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": [{"stack_answer_id": "26853961", "stack_answer_comment_id": "98971751", "comment_content": "@MohammadAzim \"strings only\" only applies to keyword argument expansion in callables, not generalized unpacking syntax. To demonstrate that this works: ", "user_id": "None"}, {"stack_answer_id": "26853961", "stack_answer_comment_id": "106950304", "comment_content": "This may be changed when PEP-0584 is accepted. A new union operator will be implemented with the following syntax: ", "user_id": "None"}, {"stack_answer_id": "26853961", "stack_answer_comment_id": "106950627", "comment_content": "@cal97g yes, I addressed that in my answer about 10 days ago: ", "user_id": "None"}, {"stack_answer_id": "26853961", "stack_answer_comment_id": "107329096", "comment_content": "Hi, the top is a summary, yes.  Up to you.  The whole thing would be a great blog post.  Note Py 3.4 and below are EOL, 3.5 approaching EOL in 2020-09.", "user_id": "None"}, {"stack_answer_id": "26853961", "stack_answer_comment_id": "109402225", "comment_content": "I agree with the eagerness to leave the old way behind, but sometimes people have to work in environments where they only have the older technology available to them. People also have to update code, and seeing the old way next to the new way allows them to confidently replace the old code with equivalent new code. I am open to suggestions on reorganizing the material, but I think we need to keep the older information.", "user_id": "None"}]}, {"stack_answer_id": "38990", "answer_content": "\r\n In your case, what you can do is: \n z = dict(list(x.items()) + list(y.items()))\n \n This will, as you want it, put the final dict in  z , and make the value for key  b  be properly overridden by the second ( y ) dict's value: \n >>> x = {'a':1, 'b': 2}\n>>> y = {'b':10, 'c': 11}\n>>> z = dict(list(x.items()) + list(y.items()))\n>>> z\n{'a': 1, 'c': 11, 'b': 10}\n\n \n If you use Python 2, you can even remove the  list()  calls. To create z: \n >>> z = dict(x.items() + y.items())\n>>> z\n{'a': 1, 'c': 11, 'b': 10}\n \n If you use Python version 3.9.0a4 or greater, then you can directly use: \n x = {'a':1, 'b': 2}\ny = {'b':10, 'c': 11}\nz = x | y\nprint(z)\n \n {'a': 1, 'c': 11, 'b': 10}\n \n    ", "date_posted": "2020-10-30 21:08:09Z", "upvote": "\r\n            1766\r\n        ", "accepted": "No", "user": {"stack_user_id": "3815432", "name": "Nikita Vlasenko", "reputation_score": "3,634"}, "answer_comments": [{"stack_answer_id": "38990", "stack_answer_comment_id": "107286634", "comment_content": "Don't use this as it is very inefficient.  (See the timeit results below.)  It may have been necessary in the Py2 days if a wrapper function was not an option, but those days are now past.", "user_id": "None"}]}, {"stack_answer_id": "39437", "answer_content": "\r\n An alternative: \n\n z = x.copy()\nz.update(y)\n \n    ", "date_posted": "2008-09-02 13:00:46Z", "upvote": "\r\n            729\r\n        ", "accepted": "No", "user": {"stack_user_id": "188", "name": "Matthew Schinckel", "reputation_score": "34.1k"}, "answer_comments": [{"stack_answer_id": "39437", "stack_answer_comment_id": "22031787", "comment_content": "To clarify why this doesn't meet the critera provided by the question: it's not a single expression and it doesn't return z.", "user_id": "None"}, {"stack_answer_id": "39437", "stack_answer_comment_id": "80608499", "comment_content": "Put it this way: if you need to put two lines of comments explaining your one line of code to the people you hand your code off to...have you really done it in one line? :) I fully agree Python is not good for this: there should be a much easier way. While this answer is more pythonic, is it really all that explicit or clear? ", "user_id": "None"}, {"stack_answer_id": "39437", "stack_answer_comment_id": "106803501", "comment_content": "Well, if people insist on making it a oneliner, you can always do ", "user_id": "None"}, {"stack_answer_id": "39437", "stack_answer_comment_id": "128914525", "comment_content": "@AlexanderOh I am not sure whenever this is a joke or not; I see this as a perfectly (valid) answ!  (at least in terms of it works) but Of course;  yeah; the second comment sets a precedent!    either way; it is ", "user_id": "None"}, {"stack_answer_id": "39437", "stack_answer_comment_id": "128918894", "comment_content": "@WilliamMartens it wasn't a joke. But let's face it, if you optimize for single line expressions,you are optimizing for the wrong thing.", "user_id": "None"}]}, {"stack_answer_id": "39858", "answer_content": "\r\n Another, more concise, option: \n\n z = dict(x, **y)\n \n\n Note : this has become a popular answer, but it is important to point out that if  y  has any non-string keys, the fact that this works at all is an abuse of a CPython implementation detail, and it does not work in Python 3, or in PyPy, IronPython, or Jython. Also,  Guido is not a fan . So I can't recommend this technique for forward-compatible or cross-implementation portable code, which really means it should be avoided entirely. \n    ", "date_posted": "2016-01-21 06:43:24Z", "upvote": "\r\n            421\r\n        ", "accepted": "No", "user": {"stack_user_id": "3207", "name": "Carl Meyer", "reputation_score": "116k"}, "answer_comments": [{"stack_answer_id": "39858", "stack_answer_comment_id": "97993261", "comment_content": ", can't speak to Jython or Iron. Given this pattern is ", "user_id": "None"}, {"stack_answer_id": "39858", "stack_answer_comment_id": "98801135", "comment_content": "@amcgregor You missed the key phrase \"if y has any non-string keys.\" That's what doesn't work in Python3; the fact that it works in CPython 2 is an implementation detail that can't be relied on. IFF all your keys are guaranteed to be strings, this is a fully supported option.", "user_id": "3207"}]}, {"stack_answer_id": "49492", "answer_content": "\r\n This probably won't be a popular answer, but you almost certainly do not want to do this.  If you want a copy that's a merge, then use copy (or  deepcopy , depending on what you want) and then update.  The two lines of code are much more readable - more Pythonic - than the single line creation with .items() + .items().  Explicit is better than implicit. \n\n In addition, when you use .items() (pre Python 3.0), you're creating a new list that contains the items from the dict.  If your dictionaries are large, then that is quite a lot of overhead (two large lists that will be thrown away as soon as the merged dict is created).  update() can work more efficiently, because it can run through the second dict item-by-item. \n\n In terms of  time : \n\n >>> timeit.Timer(\"dict(x, **y)\", \"x = dict(zip(range(1000), range(1000)))\\ny=dict(zip(range(1000,2000), range(1000,2000)))\").timeit(100000)\n15.52571702003479\n>>> timeit.Timer(\"temp = x.copy()\\ntemp.update(y)\", \"x = dict(zip(range(1000), range(1000)))\\ny=dict(zip(range(1000,2000), range(1000,2000)))\").timeit(100000)\n15.694622993469238\n>>> timeit.Timer(\"dict(x.items() + y.items())\", \"x = dict(zip(range(1000), range(1000)))\\ny=dict(zip(range(1000,2000), range(1000,2000)))\").timeit(100000)\n41.484580039978027\n \n\n IMO the tiny slowdown between the first two is worth it for the readability.  In addition, keyword arguments for dictionary creation was only added in Python 2.3, whereas copy() and update() will work in older versions. \n    ", "date_posted": "2014-08-05 23:56:02Z", "upvote": "\r\n            252\r\n        ", "accepted": "No", "user": {"stack_user_id": "2213647", "name": "twasbrillig", "reputation_score": "15.3k"}, "answer_comments": []}, {"stack_answer_id": "228366", "answer_content": "\r\n In a follow-up answer, you asked about the relative performance of these two alternatives: \n\n z1 = dict(x.items() + y.items())\nz2 = dict(x, **y)\n \n\n On my machine, at least (a fairly ordinary x86_64 running Python 2.5.2), alternative  z2  is not only shorter and simpler but also significantly faster.  You can verify this for yourself using the  timeit  module that comes with Python. \n\n Example 1: identical dictionaries mapping 20 consecutive integers to themselves: \n\n % python -m timeit -s 'x=y=dict((i,i) for i in range(20))' 'z1=dict(x.items() + y.items())'\n100000 loops, best of 3: 5.67 usec per loop\n% python -m timeit -s 'x=y=dict((i,i) for i in range(20))' 'z2=dict(x, **y)' \n100000 loops, best of 3: 1.53 usec per loop\n \n\n z2  wins by a factor of 3.5 or so.  Different dictionaries seem to yield quite different results, but  z2  always seems to come out ahead.  (If you get inconsistent results for the  same  test, try passing in  -r  with a number larger than the default 3.) \n\n Example 2: non-overlapping dictionaries mapping 252 short strings to integers and vice versa: \n\n % python -m timeit -s 'from htmlentitydefs import codepoint2name as x, name2codepoint as y' 'z1=dict(x.items() + y.items())'\n1000 loops, best of 3: 260 usec per loop\n% python -m timeit -s 'from htmlentitydefs import codepoint2name as x, name2codepoint as y' 'z2=dict(x, **y)'               \n10000 loops, best of 3: 26.9 usec per loop\n \n\n z2  wins by about a factor of 10.  That's a pretty big win in my book! \n\n After comparing those two, I wondered if  z1 's poor performance could be attributed to the overhead of constructing the two item lists, which in turn led me to wonder if this variation might work better: \n\n from itertools import chain\nz3 = dict(chain(x.iteritems(), y.iteritems()))\n \n\n A few quick tests, e.g. \n\n % python -m timeit -s 'from itertools import chain; from htmlentitydefs import codepoint2name as x, name2codepoint as y' 'z3=dict(chain(x.iteritems(), y.iteritems()))'\n10000 loops, best of 3: 66 usec per loop\n \n\n lead me to conclude that  z3  is somewhat faster than  z1 , but not nearly as fast as  z2 .  Definitely not worth all the extra typing. \n\n This discussion is still missing something important, which is a performance comparison of these alternatives with the \"obvious\" way of merging two lists: using the  update  method.  To try to keep things on an equal footing with the expressions, none of which modify x or y, I'm going to make a copy of x instead of modifying it in-place, as follows: \n\n z0 = dict(x)\nz0.update(y)\n \n\n A typical result: \n\n % python -m timeit -s 'from htmlentitydefs import codepoint2name as x, name2codepoint as y' 'z0=dict(x); z0.update(y)'\n10000 loops, best of 3: 26.9 usec per loop\n \n\n In other words,  z0  and  z2  seem to have essentially identical performance.  Do you think this might be a coincidence?  I don't.... \n\n In fact, I'd go so far as to claim that it's impossible for pure Python code to do any better than this.  And if you can do significantly better in a C extension module, I imagine the Python folks might well be interested in incorporating your code (or a variation on your approach) into the Python core.  Python uses  dict  in lots of places; optimizing its operations is a big deal. \n\n You could also write this as \n\n z0 = x.copy()\nz0.update(y)\n \n\n as Tony does, but (not surprisingly) the difference in notation turns out not to have any measurable effect on performance.  Use whichever looks right to you.  Of course, he's absolutely correct to point out that the two-statement version is much easier to understand. \n    ", "date_posted": "2015-01-10 02:32:55Z", "upvote": "\r\n            187\r\n        ", "accepted": "No", "user": {"stack_user_id": "128421", "name": "the Tin Man", "reputation_score": "156k"}, "answer_comments": [{"stack_answer_id": "228366", "stack_answer_comment_id": "46375571", "comment_content": "This does not work in Python 3; ", "user_id": "None"}]}, {"stack_answer_id": "16259217", "answer_content": "\r\n In Python 3.0 and later , you can use  collections.ChainMap  which groups multiple dicts or other mappings together to create a single, updateable view: \n >>> from collections import ChainMap\n>>> x = {'a':1, 'b': 2}\n>>> y = {'b':10, 'c': 11}\n>>> z = dict(ChainMap({}, y, x))\n>>> for k, v in z.items():\n        print(k, '-->', v)\n    \na --> 1\nb --> 10\nc --> 11\n \n Update for Python 3.5 and later : You can use  PEP 448  extended dictionary packing and unpacking.  This is fast and easy: \n >>> x = {'a':1, 'b': 2}\n>>> y = {'b':10, 'c': 11}\n>>> {**x, **y}\n{'a': 1, 'b': 10, 'c': 11}\n \n Update for Python 3.9 and later :  You can use the  PEP 584  union operator: \n >>> x = {'a':1, 'b': 2}\n>>> y = {'b':10, 'c': 11}\n>>> x | y\n{'a': 1, 'b': 10, 'c': 11}\n \n    ", "date_posted": "2020-12-11 06:43:11Z", "upvote": "\r\n            184\r\n        ", "accepted": "No", "user": {"stack_user_id": "424499", "name": "Raymond Hettinger", "reputation_score": "205k"}, "answer_comments": [{"stack_answer_id": "16259217", "stack_answer_comment_id": "71597496", "comment_content": "But one should be cautious while using ChainMap there's a catch that if you have duplicate keys the values from first mapping get used and when you call a ", "user_id": "None"}, {"stack_answer_id": "16259217", "stack_answer_comment_id": "71644530", "comment_content": "@Prerit What else would you expect it to do?  That's the normal way chained namespaces work.  Consider how $PATH works in bash.  Deleting an executable on the path doesn't preclude another executable with the same name further upstream.", "user_id": "None"}, {"stack_answer_id": "16259217", "stack_answer_comment_id": "71663990", "comment_content": "@Raymond Hettinger I agree, just added a caution. Most people may not know about it. :D", "user_id": "None"}, {"stack_answer_id": "16259217", "stack_answer_comment_id": "100615370", "comment_content": "@Prerit You could cast to ", "user_id": "None"}, {"stack_answer_id": "16259217", "stack_answer_comment_id": "120954371", "comment_content": "Suggested Edit Queue is full, but someone put the modification from @wjandrea into the answer, which is wrong - it's no longer a ", "user_id": "None"}]}, {"stack_answer_id": "44512", "answer_content": "\r\n I wanted something similar, but with the ability to specify how the values on duplicate keys were merged, so I hacked this out (but did not heavily test it).  Obviously this is not a single expression, but it is a single function call. \n\n def merge(d1, d2, merge_fn=lambda x,y:y):\n    \"\"\"\n    Merges two dictionaries, non-destructively, combining \n    values on duplicate keys as defined by the optional merge\n    function.  The default behavior replaces the values in d1\n    with corresponding values in d2.  (There is no other generally\n    applicable merge strategy, but often you'll have homogeneous \n    types in your dicts, so specifying a merge technique can be \n    valuable.)\n\n    Examples:\n\n    >>> d1\n    {'a': 1, 'c': 3, 'b': 2}\n    >>> merge(d1, d1)\n    {'a': 1, 'c': 3, 'b': 2}\n    >>> merge(d1, d1, lambda x,y: x+y)\n    {'a': 2, 'c': 6, 'b': 4}\n\n    \"\"\"\n    result = dict(d1)\n    for k,v in d2.iteritems():\n        if k in result:\n            result[k] = merge_fn(result[k], v)\n        else:\n            result[k] = v\n    return result\n \n    ", "date_posted": "2014-09-13 19:56:21Z", "upvote": "\r\n            152\r\n        ", "accepted": "No", "user": {"stack_user_id": "2748838", "name": "Rainy", "reputation_score": "1,017"}, "answer_comments": [{"stack_answer_id": "44512", "stack_answer_comment_id": "117550353", "comment_content": "Handy solution when the default behaviour of the shorter and simpler solutions (replacement of values of common keys by the second dictionary) is not wished. For Python 3, iteritems() is not available anymore in dicts, and one can simply use items() instead.", "user_id": "None"}]}, {"stack_answer_id": "8310229", "answer_content": "\r\n Recursively/deep update a dict \n\n def deepupdate(original, update):\n    \"\"\"\n    Recursively update a dict.\n    Subdict's won't be overwritten but also updated.\n    \"\"\"\n    for key, value in original.iteritems(): \n        if key not in update:\n            update[key] = value\n        elif isinstance(value, dict):\n            deepupdate(value, update[key]) \n    return update \n\n Demonstration: \n\n pluto_original = {\n    'name': 'Pluto',\n    'details': {\n        'tail': True,\n        'color': 'orange'\n    }\n}\n\npluto_update = {\n    'name': 'Pluutoo',\n    'details': {\n        'color': 'blue'\n    }\n}\n\nprint deepupdate(pluto_original, pluto_update) \n\n Outputs: \n\n {\n    'name': 'Pluutoo',\n    'details': {\n        'color': 'blue',\n        'tail': True\n    }\n} \n\n Thanks rednaw for edits. \n    ", "date_posted": "2015-12-18 11:19:15Z", "upvote": "\r\n            121\r\n        ", "accepted": "No", "user": {"stack_user_id": "1392229", "name": "Dawid Gos\u0142awski", "reputation_score": "1,918"}, "answer_comments": [{"stack_answer_id": "8310229", "stack_answer_comment_id": "93325213", "comment_content": "This does not answer the question. The question clearly asks for a new dictionary, z, from original dictionaries, x and y, with values from y replacing those of x - not an updated dictionary. This answer modifies y in-place by adding values from x. Worse, it does not copy these values, so one could further modify the modified dictionary, y, and modifications could be reflected in dictionary x. @J\u00e9r\u00f4me I hope this code is not causing any bugs for your application - at least consider using deepcopy to copy the values.", "user_id": "None"}, {"stack_answer_id": "8310229", "stack_answer_comment_id": "93339886", "comment_content": "@AaronHall agreed this does not answer the question. But it answers my need. I understand those limitations, but that's not an issue in my case. Thinking of it, maybe the name is misleading, as it might evoke a deepcopy, which it does not provide. But it addresses deep nesting. Here's another implementation from the Martellibot: ", "user_id": "None"}]}, {"stack_answer_id": "28753078", "answer_content": "\r\n Python 3.5 (PEP 448) allows a nicer syntax option: \n\n x = {'a': 1, 'b': 1}\ny = {'a': 2, 'c': 2}\nfinal = {**x, **y} \nfinal\n# {'a': 2, 'b': 1, 'c': 2}\n \n\n Or even  \n\n final = {'a': 1, 'b': 1, **x, **y}\n \n\n In Python 3.9 you also use | and |= with the below example from PEP 584 \n\n d = {'spam': 1, 'eggs': 2, 'cheese': 3}\ne = {'cheese': 'cheddar', 'aardvark': 'Ethel'}\nd | e\n# {'spam': 1, 'eggs': 2, 'cheese': 'cheddar', 'aardvark': 'Ethel'}\n \n    ", "date_posted": "2020-05-03 21:16:55Z", "upvote": "\r\n            99\r\n        ", "accepted": "No", "user": {"stack_user_id": "852240", "name": "Bilal Syed Hussain", "reputation_score": "7,924"}, "answer_comments": [{"stack_answer_id": "28753078", "stack_answer_comment_id": "45972281", "comment_content": "In what way is this solution better than the ", "user_id": "None"}, {"stack_answer_id": "28753078", "stack_answer_comment_id": "45997426", "comment_content": "Guido dislikes ", "user_id": "3207"}]}, {"stack_answer_id": "3936548", "answer_content": "\r\n The best version I could think while not using copy would be: \n\n from itertools import chain\nx = {'a':1, 'b': 2}\ny = {'b':10, 'c': 11}\ndict(chain(x.iteritems(), y.iteritems()))\n \n\n It's faster than  dict(x.items() + y.items())  but not as fast as  n = copy(a); n.update(b) , at least on CPython. This version also works in Python 3 if you change  iteritems()  to  items() , which is automatically done by the 2to3 tool. \n\n Personally I like this version best because it describes fairly good what I want in a single  functional syntax. The only minor problem is that it doesn't make completely obvious that values from y takes precedence over values from x, but I don't believe it's difficult to figure that out. \n    ", "date_posted": "2010-10-14 18:55:15Z", "upvote": "\r\n            95\r\n        ", "accepted": "No", "user": {"stack_user_id": "72476", "name": "driax", "reputation_score": "2,448"}, "answer_comments": []}, {"stack_answer_id": "38989", "answer_content": "\r\n x = {'a':1, 'b': 2}\ny = {'b':10, 'c': 11}\nz = dict(x.items() + y.items())\nprint z\n \n\n For items with keys in both dictionaries ('b'), you can control which one ends up in the output by putting that one last. \n    ", "date_posted": "2008-09-02 07:49:27Z", "upvote": "\r\n            93\r\n        ", "accepted": "No", "user": {"stack_user_id": "893", "name": "Greg Hewgill", "reputation_score": "903k"}, "answer_comments": [{"stack_answer_id": "38989", "stack_answer_comment_id": "98388054", "comment_content": "In python 3 you would get TypeError: unsupported operand type(s) for +: 'dict_items' and 'dict_items' ... you should encapsulate each dict with list() like: dict(list(x.items()) + list(y.items()))", "user_id": "None"}, {"stack_answer_id": "38989", "stack_answer_comment_id": "124851979", "comment_content": "@justSaid ", "user_id": "None"}]}, {"stack_answer_id": "7770473", "answer_content": "\r\n While the question has already been answered several times,\nthis simple solution to the problem has not been listed yet. \n\n x = {'a':1, 'b': 2}\ny = {'b':10, 'c': 11}\nz4 = {}\nz4.update(x)\nz4.update(y)\n \n\n It is as fast as z0 and the evil z2 mentioned above, but easy to understand and change. \n    ", "date_posted": "2011-10-14 16:12:33Z", "upvote": "\r\n            72\r\n        ", "accepted": "No", "user": {"stack_user_id": "509648", "name": "phobie", "reputation_score": "2,464"}, "answer_comments": [{"stack_answer_id": "7770473", "stack_answer_comment_id": "9516513", "comment_content": "but it's three statements rather than one expression", "user_id": "None"}, {"stack_answer_id": "7770473", "stack_answer_comment_id": "9680836", "comment_content": "Yes! The mentioned one-expression-solutions are either slow or evil. Good code is readable and maintainable. So the problem is the question not the answer. We should ask for the best solution of a problem not for a one-line-solution.", "user_id": "None"}, {"stack_answer_id": "7770473", "stack_answer_comment_id": "21587977", "comment_content": "Lose the ", "user_id": "None"}, {"stack_answer_id": "7770473", "stack_answer_comment_id": "23506047", "comment_content": "Your suggestion would change this to Matthews answer. While his answer is fine, I think mine is more readable and better maintainable. The extra line would only be bad if it would cost execution time.", "user_id": "None"}, {"stack_answer_id": "7770473", "stack_answer_comment_id": "110323413", "comment_content": "I suggest you put this into a function", "user_id": "None"}]}, {"stack_answer_id": "11825563", "answer_content": "\r\n def dict_merge(a, b):\n  c = a.copy()\n  c.update(b)\n  return c\n\nnew = dict_merge(old, extras)\n \n\n Among such shady and dubious answers, this shining example is the one and only good way to merge dicts in Python, endorsed by dictator for life  Guido van Rossum  himself!  Someone else suggested half of this, but did not put it in a function. \n\n print dict_merge(\n      {'color':'red', 'model':'Mini'},\n      {'model':'Ferrari', 'owner':'Carl'})\n \n\n gives: \n\n {'color': 'red', 'owner': 'Carl', 'model': 'Ferrari'}\n \n    ", "date_posted": "2012-08-06 09:30:07Z", "upvote": "\r\n            65\r\n        ", "accepted": "No", "user": {"stack_user_id": "218294", "name": "Sam Watkins", "reputation_score": "7,441"}, "answer_comments": []}, {"stack_answer_id": "8247023", "answer_content": "\r\n If you think lambdas are evil then read no further.\nAs requested, you can write the fast and memory-efficient solution with one expression: \n\n x = {'a':1, 'b':2}\ny = {'b':10, 'c':11}\nz = (lambda a, b: (lambda a_copy: a_copy.update(b) or a_copy)(a.copy()))(x, y)\nprint z\n{'a': 1, 'c': 11, 'b': 10}\nprint x\n{'a': 1, 'b': 2}\n \n\n As suggested above, using two lines or writing a function is probably a better way to go. \n    ", "date_posted": "2011-11-23 18:20:48Z", "upvote": "\r\n            58\r\n        ", "accepted": "No", "user": {"stack_user_id": "364984", "name": "EMS", "reputation_score": "1,013"}, "answer_comments": []}, {"stack_answer_id": "34899183", "answer_content": "\r\n Be pythonic. Use a  comprehension : \n z={k: v for d in [x,y] for k, v in d.items()}\n\n>>> print z\n{'a': 1, 'c': 11, 'b': 10}\n \n    ", "date_posted": "2022-06-16 22:40:57Z", "upvote": "\r\n            58\r\n        ", "accepted": "No", "user": {"stack_user_id": "833208", "name": "Robino", "reputation_score": "4,083"}, "answer_comments": []}, {"stack_answer_id": "19279501", "answer_content": "\r\n In python3, the  items  method  no longer returns a list , but rather a  view , which acts like a set. In this case you'll need to take the set union since concatenating with  +  won't work: \n\n dict(x.items() | y.items())\n \n\n For python3-like behavior in version 2.7, the  viewitems  method should work in place of  items : \n\n dict(x.viewitems() | y.viewitems())\n \n\n I prefer this notation anyways since it seems more natural to think of it as a set union operation rather than concatenation (as the title shows). \n\n Edit: \n\n A couple more points for python 3. First, note that the  dict(x, **y)  trick won't work in python 3 unless the keys in  y  are strings. \n\n Also, Raymond Hettinger's Chainmap  answer  is pretty elegant, since it can take an arbitrary number of dicts as arguments, but  from the docs  it looks like it sequentially looks through a list of all the dicts for each lookup: \n\n \n   Lookups search the underlying mappings successively until a key is found. \n \n\n This can slow you down if you have a lot of lookups in your application: \n\n In [1]: from collections import ChainMap\nIn [2]: from string import ascii_uppercase as up, ascii_lowercase as lo; x = dict(zip(lo, up)); y = dict(zip(up, lo))\nIn [3]: chainmap_dict = ChainMap(y, x)\nIn [4]: union_dict = dict(x.items() | y.items())\nIn [5]: timeit for k in union_dict: union_dict[k]\n100000 loops, best of 3: 2.15 \u00b5s per loop\nIn [6]: timeit for k in chainmap_dict: chainmap_dict[k]\n10000 loops, best of 3: 27.1 \u00b5s per loop\n \n\n So about an order of magnitude slower for lookups. I'm a fan of Chainmap, but looks less practical where there may be many lookups. \n    ", "date_posted": "2017-05-23 12:34:53Z", "upvote": "\r\n            46\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}, {"stack_answer_id": "62820532", "answer_content": "\r\n I benchmarked the suggested with  perfplot  and found that the good old \n temp = x.copy()\ntemp.update(y)\n \n is the fastest solution together with the new (Python 3.9+) \n x | y\n \n \n \n Code to reproduce the plot: \n from collections import ChainMap\nfrom itertools import chain\nimport perfplot\n\n\ndef setup(n):\n    x = dict(zip(range(n), range(n)))\n    y = dict(zip(range(n, 2 * n), range(n, 2 * n)))\n    return x, y\n\n\ndef copy_update(data):\n    x, y = data\n    temp = x.copy()\n    temp.update(y)\n    return temp\n\n\ndef add_items(data):\n    x, y = data\n    return dict(list(x.items()) + list(y.items()))\n\n\ndef curly_star(data):\n    x, y = data\n    return {**x, **y}\n\n\ndef chain_map(data):\n    x, y = data\n    return dict(ChainMap({}, y, x))\n\n\ndef itertools_chain(data):\n    x, y = data\n    return dict(chain(x.items(), y.items()))\n\n\ndef python39_concat(data):\n    x, y = data\n    return x | y\n\n\nb = perfplot.bench(\n    setup=setup,\n    kernels=[\n        copy_update,\n        add_items,\n        curly_star,\n        chain_map,\n        itertools_chain,\n        python39_concat,\n    ],\n    labels=[\n        \"copy_update\",\n        \"dict(list(x.items()) + list(y.items()))\",\n        \"{**x, **y}\",\n        \"chain_map\",\n        \"itertools.chain\",\n        \"x | y\",\n    ],\n    n_range=[2 ** k for k in range(18)],\n    xlabel=\"len(x), len(y)\",\n    equality_check=None,\n)\nb.save(\"out.png\")\nb.show()\n \n    ", "date_posted": "2021-12-17 17:54:55Z", "upvote": "\r\n            39\r\n        ", "accepted": "No", "user": {"stack_user_id": "353337", "name": "Nico Schl\u00f6mer", "reputation_score": "48.1k"}, "answer_comments": [{"stack_answer_id": "62820532", "stack_answer_comment_id": "129098958", "comment_content": "Tried to reproduce the results, getting this error -> ", "user_id": "None"}]}, {"stack_answer_id": "12926103", "answer_content": "\r\n Two dictionaries \n\n def union2(dict1, dict2):\n    return dict(list(dict1.items()) + list(dict2.items()))\n \n\n n  dictionaries \n\n def union(*dicts):\n    return dict(itertools.chain.from_iterable(dct.items() for dct in dicts))\n \n\n sum  has bad performance. See  https://mathieularose.com/how-not-to-flatten-a-list-of-lists-in-python/ \n    ", "date_posted": "2016-10-02 18:16:17Z", "upvote": "\r\n            36\r\n        ", "accepted": "No", "user": {"stack_user_id": "122894", "name": "Mathieu Larose", "reputation_score": "1,210"}, "answer_comments": []}, {"stack_answer_id": "31812635", "answer_content": "\r\n Simple solution using itertools that preserves order (latter dicts have precedence) \n # py2\nfrom itertools import chain, imap\nmerge = lambda *args: dict(chain.from_iterable(imap(dict.iteritems, args)))\n\n# py3\nfrom itertools import chain\nmerge = lambda *args: dict(chain.from_iterable(map(dict.items, args)))\n \n And it's usage: \n >>> x = {'a':1, 'b': 2}\n>>> y = {'b':10, 'c': 11}\n>>> merge(x, y)\n{'a': 1, 'b': 10, 'c': 11}\n\n>>> z = {'c': 3, 'd': 4}\n>>> merge(x, y, z)\n{'a': 1, 'b': 10, 'c': 3, 'd': 4}\n \n    ", "date_posted": "2020-09-29 19:45:06Z", "upvote": "\r\n            33\r\n        ", "accepted": "No", "user": {"stack_user_id": "408556", "name": "reubano", "reputation_score": "4,774"}, "answer_comments": []}, {"stack_answer_id": "18114065", "answer_content": "\r\n Abuse leading to a one-expression solution for  Matthew's answer : \n\n >>> x = {'a':1, 'b': 2}\n>>> y = {'b':10, 'c': 11}\n>>> z = (lambda f=x.copy(): (f.update(y), f)[1])()\n>>> z\n{'a': 1, 'c': 11, 'b': 10}\n \n\n You said you wanted one expression, so I abused  lambda  to bind a name, and tuples to override lambda's one-expression limit. Feel free to cringe. \n\n You could also do this of course if you don't care about copying it: \n\n >>> x = {'a':1, 'b': 2}\n>>> y = {'b':10, 'c': 11}\n>>> z = (x.update(y), x)[1]\n>>> z\n{'a': 1, 'b': 10, 'c': 11}\n \n    ", "date_posted": "2017-05-23 12:34:53Z", "upvote": "\r\n            31\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}, {"stack_answer_id": "46356150", "answer_content": "\r\n If you don't mind mutating  x , \n x.update(y) or x\n \n Simple, readable, performant. You  know   update()  always returns  None , which is a false value. So the above expression will always evaluate to  x , after updating it. \n Most mutating methods in the standard library (like  .update() ) return  None  by convention, so this kind of pattern will work on those too. However, if you're using a dict subclass or some other method that doesn't follow this convention, then  or  may return its left operand, which may not be what you want. Instead, you can use a tuple display and index, which works regardless of what the first element evaluates to (although it's not quite as pretty): \n (x.update(y), x)[-1]\n \n If you don't have  x  in a variable yet, you can use  lambda  to make a local without using an assignment statement. This amounts to using  lambda  as a  let expression , which is a common technique in functional languages, but is maybe unpythonic. \n (lambda x: x.update(y) or x)({'a': 1, 'b': 2})\n \n Although it's not that different from the following use of the new walrus operator (Python 3.8+ only), \n (x := {'a': 1, 'b': 2}).update(y) or x\n \n especially if you use a default argument: \n (lambda x={'a': 1, 'b': 2}: x.update(y) or x)()\n \n If you do want a copy,  PEP 584  style  x | y  is the most Pythonic on 3.9+. If you must support older versions,  PEP 448  style  {**x, **y}  is easiest for 3.5+. But if that's not available in your (even older) Python version, the  let expression  pattern works here too. \n (lambda z=x.copy(): z.update(y) or z)()\n \n (That is, of course, nearly equivalent to  (z := x.copy()).update(y) or z , but if your Python version is new enough for that, then the PEP 448 style will be available.) \n    ", "date_posted": "2021-05-29 06:33:34Z", "upvote": "\r\n            24\r\n        ", "accepted": "No", "user": {"stack_user_id": "4381487", "name": "gilch", "reputation_score": "9,922"}, "answer_comments": []}, {"stack_answer_id": "62141222", "answer_content": "\r\n New  in Python 3.9:  Use the union operator ( | ) to merge  dict s similar to  set s: \n >>> d = {'a': 1, 'b': 2}\n>>> e = {'a': 9, 'c': 3}\n>>> d | e\n{'a': 9, 'b': 2, 'c': 3}\n \n For matching keys, the  right  dict  takes precedence . \n This also works for  |=  to modify a  dict  in-place: \n >>> e |= d    # e = e | d\n>>> e\n{'a': 1, 'c': 3, 'b': 2}\n \n    ", "date_posted": "2020-11-29 21:49:39Z", "upvote": "\r\n            21\r\n        ", "accepted": "No", "user": {"stack_user_id": "2111778", "name": "xjcl", "reputation_score": "10.1k"}, "answer_comments": [{"stack_answer_id": "62141222", "stack_answer_comment_id": "128455113", "comment_content": "What does this add that wasn't mentioned already months earlier? ", "user_id": "None"}]}, {"stack_answer_id": "17738920", "answer_content": "\r\n Drawing on ideas here and elsewhere I've comprehended a function: \n\n def merge(*dicts, **kv): \n      return { k:v for d in list(dicts) + [kv] for k,v in d.items() }\n \n\n Usage (tested in python 3): \n\n assert (merge({1:11,'a':'aaa'},{1:99, 'b':'bbb'},foo='bar')==\\\n    {1: 99, 'foo': 'bar', 'b': 'bbb', 'a': 'aaa'})\n\nassert (merge(foo='bar')=={'foo': 'bar'})\n\nassert (merge({1:11},{1:99},foo='bar',baz='quux')==\\\n    {1: 99, 'foo': 'bar', 'baz':'quux'})\n\nassert (merge({1:11},{1:99})=={1: 99})\n \n\n You could use a lambda instead. \n    ", "date_posted": "2013-07-19 05:49:19Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "375570", "name": "Bijou Trouvaille", "reputation_score": "8,016"}, "answer_comments": []}, {"stack_answer_id": "22122836", "answer_content": "\r\n It's so silly that  .update  returns nothing. \nI just use a simple helper function to solve the problem: \n\n def merge(dict1,*dicts):\n    for dict2 in dicts:\n        dict1.update(dict2)\n    return dict1\n \n\n Examples: \n\n merge(dict1,dict2)\nmerge(dict1,dict2,dict3)\nmerge(dict1,dict2,dict3,dict4)\nmerge({},dict1,dict2)  # this one returns a new copy\n \n    ", "date_posted": "2014-03-02 01:44:39Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "25700", "name": "GetFree", "reputation_score": "37.5k"}, "answer_comments": []}, {"stack_answer_id": "36263150", "answer_content": "\r\n (For Python2.7* only; there are simpler solutions for Python3*.) \n\n If you're not averse to importing a standard library module, you can do \n\n from functools import reduce\n\ndef merge_dicts(*dicts):\n    return reduce(lambda a, d: a.update(d) or a, dicts, {})\n \n\n (The  or a  bit in the  lambda  is necessary because  dict.update  always returns  None  on success.) \n    ", "date_posted": "2016-03-28 13:13:27Z", "upvote": "\r\n            18\r\n        ", "accepted": "No", "user": {"stack_user_id": "559827", "name": "kjo", "reputation_score": "31.2k"}, "answer_comments": []}, {"stack_answer_id": "20358548", "answer_content": "\r\n The problem I have with solutions listed to date is that, in the merged dictionary, the value for key \"b\" is 10 but, to my way of thinking, it should be 12.\nIn that light, I present the following: \n\n import timeit\n\nn=100000\nsu = \"\"\"\nx = {'a':1, 'b': 2}\ny = {'b':10, 'c': 11}\n\"\"\"\n\ndef timeMerge(f,su,niter):\n    print \"{:4f} sec for: {:30s}\".format(timeit.Timer(f,setup=su).timeit(n),f)\n\ntimeMerge(\"dict(x, **y)\",su,n)\ntimeMerge(\"x.update(y)\",su,n)\ntimeMerge(\"dict(x.items() + y.items())\",su,n)\ntimeMerge(\"for k in y.keys(): x[k] = k in x and x[k]+y[k] or y[k] \",su,n)\n\n#confirm for loop adds b entries together\nx = {'a':1, 'b': 2}\ny = {'b':10, 'c': 11}\nfor k in y.keys(): x[k] = k in x and x[k]+y[k] or y[k]\nprint \"confirm b elements are added:\",x\n \n\n Results: \n\n 0.049465 sec for: dict(x, **y)\n0.033729 sec for: x.update(y)                   \n0.150380 sec for: dict(x.items() + y.items())   \n0.083120 sec for: for k in y.keys(): x[k] = k in x and x[k]+y[k] or y[k]\n\nconfirm b elements are added: {'a': 1, 'c': 11, 'b': 12}\n \n    ", "date_posted": "2013-12-03 18:11:54Z", "upvote": "\r\n            17\r\n        ", "accepted": "No", "user": {"stack_user_id": "3062691", "name": "upandacross", "reputation_score": "417"}, "answer_comments": [{"stack_answer_id": "20358548", "stack_answer_comment_id": "71707374", "comment_content": "You might be interested in ", "user_id": "None"}]}, {"stack_answer_id": "54930992", "answer_content": "\r\n There will be a new option when Python 3.8 releases ( scheduled for 20 October, 2019 ), thanks to  PEP 572: Assignment Expressions . The new assignment expression operator  :=  allows you to assign the result of the  copy  and still use it to call  update , leaving the combined code a single expression, rather than two statements, changing: \n\n newdict = dict1.copy()\nnewdict.update(dict2)\n \n\n to: \n\n (newdict := dict1.copy()).update(dict2)\n \n\n while behaving identically in every way. If you must also return the resulting  dict  (you asked for an expression returning the  dict ; the above creates and assigns to  newdict , but doesn't return it, so you couldn't use it to pass an argument to a function as is, a la  myfunc((newdict := dict1.copy()).update(dict2)) ), then just add  or newdict  to the end (since  update  returns  None , which is falsy, it will then evaluate and return  newdict  as the result of the expression): \n\n (newdict := dict1.copy()).update(dict2) or newdict\n \n\n Important caveat:  In general, I'd discourage this approach in favor of: \n\n newdict = {**dict1, **dict2}\n \n\n The unpacking approach is clearer (to anyone who knows about generalized unpacking in the first place,  which you should ), doesn't require a name for the result at all (so it's much more concise when constructing a temporary that is immediately passed to a function or included in a  list / tuple  literal or the like), and is almost certainly faster as well, being (on CPython) roughly equivalent to: \n\n newdict = {}\nnewdict.update(dict1)\nnewdict.update(dict2)\n \n\n but done at the C layer, using the concrete  dict  API, so no dynamic method lookup/binding or function call dispatch overhead is involved (where  (newdict := dict1.copy()).update(dict2)  is unavoidably identical to the original two-liner in behavior, performing the work in discrete steps, with dynamic lookup/binding/invocation of methods. \n\n It's also more extensible, as merging three  dict s is obvious: \n\n  newdict = {**dict1, **dict2, **dict3}\n \n\n where using assignment expressions won't scale like that; the closest you could get would be: \n\n  (newdict := dict1.copy()).update(dict2), newdict.update(dict3)\n \n\n or without the temporary tuple of  None s, but with truthiness testing of each  None  result: \n\n  (newdict := dict1.copy()).update(dict2) or newdict.update(dict3)\n \n\n either of which is obviously much uglier, and includes further inefficiencies (either a wasted temporary  tuple  of  None s for comma separation, or pointless truthiness testing of each  update 's  None  return for  or  separation). \n\n The only real advantage to the assignment expression approach occurs if: \n\n \n You have generic code that needs handle both  set s and  dict s  (both of them support  copy  and  update , so the code works roughly as you'd expect it to) \n You expect to receive arbitrary dict-like objects , not just  dict  itself,  and must preserve the type and semantics of the left hand side  (rather than ending up with a plain  dict ). While  myspecialdict({**speciala, **specialb})  might work, it would involve an extra temporary  dict , and if  myspecialdict  has features plain  dict  can't preserve (e.g. regular  dict s now preserve order based on the first appearance of a key, and value based on the last appearance of a key; you might want one that preserves order based on the  last  appearance of a key so updating a value also moves it to the end), then the semantics would be wrong. Since the assignment expression version uses the named methods (which are presumably overloaded to behave appropriately), it never creates a  dict  at all (unless  dict1  was already a  dict ), preserving the original type (and original type's semantics), all while avoiding any temporaries. \n \n    ", "date_posted": "2019-02-28 17:49:22Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "364696", "name": "ShadowRanger", "reputation_score": "129k"}, "answer_comments": []}, {"stack_answer_id": "33999337", "answer_content": "\r\n from collections import Counter\ndict1 = {'a':1, 'b': 2}\ndict2 = {'b':10, 'c': 11}\nresult = dict(Counter(dict1) + Counter(dict2))\n \n\n This should solve your problem. \n    ", "date_posted": "2015-11-30 13:04:00Z", "upvote": "\r\n            15\r\n        ", "accepted": "No", "user": {"stack_user_id": "3145137", "name": "reetesh11", "reputation_score": "631"}, "answer_comments": [{"stack_answer_id": "33999337", "stack_answer_comment_id": "121401705", "comment_content": "I will recommend using the Counter's ", "user_id": "None"}]}, {"stack_answer_id": "31478567", "answer_content": "\r\n This can be done with a single dict comprehension: \n\n >>> x = {'a':1, 'b': 2}\n>>> y = {'b':10, 'c': 11}\n>>> { key: y[key] if key in y else x[key]\n      for key in set(x) + set(y)\n    }\n \n\n In my view the best answer for the 'single expression' part as no extra functions are needed, and it is short. \n    ", "date_posted": "2015-07-17 14:47:23Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "799163", "name": "RemcoGerlich", "reputation_score": "29.3k"}, "answer_comments": [{"stack_answer_id": "31478567", "stack_answer_comment_id": "71711009", "comment_content": "I suspect performance will not be very good though; creating a set out of each dict then only iterating through the keys means another lookup for the value each time (though relatively fast, still increases the order of the function for scaling)", "user_id": "None"}, {"stack_answer_id": "31478567", "stack_answer_comment_id": "82876896", "comment_content": "it all depends on the version of the python we are using. In 3.5 and above {**x,**y} gives the concatenated dictionary", "user_id": "None"}]}], "user": {"stack_user_id": "3207", "name": "Carl Meyer", "reputation_score": "116k"}, "question_comments": []},
{"stack_question_id": "306313", "question_title": "\"is\" operator behaves unexpectedly with integers", "question_content": "\r\n                Why does the following behave unexpectedly in Python?\n\n>>> a = 256\n>>> b = 256\n>>> a is b\nTrue           # This is an expected result\n>>> a = 257\n>>> b = ...\r\n", "question_url": "/questions/306313/is-operator-behaves-unexpectedly-with-integers", "date_posted": "Nov 20, 2008 at 18:21", "upvote": "5", "view": "9", "tags": ["python", "int", "operators", "identity", "python-internals"], "answers_count": "1", "answers": [{"stack_answer_id": "306353", "answer_content": "\r\n Take a look at this: \n\n >>> a = 256\n>>> b = 256\n>>> id(a)\n9987148\n>>> id(b)\n9987148\n>>> a = 257\n>>> b = 257\n>>> id(a)\n11662816\n>>> id(b)\n11662828\n \n\n Here's what I found in the Python 2 documentation,  \"Plain Integer Objects\"  (It's the same for  Python 3 ): \n\n \n   The current implementation keeps an\n  array of integer objects for all\n  integers between -5 and 256, when you\n  create an int in that range you\n  actually just get back a reference to\n  the existing object. So it should be\n  possible to change the value of 1. I\n  suspect the behaviour of Python in\n  this case is undefined. :-) \n \n    ", "date_posted": "2020-01-29 18:59:48Z", "upvote": "\r\n            438\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "68587", "name": "John Kugelman", "reputation_score": "335k"}, "answer_comments": [{"stack_answer_id": "306353", "stack_answer_comment_id": "78696988", "comment_content": "does anyone know how that range (-5, 256) was chosen? i wouldn't be too surprised if it were (0, 255) or even (-255, 255), but a range of 262 numbers starting at -5 seems surprisingly arbitrary.", "user_id": "None"}, {"stack_answer_id": "306353", "stack_answer_comment_id": "83937709", "comment_content": "@WoodrowBarlow: The -5 is just a heuristic to capture common negative placeholders, I think.  0..255 covers arrays of single byte values.  It\u2019s 256 that\u2019s mysterious, but I guess it\u2019s for (dis)assembling integers into/from bytes.", "user_id": "None"}, {"stack_answer_id": "306353", "stack_answer_comment_id": "89237748", "comment_content": "From what I understand the range was chosen by looking at the commonly used values across multiple projects (and multiple languages).", "user_id": "None"}, {"stack_answer_id": "306353", "stack_answer_comment_id": "89434930", "comment_content": "According to ", "user_id": "None"}, {"stack_answer_id": "306353", "stack_answer_comment_id": "122849028", "comment_content": "The note about changing the value of ", "user_id": "None"}]}, {"stack_answer_id": "28864111", "answer_content": "\r\n \n   Python's \u201cis\u201d operator behaves unexpectedly with integers? \n \n\n In summary - let me emphasize:  Do not use  is  to compare integers. \n\n This isn't behavior you should have any expectations about. \n\n Instead, use  ==  and  !=  to compare for equality and inequality, respectively. For example: \n\n >>> a = 1000\n>>> a == 1000       # Test integers like this,\nTrue\n>>> a != 5000       # or this!\nTrue\n>>> a is 1000       # Don't do this! - Don't use `is` to test integers!!\nFalse\n \n\n Explanation \n\n To know this, you need to know the following. \n\n First, what does  is  do? It is a comparison operator. From the  documentation : \n\n \n   The operators  is  and  is not  test for object identity:  x is y  is true\n  if and only if x and y are the same object.  x is not y  yields the\n  inverse truth value. \n \n\n And so the following are equivalent.  \n\n >>> a is b\n>>> id(a) == id(b)\n \n\n From the  documentation : \n\n \n   id \n  Return the \u201cidentity\u201d of an object. This is an integer (or long\n  integer) which is guaranteed to be unique and constant for this object\n  during its lifetime. Two objects with non-overlapping lifetimes may\n  have the same  id()  value. \n \n\n Note that the fact that the id of an object in CPython (the reference implementation of Python) is the location in memory is an implementation detail. Other implementations of Python (such as Jython or IronPython) could easily have a different implementation for  id . \n\n So what is the use-case for  is ?   PEP8 describes : \n\n \n   Comparisons to singletons like  None  should always be done with  is  or\n   is not , never the equality operators. \n \n\n The Question \n\n You ask, and state, the following question (with code): \n\n \n   Why does the following behave unexpectedly in Python? \n\n >>> a = 256\n>>> b = 256\n>>> a is b\nTrue           # This is an expected result\n \n \n\n It is  not  an expected result. Why is it expected? It only means that the integers valued at  256  referenced by both  a  and  b  are the same instance of integer. Integers are immutable in Python, thus they cannot change. This should have no impact on any code. It should not be expected. It is merely an implementation detail.  \n\n But perhaps we should be glad that there is not a new separate instance in memory every time we state a value equals 256.  \n\n \n >>> a = 257\n>>> b = 257\n>>> a is b\nFalse          # What happened here? Why is this False?\n \n \n\n Looks like we now have two separate instances of integers with the value of  257  in memory. Since integers are immutable, this wastes memory. Let's hope we're not wasting a lot of it. We're probably not. But this behavior is not guaranteed. \n\n \n >>> 257 is 257\nTrue           # Yet the literal numbers compare properly\n \n \n\n Well, this looks like your particular implementation of Python is trying to be smart and not creating redundantly valued integers in memory unless it has to. You seem to indicate you are using the referent implementation of Python, which is CPython. Good for CPython.  \n\n It might be even better if CPython could do this globally, if it could do so cheaply (as there would a cost in the lookup), perhaps another implementation might.  \n\n But as for impact on code, you should not care if an integer is a particular instance of an integer. You should only care what the value of that instance is, and you would use the normal comparison operators for that, i.e.  == . \n\n What  is  does \n\n is  checks that the  id  of two objects are the same. In CPython, the  id  is the location in memory, but it could be some other uniquely identifying number in another implementation. To restate this with code: \n\n >>> a is b\n \n\n is the same as \n\n >>> id(a) == id(b)\n \n\n Why would we want to use  is  then? \n\n This can be a very fast check relative to say, checking if two very long strings are equal in value. But since it applies to the uniqueness of the object, we thus have limited use-cases for it. In fact, we mostly want to use it to check for  None , which is a singleton (a sole instance existing in one place in memory). We might create other singletons if there is potential to conflate them, which we might check with  is , but these are relatively rare. Here's an example (will work in Python 2 and 3) e.g. \n\n SENTINEL_SINGLETON = object() # this will only be created one time.\n\ndef foo(keyword_argument=None):\n    if keyword_argument is None:\n        print('no argument given to foo')\n    bar()\n    bar(keyword_argument)\n    bar('baz')\n\ndef bar(keyword_argument=SENTINEL_SINGLETON):\n    # SENTINEL_SINGLETON tells us if we were not passed anything\n    # as None is a legitimate potential argument we could get.\n    if keyword_argument is SENTINEL_SINGLETON:\n        print('no argument given to bar')\n    else:\n        print('argument to bar: {0}'.format(keyword_argument))\n\nfoo()\n \n\n Which prints: \n\n no argument given to foo\nno argument given to bar\nargument to bar: None\nargument to bar: baz\n \n\n And so we see, with  is  and a sentinel, we are able to differentiate between when  bar  is called with no arguments and when it is called with  None . These are the primary use-cases for  is  - do  not  use it to test for equality of integers, strings, tuples, or other things like these. \n    ", "date_posted": "2017-09-09 20:02:03Z", "upvote": "\r\n            147\r\n        ", "accepted": "No", "user": {"stack_user_id": "541136", "name": "Russia Must Remove Putin", "reputation_score": "347k"}, "answer_comments": [{"stack_answer_id": "28864111", "stack_answer_comment_id": "98590248", "comment_content": "\"These are the primary use-cases for ", "user_id": "None"}, {"stack_answer_id": "28864111", "stack_answer_comment_id": "98590866", "comment_content": "@Alexey sounds like you need enums? ", "user_id": "None"}, {"stack_answer_id": "28864111", "stack_answer_comment_id": "98591512", "comment_content": "Maybe, thanks, didn't know of them. This could be an appropriate addition to you answer IMO.", "user_id": "None"}, {"stack_answer_id": "28864111", "stack_answer_comment_id": "98591718", "comment_content": "Maybe using a number of dumb objects like the sentinel in your answer would be a more lightweight solution...", "user_id": "None"}, {"stack_answer_id": "28864111", "stack_answer_comment_id": "125042249", "comment_content": "@MarkRansom Don't use ", "user_id": "None"}]}, {"stack_answer_id": "34964030", "answer_content": "\r\n\n I'm late but, you want some source with your answer?  I'll try and word this in an introductory manner so more folks can follow along. \n \n A good thing about CPython is that you can actually see the source for this. I'm going to use links for the  3.5  release, but finding the corresponding  2.x  ones is trivial. \n In CPython, the  C-API  function that handles creating a new  int  object is  PyLong_FromLong(long v) . The description for this function is: \n \n The current implementation keeps an array of integer objects for all integers between -5 and 256, when you create an int in that range you actually just get back a reference to the existing object . So it should be possible to change the value of 1. I suspect the behaviour of Python in this case is undefined. :-) \n \n (My italics) \n Don't know about you but I see this and think:  Let's find that array! \n If you haven't fiddled with the C code implementing CPython  you should ; everything is pretty organized and readable. For our case, we need to look in the  Objects  subdirectory  of the  main source code directory tree . \n PyLong_FromLong  deals with  long  objects so it shouldn't be hard to deduce that we need to peek inside  longobject.c . After looking inside you might think things are chaotic; they are, but fear not, the function we're looking for is chilling at  line 230  waiting for us to check it out. It's a smallish function so the main body (excluding declarations) is easily pasted here: \n PyObject *\nPyLong_FromLong(long ival)\n{\n    // omitting declarations\n\n    CHECK_SMALL_INT(ival);\n\n    if (ival < 0) {\n        /* negate: cant write this as abs_ival = -ival since that\n           invokes undefined behaviour when ival is LONG_MIN */\n        abs_ival = 0U-(unsigned long)ival;\n        sign = -1;\n    }\n    else {\n        abs_ival = (unsigned long)ival;\n    }\n\n    /* Fast path for single-digit ints */\n    if (!(abs_ival >> PyLong_SHIFT)) {\n        v = _PyLong_New(1);\n        if (v) {\n            Py_SIZE(v) = sign;\n            v->ob_digit[0] = Py_SAFE_DOWNCAST(\n                abs_ival, unsigned long, digit);\n        }\n        return (PyObject*)v; \n}\n \n Now, we're no C  master-code-haxxorz  but we're also not dumb, we can see that  CHECK_SMALL_INT(ival);  peeking at us all seductively; we can understand it has something to do with this.  Let's check it out: \n #define CHECK_SMALL_INT(ival) \\\n    do if (-NSMALLNEGINTS <= ival && ival < NSMALLPOSINTS) { \\\n        return get_small_int((sdigit)ival); \\\n    } while(0)\n \n So it's a macro that calls function  get_small_int  if the value  ival  satisfies the condition: \n if (-NSMALLNEGINTS <= ival && ival < NSMALLPOSINTS)\n \n So what are  NSMALLNEGINTS  and  NSMALLPOSINTS ? Macros!  Here they are : \n #ifndef NSMALLPOSINTS\n#define NSMALLPOSINTS           257\n#endif\n#ifndef NSMALLNEGINTS\n#define NSMALLNEGINTS           5\n#endif\n \n So our condition is  if (-5 <= ival && ival < 257)  call  get_small_int . \n Next let's look at  get_small_int  in all its glory  (well, we'll just look at its body because that's where the interesting things are): \n PyObject *v;\nassert(-NSMALLNEGINTS <= ival && ival < NSMALLPOSINTS);\nv = (PyObject *)&small_ints[ival + NSMALLNEGINTS];\nPy_INCREF(v);\n \n Okay, declare a  PyObject , assert that the previous condition holds and execute the assignment: \n v = (PyObject *)&small_ints[ival + NSMALLNEGINTS];\n \n small_ints  looks a lot like that array we've been searching for, and it is!  We could've just read the damn documentation and we would've know all along! : \n /* Small integers are preallocated in this array so that they\n   can be shared.\n   The integers that are preallocated are those in the range\n   -NSMALLNEGINTS (inclusive) to NSMALLPOSINTS (not inclusive).\n*/\nstatic PyLongObject small_ints[NSMALLNEGINTS + NSMALLPOSINTS];\n \n So yup, this is our guy. When you want to create a new  int  in the range  [NSMALLNEGINTS, NSMALLPOSINTS)  you'll just get back a reference to an already existing object that has been preallocated. \n Since the reference refers to the same object, issuing  id()  directly or checking for identity with  is  on it will return exactly the same thing. \n But, when are they allocated?? \n During initialization in  _PyLong_Init  Python will gladly enter in a for loop to do this for you: \n for (ival = -NSMALLNEGINTS; ival <  NSMALLPOSINTS; ival++, v++) {\n \n Check out the source to read the loop body! \n I hope my explanation has made you  C  things clearly now (pun obviously intented). \n \n But,  257 is 257 ? What's up? \n This is actually easier to explain,  and I have attempted to do so already ; it's due to the fact that Python will execute this interactive statement as a single block: \n >>> 257 is 257\n \n During complilation of this statement, CPython will see that you have two matching literals and will use the same  PyLongObject  representing  257 . You can see this if you do the compilation yourself and examine its contents: \n >>> codeObj = compile(\"257 is 257\", \"blah!\", \"exec\")\n>>> codeObj.co_consts\n(257, None)\n \n When CPython does the operation, it's now just going to load the exact same object: \n >>> import dis\n>>> dis.dis(codeObj)\n  1           0 LOAD_CONST               0 (257)   # dis\n              3 LOAD_CONST               0 (257)   # dis again\n              6 COMPARE_OP               8 (is)\n \n So  is  will return  True . \n    ", "date_posted": "2021-03-18 16:08:30Z", "upvote": "\r\n            71\r\n        ", "accepted": "No", "user": {"stack_user_id": "2326961", "name": "Maggyero", "reputation_score": "4,880"}, "answer_comments": []}, {"stack_answer_id": "306377", "answer_content": "\r\n It depends on whether you're looking to see if 2 things are equal, or the same object.  \n\n is  checks to see if they are the same object, not just equal. The small ints are probably pointing to the same memory location for space efficiency  \n\n In [29]: a = 3\nIn [30]: b = 3\nIn [31]: id(a)\nOut[31]: 500729144\nIn [32]: id(b)\nOut[32]: 500729144\n \n\n You should use  ==  to compare equality of arbitrary objects. You can specify the behavior with the  __eq__ , and  __ne__  attributes. \n    ", "date_posted": "2017-04-24 02:20:18Z", "upvote": "\r\n            61\r\n        ", "accepted": "No", "user": {"stack_user_id": "2470818", "name": "vallentin", "reputation_score": "21.7k"}, "answer_comments": []}, {"stack_answer_id": "306603", "answer_content": "\r\n As you can check in  source file  intobject.c , Python caches small integers for efficiency. Every time you create a reference to a small integer, you are referring the cached small integer, not a new object. 257 is not an small integer, so it is calculated as a different object. \n\n It is better to use  ==  for that purpose. \n    ", "date_posted": "2017-04-24 02:20:25Z", "upvote": "\r\n            38\r\n        ", "accepted": "No", "user": {"stack_user_id": "2470818", "name": "vallentin", "reputation_score": "21.7k"}, "answer_comments": []}, {"stack_answer_id": "306347", "answer_content": "\r\n I think your hypotheses is correct. Experiment with  id  (identity of object): \n\n In [1]: id(255)\nOut[1]: 146349024\n\nIn [2]: id(255)\nOut[2]: 146349024\n\nIn [3]: id(257)\nOut[3]: 146802752\n\nIn [4]: id(257)\nOut[4]: 148993740\n\nIn [5]: a=255\n\nIn [6]: b=255\n\nIn [7]: c=257\n\nIn [8]: d=257\n\nIn [9]: id(a), id(b), id(c), id(d)\nOut[9]: (146349024, 146349024, 146783024, 146804020)\n \n\n It appears that numbers  <= 255  are treated as literals and anything above is treated differently! \n    ", "date_posted": "2017-02-08 10:12:22Z", "upvote": "\r\n            21\r\n        ", "accepted": "No", "user": {"stack_user_id": "4952130", "name": "Dimitris Fasarakis Hilliard", "reputation_score": "139k"}, "answer_comments": [{"stack_answer_id": "306347", "stack_answer_comment_id": "89237899", "comment_content": "It is because objects representing values from -5 to +256 are created at Startup time - and so all use of those value use to prebuilt object. Almost all references to integers outside that range create a new internal object each time they are referenced. I think the use of the term literal is confusing - literal normally refers to any value that is typed in a piece of code - so all number in the source code are literals.", "user_id": "None"}]}, {"stack_answer_id": "49472348", "answer_content": "\r\n There's another issue that isn't pointed out in any of the existing answers. Python is allowed to merge any two immutable values, and pre-created small int values are not the only way this can happen. A Python implementation is never  guaranteed  to do this, but they all do it for more than just small ints. \n\n \n\n For one thing, there are some other pre-created values, such as the empty  tuple ,  str , and  bytes , and some short strings (in CPython 3.6, it's the 256 single-character Latin-1 strings). For example: \n\n >>> a = ()\n>>> b = ()\n>>> a is b\nTrue\n \n\n \n\n But also, even non-pre-created values can be identical. Consider these examples: \n\n >>> c = 257\n>>> d = 257\n>>> c is d\nFalse\n>>> e, f = 258, 258\n>>> e is f\nTrue\n \n\n And this isn't limited to  int  values: \n\n >>> g, h = 42.23e100, 42.23e100\n>>> g is h\nTrue\n \n\n Obviously, CPython doesn't come with a pre-created  float  value for  42.23e100 . So, what's going on here? \n\n The CPython compiler will merge constant values of some known-immutable types like  int ,  float ,  str ,  bytes ,  in the same compilation unit. For a module, the whole module is a compilation unit, but at the interactive interpreter, each statement is a separate compilation unit. Since  c  and  d  are defined in separate statements, their values aren't merged. Since  e  and  f  are defined in the same statement, their values are merged. \n\n \n\n You can see what's going on by disassembling the bytecode. Try defining a function that does  e, f = 128, 128  and then calling  dis.dis  on it, and you'll see that there's a single constant value  (128, 128) \n\n >>> def f(): i, j = 258, 258\n>>> dis.dis(f)\n  1           0 LOAD_CONST               2 ((128, 128))\n              2 UNPACK_SEQUENCE          2\n              4 STORE_FAST               0 (i)\n              6 STORE_FAST               1 (j)\n              8 LOAD_CONST               0 (None)\n             10 RETURN_VALUE\n>>> f.__code__.co_consts\n(None, 128, (128, 128))\n>>> id(f.__code__.co_consts[1], f.__code__.co_consts[2][0], f.__code__.co_consts[2][1])\n4305296480, 4305296480, 4305296480\n \n\n \n\n You may notice that the compiler has stored  128  as a constant even though it's not actually used by the bytecode, which gives you an idea of how little optimization CPython's compiler does. Which means that (non-empty) tuples actually don't end up merged: \n\n >>> k, l = (1, 2), (1, 2)\n>>> k is l\nFalse\n \n\n Put that in a function,  dis  it, and look at the  co_consts \u2014there's a  1  and a  2 , two  (1, 2)  tuples that share the same  1  and  2  but are not identical, and a  ((1, 2), (1, 2))  tuple that has the two distinct equal tuples. \n\n \n\n There's one more optimization that CPython does: string interning. Unlike compiler constant folding, this isn't restricted to source code literals: \n\n >>> m = 'abc'\n>>> n = 'abc'\n>>> m is n\nTrue\n \n\n On the other hand, it is limited to the  str  type, and to strings of  internal storage kind \"ascii compact\", \"compact\", or \"legacy ready\" , and in many cases only \"ascii compact\" will get interned. \n\n \n\n At any rate, the rules for what values must be, might be, or cannot be distinct vary from implementation to implementation, and between versions of the same implementation, and maybe even between runs of the same code on the same copy of the same implementation. \n\n It can be worth learning the rules for one specific Python for the fun of it. But it's not worth relying on them in your code. The only safe rule is: \n\n \n Do not write code that assumes two equal but separately-created immutable values are identical (don't use  x is y , use  x == y ) \n Do not write code that assumes two equal but separately-created immutable values are distinct (don't use  x is not y , use  x != y ) \n \n\n Or, in other words, only use  is  to test for the documented singletons (like  None ) or that are only created in one place in the code (like the  _sentinel = object()  idiom). \n    ", "date_posted": "2020-03-09 06:40:04Z", "upvote": "\r\n            15\r\n        ", "accepted": "No", "user": {"stack_user_id": "202229", "name": "smci", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "49472348", "stack_answer_comment_id": "107203132", "comment_content": "The less cryptic advice is simply: don't use ", "user_id": "None"}, {"stack_answer_id": "49472348", "stack_answer_comment_id": "110073088", "comment_content": "So looking at ", "user_id": "None"}]}, {"stack_answer_id": "307594", "answer_content": "\r\n For immutable value objects, like ints, strings or datetimes, object identity is not especially useful. It's better to think about equality. Identity is essentially an implementation detail for value objects - since they're immutable, there's no effective difference between having multiple refs to the same object or multiple objects. \n    ", "date_posted": "2008-11-21 01:58:53Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "38851", "name": "babbageclunk", "reputation_score": "8,275"}, "answer_comments": []}, {"stack_answer_id": "15522094", "answer_content": "\r\n is   is  the identity equality operator (functioning like  id(a) == id(b) ); it's just that two equal numbers aren't necessarily the same object. For performance reasons some small integers happen to be  memoized  so they will tend to be the same (this can be done since they are immutable). \n\n PHP's   ===  operator, on the other hand, is described as checking equality and type:  x == y and type(x) == type(y)  as per Paulo Freitas' comment. This will suffice for common numbers, but differ from  is  for classes that define  __eq__  in an absurd manner: \n\n class Unequal:\n    def __eq__(self, other):\n        return False\n \n\n PHP apparently allows the same thing for \"built-in\" classes (which I take to mean implemented at C level, not in PHP). A slightly less absurd use might be a timer object, which has a different value every time it's used as a number. Quite why you'd want to emulate Visual Basic's  Now  instead of showing that it is an evaluation with  time.time()  I don't know. \n\n Greg Hewgill (OP) made one clarifying comment \"My goal is to compare object identity, rather than equality of value. Except for numbers, where I want to treat object identity the same as equality of value.\" \n\n This would have yet another answer, as we have to categorize things as numbers or not, to select whether we compare with  ==  or  is .  CPython  defines the  number protocol , including PyNumber_Check, but this is not accessible from Python itself. \n\n We could try to use  isinstance  with all the number types we know of, but this would inevitably be incomplete. The types module contains a StringTypes list but no NumberTypes. Since Python 2.6, the built in number classes have a base class  numbers.Number , but it has the same problem: \n\n import numpy, numbers\nassert not issubclass(numpy.int16,numbers.Number)\nassert issubclass(int,numbers.Number)\n \n\n By the way,  NumPy  will produce separate instances of low numbers. \n\n I don't actually know an answer to this variant of the question. I suppose one could theoretically use ctypes to call  PyNumber_Check , but even that function  has been debated , and it's certainly not portable. We'll just have to be less particular about what we test for now. \n\n In the end, this issue stems from Python not originally having a type tree with predicates like  Scheme's   number? , or  Haskell's   type class   Num .  is  checks object identity, not value equality. PHP has a colorful history as well, where  ===  apparently behaves as  is  only on objects  in PHP5, but not PHP4 . Such are the growing pains of moving across languages (including versions of one). \n    ", "date_posted": "2015-11-12 11:52:54Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "379311", "name": "Yann Vernier", "reputation_score": "14.9k"}, "answer_comments": []}, {"stack_answer_id": "33130014", "answer_content": "\r\n It also happens with strings: \n\n >>> s = b = 'somestr'\n>>> s == b, s is b, id(s), id(b)\n(True, True, 4555519392, 4555519392)\n \n\n Now everything seems fine. \n\n >>> s = 'somestr'\n>>> b = 'somestr'\n>>> s == b, s is b, id(s), id(b)\n(True, True, 4555519392, 4555519392)\n \n\n That's expected too. \n\n >>> s1 = b1 = 'somestrdaasd ad ad asd as dasddsg,dlfg ,;dflg, dfg a'\n>>> s1 == b1, s1 is b1, id(s1), id(b1)\n(True, True, 4555308080, 4555308080)\n\n>>> s1 = 'somestrdaasd ad ad asd as dasddsg,dlfg ,;dflg, dfg a'\n>>> b1 = 'somestrdaasd ad ad asd as dasddsg,dlfg ,;dflg, dfg a'\n>>> s1 == b1, s1 is b1, id(s1), id(b1)\n(True, False, 4555308176, 4555308272)\n \n\n Now that's unexpected. \n    ", "date_posted": "2015-10-14 15:53:05Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "4842742", "name": "sobolevn", "reputation_score": "15.2k"}, "answer_comments": [{"stack_answer_id": "33130014", "stack_answer_comment_id": "56385375", "comment_content": "Happened upon this - agreed, that even weirder.  So I played with it, and it's weirder yet - related to the space.  For example, the string ", "user_id": "None"}, {"stack_answer_id": "33130014", "stack_answer_comment_id": "66570944", "comment_content": "That's because it looks like a symbol if there's no space in it. Names are automatically interned, so if there's anything named ", "user_id": "None"}]}, {"stack_answer_id": "57641343", "answer_content": "\r\n What\u2019s New In Python 3.8: Changes in Python behavior : \n\n \n   The compiler now produces a  SyntaxWarning  when identity checks ( is  and\n   is not ) are used with certain types of literals (e.g. strings, ints).\n  These can often work by accident in CPython, but are not guaranteed by\n  the language spec. The warning advises users to use equality tests ( == \n  and  != ) instead. \n \n    ", "date_posted": "2019-11-11 21:21:47Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "2420341", "name": "cclauss", "reputation_score": "505"}, "answer_comments": []}], "user": {"stack_user_id": "893", "name": "Greg Hewgill", "reputation_score": "903k"}, "question_comments": [{"stack_question_id": "306313", "stack_question_comment_id": "99214572", "comment_content": "Take a look ", "user_id": "None"}, {"stack_question_id": "306313", "stack_question_comment_id": "99499964", "comment_content": "This is a CPython-specific implementation detail and a undefined behavior, use with cautions", "user_id": "None"}, {"stack_question_id": "306313", "stack_question_comment_id": "122294396", "comment_content": "Does this answer your question? ", "user_id": "None"}]},
{"stack_question_id": "394809", "question_title": "Does Python have a ternary conditional operator?", "question_content": "\r\n                Is there a ternary conditional operator in Python?\r\n", "question_url": "/questions/394809/does-python-have-a-ternary-conditional-operator", "date_posted": null, "upvote": "7", "view": "2", "tags": ["python", "operators", "conditional-operator"], "answers_count": "3", "answers": [{"stack_answer_id": "394814", "answer_content": "\r\n Yes, it was  added  in version 2.5. The expression syntax is: \n a if condition else b\n \n First  condition  is evaluated, then exactly one of either  a  or  b  is evaluated and returned based on the  Boolean  value of  condition . If  condition  evaluates to  True , then  a  is evaluated and returned but  b  is ignored, or else when  b  is evaluated and returned but  a  is ignored. \n This allows short-circuiting because when  condition  is true only  a  is evaluated and  b  is not evaluated at all, but when  condition  is false only  b  is evaluated and  a  is not evaluated at all. \n For example: \n >>> 'true' if True else 'false'\n'true'\n>>> 'true' if False else 'false'\n'false'\n \n Note that conditionals are an  expression , not a  statement . This means you can't use assignment statements or  pass  or other  statements  within a conditional  expression : \n >>> pass if False else x = 3\n  File \"<stdin>\", line 1\n    pass if False else x = 3\n          ^\nSyntaxError: invalid syntax\n \n You can, however, use conditional expressions to assign a variable like so: \n x = a if True else b\n \n Think of the conditional expression as switching between two values. It is very useful when you're in a 'one value or another' situation, but it doesn't do much else. \n If you need to use statements, you have to use a normal  if   statement  instead of a conditional  expression . \n \n Keep in mind that it's frowned upon by some Pythonistas for several reasons: \n \n The order of the arguments is different from those of the classic  condition ? a : b  ternary operator from many other languages (such as  C ,  C++ ,  Go ,  Perl ,  Ruby ,  Java ,  JavaScript , etc.), which may lead to bugs when people unfamiliar with Python's \"surprising\" behaviour use it (they may reverse the argument order). \n Some find it \"unwieldy\", since it goes contrary to the normal flow of thought (thinking of the condition first and then the effects). \n Stylistic reasons. (Although the 'inline  if ' can be  really  useful, and make your script more concise, it really does complicate your code) \n \n If you're having trouble remembering the order, then remember that when read aloud, you (almost) say what you mean. For example,  x = 4 if b > 8 else 9  is read aloud as  x will be 4 if b is greater than 8 otherwise 9 . \n Official documentation: \n \n Conditional expressions \n Is there an equivalent of C\u2019s \u201d?:\u201d ternary operator? \n \n    ", "date_posted": "2022-06-03 22:21:26Z", "upvote": "\r\n            8586\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "394814", "name": "\r\n        22 revs, 18 users 18%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "394814", "stack_answer_comment_id": "57719599", "comment_content": "The order may seems strange for coders however ", "user_id": "None"}, {"stack_answer_id": "394814", "stack_answer_comment_id": "59317179", "comment_content": "Be careful with order of operations when using this. For example, the line ", "user_id": "None"}, {"stack_answer_id": "394814", "stack_answer_comment_id": "60867668", "comment_content": "The point was if you want to perform additional evaluations ", "user_id": "None"}, {"stack_answer_id": "394814", "stack_answer_comment_id": "78209851", "comment_content": "@MrGeek, I see what you mean, so you would basically be nesting the operations: ` \"foo\" if Bool else (\"bar\" if Bool else \"foobar\") `", "user_id": "None"}, {"stack_answer_id": "394814", "stack_answer_comment_id": "88793385", "comment_content": "Programmers need precise correct formulation even more than mathematician, because in mathematics there is always a resort to underlying concepts. A convincing argument  is the % operator, mimicking the way \"mod\" is used in math would have been a disaster.  So no, I don't accept your argument. It is like adhering to imperial units. Groetjes Albert", "user_id": "None"}]}, {"stack_answer_id": "470376", "answer_content": "\r\n You can index into a tuple: \n\n (falseValue, trueValue)[test]\n \n\n test  needs to return  True  or  False . \nIt might be safer to always implement it as: \n\n (falseValue, trueValue)[test == True]\n \n\n or you can use the built-in  bool()  to assure a  Boolean  value: \n\n (falseValue, trueValue)[bool(<expression>)]\n \n    ", "date_posted": "2015-10-17 07:35:10Z", "upvote": "\r\n            955\r\n        ", "accepted": "No", "user": {"stack_user_id": "470376", "name": "\r\n        Landon Kuhn\r\n        ", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "470376", "stack_answer_comment_id": "5445970", "comment_content": "Note that this one always evaluates everything, whereas the if/else construct only evaluates the winning expression.", "user_id": "None"}, {"stack_answer_id": "470376", "stack_answer_comment_id": "12212868", "comment_content": " ", "user_id": "None"}, {"stack_answer_id": "470376", "stack_answer_comment_id": "14113335", "comment_content": "It should be noted that what's within the ", "user_id": "None"}, {"stack_answer_id": "470376", "stack_answer_comment_id": "59136440", "comment_content": "I've done a similar trick -- only once or twice, but done it -- by indexing into a dictionary with ", "user_id": "None"}, {"stack_answer_id": "470376", "stack_answer_comment_id": "61540187", "comment_content": " ", "user_id": "None"}]}, {"stack_answer_id": "394887", "answer_content": "\r\n For versions prior to 2.5, there's the trick: \n [expression] and [on_true] or [on_false]\n \n It can give wrong results when  on_true  has a false Boolean value. 1 \n Although it does have the benefit of evaluating expressions left to right, which is clearer in my opinion. \n 1.  Is there an equivalent of C\u2019s \u201d?:\u201d ternary operator? \n    ", "date_posted": "2022-02-06 12:19:50Z", "upvote": "\r\n            420\r\n        ", "accepted": "No", "user": {"stack_user_id": "394887", "name": "\r\n        4 revs, 4 users 35%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "394887", "stack_answer_comment_id": "1466794", "comment_content": "The remedy is to use (test and [true_value] or [false_value])[0], which avoids this trap.", "user_id": "None"}, {"stack_answer_id": "394887", "stack_answer_comment_id": "31716349", "comment_content": "Ternary operator usually executes faster(sometimes by 10-25%).", "user_id": "None"}, {"stack_answer_id": "394887", "stack_answer_comment_id": "39130413", "comment_content": "@volcano Do you have source for me?", "user_id": "None"}, {"stack_answer_id": "394887", "stack_answer_comment_id": "85745604", "comment_content": "@OrangeTux ", "user_id": "None"}]}, {"stack_answer_id": "2919360", "answer_content": "\r\n   <expression 1>   if   <condition>   else   <expression 2>   \n\n a = 1\nb = 2\n\n1 if a > b else -1 \n# Output is -1\n\n1 if a > b else -1 if a < b else 0\n# Output is -1\n \n    ", "date_posted": "2019-05-15 15:03:41Z", "upvote": "\r\n            334\r\n        ", "accepted": "No", "user": {"stack_user_id": "2919360", "name": "\r\n        3 revs, 2 users 62%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "2919360", "stack_answer_comment_id": "4103349", "comment_content": "This one emphasizes the primary intent of the ternary operator: value selection. It also shows that more than one ternary can be chained together into a single expression.", "user_id": "None"}, {"stack_answer_id": "2919360", "stack_answer_comment_id": "42951997", "comment_content": "@Craig , I agree, but it's also helpful to know what will happen when there are no parentheses. In real code, I too would tend to insert explicit parens.", "user_id": "None"}, {"stack_answer_id": "2919360", "stack_answer_comment_id": "114095475", "comment_content": "Use: ", "user_id": "None"}]}, {"stack_answer_id": "394815", "answer_content": "\r\n From  the documentation : \n\n \n   Conditional expressions (sometimes called a \u201cternary operator\u201d) have the lowest priority of all Python operations. \n  \n   The expression  x if C else y  first evaluates the condition,  C  ( not x ); if  C  is true,  x  is evaluated and its value is returned; otherwise,  y  is evaluated and its value is returned. \n  \n   See  PEP 308  for more details about conditional expressions. \n \n\n New since version 2.5. \n    ", "date_posted": "2015-10-17 07:43:53Z", "upvote": "\r\n            195\r\n        ", "accepted": "No", "user": {"stack_user_id": "394815", "name": "\r\n        Michael Burr\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "30052371", "answer_content": "\r\n An operator for a conditional expression in Python was added in 2006 as part of  Python Enhancement Proposal 308 . Its form differ from common  ?:  operator and it's: \n\n <expression1> if <condition> else <expression2>\n \n\n which is equivalent to: \n\n if <condition>: <expression1> else: <expression2>\n \n\n Here is an example: \n\n result = x if a > b else y\n \n\n Another syntax which can be used (compatible with versions before 2.5): \n\n result = (lambda:y, lambda:x)[a > b]()\n \n\n where operands are  lazily evaluated . \n\n Another way is by indexing a tuple (which isn't consistent with the conditional operator of most other languages): \n\n result = (y, x)[a > b]\n \n\n or explicitly constructed dictionary: \n\n result = {True: x, False: y}[a > b]\n \n\n Another (less reliable), but simpler method is to use  and  and  or  operators: \n\n result = (a > b) and x or y\n \n\n however this won't work if  x  would be  False . \n\n A possible workaround is to make  x  and  y  lists or tuples as in the following: \n\n result = ((a > b) and [x] or [y])[0]\n \n\n or: \n\n result = ((a > b) and (x,) or (y,))[0]\n \n\n If you're working with dictionaries, instead of using a ternary conditional, you can take advantage of  get(key, default) , for example: \n\n shell = os.environ.get('SHELL', \"/bin/sh\")\n \n\n Source:  ?: in Python at Wikipedia \n    ", "date_posted": "2017-08-07 14:22:32Z", "upvote": "\r\n            159\r\n        ", "accepted": "No", "user": {"stack_user_id": "30052371", "name": "\r\n        2 revs, 2 users 98%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "30052371", "stack_answer_comment_id": "96013109", "comment_content": " is another possible variant (", "user_id": "None"}]}, {"stack_answer_id": "1855173", "answer_content": "\r\n Unfortunately, the \n (falseValue, trueValue)[test]\n \n solution doesn't have short-circuit behaviour; thus both  falseValue  and  trueValue  are evaluated regardless of the condition. This could be suboptimal or even buggy (i.e. both  trueValue  and  falseValue  could be methods and have side effects). \n One solution to this would be \n (lambda: falseValue, lambda: trueValue)[test]()\n \n (execution delayed until the winner is known ;)), but it introduces inconsistency between callable and non-callable objects. In addition, it doesn't solve the case when using properties. \n And so the story goes - choosing between three mentioned solutions is a trade-off between having the short-circuit feature, using at least Python 2.5 (IMHO, not a problem anymore) and not being prone to \" trueValue -evaluates-to-false\" errors. \n    ", "date_posted": "2022-02-06 12:22:50Z", "upvote": "\r\n            118\r\n        ", "accepted": "No", "user": {"stack_user_id": "1855173", "name": "\r\n        6 revs, 5 users 67%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "1855173", "stack_answer_comment_id": "92454573", "comment_content": "While the tuple of lambdas trick works, it takes roughly 3x as long as the ternary operator.  It's only likely to be a reasonable idea if it can replace a long chain of ", "user_id": "None"}]}, {"stack_answer_id": "39067220", "answer_content": "\r\n Ternary operator in different programming languages \n Here I just try to show some important differences in the  ternary operator  between a couple of programming languages. \n Ternary operator in  JavaScript \n var a = true ? 1 : 0;\n# 1\nvar b = false ? 1 : 0;\n# 0\n \n Ternary operator in  Ruby \n a = true ? 1 : 0\n# 1\nb = false ? 1 : 0\n# 0\n \n Ternary operator in  Scala \n val a = true ? 1 | 0\n# 1\nval b = false ? 1 | 0\n# 0\n \n Ternary operator in  R  programming \n a <- if (TRUE) 1 else 0\n# 1\nb <- if (FALSE) 1 else 0\n# 0\n \n Ternary operator in Python \n a = 1 if True else 0\n# 1\nb = 1 if False else 0\n# 0\n \n    ", "date_posted": "2022-02-06 12:47:23Z", "upvote": "\r\n            94\r\n        ", "accepted": "No", "user": {"stack_user_id": "39067220", "name": "\r\n        5 revs, 4 users 78%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "39067220", "stack_answer_comment_id": "71681244", "comment_content": "This ", "user_id": "None"}, {"stack_answer_id": "39067220", "stack_answer_comment_id": "83365814", "comment_content": "It may sound opinionated; but what it essentially says is that it the Python syntax is likely to be understood by a person who never saw a ternary operator, while very few people will understand the more usual syntax unless they have been told first what it means.", "user_id": "None"}, {"stack_answer_id": "39067220", "stack_answer_comment_id": "88793454", "comment_content": "Algol68:  a=.if. .true. .then. 1 .else. 0 .fi. This may be expressed also a=(.true.|1|0)  As usual Algol68 is an improvement over its successors.", "user_id": "None"}, {"stack_answer_id": "39067220", "stack_answer_comment_id": "114386996", "comment_content": "something simple as ", "user_id": "None"}, {"stack_answer_id": "39067220", "stack_answer_comment_id": "114654346", "comment_content": "@VarunGarg But of course you can say ", "user_id": "None"}]}, {"stack_answer_id": "10314837", "answer_content": "\r\n For Python 2.5 and newer there is a specific syntax: \n\n [on_true] if [cond] else [on_false]\n \n\n In older Pythons a ternary operator is not implemented but it's possible to simulate it. \n\n cond and on_true or on_false\n \n\n Though, there is a potential problem, which if  cond  evaluates to  True  and  on_true  evaluates to  False  then  on_false  is returned instead of  on_true . If you want this behavior the method is OK, otherwise use this: \n\n {True: on_true, False: on_false}[cond is True] # is True, not == True\n \n\n which can be wrapped by: \n\n def q(cond, on_true, on_false)\n    return {True: on_true, False: on_false}[cond is True]\n \n\n and used this way: \n\n q(cond, on_true, on_false)\n \n\n It is compatible with all Python versions. \n    ", "date_posted": "2012-04-25 12:02:06Z", "upvote": "\r\n            79\r\n        ", "accepted": "No", "user": {"stack_user_id": "10314837", "name": "\r\n        Paolo\r\n        ", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "10314837", "stack_answer_comment_id": "16979616", "comment_content": "The behaviour is not identical - ", "user_id": "None"}, {"stack_answer_id": "10314837", "stack_answer_comment_id": "29624617", "comment_content": "Why not ", "user_id": "None"}]}, {"stack_answer_id": "14321907", "answer_content": "\r\n You might often find \n cond and on_true or on_false\n \n but this leads to a problem when on_true == 0 \n >>> x = 0\n>>> print x == 0 and 0 or 1\n1\n>>> x = 1\n>>> print x == 0 and 0 or 1\n1\n \n Where you would expect this result for a normal ternary operator: \n >>> x = 0\n>>> print 0 if x == 0 else 1\n0\n>>> x = 1\n>>> print 0 if x == 0 else 1\n1\n \n    ", "date_posted": "2022-04-01 17:25:19Z", "upvote": "\r\n            56\r\n        ", "accepted": "No", "user": {"stack_user_id": "14321907", "name": "\r\n        3 revs, 3 users 64%", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "33765206", "answer_content": "\r\n \n Does Python have a ternary conditional operator? \n \n Yes. From the  grammar file : \n test: or_test ['if' or_test 'else' test] | lambdef\n \n The part of interest is: \n or_test ['if' or_test 'else' test]\n \n So, a ternary conditional operation is of the form: \n expression1 if expression2 else expression3\n \n expression3  will be lazily evaluated (that is, evaluated only if  expression2  is false in a boolean context). And because of the recursive definition, you can chain them indefinitely (though it may considered bad style.) \n expression1 if expression2 else expression3 if expression4 else expression5 # and so on\n \n A note on usage: \n Note that every  if  must be followed with an  else . People learning list comprehensions and generator expressions may find this to be a difficult lesson to learn - the following will not work, as Python expects a third expression for an else: \n [expression1 if expression2 for element in iterable]\n#                          ^-- need an else here\n \n which raises a  SyntaxError: invalid syntax .\nSo the above is either an incomplete piece of logic (perhaps the user expects a no-op in the false condition) or what may be intended is to use  expression2  as a filter - notes that the following is legal Python: \n [expression1 for element in iterable if expression2]\n \n expression2  works as a filter for the list comprehension, and is  not  a ternary conditional operator. \n Alternative syntax for a more narrow case: \n You may find it somewhat painful to write the following: \n expression1 if expression1 else expression2\n \n expression1  will have to be evaluated twice with the above usage. It can limit redundancy if it is simply a local variable. However, a common and performant Pythonic idiom for this use-case is to use  or 's shortcutting behavior: \n expression1 or expression2\n \n which is equivalent in semantics. Note that some style-guides may limit this usage on the grounds of clarity - it does pack a lot of meaning into very little syntax. \n    ", "date_posted": "2022-04-01 17:30:21Z", "upvote": "\r\n            50\r\n        ", "accepted": "No", "user": {"stack_user_id": "33765206", "name": "\r\n        3 revs, 2 users 76%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "33765206", "stack_answer_comment_id": "58658010", "comment_content": " being similar and with the same drawbacks/positives as ", "user_id": "None"}, {"stack_answer_id": "33765206", "stack_answer_comment_id": "62448054", "comment_content": "Thanks, @selurvedu - it can be confusing until you get it straight. I learned the hard way, so your way might not be as hard. ;) Using if without the else, at the end of a generator expression or list comprehension will filter the iterable. In the front, it's a ternary conditional operation, and requires the else. Cheers!!", "user_id": "None"}, {"stack_answer_id": "33765206", "stack_answer_comment_id": "95571762", "comment_content": "@AaronHall Although your use of metasyntactic ", "user_id": "None"}, {"stack_answer_id": "33765206", "stack_answer_comment_id": "95575895", "comment_content": "@tchrist thanks for the review - if you look at the revision history, this post currently has two revisions. Most of my other answers, especially the top ones, have been revisited again and again. This answer never gets my attention because the community wiki status gives me no credit for the content, and so I never see any votes on it. As I don't really have time for an edit on this right now, frog knows when it will come to my attention again in the future. I can see you've edited the top answer, so feel free to borrow/quote my material from this post in that one (and cite me if apropos!)", "user_id": "None"}]}, {"stack_answer_id": "58409100", "answer_content": "\r\n As already answered, yes, there is a ternary operator in Python: \n <expression 1> if <condition> else <expression 2>\n \n In many cases  <expression 1>  is also used as Boolean evaluated  <condition> . Then you can use  short-circuit evaluation . \n a = 0\nb = 1\n\n# Instead of this:\nx = a if a else b\n# Evaluates as 'a if bool(a) else b'\n\n# You could use short-circuit evaluation:\nx = a or b\n \n One big pro of short-circuit evaluation is the possibility of chaining more than two expressions: \n x = a or b or c or d or e\n \n When working with functions it is more different in detail: \n # Evaluating functions:\ndef foo(x):\n    print('foo executed')\n    return x\n\n\ndef bar(y):\n    print('bar executed')\n    return y\n\n\ndef blubb(z):\n    print('blubb executed')\n    return z\n\n\n# Ternary Operator expression 1 equals to False\nprint(foo(0) if foo(0) else bar(1))\n''' foo and bar are executed once\nfoo executed\nbar executed\n1\n'''\n\n# Ternary Operator expression 1 equals to True\nprint(foo(2) if foo(2) else bar(3))\n''' foo is executed twice!\nfoo executed\nfoo executed\n2\n'''\n\n# Short-circuit evaluation second equals to True\nprint(foo(0) or bar(1) or blubb(2))\n''' blubb is not executed\nfoo executed\nbar executed\n1\n'''\n\n# Short-circuit evaluation third equals to True\nprint(foo(0) or bar(0) or blubb(2))\n'''\nfoo executed\nbar executed\nblubb executed\n2\n'''\n\n# Short-circuit evaluation all equal to False\nprint(foo(0) or bar(0) or blubb(0))\n''' Result is 0 (from blubb(0)) because no value equals to True\nfoo executed\nbar executed\nblubb executed\n0\n'''\n \n PS: Of course, a short-circuit evaluation is not a ternary operator, but often the ternary is used in cases where the short circuit would be enough. It has a better readability and can be chained. \n    ", "date_posted": "2022-02-06 13:28:15Z", "upvote": "\r\n            33\r\n        ", "accepted": "No", "user": {"stack_user_id": "58409100", "name": "\r\n        4 revs, 2 users 89%", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "54609267", "answer_content": "\r\n One of the alternatives to Python's  conditional expression \n \"yes\" if boolean else \"no\"\n \n is the following: \n {True: \"yes\", False: \"no\"}[boolean]\n \n which has the following nice extension: \n {True: \"yes\", False: \"no\", None: \"maybe\"}[boolean_or_none]\n \n The shortest alternative remains \n (\"no\", \"yes\")[boolean]\n \n which works because  issubclass(bool, int) . \n Careful, though: the alternative to \n yes() if boolean else no()\n \n is  not \n (no(), yes())[boolean]  # bad: BOTH no() and yes() are called\n \n but \n (no, yes)[boolean]()\n \n This works fine as long as  no  and  yes  are to be called with exactly the same parameters. If they are not, like in \n yes(\"ok\") if boolean else no()  # (1)\n \n or in \n yes(\"ok\") if boolean else no(\"sorry\")  # (2)\n \n then a similar alternative either does not exist (1) or is hardly viable (2). (In rare cases, depending on the context, something like \n msg = (\"sorry\", \"ok\")[boolean]\n(no, yes)[boolean](msg)\n \n could make sense.) \n Thanks to Radek Roj\u00edk for his comment \n    ", "date_posted": "2022-06-01 12:19:26Z", "upvote": "\r\n            33\r\n        ", "accepted": "No", "user": {"stack_user_id": "54609267", "name": "\r\n        6 revs", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "54609267", "stack_answer_comment_id": "127061683", "comment_content": "Alternative: ", "user_id": "None"}]}, {"stack_answer_id": "20093702", "answer_content": "\r\n Simulating the Python ternary operator. \n For example \n a, b, x, y = 1, 2, 'a greather than b', 'b greater than a'\nresult = (lambda:y, lambda:x)[a > b]()\n \n Output: \n 'b greater than a'\n \n    ", "date_posted": "2022-02-06 12:25:06Z", "upvote": "\r\n            31\r\n        ", "accepted": "No", "user": {"stack_user_id": "20093702", "name": "\r\n        2 revs, 2 users 81%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "20093702", "stack_answer_comment_id": "31175220", "comment_content": "Why not simply ", "user_id": "None"}, {"stack_answer_id": "20093702", "stack_answer_comment_id": "32895313", "comment_content": "@GrijeshChauhan Because on \"compliated\" expressions, e. g. involving a function call etc., this would be executed in both cases. This might not be wanted.", "user_id": "None"}, {"stack_answer_id": "20093702", "stack_answer_comment_id": "115414421", "comment_content": "The use of ", "user_id": "None"}, {"stack_answer_id": "20093702", "stack_answer_comment_id": "116319126", "comment_content": "@GrijeshChauhan In short, this implements the so-called \u201c", "user_id": "None"}]}, {"stack_answer_id": "53653902", "answer_content": "\r\n a if condition else b\n \n\n Just memorize this pyramid if you have trouble remembering: \n\n      condition\n  if           else\na                   b \n \n    ", "date_posted": "2018-12-06 14:45:27Z", "upvote": "\r\n            29\r\n        ", "accepted": "No", "user": {"stack_user_id": "53653902", "name": "\r\n        shivtej\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "49653070", "answer_content": "\r\n The ternary conditional operator simply allows testing a condition in a single line replacing the multiline if-else making the code compact. \n Syntax: \n \n [on_true] if [expression] else [on_false] \n \n 1- Simple Method to use ternary operator: \n # Program to demonstrate conditional operator\na, b = 10, 20\n# Copy value of a in min if a < b else copy b\nmin = a if a < b else b\nprint(min)  # Output: 10\n \n 2- Direct Method of using tuples, Dictionary, and lambda: \n # Python program to demonstrate ternary operator\na, b = 10, 20\n# Use tuple for selecting an item\nprint( (b, a) [a < b] )\n# Use Dictionary for selecting an item\nprint({True: a, False: b} [a < b])\n# lambda is more efficient than above two methods\n# because in lambda  we are assure that\n# only one expression will be evaluated unlike in\n# tuple and Dictionary\nprint((lambda: b, lambda: a)[a < b]()) # in output you should see three 10\n \n 3- Ternary operator can be written as nested if-else: \n # Python program to demonstrate nested ternary operator\na, b = 10, 20\nprint (\"Both a and b are equal\" if a == b else \"a is greater than b\"\n        if a > b else \"b is greater than a\")\n \n Above approach can be written as: \n # Python program to demonstrate nested ternary operator\na, b = 10, 20\nif a != b:\n    if a > b:\n        print(\"a is greater than b\")\n    else:\n        print(\"b is greater than a\")\nelse:\n    print(\"Both a and b are equal\")\n# Output: b is greater than a\n \n    ", "date_posted": "2022-02-06 13:11:36Z", "upvote": "\r\n            28\r\n        ", "accepted": "No", "user": {"stack_user_id": "49653070", "name": "\r\n        3 revs, 2 users 86%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "49653070", "stack_answer_comment_id": "92454366", "comment_content": "Note that the ternary operator is smaller (in memory) and faster than the nested if.  Also, your nested ", "user_id": "None"}]}, {"stack_answer_id": "65422380", "answer_content": "\r\n Vinko Vrsalovic's answer  is good enough. There is only one more thing: \n \n Note that conditionals are an  expression , not a  statement . This means you can't use assignment statements or  pass  or other  statements  within a conditional  expression \n \n Walrus operator in Python 3.8 \n After the  walrus operator  was introduced in Python 3.8, something changed. \n (a := 3) if True else (b := 5)\n \n gives  a = 3  and  b is not defined , \n (a := 3) if False else (b := 5)\n \n gives  a is not defined  and  b = 5 , and \n c = (a := 3) if False else (b := 5)\n \n gives  c = 5 ,  a is not defined  and  b = 5 . \n Even if this may be ugly,  assignments  can be done  inside  conditional expressions after Python 3.8. Anyway, it is still better to use normal  if   statement  instead in this case. \n    ", "date_posted": "2022-02-06 13:36:09Z", "upvote": "\r\n            27\r\n        ", "accepted": "No", "user": {"stack_user_id": "65422380", "name": "\r\n        2 revs, 2 users 69%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "65422380", "stack_answer_comment_id": "121325576", "comment_content": "In the first example: ", "user_id": "None"}, {"stack_answer_id": "65422380", "stack_answer_comment_id": "121356996", "comment_content": "@AndrewAnderson No it's not redundant. You should compare both the first and the second examples. You can combine them and consider this: ", "user_id": "None"}, {"stack_answer_id": "65422380", "stack_answer_comment_id": "121376861", "comment_content": "Yes, that's correct :). I considered this only for ", "user_id": "None"}, {"stack_answer_id": "65422380", "stack_answer_comment_id": "121396760", "comment_content": "Because we don't really write down this code ", "user_id": "None"}]}, {"stack_answer_id": "37155553", "answer_content": "\r\n More a tip than an answer (I don't need to repeat the obvious for the hundredth time), but I sometimes use it as a one-liner shortcut in such constructs: \n if conditionX:\n    print('yes')\nelse:\n    print('nah')\n \n , becomes: \n print('yes') if conditionX else print('nah')\n \n Some (many :) may frown upon it as unpythonic (even, Ruby-ish :), but I personally find it more natural - i.e., how you'd express it normally, plus a bit more visually appealing in large blocks of code. \n    ", "date_posted": "2022-02-06 12:30:29Z", "upvote": "\r\n            26\r\n        ", "accepted": "No", "user": {"stack_user_id": "37155553", "name": "\r\n        3 revs, 3 users 76%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "37155553", "stack_answer_comment_id": "78515516", "comment_content": "I prefer ", "user_id": "None"}, {"stack_answer_id": "37155553", "stack_answer_comment_id": "80853618", "comment_content": "That is if you want to ", "user_id": "None"}, {"stack_answer_id": "37155553", "stack_answer_comment_id": "92749861", "comment_content": "To add to Frederick99's remark, another reason to avoid ", "user_id": "None"}, {"stack_answer_id": "37155553", "stack_answer_comment_id": "92753803", "comment_content": "The only reason it gives a syntax error is because in Python 2 print is a statement - ", "user_id": "None"}]}, {"stack_answer_id": "45779600", "answer_content": "\r\n You can do this: \n [condition] and [expression_1] or [expression_2];\n \n Example: \n print(number%2 and \"odd\" or \"even\")\n \n This would print \"odd\" if the number is odd or \"even\" if the number is even. \n \n The result:  If condition is true, exp_1 is executed, else exp_2 is executed. \n Note:  0, None, False, emptylist, and emptyString evaluates as False. \n And any data other than 0 evaluates to True. \n Here's how it works: \n If the condition [condition] becomes \"True\", then expression_1 will be evaluated, but not expression_2. \n If we \"and\" something with 0 (zero), the result will always to be false. So in the below statement, \n 0 and exp\n \n The expression  exp  won't be evaluated at all since \"and\" with 0 will always evaluate to zero and there is no need to evaluate the expression. This is how the compiler itself works, in all languages. \n In \n 1 or exp\n \n the expression  exp  won't be evaluated at all since \"or\" with 1 will always be 1. So it won't bother to evaluate the expression exp since the result will be 1 anyway (compiler optimization methods). \n But in case of \n True and exp1 or exp2\n \n The second expression exp2 won't be evaluated since  True and exp1  would be True when exp1 isn't false. \n Similarly in \n False and exp1 or exp2\n \n The expression  exp1  won't be evaluated since False is equivalent to writing 0 and doing \"and\" with 0 would be 0 itself, but after exp1 since \"or\" is used, it will evaluate the expression exp2 after \"or\". \n \n Note:-  This kind of branching using \"or\" and \"and\" can only be used when the expression_1 doesn't have a Truth value of False (or 0 or None or emptylist [ ] or emptystring ' '.) since if expression_1 becomes False, then the expression_2 will be evaluated because of the presence \"or\" between exp_1 and exp_2. \n In case you still want to make it work for all the cases regardless of what exp_1 and exp_2 truth values are, do this: \n [condition] and ([expression_1] or 1) or [expression_2];\n \n    ", "date_posted": "2022-02-06 12:43:54Z", "upvote": "\r\n            26\r\n        ", "accepted": "No", "user": {"stack_user_id": "45779600", "name": "\r\n        5 revs, 2 users 52%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "45779600", "stack_answer_comment_id": "80634562", "comment_content": "If you want to use that in the context of ", "user_id": "None"}]}, {"stack_answer_id": "53922638", "answer_content": "\r\n Many programming languages derived from  C  usually have the following syntax of the ternary conditional operator: \n <condition> ? <expression1> : <expression2>\n \n At first, the Python's  benevolent dictator for life  (I mean  Guido van Rossum , of course) rejected it (as non-Pythonic style), since it's quite hard to understand for people not used to C language. Also, the colon sign  :  already has many uses in Python. After  PEP 308  was approved, Python finally received its own shortcut conditional expression (what we use now): \n <expression1> if <condition> else <expression2>\n \n So, firstly it evaluates the condition. If it returns  True ,  expression1  will be evaluated to give the result, otherwise  expression2  will be evaluated. Due to  lazy evaluation  mechanics \u2013 only one expression will be executed. \n Here are some examples (conditions will be evaluated from left to right): \n pressure = 10\nprint('High' if pressure < 20 else 'Critical')\n\n# Result is 'High'\n \n Ternary operators can be chained in series: \n pressure = 5\nprint('Normal' if pressure < 10 else 'High' if pressure < 20 else 'Critical')\n\n# Result is 'Normal'\n \n The following one is the same as previous one: \n pressure = 5\n\nif pressure < 20:\n    if pressure < 10:\n        print('Normal')\n    else:\n        print('High')\nelse:\n    print('Critical')\n\n# Result is 'Normal'\n \n    ", "date_posted": "2022-02-06 12:57:48Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "53922638", "name": "\r\n        4 revs, 3 users 87%", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "52919467", "answer_content": "\r\n Yes , Python have a ternary operator, here is the syntax and an example code to demonstrate the same :) \n #[On true] if [expression] else[On false]\n# if the expression evaluates to true then it will pass On true otherwise On false\n\na = input(\"Enter the First Number \")\nb = input(\"Enter the Second Number \")\n\nprint(\"A is Bigger\") if a>b else print(\"B is Bigger\")\n \n    ", "date_posted": "2022-02-06 12:52:56Z", "upvote": "\r\n            15\r\n        ", "accepted": "No", "user": {"stack_user_id": "52919467", "name": "\r\n        3 revs, 2 users 51%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "52919467", "stack_answer_comment_id": "92748969", "comment_content": "I have added a one line statement example to check which number is big to elaborate it further", "user_id": "None"}, {"stack_answer_id": "52919467", "stack_answer_comment_id": "92749878", "comment_content": " is really not a good choice, as this will give a SyntaxError in Python2.", "user_id": "None"}, {"stack_answer_id": "52919467", "stack_answer_comment_id": "92749900", "comment_content": "@Thierry Lathuille here I used print() function not print statement, print function is for Python 3 while print statement is for Python 2", "user_id": "None"}, {"stack_answer_id": "52919467", "stack_answer_comment_id": "92749954", "comment_content": "The question has already been asked on SO, just try it with Python 2 and you will see by yourself. 'print('hello') is a perfectly valid syntax in Python 2.7, but the way it is parsed makes your code above throw a SyntaxError.", "user_id": "None"}]}, {"stack_answer_id": "61896436", "answer_content": "\r\n Other answers correctly talk about the Python ternary operator. I would like to complement by mentioning a scenario for which the ternary operator is often used, but for which there is a better idiom. This is the scenario of using a default value. \n Suppose we want to use  option_value  with a default value if it is not set: \n run_algorithm(option_value if option_value is not None else 10)\n \n or, if  option_value  is never set to a falsy value ( 0 ,  \"\" , etc.), simply \n run_algorithm(option_value if option_value else 10)\n \n However, in this case an ever better solution is simply to write \n run_algorithm(option_value or 10)\n \n    ", "date_posted": "2022-02-06 13:31:30Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "61896436", "name": "\r\n        3 revs, 2 users 83%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "61896436", "stack_answer_comment_id": "113960535", "comment_content": "A valuable complement, but I disagree: ", "user_id": "None"}, {"stack_answer_id": "61896436", "stack_answer_comment_id": "114022487", "comment_content": "@ruancomelli: Good point. I've modified the answer to reflect that correction.", "user_id": "None"}, {"stack_answer_id": "61896436", "stack_answer_comment_id": "114022542", "comment_content": "As for it looking weird, I wonder if it looked weird to you because you noticed the imprecision (that it was not really equivalent). To me it sounds natural because it reminds me saying in English: \"Use this or that (if the first option is unavailable)\". But of course that is subjective. It is useful to know it does not look natural to everybody.", "user_id": "None"}, {"stack_answer_id": "61896436", "stack_answer_comment_id": "114190254", "comment_content": "Much better! And thanks for the explanation regarding the \"or\"-idiom. It looks weird to me because I tend to think of ", "user_id": "None"}]}, {"stack_answer_id": "71819081", "answer_content": "\r\n The syntax for the ternary operator in Python is: \n [on_true] if [expression] else [on_false] \n Using that syntax, here is how we would rewrite the code above using Python\u2019s ternary operator: \n game_type = 'home'\nshirt = 'white' if game_type == 'home' else 'green'\n\n \n It's still pretty clear, but much shorter. Note that the expression could be any type of expression, including a function call, that returns a value that evaluates to True or False. \n    ", "date_posted": "2022-04-10 17:39:25Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "71819081", "name": "\r\n        George Imerlishvili\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "60630600", "answer_content": "\r\n Python has a ternary form for assignments; however there may be even a shorter form that people should be aware of. \n It's very common to need to assign to a variable one value or another depending on a condition. \n >>> li1 = None\n>>> li2 = [1, 2, 3]\n>>>\n>>> if li1:\n...     a = li1\n... else:\n...     a = li2\n...\n>>> a\n[1, 2, 3]\n \n ^ This is the long form for doing such assignments. \n Below is the ternary form. But this isn't the most succinct way - see the last example. \n >>> a = li1 if li1 else li2\n>>>\n>>> a\n[1, 2, 3]\n>>>\n \n With Python, you can simply use  or  for alternative assignments. \n >>> a = li1 or li2\n>>>\n>>> a\n[1, 2, 3]\n>>>\n \n The above works since  li1  is  None  and the interpreter treats that as False in logic expressions. The interpreter then moves on and evaluates the second expression, which is not  None  and it's not an empty list - so it gets assigned to  a . \n This also works with empty lists. For instance, if you want to assign  a  whichever list has items. \n >>> li1 = []\n>>> li2 = [1, 2, 3]\n>>>\n>>> a = li1 or li2\n>>>\n>>> a\n[1, 2, 3]\n>>>\n \n Knowing this, you can simply such assignments whenever you encounter them. This also works with strings and other iterables. You could assign  a  whichever string isn't empty. \n >>> s1 = ''\n>>> s2 = 'hello world'\n>>>\n>>> a = s1 or s2\n>>>\n>>> a\n'hello world'\n>>>\n \n I always liked the C ternary syntax, but Python takes it a step further! \n I understand that some may say this isn't a good stylistic choice, because it relies on mechanics that aren't immediately apparent to all developers. I personally disagree with that viewpoint. Python is a syntax-rich language with lots of idiomatic tricks that aren't immediately apparent to the dabbler. But the more you learn and understand the mechanics of the underlying system, the more you appreciate it. \n    ", "date_posted": "2022-02-06 13:26:23Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "60630600", "name": "\r\n        4 revs, 2 users 86%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "60630600", "stack_answer_comment_id": "125525088", "comment_content": "Something seems to be missing near ", "user_id": "None"}, {"stack_answer_id": "60630600", "stack_answer_comment_id": "125527651", "comment_content": "\"Simplify\" such assignments =) @PeterMortensen", "user_id": "None"}]}, {"stack_answer_id": "70523744", "answer_content": "\r\n Pythonic way of doing the things: \n \"true\" if var else \"false\"\n \n But there always exists a different way of doing a ternary condition too: \n \"true\" and var or \"false\"\n \n    ", "date_posted": "2022-02-06 13:55:46Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "70523744", "name": "\r\n        2 revs, 2 users 80%", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "71007804", "answer_content": "\r\n There are multiple ways. The simplest one is to use the condition inside the \"print\" method. \n You can use \n print(\"Twenty\" if number == 20 else \"Not twenty\")\n \n Which is equivalent to: \n if number == 20:\n    print(\"Twenty\")\nelse:\n    print(\"Not twenty\")\n \n In this way, more than two statements are also possible to print. For example: \n if number == 20:\n    print(\"Twenty\")\nelif number < 20:\n    print(\"Lesser\")\nelif 30 > number > 20:\n    print(\"Between\")\nelse:\n    print(\"Greater\")\n \n can be written as: \n print(\"Twenty\" if number == 20 else \"Lesser\" if number < 20 else \"Between\" if 30 > number > 20 else \"Greater\")\n \n    ", "date_posted": "2022-02-06 13:46:32Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "71007804", "name": "\r\n        Aldrin Saurov Sarker\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "70941294", "answer_content": "\r\n The  if else-if  version can be written as: \n sample_set=\"train\" if \"Train\" in full_path else (\"test\" if \"Test\" in full_path else \"validation\")\n \n    ", "date_posted": "2022-02-06 13:56:20Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "70941294", "name": "\r\n        2 revs, 2 users 67%", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "71150434", "answer_content": "\r\n Yes, it has, but it's different from C-syntax-like programming languages (which is  condition ? value_if_true : value_if_false \n In Python, it goes like this:  value_if_true if condition else value_if_false \n Example:  even_or_odd = \"even\" if x % 2 == 0 else \"odd\" \n    ", "date_posted": "2022-02-16 23:09:11Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "71150434", "name": "\r\n        Heroes Of Balkan\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "56099511", "answer_content": "\r\n A neat way to chain multiple operators: \n\n f = lambda x,y: 'greater' if x > y else 'less' if y > x else 'equal'\n\narray = [(0,0),(0,1),(1,0),(1,1)]\n\nfor a in array:\n  x, y = a[0], a[1]\n  print(f(x,y))\n\n# Output is:\n#   equal,\n#   less,\n#   greater,\n#   equal\n\n \n    ", "date_posted": "2019-05-12 13:03:48Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "56099511", "name": "\r\n        Yaakov Bressler\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "60876846", "answer_content": "\r\n I find the default Python syntax  val = a if cond else b  cumbersome, so sometimes I do this: \n iif = lambda (cond, a, b): a if cond else b\n# So I can then use it like:\nval = iif(cond, a, b)\n \n Of course, it has the downside of always evaluating both sides ( a  and  b ), but the syntax is way clearer to me. \n    ", "date_posted": "2022-02-06 13:30:33Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "60876846", "name": "\r\n        2 revs, 2 users 60%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "60876846", "stack_answer_comment_id": "108765520", "comment_content": "This seems to be twice the amount of work, more RAM usage and more obfuscated than the simpler ", "user_id": "None"}, {"stack_answer_id": "60876846", "stack_answer_comment_id": "116103460", "comment_content": "Also both ", "user_id": "None"}, {"stack_answer_id": "60876846", "stack_answer_comment_id": "126733397", "comment_content": "According to PEP8 assigning lambda to variable is a code smell. Lambda should be used only as inplace function.", "user_id": "None"}]}], "user": {"stack_user_id": null, "name": null, "reputation_score": 0}, "question_comments": [{"stack_question_id": "394809", "stack_question_comment_id": "19777451", "comment_content": "In the Python 3.0 official documentation referenced in a comment above, this is referred to as \"conditional_expressions\" and is very cryptically defined.  That documentation doesn't even include the term \"ternary\", so you would be hard-pressed to find it via Google unless you knew exactly what to look for.  The ", "user_id": "None"}, {"stack_question_id": "394809", "stack_question_comment_id": "43418120", "comment_content": "\"ternary\" (having three inputs) is a consequential property of this impelmentation, not a defining property of the concept. eg:  SQL has ", "user_id": "None"}, {"stack_question_id": "394809", "stack_question_comment_id": "43418299", "comment_content": "also ISO/IEC 9899 (the C programming language standard) section 6.5.15 calls it the \"the condtitional operator\"", "user_id": "None"}, {"stack_question_id": "394809", "stack_question_comment_id": "62912948", "comment_content": "Wikipedia covers this thoroughly in the article \"", "user_id": "None"}, {"stack_question_id": "394809", "stack_question_comment_id": "90671337", "comment_content": "In the years since nobar's comment the ", "user_id": "None"}]},
{"stack_question_id": "2709821", "question_title": "What is the `self` parameter in class methods?", "question_content": "\r\n                self refers to the specific object instance created from a class. But why must every method explicitly include self as a parameter?\nclass MyClass:\n    def func(self, name):\n        self.name = name\n\n...\r\n", "question_url": "/questions/2709821/what-is-the-self-parameter-in-class-methods", "date_posted": "Apr 25, 2010 at 20:22", "upvote": "1", "view": "9", "tags": ["python", "class", "oop", "self"], "answers_count": "2", "answers": [{"stack_answer_id": "2709832", "answer_content": "\r\n The reason you need to use  self.  is because Python does not use the  @  syntax to refer to instance attributes. Python decided to do methods in a way that makes the instance to which the method belongs be  passed  automatically, but not  received  automatically: the first parameter of methods is the instance the method is called on. That makes methods entirely the same as functions, and leaves the actual name to use up to you (although  self  is the convention, and people will generally frown at you when you use something else.)  self  is not special to the code, it's just another object. \n\n Python could have done something else to distinguish normal names from attributes -- special syntax like Ruby has, or requiring declarations like C++ and Java do, or perhaps something  yet more different -- but it didn't. Python's all for making things explicit, making it obvious what's what, and although it doesn't do it entirely everywhere, it does do it for instance attributes. That's why assigning to an instance attribute needs to know what instance to assign to, and that's why it needs  self. . \n    ", "date_posted": "2010-04-27 23:01:28Z", "upvote": "\r\n            765\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "17624", "name": "Thomas Wouters", "reputation_score": "126k"}, "answer_comments": [{"stack_answer_id": "2709832", "stack_answer_comment_id": "2734191", "comment_content": "@Georg: ", "user_id": "None"}, {"stack_answer_id": "2709832", "stack_answer_comment_id": "4604498", "comment_content": "@SilentGhost: Actually, the name of the first parameter is whatever you want it to be.  On class methods, the convention is to use ", "user_id": "None"}, {"stack_answer_id": "2709832", "stack_answer_comment_id": "19063966", "comment_content": "I find it interesting that the community didn't choose ", "user_id": "None"}, {"stack_answer_id": "2709832", "stack_answer_comment_id": "27940514", "comment_content": "@Julius The ", "user_id": "None"}, {"stack_answer_id": "2709832", "stack_answer_comment_id": "42210957", "comment_content": "@Julius The ", "user_id": "None"}]}, {"stack_answer_id": "21366809", "answer_content": "\r\n Let's say you have a class  ClassA  which contains a method  methodA  defined as: \n\n def methodA(self, arg1, arg2):\n    # do something\n \n\n and  ObjectA  is an instance of this class. \n\n Now when  ObjectA.methodA(arg1, arg2)  is called, python internally converts it for you as: \n\n ClassA.methodA(ObjectA, arg1, arg2)\n \n\n The  self  variable refers to the object itself. \n    ", "date_posted": "2019-11-16 18:56:13Z", "upvote": "\r\n            583\r\n        ", "accepted": "No", "user": {"stack_user_id": "997813", "name": "Arjun Sreedharan", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "21366809", "stack_answer_comment_id": "41174707", "comment_content": "I read all the other answers and sort of understood, I read this one and then it all made sense.", "user_id": "None"}, {"stack_answer_id": "21366809", "stack_answer_comment_id": "79661533", "comment_content": "Why not keep those guts inside, though, like Ruby does?", "user_id": "None"}, {"stack_answer_id": "21366809", "stack_answer_comment_id": "83963043", "comment_content": "But in __init__(self) method, it accepts self, then even without creating the object, how does it refer to itself?", "user_id": "None"}, {"stack_answer_id": "21366809", "stack_answer_comment_id": "120812764", "comment_content": "This doesn't answer the question though. The OP was asking about why ", "user_id": "None"}, {"stack_answer_id": "21366809", "stack_answer_comment_id": "129280090", "comment_content": "Why then a new function is generated for every instance of ", "user_id": "None"}]}, {"stack_answer_id": "2725996", "answer_content": "\r\n Let\u2019s take a simple vector class: \n\n class Vector:\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n \n\n We want to have a method which calculates the length. What would it look like if we wanted to define it inside the class? \n\n     def length(self):\n        return math.sqrt(self.x ** 2 + self.y ** 2)\n \n\n What should it look like when we were to define it as a global method/function? \n\n def length_global(vector):\n    return math.sqrt(vector.x ** 2 + vector.y ** 2)\n \n\n So the whole structure stays the same. How can me make use of this? If we assume for a moment that we hadn\u2019t written a  length  method for our  Vector  class, we could do this: \n\n Vector.length_new = length_global\nv = Vector(3, 4)\nprint(v.length_new()) # 5.0\n \n\n This works because the first parameter of  length_global , can be re-used as the  self  parameter in  length_new . This would not be possible without an explicit  self . \n\n \n\n Another way of understanding the need for the explicit  self  is to see where Python adds some syntactical sugar. When you keep in mind, that basically, a call like \n\n v_instance.length()\n \n\n is internally transformed to \n\n Vector.length(v_instance)\n \n\n it is easy to see where the  self  fits in. You don't actually write instance methods in Python; what you write is class methods which must take an instance as a first parameter. And therefore, you\u2019ll have to place the instance parameter somewhere explicitly. \n    ", "date_posted": "2017-08-15 06:40:38Z", "upvote": "\r\n            436\r\n        ", "accepted": "No", "user": {"stack_user_id": "1637126", "name": "empty", "reputation_score": "4,892"}, "answer_comments": [{"stack_answer_id": "2725996", "stack_answer_comment_id": "4604132", "comment_content": "Vector.length_new = length_global... I actually started to use syntax like this in my class declarations. Whenever I only want to inherit some of the methods from another class, I just explicitly copy the reference to the methods.", "user_id": "None"}, {"stack_answer_id": "2725996", "stack_answer_comment_id": "16540616", "comment_content": "would it be fair to say that python's \"instance method\" is simply a syntactic sugar of static global methods (as in Java or C++) with an instance object passed in to package multiple attributes?  --- well this is kind of half-true since in polymorphism, the more important purpose of \"this\" (as in java) or \"self\" is to give u the correct implementation of methods. Python does have this. so calling myobj.someMethod() is equal to TheClassOfMyObj.someMethod(myobj) in python. note that the \"TheClassOfMyObj\" is automatically figured out by python from \"self\", otherwise u'd have to find that out.", "user_id": "None"}, {"stack_answer_id": "2725996", "stack_answer_comment_id": "27469407", "comment_content": "Infact, not only are instance methods just class methods, but methods are just functions which are members of a class, as the ", "user_id": "None"}, {"stack_answer_id": "2725996", "stack_answer_comment_id": "34102116", "comment_content": "\"This works, because the first parameter of length_global, can be re-used as the self parameter in length_new. This would not be possible without an explicit self.\" - it would work just the same. it would be re-used for the implicit self... the second example is a circular reasoning - you have to explicitly place self there, because python needs the explicit self.", "user_id": "None"}, {"stack_answer_id": "2725996", "stack_answer_comment_id": "34123622", "comment_content": "@KarolyHorvath: Sure, it would also be possible to have a language with a model where internally defined methods do not need an explicit self but externally defined methods do. But I\u2019d say there is some consistency in requiring the explicit self in both cases, which makes it a legitimate reason to do it this way. Other languages may choose different approaches.", "user_id": "None"}]}, {"stack_answer_id": "31096552", "answer_content": "\r\n When objects are instantiated, the object itself is passed into the self parameter.  \n\n \n\n Because of this, the object\u2019s data is bound to the object. Below is an example of how you might like to visualize what each object\u2019s data might look. Notice how \u2018self\u2019 is replaced with the objects name. I'm not saying this example diagram below is wholly accurate but it hopefully with serve a purpose in visualizing the use of self.  \n\n \n\n The Object is passed into the self parameter so that the object can keep hold of its own data. \n\n Although this may not be wholly accurate, think of the process of instantiating an object like this: When an object is made it uses the class as a template for its own data and methods. Without passing it's own name into the self parameter, the attributes and methods in the class would remain as a general template and would not be referenced to (belong to) the object. So by passing the object's name into the self parameter it means that if 100 objects are instantiated from the one class, they can all keep track of their own data and methods. \n\n See the illustration below: \n\n \n    ", "date_posted": "2015-06-28 05:47:02Z", "upvote": "\r\n            246\r\n        ", "accepted": "No", "user": {"stack_user_id": "2686197", "name": "sw123456", "reputation_score": "3,171"}, "answer_comments": [{"stack_answer_id": "31096552", "stack_answer_comment_id": "51742866", "comment_content": "Hey there, when accessing Bob's attributes for example by \"bob.name()\", you actually accesing bob().self.name so to speak from the '", "user_id": "None"}, {"stack_answer_id": "31096552", "stack_answer_comment_id": "51743445", "comment_content": "When you write bob.name() in the above comment, you are implying that bob has a method called name() due to the fact that you added brackets after name. In this example however there is no such method. 'bob.name' (which has no parenthesis) is directly accessing the attribute called name from the init (constructor) method. When bob's speak method is called it is the method which accesses the name attribute and returns it in a print statement. Hope this helps.", "user_id": "None"}, {"stack_answer_id": "31096552", "stack_answer_comment_id": "51744484", "comment_content": "No, you get the value of self.name, which for the bob object is actually bob.name, because the object's name is passed into the self parameter when it is created (instantiated). Again, hope this helps. Feel free to upvote main post if it has.", "user_id": "None"}, {"stack_answer_id": "31096552", "stack_answer_comment_id": "51744680", "comment_content": "Name is assigned to self.name at instantiation. After an object is created, all variables that belong to the object are those prefixed with 'self.' Remember that self is replaced with the object's name when it is created from the class.", "user_id": "None"}, {"stack_answer_id": "31096552", "stack_answer_comment_id": "81189993", "comment_content": "This is how you explain stuff ! nice job :)", "user_id": "None"}]}, {"stack_answer_id": "2714920", "answer_content": "\r\n I like this example: \n\n class A: \n    foo = []\na, b = A(), A()\na.foo.append(5)\nb.foo\nans: [5]\n\nclass A: \n    def __init__(self): \n        self.foo = []\na, b = A(), A()\na.foo.append(5)\nb.foo\nans: []\n \n    ", "date_posted": "2010-04-26 16:02:48Z", "upvote": "\r\n            85\r\n        ", "accepted": "No", "user": {"stack_user_id": "237934", "name": "kame", "reputation_score": "19.4k"}, "answer_comments": [{"stack_answer_id": "2714920", "stack_answer_comment_id": "16540656", "comment_content": "so vars without self is simply static vars of the class, like in java", "user_id": "None"}, {"stack_answer_id": "2714920", "stack_answer_comment_id": "34582202", "comment_content": "teddy teddy, you aren't entirely correct. The behavior (static or non-static like) depends not only on ", "user_id": "None"}, {"stack_answer_id": "2714920", "stack_answer_comment_id": "39184200", "comment_content": "Actually, my question with this is why are you allowed to say ", "user_id": "None"}, {"stack_answer_id": "2714920", "stack_answer_comment_id": "41852298", "comment_content": "You can call static members from instances of the object in most languages. Why is that surprising?", "user_id": "None"}, {"stack_answer_id": "2714920", "stack_answer_comment_id": "77100679", "comment_content": "@RadonRosborough Because in the first example, ", "user_id": "None"}]}, {"stack_answer_id": "6433556", "answer_content": "\r\n I will demonstrate with code that  does not use classes : \n\n def state_init(state):\n    state['field'] = 'init'\n\ndef state_add(state, x):\n    state['field'] += x\n\ndef state_mult(state, x):\n    state['field'] *= x\n\ndef state_getField(state):\n    return state['field']\n\nmyself = {}\nstate_init(myself)\nstate_add(myself, 'added')\nstate_mult(myself, 2)\n\nprint( state_getField(myself) )\n#--> 'initaddedinitadded'\n \n\n Classes are just a way to avoid passing in this \"state\" thing all the time (and other nice things like initializing, class composition, the rarely-needed metaclasses, and supporting custom methods to override operators). \n\n Now let's demonstrate the above code using the built-in python class machinery, to show how it's basically the same thing. \n\n class State(object):\n    def __init__(self):\n        self.field = 'init'\n    def add(self, x):\n        self.field += x\n    def mult(self, x):\n        self.field *= x\n\ns = State()\ns.add('added')    # self is implicitly passed in\ns.mult(2)         # self is implicitly passed in\nprint( s.field )\n \n\n [migrated my answer from duplicate closed question] \n    ", "date_posted": "2011-06-22 00:27:23Z", "upvote": "\r\n            45\r\n        ", "accepted": "No", "user": {"stack_user_id": "711085", "name": "ninjagecko", "reputation_score": "84.7k"}, "answer_comments": [{"stack_answer_id": "6433556", "stack_answer_comment_id": "79661616", "comment_content": "I wish Python sugarcoated the handlers as well as Ruby does.", "user_id": "None"}]}, {"stack_answer_id": "2709847", "answer_content": "\r\n The following excerpts are from the  Python documentation about self : \n \n As in Modula-3, there are no shorthands [in Python] for referencing the object\u2019s members from its methods: the method function is declared with an explicit first argument representing the object, which is provided implicitly by the call. \n Often, the first argument of a method is called self. This is nothing more than a convention: the name self has absolutely no special meaning to Python. Note, however, that by not following the convention your code may be less readable to other Python programmers, and it is also conceivable that a class browser program might be written that relies upon such a convention. \n \n For more information, see the  Python documentation tutorial on classes . \n    ", "date_posted": "2020-06-20 09:12:55Z", "upvote": "\r\n            23\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}, {"stack_answer_id": "2709857", "answer_content": "\r\n As well as all the other reasons already stated, it allows for easier access to overridden methods; you can call  Class.some_method(inst) . \n\n An example of where it\u2019s useful: \n\n class C1(object):\n    def __init__(self):\n         print \"C1 init\"\n\nclass C2(C1):\n    def __init__(self): #overrides C1.__init__\n        print \"C2 init\"\n        C1.__init__(self) #but we still want C1 to init the class too\n \n\n\n\n >>> C2()\n\"C2 init\"\n\"C1 init\"\n \n    ", "date_posted": "2013-12-24 22:23:49Z", "upvote": "\r\n            22\r\n        ", "accepted": "No", "user": {"stack_user_id": "707111", "name": "Ry-", "reputation_score": "211k"}, "answer_comments": []}, {"stack_answer_id": "12201574", "answer_content": "\r\n Its use is similar to the use of  this  keyword in Java, i.e. to give a reference to the current object. \n    ", "date_posted": "2017-02-27 09:47:48Z", "upvote": "\r\n            18\r\n        ", "accepted": "No", "user": {"stack_user_id": "5387193", "name": "ChickenFeet", "reputation_score": "2,417"}, "answer_comments": [{"stack_answer_id": "12201574", "stack_answer_comment_id": "17780797", "comment_content": "class myClass:         def myFunc(this, name):             this.name = name", "user_id": "None"}]}, {"stack_answer_id": "30442095", "answer_content": "\r\n Python is not a language built for Object Oriented Programming unlike Java or C++.  \n\n When calling a static method in Python, one simply writes a method with regular arguments inside it.  \n\n class Animal():\n    def staticMethod():\n        print \"This is a static method\"\n \n\n However, an object method, which requires you to make a variable, which is an Animal, in this case, needs the self argument \n\n class Animal():\n    def objectMethod(self):\n        print \"This is an object method which needs an instance of a class\"\n \n\n The self method is also used to refer to a variable field within the class.  \n\n class Animal():\n    #animalName made in constructor\n    def Animal(self):\n        self.animalName = \"\";\n\n\n    def getAnimalName(self):\n        return self.animalName\n \n\n In this case, self is referring to the animalName variable of the entire class. REMEMBER: If you have a variable within a method, self will not work. That variable is simply existent only while that method is running. For defining fields (the variables of the entire class), you have to define them OUTSIDE the class methods.  \n\n If you don't understand a single word of what I am saying, then Google \"Object Oriented Programming.\" Once you understand this, you won't even need to ask that question :). \n    ", "date_posted": "2017-09-21 18:39:06Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "4871483", "name": "rassa45", "reputation_score": "3,406"}, "answer_comments": [{"stack_answer_id": "30442095", "stack_answer_comment_id": "51164282", "comment_content": "+1 because of the distinction between ", "user_id": "None"}, {"stack_answer_id": "30442095", "stack_answer_comment_id": "57247895", "comment_content": "What you are saying isn't 100% true. That's just a convention. You can still call the static method from an object created. You just won't be able to use any class members because you didn't declare a self. I can even call Animal.objectMethod(animalObj) to call the non static. Basically this means a static method is only a method that doesn't use member variables. There shouldn't be any need to declare self. It's a silly language requirement I think. Languages like Lua and C++ give you obj variables behind the scenes.", "user_id": "None"}, {"stack_answer_id": "30442095", "stack_answer_comment_id": "79661861", "comment_content": "You made a useless animalName string declaration and crashing animalName method.", "user_id": "None"}, {"stack_answer_id": "30442095", "stack_answer_comment_id": "79662136", "comment_content": "@ytpillai Irrelevant. Confusing and incorrect code should not be presented as an answer.", "user_id": "None"}, {"stack_answer_id": "30442095", "stack_answer_comment_id": "79662264", "comment_content": " to not clobber the string you're trying to return, and ", "user_id": "None"}]}, {"stack_answer_id": "48219699", "answer_content": "\r\n First of all, self is a conventional name, you could put anything else (being coherent) in its stead. \n\n It refers to the object itself, so when you are using it, you are declaring that .name and .age are properties of the Student objects (note, not of the Student class) you are going to create. \n\n class Student:\n    #called each time you create a new Student instance\n    def __init__(self,name,age): #special method to initialize\n        self.name=name\n        self.age=age\n\n    def __str__(self): #special method called for example when you use print\n        return \"Student %s is %s years old\" %(self.name,self.age)\n\n    def call(self, msg): #silly example for custom method\n        return (\"Hey, %s! \"+msg) %self.name\n\n#initializing two instances of the student class\nbob=Student(\"Bob\",20)\nalice=Student(\"Alice\",19)\n\n#using them\nprint bob.name\nprint bob.age\nprint alice #this one only works if you define the __str__ method\nprint alice.call(\"Come here!\") #notice you don't put a value for self\n\n#you can modify attributes, like when alice ages\nalice.age=20\nprint alice\n \n\n Code is here  \n    ", "date_posted": "2018-01-12 04:45:25Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "6464277", "name": "Akash Kandpal", "reputation_score": "2,684"}, "answer_comments": []}, {"stack_answer_id": "2709836", "answer_content": "\r\n self  is an object reference to the object itself, therefore, they are same.\nPython methods are not called in the context of the object itself.\n self  in Python may be used to deal with custom object models or something. \n    ", "date_posted": "2010-04-25 20:26:35Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "303939", "name": "Ming-Tang", "reputation_score": "17.1k"}, "answer_comments": []}, {"stack_answer_id": "18278904", "answer_content": "\r\n It\u2019s there to follow the Python zen \u201cexplicit is better than implicit\u201d. It\u2019s indeed a reference to your class object. In Java and PHP, for example, it's called  this . \n\n If  user_type_name  is a field on your model you access it by  self.user_type_name . \n    ", "date_posted": "2013-12-24 22:24:58Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "707111", "name": "Ry-", "reputation_score": "211k"}, "answer_comments": []}, {"stack_answer_id": "34750920", "answer_content": "\r\n I'm surprised nobody has brought up Lua. Lua also uses the 'self' variable however it can be omitted but still used. C++ does the same with 'this'. I don't see any reason to have to declare 'self' in each function but you should still be able to use it just like you can with lua and C++. For a language that prides itself on being brief it's odd that it requires you to declare the self variable. \n    ", "date_posted": "2016-01-12 18:10:32Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "441521", "name": "user441521", "reputation_score": "6,684"}, "answer_comments": []}, {"stack_answer_id": "51631485", "answer_content": "\r\n The use of the argument, conventionally called  self  isn't as hard to understand, as is why is it necessary? Or as to why explicitly mention it? That, I suppose, is a bigger question for most users who look up this question, or if it is not, they will certainly have the same question as they move forward learning python. I recommend them to read these couple of blogs: \n\n 1: Use of self explained \n\n Note that it is not a keyword. \n\n \n   The first argument of every class method, including init, is always a reference to the current instance of the class. By convention, this argument is always named self. In the init method, self refers to the newly created object; in other class methods, it refers to the instance whose method was called. For example the below code is the same as the above code. \n \n\n 2: Why do we have it this way and why can we not eliminate it as an argument, like Java, and have a keyword instead \n\n Another thing I would like to add is, an optional  self  argument allows me to declare static methods inside a class, by not writing  self . \n\n Code examples: \n\n class MyClass():\n    def staticMethod():\n        print \"This is a static method\"\n\n    def objectMethod(self):\n        print \"This is an object method which needs an instance of a class, and that is what self refers to\"\n \n\n PS :This works only in Python 3.x. \n\n In previous versions, you have to explicitly add  @staticmethod  decorator, otherwise  self  argument is obligatory.  \n    ", "date_posted": "2018-08-12 10:20:06Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "5758889", "name": "Bugs Buggy", "reputation_score": "1,494"}, "answer_comments": []}, {"stack_answer_id": "26943812", "answer_content": "\r\n Take a look at the following example, which clearly explains the purpose of  self \n\n class Restaurant(object):  \n    bankrupt = False\n\n    def open_branch(self):\n        if not self.bankrupt:\n           print(\"branch opened\")\n\n#create instance1\n>>> x = Restaurant()\n>>> x.bankrupt\nFalse\n\n#create instance2\n>>> y = Restaurant()\n>>> y.bankrupt = True   \n>>> y.bankrupt\nTrue\n\n>>> x.bankrupt\nFalse  \n \n\n self  is used/needed to distinguish between instances. \n\n Source:  self variable in python explained - Pythontips \n    ", "date_posted": "2020-05-19 22:05:41Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "2956066", "name": "kmario23", "reputation_score": "52.1k"}, "answer_comments": [{"stack_answer_id": "26943812", "stack_answer_comment_id": "57247643", "comment_content": "Yes, I think we know why self is used, but the question is why does the language make you explicitly declare it. Many other languages don't require this and a language which prides itself on being brief, you'd think they would just give you the variable behind the scenes to use like Lua or C++ (this) does.", "user_id": "None"}, {"stack_answer_id": "26943812", "stack_answer_comment_id": "86661379", "comment_content": "@kmario23 You're response was from here: ", "user_id": "None"}]}, {"stack_answer_id": "32243243", "answer_content": "\r\n Is because by the way python is designed the alternatives would hardly work. Python is designed to allow methods or functions to be defined in a context where both implicit  this  (a-la Java/C++) or explicit  @  (a-la ruby) wouldn't work. Let's have an example with the explicit approach with python conventions: \n\n def fubar(x):\n    self.x = x\n\nclass C:\n    frob = fubar\n \n\n Now the  fubar  function wouldn't work since it would assume that  self  is a global variable (and in  frob  as well). The alternative would be to execute method's with a replaced global scope (where  self  is the object). \n\n The implicit approach would be \n\n def fubar(x)\n    myX = x\n\nclass C:\n    frob = fubar\n \n\n This would mean that  myX  would be interpreted as a local variable in  fubar  (and in  frob  as well). The alternative here would be to execute methods with a replaced local scope which is retained between calls, but that would remove the posibility of method local variables. \n\n However the current situation works out well: \n\n  def fubar(self, x)\n     self.x = x\n\n class C:\n     frob = fubar\n \n\n here when called as a method  frob  will receive the object on which it's called via the  self  parameter, and  fubar  can still be called with an object as parameter and work the same (it  is  the same as  C.frob  I think). \n    ", "date_posted": "2015-08-27 07:31:02Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "4498329", "name": "skyking", "reputation_score": "13.3k"}, "answer_comments": []}, {"stack_answer_id": "21367245", "answer_content": "\r\n In the  __init__  method, self refers to the newly created object; in other class methods, it refers to the instance whose method was called. \n\n self, as a name, is  just a convention , call it as you want ! but when using it, for example to delete the object, you have to use the same name:  __del__(var) , where  var  was used in the  __init__(var,[...]) \n\n You should take a look at  cls  too, to have  the bigger picture . This  post  could be helpful. \n    ", "date_posted": "2017-05-23 12:18:30Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}, {"stack_answer_id": "58585068", "answer_content": "\r\n self is acting as like current object name or instance of class . \n\n # Self explanation.\n\n\n class classname(object):\n\n    def __init__(self,name):\n\n        self.name=name\n        # Self is acting as a replacement of object name.\n        #self.name=object1.name\n\n   def display(self):\n      print(\"Name of the person is :\",self.name)\n      print(\"object name:\",object1.name)\n\n\n object1=classname(\"Bucky\")\n object2=classname(\"ford\")\n\n object1.display()\n object2.display()\n\n###### Output \nName of the person is : Bucky\nobject name: Bucky\nName of the person is : ford\nobject name: Bucky\n \n    ", "date_posted": "2019-10-28 02:15:18Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "9724968", "name": "sameer_nubia", "reputation_score": "661"}, "answer_comments": []}, {"stack_answer_id": "63320527", "answer_content": "\r\n \"self\" keyword holds the reference of class and it is upto you if you want to use it or not but if you notice, whenever you create a new method in python, python automatically write self keyword for you. If you do some R&D, you will notice that if you create say two methods in a class and try to call one inside another, it does not recognize method unless you add self (reference of class). \n class testA:\ndef __init__(self):\n    print('ads')\ndef m1(self):\n    print('method 1')\n    self.m2()\ndef m2(self):\n    print('method 2')\n \n Below code throws unresolvable reference error. \n class testA:\ndef __init__(self):\n    print('ads')\ndef m1(self):\n    print('method 1')\n    m2()  #throws unresolvable reference error as class does not know if m2 exist in class scope\ndef m2(self):\n    print('method 2')\n \n Now let see below example \n class testA:\ndef __init__(self):\n    print('ads')\ndef m1(self):\n    print('method 1')\ndef m2():\n    print('method 2')\n \n Now when you create object of class testA, you can call method m1() using class object like this as method m1() has included self keyword \n obj = testA()\nobj.m1()\n \n But if you want to call method m2(), because is has no self reference so you can call m2() directly using class name like below \n testA.m2()\n \n But keep in practice to live with self keyword as there are other benefits too of it like creating global variable inside and so on. \n    ", "date_posted": "2020-08-09 08:33:08Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "4268680", "name": "Rahul Jha", "reputation_score": "726"}, "answer_comments": []}, {"stack_answer_id": "56279547", "answer_content": "\r\n self  is inevitable. \n\n There was just a  question  should  self  be implicit or explicit.\n Guido van Rossum  resolved this question saying  self  has to stay . \n\n So where the  self  live? \n\n If we would just stick to functional programming we would not need  self .\nOnce we enter the  Python OOP  we find  self  there. \n\n Here is the typical use case  class C  with the method  m1 \n\n class C:\n    def m1(self, arg):\n        print(self, ' inside')\n        pass\n\nci =C()\nprint(ci, ' outside')\nci.m1(None)\nprint(hex(id(ci))) # hex memory address\n \n\n \n\n This program will output: \n\n <__main__.C object at 0x000002B9D79C6CC0>  outside\n<__main__.C object at 0x000002B9D79C6CC0>  inside\n0x2b9d79c6cc0\n \n\n So  self  holds the memory address of the class instance.\n The purpose  of  self  would be to hold the reference for  instance methods  and for us to have  explicit  access to that reference.      \n\n \n\n Note there are three different types of class methods:  \n\n \n static methods (read: functions),  \n class methods,  \n instance methods (mentioned). \n \n    ", "date_posted": "2019-05-25 08:53:24Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "5884955", "name": "prosti", "reputation_score": "36.9k"}, "answer_comments": []}, {"stack_answer_id": "67015236", "answer_content": "\r\n The word 'self' refers to instance of a class \n class foo:\n      def __init__(self, num1, num2):\n             self.n1 = num1 #now in this it will make the perimeter num1 and num2 access across the whole class\n             self.n2 = num2\n      def add(self):\n             return self.n1 + self.n2 # if we had not written self then if would throw an error that n1 and n2 is not defined and we have to include self in the function's perimeter to access it's variables\n \n    ", "date_posted": "2021-04-09 04:52:32Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "15394199", "name": "PrabhavDevo", "reputation_score": "1,270"}, "answer_comments": []}, {"stack_answer_id": "2709828", "answer_content": "\r\n it's an explicit reference to the class instance object.  \n    ", "date_posted": "2010-04-25 20:24:57Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "12855", "name": "SilentGhost", "reputation_score": "291k"}, "answer_comments": [{"stack_answer_id": "2709828", "stack_answer_comment_id": "2734185", "comment_content": "I don't think this helps richzilla to understand the reason behind it.", "user_id": "None"}, {"stack_answer_id": "2709828", "stack_answer_comment_id": "80247629", "comment_content": "@SilentGhost: you have nailed it. I am impressed. if I understand it correctly: I do create an object as an instance of the defined class and the self parameter refers to that object? I understand self refers in implicit way to the class itself but it would be great if you explain your answer a bit more.", "user_id": "None"}]}, {"stack_answer_id": "60412005", "answer_content": "\r\n from the  docs ,  \n\n \n   the special thing about methods is that the instance object is passed as the first argument of the function. In our example, the call  x.f()  is exactly equivalent to  MyClass.f(x) . In general, calling a method with a list of n arguments is equivalent to calling the corresponding function with an argument list that is created by inserting the method\u2019s instance object before the first argument. \n \n\n preceding this the related snippet, \n\n class MyClass:\n    \"\"\"A simple example class\"\"\"\n    i = 12345\n\n    def f(self):\n        return 'hello world'\n \n\n x = MyClass()\n \n    ", "date_posted": "2020-02-26 10:39:14Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "6903290", "name": "laxman", "reputation_score": "1,342"}, "answer_comments": []}, {"stack_answer_id": "62536337", "answer_content": "\r\n I would say for Python at least, the self parameter can be thought of as a placeholder.\nTake a look at this: \n class Person:\n  def __init__(self, name, age):\n    self.name = name\n    self.age = age\n\np1 = Person(\"John\", 36)\n\nprint(p1.name)\nprint(p1.age)\n \n Self in this case and a lot of others was used as a method to say store the name value. However, after that, we use the p1 to assign it to the class we're using. Then when we print it we use the same p1 keyword. \n Hope this helps for Python! \n    ", "date_posted": "2020-06-23 13:50:57Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "13750055", "name": "Rishi", "reputation_score": "41"}, "answer_comments": []}, {"stack_answer_id": "65461903", "answer_content": "\r\n my little 2 cents \n In this class Person, we defined out  init  method with the self and interesting thing to notice here is the memory location of both the  self  and instance variable  p  is same  <__main__.Person object at 0x106a78fd0> \n class Person:\n\n    def __init__(self, name, age):\n        self.name = name \n        self.age = age \n\n    def say_hi(self):\n        print(\"the self is at:\", self)\n        print((f\"hey there, my name is {self.name} and I am {self.age} years old\"))\n\n    def say_bye(self):\n        print(\"the self is at:\", self)\n        print(f\"good to see you {self.name}\")\n\np = Person(\"john\", 78)\nprint(\"the p is at\",p)\np.say_hi()  \np.say_bye() \n \n so as explained in above, both self and instance variable are same object. \n    ", "date_posted": "2020-12-27 00:13:06Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "9476814", "name": "saran", "reputation_score": "326"}, "answer_comments": []}], "user": {"stack_user_id": "301032", "name": "richzilla", "reputation_score": "38.6k"}, "question_comments": [{"stack_question_id": "2709821", "stack_question_comment_id": "2734198", "comment_content": "You may find interesting this essay \"Why explicit self has to stay\" by Guido van Rossum: ", "user_id": "None"}, {"stack_question_id": "2709821", "stack_question_comment_id": "2734210", "comment_content": "See also \"Why must 'self' be used explicitly in method definitions and calls\": ", "user_id": "None"}, {"stack_question_id": "2709821", "stack_question_comment_id": "2752890", "comment_content": "\"Which i understand, quite easily\" ---  Quite subjective, don't you think? What makes ", "user_id": "None"}, {"stack_question_id": "2709821", "stack_question_comment_id": "2752966", "comment_content": "Although to play devils advocate its very easy to forget to add an additional argument to each method and have bizarre behavior when you forget which makes it hard for beginners. IMHO I rather be specific about unusual things like static methods then normal behavior like instance methods.", "user_id": "None"}, {"stack_question_id": "2709821", "stack_question_comment_id": "11116129", "comment_content": "That's the key difference between a function and a class method. A function is floating free, unencumbered. A class (instance) method has to be aware of it's parent (and parent properties) so you need to pass the method a reference to the parent class (as ", "user_id": "None"}]},
{"stack_question_id": "29640685", "question_title": "How do I detect collision in pygame?", "question_content": "\r\n                I have made a list of bullets and a list of sprites using the classes below. How do I detect if a bullet collides with a sprite and then delete that sprite and the bullet?\n\n#Define the sprite class\n...\r\n", "question_url": "/questions/29640685/how-do-i-detect-collision-in-pygame", "date_posted": "Apr 15, 2015 at 2:38", "upvote": "2", "view": "9", "tags": ["python", "pygame", "collision-detection", "pygame-surface", "pygame2"], "answers_count": "5", "answers": [{"stack_answer_id": "65064907", "answer_content": "\r\n In PyGame, collision detection is done using  pygame.Rect  objects. The  Rect  object offers various methods for detecting collisions between objects. Even the collision between a rectangular and circular object such as a paddle and a ball can be detected by a collision between two rectangular objects, the paddle and the bounding rectangle of the ball. \n Some examples: \n \n pygame.Rect.collidepoint : \n \n Test if a point is inside a rectangle \n \n  repl.it/@Rabbid76/PyGame-collidepoint \n \n import pygame\n\npygame.init()\nwindow = pygame.display.set_mode((250, 250))\nrect = pygame.Rect(*window.get_rect().center, 0, 0).inflate(100, 100)\n\nrun = True\nwhile run:\n    for event in pygame.event.get():\n        if event.type == pygame.QUIT:\n            run = False\n\n    point = pygame.mouse.get_pos()\n    collide = rect.collidepoint(point)\n    color = (255, 0, 0) if collide else (255, 255, 255)\n\n    window.fill(0)\n    pygame.draw.rect(window, color, rect)\n    pygame.display.flip()\n\npygame.quit()\nexit()\n \n \n pygame.Rect.colliderect \n \n Test if two rectangles overlap \n \n See also  How to detect collisions between two rectangular objects or images in pygame \n  repl.it/@Rabbid76/PyGame-colliderect \n \n import pygame\n\npygame.init()\nwindow = pygame.display.set_mode((250, 250))\nrect1 = pygame.Rect(*window.get_rect().center, 0, 0).inflate(75, 75)\nrect2 = pygame.Rect(0, 0, 75, 75)\n\nrun = True\nwhile run:\n    for event in pygame.event.get():\n        if event.type == pygame.QUIT:\n            run = False\n\n    rect2.center = pygame.mouse.get_pos()\n    collide = rect1.colliderect(rect2)\n    color = (255, 0, 0) if collide else (255, 255, 255)\n\n    window.fill(0)\n    pygame.draw.rect(window, color, rect1)\n    pygame.draw.rect(window, (0, 255, 0), rect2, 6, 1)\n    pygame.display.flip()\n\npygame.quit()\nexit()\n \n \n \n Furthermore,  pygame.Rect.collidelist  and  pygame.Rect.collidelistall  can be used for the collision test between a rectangle and a list of rectangles.  pygame.Rect.collidedict  and  pygame.Rect.collidedictall  can be used for the collision test between a rectangle and a dictionary of rectangles. \n The collision of  pygame.sprite.Sprite  and  pygame.sprite.Group  objects, can be detected by  pygame.sprite.spritecollide() ,  pygame.sprite.groupcollide()  or  pygame.sprite.spritecollideany() . When using these methods, the collision detection algorithm can be specified by the  collided  argument: \n \n The collided argument is a callback function used to calculate if two sprites are colliding. \n \n Possible  collided  callables are  collide_rect ,  collide_rect_ratio ,  collide_circle ,  collide_circle_ratio ,  collide_mask \n Some examples: \n \n pygame.sprite.spritecollide() \n  repl.it/@Rabbid76/PyGame-spritecollide \n \n import pygame\n\npygame.init()\nwindow = pygame.display.set_mode((250, 250))\n\nsprite1 = pygame.sprite.Sprite()\nsprite1.image = pygame.Surface((75, 75))\nsprite1.image.fill((255, 0, 0))\nsprite1.rect = pygame.Rect(*window.get_rect().center, 0, 0).inflate(75, 75)\nsprite2 = pygame.sprite.Sprite()\nsprite2.image = pygame.Surface((75, 75))\nsprite2.image.fill((0, 255, 0))\nsprite2.rect = pygame.Rect(*window.get_rect().center, 0, 0).inflate(75, 75)\n\nall_group = pygame.sprite.Group([sprite2, sprite1])\ntest_group = pygame.sprite.Group(sprite2)\n\nrun = True\nwhile run:\n    for event in pygame.event.get():\n        if event.type == pygame.QUIT:\n            run = False\n\n    sprite1.rect.center = pygame.mouse.get_pos()\n    collide = pygame.sprite.spritecollide(sprite1, test_group, False)\n\n    window.fill(0)\n    all_group.draw(window)\n    for s in collide:\n        pygame.draw.rect(window, (255, 255, 255), s.rect, 5, 1)\n    pygame.display.flip()\n\npygame.quit()\nexit()\n \n \n \n For a collision with masks, see  How can I make a collision mask?  or  Pygame mask collision \n See also  Collision and Intersection \n \n pygame.sprite.spritecollide()  /  collide_circle \n  repl.it/@Rabbid76/PyGame-spritecollidecollidecircle \n \n import pygame\n\npygame.init()\nwindow = pygame.display.set_mode((250, 250))\n\nsprite1 = pygame.sprite.Sprite()\nsprite1.image = pygame.Surface((80, 80), pygame.SRCALPHA)\npygame.draw.circle(sprite1.image, (255, 0, 0), (40, 40), 40)\nsprite1.rect = pygame.Rect(*window.get_rect().center, 0, 0).inflate(40, 40)\nsprite2 = pygame.sprite.Sprite()\nsprite2.image = pygame.Surface((80, 89), pygame.SRCALPHA)\npygame.draw.circle(sprite2.image, (0, 255, 0), (40, 40), 40)\nsprite2.rect = pygame.Rect(*window.get_rect().center, 0, 0).inflate(80, 80)\n\nall_group = pygame.sprite.Group([sprite2, sprite1])\ntest_group = pygame.sprite.Group(sprite2)\n\nrun = True\nwhile run:\n    for event in pygame.event.get():\n        if event.type == pygame.QUIT:\n            run = False\n\n    sprite1.rect.center = pygame.mouse.get_pos()\n    collide = pygame.sprite.spritecollide(sprite1, test_group, False, pygame.sprite.collide_circle)\n\n    window.fill(0)\n    all_group.draw(window)\n    for s in collide:\n        pygame.draw.circle(window, (255, 255, 255), s.rect.center, s.rect.width // 2, 5)\n    pygame.display.flip()\n\npygame.quit()\nexit()\n \n \n \n \n What does this all mean for your code? \n pygame.Surface.get_rect.get_rect()  returns a rectangle with the size of the  Surface  object, that always starts at (0, 0) since a  Surface  object has no position. The position of the rectangle can be specified by a keyword argument. For example, the centre of the rectangle can be specified with the keyword argument  center . These keyword arguments are applied to the attributes of the  pygame.Rect  before it is returned (see  pygame.Rect  for a list of the keyword arguments). \nSee * Why is my collision test always returning 'true' and why is the position of the rectangle of the image always wrong (0, 0)? \n You do not need the  x  and  y  attributes of  Sprite  and  Bullet  at all. Use the position of the  rect  attribute instead: \n #Define the sprite class\nclass Sprite:\n    def __init__(self, x, y, name):\n        self.image = pygame.image.load(name)\n        self.rect = self.image.get_rect(topleft = (x, y))\n\n    def render(self):\n        window.blit(self.image, self.rect)\n\n# Define the bullet class to create bullets          \nclass Bullet:\n    def __init__(self, x, y):\n        self.bullet = pygame.image.load(\"user_bullet.BMP\")\n        self.rect = self.bullet.get_rect(topleft = (x + 23, y))\n\n    def render(self):\n        window.blit(self.bullet, self.rect)\n \n Use  pygame.Rect.colliderect()  to detect collisions between instances of  Sprite  and  Bullet . \nSee  How to detect collisions between two rectangular objects or images in pygame : \n my_sprite = Sprite(sx, sy, name)\nmy_bullet = Bullet(by, by)\n \n while True:\n    # [...]\n\n    if my_sprite.rect.colliderect(my_bullet.rect):\n        printe(\"hit\")\n \n    ", "date_posted": "2022-06-20 05:17:50Z", "upvote": "\r\n            64\r\n        ", "accepted": "No", "user": {"stack_user_id": "19372340", "name": "Joshua Rose", "reputation_score": "11"}, "answer_comments": []}, {"stack_answer_id": "29641464", "answer_content": "\r\n From what I understand of pygame you just need to check if the two rectangles overlap using the  colliderect  method. One way to do it is to have a method in your  Bullet  class that checks for collisions: \n\n def is_collided_with(self, sprite):\n    return self.rect.colliderect(sprite.rect)\n \n\n Then you can call it like: \n\n sprite = Sprite(10, 10, 'my_sprite')\nbullet = Bullet(20, 10)\nif bullet.is_collided_with(sprite):\n    print('collision!')\n    bullet.kill()\n    sprite.kill()\n \n    ", "date_posted": "2020-01-03 21:48:42Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "1470749", "name": "101", "reputation_score": "8,012"}, "answer_comments": [{"stack_answer_id": "29641464", "stack_answer_comment_id": "47424513", "comment_content": "Note that if the speed of bullet relative to the target is more than target's width per tick, the bullet can just 'teleport' to the other side of the target without hitting. If this might be the case, you might need to check against a rectangle that represents the trajectory of the bullet from the previous frame to the current frame, not just the bullet itself.", "user_id": "None"}]}, {"stack_answer_id": "40338475", "answer_content": "\r\n There is a very simple method for what you are trying to do using built in methods. \n\n here is an example. \n\n import pygame\nimport sys\n\nclass Sprite(pygame.sprite.Sprite):\n    def __init__(self, pos):\n        pygame.sprite.Sprite.__init__(self)\n        self.image = pygame.Surface([20, 20])\n        self.image.fill((255, 0, 0))\n        self.rect = self.image.get_rect()\n\n        self.rect.center = pos\n\ndef main():\n    pygame.init()\n    clock = pygame.time.Clock()\n    fps = 50\n    bg = [255, 255, 255]\n    size =[200, 200]\n\n\n    screen = pygame.display.set_mode(size)\n\n    player = Sprite([40, 50])\n    player.move = [pygame.K_LEFT, pygame.K_RIGHT, pygame.K_UP, pygame.K_DOWN]\n    player.vx = 5\n    player.vy = 5\n\n\n    wall = Sprite([100, 60])\n\n    wall_group = pygame.sprite.Group()\n    wall_group.add(wall)\n\n    player_group = pygame.sprite.Group()\n    player_group.add(player)\n\n    # I added loop for a better exit from the game\n    loop = 1\n    while loop:\n        for event in pygame.event.get():\n            if event.type == pygame.QUIT:\n                loop = 0\n\n        key = pygame.key.get_pressed()\n\n        for i in range(2):\n            if key[player.move[i]]:\n                player.rect.x += player.vx * [-1, 1][i]\n\n        for i in range(2):\n            if key[player.move[2:4][i]]:\n                player.rect.y += player.vy * [-1, 1][i]\n\n        screen.fill(bg)\n\n        # first parameter takes a single sprite\n        # second parameter takes sprite groups\n        # third parameter is a do kill command if true\n        # all group objects colliding with the first parameter object will be\n        # destroyed. The first parameter could be bullets and the second one\n        # targets although the bullet is not destroyed but can be done with\n        # simple trick bellow\n        hit = pygame.sprite.spritecollide(player, wall_group, True)\n\n        if hit:\n            # if collision is detected call a function in your case destroy\n            # bullet\n            player.image.fill((255, 255, 255))\n\n        player_group.draw(screen)\n        wall_group.draw(screen)\n\n        pygame.display.update()\n        clock.tick(fps)\n\n    pygame.quit()\n    # sys.exit\n\n\nif __name__ == '__main__':\n    main()\n \n    ", "date_posted": "2019-11-01 17:53:22Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "6464947", "name": "PythonProgrammi", "reputation_score": "20.8k"}, "answer_comments": []}, {"stack_answer_id": "56195193", "answer_content": "\r\n Make a group for the bullets, and then add the bullets to the group. \n\n What I would do is this:\nIn the class for the player: \n\n def collideWithBullet(self):\n    if pygame.sprite.spritecollideany(self, 'groupName'):\n        print(\"CollideWithBullet!!\")\n        return True\n \n\n And in the main loop somewhere:   \n\n def run(self):\n    if self.player.collideWithBullet():\n         print(\"Game Over\")\n \n\n Hopefully that works for you!!! \n    ", "date_posted": "2019-05-18 01:15:02Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "11483179", "name": "jaden.joeyak", "reputation_score": "91"}, "answer_comments": []}, {"stack_answer_id": "72277288", "answer_content": "\r\n Inside the Sprite class, try adding a  self.mask  attribute with \n self.mask = pygame.mask.from_surface(self.image) \nand a  collide_mask  function inside of the Sprite class with this code: \n     def collide_mask(self, mask):\n        collided = False\n        mask_outline = mask.outline()\n        self.mask_outline = self.mask.outline()\n        for point in range(len(mask_outline)):\n            mask_outline[point] = list(mask_outline[point])\n            mask_outline[point][0] += bullet.x\n            mask_outline[point][1] += bullet.y\n        for point in range(len(self.mask_outline)):\n            self.mask_outline[point] = list(mask_outline[point])\n            self.mask_outline[point][0] += self.x\n            self.mask_outline[point][1] += self.y\n        for point in mask_outline:\n            for self_mask_point in self.mask_outline:\n                if point = self_mask_point:\n                    collided = True\n        return collided\n \n    ", "date_posted": "2022-05-19 00:54:05Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "5014656", "name": "Soumendra", "reputation_score": "1,347"}, "answer_comments": []}], "user": {"stack_user_id": "4744250", "name": "Mike Schmidt", "reputation_score": "843"}, "question_comments": [{"stack_question_id": "29640685", "stack_question_comment_id": "47451199", "comment_content": "I would notes that there is a Sprite Class in pygame - I am not sure redefining it in your code is a good idea. Besides are they really targets (for want of a better word), as a sprite is simply an object with a graphical representation on screen (and therefore your Bullet is a sprite too).", "user_id": "None"}]},
{"stack_question_id": "19960077", "question_title": "How to filter Pandas dataframe using 'in' and 'not in' like in SQL", "question_content": "\r\n                How can I achieve the equivalents of SQL's IN and NOT IN?\nI have a list with the required values.\nHere's the scenario:\ndf = pd.DataFrame({'country': ['US', 'UK', 'Germany', 'China']})\n...\r\n", "question_url": "/questions/19960077/how-to-filter-pandas-dataframe-using-in-and-not-in-like-in-sql", "date_posted": "Nov 13, 2013 at 17:11", "upvote": "7", "view": "9", "tags": ["python", "pandas", "dataframe", "sql-function"], "answers_count": "1", "answers": [{"stack_answer_id": "19960116", "answer_content": "\r\n You can use  pd.Series.isin . \n For \"IN\" use:  something.isin(somewhere) \n Or for \"NOT IN\":  ~something.isin(somewhere) \n As a worked example: \n import pandas as pd\n\n>>> df\n  country\n0        US\n1        UK\n2   Germany\n3     China\n>>> countries_to_keep\n['UK', 'China']\n>>> df.country.isin(countries_to_keep)\n0    False\n1     True\n2    False\n3     True\nName: country, dtype: bool\n>>> df[df.country.isin(countries_to_keep)]\n  country\n1        UK\n3     China\n>>> df[~df.country.isin(countries_to_keep)]\n  country\n0        US\n2   Germany\n \n    ", "date_posted": "2020-07-09 19:25:24Z", "upvote": "\r\n            1300\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "12814639", "name": "gpr", "reputation_score": "106"}, "answer_comments": [{"stack_answer_id": "19960116", "stack_answer_comment_id": "29714037", "comment_content": "If you're actually dealing with 1-dimensional arrays (like in you're example) then on you're first line use a Series instead of a DataFrame, like @DSM used: ", "user_id": "None"}, {"stack_answer_id": "19960116", "stack_answer_comment_id": "29747942", "comment_content": "@TomAugspurger: like usual, I'm probably missing something.  ", "user_id": "None"}, {"stack_answer_id": "19960116", "stack_answer_comment_id": "87855266", "comment_content": "This answer is confusing because you keep reusing the ", "user_id": "None"}, {"stack_answer_id": "19960116", "stack_answer_comment_id": "108599103", "comment_content": "@ifly6 : Agreed, I made the same mistake and realized it when I got a error : \"'DataFrame' object has no attribute 'countries'", "user_id": "None"}, {"stack_answer_id": "19960116", "stack_answer_comment_id": "118083299", "comment_content": "For people who are confused by the tilde (like me): ", "user_id": "None"}]}, {"stack_answer_id": "45190397", "answer_content": "\r\n Alternative solution that uses  .query()  method: \n In [5]: df.query(\"countries in @countries_to_keep\")\nOut[5]:\n  countries\n1        UK\n3     China\n\nIn [6]: df.query(\"countries not in @countries_to_keep\")\nOut[6]:\n  countries\n0        US\n2   Germany\n \n    ", "date_posted": "2021-09-07 06:46:56Z", "upvote": "\r\n            133\r\n        ", "accepted": "No", "user": {"stack_user_id": "5741205", "name": "MaxU - stop genocide of UA", "reputation_score": "195k"}, "answer_comments": [{"stack_answer_id": "45190397", "stack_answer_comment_id": "112681283", "comment_content": ".query is so much more readable. Especially for the \"not in\" scenario, vs a distant tilde. Thanks!", "user_id": "None"}, {"stack_answer_id": "45190397", "stack_answer_comment_id": "122096421", "comment_content": "What is @countries ? Another dataframe ? A list ?", "user_id": "None"}, {"stack_answer_id": "45190397", "stack_answer_comment_id": "122127585", "comment_content": "@FlorianCastelain countries are the column you want to check on, OP called this column", "user_id": "None"}, {"stack_answer_id": "45190397", "stack_answer_comment_id": "122129378", "comment_content": "@FlorianCastelain, somebody has renamed a variable in the original question: ", "user_id": "None"}, {"stack_answer_id": "45190397", "stack_answer_comment_id": "124255455", "comment_content": "The most readable solution indeed. I wonder if syntax exists to avoid creating ", "user_id": "None"}]}, {"stack_answer_id": "55554709", "answer_content": "\r\n \n   How to implement 'in' and 'not in' for a pandas DataFrame? \n \n\n Pandas offers two methods:  Series.isin  and  DataFrame.isin  for Series and DataFrames, respectively. \n\n \n\n Filter DataFrame Based on ONE Column (also applies to Series) \n\n The most common scenario is applying an  isin  condition on a specific column to filter rows in a DataFrame. \n\n df = pd.DataFrame({'countries': ['US', 'UK', 'Germany', np.nan, 'China']})\ndf\n  countries\n0        US\n1        UK\n2   Germany\n3     China\n\nc1 = ['UK', 'China']             # list\nc2 = {'Germany'}                 # set\nc3 = pd.Series(['China', 'US'])  # Series\nc4 = np.array(['US', 'UK'])      # array\n \n\n \n\n Series.isin  accepts various types as inputs. The following are all valid ways of getting what you want: \n\n df['countries'].isin(c1)\n\n0    False\n1     True\n2    False\n3    False\n4     True\nName: countries, dtype: bool\n\n# `in` operation\ndf[df['countries'].isin(c1)]\n\n  countries\n1        UK\n4     China\n\n# `not in` operation\ndf[~df['countries'].isin(c1)]\n\n  countries\n0        US\n2   Germany\n3       NaN\n \n\n \n\n # Filter with `set` (tuples work too)\ndf[df['countries'].isin(c2)]\n\n  countries\n2   Germany\n \n\n \n\n # Filter with another Series\ndf[df['countries'].isin(c3)]\n\n  countries\n0        US\n4     China\n \n\n \n\n # Filter with array\ndf[df['countries'].isin(c4)]\n\n  countries\n0        US\n1        UK\n \n\n \n\n Filter on MANY Columns \n\n Sometimes, you will want to apply an 'in' membership check with some search terms over multiple columns, \n\n df2 = pd.DataFrame({\n    'A': ['x', 'y', 'z', 'q'], 'B': ['w', 'a', np.nan, 'x'], 'C': np.arange(4)})\ndf2\n\n   A    B  C\n0  x    w  0\n1  y    a  1\n2  z  NaN  2\n3  q    x  3\n\nc1 = ['x', 'w', 'p']\n \n\n To apply the  isin  condition to both columns \"A\" and \"B\", use  DataFrame.isin : \n\n df2[['A', 'B']].isin(c1)\n\n      A      B\n0   True   True\n1  False  False\n2  False  False\n3  False   True\n \n\n From this,  to retain rows where at least one column is  True , we can use  any  along the first axis: \n\n df2[['A', 'B']].isin(c1).any(axis=1)\n\n0     True\n1    False\n2    False\n3     True\ndtype: bool\n\ndf2[df2[['A', 'B']].isin(c1).any(axis=1)]\n\n   A  B  C\n0  x  w  0\n3  q  x  3\n \n\n Note that if you want to search every column, you'd just omit the column selection step and do  \n\n df2.isin(c1).any(axis=1)\n \n\n Similarly,  to retain rows where ALL columns are  True , use  all  in the same manner as before. \n\n df2[df2[['A', 'B']].isin(c1).all(axis=1)]\n\n   A  B  C\n0  x  w  0\n \n\n \n\n Notable Mentions:  numpy.isin ,  query , list comprehensions (string data) \n\n In addition to the methods described above, you can also use the numpy equivalent:  numpy.isin . \n\n # `in` operation\ndf[np.isin(df['countries'], c1)]\n\n  countries\n1        UK\n4     China\n\n# `not in` operation\ndf[np.isin(df['countries'], c1, invert=True)]\n\n  countries\n0        US\n2   Germany\n3       NaN\n \n\n Why is it worth considering? NumPy functions are usually a bit faster than their pandas equivalents because of lower overhead. Since this is an elementwise operation that does not depend on index alignment, there are very few situations where this method is not an appropriate replacement for pandas'  isin . \n\n Pandas routines are usually iterative when working with strings, because string operations are hard to vectorise.  There is a lot of evidence to suggest that list comprehensions will be faster here. .\nWe resort to an  in  check now.  \n\n c1_set = set(c1) # Using `in` with `sets` is a constant time operation... \n                 # This doesn't matter for pandas because the implementation differs.\n# `in` operation\ndf[[x in c1_set for x in df['countries']]]\n\n  countries\n1        UK\n4     China\n\n# `not in` operation\ndf[[x not in c1_set for x in df['countries']]]\n\n  countries\n0        US\n2   Germany\n3       NaN\n \n\n It is a lot more unwieldy to specify, however, so don't use it unless you know what you're doing. \n\n Lastly, there's also  DataFrame.query  which has been covered in  this answer . numexpr FTW! \n    ", "date_posted": "2019-06-06 20:48:21Z", "upvote": "\r\n            82\r\n        ", "accepted": "No", "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "answer_comments": [{"stack_answer_id": "55554709", "stack_answer_comment_id": "103289706", "comment_content": "I like it, but what if I want to compare a column in df3 that isin df1 column?  What would that look like?", "user_id": "None"}]}, {"stack_answer_id": "19960136", "answer_content": "\r\n I've been usually doing generic filtering over rows like this: \n\n criterion = lambda row: row['countries'] not in countries\nnot_in = df[df.apply(criterion, axis=1)]\n \n    ", "date_posted": "2013-11-13 17:14:32Z", "upvote": "\r\n            18\r\n        ", "accepted": "No", "user": {"stack_user_id": "399317", "name": "Kos", "reputation_score": "68.5k"}, "answer_comments": [{"stack_answer_id": "19960136", "stack_answer_comment_id": "29710214", "comment_content": "FYI, this is much slower than @DSM soln which is vectorized", "user_id": "None"}, {"stack_answer_id": "19960136", "stack_answer_comment_id": "29730160", "comment_content": "@Jeff I'd expect that, but that's what I fall back to when I need to filter over something unavailable in pandas directly. (I was about to say \"like .startwith or regex matching, but just found out about Series.str that has all of that!)", "user_id": "None"}]}, {"stack_answer_id": "56407969", "answer_content": "\r\n Collating possible solutions from the answers: \n\n For IN:  df[df['A'].isin([3, 6])] \n\n For NOT IN: \n\n \n df[-df[\"A\"].isin([3, 6])] \n df[~df[\"A\"].isin([3, 6])] \n df[df[\"A\"].isin([3, 6]) == False] \n df[np.logical_not(df[\"A\"].isin([3, 6]))] \n \n    ", "date_posted": "2019-06-02 02:47:13Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "answer_comments": [{"stack_answer_id": "56407969", "stack_answer_comment_id": "99414948", "comment_content": "This mostly repeats information from other answers. Using ", "user_id": "None"}]}, {"stack_answer_id": "45070797", "answer_content": "\r\n I wanted to filter out dfbc rows that had a BUSINESS_ID that was also in the BUSINESS_ID of dfProfilesBusIds \n\n dfbc = dfbc[~dfbc['BUSINESS_ID'].isin(dfProfilesBusIds['BUSINESS_ID'])]\n \n    ", "date_posted": "2019-05-19 03:26:27Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "answer_comments": [{"stack_answer_id": "45070797", "stack_answer_comment_id": "77347669", "comment_content": "You can negate the isin (as done in the accepted answer)  rather than comparing to False", "user_id": "None"}]}, {"stack_answer_id": "69195120", "answer_content": "\r\n Why is no one talking about the performance of various filtering methods? In fact, this topic often pops up here (see the example). I did my own performance test for a large data set. It is very interesting and instructive. \n df = pd.DataFrame({'animals': np.random.choice(['cat', 'dog', 'mouse', 'birds'], size=10**7), \n                   'number': np.random.randint(0,100, size=(10**7,))})\n\ndf.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 10000000 entries, 0 to 9999999\nData columns (total 2 columns):\n #   Column   Dtype \n---  ------   ----- \n 0   animals  object\n 1   number   int64 \ndtypes: int64(1), object(1)\nmemory usage: 152.6+ MB\n \n %%timeit\n# .isin() by one column\nconditions = ['cat', 'dog']\ndf[df.animals.isin(conditions)]\n \n 367 ms \u00b1 2.34 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n \n %%timeit\n# .query() by one column\nconditions = ['cat', 'dog']\ndf.query('animals in @conditions')\n \n 395 ms \u00b1 3.9 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n \n %%timeit\n# .loc[]\ndf.loc[(df.animals=='cat')|(df.animals=='dog')]\n \n 987 ms \u00b1 5.17 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n \n %%timeit\ndf[df.apply(lambda x: x['animals'] in ['cat', 'dog'], axis=1)]\n \n 41.9 s \u00b1 490 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n \n %%timeit\nnew_df = df.set_index('animals')\nnew_df.loc[['cat', 'dog'], :]\n \n 3.64 s \u00b1 62.5 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n \n %%timeit\nnew_df = df.set_index('animals')\nnew_df[new_df.index.isin(['cat', 'dog'])]\n \n 469 ms \u00b1 8.98 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n \n %%timeit\ns = pd.Series(['cat', 'dog'], name='animals')\ndf.merge(s, on='animals', how='inner')\n \n 796 ms \u00b1 30.9 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n \n Thus, the  isin  method turned out to be the fastest and the method with  apply()  was the slowest, which is not surprising. \n    ", "date_posted": "2021-09-15 14:33:28Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "16591526", "name": "padu", "reputation_score": "294"}, "answer_comments": []}, {"stack_answer_id": "71227998", "answer_content": "\r\n You can also use  .isin()  inside  .query() : \n df.query('country.isin(@countries_to_keep).values')\n\n# Or alternatively:\ndf.query('country.isin([\"UK\", \"China\"]).values')\n \n To negate your query, use  ~ : \n df.query('~country.isin(@countries_to_keep).values')\n \n \n Update: \n Another way is to use comparison operators: \n df.query('country == @countries_to_keep')\n\n# Or alternatively:\ndf.query('country == [\"UK\", \"China\"]')\n \n And to negate the query, use  != : \n df.query('country != @countries_to_keep')\n \n    ", "date_posted": "2022-06-21 18:48:02Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "18145256", "name": "rachwa", "reputation_score": "770"}, "answer_comments": [{"stack_answer_id": "71227998", "stack_answer_comment_id": "126028674", "comment_content": "Good to know, although this is a bit less readable than ", "user_id": "2071807"}]}, {"stack_answer_id": "49650285", "answer_content": "\r\n df = pd.DataFrame({'countries':['US','UK','Germany','China']})\ncountries = ['UK','China']\n \n\n implement in :     \n\n df[df.countries.isin(countries)]\n \n\n implement not in  as in of rest countries: \n\n df[df.countries.isin([x for x in np.unique(df.countries) if x not in countries])]\n \n    ", "date_posted": "2018-04-04 11:51:01Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "8563649", "name": "Ioannis Nasios", "reputation_score": "7,996"}, "answer_comments": []}, {"stack_answer_id": "63918237", "answer_content": "\r\n A trick if you want to keep the order of the list: \n df = pd.DataFrame({'country': ['US', 'UK', 'Germany', 'China']})\ncountries_to_keep = ['Germany', 'US']\n\n\nind=[df.index[df['country']==i].tolist() for i in countries_to_keep]\nflat_ind=[item for sublist in ind for item in sublist]\n\ndf.reindex(flat_ind)\n\n   country\n2  Germany\n0       US\n \n    ", "date_posted": "2020-09-16 10:38:18Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "7183444", "name": "Billy Bonaros", "reputation_score": "1,539"}, "answer_comments": []}, {"stack_answer_id": "68108690", "answer_content": "\r\n My 2c worth:\nI needed a combination of in and ifelse statements for a dataframe, and this worked for me. \n sale_method = pd.DataFrame(model_data[\"Sale Method\"].str.upper())\nsale_method[\"sale_classification\"] = np.where(\n    sale_method[\"Sale Method\"].isin([\"PRIVATE\"]),\n    \"private\",\n    np.where(\n        sale_method[\"Sale Method\"].str.contains(\"AUCTION\"), \"auction\", \"other\"\n    ),\n)\n \n    ", "date_posted": "2021-06-24 09:17:55Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "2071807", "name": "LondonRob", "reputation_score": "65.3k"}, "answer_comments": []}], "user": {"stack_user_id": "2071807", "name": "LondonRob", "reputation_score": "65.3k"}, "question_comments": [{"stack_question_id": "19960077", "stack_question_comment_id": "89135565", "comment_content": "Related (performance / pandas internals): ", "user_id": "None"}, {"stack_question_id": "19960077", "stack_question_comment_id": "115748356", "comment_content": " is similar, but the negation ", "user_id": "None"}]},
{"stack_question_id": "19913659", "question_title": "Pandas conditional creation of a series/dataframe column", "question_content": "\r\n                How do I add a color column to the following dataframe so that color='green' if Set\u00a0==\u00a0'Z', and color='red' otherwise?\n    Type       Set\n1    A          Z\n2    B          Z           \n3    B          ...\r\n", "question_url": "/questions/19913659/pandas-conditional-creation-of-a-series-dataframe-column", "date_posted": "Nov 11, 2013 at 18:52", "upvote": "4", "view": "7", "tags": ["python", "pandas", "numpy", "dataframe"], "answers_count": "1", "answers": [{"stack_answer_id": "19913845", "answer_content": "\r\n If you only have two choices to select from: \n\n df['color'] = np.where(df['Set']=='Z', 'green', 'red')\n \n\n For example, \n\n import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({'Type':list('ABBC'), 'Set':list('ZZXY')})\ndf['color'] = np.where(df['Set']=='Z', 'green', 'red')\nprint(df)\n \n\n yields \n\n   Set Type  color\n0   Z    A  green\n1   Z    B  green\n2   X    B    red\n3   Y    C    red\n \n\n \n\n If you have more than two conditions then use  np.select . For example, if you want  color  to be  \n\n \n yellow  when  (df['Set'] == 'Z') & (df['Type'] == 'A') \n otherwise  blue  when  (df['Set'] == 'Z') & (df['Type'] == 'B')   \n otherwise  purple  when  (df['Type'] == 'B') \n otherwise  black , \n \n\n then use \n\n df = pd.DataFrame({'Type':list('ABBC'), 'Set':list('ZZXY')})\nconditions = [\n    (df['Set'] == 'Z') & (df['Type'] == 'A'),\n    (df['Set'] == 'Z') & (df['Type'] == 'B'),\n    (df['Type'] == 'B')]\nchoices = ['yellow', 'blue', 'purple']\ndf['color'] = np.select(conditions, choices, default='black')\nprint(df)\n \n\n which yields \n\n   Set Type   color\n0   Z    A  yellow\n1   Z    B    blue\n2   X    B  purple\n3   Y    C   black\n \n    ", "date_posted": "2020-01-09 21:47:51Z", "upvote": "\r\n            965\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "answer_comments": [{"stack_answer_id": "19913845", "stack_answer_comment_id": "118100469", "comment_content": "what is the reason for having to use numpy?", "user_id": "None"}, {"stack_answer_id": "19913845", "stack_answer_comment_id": "120730869", "comment_content": "It's the library ", "user_id": "None"}, {"stack_answer_id": "19913845", "stack_answer_comment_id": "125065370", "comment_content": "This code now (January 2022) returns ", "user_id": "None"}, {"stack_answer_id": "19913845", "stack_answer_comment_id": "128376343", "comment_content": "@Luis , for your case, it's not related to the np.select function, but rather caused by how you assign new Series / DataFrame values.  And the message is simply a warning. Please check this out: ", "user_id": "None"}]}, {"stack_answer_id": "31173785", "answer_content": "\r\n List comprehension is another way to create another column conditionally. If you are working with object dtypes in columns, like in your example, list comprehensions typically outperform most other methods. \n\n Example list comprehension: \n\n df['color'] = ['red' if x == 'Z' else 'green' for x in df['Set']]\n \n\n %timeit tests: \n\n import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({'Type':list('ABBC'), 'Set':list('ZZXY')})\n%timeit df['color'] = ['red' if x == 'Z' else 'green' for x in df['Set']]\n%timeit df['color'] = np.where(df['Set']=='Z', 'green', 'red')\n%timeit df['color'] = df.Set.map( lambda x: 'red' if x == 'Z' else 'green')\n\n1000 loops, best of 3: 239 \u00b5s per loop\n1000 loops, best of 3: 523 \u00b5s per loop\n1000 loops, best of 3: 263 \u00b5s per loop\n \n    ", "date_posted": "2017-08-16 16:49:28Z", "upvote": "\r\n            167\r\n        ", "accepted": "No", "user": {"stack_user_id": "4561314", "name": "stackoverflowuser2010", "reputation_score": "35.2k"}, "answer_comments": [{"stack_answer_id": "31173785", "stack_answer_comment_id": "74103959", "comment_content": "Note that, with much larger dataframes (think ", "user_id": "None"}, {"stack_answer_id": "31173785", "stack_answer_comment_id": "94824690", "comment_content": "Can the list comprehension method be used if the condition needs information from multiple columns? I am looking for something like this (this does not work): ", "user_id": "None"}, {"stack_answer_id": "31173785", "stack_answer_comment_id": "95178560", "comment_content": "Add iterrows to the dataframe, then you can access multiple columns via row:  ['red' if (row['Set'] == 'Z') & (row['Type'] == 'B') else 'green' for index, row in in df.iterrows()]", "user_id": "None"}, {"stack_answer_id": "31173785", "stack_answer_comment_id": "102364666", "comment_content": "Note this nice solution will not work if you need to take replacement values from another series in the data frame, such as ", "user_id": "None"}, {"stack_answer_id": "31173785", "stack_answer_comment_id": "106373265", "comment_content": "@cheekybastard Or don't, since ", "user_id": "None"}]}, {"stack_answer_id": "24074316", "answer_content": "\r\n Another way in which this could be achieved is  \n\n df['color'] = df.Set.map( lambda x: 'red' if x == 'Z' else 'green')\n \n    ", "date_posted": "2014-06-06 04:43:52Z", "upvote": "\r\n            28\r\n        ", "accepted": "No", "user": {"stack_user_id": "678613", "name": "acharuva", "reputation_score": "665"}, "answer_comments": []}, {"stack_answer_id": "42113965", "answer_content": "\r\n The following is slower than the approaches timed  here , but we can compute the extra column based on the contents of more than one column, and more than two values can be computed for the extra column. \n\n Simple example using just the \"Set\" column: \n\n def set_color(row):\n    if row[\"Set\"] == \"Z\":\n        return \"red\"\n    else:\n        return \"green\"\n\ndf = df.assign(color=df.apply(set_color, axis=1))\n\nprint(df)\n \n\n   Set Type  color\n0   Z    A    red\n1   Z    B    red\n2   X    B  green\n3   Y    C  green\n \n\n Example with more colours and more columns taken into account: \n\n def set_color(row):\n    if row[\"Set\"] == \"Z\":\n        return \"red\"\n    elif row[\"Type\"] == \"C\":\n        return \"blue\"\n    else:\n        return \"green\"\n\ndf = df.assign(color=df.apply(set_color, axis=1))\n\nprint(df)\n \n\n   Set Type  color\n0   Z    A    red\n1   Z    B    red\n2   X    B  green\n3   Y    C   blue\n \n\n Edit (21/06/2019): Using plydata \n\n It is also possible to use  plydata  to do this kind of things (this seems even slower than using  assign  and  apply , though). \n\n from plydata import define, if_else\n \n\n Simple  if_else : \n\n df = define(df, color=if_else('Set==\"Z\"', '\"red\"', '\"green\"'))\n\nprint(df)\n \n\n   Set Type  color\n0   Z    A    red\n1   Z    B    red\n2   X    B  green\n3   Y    C  green\n \n\n Nested  if_else : \n\n df = define(df, color=if_else(\n    'Set==\"Z\"',\n    '\"red\"',\n    if_else('Type==\"C\"', '\"green\"', '\"blue\"')))\n\nprint(df)                            \n \n\n   Set Type  color\n0   Z    A    red\n1   Z    B    red\n2   X    B   blue\n3   Y    C  green\n \n    ", "date_posted": "2019-06-21 15:23:50Z", "upvote": "\r\n            26\r\n        ", "accepted": "No", "user": {"stack_user_id": "1878788", "name": "bli", "reputation_score": "6,866"}, "answer_comments": [{"stack_answer_id": "42113965", "stack_answer_comment_id": "115250012", "comment_content": "How do we refer to other rows with this type of function? eg. ", "user_id": "None"}, {"stack_answer_id": "42113965", "stack_answer_comment_id": "115271309", "comment_content": "@ChrisDixon As far as I know, ", "user_id": "None"}]}, {"stack_answer_id": "42260631", "answer_content": "\r\n Here's yet another way to skin this cat, using a dictionary to map new values onto the keys in the list: \n\n def map_values(row, values_dict):\n    return values_dict[row]\n\nvalues_dict = {'A': 1, 'B': 2, 'C': 3, 'D': 4}\n\ndf = pd.DataFrame({'INDICATOR': ['A', 'B', 'C', 'D'], 'VALUE': [10, 9, 8, 7]})\n\ndf['NEW_VALUE'] = df['INDICATOR'].apply(map_values, args = (values_dict,))\n \n\n What's it look like: \n\n df\nOut[2]: \n  INDICATOR  VALUE  NEW_VALUE\n0         A     10          1\n1         B      9          2\n2         C      8          3\n3         D      7          4\n \n\n This approach can be very powerful when you have many  ifelse -type statements to make (i.e. many unique values to replace). \n\n And of course you could always do this: \n\n df['NEW_VALUE'] = df['INDICATOR'].map(values_dict)\n \n\n But that approach is more than three times as slow as the  apply  approach from above, on my machine. \n\n And you could also do this, using  dict.get : \n\n df['NEW_VALUE'] = [values_dict.get(v, None) for v in df['INDICATOR']]\n \n    ", "date_posted": "2017-05-16 20:59:07Z", "upvote": "\r\n            25\r\n        ", "accepted": "No", "user": {"stack_user_id": "5015569", "name": "blacksite", "reputation_score": "11.3k"}, "answer_comments": [{"stack_answer_id": "42260631", "stack_answer_comment_id": "88914688", "comment_content": "I like this answer because it shows how to do multiple replacements of values", "user_id": "None"}, {"stack_answer_id": "42260631", "stack_answer_comment_id": "106373391", "comment_content": " How did you benchmark these? From my quick measurements, the ", "user_id": "None"}, {"stack_answer_id": "42260631", "stack_answer_comment_id": "106373539", "comment_content": "Update: On 100,000,000 rows, 52 string values, ", "user_id": "None"}]}, {"stack_answer_id": "55029355", "answer_content": "\r\n You can simply use the powerful  .loc  method and use one condition or several depending on your need (tested with pandas=1.0.5). \n Code Summary: \n df=pd.DataFrame(dict(Type='A B B C'.split(), Set='Z Z X Y'.split()))\ndf['Color'] = \"red\"\ndf.loc[(df['Set']==\"Z\"), 'Color'] = \"green\"\n\n#practice!\ndf.loc[(df['Set']==\"Z\")&(df['Type']==\"B\")|(df['Type']==\"C\"), 'Color'] = \"purple\"\n\n \n Explanation: \n df=pd.DataFrame(dict(Type='A B B C'.split(), Set='Z Z X Y'.split()))\n\n# df so far: \n  Type Set  \n0    A   Z \n1    B   Z \n2    B   X \n3    C   Y\n \n add a 'color' column and set all values to \"red\" \n df['Color'] = \"red\"\n \n Apply your single condition: \n df.loc[(df['Set']==\"Z\"), 'Color'] = \"green\"\n\n\n# df: \n  Type Set  Color\n0    A   Z  green\n1    B   Z  green\n2    B   X    red\n3    C   Y    red\n \n or multiple conditions if you want: \n df.loc[(df['Set']==\"Z\")&(df['Type']==\"B\")|(df['Type']==\"C\"), 'Color'] = \"purple\"\n \n You can read on Pandas logical operators and conditional selection here:\n Logical operators for boolean indexing in Pandas \n    ", "date_posted": "2021-01-31 07:17:13Z", "upvote": "\r\n            23\r\n        ", "accepted": "No", "user": {"stack_user_id": "10951905", "name": "Hossein Kalbasi", "reputation_score": "1,393"}, "answer_comments": []}, {"stack_answer_id": "65760879", "answer_content": "\r\n You can use pandas methods  where  and  mask : \n df['color'] = 'green'\ndf['color'] = df['color'].where(df['Set']=='Z', other='red')\n# Replace values where the condition is False\n \n or \n df['color'] = 'red'\ndf['color'] = df['color'].mask(df['Set']=='Z', other='green')\n# Replace values where the condition is True\n \n Alternatively, you can use the method  transform  with a lambda function: \n df['color'] = df['Set'].transform(lambda x: 'green' if x == 'Z' else 'red')\n \n Output: \n   Type Set  color\n1    A   Z  green\n2    B   Z  green\n3    B   X    red\n4    C   Y    red\n \n Performance comparison from @chai: \n import pandas as pd\nimport numpy as np\ndf = pd.DataFrame({'Type':list('ABBC')*1000000, 'Set':list('ZZXY')*1000000})\n \n%timeit df['color1'] = 'red'; df['color1'].where(df['Set']=='Z','green')\n%timeit df['color2'] = ['red' if x == 'Z' else 'green' for x in df['Set']]\n%timeit df['color3'] = np.where(df['Set']=='Z', 'red', 'green')\n%timeit df['color4'] = df.Set.map(lambda x: 'red' if x == 'Z' else 'green')\n\n397 ms \u00b1 101 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n976 ms \u00b1 241 ms per loop\n673 ms \u00b1 139 ms per loop\n796 ms \u00b1 182 ms per loop\n \n    ", "date_posted": "2021-12-28 14:25:49Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "8973620", "name": "Mykola Zotko", "reputation_score": "12.6k"}, "answer_comments": [{"stack_answer_id": "65760879", "stack_answer_comment_id": "124631526", "comment_content": "It is also faster: import pandas as pd import numpy as np df = pd.DataFrame({'Type':list('ABBC')*1000000, 'Set':list('ZZXY')*1000000}) %timeit df['color1'] = 'red'; df['color1'].where(df['Set']=='Z','green') %timeit df['color2'] = ['red' if x == 'Z' else 'green' for x in df['Set']] %timeit df['color3'] = np.where(df['Set']=='Z', 'red', 'green') %timeit df['color4'] = df.Set.map( lambda x: 'red' if x == 'Z' else 'green') 397 ms \u00b1 101 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) 976 ms \u00b1 241 ms per loop  673 ms \u00b1 139 ms per loop  796 ms \u00b1 182 ms per loop", "user_id": "None"}, {"stack_answer_id": "65760879", "stack_answer_comment_id": "124637064", "comment_content": "@chai added your evaluation to my answer. Thank you!", "user_id": "None"}]}, {"stack_answer_id": "68221846", "answer_content": "\r\n if you have only  2 choices , use  np.where() \n df = pd.DataFrame({'A':range(3)})\ndf['B'] = np.where(df.A>2, 'yes', 'no')\n \n if you have over  2 choices , maybe  apply()  could work\ninput \n arr = pd.DataFrame({'A':list('abc'), 'B':range(3), 'C':range(3,6), 'D':range(6, 9)})\n \n and arr is \n     A   B   C   D\n0   a   0   3   6\n1   b   1   4   7\n2   c   2   5   8\n \n if you want the column E tobe  if arr.A =='a' then arr.B elif arr.A=='b' then arr.C elif arr.A == 'c' then arr.D else something_else \n arr['E'] = arr.apply(lambda x: x['B'] if x['A']=='a' else(x['C'] if x['A']=='b' else(x['D'] if x['A']=='c' else 1234)), axis=1)\n \n and finally the arr is \n     A   B   C   D   E\n0   a   0   3   6   0\n1   b   1   4   7   4\n2   c   2   5   8   8\n \n    ", "date_posted": "2021-07-02 08:17:27Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "4821909", "name": "xiaotong xu", "reputation_score": "131"}, "answer_comments": []}, {"stack_answer_id": "58325311", "answer_content": "\r\n One liner with  .apply()  method is following: \n\n df['color'] = df['Set'].apply(lambda set_: 'green' if set_=='Z' else 'red')\n \n\n After that,  df  data frame looks like this: \n\n >>> print(df)\n  Type Set  color\n0    A   Z  green\n1    B   Z  green\n2    B   X    red\n3    C   Y    red\n \n    ", "date_posted": "2019-10-10 14:30:03Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "7122272", "name": "Jaroslav Bezd\u011bk", "reputation_score": "5,139"}, "answer_comments": []}, {"stack_answer_id": "59238705", "answer_content": "\r\n If you're working with massive data, a memoized approach would be best: \n\n # First create a dictionary of manually stored values\ncolor_dict = {'Z':'red'}\n\n# Second, build a dictionary of \"other\" values\ncolor_dict_other = {x:'green' for x in df['Set'].unique() if x not in color_dict.keys()}\n\n# Next, merge the two\ncolor_dict.update(color_dict_other)\n\n# Finally, map it to your column\ndf['color'] = df['Set'].map(color_dict)\n \n\n This approach will be fastest when you have many repeated values.  My general rule of thumb is to memoize when:  data_size  >  10**4  &  n_distinct  <  data_size/4   \n\n E.x. Memoize in a case 10,000 rows with 2,500 or fewer distinct values. \n    ", "date_posted": "2019-12-08 18:42:01Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "10521959", "name": "Yaakov Bressler", "reputation_score": "7,312"}, "answer_comments": [{"stack_answer_id": "59238705", "stack_answer_comment_id": "106373684", "comment_content": "Alright, so with only 2 distinct values to map, 100,000,000 rows, it takes 6.67 seconds to run without \"memoization\", and 9.86 seconds with.", "user_id": "None"}, {"stack_answer_id": "59238705", "stack_answer_comment_id": "106373894", "comment_content": "100,000,000 rows, 52 distinct values, where 1 of those maps to the first output value, and the other 51 all correspond to the other: 7.99 seconds without memoization, 11.1 seconds with.", "user_id": "None"}, {"stack_answer_id": "59238705", "stack_answer_comment_id": "106374783", "comment_content": "Are your values in random order? Or are they back to back? High speed of pandas could be due to caching @AMC", "user_id": "None"}, {"stack_answer_id": "59238705", "stack_answer_comment_id": "106404740", "comment_content": " Values are random, selected using ", "user_id": "None"}]}, {"stack_answer_id": "69613519", "answer_content": "\r\n The  case_when  function from  pyjanitor  is a wrapper around  pd.Series.mask  and offers a chainable/convenient form for multiple conditions: \n For a single condition: \n df.case_when(\n    df.col1 == \"Z\",  # condition\n    \"green\",         # value if True\n    \"red\",           # value if False\n    column_name = \"color\"\n    )\n\n  Type Set  color\n1    A   Z  green\n2    B   Z  green\n3    B   X    red\n4    C   Y    red\n \n For multiple conditions: \n df.case_when(\n    df.Set.eq('Z') & df.Type.eq('A'), 'yellow', # condition, result\n    df.Set.eq('Z') & df.Type.eq('B'), 'blue',   # condition, result\n    df.Type.eq('B'), 'purple',                  # condition, result\n    'black',              # default if none of the conditions evaluate to True\n    column_name = 'color'  \n)\n  Type  Set   color\n1    A   Z  yellow\n2    B   Z    blue\n3    B   X  purple\n4    C   Y   black\n \n More examples can be found  here \n    ", "date_posted": "2021-10-18 09:11:47Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "7175713", "name": "sammywemmy", "reputation_score": "23.6k"}, "answer_comments": []}, {"stack_answer_id": "71358186", "answer_content": "\r\n A Less verbose approach using  np.select : \n a = np.array([['A','Z'],['B','Z'],['B','X'],['C','Y']])\ndf = pd.DataFrame(a,columns=['Type','Set'])\n\nconditions = [\n    df['Set'] == 'Z'\n]\n\noutputs = [\n    'Green'\n    ]\n             # conditions Z is Green, Red Otherwise.\nres = np.select(conditions, outputs, 'Red')\nres \narray(['Green', 'Green', 'Red', 'Red'], dtype='<U5')\ndf.insert(2, 'new_column',res)    \n\ndf\n    Type    Set new_column\n0   A   Z   Green\n1   B   Z   Green\n2   B   X   Red\n3   C   Y   Red\n\ndf.to_numpy()    \n    \narray([['A', 'Z', 'Green'],\n       ['B', 'Z', 'Green'],\n       ['B', 'X', 'Red'],\n       ['C', 'Y', 'Red']], dtype=object)\n\n%%timeit conditions = [df['Set'] == 'Z'] \noutputs = ['Green'] \nnp.select(conditions, outputs, 'Red')\n\n134 \u00b5s \u00b1 9.71 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\n\ndf2 = pd.DataFrame({'Type':list('ABBC')*1000000, 'Set':list('ZZXY')*1000000})\n%%timeit conditions = [df2['Set'] == 'Z'] \noutputs = ['Green'] \nnp.select(conditions, outputs, 'Red')\n\n188 ms \u00b1 26.5 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n \n    ", "date_posted": "2022-03-04 23:16:57Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "9550633", "name": "rubengavidia0x", "reputation_score": "361"}, "answer_comments": []}], "user": {"stack_user_id": "213216", "name": "user7289", "reputation_score": "30.1k"}, "question_comments": []},
{"stack_question_id": "1894269", "question_title": "How to convert string representation of list to a list", "question_content": "\r\n                I was wondering what the simplest way is to convert a string representation of a list like the following to a list:\nx = '[ \"A\",\"B\",\"C\" , \" D\"]'\n\nEven in cases ...\r\n", "question_url": "/questions/1894269/how-to-convert-string-representation-of-list-to-a-list", "date_posted": "Dec 12, 2009 at 18:19", "upvote": "7", "view": "5", "tags": ["python", "string"], "answers_count": "1", "answers": [{"stack_answer_id": "1894296", "answer_content": "\r\n >>> import ast\n>>> x = '[ \"A\",\"B\",\"C\" , \" D\"]'\n>>> x = ast.literal_eval(x)\n>>> x\n['A', 'B', 'C', ' D']\n>>> x = [n.strip() for n in x]\n>>> x\n['A', 'B', 'C', 'D']\n \n ast.literal_eval : \n \n With  ast.literal_eval  you can safely evaluate an expression node or a string containing a Python literal or container display. The string or node provided may only consist of the following Python literal structures: strings, bytes, numbers, tuples, lists, dicts, booleans, and  None . \n \n    ", "date_posted": "2020-10-30 08:58:25Z", "upvote": "\r\n            1075\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": [{"stack_answer_id": "1894296", "stack_answer_comment_id": "81694867", "comment_content": "Per comment below, this is dangerous as it simply runs whatever python is in the string.  So if someone puts a call to delete everything in there, it happily will.", "user_id": "None"}, {"stack_answer_id": "1894296", "stack_answer_comment_id": "85749309", "comment_content": "@PaulKenjora: You're thinking of ", "user_id": "None"}, {"stack_answer_id": "1894296", "stack_answer_comment_id": "86141783", "comment_content": " is ", "user_id": "None"}, {"stack_answer_id": "1894296", "stack_answer_comment_id": "110342556", "comment_content": "@sqp_125, then it's a regular list, and you don't need to parse anything?", "user_id": "None"}, {"stack_answer_id": "1894296", "stack_answer_comment_id": "124170297", "comment_content": "The documentation states (in 2021):  \"This can be used for safely evaluating strings containing Python values from untrusted sources without the need to parse the values oneself. It is not capable of evaluating arbitrarily complex expressions, for example involving operators or indexing.\"", "user_id": "None"}]}, {"stack_answer_id": "35461204", "answer_content": "\r\n The  json  module is a better solution whenever there is a  stringified  list of dictionaries. The  json.loads(your_data)  function can be used to convert it to a list. \n >>> import json\n>>> x = '[ \"A\",\"B\",\"C\" , \" D\"]'\n>>> json.loads(x)\n['A', 'B', 'C', ' D']\n \n Similarly \n >>> x = '[ \"A\",\"B\",\"C\" , {\"D\":\"E\"}]'\n>>> json.loads(x)\n['A', 'B', 'C', {'D': 'E'}]\n \n    ", "date_posted": "2020-10-30 09:02:00Z", "upvote": "\r\n            205\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": [{"stack_answer_id": "35461204", "stack_answer_comment_id": "81694901", "comment_content": "This works for ints but not for strings in my case because each string is single quoted not double quoted, sigh.", "user_id": "None"}, {"stack_answer_id": "35461204", "stack_answer_comment_id": "99897185", "comment_content": "As per @PaulKenjora's comment, it works for ", "user_id": "None"}, {"stack_answer_id": "35461204", "stack_answer_comment_id": "115322875", "comment_content": "In my case I had to replace single quotes with double quotes in initial string to ensure it works ", "user_id": "None"}, {"stack_answer_id": "35461204", "stack_answer_comment_id": "124307845", "comment_content": "If user should only enter list of numeric, I think this is the safest way to go to stop malicious intend user.", "user_id": "None"}, {"stack_answer_id": "35461204", "stack_answer_comment_id": "129474567", "comment_content": "The ", "user_id": "None"}]}, {"stack_answer_id": "1894293", "answer_content": "\r\n The  eval  is dangerous - you shouldn't execute user input. \n\n If you have 2.6 or newer, use ast instead of eval: \n\n >>> import ast\n>>> ast.literal_eval('[\"A\",\"B\" ,\"C\" ,\" D\"]')\n[\"A\", \"B\", \"C\", \" D\"]\n \n\n Once you have that,  strip  the strings. \n\n If you're on an older version of Python, you can get very close to what you want with a simple regular expression: \n\n >>> x='[  \"A\",  \" B\", \"C\",\"D \"]'\n>>> re.findall(r'\"\\s*([^\"]*?)\\s*\"', x)\n['A', 'B', 'C', 'D']\n \n\n This isn't as good as the ast solution, for example it doesn't correctly handle escaped quotes in strings. But it's simple, doesn't involve a dangerous eval, and might be good enough for your purpose if you're on an older Python without ast. \n    ", "date_posted": "2009-12-12 20:21:43Z", "upvote": "\r\n            107\r\n        ", "accepted": "No", "user": {"stack_user_id": "61974", "name": "Mark Byers", "reputation_score": "777k"}, "answer_comments": [{"stack_answer_id": "1894293", "stack_answer_comment_id": "77239301", "comment_content": "Could you please tell me what why did you say \u201cThe ", "user_id": "None"}, {"stack_answer_id": "1894293", "stack_answer_comment_id": "79669145", "comment_content": "@AaryanDewan if you use ", "user_id": "None"}]}, {"stack_answer_id": "1894283", "answer_content": "\r\n There is a quick solution: \n\n x = eval('[ \"A\",\"B\",\"C\" , \" D\"]')\n \n\n Unwanted whitespaces in the list elements may be removed in this way: \n\n x = [x.strip() for x in eval('[ \"A\",\"B\",\"C\" , \" D\"]')]\n \n    ", "date_posted": "2009-12-12 18:24:11Z", "upvote": "\r\n            28\r\n        ", "accepted": "No", "user": {"stack_user_id": "213682", "name": "Alexei Sholik", "reputation_score": "7,063"}, "answer_comments": [{"stack_answer_id": "1894283", "stack_answer_comment_id": "1795912", "comment_content": "this would still preserve the spaces inside the quotes", "user_id": "None"}, {"stack_answer_id": "1894283", "stack_answer_comment_id": "1795920", "comment_content": "This is an open invitation to arbitrary code execution, NEVER do this or anything like it unless you know with absolute certainty that the input will always be 100% trusted.", "user_id": "None"}, {"stack_answer_id": "1894283", "stack_answer_comment_id": "59555410", "comment_content": "I could use this suggestion because I knew my data was always gonna be in that format and was a data processing work.", "user_id": "None"}]}, {"stack_answer_id": "55931430", "answer_content": "\r\n Inspired from some of the answers above that work with base python packages I compared the performance of a few (using Python 3.7.3): \n\n Method 1: ast \n\n import ast\nlist(map(str.strip, ast.literal_eval(u'[ \"A\",\"B\",\"C\" , \" D\"]')))\n# ['A', 'B', 'C', 'D']\n\nimport timeit\ntimeit.timeit(stmt=\"list(map(str.strip, ast.literal_eval(u'[ \\\"A\\\",\\\"B\\\",\\\"C\\\" , \\\" D\\\"]')))\", setup='import ast', number=100000)\n# 1.292875313000195\n \n\n Method 2: json \n\n import json\nlist(map(str.strip, json.loads(u'[ \"A\",\"B\",\"C\" , \" D\"]')))\n# ['A', 'B', 'C', 'D']\n\nimport timeit\ntimeit.timeit(stmt=\"list(map(str.strip, json.loads(u'[ \\\"A\\\",\\\"B\\\",\\\"C\\\" , \\\" D\\\"]')))\", setup='import json', number=100000)\n# 0.27833264000014424\n \n\n Method 3: no import \n\n list(map(str.strip, u'[ \"A\",\"B\",\"C\" , \" D\"]'.strip('][').replace('\"', '').split(',')))\n# ['A', 'B', 'C', 'D']\n\nimport timeit\ntimeit.timeit(stmt=\"list(map(str.strip, u'[ \\\"A\\\",\\\"B\\\",\\\"C\\\" , \\\" D\\\"]'.strip('][').replace('\\\"', '').split(',')))\", number=100000)\n# 0.12935059100027502\n \n\n I was disappointed to see what I considered the method with the worst readability was the method with the best performance... there are tradeoffs to consider when going with the most readable option... for the type of workloads I use python for I usually value readability over a slightly more performant option, but as usual it depends. \n    ", "date_posted": "2019-05-01 03:54:25Z", "upvote": "\r\n            24\r\n        ", "accepted": "No", "user": {"stack_user_id": "4277990", "name": "kinzleb", "reputation_score": "955"}, "answer_comments": [{"stack_answer_id": "55931430", "stack_answer_comment_id": "114797691", "comment_content": "is there any particular reason for there being a ", "user_id": "None"}, {"stack_answer_id": "55931430", "stack_answer_comment_id": "129474506", "comment_content": "The manual method is simply not as powerful, and does less work, so it's not surprising that it's faster. It will not handle escape sequences in the strings, or a different quote type. (The JSON method demands double-quotes, but does process escape sequences.) It also will only process a flat list of strings; the other approaches can handle complex nested data structures.", "user_id": "None"}]}, {"stack_answer_id": "1894292", "answer_content": "\r\n import ast\nl = ast.literal_eval('[ \"A\",\"B\",\"C\" , \" D\"]')\nl = [i.strip() for i in l]\n \n    ", "date_posted": "2009-12-12 18:29:02Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "403939", "name": "tosh", "reputation_score": "5,554"}, "answer_comments": []}, {"stack_answer_id": "52058605", "answer_content": "\r\n If it's only a one dimensional list, this can be done without importing anything: \n\n >>> x = u'[ \"A\",\"B\",\"C\" , \" D\"]'\n>>> ls = x.strip('[]').replace('\"', '').replace(' ', '').split(',')\n>>> ls\n['A', 'B', 'C', 'D']\n \n    ", "date_posted": "2020-03-19 15:58:33Z", "upvote": "\r\n            15\r\n        ", "accepted": "No", "user": {"stack_user_id": "9835872", "name": "ruohola", "reputation_score": "19.8k"}, "answer_comments": [{"stack_answer_id": "52058605", "stack_answer_comment_id": "92199807", "comment_content": "Cautionary note: this could potentially be dangerous if any of the strings inside list has a comma in between.", "user_id": "None"}, {"stack_answer_id": "52058605", "stack_answer_comment_id": "107501629", "comment_content": "This will not work if your string list is a list of lists", "user_id": "None"}]}, {"stack_answer_id": "70891720", "answer_content": "\r\n This u can do, \n ** \n x = '[ \"A\",\"B\",\"C\" , \" D\"]'\nprint(list(eval(x)))\n \n **\nbest one is the accepted answer \n Though this is not a safe way, the best answer is the accepted one.\nwasn't aware of the eval danger when answer was posted. \n    ", "date_posted": "2022-03-02 07:45:56Z", "upvote": "\r\n            10\r\n        ", "accepted": "No", "user": {"stack_user_id": "11863894", "name": "Tomato Master", "reputation_score": "416"}, "answer_comments": [{"stack_answer_id": "70891720", "stack_answer_comment_id": "125495153", "comment_content": "eval is not recommended in several places on this thread as it will simple run as code whatever is entered, presenting a security risk. it is also a duplicate answer.", "user_id": "None"}]}, {"stack_answer_id": "1894876", "answer_content": "\r\n Assuming that all your inputs are lists and that the double quotes in the input actually don't matter, this can be done with a simple regexp replace.  It is a bit perl-y but works like a charm.  Note also that the output is now a list of unicode strings, you didn't specify that you needed that, but it seems to make sense given unicode input. \n\n import re\nx = u'[ \"A\",\"B\",\"C\" , \" D\"]'\njunkers = re.compile('[[\" \\]]')\nresult = junkers.sub('', x).split(',')\nprint result\n--->  [u'A', u'B', u'C', u'D']\n \n\n The junkers variable contains a compiled regexp (for speed) of all characters we don't want, using ] as a character required some backslash trickery.\nThe re.sub replaces all these characters with nothing, and we split the resulting string at the commas.    \n\n Note that this also removes spaces from inside entries u'[\"oh no\"]' ---> [u'ohno'].  If this is not what you wanted, the regexp needs to be souped up a bit.   \n    ", "date_posted": "2009-12-12 22:18:37Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "230446", "name": "dirkjot", "reputation_score": "3,089"}, "answer_comments": []}, {"stack_answer_id": "68293376", "answer_content": "\r\n No need to import anything and no need evaluate. You can do this in one line for most basic use cases, including the one given in original question. \n One liner \n l_x = [i.strip() for i in x[1:-1].replace('\"',\"\").split(',')]\n \n Explanation \n x = '[ \"A\",\"B\",\"C\" , \" D\"]'\n# str indexing to eliminate the brackets\n# replace as split will otherwise retain the quotes in returned list\n# split to conv to list\nl_x = x[1:-1].replace('\"',\"\").split(',')\n \n Outputs : \n for i in range(0, len(l_x)):\n    print(l_x[i])\n# vvvv output vvvvv\n'''\n A\nB\nC \n  D\n'''\nprint(type(l_x)) # out: class 'list'\nprint(len(l_x)) # out: 4\n \n You can parse and clean up this list as needed using list comprehension. \n l_x = [i.strip() for i in l_x] # list comprehension to clean up\nfor i in range(0, len(l_x)):\n    print(l_x[i])\n# vvvvv output vvvvv\n'''\nA\nB\nC\nD\n'''\n \n Nested lists \n If you have nested lists, it does get a bit more annoying. Without using regex (which would simplify the replace), and assuming you want to return a flattened list (and the  zen of python says flat is better than nested ): \n x = '[ \"A\",\"B\",\"C\" , \" D\", [\"E\",\"F\",\"G\"]]'\nl_x = x[1:-1].split(',')\nl_x = [i\n    .replace(']', '')\n    .replace('[', '')\n    .replace('\"', '')\n    .strip() for i in l_x\n]\n# returns ['A', 'B', 'C', 'D', 'E', 'F', 'G']\n \n If you need to retain the nested list it gets a bit uglier, but can still be done just with re and list comprehension: \n import re\nx = '[ \"A\",\"B\",\"C\" , \" D\", \"[\"E\",\"F\",\"G\"]\",\"Z\", \"Y\", \"[\"H\",\"I\",\"J\"]\", \"K\", \"L\"]'\n# clean it up so regex is simpler\nx = x.replace('\"', '').replace(' ', '') \n# look ahead for the bracketed text that signifies nested list\nl_x = re.split(r',(?=\\[[A-Za-z0-9\\',]+\\])|(?<=\\]),', x[1:-1])\nprint(l_x)\n# flatten and split the non nested list items\nl_x0 = [item for items in l_x for item in items.split(',') if not '[' in items]\n# convert the nested lists to lists\nl_x1 = [\n    i[1:-1].split(',') for i in l_x if '[' in i \n]\n# add the two lists \nl_x = l_x0 + l_x1\n \n This last solution will work on any list stored as a string, nested or not. \n    ", "date_posted": "2021-07-07 22:07:51Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "12642339", "name": "born_naked", "reputation_score": "634"}, "answer_comments": [{"stack_answer_id": "68293376", "stack_answer_comment_id": "128067504", "comment_content": "Notice the method doesn't play well with empty lists. You take ", "user_id": "None"}]}, {"stack_answer_id": "1894785", "answer_content": "\r\n If you know that your lists only contain quoted strings, this pyparsing example will give you your list of stripped strings (even preserving the original Unicode-ness). \n >>> from pyparsing import *\n>>> x =u'[ \"A\",\"B\",\"C\" , \" D\"]'\n>>> LBR,RBR = map(Suppress,\"[]\")\n>>> qs = quotedString.setParseAction(removeQuotes, lambda t: t[0].strip())\n>>> qsList = LBR + delimitedList(qs) + RBR\n>>> print qsList.parseString(x).asList()\n[u'A', u'B', u'C', u'D']\n \n If your lists can have more datatypes, or even contain lists within lists, then you will need a more complete grammar - like  this one  in the pyparsing examples directory, which will handle tuples, lists, ints, floats, and quoted strings. \n    ", "date_posted": "2022-05-28 14:28:20Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "165216", "name": "PaulMcG", "reputation_score": "60.2k"}, "answer_comments": []}, {"stack_answer_id": "62050605", "answer_content": "\r\n You may run into such problem while dealing with scraped data stored as Pandas DataFrame. \n\n This solution works like charm if the  list of values is present as text .  \n\n def textToList(hashtags):\n    return hashtags.strip('[]').replace('\\'', '').replace(' ', '').split(',')\n\nhashtags = \"[ 'A','B','C' , ' D']\"\nhashtags = textToList(hashtags)\n\nOutput: ['A', 'B', 'C', 'D']\n \n\n \n   No external library required. \n \n    ", "date_posted": "2020-05-27 18:44:33Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "3888829", "name": "dobydx", "reputation_score": "57"}, "answer_comments": []}, {"stack_answer_id": "50063947", "answer_content": "\r\n To further complete @Ryan 's answer using json, one very convenient function to convert unicode is the one posted here:  https://stackoverflow.com/a/13105359/7599285 \n\n ex with double or single quotes: \n\n >print byteify(json.loads(u'[ \"A\",\"B\",\"C\" , \" D\"]')\n>print byteify(json.loads(u\"[ 'A','B','C' , ' D']\".replace('\\'','\"')))\n['A', 'B', 'C', ' D']\n['A', 'B', 'C', ' D']\n \n    ", "date_posted": "2018-04-27 13:56:02Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "7599285", "name": "CptHwK", "reputation_score": "105"}, "answer_comments": [{"stack_answer_id": "50063947", "stack_answer_comment_id": "129474559", "comment_content": "The only new information here is a further processing step that is ", "user_id": "None"}]}, {"stack_answer_id": "66908306", "answer_content": "\r\n This usually happens when you load list stored as string to CSV \n If you have your list stored in CSV in form like OP asked: \n x = '[ \"A\",\"B\",\"C\" , \" D\"]'\n \n Here is how you can load it back to list: \n import csv\nwith open('YourCSVFile.csv') as csv_file:\n    reader = csv.reader(csv_file, delimiter=',')\n    rows = list(reader)\n\nlistItems = rows[0]\n \n listItems  is now list \n    ", "date_posted": "2021-04-02 14:58:20Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "2119941", "name": "Hrvoje", "reputation_score": "11.1k"}, "answer_comments": [{"stack_answer_id": "66908306", "stack_answer_comment_id": "118291288", "comment_content": "Not sure how this is related to the question... ", "user_id": "None"}, {"stack_answer_id": "66908306", "stack_answer_comment_id": "118292398", "comment_content": "@Tomerikoo string representation of list is exactly the same only it's in the file.", "user_id": "None"}, {"stack_answer_id": "66908306", "stack_answer_comment_id": "118292450", "comment_content": "No. A string representation of a list is ", "user_id": "None"}, {"stack_answer_id": "66908306", "stack_answer_comment_id": "118292698", "comment_content": "@Tomerikoo how about you store list in file and than use any method here to restore it.", "user_id": "None"}, {"stack_answer_id": "66908306", "stack_answer_comment_id": "118292778", "comment_content": "Ok, let's say the csv has literally ", "user_id": "None"}]}, {"stack_answer_id": "50640336", "answer_content": "\r\n I would like to provide a more intuitive patterning solution with regex. \nThe below function takes as input a stringified list containing arbitrary strings.  \n\n Stepwise explanation: \nYou remove all whitespacing,bracketing and value_separators (provided they are not part of the values you want to extract, else make the regex more complex). Then you split the cleaned string on single or double quotes and take the non-empty values (or odd indexed values, whatever the preference).  \n\n def parse_strlist(sl):\nimport re\nclean = re.sub(\"[\\[\\],\\s]\",\"\",sl)\nsplitted = re.split(\"[\\'\\\"]\",clean)\nvalues_only = [s for s in splitted if s != '']\nreturn values_only\n \n\n testsample : \"['21',\"foo\" '6', '0', \" A\"]\" \n    ", "date_posted": "2018-06-01 09:32:00Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "7141994", "name": "Jordy Van Landeghem", "reputation_score": "19"}, "answer_comments": []}, {"stack_answer_id": "54101165", "answer_content": "\r\n you can save yourself the .strip() fcn by just slicing off the first and last characters from the string representation of the list (see third line below) \n\n >>> mylist=[1,2,3,4,5,'baloney','alfalfa']\n>>> strlist=str(mylist)\n['1', ' 2', ' 3', ' 4', ' 5', \" 'baloney'\", \" 'alfalfa'\"]\n>>> mylistfromstring=(strlist[1:-1].split(', '))\n>>> mylistfromstring[3]\n'4'\n>>> for entry in mylistfromstring:\n...     print(entry)\n...     type(entry)\n... \n1\n<class 'str'>\n2\n<class 'str'>\n3\n<class 'str'>\n4\n<class 'str'>\n5\n<class 'str'>\n'baloney'\n<class 'str'>\n'alfalfa'\n<class 'str'>\n \n    ", "date_posted": "2019-01-08 23:24:24Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "6470375", "name": "JCMontalbano", "reputation_score": "69"}, "answer_comments": []}, {"stack_answer_id": "57186365", "answer_content": "\r\n and with pure python - not importing any libraries \n\n [x for x in  x.split('[')[1].split(']')[0].split('\"')[1:-1] if x not in[',',' , ',', ']]\n \n    ", "date_posted": "2019-07-26 08:40:47Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "8563649", "name": "Ioannis Nasios", "reputation_score": "7,996"}, "answer_comments": []}, {"stack_answer_id": "69755095", "answer_content": "\r\n This solution is simpler than some I read above but requires to match all features of the list \n x = '[ \"A\",\"B\",\"C\" , \" D\"]'\n[i.strip() for i in x.split('\"') if len(i.strip().strip(',').strip(']').strip('['))>0]\n \n \n \n ['A', 'B', 'C', 'D'] \n \n \n    ", "date_posted": "2021-10-28 13:35:18Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "11955928", "name": "CassAndr", "reputation_score": "13"}, "answer_comments": []}, {"stack_answer_id": "51705980", "answer_content": "\r\n So, following all the answers I decided to time the most common methods: \n\n from time import time\nimport re\nimport json\n\n\nmy_str = str(list(range(19)))\nprint(my_str)\n\nreps = 100000\n\nstart = time()\nfor i in range(0, reps):\n    re.findall(\"\\w+\", my_str)\nprint(\"Regex method:\\t\", (time() - start) / reps)\n\nstart = time()\nfor i in range(0, reps):\n    json.loads(my_str)\nprint(\"json method:\\t\", (time() - start) / reps)\n\nstart = time()\nfor i in range(0, reps):\n    ast.literal_eval(my_str)\nprint(\"ast method:\\t\\t\", (time() - start) / reps)\n\nstart = time()\nfor i in range(0, reps):\n    [n.strip() for n in my_str]\nprint(\"strip method:\\t\", (time() - start) / reps)\n\n\n\n    regex method:    6.391477584838867e-07\n    json method:     2.535374164581299e-06\n    ast method:      2.4425282478332518e-05\n    strip method:    4.983267784118653e-06\n \n\n So in the end regex wins! \n    ", "date_posted": "2018-08-06 11:12:47Z", "upvote": "\r\n            -1\r\n        ", "accepted": "No", "user": {"stack_user_id": "9224152", "name": "passs", "reputation_score": "43"}, "answer_comments": []}], "user": {"stack_user_id": "65424", "name": "harijay", "reputation_score": "10.4k"}, "question_comments": []},
{"stack_question_id": "16424091", "question_title": "Why does Tkinter image not show up if created in a function?", "question_content": "\r\n                This code works:\n\nimport tkinter\n\nroot = tkinter.Tk()\ncanvas = tkinter.Canvas(root)\ncanvas.grid(row = 0, column = 0)\nphoto = tkinter.PhotoImage(file = './test.gif')\ncanvas.create_image(0, 0, image=...\r\n", "question_url": "/questions/16424091/why-does-tkinter-image-not-show-up-if-created-in-a-function", "date_posted": "May 7, 2013 at 16:30", "upvote": "7", "view": "8", "tags": ["python", "image", "tkinter", "tkinter-canvas"], "answers_count": "4", "answers": [{"stack_answer_id": "16424553", "answer_content": "\r\n The variable  photo  is a local variable which gets garbage collected after the class is instantiated. Save a reference to the photo, for example: \n self.photo = tkinter.PhotoImage(...)\n \n If you do a Google search on \"tkinter image doesn't display\", the first result is this: \n Why do my Tkinter images not appear?  (The FAQ answer is currently  not  outdated) \n    ", "date_posted": "2021-03-15 16:50:04Z", "upvote": "\r\n            106\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "355230", "name": "martineau", "reputation_score": "115k"}, "answer_comments": [{"stack_answer_id": "16424553", "stack_answer_comment_id": "115733354", "comment_content": "Wow. Do they consider this a bug in tkinter? They should.", "user_id": "None"}, {"stack_answer_id": "16424553", "stack_answer_comment_id": "117806780", "comment_content": "@TamasHegedus: I agree it's bug, but apparently not one that anyone has ever bothered to fix after (currently) nearly two decades. Have lost count how many times I see a question regarding to it still pops up.", "user_id": "None"}, {"stack_answer_id": "16424553", "stack_answer_comment_id": "129582113", "comment_content": "@Enderman: a reference needs to be kept by something, somewhere.", "user_id": "None"}, {"stack_answer_id": "16424553", "stack_answer_comment_id": "129587214", "comment_content": "@Enderman: no, because it's referencing itself. An object needs an external reference to it or the garbage collector might destroy it.", "user_id": "None"}, {"stack_answer_id": "16424553", "stack_answer_comment_id": "129588131", "comment_content": "@Enderman: no. You need to save a reference to the instance of the class.", "user_id": "None"}]}, {"stack_answer_id": "63599265", "answer_content": "\r\n from tkinter import *\nfrom PIL import ImageTk, Image\n\nroot = Tk()\n\ndef open_img():\n    global img\n    path = r\"C:\\.....\\\\\"\n    img = ImageTk.PhotoImage(Image.open(path))\n    panel = Label(root, image=img)\n    panel.pack(side=\"bottom\", fill=\"both\")\nbut1 = Button(root, text=\"click to get the image\", command=open_img)\nbut1.pack()\nroot.mainloop() \n \n \n Just add global to the img definition and it will work \n \n    ", "date_posted": "2020-08-26 13:57:15Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "9769923", "name": "TIRTH SHAH", "reputation_score": "79"}, "answer_comments": [{"stack_answer_id": "63599265", "stack_answer_comment_id": "124847517", "comment_content": "This answer is fine for a program that just uses functions, but if, as in the OP's case, you use a class, than ", "user_id": "None"}]}, {"stack_answer_id": "71502573", "answer_content": "\r\n The problem is Python automatically deletes the references to the variable by a process known as  Garbage Collection . The solution is to save the reference or to create a new reference. \n The following are the ways: \n \n Using  self  to increase the reference count and to save the reference. \n \n import tkinter\n\nclass Test:\n    def __init__(self, master):\n        canvas = tkinter.Canvas(master)\n        canvas.grid(row = 0, column = 0)\n        self.photo = tkinter.PhotoImage(file = './test.gif') # Changes here\n        canvas.create_image(0, 0, image=self.photo) # Changes here\n\nroot = tkinter.Tk()\ntest = Test(root)\nroot.mainloop()\n \n \n Saving it to a list to increase the reference count and to save the reference. \n \n import tkinter\nl=[]\nclass Test:\n\n    def __init__(self, master):\n        canvas = tkinter.Canvas(master)\n        canvas.grid(row = 0, column = 0)\n        photo = tkinter.PhotoImage(file = './test.gif')\n        l.append(photo)\n        canvas.create_image(0, 0, image=photo)\n\nroot = tkinter.Tk()\ntest = Test(root)\nroot.mainloop()\n \n While using method 2, you can either make a global list as i did or use list inside the class. Both would work. \n Some useful links: \n \n About Garbage Collection 1 \n About Garbage Collection 2 ( More useful ) \n \n    ", "date_posted": "2022-03-16 19:03:59Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "16187613", "name": "Faraaz Kurawle", "reputation_score": "945"}, "answer_comments": []}, {"stack_answer_id": "54936405", "answer_content": "\r\n Just add  global photo  as the first line inside the function. \n    ", "date_posted": "2019-03-01 00:45:49Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "6451750", "name": "Gabriel", "reputation_score": "37"}, "answer_comments": [{"stack_answer_id": "54936405", "stack_answer_comment_id": "99917567", "comment_content": "And then you create a 2nd ", "user_id": "None"}, {"stack_answer_id": "54936405", "stack_answer_comment_id": "123329075", "comment_content": "There is definitely no no need to use ", "user_id": "None"}]}], "user": {"stack_user_id": "1554934", "name": "thomas.winckell", "reputation_score": "1,107"}, "question_comments": [{"stack_question_id": "16424091", "stack_question_comment_id": "116648223", "comment_content": " is down. The gist of it is that the image is passed by reference. If the reference is to a local variable, the memory referenced gets reused and the reference becomes stale. The variable storing the image should be in the same scope (has to have the same lifetime) as the Tk gui object it appears on.", "user_id": "None"}, {"stack_question_id": "16424091", "stack_question_comment_id": "122756541", "comment_content": "@maszoka: ", "user_id": "None"}, {"stack_question_id": "16424091", "stack_question_comment_id": "125991644", "comment_content": "Also note that the same problem can appear anywhere temporary ", "user_id": "None"}]},
{"stack_question_id": "49775502", "question_title": "WebDriverWait not working as expected", "question_content": "\r\n                I am working with selenium to scrape some data.\n\nThere is button on the page that I am clicking say \"custom_cols\". This button opens up a window for me where I can select my columns. \n\nThis new window ...\r\n", "question_url": "/questions/49775502/webdriverwait-not-working-as-expected", "date_posted": "Apr 11, 2018 at 12:43", "upvote": "1", "view": "1", "tags": ["python", "selenium", "web-scraping", "webdriverwait", "expected-condition"], "answers_count": "1", "answers": [{"stack_answer_id": "49775808", "answer_content": "\r\n Once you wait for the element and moving forward as you are trying to invoke  click()  method instead of using  presence_of_element_located()  method you need to use  element_to_be_clickable()  as follows : \n\n try:\n    myElem = WebDriverWait(self.browser, delay).until(EC.element_to_be_clickable((By.XPATH , xpath)))\n \n\n \n\n Update \n\n As per your counter question in the comments here are the details of the three methods : \n\n presence_of_element_located \n\n presence_of_element_located(locator)  is defined as follows : \n\n class selenium.webdriver.support.expected_conditions.presence_of_element_located(locator)\n\nParameter : locator - used to find the element returns the WebElement once it is located\n\nDescription : An expectation for checking that an element is present on the DOM of a page. This does not necessarily mean that the element is visible or interactable (i.e. clickable). \n \n\n visibility_of_element_located \n\n visibility_of_element_located(locator)  is defined as follows : \n\n class selenium.webdriver.support.expected_conditions.visibility_of_element_located(locator)\n\nParameter : locator -  used to find the element returns the WebElement once it is located and visible\n\nDescription : An expectation for checking that an element is present on the DOM of a page and visible. Visibility means that the element is not only displayed but also has a height and width that is greater than 0.\n \n\n element_to_be_clickable \n\n element_to_be_clickable(locator)  is defined as follows : \n\n class selenium.webdriver.support.expected_conditions.element_to_be_clickable(locator)\n\nParameter : locator - used to find the element returns the WebElement once it is visible, enabled and interactable (i.e. clickable).\n\nDescription : An Expectation for checking an element is visible, enabled and interactable such that you can click it. \n \n    ", "date_posted": "2018-10-02 11:32:14Z", "upvote": "\r\n            12\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "7429447", "name": "undetected Selenium", "reputation_score": "160k"}, "answer_comments": [{"stack_answer_id": "49775808", "stack_answer_comment_id": "86567318", "comment_content": "Can you please explain why it works but other function not.", "user_id": "6770735"}, {"stack_answer_id": "49775808", "stack_answer_comment_id": "123680315", "comment_content": " definitely helped, but I still had situations where ", "user_id": "None"}]}], "user": {"stack_user_id": "6770735", "name": "Rao Sahab", "reputation_score": "971"}, "question_comments": [{"stack_question_id": "49775502", "stack_question_comment_id": "123680419", "comment_content": "Just a comment that the 2nd argument for ", "user_id": "None"}]},
{"stack_question_id": "16476924", "question_title": "How to iterate over rows in a DataFrame in Pandas", "question_content": "\r\n                I have a pandas dataframe, df:\n   c1   c2\n0  10  100\n1  11  110\n2  12  120\n\nHow do I iterate over the rows of this dataframe? For every row, I want to be able to access its elements (values in cells) ...\r\n", "question_url": "/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas", "date_posted": "May 10, 2013 at 7:04", "upvote": "3", "view": "5", "tags": ["python", "pandas", "dataframe"], "answers_count": "3", "answers": [{"stack_answer_id": "16476974", "answer_content": "\r\n DataFrame.iterrows  is a generator which yields both the index and row (as a Series): \n import pandas as pd\n\ndf = pd.DataFrame({'c1': [10, 11, 12], 'c2': [100, 110, 120]})\ndf = df.reset_index()  # make sure indexes pair with number of rows\n\nfor index, row in df.iterrows():\n    print(row['c1'], row['c2'])\n \n\n 10 100\n11 110\n12 120\n \n    ", "date_posted": "2022-06-06 03:16:21Z", "upvote": "\r\n            4654\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": [{"stack_answer_id": "16476974", "stack_answer_comment_id": "69252004", "comment_content": "Note: \"Because iterrows returns a Series for each row, it ", "user_id": "None"}, {"stack_answer_id": "16476974", "stack_answer_comment_id": "79079467", "comment_content": "@viddik13 that's a great note thanks. Because of that I ran into a case where numerical values like ", "user_id": "None"}, {"stack_answer_id": "16476974", "stack_answer_comment_id": "79152689", "comment_content": "@AzizAlto use ", "user_id": "None"}, {"stack_answer_id": "16476974", "stack_answer_comment_id": "82152649", "comment_content": "Do not use iterrows. Itertuples is faster and preserves data type. ", "user_id": "None"}, {"stack_answer_id": "16476974", "stack_answer_comment_id": "99276519", "comment_content": "From ", "user_id": "None"}]}, {"stack_answer_id": "55557758", "answer_content": "\r\n \n How to iterate over rows in a DataFrame in Pandas? \n \n Answer: DON'T * ! \n Iteration in Pandas is an anti-pattern and is something you should only do when you have exhausted every other option. You should not use any function with \" iter \" in its name for more than a few thousand rows or you will have to get used to a  lot  of waiting. \n Do you want to print a DataFrame? Use  DataFrame.to_string() . \n Do you want to compute something? In that case, search for methods in this order (list modified from  here ): \n \n Vectorization \n Cython  routines \n List Comprehensions (vanilla  for  loop) \n DataFrame.apply() : i) \u00a0Reductions that can be performed in Cython, ii) Iteration in Python space \n DataFrame.itertuples()  and  iteritems() \n DataFrame.iterrows() \n \n iterrows  and  itertuples  (both receiving many votes in answers to this question) should be used in very rare circumstances, such as generating row objects/nametuples for sequential processing, which is really the only thing these functions are useful for. \n Appeal to Authority \n The documentation page  on iteration has a huge red warning box that says: \n \n Iterating through pandas objects is generally slow. In many cases, iterating manually over the rows is not needed [...]. \n \n * It's actually a little more complicated than \"don't\".  df.iterrows()  is the correct answer to this question, but \"vectorize your ops\" is the better one. I will concede that there are circumstances where iteration cannot be avoided (for example, some operations where the result depends on the value computed for the previous row). However, it takes some familiarity with the library to know when. If you're not sure whether you need an iterative solution, you probably don't. PS: To know more about my rationale for writing this answer, skip to the very bottom. \n \n Faster than Looping:  Vectorization ,  Cython \n A good number of basic operations and computations are \"vectorised\" by pandas (either through NumPy, or through Cythonized functions). This includes arithmetic, comparisons, (most) reductions, reshaping (such as pivoting), joins, and groupby operations. Look through the documentation on  Essential Basic Functionality  to find a suitable vectorised method for your problem. \n If none exists, feel free to write your own using custom  Cython extensions . \n \n Next Best Thing:  List Comprehensions * \n List comprehensions should be your next port of call if 1) there is no vectorized solution available, 2) performance is important, but not important enough to go through the hassle of cythonizing your code, and 3) you're trying to perform elementwise transformation on your code. There is a  good amount of evidence  to suggest that list comprehensions are sufficiently fast (and even sometimes faster) for many common Pandas tasks. \n The formula is simple, \n # Iterating over one column - `f` is some function that processes your data\nresult = [f(x) for x in df['col']]\n# Iterating over two columns, use `zip`\nresult = [f(x, y) for x, y in zip(df['col1'], df['col2'])]\n# Iterating over multiple columns - same data type\nresult = [f(row[0], ..., row[n]) for row in df[['col1', ...,'coln']].to_numpy()]\n# Iterating over multiple columns - differing data type\nresult = [f(row[0], ..., row[n]) for row in zip(df['col1'], ..., df['coln'])]\n \n If you can encapsulate your business logic into a function, you can use a list comprehension that calls it. You can make arbitrarily complex things work through the simplicity and speed of raw Python code. \n Caveats \n List comprehensions assume that your data is easy to work with - what that means is your data types are consistent and you don't have NaNs, but this cannot always be guaranteed. \n \n The first one is more obvious, but when dealing with NaNs, prefer in-built pandas methods if they exist (because they have much better corner-case handling logic), or ensure your business logic includes appropriate NaN handling logic. \n When dealing with mixed data types you should iterate over  zip(df['A'], df['B'], ...)  instead of  df[['A', 'B']].to_numpy()  as the latter implicitly upcasts data to the most common type. As an example if A is numeric and B is string,  to_numpy()  will cast the entire array to string, which may not be what you want. Fortunately  zip ping your columns together is the most straightforward workaround to this. \n \n *Your mileage may vary for the reasons outlined in the  Caveats  section above. \n \n An Obvious Example \n Let's demonstrate the difference with a simple example of adding two pandas columns  A + B . This is a vectorizable operaton, so it will be easy to contrast the performance of the methods discussed above. \n \n Benchmarking code, for your reference . The line at the bottom measures a function written in numpandas, a style of Pandas that mixes heavily with NumPy to squeeze out maximum performance. Writing numpandas code should be avoided unless you know what you're doing. Stick to the API where you can (i.e., prefer  vec  over  vec_numpy ). \n I should mention, however, that it isn't always this cut and dry. Sometimes the answer to \"what is the best method for an operation\" is \"it depends on your data\". My advice is to test out different approaches on your data before settling on one. \n \n My Personal Opinion  * \n Most of the analyses performed on the various alternatives to the iter family has been through the lens of performance. However, in most situations you will typically be working on a reasonably sized dataset (nothing beyond a few thousand or 100K rows) and performance will come second to simplicity/readability of the solution. \n Here is my personal preference when selecting a method to use for a problem. \n For the novice: \n \n Vectorization  (when possible) ;  apply() ; List Comprehensions;  itertuples() / iteritems() ;  iterrows() ; Cython \n \n For the more experienced: \n \n Vectorization  (when possible) ;  apply() ; List Comprehensions; Cython;  itertuples() / iteritems() ;  iterrows() \n \n Vectorization prevails as the most idiomatic method for any problem that can be vectorized. Always seek to vectorize! When in doubt, consult the docs, or look on Stack Overflow for an existing question on your particular task. \n I do tend to go on about how bad  apply  is in a lot of my posts, but I do concede it is easier for a beginner to wrap their head around what it's doing. Additionally, there are quite a few use cases for  apply  has explained in  this post of mine . \n Cython ranks lower down on the list because it takes more time and effort to pull off correctly. You will usually never need to write code with pandas that demands this level of performance that even a list comprehension cannot satisfy. \n * As with any personal opinion, please take with heaps of salt! \n \n Further Reading \n \n 10 Minutes to pandas , and  Essential Basic Functionality  - Useful links that introduce you to Pandas and its library of vectorized*/cythonized functions. \n \n Enhancing Performance  - A primer from the documentation on enhancing standard Pandas operations \n \n Are for-loops in pandas really bad? When should I care?  - a detailed writeup by me on list comprehensions and their suitability for various operations (mainly ones involving non-numeric data) \n \n When should I (not) want to use pandas apply() in my code?  -  apply  is slow (but not as slow as the  iter*  family. There are, however, situations where one can (or should) consider  apply  as a serious alternative, especially in some  GroupBy  operations). \n \n \n * Pandas string methods are \"vectorized\" in the sense that they are specified on the series but operate on each element. The underlying mechanisms are still iterative, because string operations are inherently hard to vectorize. \n \n Why I Wrote this Answer \n A common trend I notice from new users is to ask questions of the form \"How can I iterate over my df to do X?\". Showing code that calls  iterrows()  while doing something inside a  for  loop. Here is why. A new user to the library who has not been introduced to the concept of vectorization will likely envision the code that solves their problem as iterating over their data to do something. Not knowing how to iterate over a DataFrame, the first thing they do is Google it and end up here, at this question. They then see the accepted answer telling them how to, and they close their eyes and run this code without ever first questioning if iteration is the right thing to do. \n The aim of this answer is to help new users understand that iteration is not necessarily the solution to every problem, and that better, faster and more idiomatic solutions could exist, and that it is worth investing time in exploring them. I'm not trying to start a war of iteration vs. vectorization, but I want new users to be informed when developing solutions to their problems with this library. \n    ", "date_posted": "2022-03-19 15:58:59Z", "upvote": "\r\n            1969\r\n        ", "accepted": "No", "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "answer_comments": [{"stack_answer_id": "55557758", "stack_answer_comment_id": "99356021", "comment_content": "Note that there are important caveats with ", "user_id": "None"}, {"stack_answer_id": "55557758", "stack_answer_comment_id": "99360660", "comment_content": "This is the only answer that focuses on the idiomatic techniques one should use with pandas, making it the best answer for this question. Learning to get the ", "user_id": "None"}, {"stack_answer_id": "55557758", "stack_answer_comment_id": "100017200", "comment_content": "I think you are being unfair to the for loop, though, seeing as they are only a bit slower than list comprehension in my tests. The trick is to loop over ", "user_id": "None"}, {"stack_answer_id": "55557758", "stack_answer_comment_id": "105699071", "comment_content": "Under List Comprehensions, the \"iterating over multiple columns\" example needs a caveat: ", "user_id": "None"}, {"stack_answer_id": "55557758", "stack_answer_comment_id": "111575230", "comment_content": "@Dean I get this response quite often and it honestly confuses me. It's all about forming good habits. \"My data is small and performance doesn't matter so my use of this antipattern can be excused\" ..? When performance actually does matter one day, you'll thank yourself for having prepared the right tools in advance.", "user_id": "None"}]}, {"stack_answer_id": "41022840", "answer_content": "\r\n First consider if you really need to  iterate  over rows in a DataFrame. See  this answer  for alternatives. \n If you still need to iterate over rows, you can use methods below. Note some   important caveats  which are not mentioned in any of the other answers. \n \n DataFrame.iterrows() \n   for index, row in df.iterrows():\n      print(row[\"c1\"], row[\"c2\"])\n \n \n DataFrame.itertuples() \n   for row in df.itertuples(index=True, name='Pandas'):\n      print(row.c1, row.c2)\n \n \n \n itertuples()  is supposed to be faster than  iterrows() \n But be aware, according to the docs (pandas 0.24.2 at the moment): \n \n iterrows:  dtype  might not match from row to row \n \n \n Because iterrows returns a Series for each row, it  does not preserve  dtypes across the rows (dtypes are preserved across columns for DataFrames). To preserve dtypes while iterating over the rows, it is better to use itertuples() which returns namedtuples of the values and which is generally much faster than iterrows() \n \n \n iterrows: Do not modify rows \n \n \n You should  never modify  something you are iterating over. This is not guaranteed to work in all cases. Depending on the data types, the iterator returns a copy and not a view, and writing to it will have no effect. \n \n Use  DataFrame.apply()  instead: \n     new_df = df.apply(lambda x: x * 2, axis = 1)\n \n \n itertuples: \n \n \n The column names will be renamed to positional names if they are invalid Python identifiers, repeated, or start with an underscore. With a large number of columns (>255), regular tuples are returned. \n \n See  pandas docs on iteration  for more details. \n    ", "date_posted": "2022-04-30 18:45:58Z", "upvote": "\r\n            534\r\n        ", "accepted": "No", "user": {"stack_user_id": "7156008", "name": "George", "reputation_score": "2,904"}, "answer_comments": [{"stack_answer_id": "41022840", "stack_answer_comment_id": "83917009", "comment_content": "Just a small question from someone reading this thread so long after its completion: how df.apply() compares to itertuples in terms of efficiency?", "user_id": "None"}, {"stack_answer_id": "41022840", "stack_answer_comment_id": "89180584", "comment_content": "Note: you can also say something like ", "user_id": "None"}, {"stack_answer_id": "41022840", "stack_answer_comment_id": "90586609", "comment_content": "Instead of ", "user_id": "None"}, {"stack_answer_id": "41022840", "stack_answer_comment_id": "90954217", "comment_content": "I am about 90% sure that if you use ", "user_id": "None"}, {"stack_answer_id": "41022840", "stack_answer_comment_id": "99357008", "comment_content": "I have stumbled upon this question because, although I knew there's split-apply-combine, I still ", "user_id": "None"}]}, {"stack_answer_id": "10739432", "answer_content": "\r\n You should use  df.iterrows() . Though iterating row-by-row is not especially efficient since  Series  objects have to be created. \n    ", "date_posted": "2019-12-11 18:42:58Z", "upvote": "\r\n            238\r\n        ", "accepted": "No", "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "answer_comments": [{"stack_answer_id": "10739432", "stack_answer_comment_id": "17255818", "comment_content": "Is this faster than converting the DataFrame to a numpy array (via .values) and operating on the array directly? I have the same problem, but ended up converting to a numpy array and then using cython.", "user_id": "None"}, {"stack_answer_id": "10739432", "stack_answer_comment_id": "24785470", "comment_content": "@vgoklani If iterating row-by-row is inefficient and you have a non-object numpy array then almost surely using the raw numpy array will be faster, especially for arrays with many rows. you should avoid iterating over rows unless you absolutely have to", "user_id": "None"}, {"stack_answer_id": "10739432", "stack_answer_comment_id": "56363619", "comment_content": "I have done a bit of testing on the time consumption for df.iterrows(), df.itertuples(), and zip(df['a'], df['b']) and posted the result in the answer of another question: ", "user_id": "None"}]}, {"stack_answer_id": "32680162", "answer_content": "\r\n While  iterrows()  is a good option, sometimes  itertuples()  can be much faster: \n\n df = pd.DataFrame({'a': randn(1000), 'b': randn(1000),'N': randint(100, 1000, (1000)), 'x': 'x'})\n\n%timeit [row.a * 2 for idx, row in df.iterrows()]\n# => 10 loops, best of 3: 50.3 ms per loop\n\n%timeit [row[1] * 2 for row in df.itertuples()]\n# => 1000 loops, best of 3: 541 \u00b5s per loop\n \n    ", "date_posted": "2016-06-01 09:00:01Z", "upvote": "\r\n            178\r\n        ", "accepted": "No", "user": {"stack_user_id": "1054939", "name": "e9t", "reputation_score": "14.5k"}, "answer_comments": [{"stack_answer_id": "32680162", "stack_answer_comment_id": "53208434", "comment_content": "Much of the time difference in your two examples seems like it is due to the fact that you appear to be using label-based indexing for the .iterrows() command and integer-based indexing for the .itertuples() command.", "user_id": "None"}, {"stack_answer_id": "32680162", "stack_answer_comment_id": "54234206", "comment_content": "For a finance data based dataframe(timestamp, and 4x float), itertuples is 19,57 times faster then iterrows on my machine. Only ", "user_id": "None"}, {"stack_answer_id": "32680162", "stack_answer_comment_id": "70363504", "comment_content": "Can you explain why it's faster?", "user_id": "None"}, {"stack_answer_id": "32680162", "stack_answer_comment_id": "71581133", "comment_content": "@AbeMiessler ", "user_id": "None"}, {"stack_answer_id": "32680162", "stack_answer_comment_id": "81199073", "comment_content": "Note that the order of the columns is actually indeterminate, because ", "user_id": "None"}]}, {"stack_answer_id": "39370553", "answer_content": "\r\n You can use the  df.iloc  function as follows: \n for i in range(0, len(df)):\n    print(df.iloc[i]['c1'], df.iloc[i]['c2'])\n \n    ", "date_posted": "2022-01-08 22:42:21Z", "upvote": "\r\n            129\r\n        ", "accepted": "No", "user": {"stack_user_id": "6160119", "name": "Tonechas", "reputation_score": "12.9k"}, "answer_comments": [{"stack_answer_id": "39370553", "stack_answer_comment_id": "80130437", "comment_content": "I know that one should avoid this in favor of iterrows or itertuples, but it would be interesting to know why. Any thoughts?", "user_id": "None"}, {"stack_answer_id": "39370553", "stack_answer_comment_id": "83643245", "comment_content": "This is the only valid technique I know of if you want to preserve the data types, and also refer to columns by name.  ", "user_id": "None"}, {"stack_answer_id": "39370553", "stack_answer_comment_id": "91754942", "comment_content": "Spent hours trying to wade through the idiosyncrasies of pandas data structures to do something simple AND expressive.  This results in readable code.", "user_id": "None"}, {"stack_answer_id": "39370553", "stack_answer_comment_id": "94421406", "comment_content": "While ", "user_id": "None"}, {"stack_answer_id": "39370553", "stack_answer_comment_id": "94897279", "comment_content": "On large Datafrmes this seems better as ", "user_id": "None"}]}, {"stack_answer_id": "30566899", "answer_content": "\r\n You can also use  df.apply()  to iterate over rows and access multiple columns for a function. \n\n docs: DataFrame.apply() \n\n def valuation_formula(x, y):\n    return x * y * 0.5\n\ndf['price'] = df.apply(lambda row: valuation_formula(row['x'], row['y']), axis=1)\n \n    ", "date_posted": "2015-06-01 06:24:44Z", "upvote": "\r\n            120\r\n        ", "accepted": "No", "user": {"stack_user_id": "1803298", "name": "cheekybastard", "reputation_score": "5,355"}, "answer_comments": [{"stack_answer_id": "30566899", "stack_answer_comment_id": "50344574", "comment_content": "Is the df['price'] refers to a column name in the data frame? I am trying to create a dictionary with unique values from several columns in a csv file. I used your logic to create a dictionary with unique keys and values and got an error stating ", "user_id": "None"}, {"stack_answer_id": "30566899", "stack_answer_comment_id": "50344609", "comment_content": "  df['Workclass'] = df.apply(lambda row: dic_update(row), axis=1) ", "user_id": "None"}, {"stack_answer_id": "30566899", "stack_answer_comment_id": "82085632", "comment_content": "Having the axis default to 0 is the worst", "user_id": "None"}, {"stack_answer_id": "30566899", "stack_answer_comment_id": "86313667", "comment_content": "Notice that ", "user_id": "None"}, {"stack_answer_id": "30566899", "stack_answer_comment_id": "111570055", "comment_content": "this is the appropriate answer for pandas", "user_id": "None"}]}, {"stack_answer_id": "59413206", "answer_content": "\r\n How to iterate efficiently \n\n If you really have to iterate a Pandas dataframe, you will probably want to  avoid using iterrows() . There are different methods and the usual  iterrows()  is far from being the best.  itertuples() can be 100 times faster. \n\n In short: \n\n \n As a general rule, use  df.itertuples(name=None) . In particular, when you have a fixed number columns and less than 255 columns.  See point (3) \n Otherwise, use  df.itertuples()  except if your columns have special characters such as spaces or '-'.  See point (2) \n It is possible to use  itertuples()  even if your dataframe has strange columns by using the last example.  See point (4) \n Only use  iterrows()  if you cannot the previous solutions.  See point (1) \n \n\n Different methods to iterate over rows in a Pandas dataframe: \n\n Generate a random dataframe with a million rows and 4 columns: \n\n     df = pd.DataFrame(np.random.randint(0, 100, size=(1000000, 4)), columns=list('ABCD'))\n    print(df)\n \n\n 1) The usual  iterrows()  is convenient, but damn slow: \n\n start_time = time.clock()\nresult = 0\nfor _, row in df.iterrows():\n    result += max(row['B'], row['C'])\n\ntotal_elapsed_time = round(time.clock() - start_time, 2)\nprint(\"1. Iterrows done in {} seconds, result = {}\".format(total_elapsed_time, result))\n \n\n 2) The default  itertuples()  is already much faster, but it doesn't work with column names such as  My Col-Name is very Strange  (you should avoid this method if your columns are repeated or if a column name cannot be simply converted to a Python variable name).: \n\n start_time = time.clock()\nresult = 0\nfor row in df.itertuples(index=False):\n    result += max(row.B, row.C)\n\ntotal_elapsed_time = round(time.clock() - start_time, 2)\nprint(\"2. Named Itertuples done in {} seconds, result = {}\".format(total_elapsed_time, result))\n \n\n 3) The default  itertuples()  using name=None is even faster but not really convenient as you have to define a variable per column. \n\n start_time = time.clock()\nresult = 0\nfor(_, col1, col2, col3, col4) in df.itertuples(name=None):\n    result += max(col2, col3)\n\ntotal_elapsed_time = round(time.clock() - start_time, 2)\nprint(\"3. Itertuples done in {} seconds, result = {}\".format(total_elapsed_time, result))\n \n\n 4) Finally, the named  itertuples()  is slower than the previous point, but you do not have to define a variable per column and it works with column names such as  My Col-Name is very Strange . \n\n start_time = time.clock()\nresult = 0\nfor row in df.itertuples(index=False):\n    result += max(row[df.columns.get_loc('B')], row[df.columns.get_loc('C')])\n\ntotal_elapsed_time = round(time.clock() - start_time, 2)\nprint(\"4. Polyvalent Itertuples working even with special characters in the column name done in {} seconds, result = {}\".format(total_elapsed_time, result))\n \n\n Output: \n\n          A   B   C   D\n0       41  63  42  23\n1       54   9  24  65\n2       15  34  10   9\n3       39  94  82  97\n4        4  88  79  54\n...     ..  ..  ..  ..\n999995  48  27   4  25\n999996  16  51  34  28\n999997   1  39  61  14\n999998  66  51  27  70\n999999  51  53  47  99\n\n[1000000 rows x 4 columns]\n\n1. Iterrows done in 104.96 seconds, result = 66151519\n2. Named Itertuples done in 1.26 seconds, result = 66151519\n3. Itertuples done in 0.94 seconds, result = 66151519\n4. Polyvalent Itertuples working even with special characters in the column name done in 2.94 seconds, result = 66151519\n \n\n This article is a very interesting comparison between iterrows and itertuples \n    ", "date_posted": "2020-06-11 13:43:59Z", "upvote": "\r\n            61\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "59413206", "stack_answer_comment_id": "124783543", "comment_content": "So WHY are these inefficient methods available in Pandas in the first place - if it's \"common knowledge\" that iterrows and itertuples should not be used - then why are they there, or rather, why are those methods not updated and made more efficient in the background by the maintainers of Pandas?", "user_id": "None"}, {"stack_answer_id": "59413206", "stack_answer_comment_id": "124794962", "comment_content": "@Monty, it's not always possible to vectorize all operations.", "user_id": "None"}]}, {"stack_answer_id": "48297889", "answer_content": "\r\n I was looking for  How to iterate on rows   and   columns  and ended here so: \n\n for i, row in df.iterrows():\n    for j, column in row.iteritems():\n        print(column)\n \n    ", "date_posted": "2020-06-11 13:37:53Z", "upvote": "\r\n            48\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "48297889", "stack_answer_comment_id": "111393447", "comment_content": "When possible, you should avoid using iterrows(). I explain why in the answer ", "user_id": "None"}]}, {"stack_answer_id": "47149876", "answer_content": "\r\n You can write your own iterator that implements  namedtuple \n\n from collections import namedtuple\n\ndef myiter(d, cols=None):\n    if cols is None:\n        v = d.values.tolist()\n        cols = d.columns.values.tolist()\n    else:\n        j = [d.columns.get_loc(c) for c in cols]\n        v = d.values[:, j].tolist()\n\n    n = namedtuple('MyTuple', cols)\n\n    for line in iter(v):\n        yield n(*line)\n \n\n This is directly comparable to  pd.DataFrame.itertuples .  I'm aiming at performing the same task with more efficiency. \n\n \n\n For the given dataframe with my function: \n\n list(myiter(df))\n\n[MyTuple(c1=10, c2=100), MyTuple(c1=11, c2=110), MyTuple(c1=12, c2=120)]\n \n\n Or with  pd.DataFrame.itertuples : \n\n list(df.itertuples(index=False))\n\n[Pandas(c1=10, c2=100), Pandas(c1=11, c2=110), Pandas(c1=12, c2=120)]\n \n\n \n\n A comprehensive test \nWe test making all columns available and subsetting the columns.   \n\n def iterfullA(d):\n    return list(myiter(d))\n\ndef iterfullB(d):\n    return list(d.itertuples(index=False))\n\ndef itersubA(d):\n    return list(myiter(d, ['col3', 'col4', 'col5', 'col6', 'col7']))\n\ndef itersubB(d):\n    return list(d[['col3', 'col4', 'col5', 'col6', 'col7']].itertuples(index=False))\n\nres = pd.DataFrame(\n    index=[10, 30, 100, 300, 1000, 3000, 10000, 30000],\n    columns='iterfullA iterfullB itersubA itersubB'.split(),\n    dtype=float\n)\n\nfor i in res.index:\n    d = pd.DataFrame(np.random.randint(10, size=(i, 10))).add_prefix('col')\n    for j in res.columns:\n        stmt = '{}(d)'.format(j)\n        setp = 'from __main__ import d, {}'.format(j)\n        res.at[i, j] = timeit(stmt, setp, number=100)\n\nres.groupby(res.columns.str[4:-1], axis=1).plot(loglog=True);\n \n\n \n\n \n    ", "date_posted": "2017-11-07 04:29:57Z", "upvote": "\r\n            24\r\n        ", "accepted": "No", "user": {"stack_user_id": "2336654", "name": "piRSquared", "reputation_score": "270k"}, "answer_comments": [{"stack_answer_id": "47149876", "stack_answer_comment_id": "82152350", "comment_content": "For people who don't want to read the code: blue line is ", "user_id": "None"}]}, {"stack_answer_id": "42741552", "answer_content": "\r\n To loop all rows in a  dataframe  you can use: \n\n for x in range(len(date_example.index)):\n    print date_example['Date'].iloc[x]\n \n    ", "date_posted": "2017-04-04 20:46:53Z", "upvote": "\r\n            21\r\n        ", "accepted": "No", "user": {"stack_user_id": "797495", "name": "Pedro Lobito", "reputation_score": "87.6k"}, "answer_comments": [{"stack_answer_id": "42741552", "stack_answer_comment_id": "98185901", "comment_content": "This is chained indexing. I do not recommend doing this.", "user_id": "None"}, {"stack_answer_id": "42741552", "stack_answer_comment_id": "98187282", "comment_content": "@cs95 What would you recommend instead?", "user_id": "None"}, {"stack_answer_id": "42741552", "stack_answer_comment_id": "98187416", "comment_content": "If you want to make this work, call df.columns.get_loc to get the integer index position of the date column (outside the loop), then use a single iloc indexing call inside.", "user_id": "None"}]}, {"stack_answer_id": "47073107", "answer_content": "\r\n  for ind in df.index:\n     print df['c1'][ind], df['c2'][ind]\n \n    ", "date_posted": "2019-05-07 06:37:44Z", "upvote": "\r\n            21\r\n        ", "accepted": "No", "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "answer_comments": [{"stack_answer_id": "47073107", "stack_answer_comment_id": "91463214", "comment_content": "how is the performance of this option when used on a large dataframe (millions of rows for example)?", "user_id": "None"}, {"stack_answer_id": "47073107", "stack_answer_comment_id": "92887253", "comment_content": "Honestly, I don\u2019t know exactly, I think that in comparison with the best answer, the elapsed time will be about the same, because both cases use \"for\"-construction.  But the memory may be different in some cases.", "user_id": "None"}, {"stack_answer_id": "47073107", "stack_answer_comment_id": "98185895", "comment_content": "This is chained indexing. Do not use this!", "user_id": "None"}]}, {"stack_answer_id": "70096237", "answer_content": "\r\n We have multiple options to do the same, lots of folks have shared their answers. \n I found below two methods easy and efficient to do : \n \n DataFrame.iterrows() \n DataFrame.itertuples() \n \n Example: \n  import pandas as pd\n inp = [{'c1':10, 'c2':100}, {'c1':11,'c2':110}, {'c1':12,'c2':120}]\n df = pd.DataFrame(inp)\n print (df)\n\n #With iterrows method \n\n for index, row in df.iterrows():\n     print(row[\"c1\"], row[\"c2\"])\n\n #With itertuples method\n\n for row in df.itertuples(index=True, name='Pandas'):\n     print(row.c1, row.c2)\n \n Note: itertuples() is supposed to be faster than iterrows() \n    ", "date_posted": "2022-01-06 09:46:42Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "9076666", "name": "Sachin", "reputation_score": "862"}, "answer_comments": [{"stack_answer_id": "70096237", "stack_answer_comment_id": "124086617", "comment_content": "This actually answers the question. +1", "user_id": "None"}]}, {"stack_answer_id": "60836700", "answer_content": "\r\n Update : cs95 has updated  his answer  to include plain numpy vectorization. You can simply refer to his answer. \n \n cs95 shows  that Pandas vectorization far outperforms other Pandas methods for computing stuff with dataframes. \n I wanted to add that if you first convert the dataframe to a NumPy array and then use vectorization, it's even faster than Pandas dataframe vectorization, (and that includes the time to turn it back into a dataframe series). \n If you add the following functions to cs95's benchmark code, this becomes pretty evident: \n def np_vectorization(df):\n    np_arr = df.to_numpy()\n    return pd.Series(np_arr[:,0] + np_arr[:,1], index=df.index)\n\ndef just_np_vectorization(df):\n    np_arr = df.to_numpy()\n    return np_arr[:,0] + np_arr[:,1]\n \n \n    ", "date_posted": "2021-08-27 05:47:45Z", "upvote": "\r\n            15\r\n        ", "accepted": "No", "user": {"stack_user_id": "10801098", "name": "bug_spray", "reputation_score": "1,335"}, "answer_comments": [{"stack_answer_id": "60836700", "stack_answer_comment_id": "121890161", "comment_content": "how do did you plot this?", "user_id": "None"}, {"stack_answer_id": "60836700", "stack_answer_comment_id": "121960481", "comment_content": " ", "user_id": "None"}]}, {"stack_answer_id": "51069586", "answer_content": "\r\n Sometimes a useful pattern is: \n\n # Borrowing @KutalmisB df example\ndf = pd.DataFrame({'col1': [1, 2], 'col2': [0.1, 0.2]}, index=['a', 'b'])\n# The to_dict call results in a list of dicts\n# where each row_dict is a dictionary with k:v pairs of columns:value for that row\nfor row_dict in df.to_dict(orient='records'):\n    print(row_dict)\n \n\n Which results in: \n\n {'col1':1.0, 'col2':0.1}\n{'col1':2.0, 'col2':0.2}\n \n    ", "date_posted": "2019-04-13 23:06:06Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "answer_comments": []}, {"stack_answer_id": "62136475", "answer_content": "\r\n In short \n \n Use vectorization if possible \n If an operation can't be vectorized - use list comprehensions \n If you need a single object representing the entire row - use itertuples \n If the above is too slow - try  swifter.apply \n If it's still too slow - try a  Cython  routine \n \n Benchmark \n \n    ", "date_posted": "2021-04-21 16:42:24Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "58436037", "answer_content": "\r\n There is a way to iterate throw rows while getting a DataFrame in return, and not a Series. I don't see anyone mentioning that you can pass index as a list for the row to be returned as a DataFrame: \n\n for i in range(len(df)):\n    row = df.iloc[[i]]\n \n\n Note the usage of double brackets. This returns a DataFrame with a single row. \n    ", "date_posted": "2019-10-17 15:26:30Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "1871385", "name": "Zeitgeist", "reputation_score": "1,242"}, "answer_comments": [{"stack_answer_id": "58436037", "stack_answer_comment_id": "104526424", "comment_content": "This was very helpful for getting the nth largest row in a data frame after sorting. Thanks!", "user_id": "None"}]}, {"stack_answer_id": "49984074", "answer_content": "\r\n To loop all rows in a  dataframe  and  use  values of each row  conveniently ,  namedtuples  can be converted to  ndarray s. For example: \n\n df = pd.DataFrame({'col1': [1, 2], 'col2': [0.1, 0.2]}, index=['a', 'b'])\n \n\n Iterating over the rows: \n\n for row in df.itertuples(index=False, name='Pandas'):\n    print np.asarray(row)\n \n\n results in: \n\n [ 1.   0.1]\n[ 2.   0.2]\n \n\n Please note that if  index=True ,  the index is added as the first element of the tuple , which may be undesirable for some applications. \n    ", "date_posted": "2018-04-24 08:48:05Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "3393574", "name": "Herpes Free Engineer", "reputation_score": "2,125"}, "answer_comments": []}, {"stack_answer_id": "54896256", "answer_content": "\r\n For both viewing and modifying values, I would use  iterrows() . In a for loop and by using tuple unpacking (see the example:  i, row ), I use the  row  for only viewing the value and use  i  with the  loc  method when I want to modify values. As stated in previous answers, here you should not modify something you are iterating over. \n\n for i, row in df.iterrows():\n    df_column_A = df.loc[i, 'A']\n    if df_column_A == 'Old_Value':\n        df_column_A = 'New_value'  \n \n\n Here the  row  in the loop is a copy of that row, and not a view of it. Therefore, you should NOT write something like  row['A'] = 'New_Value' , it will not modify the DataFrame. However, you can use  i  and  loc  and specify the DataFrame to do the work. \n    ", "date_posted": "2020-02-28 17:51:44Z", "upvote": "\r\n            10\r\n        ", "accepted": "No", "user": {"stack_user_id": "10951905", "name": "Hossein Kalbasi", "reputation_score": "1,393"}, "answer_comments": []}, {"stack_answer_id": "54264778", "answer_content": "\r\n There are so many ways to iterate over the rows in Pandas dataframe. One very simple and intuitive way is: \n\n df = pd.DataFrame({'A':[1, 2, 3], 'B':[4, 5, 6], 'C':[7, 8, 9]})\nprint(df)\nfor i in range(df.shape[0]):\n    # For printing the second column\n    print(df.iloc[i, 1])\n\n    # For printing more than one columns\n    print(df.iloc[i, [0, 2]])\n \n    ", "date_posted": "2020-06-11 13:38:59Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "64653674", "answer_content": "\r\n The easiest way, use the  apply  function \n def print_row(row):\n   print row['c1'], row['c2']\n\ndf.apply(lambda row: print_row(row), axis=1)\n \n    ", "date_posted": "2020-11-02 21:35:10Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "12566550", "name": "Fran\u00e7ois B.", "reputation_score": "1,014"}, "answer_comments": []}, {"stack_answer_id": "65396738", "answer_content": "\r\n As many answers here correctly and clearly point out, you should not generally attempt to loop in Pandas, but rather should write vectorized code.  But the question remains if you should  ever  write loops in Pandas, and if so the best way to loop in those situations. \n I believe there is at least one general situation where loops are appropriate: when you need to calculate some function that depends on values in  other  rows in a somewhat complex manner.  In this case, the looping code is often simpler, more readable, and less error prone than vectorized code.   The looping code might even be faster, too. \n I will attempt to show this with an example.  Suppose you want to take a cumulative sum of a column, but reset it whenever some other column equals zero: \n import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame( { 'x':[1,2,3,4,5,6], 'y':[1,1,1,0,1,1]  } )\n\n#   x  y  desired_result\n#0  1  1               1\n#1  2  1               3\n#2  3  1               6\n#3  4  0               4\n#4  5  1               9\n#5  6  1              15\n \n This is a good example where you could certainly write one line of Pandas to achieve this, although it's not especially readable, especially if you aren't fairly experienced with Pandas already: \n df.groupby( (df.y==0).cumsum() )['x'].cumsum()\n \n That's going to be fast enough for most situations, although you could also write faster code by avoiding the  groupby , but it will likely be even less readable. \n Alternatively, what if we write this as a loop?  You could do something like the following with NumPy: \n import numba as nb\n\n@nb.jit(nopython=True)  # Optional\ndef custom_sum(x,y):\n    x_sum = x.copy()\n    for i in range(1,len(df)):\n        if y[i] > 0: x_sum[i] = x_sum[i-1] + x[i]\n    return x_sum\n\ndf['desired_result'] = custom_sum( df.x.to_numpy(), df.y.to_numpy() )\n \n Admittedly, there's a bit of overhead there required to convert DataFrame columns to NumPy arrays, but the core piece of code is just one line of code that you could read even if you didn't know anything about Pandas or NumPy: \n if y[i] > 0: x_sum[i] = x_sum[i-1] + x[i]\n \n And this code is actually  faster  than the vectorized code.  In some quick tests with 100,000 rows, the above is about 10x faster than the  groupby  approach.  Note that one key to the speed there is numba, which is optional.  Without the \"@nb.jit\" line, the looping code is actually about 10x slower than the  groupby  approach. \n Clearly this example is simple enough that you would likely prefer the one line of pandas to writing a loop with its associated overhead.  However, there are more complex versions of this problem for which the readability or speed of the NumPy/numba loop approach likely makes sense. \n    ", "date_posted": "2021-07-23 18:29:01Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "3877338", "name": "JohnE", "reputation_score": "27.1k"}, "answer_comments": []}, {"stack_answer_id": "68233908", "answer_content": "\r\n df.iterrows()  returns  tuple(a, b)  where  a  is the  index  and  b  is the  row . \n    ", "date_posted": "2022-03-31 07:36:53Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "9534390", "name": "pythonic833", "reputation_score": "2,904"}, "answer_comments": []}, {"stack_answer_id": "47598852", "answer_content": "\r\n You can also do NumPy indexing for even greater speed ups. It's not really iterating but works much better than iteration for certain applications. \n\n subset = row['c1'][0:5]\nall = row['c1'][:]\n \n\n You may also want to cast it to an array. These indexes/selections are supposed to act like NumPy arrays already, but I ran into issues and needed to cast \n\n np.asarray(all)\nimgs[:] = cv2.resize(imgs[:], (224,224) ) # Resize every image in an hdf5 file\n \n    ", "date_posted": "2020-06-11 13:37:16Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "71234113", "answer_content": "\r\n Disclaimer:  Although here are so many answers which recommend  not  using an iterative (loop) approach (and I mostly agree), I would still see it as a reasonable approach for the following situation: \n Extend dataframe with data from API \n Let's say you have a large dataframe which contains incomplete user data. Now you have to extend this data with additional columns, for example the user's  age  and  gender . \n Both values have to be fetched from a backend API. I'm assuming the API doesn't provide a \"batch\" endpoint (which would accept multiple user IDs at once). Otherwise, you should rather call the API only once. \n The costs (waiting time) for the network request surpass the iteration of the dataframe by far. We're talking about network roundtrip times of hundreds of milliseconds compared to the negligibly small gains in using alternative approaches to iterations. \n 1 expensive network request for each row \n So in this case, I would absolutely prefer using an iterative approach. Although the network request is expensive, it is guaranteed being triggered only once for each row in the dataframe. Here is an example using  DataFrame.iterrows : \n Example \n for index, row in users_df.iterrows():\n  user_id = row['user_id']\n  # trigger expensive network request once for each row\n  response_dict = backend_api.get(f'/api/user-data/{user_id}')\n  # extend dataframe with multiple data from response\n  users_df.at[index, 'age'] = response_dict.get('age')\n  users_df.at[index, 'gender'] = response_dict.get('gender')\n \n    ", "date_posted": "2022-04-08 16:02:59Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "2472398", "name": "gru", "reputation_score": "1,480"}, "answer_comments": []}, {"stack_answer_id": "55202153", "answer_content": "\r\n This example uses iloc to isolate each digit in the data frame.  \n\n import pandas as pd\n\n a = [1, 2, 3, 4]\n b = [5, 6, 7, 8]\n\n mjr = pd.DataFrame({'a':a, 'b':b})\n\n size = mjr.shape\n\n for i in range(size[0]):\n     for j in range(size[1]):\n         print(mjr.iloc[i, j])\n \n    ", "date_posted": "2019-03-16 22:33:02Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "8042986", "name": "mjr2000", "reputation_score": "90"}, "answer_comments": []}, {"stack_answer_id": "59264161", "answer_content": "\r\n Some libraries (e.g. a Java interop library that I use) require values to be passed in a row at a time, for example, if streaming data. To replicate the streaming nature, I 'stream' my dataframe values one by one, I wrote the below, which comes in handy from time to time. \n\n class DataFrameReader:\n  def __init__(self, df):\n    self._df = df\n    self._row = None\n    self._columns = df.columns.tolist()\n    self.reset()\n    self.row_index = 0\n\n  def __getattr__(self, key):\n    return self.__getitem__(key)\n\n  def read(self) -> bool:\n    self._row = next(self._iterator, None)\n    self.row_index += 1\n    return self._row is not None\n\n  def columns(self):\n    return self._columns\n\n  def reset(self) -> None:\n    self._iterator = self._df.itertuples()\n\n  def get_index(self):\n    return self._row[0]\n\n  def index(self):\n    return self._row[0]\n\n  def to_dict(self, columns: List[str] = None):\n    return self.row(columns=columns)\n\n  def tolist(self, cols) -> List[object]:\n    return [self.__getitem__(c) for c in cols]\n\n  def row(self, columns: List[str] = None) -> Dict[str, object]:\n    cols = set(self._columns if columns is None else columns)\n    return {c : self.__getitem__(c) for c in self._columns if c in cols}\n\n  def __getitem__(self, key) -> object:\n    # the df index of the row is at index 0\n    try:\n        if type(key) is list:\n            ix = [self._columns.index(key) + 1 for k in key]\n        else:\n            ix = self._columns.index(key) + 1\n        return self._row[ix]\n    except BaseException as e:\n        return None\n\n  def __next__(self) -> 'DataFrameReader':\n    if self.read():\n        return self\n    else:\n        raise StopIteration\n\n  def __iter__(self) -> 'DataFrameReader':\n    return self\n \n\n Which can be used: \n\n for row in DataFrameReader(df):\n  print(row.my_column_name)\n  print(row.to_dict())\n  print(row['my_column_name'])\n  print(row.tolist())\n \n\n And preserves the values/ name mapping for the rows being iterated. Obviously, is a lot slower than using apply and Cython as indicated above, but is necessary in some circumstances. \n    ", "date_posted": "2019-12-10 09:36:45Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "6690508", "name": "morganics", "reputation_score": "1,111"}, "answer_comments": []}, {"stack_answer_id": "64177887", "answer_content": "\r\n Along with the great answers in this post I am going to propose  Divide and Conquer  approach, I am not writing this answer to abolish the other great answers but to fulfill them with another approach which was working efficiently for me. It has two steps of  splitting  and  merging  the pandas dataframe: \n PROS of Divide and Conquer: \n \n You don't need to use vectorization or any other methods to cast the type of your dataframe into another type \n You don't need to Cythonize your code which normally takes extra time from you \n Both  iterrows()  and  itertuples()  in my case were having the same performance over entire dataframe \n Depends on your choice of slicing  index , you will be able to exponentially quicken the iteration. The higher  index , the quicker your iteration process. \n \n CONS of Divide and Conquer: \n \n You shouldn't have dependency over the iteration process to the same dataframe and different  slice . Meaning if you want to read or write from other  slice , it maybe difficult to do that. \n \n ===================    Divide and Conquer Approach    ================= \n Step 1: Splitting/Slicing \n In this step, we are going to divide the iteration over the entire dataframe. Think that you are going to read a csv file into pandas df then iterate over it. In may case I have 5,000,000 records and I am going to split it into 100,000 records. \n NOTE:  I need to reiterate as other runtime analysis explained in the other solutions in this page, \"number of records\" has exponential proportion of \"runtime\" on search on the df. Based on the benchmark on my data here are the results: \n Number of records | Iteration per second\n========================================\n100,000           | 500 it/s\n500,000           | 200 it/s\n1,000,000         | 50 it/s\n5,000,000         | 20 it/s\n \n Step 2: Merging \n This is going to be an easy step, just merge all the written csv files into one dataframe and write it into a bigger csv file. \n Here is the sample code: \n # Step 1 (Splitting/Slicing)\nimport pandas as pd\ndf_all = pd.read_csv('C:/KtV.csv')\ndf_index = 100000\ndf_len = len(df)\nfor i in range(df_len // df_index + 1):\n    lower_bound = i * df_index \n    higher_bound = min(lower_bound + df_index, df_len)\n    # splitting/slicing df (make sure to copy() otherwise it will be a view\n    df = df_all[lower_bound:higher_bound].copy()\n    '''\n    write your iteration over the sliced df here\n    using iterrows() or intertuples() or ...\n    '''\n    # writing into csv files\n    df.to_csv('C:/KtV_prep_'+str(i)+'.csv')\n\n\n\n# Step 2 (Merging)\nfilename='C:/KtV_prep_'\ndf = (pd.read_csv(f) for f in [filename+str(i)+'.csv' for i in range(ktv_len // ktv_index + 1)])\ndf_prep_all = pd.concat(df)\ndf_prep_all.to_csv('C:/KtV_prep_all.csv')\n \n Reference: \n Efficient way of iteration over datafreame \n Concatenate csv files into one Pandas Dataframe \n    ", "date_posted": "2020-10-31 13:57:20Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "6117017", "name": "Timbus Calin", "reputation_score": "12.2k"}, "answer_comments": []}, {"stack_answer_id": "67701850", "answer_content": "\r\n As  the accepted answer  states, the fastest way to apply a function over rows is to use a  vectorized function , the so-called NumPy  ufuncs  (universal functions). \n But what should you do when the function you want to apply isn't already implemented in NumPy? \n Well, using the  vectorize  decorator from  numba , you can easily create ufuncs directly in Python like this: \n from numba import vectorize, float64\n\n@vectorize([float64(float64)])\ndef f(x):\n    #x is your line, do something with it, and return a float\n \n The documentation for this function is here:  Creating NumPy universal functions \n    ", "date_posted": "2022-01-05 20:48:26Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "68562557", "answer_content": "\r\n Probably the most elegant solution (but certainly not the most efficient): \n for row in df.values:\n    c2 = row[1]\n    print(row)\n    # ...\n\nfor c1, c2 in df.values:\n    # ...\n \n Note that: \n \n the  documentation  explicitly recommends to use  .to_numpy()  instead \n the produced NumPy array will have a dtype that fits all columns, in the worst case  object \n there are  good reasons  not to use a loop in the first place \n \n Still, I think this option should be included here, as a straight-forward solution to a (one should think) trivial problem. \n    ", "date_posted": "2021-08-02 10:04:04Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "4248897", "name": "Ernesto Els\u00e4\u00dfer", "reputation_score": "694"}, "answer_comments": []}], "user": {"stack_user_id": "245549", "name": "Roman", "reputation_score": "115k"}, "question_comments": [{"stack_question_id": "16476924", "stack_question_comment_id": "82610234", "comment_content": "The df.iteritems() iterates over columns and not rows. Thus, to make it iterate over rows, you have to transpose (the \"T\"), which means you change rows and columns into each other (reflect over diagonal). As a result, you effectively iterate the original dataframe over its rows when you use df.T.iteritems()", "user_id": "None"}, {"stack_question_id": "16476924", "stack_question_comment_id": "103162518", "comment_content": "In contrast to what cs95 says, there are perfectly fine reasons to want to iterate over a dataframe, so new users should not feel discouraged. One example is if you want to execute some code using the values of each row as input. Also, if your dataframe is reasonably small (e.g. less than 1000 items), performance is not really an issue.", "user_id": "None"}, {"stack_question_id": "16476924", "stack_question_comment_id": "104047003", "comment_content": "@cs95 It seems to me that dataframes are the go-to table format in Python. So whenever you want to read in a csv, or you have a list of dicts whose values you want to manipulate, or you want to perform simple join, groupby or window operations, you use a dataframe, even if your data is comparitively small.", "user_id": "None"}, {"stack_question_id": "16476924", "stack_question_comment_id": "104053145", "comment_content": "@cs95 No, but this was in response to \"using a DataFrame at all\". My point is that this is why one may have one's data in a dataframe. If you then want to e.g. run a script for each line of your data, you have to iterate over that dataframe.", "user_id": "None"}, {"stack_question_id": "16476924", "stack_question_comment_id": "104107821", "comment_content": "I second @oulenz. As far as I can tell ", "user_id": "None"}]},
{"stack_question_id": "2158395", "question_title": "Flatten an irregular list of lists", "question_content": "\r\n                Yes, I know this subject has been covered before (here, here, here, here), but as far as I know, all solutions, except for one, fail on a list like this:\n\nL = [[[1, 2, 3], [4, 5]], 6]\r\nWhere the ...\r\n", "question_url": "/questions/2158395/flatten-an-irregular-list-of-lists", "date_posted": "Jan 28, 2010 at 22:15", "upvote": "5", "view": "1", "tags": ["python", "list", "optimization", "nested-lists", "flatten"], "answers_count": "5", "answers": [{"stack_answer_id": "2158532", "answer_content": "\r\n Using generator functions can make your example easier to read and improve performance. \n Python 2 \n Using the  Iterable  ABC  added in 2.6: \n from collections import Iterable\n\ndef flatten(xs):\n    for x in xs:\n        if isinstance(x, Iterable) and not isinstance(x, basestring):\n            for item in flatten(x):\n                yield item\n        else:\n            yield x\n \n Python 3 \n In Python 3,  basestring  is no more, but the tuple  (str, bytes)  gives the same effect. Also, the  yield from  operator returns an item from a generator one at a time. \n from collections.abc import Iterable\n\ndef flatten(xs):\n    for x in xs:\n        if isinstance(x, Iterable) and not isinstance(x, (str, bytes)):\n            yield from flatten(x)\n        else:\n            yield x\n \n    ", "date_posted": "2022-05-22 20:17:07Z", "upvote": "\r\n            448\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": [{"stack_answer_id": "2158532", "stack_answer_comment_id": "14265381", "comment_content": "Of all the suggestions on this page, this is the only one that flattened this list ", "user_id": "None"}, {"stack_answer_id": "2158532", "stack_answer_comment_id": "49961116", "comment_content": "This also flattens dictionaries. Maybe you want to use ", "user_id": "None"}, {"stack_answer_id": "2158532", "stack_answer_comment_id": "52038449", "comment_content": "This doesn't work with things that aren't lists initially, e.g. ", "user_id": "None"}, {"stack_answer_id": "2158532", "stack_answer_comment_id": "92094122", "comment_content": "For Python 3.7, using ", "user_id": "None"}, {"stack_answer_id": "2158532", "stack_answer_comment_id": "96939998", "comment_content": "Indeed, recursion is ", "user_id": "None"}]}, {"stack_answer_id": "2158522", "answer_content": "\r\n My solution: \n\n import collections\n\n\ndef flatten(x):\n    if isinstance(x, collections.Iterable):\n        return [a for i in x for a in flatten(i)]\n    else:\n        return [x]\n \n\n A little more concise, but pretty much the same. \n    ", "date_posted": "2019-05-23 12:18:40Z", "upvote": "\r\n            62\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "2158522", "stack_answer_comment_id": "25410021", "comment_content": "You can do this without importing anything if you just ", "user_id": "None"}, {"stack_answer_id": "2158522", "stack_answer_comment_id": "43136613", "comment_content": "Worth to note that this solution works only if all the items are of type ", "user_id": "None"}, {"stack_answer_id": "2158522", "stack_answer_comment_id": "77581475", "comment_content": "Could make it more concise, ", "user_id": "None"}, {"stack_answer_id": "2158522", "stack_answer_comment_id": "93943979", "comment_content": "this doesn't work on strings because strings are iterable too. Replace the condition with ", "user_id": "None"}, {"stack_answer_id": "2158522", "stack_answer_comment_id": "110395399", "comment_content": "replace ", "user_id": "None"}]}, {"stack_answer_id": "14491059", "answer_content": "\r\n Generator using recursion and duck typing (updated for Python 3): \n\n def flatten(L):\n    for item in L:\n        try:\n            yield from flatten(item)\n        except TypeError:\n            yield item\n\nlist(flatten([[[1, 2, 3], [4, 5]], 6]))\n>>>[1, 2, 3, 4, 5, 6]\n \n    ", "date_posted": "2015-09-08 15:01:25Z", "upvote": "\r\n            46\r\n        ", "accepted": "No", "user": {"stack_user_id": "1355221", "name": "dansalmo", "reputation_score": "11.1k"}, "answer_comments": [{"stack_answer_id": "14491059", "stack_answer_comment_id": "52784011", "comment_content": "Thanks, that works nice for Python 3.  For 2.x the previous is needed:  ", "user_id": "None"}, {"stack_answer_id": "14491059", "stack_answer_comment_id": "85707692", "comment_content": "list(flatten([['X'], 'Y'])) fails on 2.X variant", "user_id": "None"}, {"stack_answer_id": "14491059", "stack_answer_comment_id": "85750061", "comment_content": "@user1019129 see my comment above yours", "user_id": "None"}, {"stack_answer_id": "14491059", "stack_answer_comment_id": "85788346", "comment_content": "yes it fails with the cycle.. i think because a string is also an \"array\"-of-chars", "user_id": "None"}]}, {"stack_answer_id": "5409395", "answer_content": "\r\n Here is my functional version of recursive flatten which handles both tuples and lists, and lets you throw in any mix of positional arguments. Returns a generator which produces the entire sequence in order, arg by arg: \n\n flatten = lambda *n: (e for a in n\n    for e in (flatten(*a) if isinstance(a, (tuple, list)) else (a,)))\n \n\n Usage: \n\n l1 = ['a', ['b', ('c', 'd')]]\nl2 = [0, 1, (2, 3), [[4, 5, (6, 7, (8,), [9]), 10]], (11,)]\nprint list(flatten(l1, -2, -1, l2))\n['a', 'b', 'c', 'd', -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n \n    ", "date_posted": "2011-03-23 17:42:24Z", "upvote": "\r\n            39\r\n        ", "accepted": "No", "user": {"stack_user_id": "538718", "name": "samplebias", "reputation_score": "36k"}, "answer_comments": [{"stack_answer_id": "5409395", "stack_answer_comment_id": "29945046", "comment_content": "great solution, however would be much helpful if you added some comment to describe what ", "user_id": "None"}, {"stack_answer_id": "5409395", "stack_answer_comment_id": "31445589", "comment_content": "@WolfgangKuehne: Try ", "user_id": "None"}, {"stack_answer_id": "5409395", "stack_answer_comment_id": "51406248", "comment_content": "This is significantly faster than ", "user_id": "None"}, {"stack_answer_id": "5409395", "stack_answer_comment_id": "111812784", "comment_content": "This is the only solution I have come across, in a moderate google search, on any website that actually works for lists nested deeper than one level.", "user_id": "None"}, {"stack_answer_id": "5409395", "stack_answer_comment_id": "114103535", "comment_content": "This is a work of art. So few characters, and still nearly impossible to understand. 10/10 best Python code golf I've seen yet \ud83c\udfcc\ufe0f\u200d\u2642\ufe0f\ud83c\udfcc\ufe0f\u200d\u2640\ufe0f\u26f3\ufe0f.  Having something this short almost makes up for the fact that Python doesn't have a built-in flatten function.", "user_id": "None"}]}, {"stack_answer_id": "2159079", "answer_content": "\r\n Generator version of @unutbu's non-recursive solution, as requested by @Andrew in a comment: \n\n def genflat(l, ltypes=collections.Sequence):\n    l = list(l)\n    i = 0\n    while i < len(l):\n        while isinstance(l[i], ltypes):\n            if not l[i]:\n                l.pop(i)\n                i -= 1\n                break\n            else:\n                l[i:i + 1] = l[i]\n        yield l[i]\n        i += 1\n \n\n Slightly simplified version of this generator: \n\n def genflat(l, ltypes=collections.Sequence):\n    l = list(l)\n    while l:\n        while l and isinstance(l[0], ltypes):\n            l[0:1] = l[0]\n        if l: yield l.pop(0)\n \n    ", "date_posted": "2010-01-29 00:27:22Z", "upvote": "\r\n            36\r\n        ", "accepted": "No", "user": {"stack_user_id": "95810", "name": "Alex Martelli", "reputation_score": "820k"}, "answer_comments": [{"stack_answer_id": "2159079", "stack_answer_comment_id": "2104766", "comment_content": "it's a pre-order traversal of the tree formed by the nested lists.  only the leaves are returned.  Note that this implementation will consume the original data structure, for better or worse.  Could be fun to write one that both preserves the original tree, but also doesn't have to copy the list entries.", "user_id": "None"}, {"stack_answer_id": "2159079", "stack_answer_comment_id": "4686862", "comment_content": "I think you need to test for strings -- eg add \"and not isinstance(l[0], basestring)\" as in Cristian's solution. Otherwise you get an infinite loop around l[0:1] = l[0]", "user_id": "None"}, {"stack_answer_id": "2159079", "stack_answer_comment_id": "17780727", "comment_content": "This is a good example of making a generator, but as c-urchin mentions, the algorithm itself fails when the sequence contains strings.", "user_id": "None"}]}, {"stack_answer_id": "2158562", "answer_content": "\r\n This version of  flatten  avoids python's recursion limit (and thus works with arbitrarily deep, nested iterables). It is a generator which can handle strings and arbitrary iterables (even infinite ones). \n\n import itertools as IT\nimport collections\n\ndef flatten(iterable, ltypes=collections.Iterable):\n    remainder = iter(iterable)\n    while True:\n        first = next(remainder)\n        if isinstance(first, ltypes) and not isinstance(first, (str, bytes)):\n            remainder = IT.chain(first, remainder)\n        else:\n            yield first\n \n\n Here are some examples demonstrating its use: \n\n print(list(IT.islice(flatten(IT.repeat(1)),10)))\n# [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n\nprint(list(IT.islice(flatten(IT.chain(IT.repeat(2,3),\n                                       {10,20,30},\n                                       'foo bar'.split(),\n                                       IT.repeat(1),)),10)))\n# [2, 2, 2, 10, 20, 30, 'foo', 'bar', 1, 1]\n\nprint(list(flatten([[1,2,[3,4]]])))\n# [1, 2, 3, 4]\n\nseq = ([[chr(i),chr(i-32)] for i in range(ord('a'), ord('z')+1)] + list(range(0,9)))\nprint(list(flatten(seq)))\n# ['a', 'A', 'b', 'B', 'c', 'C', 'd', 'D', 'e', 'E', 'f', 'F', 'g', 'G', 'h', 'H',\n# 'i', 'I', 'j', 'J', 'k', 'K', 'l', 'L', 'm', 'M', 'n', 'N', 'o', 'O', 'p', 'P',\n# 'q', 'Q', 'r', 'R', 's', 'S', 't', 'T', 'u', 'U', 'v', 'V', 'w', 'W', 'x', 'X',\n# 'y', 'Y', 'z', 'Z', 0, 1, 2, 3, 4, 5, 6, 7, 8]\n \n\n Although  flatten  can handle infinite generators, it can not handle infinite nesting: \n\n def infinitely_nested():\n    while True:\n        yield IT.chain(infinitely_nested(), IT.repeat(1))\n\nprint(list(IT.islice(flatten(infinitely_nested()), 10)))\n# hangs\n \n    ", "date_posted": "2019-05-23 12:53:56Z", "upvote": "\r\n            33\r\n        ", "accepted": "No", "user": {"stack_user_id": "190597", "name": "unutbu", "reputation_score": "791k"}, "answer_comments": [{"stack_answer_id": "2158562", "stack_answer_comment_id": "27754234", "comment_content": "any consensus on whether to use ABC Iterable or ABC Sequence?", "user_id": "None"}, {"stack_answer_id": "2158562", "stack_answer_comment_id": "27754354", "comment_content": ", ", "user_id": "None"}, {"stack_answer_id": "2158562", "stack_answer_comment_id": "27804882", "comment_content": "@wim: One problem with using ", "user_id": "None"}, {"stack_answer_id": "2158562", "stack_answer_comment_id": "99165386", "comment_content": "This doesn't seem to work for the 3rd and the 4th examples. It throws ", "user_id": "None"}, {"stack_answer_id": "2158562", "stack_answer_comment_id": "106796892", "comment_content": "@Georgy this could be fixed with encapsulating the body of flatten in a ", "user_id": "None"}]}, {"stack_answer_id": "4590652", "answer_content": "\r\n def flatten(xs):\n    res = []\n    def loop(ys):\n        for i in ys:\n            if isinstance(i, list):\n                loop(i)\n            else:\n                res.append(i)\n    loop(xs)\n    return res\n \n    ", "date_posted": "2012-08-21 14:39:45Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "348785", "name": "kev", "reputation_score": "148k"}, "answer_comments": [{"stack_answer_id": "4590652", "stack_answer_comment_id": "121983372", "comment_content": "This looks very elegant and simple. Why it does not have more upvotes? Are there any problems with this solution?", "user_id": "None"}, {"stack_answer_id": "4590652", "stack_answer_comment_id": "129064569", "comment_content": "This is a brilliant solution!", "user_id": "None"}]}, {"stack_answer_id": "4694575", "answer_content": "\r\n Here's another answer that is even more interesting... \n import re\n\ndef Flatten(TheList):\n    a = str(TheList)\n    b,_Anon = re.subn(r'[\\[,\\]]', ' ', a)\n    c = b.split()\n    d = [int(x) for x in c]\n\n    return(d)\n \n Basically, it converts the nested list to a string, uses a regex to strip out the nested syntax, and then converts the result back to a (flattened) list. \n    ", "date_posted": "2021-01-20 14:15:09Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "392301", "name": "clay", "reputation_score": "1,677"}, "answer_comments": [{"stack_answer_id": "4694575", "stack_answer_comment_id": "40277369", "comment_content": "If you try to generalize this to something other than int values, it'll be fun with, e.g., ", "user_id": "None"}, {"stack_answer_id": "4694575", "stack_answer_comment_id": "40293216", "comment_content": "The original prompt was about flattening a list of integers. If you just change the list comprehension to d=[x for x in c] it should work fine for your sample.", "user_id": "None"}, {"stack_answer_id": "4694575", "stack_answer_comment_id": "40305748", "comment_content": "First, ", "user_id": "None"}, {"stack_answer_id": "4694575", "stack_answer_comment_id": "40313909", "comment_content": "Ha! The way your comment got formatted on my computer, I didn't even realize that was supposed to be Apple II as it appeared on the old computers. In any case, my answer to both your questions is that this exercise--for me--is merely an experiment to find a creative solution to flattening a list. I'm not sure I would generalize it to flattening every list out there.", "user_id": "None"}, {"stack_answer_id": "4694575", "stack_answer_comment_id": "95431251", "comment_content": "You just need to ", "user_id": "None"}]}, {"stack_answer_id": "17868434", "answer_content": "\r\n It was fun trying to create a function that could flatten irregular list in Python, but of course that is what Python is for (to make programming fun). The following generator works fairly well with some caveats: \n\n def flatten(iterable):\n    try:\n        for item in iterable:\n            yield from flatten(item)\n    except TypeError:\n        yield iterable\n \n\n It will flatten datatypes that you might want left alone (like  bytearray ,  bytes , and  str  objects). Also, the code relies on the fact that requesting an iterator from a non-iterable raises a  TypeError . \n\n >>> L = [[[1, 2, 3], [4, 5]], 6]\n>>> def flatten(iterable):\n    try:\n        for item in iterable:\n            yield from flatten(item)\n    except TypeError:\n        yield iterable\n\n\n>>> list(flatten(L))\n[1, 2, 3, 4, 5, 6]\n>>>\n \n\n \n\n Edit: \n\n I disagree with the previous implementation. The problem is that you should not be able to flatten something that is not an iterable. It is confusing and gives the wrong impression of the argument. \n\n >>> list(flatten(123))\n[123]\n>>>\n \n\n The following generator is almost the same as the first but does not have the problem of trying to flatten a non-iterable object. It fails as one would expect when an inappropriate argument is given to it. \n\n def flatten(iterable):\n    for item in iterable:\n        try:\n            yield from flatten(item)\n        except TypeError:\n            yield item\n \n\n Testing the generator works fine with the list that was provided. However, the new code will raise a  TypeError  when a non-iterable object is given to it. Example are shown below of the new behavior. \n\n >>> L = [[[1, 2, 3], [4, 5]], 6]\n>>> list(flatten(L))\n[1, 2, 3, 4, 5, 6]\n>>> list(flatten(123))\nTraceback (most recent call last):\n  File \"<pyshell#32>\", line 1, in <module>\n    list(flatten(123))\n  File \"<pyshell#27>\", line 2, in flatten\n    for item in iterable:\nTypeError: 'int' object is not iterable\n>>>\n \n    ", "date_posted": "2014-08-28 13:51:28Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "216356", "name": "Noctis Skytower", "reputation_score": "20.6k"}, "answer_comments": []}, {"stack_answer_id": "45390129", "answer_content": "\r\n You could use  deepflatten  from the 3rd party package  iteration_utilities : \n\n >>> from iteration_utilities import deepflatten\n>>> L = [[[1, 2, 3], [4, 5]], 6]\n>>> list(deepflatten(L))\n[1, 2, 3, 4, 5, 6]\n\n>>> list(deepflatten(L, types=list))  # only flatten \"inner\" lists\n[1, 2, 3, 4, 5, 6]\n \n\n It's an iterator so you need to iterate it (for example by wrapping it with  list  or using it in a loop). Internally it uses an iterative approach instead of an recursive approach and it's written as C extension so it can be faster than pure python approaches: \n\n >>> %timeit list(deepflatten(L))\n12.6 \u00b5s \u00b1 298 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n>>> %timeit list(deepflatten(L, types=list))\n8.7 \u00b5s \u00b1 139 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n\n>>> %timeit list(flatten(L))   # Cristian - Python 3.x approach from https://stackoverflow.com/a/2158532/5393381\n86.4 \u00b5s \u00b1 4.42 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\n\n>>> %timeit list(flatten(L))   # Josh Lee - https://stackoverflow.com/a/2158522/5393381\n107 \u00b5s \u00b1 2.99 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\n\n>>> %timeit list(genflat(L, list))  # Alex Martelli - https://stackoverflow.com/a/2159079/5393381\n23.1 \u00b5s \u00b1 710 ns per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\n \n\n \n\n I'm the author of the  iteration_utilities  library. \n    ", "date_posted": "2017-07-29 14:01:42Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "5393381", "name": "MSeifert", "reputation_score": "136k"}, "answer_comments": []}, {"stack_answer_id": "20495215", "answer_content": "\r\n Here's a simple function that flattens lists of arbitrary depth. No recursion, to avoid stack overflow. \n\n from copy import deepcopy\n\ndef flatten_list(nested_list):\n    \"\"\"Flatten an arbitrarily nested list, without recursion (to avoid\n    stack overflows). Returns a new list, the original list is unchanged.\n\n    >> list(flatten_list([1, 2, 3, [4], [], [[[[[[[[[5]]]]]]]]]]))\n    [1, 2, 3, 4, 5]\n    >> list(flatten_list([[1, 2], 3]))\n    [1, 2, 3]\n\n    \"\"\"\n    nested_list = deepcopy(nested_list)\n\n    while nested_list:\n        sublist = nested_list.pop(0)\n\n        if isinstance(sublist, list):\n            nested_list = sublist + nested_list\n        else:\n            yield sublist\n \n    ", "date_posted": "2013-12-10 14:55:11Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "509706", "name": "Wilfred Hughes", "reputation_score": "28.2k"}, "answer_comments": [{"stack_answer_id": "20495215", "stack_answer_comment_id": "95431976", "comment_content": "Yes! Very similar to my code at ", "user_id": "None"}, {"stack_answer_id": "20495215", "stack_answer_comment_id": "127199352", "comment_content": "This could be made much more efficient by using ", "user_id": "None"}]}, {"stack_answer_id": "64517529", "answer_content": "\r\n Pandas has a function that does this. It returns an iterator as you mentioned. \n In [1]: import pandas\nIn [2]: pandas.core.common.flatten([[[1, 2, 3], [4, 5]], 6])\nOut[2]: <generator object flatten at 0x7f12ade66200>\nIn [3]: list(pandas.core.common.flatten([[[1, 2, 3], [4, 5]], 6]))\nOut[3]: [1, 2, 3, 4, 5, 6]\n \n    ", "date_posted": "2020-10-24 20:03:15Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "116", "name": "Mark Harrison", "reputation_score": "287k"}, "answer_comments": [{"stack_answer_id": "64517529", "stack_answer_comment_id": "116168058", "comment_content": "Great stuff! For people (like me) who are using pandas anyway, this is a beautifully simple way", "user_id": "None"}]}, {"stack_answer_id": "5226060", "answer_content": "\r\n Although an elegant and very pythonic answer has been selected I would present my solution just for the review: \n\n def flat(l):\n    ret = []\n    for i in l:\n        if isinstance(i, list) or isinstance(i, tuple):\n            ret.extend(flat(i))\n        else:\n            ret.append(i)\n    return ret\n \n\n Please tell how good or bad this code is? \n    ", "date_posted": "2011-03-07 22:32:07Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "69746", "name": "Xolve", "reputation_score": "21.3k"}, "answer_comments": [{"stack_answer_id": "5226060", "stack_answer_comment_id": "25450076", "comment_content": "Use ", "user_id": "None"}, {"stack_answer_id": "5226060", "stack_answer_comment_id": "35343653", "comment_content": " will get you the same container type back as was passed in, also. :)", "user_id": "None"}, {"stack_answer_id": "5226060", "stack_answer_comment_id": "35429281", "comment_content": "@dash-tom-bang Can you please explain what it means in a bit detail.", "user_id": "None"}, {"stack_answer_id": "5226060", "stack_answer_comment_id": "37392303", "comment_content": "If you pass in a list, you probably want a list back. If you pass in a tuple, you probably want a tuple back. If you pass in a mishmash of the two, you'll get whatever the outer enclosing thing was.", "user_id": "None"}]}, {"stack_answer_id": "4676482", "answer_content": "\r\n I prefer simple answers.  No generators.  No recursion or recursion limits.  Just iteration: \n\n def flatten(TheList):\n    listIsNested = True\n\n    while listIsNested:                 #outer loop\n        keepChecking = False\n        Temp = []\n\n        for element in TheList:         #inner loop\n            if isinstance(element,list):\n                Temp.extend(element)\n                keepChecking = True\n            else:\n                Temp.append(element)\n\n        listIsNested = keepChecking     #determine if outer loop exits\n        TheList = Temp[:]\n\n    return TheList\n \n\n This works with two lists: an inner for loop and an outer while loop.   \n\n The inner for loop iterates through the list.  If it finds a list element, it (1) uses list.extend() to flatten that part one level of nesting and (2) switches keepChecking to True.  keepchecking is used to control the outer while loop.  If the outer loop gets set to true, it triggers the inner loop for another pass.   \n\n Those passes keep happening until no more nested lists are found.  When a pass finally occurs where none are found, keepChecking never gets tripped to true, which means listIsNested stays false and the outer while loop exits.   \n\n The flattened list is then returned. \n\n Test-run    \n\n flatten([1,2,3,4,[100,200,300,[1000,2000,3000]]])\n \n\n [1, 2, 3, 4, 100, 200, 300, 1000, 2000, 3000] \n    ", "date_posted": "2011-01-13 04:16:53Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "392301", "name": "clay", "reputation_score": "1,677"}, "answer_comments": [{"stack_answer_id": "4676482", "stack_answer_comment_id": "5159157", "comment_content": "I like simple too.  In this case though, you iterate over the list as many times as there are nestings or levels.  Could get expensive.", "user_id": "215679"}, {"stack_answer_id": "4676482", "stack_answer_comment_id": "5176210", "comment_content": "@telliott99: You're right if your lists are really big and/or nested to great depths.  However, if that isn't the case, then the simpler solution works just as well, and without the deep magic of some of the other answers.  There is a place for multi-stage recursive generator comprehensions, but I'm not convinced that should be where you look first.  (I guess you know where I fall in the \"Worse is Better\" debate.)", "user_id": "None"}, {"stack_answer_id": "4676482", "stack_answer_comment_id": "5176316", "comment_content": "@telliott99: Or to put that another way, you won't have to \"try to Grok\" my solution.  If performance isn't a bottleneck, what matters most to you as a programmer?", "user_id": "None"}, {"stack_answer_id": "4676482", "stack_answer_comment_id": "35343606", "comment_content": "Simpler solutions have less logic. Recursion is a pretty fundamental programming construct that anyone who considers themselves a programmer should be completely comfortable with. Generators are very much the Python Way and (along with comprehensions) are something that any professional Python programmer should grok instantly.", "user_id": "None"}, {"stack_answer_id": "4676482", "stack_answer_comment_id": "35348551", "comment_content": "I agree about recursion. When I wrote my answer, python still broke recursion at 1000 cycles. Have they changed this? As for being a professional python programmer, I'm not. Moreover, I imagine many people programming in python do not do so full time.", "user_id": "None"}]}, {"stack_answer_id": "51649649", "answer_content": "\r\n When trying to answer such a question you really need to give the limitations of the code you propose as a solution. If it was only about performances I wouldn't mind too much, but most of the codes proposed as solution (including the accepted answer) fail to flatten any list that has a depth greater than 1000. \n\n When I say  most of the codes  I mean all codes that use any form of recursion (or call a standard library function that is recursive). All these codes fail because for every of the recursive call made, the (call) stack grow by one unit, and the (default) python call stack has a size of 1000.  \n\n If you're not too familiar with the call stack, then maybe the following will help (otherwise you can just scroll to the  Implementation ). \n\n Call stack size and recursive programming (dungeon analogy) \n\n Finding the treasure and exit \n\n Imagine you enter a huge  dungeon with numbered rooms , looking for a treasure. You don't know the place but you have some  indications  on how to find the treasure. Each indication is a riddle (difficulty varies, but you can't predict how hard they will be). You decide to think a little bit about a strategy to save time, you make two observations:  \n\n \n It's hard (long) to find the treasure as you'll have to solve (potentially hard) riddles to get there.  \n Once the treasure found, returning to the entrance may be easy, you just have to use the same path in the other direction (though this needs a bit of memory to recall your path).  \n \n\n When entering the dungeon, you notice a small  notebook  here. You decide to use it to write down every room you exit after solving a riddle (when entering a new room), this way you'll be able to return back to the entrance. That's a genius idea, you  won't even spend a cent  implementing your strategy. \n\n You enter the dungeon, solving with great success the first 1001 riddles, but here comes something you hadn't planed, you have no space left in the notebook you borrowed. You decide to  abandon  your quest as you prefer not having the treasure than being lost forever inside the dungeon (that looks smart indeed). \n\n Executing a recursive program \n\n Basically, it's the exact same thing as finding the treasure. The dungeon is the  computer's memory , your goal now is not to find a treasure but to  compute some function  (find  f(x)  for a given  x ). The indications simply are sub-routines that will help you solving  f(x) . Your strategy is the same as the  call stack  strategy, the notebook is the stack, the rooms are the functions' return addresses:  \n\n x = [\"over here\", \"am\", \"I\"]\ny = sorted(x) # You're about to enter a room named `sorted`, note down the current room address here so you can return back: 0x4004f4 (that room address looks weird)\n# Seems like you went back from your quest using the return address 0x4004f4\n# Let's see what you've collected \nprint(' '.join(y))\n \n\n The problem you encountered in the dungeon will be the same here, the call stack has a finite size (here 1000) and therefore, if you enter too many functions without returning back then you'll fill the call stack and have an error that look like  \"Dear adventurer, I'm very sorry but your notebook is full\" :  RecursionError: maximum recursion depth exceeded . Note that you don't need recursion to fill the call stack, but it's very unlikely that a non-recursive program call 1000 functions without ever returning. It's important to also understand that once you returned from a function, the call stack is freed from the address used (hence the name \"stack\", return address are pushed in before entering a function and pulled out when returning). In the special case of a simple recursion (a function  f  that call itself once -- over and over --) you will enter  f  over and over until the computation is finished (until the treasure is found) and return from  f  until you go back to the place where you called  f  in the first place. The call stack will never be freed from anything until the end where it will be freed from all return addresses one after the other.  \n\n How to avoid this issue? \n\n That's actually pretty simple: \"don't use recursion if you don't know how deep it can go\". That's not always true as in some cases,  Tail Call recursion can be Optimized (TCO) . But in python, this is not the case, and even \"well written\" recursive function will  not  optimize stack use. There is an interesting post from Guido about this question:  Tail Recursion Elimination . \n\n There is a technique that you can use to make any recursive function iterative, this technique we could call  bring your own notebook . For example, in our particular case we simply are exploring a list, entering a room is equivalent to entering a sublist, the question you should ask yourself is  how can I get back from a list to its parent list?  The answer is not that complex, repeat the following until the  stack  is empty: \n\n \n push the current list  address  and  index  in a  stack  when entering a new sublist (note that a list address+index is also an address, therefore we just use the exact same technique used by the call stack); \n every time an item is found,  yield  it (or add them in a list); \n once a list is fully explored, go back to the parent list using the  stack   return  address  (and  index ) . \n \n\n Also note that this is equivalent to a DFS in a tree where some nodes are sublists  A = [1, 2]  and some are simple items:  0, 1, 2, 3, 4  (for  L = [0, [1,2], 3, 4] ). The tree looks like this: \n\n                     L\n                    |\n           -------------------\n           |     |     |     |\n           0   --A--   3     4\n               |   |\n               1   2\n \n\n The DFS traversal pre-order is: L, 0, A, 1, 2, 3, 4. Remember, in order to implement an iterative DFS you also \"need\" a stack. The implementation I proposed before result in having the following states (for the  stack  and the  flat_list ):  \n\n init.:  stack=[(L, 0)]\n**0**:  stack=[(L, 0)],         flat_list=[0]\n**A**:  stack=[(L, 1), (A, 0)], flat_list=[0]\n**1**:  stack=[(L, 1), (A, 0)], flat_list=[0, 1]\n**2**:  stack=[(L, 1), (A, 1)], flat_list=[0, 1, 2]\n**3**:  stack=[(L, 2)],         flat_list=[0, 1, 2, 3]\n**3**:  stack=[(L, 3)],         flat_list=[0, 1, 2, 3, 4]\nreturn: stack=[],               flat_list=[0, 1, 2, 3, 4]\n \n\n In this example, the stack maximum size is 2, because the input list (and therefore the tree) have depth 2. \n\n Implementation \n\n For the implementation, in python you can simplify a little bit by using iterators instead of simple lists. References to the (sub)iterators will be used to store  sublists return addresses  (instead of having both the list address and the index). This is not a big difference but I feel this is more readable (and also a bit faster): \n\n def flatten(iterable):\n    return list(items_from(iterable))\n\ndef items_from(iterable):\n    cursor_stack = [iter(iterable)]\n    while cursor_stack:\n        sub_iterable = cursor_stack[-1]\n        try:\n            item = next(sub_iterable)\n        except StopIteration:   # post-order\n            cursor_stack.pop()\n            continue\n        if is_list_like(item):  # pre-order\n            cursor_stack.append(iter(item))\n        elif item is not None:\n            yield item          # in-order\n\ndef is_list_like(item):\n    return isinstance(item, list)\n \n\n Also, notice that in  is_list_like  I have  isinstance(item, list) , which could be changed to handle more input types, here I just wanted to have the simplest version where (iterable) is just a list. But you could also do that: \n\n def is_list_like(item):\n    try:\n        iter(item)\n        return not isinstance(item, str)  # strings are not lists (hmm...) \n    except TypeError:\n        return False\n \n\n This considers strings as \"simple items\" and therefore  flatten_iter([[\"test\", \"a\"], \"b])  will return  [\"test\", \"a\", \"b\"]  and not  [\"t\", \"e\", \"s\", \"t\", \"a\", \"b\"] . Remark that in that case,  iter(item)  is called twice on each item, let's pretend it's an exercise for the reader to make this cleaner.  \n\n Testing and remarks on other implementations \n\n In the end, remember that you can't print a infinitely nested list  L  using  print(L)  because internally it will use recursive calls to  __repr__  ( RecursionError: maximum recursion depth exceeded while getting the repr of an object ). For the same reason, solutions to  flatten  involving  str  will fail with the same error message.  \n\n If you need to test your solution, you can use this function to generate a simple nested list: \n\n def build_deep_list(depth):\n    \"\"\"Returns a list of the form $l_{depth} = [depth-1, l_{depth-1}]$\n    with $depth > 1$ and $l_0 = [0]$.\n    \"\"\"\n    sub_list = [0]\n    for d in range(1, depth):\n        sub_list = [d, sub_list]\n    return sub_list\n \n\n Which gives:  build_deep_list(5)  >>>  [4, [3, [2, [1, [0]]]]] . \n    ", "date_posted": "2018-08-02 10:30:05Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "1720199", "name": "cglacet", "reputation_score": "7,038"}, "answer_comments": []}, {"stack_answer_id": "36500762", "answer_content": "\r\n I didn't go through all the already available answers here, but here is a one liner I came up with, borrowing from lisp's way of first and rest list processing \n def flatten(l): return flatten(l[0]) + (flatten(l[1:]) if len(l) > 1 else []) if type(l) is list else [l]\n \n here is one simple and one not-so-simple case - \n >>> flatten([1,[2,3],4])\n[1, 2, 3, 4]\n\n>>> flatten([1, [2, 3], 4, [5, [6, {'name': 'some_name', 'age':30}, 7]], [8, 9, [10, [11, [12, [13, {'some', 'set'}, 14, [15, 'some_string'], 16], 17, 18], 19], 20], 21, 22, [23, 24], 25], 26, 27, 28, 29, 30])\n[1, 2, 3, 4, 5, 6, {'age': 30, 'name': 'some_name'}, 7, 8, 9, 10, 11, 12, 13, set(['set', 'some']), 14, 15, 'some_string', 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n>>> \n \n    ", "date_posted": "2021-06-16 03:10:18Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "3098229", "name": "Shreyas", "reputation_score": "1,204"}, "answer_comments": [{"stack_answer_id": "36500762", "stack_answer_comment_id": "83335636", "comment_content": "It's not a one liner.  No matter how much you attempt to fit it into one, the ", "user_id": "None"}, {"stack_answer_id": "36500762", "stack_answer_comment_id": "84252901", "comment_content": "I've de-one-line-ified the code, and did some further refactoring. (edit is pending peer review as I write this) This particular method seemed very readable to me, though the original code did need some refactoring.", "user_id": "None"}, {"stack_answer_id": "36500762", "stack_answer_comment_id": "120182087", "comment_content": "Please do not edit the answer. If you feel the need to \"refactor\", feel free to post as your own answer. There is a reason why the code is presented the way it is. It is to emphasise that the approach came from lisp. You can plain ignore the \"one-liner\" part of it - it was not intended as some kind of boasting. It was, again, to indicate that the thought behind it is still \"one-liner\": that of first and rest list processing.", "user_id": "None"}]}, {"stack_answer_id": "18466318", "answer_content": "\r\n Here's the  compiler.ast.flatten  implementation in 2.7.5: \n\n def flatten(seq):\n    l = []\n    for elt in seq:\n        t = type(elt)\n        if t is tuple or t is list:\n            for elt2 in flatten(elt):\n                l.append(elt2)\n        else:\n            l.append(elt)\n    return l\n \n\n There are better, faster methods (If you've reached here, you have seen them already) \n\n Also note: \n\n \n   Deprecated since version 2.6: The compiler package has been removed in Python 3. \n \n    ", "date_posted": "2013-08-27 13:05:57Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "1931274", "name": "pradyunsg", "reputation_score": "16.9k"}, "answer_comments": []}, {"stack_answer_id": "23918614", "answer_content": "\r\n totally hacky but I think it would work (depending on your data_type) \n\n flat_list = ast.literal_eval(\"[%s]\"%re.sub(\"[\\[\\]]\",\"\",str(the_list)))\n \n    ", "date_posted": "2014-05-28 17:54:20Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "541038", "name": "Joran Beasley", "reputation_score": "104k"}, "answer_comments": []}, {"stack_answer_id": "33705609", "answer_content": "\r\n I'm surprised no one has thought of this. Damn recursion I don't get the recursive answers that the advanced people here made. anyway here is my attempt on this. caveat is it's very specific to the OP's use case \n\n import re\n\nL = [[[1, 2, 3], [4, 5]], 6]\nflattened_list = re.sub(\"[\\[\\]]\", \"\", str(L)).replace(\" \", \"\").split(\",\")\nnew_list = list(map(int, flattened_list))\nprint(new_list)\n \n\n output: \n\n [1, 2, 3, 4, 5, 6]\n \n    ", "date_posted": "2015-11-14 06:28:45Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "5166790", "name": "Zion", "reputation_score": "1,480"}, "answer_comments": [{"stack_answer_id": "33705609", "stack_answer_comment_id": "113752265", "comment_content": "this only works for types (like int) which are convertible to string and back. something with the complexity of regular expressions is also not needed to tackle such a simple problem. If you want a simple solution, pradyunsg's is best.", "user_id": "None"}]}, {"stack_answer_id": "55305409", "answer_content": "\r\n Just use a  funcy  library:\n pip install funcy \n\n import funcy\n\n\nfuncy.flatten([[[[1, 1], 1], 2], 3]) # returns generator\nfuncy.lflatten([[[[1, 1], 1], 2], 3]) # returns list\n \n    ", "date_posted": "2019-05-23 13:32:02Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "55305409", "stack_answer_comment_id": "99167172", "comment_content": "FYI: it uses recursive solution: ", "user_id": "None"}]}, {"stack_answer_id": "36412443", "answer_content": "\r\n I am a dumb guy so I'll give a \"dumb\" solution. All that recursion hurts my brain. \n\n flattened_list = []\nnested_list = [[[1, 2, 3], [4, 5]], 6]\n\ndef flatten(nested_list, container):\n    for item in nested_list:\n        if isintance(item, list):\n            flatten(item, container)\n        else:\n            container.append(item)\n\n>>> flatten(nested_list, flattened_list)\n>>> flattened_list\n[1, 2, 3, 4, 5, 6]\n \n\n I get that it's using a side effect but well that's to the best of my comprehension of recursion can go \n    ", "date_posted": "2019-09-04 11:12:13Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "1879728", "name": "vlz", "reputation_score": "836"}, "answer_comments": []}, {"stack_answer_id": "7037726", "answer_content": "\r\n I don't see anything like this posted around here and just got here from a closed question on the same subject, but why not just do something like this(if you know the type of the list you want to split): \n\n >>> a = [1, 2, 3, 5, 10, [1, 25, 11, [1, 0]]]    \n>>> g = str(a).replace('[', '').replace(']', '')    \n>>> b = [int(x) for x in g.split(',') if x.strip()]\n \n\n You would need to know the type of the elements but I think this can be generalised and in terms of speed I think it would be faster. \n    ", "date_posted": "2013-07-25 17:36:51Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "977038", "name": "Abhijit", "reputation_score": "59.7k"}, "answer_comments": [{"stack_answer_id": "7037726", "stack_answer_comment_id": "14305819", "comment_content": "This is clever (and probably fast)... but it's not very pythonic.", "user_id": "None"}, {"stack_answer_id": "7037726", "stack_answer_comment_id": "16146250", "comment_content": "\"why not just do something like this\"  you say? Because it is very easy to break! Very bad idea. One example, what if your items are strings, not ints? Then if a string contains a '[' you are doomed. And what if your items have no good (or very long) string representation?", "user_id": "None"}, {"stack_answer_id": "7037726", "stack_answer_comment_id": "55183752", "comment_content": "@gb. Well what if this was what the op needed? and the example was clearly a list of ", "user_id": "None"}, {"stack_answer_id": "7037726", "stack_answer_comment_id": "55235168", "comment_content": "Well sorry, \"what ifs\" apply, careful considerations of all \"what ifs\" is the blood and guts of programming.", "user_id": "None"}]}, {"stack_answer_id": "25353058", "answer_content": "\r\n Here is another py2 approach, Im not sure if its the fastest or the most elegant nor safest ... \n\n from collections import Iterable\nfrom itertools import imap, repeat, chain\n\n\ndef flat(seqs, ignore=(int, long, float, basestring)):\n    return repeat(seqs, 1) if any(imap(isinstance, repeat(seqs), ignore)) or not isinstance(seqs, Iterable) else chain.from_iterable(imap(flat, seqs))\n \n\n It can ignore any specific (or derived) type you would like, it returns an iterator, so you can convert it to any specific container such as list, tuple, dict or simply consume it in order to reduce memory footprint, for better or worse it can handle initial non-iterable objects such as int ... \n\n Note most of the heavy lifting is done in C, since as far as I know thats how itertools are implemented, so while it is recursive, AFAIK it isn't bounded by python recursion depth since the function calls are happening in C, though this doesn't mean you are bounded by memory, specially in OS X where its stack size has a hard limit as of today (OS X Mavericks) ... \n\n there is a slightly faster approach, but less portable method, only use it if you can assume that the base elements of the input can be explicitly determined otherwise, you'll get an infinite recursion, and OS X with its limited stack size, will throw a segmentation fault fairly quickly ... \n\n def flat(seqs, ignore={int, long, float, str, unicode}):\n    return repeat(seqs, 1) if type(seqs) in ignore or not isinstance(seqs, Iterable) else chain.from_iterable(imap(flat, seqs))\n \n\n here we are using sets to check for the type so it takes O(1) vs O(number of types) to check whether or not an element should be ignored, though of course any value with derived type of the stated ignored types will fail, this is why its using  str ,  unicode  so use it with caution ... \n\n tests: \n\n import random\n\ndef test_flat(test_size=2000):\n    def increase_depth(value, depth=1):\n        for func in xrange(depth):\n            value = repeat(value, 1)\n        return value\n\n    def random_sub_chaining(nested_values):\n        for values in nested_values:\n            yield chain((values,), chain.from_iterable(imap(next, repeat(nested_values, random.randint(1, 10)))))\n\n    expected_values = zip(xrange(test_size), imap(str, xrange(test_size)))\n    nested_values = random_sub_chaining((increase_depth(value, depth) for depth, value in enumerate(expected_values)))\n    assert not any(imap(cmp, chain.from_iterable(expected_values), flat(chain(((),), nested_values, ((),)))))\n\n>>> test_flat()\n>>> list(flat([[[1, 2, 3], [4, 5]], 6]))\n[1, 2, 3, 4, 5, 6]\n>>>  \n\n$ uname -a\nDarwin Samys-MacBook-Pro.local 13.3.0 Darwin Kernel Version 13.3.0: Tue Jun  3 21:27:35 PDT 2014; root:xnu-2422.110.17~1/RELEASE_X86_64 x86_64\n$ python --version\nPython 2.7.5\n \n    ", "date_posted": "2014-08-18 16:14:38Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "1445740", "name": "Samy Vilar", "reputation_score": "10.2k"}, "answer_comments": []}, {"stack_answer_id": "27340134", "answer_content": "\r\n Without using any library: \n\n def flat(l):\n    def _flat(l, r):    \n        if type(l) is not list:\n            r.append(l)\n        else:\n            for i in l:\n                r = r + flat(i)\n        return r\n    return _flat(l, [])\n\n\n\n# example\ntest = [[1], [[2]], [3], [['a','b','c'] , [['z','x','y']], ['d','f','g']], 4]    \nprint flat(test) # prints [1, 2, 3, 'a', 'b', 'c', 'z', 'x', 'y', 'd', 'f', 'g', 4]\n \n    ", "date_posted": "2014-12-07 17:58:00Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "1057429", "name": "Nir Alfasi", "reputation_score": "52.1k"}, "answer_comments": []}, {"stack_answer_id": "28756609", "answer_content": "\r\n Using  itertools.chain : \n\n import itertools\nfrom collections import Iterable\n\ndef list_flatten(lst):\n    flat_lst = []\n    for item in itertools.chain(lst):\n        if isinstance(item, Iterable):\n            item = list_flatten(item)\n            flat_lst.extend(item)\n        else:\n            flat_lst.append(item)\n    return flat_lst\n \n\n Or without chaining: \n\n def flatten(q, final):\n    if not q:\n        return\n    if isinstance(q, list):\n        if not isinstance(q[0], list):\n            final.append(q[0])\n        else:\n            flatten(q[0], final)\n        flatten(q[1:], final)\n    else:\n        final.append(q)\n \n    ", "date_posted": "2015-05-09 22:04:16Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "4596008", "name": "Saksham Varma", "reputation_score": "2,072"}, "answer_comments": []}, {"stack_answer_id": "26130883", "answer_content": "\r\n I used recursive to solve  nested list with any depth \n\n def combine_nlist(nlist,init=0,combiner=lambda x,y: x+y):\n    '''\n    apply function: combiner to a nested list element by element(treated as flatten list)\n    '''\n    current_value=init\n    for each_item in nlist:\n        if isinstance(each_item,list):\n            current_value =combine_nlist(each_item,current_value,combiner)\n        else:\n            current_value = combiner(current_value,each_item)\n    return current_value\n \n\n So after i define function combine_nlist, it is easy to use this function do flatting. Or you can combine it into one function. I like my solution because it can be applied to any nested list. \n\n def flatten_nlist(nlist):\n    return combine_nlist(nlist,[],lambda x,y:x+[y])\n \n\n result \n\n In [379]: flatten_nlist([1,2,3,[4,5],[6],[[[7],8],9],10])\nOut[379]: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n \n    ", "date_posted": "2015-08-09 11:13:41Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "2169114", "name": "Alex Lisovoy", "reputation_score": "5,357"}, "answer_comments": [{"stack_answer_id": "26130883", "stack_answer_comment_id": "90241387", "comment_content": "\"nested list with any depth\" not true. Just try you'll see:  ", "user_id": "None"}, {"stack_answer_id": "26130883", "stack_answer_comment_id": "90247735", "comment_content": "hmmm I are you trying to flaten list with more than 1000 layers?", "user_id": "None"}, {"stack_answer_id": "26130883", "stack_answer_comment_id": "90257853", "comment_content": "Of course, that's the whole point of the discussion about recursive vs. iterative solutions. If you know in advance that the number of layers is < than 1000 then the most simple solution will work. When you say \"any depth\" this includes list with depth > 1000.", "user_id": "None"}]}, {"stack_answer_id": "34298369", "answer_content": "\r\n The easiest way is to use the  morph  library using  pip install morph . \n\n The code is: \n\n import morph\n\nlist = [[[1, 2, 3], [4, 5]], 6]\nflattened_list = morph.flatten(list)  # returns [1, 2, 3, 4, 5, 6]\n \n    ", "date_posted": "2015-12-15 20:03:50Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "2532070", "name": "YPCrumble", "reputation_score": "24.4k"}, "answer_comments": []}, {"stack_answer_id": "39835505", "answer_content": "\r\n I am aware that there are already many awesome answers but i wanted to add an answer that uses the functional programming method of solving the question. In this answer i make use of double recursion : \n\n def flatten_list(seq):\n    if not seq:\n        return []\n    elif isinstance(seq[0],list):\n        return (flatten_list(seq[0])+flatten_list(seq[1:]))\n    else:\n        return [seq[0]]+flatten_list(seq[1:])\n\nprint(flatten_list([1,2,[3,[4],5],[6,7]]))\n \n\n output: \n\n [1, 2, 3, 4, 5, 6, 7]\n \n    ", "date_posted": "2016-10-03 15:46:27Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "6797779", "name": "Leo wahyd", "reputation_score": "197"}, "answer_comments": []}, {"stack_answer_id": "43948658", "answer_content": "\r\n I'm not sure if this is necessarily quicker or more effective, but this is what I do: \n\n def flatten(lst):\n    return eval('[' + str(lst).replace('[', '').replace(']', '') + ']')\n\nL = [[[1, 2, 3], [4, 5]], 6]\nprint(flatten(L))\n \n\n The  flatten  function here turns the list into a string, takes out  all  of the square brackets, attaches square brackets back onto the ends, and turns it back into a list.  \n\n Although, if you knew you would have square brackets in your list in strings, like  [[1, 2], \"[3, 4] and [5]\"] , you would have to do something else. \n    ", "date_posted": "2017-05-13 02:32:08Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "3571147", "name": "diligar", "reputation_score": "393"}, "answer_comments": [{"stack_answer_id": "43948658", "stack_answer_comment_id": "90257931", "comment_content": "This has no advantage over the simple solution as this fails to process deep lists, ie \"RecursionError: maximum recursion depth exceeded while getting the repr of an object\".", "user_id": "None"}]}, {"stack_answer_id": "53523266", "answer_content": "\r\n This is a simple implement of flatten on python2 \n\n flatten=lambda l: reduce(lambda x,y:x+y,map(flatten,l),[]) if isinstance(l,list) else [l]\n\ntest=[[1,2,3,[3,4,5],[6,7,[8,9,[10,[11,[12,13,14]]]]]],]\nprint flatten(test)\n\n#output [1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n \n    ", "date_posted": "2018-11-28 15:48:09Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "5918696", "name": "Statham", "reputation_score": "3,818"}, "answer_comments": []}], "user": {"stack_user_id": "215679", "name": "telliott99", "reputation_score": "7,374"}, "question_comments": [{"stack_question_id": "2158395", "stack_question_comment_id": "34197359", "comment_content": "The fact that there are this many answers and so much action on this question really suggests that this should be a built-in function somewhere, right?  It's especially too bad the compiler.ast was removed from Python 3.0", "user_id": "None"}, {"stack_question_id": "2158395", "stack_question_comment_id": "47164204", "comment_content": "I would say that what Python really needs is unbroken recursion rather than another builtin.", "user_id": "None"}, {"stack_question_id": "2158395", "stack_question_comment_id": "99158509", "comment_content": "@Mittenchops: totally disagree, the fact that people working with obviously bad APIs/overly complicated data structures (just a note: ", "user_id": "None"}, {"stack_question_id": "2158395", "stack_question_comment_id": "107119718", "comment_content": "If you can afford adding a package to your project - I suppose the ", "user_id": "None"}, {"stack_question_id": "2158395", "stack_question_comment_id": "116850410", "comment_content": "@viddik13: please consider making that an answer for this question, as well.  It would absolutely get my upvote.  (I agree with Mittenchops.)  The fact that it's not a ", "user_id": "None"}]},
{"stack_question_id": "1832940", "question_title": "Why is using 'eval' a bad practice?", "question_content": "\r\n                I use the following class to easily store data of my songs.\nclass Song:\n    \"\"\"The class to store the details of each song\"\"\"\n    attsToStore=('Name', 'Artist', 'Album', '...\r\n", "question_url": "/questions/1832940/why-is-using-eval-a-bad-practice", "date_posted": "Dec 2, 2009 at 13:34", "upvote": "1", "view": "6", "tags": ["python", "eval"], "answers_count": "8", "answers": [{"stack_answer_id": "1832957", "answer_content": "\r\n Yes, using  eval  is a bad practice. Just to name a few reasons: \n \n There is almost always a better way to do it \n Very dangerous and insecure \n Makes debugging difficult \n Slow \n \n In your case you can use  setattr  instead: \n class Song:\n    \"\"\"The class to store the details of each song\"\"\"\n    attsToStore=('Name', 'Artist', 'Album', 'Genre', 'Location')\n    def __init__(self):\n        for att in self.attsToStore:\n            setattr(self, att.lower(), None)\n    def setDetail(self, key, val):\n        if key in self.attsToStore:\n            setattr(self, key.lower(), val)\n \n There are some cases where you have to use  eval  or  exec . But they are rare. Using  eval  in your case is a bad practice for sure. I'm emphasizing on bad practice because  eval  and  exec  are frequently used in the wrong place. \n Replying to the comments: \n It looks like some disagree that  eval  is 'very dangerous and insecure' in the OP case. That might be true for this specific case but not in general. The question was general and the reasons I listed are true for the general case as well. \n    ", "date_posted": "2021-02-18 10:22:36Z", "upvote": "\r\n            229\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "1832957", "stack_answer_comment_id": "1725807", "comment_content": "-1: \"Very dangerous and insecure\" is false.  The other three are outstandingly clear.  Please reorder them so that 2 and 4 are the first two.  It's only insecure if you are surrounded by evil sociopaths who are looking for ways to subvert your application.", "user_id": "None"}, {"stack_answer_id": "1832957", "stack_answer_comment_id": "1726183", "comment_content": "@S.Lott, Insecurity is a very important reason to avoid eval/exec in general. Many applications like websites should take extra care. Take the OP example in a website that expects users to enter the song name. It is bound to be exploited sooner or later. Even an innocent input like: Let's have fun. will cause a syntax error and expose the vulnerability.", "user_id": "None"}, {"stack_answer_id": "1832957", "stack_answer_comment_id": "1726811", "comment_content": "@Nadia Alramli: User input and ", "user_id": "None"}, {"stack_answer_id": "1832957", "stack_answer_comment_id": "3268287", "comment_content": "@jeffjose: Actually, ", "user_id": "None"}, {"stack_answer_id": "1832957", "stack_answer_comment_id": "8538640", "comment_content": "I'm not sure why Nadia's assertion is so contentious. It seems simple to me: eval is a vector for code injection, and is dangerous in a way that most other Python functions are not. That doesn't mean you shouldn't use it at all, but I think you should use it judiciously.", "user_id": "None"}]}, {"stack_answer_id": "1834754", "answer_content": "\r\n Using  eval  is weak, not a clearly  bad  practice. \n\n \n It violates the \"Fundamental Principle of Software\".  Your source is not the sum total of what's executable.  In addition to your source, there are the arguments to  eval , which must be clearly understood.  For this reason, it's the tool of last resort. \n It's usually a sign of thoughtless design.  There's rarely a good reason for dynamic source code, built on-the-fly.  Almost anything can be done with delegation and other OO design techniques. \n It leads to relatively slow on-the-fly compilation of small pieces of code.  An overhead which can be avoided by using better design patterns. \n \n\n As a footnote, in the hands of deranged sociopaths, it may not work out well.  However, when confronted with deranged sociopathic users or administrators, it's best to not give them interpreted Python in the first place.  In the hands of the truly evil, Python can a liability;  eval  doesn't increase the risk at all.   \n    ", "date_posted": "2009-12-02 18:08:39Z", "upvote": "\r\n            47\r\n        ", "accepted": "No", "user": {"stack_user_id": "10661", "name": "S.Lott", "reputation_score": "375k"}, "answer_comments": [{"stack_answer_id": "1834754", "stack_answer_comment_id": "8543247", "comment_content": "@Owen S. The point is this.  Folks will tell you that ", "user_id": "None"}, {"stack_answer_id": "1834754", "stack_answer_comment_id": "10920770", "comment_content": "Well, I can tell you exactly why I would say eval is a security vulnerability, and it has to do with the trustworthiness of the string it's given as input. If that string comes, in whole or in part, from the outside world, there's a possibility of a scripting attack on your program if you're not careful. But that's thge derangement of an outside attacker, not of the user or administrator.", "user_id": "None"}, {"stack_answer_id": "1834754", "stack_answer_comment_id": "10921231", "comment_content": "@OwenS.: \"If that string comes, in whole or in part, from the outside world\"  Often false.  This isn't a \"careful\" thing.  It's black and white.  If the text comes from a user, it can ", "user_id": "None"}, {"stack_answer_id": "1834754", "stack_answer_comment_id": "10925199", "comment_content": "@OwenS.: There's no possible escaping for a string of untrusted Python code that would make it trustable.  I agree with most of what you're saying except for the \"careful\" part.  It's a very crisp distinction. Code from the outside world is untrustable.  AFAIK, no amount of escaping or filtering can clean it up.  If you have some kind of escaping function that would make code acceptable, please share.  I didn't think such a thing was possible.  For example ", "user_id": "None"}, {"stack_answer_id": "1834754", "stack_answer_comment_id": "10952344", "comment_content": "@OwenS.: \"intended as a string, not arbitrary code\".  That's unrelated.  That's just a string value, which you would never pass through ", "user_id": "None"}]}, {"stack_answer_id": "37081082", "answer_content": "\r\n Yes, it is: \n\n Hack using Python: \n\n >>> eval(input())\n\"__import__('os').listdir('.')\"\n...........\n...........   #dir listing\n...........\n \n\n The below code will list all tasks running on a Windows machine. \n\n >>> eval(input())\n\"__import__('subprocess').Popen(['tasklist'],stdout=__import__('subprocess').PIPE).communicate()[0]\"\n \n\n In Linux: \n\n >>> eval(input())\n\"__import__('subprocess').Popen(['ps', 'aux'],stdout=__import__('subprocess').PIPE).communicate()[0]\"\n \n    ", "date_posted": "2016-11-21 08:17:22Z", "upvote": "\r\n            26\r\n        ", "accepted": "No", "user": {"stack_user_id": "2294755", "name": "Hackaholic", "reputation_score": "17.9k"}, "answer_comments": [{"stack_answer_id": "37081082", "stack_answer_comment_id": "127060561", "comment_content": "Why is that bad/dangerous? Can't I just execute the same Python code anyway without ", "user_id": "None"}, {"stack_answer_id": "37081082", "stack_answer_comment_id": "127949948", "comment_content": "It is dangerous because it allows for text ", "user_id": "None"}]}, {"stack_answer_id": "1832968", "answer_content": "\r\n In this case, yes. Instead of \n\n exec 'self.Foo=val'\n \n\n you should use the  builtin  function  setattr : \n\n setattr(self, 'Foo', val)\n \n    ", "date_posted": "2009-12-02 13:38:31Z", "upvote": "\r\n            23\r\n        ", "accepted": "No", "user": {"stack_user_id": "19750", "name": "Josh Lee", "reputation_score": "163k"}, "answer_comments": []}, {"stack_answer_id": "40831661", "answer_content": "\r\n Other users pointed out how your code can be changed as to not depend on  eval ; I'll offer a legitimate use-case for using  eval , one that is found even in CPython:  testing . \n\n Here's one example I found in  test_unary.py  where a test on whether  (+|-|~)b'a'  raises a  TypeError : \n\n def test_bad_types(self):\n    for op in '+', '-', '~':\n        self.assertRaises(TypeError, eval, op + \"b'a'\")\n        self.assertRaises(TypeError, eval, op + \"'a'\")\n \n\n The usage is clearly not bad practice here;  you define the input  and merely observe behavior.  eval  is handy for testing. \n\n Take a look at this search  for  eval , performed on the CPython git repository; testing with eval is heavily used. \n    ", "date_posted": "2016-11-27 17:20:00Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "4952130", "name": "Dimitris Fasarakis Hilliard", "reputation_score": "139k"}, "answer_comments": []}, {"stack_answer_id": "1834815", "answer_content": "\r\n It's worth noting that for the specific problem in question, there are several alternatives to using  eval : \n\n The simplest, as noted, is using  setattr : \n\n def __init__(self):\n    for name in attsToStore:\n        setattr(self, name, None)\n \n\n A less obvious approach is updating the object's  __dict__  object directly.  If all you want to do is initialize the attributes to  None , then this is less straightforward than the above.  But consider this: \n\n def __init__(self, **kwargs):\n    for name in self.attsToStore:\n       self.__dict__[name] = kwargs.get(name, None)\n \n\n This allows you to pass keyword arguments to the constructor, e.g.: \n\n s = Song(name='History', artist='The Verve')\n \n\n It also allows you to make your use of  locals()  more explicit, e.g.: \n\n s = Song(**locals())\n \n\n ...and, if you really want to assign  None  to the attributes whose names are found in  locals() : \n\n s = Song(**dict([(k, None) for k in locals().keys()]))\n \n\n Another approach to providing an object with default values for a list of attributes is to define the class's  __getattr__  method: \n\n def __getattr__(self, name):\n    if name in self.attsToStore:\n        return None\n    raise NameError, name\n \n\n This method gets called when the named attribute isn't found in the normal way.  This approach somewhat less straightforward than simply setting the attributes in the constructor or updating the  __dict__ , but it has the merit of not actually creating the attribute unless it exists, which can pretty substantially reduce the class's memory usage. \n\n The point of all this:  There are lots of reasons, in general, to avoid  eval  - the security problem of executing code that you don't control, the practical problem of code you can't debug, etc.  But an even more important reason is that generally, you don't need to use it.  Python exposes so much of its internal mechanisms to the programmer that you rarely really need to write code that writes code. \n    ", "date_posted": "2009-12-02 18:19:56Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "19403", "name": "Robert Rossney", "reputation_score": "92.3k"}, "answer_comments": [{"stack_answer_id": "1834815", "stack_answer_comment_id": "1727231", "comment_content": "Another way that's arguably more (or less) Pythonic: Instead of using the object's ", "user_id": "None"}, {"stack_answer_id": "1834815", "stack_answer_comment_id": "88177930", "comment_content": "\"A less obvious approach is updating the object's ", "user_id": "None"}]}, {"stack_answer_id": "50581256", "answer_content": "\r\n When  eval()  is used to process user-provided input, you enable the user to  Drop-to-REPL  providing something like this: \n\n \"__import__('code').InteractiveConsole(locals=globals()).interact()\"\n \n\n You may get away with it, but normally you don't want vectors for  arbitrary code execution  in your applications. \n    ", "date_posted": "2018-06-01 10:22:13Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "1025391", "name": "moooeeeep", "reputation_score": "30.1k"}, "answer_comments": []}, {"stack_answer_id": "53040664", "answer_content": "\r\n In addition to @Nadia Alramli answer, since I am new to Python and was eager to check how using  eval  will affect the  timings , I tried a small program and below were the observations:  \n\n #Difference while using print() with eval() and w/o eval() to print an int = 0.528969s per 100000 evals()\n\nfrom datetime import datetime\ndef strOfNos():\n    s = []\n    for x in range(100000):\n        s.append(str(x))\n    return s\n\nstrOfNos()\nprint(datetime.now())\nfor x in strOfNos():\n    print(x) #print(eval(x))\nprint(datetime.now())\n\n#when using eval(int)\n#2018-10-29 12:36:08.206022\n#2018-10-29 12:36:10.407911\n#diff = 2.201889 s\n\n#when using int only\n#2018-10-29 12:37:50.022753\n#2018-10-29 12:37:51.090045\n#diff = 1.67292\n \n    ", "date_posted": "2018-10-29 07:46:40Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "2227834", "name": "Unheilig", "reputation_score": "16k"}, "answer_comments": []}], "user": {"stack_user_id": "32001", "name": "Nikwin", "reputation_score": "6,376"}, "question_comments": [{"stack_question_id": "1832940", "stack_question_comment_id": "1725429", "comment_content": "how did you learn about ", "user_id": "None"}, {"stack_question_id": "1832940", "stack_question_comment_id": "1726037", "comment_content": "I believe it was from an article comparing python and lisp than I learned about eval.", "user_id": "32001"}, {"stack_question_id": "1832940", "stack_question_comment_id": "127949976", "comment_content": "This should have been considered as two separate questions in the first place - explaining the risk of ", "user_id": "None"}, {"stack_question_id": "1832940", "stack_question_comment_id": "127949979", "comment_content": "See also: ", "user_id": "None"}]}[
{"stack_question_id": "20109391", "question_title": "How to make good reproducible pandas examples", "question_content": "\r\n                Having spent a decent amount of time watching both the r and pandas tags on SO, the impression that I get is that pandas questions are less likely to contain reproducible data. This is something that ...\r\n", "question_url": "/questions/20109391/how-to-make-good-reproducible-pandas-examples", "date_posted": "Nov 20, 2013 at 23:31", "upvote": "2", "view": "4", "tags": ["python", "pandas"], "answers_count": "5", "answers": [{"stack_answer_id": "20159305", "answer_content": "\r\n Note: The ideas here are pretty generic for Stack Overflow, indeed  questions . \n Disclaimer: Writing a good question is  hard . \n The Good: \n \n do include small* example DataFrame, either as runnable code: \n In [1]: df = pd.DataFrame([[1, 2], [1, 3], [4, 6]], columns=['A', 'B'])\n \n or make it \"copy and pasteable\" using  pd.read_clipboard(sep='\\s\\s+') , you can format the text for Stack Overflow highlight and use  Ctrl + K  (or prepend four spaces to each line), or place three backticks (```) above and below your code with your code unindented: \n In [2]: df\nOut[2]:\n   A  B\n0  1  2\n1  1  3\n2  4  6\n \n test  pd.read_clipboard(sep='\\s\\s+')  yourself. \n *  I really do mean  small . The vast majority of example DataFrames could be fewer than 6 rows  [citation needed] , and  I bet I can do it in 5 rows.  Can you reproduce the error with  df = df.head() ? If not, fiddle around to see if you can make up a small DataFrame which exhibits the issue you are facing. \n *  Every rule has an exception, the obvious one is for performance issues  ( in which case definitely use %timeit and possibly %prun ), where you should generate:  df = pd.DataFrame(np.random.randn(100000000, 10)) . Consider using  np.random.seed  so we have the exact same frame. Saying that, \"make this code fast for me\" is not strictly on topic for the site. \n \n write out the outcome you desire (similarly to above) \n In [3]: iwantthis\nOut[3]:\n   A  B\n0  1  5\n1  4  6\n \n Explain what the numbers come from: the 5 is sum of the B column for the rows where A is 1. \n \n do show  the code  you've tried: \n In [4]: df.groupby('A').sum()\nOut[4]:\n   B\nA\n1  5\n4  6\n \n But say what's incorrect: the A column is in the index rather than a column. \n \n do show you've done some research ( search the documentation ,  search Stack\u00a0Overflow ), and give a summary: \n \n The docstring for sum simply states \"Compute sum of group values\" \n \n \n The  groupby documentation  doesn't give any examples for this. \n \n Aside: the answer here is to use  df.groupby('A', as_index=False).sum() . \n \n if it's relevant that you have Timestamp columns, e.g. you're resampling or something, then be explicit and apply  pd.to_datetime  to them for good measure**. \n df['date'] = pd.to_datetime(df['date']) # this column ought to be date..\n \n **  Sometimes this is the issue itself: they were strings. \n \n \n The Bad: \n \n don't include a MultiIndex, which  we can't copy and paste  (see above). This is kind of a grievance with Pandas' default display, but nonetheless annoying: \n In [11]: df\nOut[11]:\n     C\nA B\n1 2  3\n  2  6\n \n The correct way is to include an ordinary DataFrame with a  set_index  call: \n In [12]: df = pd.DataFrame([[1, 2, 3], [1, 2, 6]], columns=['A', 'B', 'C']).set_index(['A', 'B'])\n\nIn [13]: df\nOut[13]:\n     C\nA B\n1 2  3\n  2  6\n \n \n do provide insight to what it is when giving the outcome you want: \n    B\nA\n1  1\n5  0\n \n Be specific about how you got the numbers (what are they)... double check they're correct. \n \n If your code throws an error, do include the entire stack trace (this can be edited out later if it's too noisy). Show the line number (and the corresponding line of your code which it's raising against). \n \n \n The Ugly: \n \n don't link to a  CSV  file we don't have access to (ideally don't link to an external source at all...) \n df = pd.read_csv('my_secret_file.csv')  # ideally with lots of parsing options\n \n Most data is proprietary  we get that: Make up similar data and see if you can reproduce the problem (something small). \n \n don't explain the situation vaguely in words, like you have a DataFrame which is \"large\", mention some of the column names in passing (be sure not to mention their dtypes). Try and go into lots of detail about something which is completely meaningless without seeing the actual context. Presumably no one is even going to read to the end of this paragraph. \n Essays are bad, it's easier with small examples. \n \n don't include 10+ (100+??) lines of data munging before getting to your actual question. \n Please, we see enough of this in our day jobs. We want to help, but  not like this... . \n Cut the intro, and just show the relevant DataFrames (or small versions of them) in the step which is causing you trouble. \n \n \n Anyway, have fun learning Python, NumPy and Pandas! \n    ", "date_posted": "2022-04-03 17:29:39Z", "upvote": "\r\n            451\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "4518341", "name": "wjandrea", "reputation_score": "24.1k"}, "answer_comments": [{"stack_answer_id": "20159305", "stack_answer_comment_id": "60808128", "comment_content": "+1 for the ", "user_id": "None"}, {"stack_answer_id": "20159305", "stack_answer_comment_id": "69339225", "comment_content": "the ", "user_id": "None"}, {"stack_answer_id": "20159305", "stack_answer_comment_id": "94715719", "comment_content": "Why ", "user_id": "None"}, {"stack_answer_id": "20159305", "stack_answer_comment_id": "94739875", "comment_content": "@MarianD the reason that \\s\\s+ is so popular is that there is often one e.g. in a column name, but multiple is rarer, and pandas output nicely puts in at least two between columns. Since this is just for toy/small datasets it's pretty powerful/majority of cases. Note: tabs separated would be a different story, though stackoverflow replaces tabs with spaces, but if you have a tsv then just use \\t.", "user_id": "None"}, {"stack_answer_id": "20159305", "stack_answer_comment_id": "99634737", "comment_content": "Ugh, i always use ", "user_id": "None"}]}, {"stack_answer_id": "30424537", "answer_content": "\r\n How to create sample datasets \n This is to mainly to expand on  AndyHayden's answer  by providing examples of how you can create sample dataframes.  Pandas and (especially) NumPy give you a variety of tools for this such that you can generally create a reasonable facsimile of any real dataset with just a few lines of code. \n After importing NumPy and Pandas, be sure to provide a random seed if you want folks to be able to exactly reproduce your data and results. \n import numpy as np\nimport pandas as pd\n\nnp.random.seed(123)\n \n A kitchen sink example \n Here's an example showing a variety of things you can do.  All kinds of useful sample dataframes could be created from a subset of this: \n df = pd.DataFrame({\n\n    # some ways to create random data\n    'a':np.random.randn(6),\n    'b':np.random.choice( [5,7,np.nan], 6),\n    'c':np.random.choice( ['panda','python','shark'], 6),\n\n    # some ways to create systematic groups for indexing or groupby\n    # this is similar to R's expand.grid(), see note 2 below\n    'd':np.repeat( range(3), 2 ),\n    'e':np.tile(   range(2), 3 ),\n\n    # a date range and set of random dates\n    'f':pd.date_range('1/1/2011', periods=6, freq='D'),\n    'g':np.random.choice( pd.date_range('1/1/2011', periods=365,\n                          freq='D'), 6, replace=False)\n    })\n \n This produces: \n           a   b       c  d  e          f          g\n0 -1.085631 NaN   panda  0  0 2011-01-01 2011-08-12\n1  0.997345   7   shark  0  1 2011-01-02 2011-11-10\n2  0.282978   5   panda  1  0 2011-01-03 2011-10-30\n3 -1.506295   7  python  1  1 2011-01-04 2011-09-07\n4 -0.578600 NaN   shark  2  0 2011-01-05 2011-02-27\n5  1.651437   7  python  2  1 2011-01-06 2011-02-03\n \n Some notes: \n \n np.repeat  and  np.tile  (columns  d  and  e ) are very useful for creating groups and indices in a very regular way.  For 2 columns, this can be used to easily duplicate r's  expand.grid()  but is also more flexible in ability to provide a subset of all permutations.  However, for 3 or more columns the syntax quickly becomes unwieldy. \n For a more direct replacement for R's  expand.grid()  see the  itertools  solution in the  pandas cookbook  or the  np.meshgrid  solution shown  here .  Those will allow any number of dimensions. \n You can do quite a bit with  np.random.choice .  For example, in column  g , we have a random selection of six dates from 2011.  Additionally, by setting  replace=False  we can assure these dates are unique -- very handy if we want to use this as an index with unique values. \n \n Fake stock market data \n In addition to taking subsets of the above code, you can further combine the techniques to do just about anything.  For example, here's a short example that combines  np.tile  and  date_range  to create sample ticker data for 4 stocks covering the same dates: \n stocks = pd.DataFrame({\n    'ticker':np.repeat( ['aapl','goog','yhoo','msft'], 25 ),\n    'date':np.tile( pd.date_range('1/1/2011', periods=25, freq='D'), 4 ),\n    'price':(np.random.randn(100).cumsum() + 10) })\n \n Now we have a sample dataset with 100 lines (25 dates per ticker), but we have only used 4 lines to do it, making it easy for everyone else to reproduce without copying and pasting 100 lines of code.  You can then display subsets of the data if it helps to explain your question: \n >>> stocks.head(5)\n\n        date      price ticker\n0 2011-01-01   9.497412   aapl\n1 2011-01-02  10.261908   aapl\n2 2011-01-03   9.438538   aapl\n3 2011-01-04   9.515958   aapl\n4 2011-01-05   7.554070   aapl\n\n>>> stocks.groupby('ticker').head(2)\n\n         date      price ticker\n0  2011-01-01   9.497412   aapl\n1  2011-01-02  10.261908   aapl\n25 2011-01-01   8.277772   goog\n26 2011-01-02   7.714916   goog\n50 2011-01-01   5.613023   yhoo\n51 2011-01-02   6.397686   yhoo\n75 2011-01-01  11.736584   msft\n76 2011-01-02  11.944519   msft\n \n    ", "date_posted": "2021-07-24 21:01:22Z", "upvote": "\r\n            84\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "30424537", "stack_answer_comment_id": "48943556", "comment_content": "Great answer. After writing this question I actually did write a very short, simple implementation of ", "user_id": "1222578"}, {"stack_answer_id": "30424537", "stack_answer_comment_id": "114458561", "comment_content": "This is a really useful example and I'll be using it as a base for examples. Many thanks!", "user_id": "None"}]}, {"stack_answer_id": "38466059", "answer_content": "\r\n Diary of an Answerer \n\n My best advice for asking questions would be to play on the psychology of the people who answer questions.  Being one of those people, I can give insight into why I answer certain questions and why I don't answer others. \n\n Motivations \n\n I'm motivated to answer questions for several reasons \n\n \n Stackoverflow.com has been a tremendously valuable resource to me.  I wanted to give back. \n In my efforts to give back, I've found this site to be an even more powerful resource than before.  Answering questions is a learning experience for me and I like to learn.   Read this answer and comment from another vet .  This kind of interaction makes me happy. \n I like points! \n See #3. \n I like interesting problems. \n \n\n All my purest intentions are great and all, but I get that satisfaction if I answer 1 question or 30.   What drives my choices  for which questions to answer has a huge component of point maximization. \n\n I'll also spend time on interesting problems but that is few and far between and doesn't help an asker who needs a solution to a non-interesting question.  Your best bet to get me to answer a question is to serve that question up on a platter ripe for me to answer it with as little effort as possible.  If I'm looking at two questions and one has code I can copy paste to create all the variables I need... I'm taking that one!  I'll come back to the other one if I have time, maybe. \n\n Main Advice \n\n Make it easy for the people answering questions. \n\n \n Provide code that creates variables that are needed. \n Minimize that code.  If my eyes glaze over as I look at the post, I'm on to the next question or getting back to whatever else I'm doing. \n Think about what you're asking and be specific.  We want to see what you've done because natural languages (English) are inexact and confusing.  Code samples of what you've tried help resolve inconsistencies in a natural language description. \n PLEASE show what you expect!!!  I have to sit down and try things.  I almost never know the answer to a question without trying some things out.  If I don't see an example of what you're looking for, I might pass on the question because I don't feel like guessing. \n \n\n Your reputation is more than just your reputation. \n\n I like points (I mentioned that above).  But those points aren't really really my reputation.  My real reputation is an amalgamation of what others on the site think of me.  I strive to be fair and honest and I hope others can see that.  What that means for an asker is, we remember the behaviors of askers.  If you don't select answers and upvote good answers, I remember.  If you behave in ways I don't like or in ways I do like, I remember.  This also plays into which questions I'll answer. \n\n \n\n Anyway, I can probably go on, but I'll spare all of you who actually read this. \n    ", "date_posted": "2018-01-01 09:39:28Z", "upvote": "\r\n            59\r\n        ", "accepted": "No", "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "answer_comments": []}, {"stack_answer_id": "32536193", "answer_content": "\r\n The Challenge  One of the most challenging aspects of responding to SO questions is the time it takes to recreate the problem (including the data).  Questions which don't have a clear way to reproduce the data are less likely to be answered.  Given that you are taking the time to write a question and you have an issue that you'd like help with, you can easily help yourself by providing data that others can then use to help solve your problem. \n The instructions provided by @Andy for writing good Pandas questions are an excellent place to start.  For more information, refer to  how to ask  and how to create  Minimal, Complete, and Verifiable examples . \n Please clearly state your question upfront.   After taking the time to write your question and any sample code, try to read it and provide an 'Executive Summary' for your reader which summarizes the problem and clearly states the question. \n Original question : \n \n I have this data... \n I want to do this... \n I want my result to look like this... \n However, when I try to do [this], I get the following problem... \n I've tried to find solutions by doing [this] and [that]. \n How do I fix it? \n \n Depending on the amount of data, sample code and error stacks provided, the reader needs to go a long way before understanding what the problem is.  Try restating your question so that the question itself is on top, and then provide the necessary details. \n Revised Question : \n \n Qustion:   How can I do [this]? \n I've tried to find solutions by doing [this] and [that]. \n When I've tried to do [this], I get the following problem... \n I'd like my final results to look like this... \n Here is some minimal code that can reproduce my problem... \n And here is how to recreate my sample data:\n df = pd.DataFrame({'A': [...], 'B': [...], ...}) \n \n PROVIDE SAMPLE DATA IF NEEDED!!! \n Sometimes just the head or tail of the DataFrame is all that is needed.  You can also use the methods proposed by @JohnE to create larger datasets that can be reproduced by others.  Using his example to generate a 100 row DataFrame of stock prices: \n stocks = pd.DataFrame({ \n    'ticker':np.repeat( ['aapl','goog','yhoo','msft'], 25 ),\n    'date':np.tile( pd.date_range('1/1/2011', periods=25, freq='D'), 4 ),\n    'price':(np.random.randn(100).cumsum() + 10) })\n \n If this was your actual data, you may just want to include the head and/or tail of the dataframe as follows (be sure to anonymize any sensitive data): \n >>> stocks.head(5).to_dict()\n{'date': {0: Timestamp('2011-01-01 00:00:00'),\n  1: Timestamp('2011-01-01 00:00:00'),\n  2: Timestamp('2011-01-01 00:00:00'),\n  3: Timestamp('2011-01-01 00:00:00'),\n  4: Timestamp('2011-01-02 00:00:00')},\n 'price': {0: 10.284260107718254,\n  1: 11.930300761831457,\n  2: 10.93741046217319,\n  3: 10.884574289565609,\n  4: 11.78005850418319},\n 'ticker': {0: 'aapl', 1: 'aapl', 2: 'aapl', 3: 'aapl', 4: 'aapl'}}\n\n>>> pd.concat([stocks.head(), stocks.tail()], ignore_index=True).to_dict()\n{'date': {0: Timestamp('2011-01-01 00:00:00'),\n  1: Timestamp('2011-01-01 00:00:00'),\n  2: Timestamp('2011-01-01 00:00:00'),\n  3: Timestamp('2011-01-01 00:00:00'),\n  4: Timestamp('2011-01-02 00:00:00'),\n  5: Timestamp('2011-01-24 00:00:00'),\n  6: Timestamp('2011-01-25 00:00:00'),\n  7: Timestamp('2011-01-25 00:00:00'),\n  8: Timestamp('2011-01-25 00:00:00'),\n  9: Timestamp('2011-01-25 00:00:00')},\n 'price': {0: 10.284260107718254,\n  1: 11.930300761831457,\n  2: 10.93741046217319,\n  3: 10.884574289565609,\n  4: 11.78005850418319,\n  5: 10.017209045035006,\n  6: 10.57090128181566,\n  7: 11.442792747870204,\n  8: 11.592953372130493,\n  9: 12.864146419530938},\n 'ticker': {0: 'aapl',\n  1: 'aapl',\n  2: 'aapl',\n  3: 'aapl',\n  4: 'aapl',\n  5: 'msft',\n  6: 'msft',\n  7: 'msft',\n  8: 'msft',\n  9: 'msft'}}\n \n You may also want to provide a description of the DataFrame (using only the relevant columns).  This makes it easier for others to check the data types of each column and identify other common errors (e.g. dates as string vs. datetime64 vs. object): \n stocks.info()\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 100 entries, 0 to 99\nData columns (total 3 columns):\ndate      100 non-null datetime64[ns]\nprice     100 non-null float64\nticker    100 non-null object\ndtypes: datetime64[ns](1), float64(1), object(1)\n \n NOTE:  If your DataFrame has a MultiIndex: \n If your DataFrame has a multiindex, you must first reset before calling  to_dict .  You then need to recreate the index using  set_index : \n # MultiIndex example.  First create a MultiIndex DataFrame.\ndf = stocks.set_index(['date', 'ticker'])\n>>> df\n                       price\ndate       ticker           \n2011-01-01 aapl    10.284260\n           aapl    11.930301\n           aapl    10.937410\n           aapl    10.884574\n2011-01-02 aapl    11.780059\n...\n\n# After resetting the index and passing the DataFrame to `to_dict`, make sure to use \n# `set_index` to restore the original MultiIndex.  This DataFrame can then be restored.\n\nd = df.reset_index().to_dict()\ndf_new = pd.DataFrame(d).set_index(['date', 'ticker'])\n>>> df_new.head()\n                       price\ndate       ticker           \n2011-01-01 aapl    10.284260\n           aapl    11.930301\n           aapl    10.937410\n           aapl    10.884574\n2011-01-02 aapl    11.780059\n \n    ", "date_posted": "2020-06-20 09:12:55Z", "upvote": "\r\n            38\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}, {"stack_answer_id": "41189949", "answer_content": "\r\n Here is my version of  dput  - the standard R tool to produce reproducible reports - for Pandas  DataFrame s.\nIt will probably fail for more complex frames, but it seems to do the job in simple cases: \n import pandas as pd\ndef dput(x):\n    if isinstance(x,pd.Series):\n        return \"pd.Series(%s,dtype='%s',index=pd.%s)\" % (list(x),x.dtype,x.index)\n    if isinstance(x,pd.DataFrame):\n        return \"pd.DataFrame({\" + \", \".join([\n            \"'%s': %s\" % (c,dput(x[c])) for c in x.columns]) + (\n                \"}, index=pd.%s)\" % (x.index))\n    raise NotImplementedError(\"dput\",type(x),x)\n \n now, \n df = pd.DataFrame({'a':[1,2,3,4,2,1,3,1]})\nassert df.equals(eval(dput(df)))\ndu = pd.get_dummies(df.a,\"foo\")\nassert du.equals(eval(dput(du)))\ndi = df\ndi.index = list('abcdefgh')\nassert di.equals(eval(dput(di)))\n \n Note  that this produces a much more verbose output than  DataFrame.to_dict , e.g., \n \n pd.DataFrame({\n  'foo_1':pd.Series([1, 0, 0, 0, 0, 1, 0, 1],dtype='uint8',index=pd.RangeIndex(start=0, stop=8, step=1)),\n  'foo_2':pd.Series([0, 1, 0, 0, 1, 0, 0, 0],dtype='uint8',index=pd.RangeIndex(start=0, stop=8, step=1)),\n  'foo_3':pd.Series([0, 0, 1, 0, 0, 0, 1, 0],dtype='uint8',index=pd.RangeIndex(start=0, stop=8, step=1)),\n  'foo_4':pd.Series([0, 0, 0, 1, 0, 0, 0, 0],dtype='uint8',index=pd.RangeIndex(start=0, stop=8, step=1))},\n  index=pd.RangeIndex(start=0, stop=8, step=1))\n \n \n vs \n \n {'foo_1': {0: 1, 1: 0, 2: 0, 3: 0, 4: 0, 5: 1, 6: 0, 7: 1}, \n 'foo_2': {0: 0, 1: 1, 2: 0, 3: 0, 4: 1, 5: 0, 6: 0, 7: 0}, \n 'foo_3': {0: 0, 1: 0, 2: 1, 3: 0, 4: 0, 5: 0, 6: 1, 7: 0}, \n 'foo_4': {0: 0, 1: 0, 2: 0, 3: 1, 4: 0, 5: 0, 6: 0, 7: 0}}\n \n \n for  du  above, but it  preserves column types .\nE.g., in the above test case, \n du.equals(pd.DataFrame(du.to_dict()))\n==> False\n \n because  du.dtypes  is  uint8  and  pd.DataFrame(du.to_dict()).dtypes  is  int64 . \n    ", "date_posted": "2020-11-08 03:20:49Z", "upvote": "\r\n            21\r\n        ", "accepted": "No", "user": {"stack_user_id": "50065", "name": "BioGeek", "reputation_score": "21.1k"}, "answer_comments": [{"stack_answer_id": "41189949", "stack_answer_comment_id": "71988989", "comment_content": "it is clearer, though i admit i don't see why i would want to use it over ", "user_id": "None"}, {"stack_answer_id": "41189949", "stack_answer_comment_id": "71989097", "comment_content": "Because it preserves column types. More specifically, ", "user_id": "None"}, {"stack_answer_id": "41189949", "stack_answer_comment_id": "124382725", "comment_content": "I like this. I have a more modern version with interpolated strings, which also breaks up the output with line breaks: ", "user_id": "None"}]}], "user": {"stack_user_id": "1222578", "name": "Marius", "reputation_score": "55.5k"}, "question_comments": [{"stack_question_id": "20109391", "stack_question_comment_id": "29965074", "comment_content": "If you copy the output of printing, most of the time answerers can use read_clipboard()... except for MultiIndex :s. Saying that, dict is good addition", "user_id": "None"}, {"stack_question_id": "20109391", "stack_question_comment_id": "29965293", "comment_content": "In addition to what Andy said, I think copy-pasting ", "user_id": "None"}]},
{"stack_question_id": "1132941", "question_title": "\"Least Astonishment\" and the Mutable Default Argument", "question_content": "\r\n                Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:\ndef foo(a=[]):\n    a.append(5)\n    return a\n\nPython novices would expect this function called with ...\r\n", "question_url": "/questions/1132941/least-astonishment-and-the-mutable-default-argument", "date_posted": "Jul 15, 2009 at 18:00", "upvote": "3", "view": "2", "tags": ["python", "language-design", "default-parameters", "least-astonishment"], "answers_count": "3", "answers": [{"stack_answer_id": "1145781", "answer_content": "\r\n Actually, this is not a design flaw, and it is not because of internals or performance. It comes simply from the fact that functions in Python are first-class objects, and not only a piece of code. \n As soon as you think of it this way, then it completely makes sense: a function is an object being evaluated on its definition; default parameters are kind of \"member data\" and therefore their state may change from one call to the other - exactly as in any other object. \n In any case, the effbot (Fredrik Lundh) has a very nice explanation of the reasons for this behavior in  Default Parameter Values in Python .\nI found it very clear, and I really suggest reading it for a better knowledge of how function objects work. \n    ", "date_posted": "2022-06-10 08:20:18Z", "upvote": "\r\n            1836\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "355230", "name": "martineau", "reputation_score": "115k"}, "answer_comments": [{"stack_answer_id": "1145781", "stack_answer_comment_id": "9448792", "comment_content": "To anyone reading the above answer, I strongly recommend you take the time to read through the linked Effbot article. As well as all the other useful info, the part on how this language feature can be used for result caching/memoisation is very handy to know!", "user_id": "None"}, {"stack_answer_id": "1145781", "stack_answer_comment_id": "19820636", "comment_content": "Even if it's a first-class object, one might still envision a design where the ", "user_id": "None"}, {"stack_answer_id": "1145781", "stack_answer_comment_id": "24551066", "comment_content": "Sorry, but anything considered \"The biggest WTF in Python\" is ", "user_id": "None"}, {"stack_answer_id": "1145781", "stack_answer_comment_id": "31573411", "comment_content": "Whether or not it's a design flaw, your answer seems to imply that this behaviour is somehow necessary, natural and obvious given that functions are first-class objects, and that simply isn't the case. Python has closures. If you replace the default argument with an assignment on the first line of the function, it evaluates the expression each call (potentially using names declared in an enclosing scope). There is no reason at all that it wouldn't be possible or reasonable to have default arguments evaluated each time the function is called in exactly the same way.", "user_id": "None"}, {"stack_answer_id": "1145781", "stack_answer_comment_id": "35944779", "comment_content": "The design doesn't directly follow from ", "user_id": "None"}]}, {"stack_answer_id": "1133013", "answer_content": "\r\n Suppose you have the following code \n fruits = (\"apples\", \"bananas\", \"loganberries\")\n\ndef eat(food=fruits):\n    ...\n \n When I see the declaration of eat, the least astonishing thing is to think that if the first parameter is not given, that it will be equal to the tuple  (\"apples\", \"bananas\", \"loganberries\") \n However, suppose later on in the code, I do something like \n def some_random_function():\n    global fruits\n    fruits = (\"blueberries\", \"mangos\")\n \n then if default parameters were bound at function execution rather than function declaration, I would be astonished (in a very bad way) to discover that fruits had been changed. This would be more astonishing IMO than discovering that your  foo  function above was mutating the list. \n The real problem lies with mutable variables, and all languages have this problem to some extent. Here's a question: suppose in Java I have the following code: \n StringBuffer s = new StringBuffer(\"Hello World!\");\nMap<StringBuffer,Integer> counts = new HashMap<StringBuffer,Integer>();\ncounts.put(s, 5);\ns.append(\"!!!!\");\nSystem.out.println( counts.get(s) );  // does this work?\n \n Now, does my map use the value of the  StringBuffer  key when it was placed into the map, or does it store the key by reference? Either way, someone is astonished; either the person who tried to get the object out of the  Map  using a value identical to the one they put it in with, or the person who can't seem to retrieve their object even though the key they're using is literally the same object that was used to put it into the map (this is actually why Python doesn't allow its mutable built-in data types to be used as dictionary keys). \n Your example is a good one of a case where Python newcomers will be surprised and bitten. But I'd argue that if we \"fixed\" this, then that would only create a different situation where they'd be bitten instead, and that one would be even less intuitive. Moreover, this is always the case when dealing with mutable variables; you always run into cases where someone could intuitively expect one or the opposite behavior depending on what code they're writing. \n I personally like Python's current approach: default function arguments are evaluated when the function is defined and that object is always the default. I suppose they could special-case using an empty list, but that kind of special casing would cause even more astonishment, not to mention be backwards incompatible. \n    ", "date_posted": "2021-07-30 23:44:28Z", "upvote": "\r\n            319\r\n        ", "accepted": "No", "user": {"stack_user_id": "7487335", "name": "Josh Correia", "reputation_score": "2,999"}, "answer_comments": [{"stack_answer_id": "1133013", "stack_answer_comment_id": "950511", "comment_content": "I think it's a matter of debate. You are acting on a global variable. Any evaluation performed anywhere in your code involving your global variable will now (correctly) refer to (\"blueberries\", \"mangos\"). the default parameter could just be like any other case.", "user_id": "78374"}, {"stack_answer_id": "1133013", "stack_answer_comment_id": "950592", "comment_content": "Actually, I don't think I agree with your first example.  I'm not sure I like the idea of modifying an initializer like that in the first place, but if I did, I'd expect it to behave exactly as you describe \u2014 changing the default value to ", "user_id": "None"}, {"stack_answer_id": "1133013", "stack_answer_comment_id": "950800", "comment_content": "The default parameter ", "user_id": "None"}, {"stack_answer_id": "1133013", "stack_answer_comment_id": "41236608", "comment_content": "I find the example misleading rather than brilliant. If ", "user_id": "None"}, {"stack_answer_id": "1133013", "stack_answer_comment_id": "44679235", "comment_content": "You just explicitly declared ", "user_id": "None"}]}, {"stack_answer_id": "11416002", "answer_content": "\r\n The relevant part of the  documentation : \n\n \n   Default parameter values are evaluated from left to right when the function definition is executed.  This means that the expression is evaluated once, when the function is defined, and that the same \u201cpre-computed\u201d value is used for each call. This is especially important to understand when a default parameter is a mutable object, such as a list or a dictionary: if the function modifies the object (e.g. by appending an item to a list), the default value is in effect modified. This is generally not what was intended. A way around this is to use  None  as the default, and explicitly test for it in the body of the function, e.g.: \n\n def whats_on_the_telly(penguin=None):\n    if penguin is None:\n        penguin = []\n    penguin.append(\"property of the zoo\")\n    return penguin\n \n \n    ", "date_posted": "2020-01-30 18:00:14Z", "upvote": "\r\n            295\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": [{"stack_answer_id": "11416002", "stack_answer_comment_id": "35944900", "comment_content": "The phrases \"this is not generally what was intended\" and \"a way around this is\" smell like they're documenting a design flaw.", "user_id": "None"}, {"stack_answer_id": "11416002", "stack_answer_comment_id": "37577356", "comment_content": "@bukzor: Pitfalls need to be noted and documented, which is why this question is good and has received so many upvotes. At the same time, pitfalls don't necessarily need to be removed. How many Python beginners have passed a list to a function that modified it, and were shocked to see the changes show up in the original variable? Yet mutable object types are wonderful, when you understand how to use them. I guess it just boils down to opinion on this particular pitfall.", "user_id": "None"}, {"stack_answer_id": "11416002", "stack_answer_comment_id": "43555974", "comment_content": "The phrase \"this is not generally what was intended\" means \"not what the programmer actually wanted to happen,\" not \"not what Python is supposed to do.\"", "user_id": "None"}, {"stack_answer_id": "11416002", "stack_answer_comment_id": "80032999", "comment_content": "@holdenweb Wow, I'm mega-late to the party. Given the context, bukzor is completely right: they're documenting behavior/consequence that was not \"intended\" when they they decided the language should exec the function's definition. Since it's an unintended consequence of their design choice, it's a design flaw. If it were not a design flaw, there'd be no need to even offer \"a way around this\".", "user_id": "None"}, {"stack_answer_id": "11416002", "stack_answer_comment_id": "80051888", "comment_content": "We could take it to chat and discuss how else it could be, but the semantics have been thoroughly debated and nobody could come up with a sensible mechanism for create-default-value-on-call. One serious issue is that the scope on call is often entirely different from that on definition, making name resolution uncertain if defaults were evaluated at call time. A \"way around\" means \"you can achieve your desired end in the following way,\" not \"this is a mistake in Python's design.\"", "user_id": "None"}]}, {"stack_answer_id": "1134623", "answer_content": "\r\n I know nothing about the Python interpreter inner workings (and I'm not an expert in compilers and interpreters either) so don't blame me if I propose anything unsensible or impossible. \n\n Provided that python objects  are mutable  I think that this should be taken into account when designing the default arguments stuff.\nWhen you instantiate a list: \n\n a = []\n \n\n you expect to get a  new  list referenced by  a . \n\n Why should the  a=[]  in \n\n def x(a=[]):\n \n\n instantiate a new list on function definition and not on invocation?\nIt's just like you're asking \"if the user doesn't provide the argument then  instantiate  a new list and use it as if it was produced by the caller\".\nI think this is ambiguous instead: \n\n def x(a=datetime.datetime.now()):\n \n\n user, do you want  a  to default to the datetime corresponding to when you're defining or executing  x ?\nIn this case, as in the previous one, I'll keep the same behaviour as if the default argument \"assignment\" was the first instruction of the function ( datetime.now()  called on function invocation).\nOn the other hand, if the user wanted the definition-time mapping he could write: \n\n b = datetime.datetime.now()\ndef x(a=b):\n \n\n I know, I know: that's a closure. Alternatively Python might provide a keyword to force definition-time binding: \n\n def x(static a=b):\n \n    ", "date_posted": "2019-05-09 09:15:36Z", "upvote": "\r\n            139\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "1134623", "stack_answer_comment_id": "952595", "comment_content": "You could do: def x(a=None): And then, if a is None, set a=datetime.datetime.now()", "user_id": "None"}, {"stack_answer_id": "1134623", "stack_answer_comment_id": "6587169", "comment_content": "Thank you for this. I couldn't really put my finger on why this  irks me to no end. You have done it beautifully with a minimum of fuzz and confusion. As someone comming from systems programming in C++ and sometimes naively \"translating\" language features, this false friend kicked me in the in the soft of the head big time, just like class attributes. I understand why things are this way, but I cannot help but dislike it, no matter what positive might come of it. At least it is so contrary to my experience, that I'll probably (hopefully) never forget it...", "user_id": "None"}, {"stack_answer_id": "1134623", "stack_answer_comment_id": "8065966", "comment_content": "@Andreas once you use Python for long enough, you begin to see how logical it is for Python to interpret things as class attributes the way it does - it is only because of the particular quirks and limitations of languages like C++ (and Java, and C#...) that it makes any sense for contents of the ", "user_id": "None"}, {"stack_answer_id": "1134623", "stack_answer_comment_id": "8112414", "comment_content": "Normative structure is no quirk or limitation in my book. I know it can be clumsy and ugly, but you can call it a \"definition\" of something. The dynamic languages seem a bit like anarchists to me: Sure everybody is free, but you need structure to get someone to empty the trash and pave the road. Guess I'm old... :)", "user_id": "None"}, {"stack_answer_id": "1134623", "stack_answer_comment_id": "46876103", "comment_content": "The function ", "user_id": "None"}]}, {"stack_answer_id": "1133255", "answer_content": "\r\n Well, the reason is quite simply that bindings are done when code is executed, and the function definition is executed, well... when the functions is defined. \n\n Compare this: \n\n class BananaBunch:\n    bananas = []\n\n    def addBanana(self, banana):\n        self.bananas.append(banana)\n \n\n This code suffers from the exact same unexpected happenstance. bananas is a class attribute, and hence, when you add things to it, it's added to all instances of that class. The reason is exactly the same. \n\n It's just \"How It Works\", and making it work differently in the function case would probably be complicated, and in the class case likely impossible, or at least slow down object instantiation a lot, as you would have to keep the class code around and execute it when objects are created. \n\n Yes, it is unexpected. But once the penny drops, it fits in perfectly with how Python works in general. In fact, it's a good teaching aid, and once you understand why this happens, you'll grok python much better. \n\n That said it should feature prominently in any good Python tutorial. Because as you mention, everyone runs into this problem sooner or later. \n    ", "date_posted": "2014-12-19 22:53:35Z", "upvote": "\r\n            93\r\n        ", "accepted": "No", "user": {"stack_user_id": "126214", "name": "Lennart Regebro", "reputation_score": "161k"}, "answer_comments": [{"stack_answer_id": "1133255", "stack_answer_comment_id": "950835", "comment_content": "How do you define a class attribute that is different for each instance of a class?", "user_id": "None"}, {"stack_answer_id": "1133255", "stack_answer_comment_id": "950938", "comment_content": "If it's different for each instance it's not a class attribute. Class attributes are attributes on the CLASS. Hence the name. Hence they are the same for all instances.", "user_id": "None"}, {"stack_answer_id": "1133255", "stack_answer_comment_id": "955561", "comment_content": "How do you define an attribute in a class that is different for each instance of a class? (Re-defined for those who could not determine that a person not familiar with Python's naming convenctions might be asking about normal member variables of a class).", "user_id": "None"}, {"stack_answer_id": "1133255", "stack_answer_comment_id": "955627", "comment_content": "@Kievieli: You ARE talking about normal member variables of a class. :-)  You define instance attributes by saying self.attribute = value in any method. For example __init__().", "user_id": "None"}, {"stack_answer_id": "1133255", "stack_answer_comment_id": "10928164", "comment_content": "@Kieveli: Two answers:  you can't, because any thing you define at a class level will be a class attribute, and any instance that accesses that attribute will access the same class attribute; you can, /sort of/, by using ", "user_id": "None"}]}, {"stack_answer_id": "34172768", "answer_content": "\r\n Why don't you introspect? \n\n I'm  really  surprised no one has performed the insightful introspection offered by Python ( 2  and  3  apply) on callables.  \n\n Given a simple little function  func  defined as: \n\n >>> def func(a = []):\n...    a.append(5)\n \n\n When Python encounters it, the first thing it will do is compile it in order to create a  code  object for this function. While this compilation step is done,  Python  evaluates * and then  stores  the default arguments (an empty list  []  here) in the function object itself . As the top answer mentioned: the list  a  can now be considered a  member  of the function  func . \n\n So, let's do some introspection, a before and after to examine how the list gets expanded  inside  the function object. I'm using  Python 3.x  for this, for Python 2 the same applies (use  __defaults__  or  func_defaults  in Python 2; yes, two names for the same thing). \n\n Function Before Execution: \n\n >>> def func(a = []):\n...     a.append(5)\n...     \n \n\n After Python executes this definition it will take any default parameters specified ( a = []  here) and  cram them in the  __defaults__  attribute for the function object  (relevant section: Callables):      \n\n >>> func.__defaults__\n([],)\n \n\n O.k, so an empty list as the single entry in  __defaults__ , just as expected.  \n\n Function After Execution: \n\n Let's now execute this function: \n\n >>> func()\n \n\n Now, let's see those  __defaults__  again:  \n\n >>> func.__defaults__\n([5],)\n \n\n Astonished?  The value inside the object changes! Consecutive calls to the function will now simply append to that embedded  list  object: \n\n >>> func(); func(); func()\n>>> func.__defaults__\n([5, 5, 5, 5],)\n \n\n So, there you have it, the reason why this  'flaw'  happens, is because default arguments are part of the function object. There's nothing weird going on here, it's all just a bit surprising. \n\n The common solution to combat this is to use  None  as the default and then initialize in the function body: \n\n def func(a = None):\n    # or: a = [] if a is None else a\n    if a is None:\n        a = []\n \n\n Since the function body is executed anew each time, you always get a fresh new empty list if no argument was passed for  a . \n\n \n\n To further verify that the list in  __defaults__  is the same as that used in the function  func  you can just change your function to return the  id  of the list  a  used inside the function body. Then, compare it to the list in  __defaults__  (position  [0]  in  __defaults__ ) and you'll see how these are indeed refering to the same list instance: \n\n >>> def func(a = []): \n...     a.append(5)\n...     return id(a)\n>>>\n>>> id(func.__defaults__[0]) == func()\nTrue\n \n\n All with the power of introspection!  \n\n \n\n *  To verify that Python evaluates the default arguments during compilation of the function, try executing the following: \n\n def bar(a=input('Did you just see me without calling the function?')): \n    pass  # use raw_input in Py2\n \n\n as you'll notice,  input()  is called before the process of building the function and binding it to the name  bar  is made. \n    ", "date_posted": "2018-10-11 16:33:49Z", "upvote": "\r\n            81\r\n        ", "accepted": "No", "user": {"stack_user_id": "4850040", "name": "Toby Speight", "reputation_score": "25.5k"}, "answer_comments": [{"stack_answer_id": "34172768", "stack_answer_comment_id": "59433843", "comment_content": "Is ", "user_id": "None"}, {"stack_answer_id": "34172768", "stack_answer_comment_id": "59434204", "comment_content": "@das-g ", "user_id": "None"}, {"stack_answer_id": "34172768", "stack_answer_comment_id": "103227664", "comment_content": "Using ", "user_id": "None"}]}, {"stack_answer_id": "1136611", "answer_content": "\r\n I used to think that creating the objects at runtime would be the better approach.  I'm less certain now, since you do lose some useful features, though it may be worth it regardless simply to prevent newbie confusion.  The disadvantages of doing so are: \n\n 1. Performance \n\n def foo(arg=something_expensive_to_compute())):\n    ...\n \n\n If call-time evaluation is used, then the expensive function is called every time your function is used without an argument.  You'd either pay an expensive price on each call, or need to manually cache the value externally, polluting your namespace and adding verbosity. \n\n 2. Forcing bound parameters \n\n A useful trick is to bind parameters of a lambda to the  current  binding of a variable when the lambda is created.  For example: \n\n funcs = [ lambda i=i: i for i in range(10)]\n \n\n This returns a list of functions that return 0,1,2,3... respectively.  If the behaviour is changed, they will instead bind  i  to the  call-time  value of i, so you would get a list of functions that all returned  9 . \n\n The only way to implement this otherwise would be to create a further closure with the i bound, ie: \n\n def make_func(i): return lambda: i\nfuncs = [make_func(i) for i in range(10)]\n \n\n 3. Introspection \n\n Consider the code: \n\n def foo(a='test', b=100, c=[]):\n   print a,b,c\n \n\n We can get information about the arguments and defaults using the  inspect  module, which  \n\n >>> inspect.getargspec(foo)\n(['a', 'b', 'c'], None, None, ('test', 100, []))\n \n\n This information is very useful for things like document generation, metaprogramming, decorators etc. \n\n Now, suppose the behaviour of defaults could be changed so that this is the equivalent of: \n\n _undefined = object()  # sentinel value\n\ndef foo(a=_undefined, b=_undefined, c=_undefined)\n    if a is _undefined: a='test'\n    if b is _undefined: b=100\n    if c is _undefined: c=[]\n \n\n However, we've lost the ability to introspect, and see what the default arguments  are .  Because the objects haven't been constructed, we can't ever get hold of them without actually calling the function.  The best we could do is to store off the source code and return that as a string. \n    ", "date_posted": "2009-07-16 19:13:35Z", "upvote": "\r\n            65\r\n        ", "accepted": "No", "user": {"stack_user_id": "9493", "name": "Brian", "reputation_score": "114k"}, "answer_comments": [{"stack_answer_id": "1136611", "stack_answer_comment_id": "954490", "comment_content": "you could achieve introspection also if for each there was a function to create the default argument instead of a value. the inspect module will just call that function.", "user_id": "None"}, {"stack_answer_id": "1136611", "stack_answer_comment_id": "954611", "comment_content": "@SilentGhost:  I'm talking about if the behaviour was changed to recreate it - creating it once is the current behaviour, and why the mutable default problem exists.", "user_id": "None"}, {"stack_answer_id": "1136611", "stack_answer_comment_id": "954628", "comment_content": "@yairchu: That assumes the construction is safe to so (ie has no side effects).  Introspecting the args shouldn't ", "user_id": "None"}, {"stack_answer_id": "1136611", "stack_answer_comment_id": "957188", "comment_content": "A different language design often just means writing things differently.  Your first example could easily be written as: _expensive = expensive(); def foo(arg=_expensive), if you specifically ", "user_id": "None"}, {"stack_answer_id": "1136611", "stack_answer_comment_id": "957359", "comment_content": "@Glenn - that's what I was referring to with \"cache the variable externally\" - it is a bit more verbose, and you end up with extra variables in your namespace though.", "user_id": "None"}]}, {"stack_answer_id": "29344819", "answer_content": "\r\n 5 points in defense of Python \n \n Simplicity : The behavior is simple in the following sense:\nMost people fall into this trap only once, not several times. \n \n Consistency : Python  always  passes objects, not names.\nThe default parameter is, obviously, part of the function\nheading (not the function body). It therefore ought to be evaluated\nat module load time (and only at module load time, unless nested), not\nat function call time. \n \n Usefulness : As Frederik Lundh points out in his explanation\nof  \"Default Parameter Values in Python\" , the\ncurrent behavior can be quite useful for advanced programming.\n(Use sparingly.) \n \n Sufficient documentation : In the most basic Python documentation,\nthe tutorial, the issue is loudly announced as\nan  \"Important warning\"  in the  first  subsection of Section\n \"More on Defining Functions\" .\nThe warning even uses boldface,\nwhich is rarely applied outside of headings.\nRTFM: Read the fine manual. \n \n Meta-learning : Falling into the trap is actually a very\nhelpful moment (at least if you are a reflective learner),\nbecause you will subsequently better understand the point\n\"Consistency\" above and that will\nteach you a great deal about Python. \n \n \n    ", "date_posted": "2021-01-21 12:41:46Z", "upvote": "\r\n            65\r\n        ", "accepted": "No", "user": {"stack_user_id": "13367995", "name": "jakubde", "reputation_score": "27"}, "answer_comments": [{"stack_answer_id": "29344819", "stack_answer_comment_id": "52693997", "comment_content": "It took me a year to find this behavior is messing up my code on production, ended up removing a complete feature until I bumped into this design flaw by chance.  I'm using Django.  Since the staging environment did not have many requests, this bug never had any impact on QA.  When we went live and received many simultaneous requests - some utility functions started overwriting each other's parameters!  Making security holes, bugs and what not.", "user_id": "None"}, {"stack_answer_id": "29344819", "stack_answer_comment_id": "65774123", "comment_content": "@oriadam, no offense, but I wonder how you learned Python without running into this before.  I am just learning Python now and this possible pitfall is ", "user_id": "None"}, {"stack_answer_id": "29344819", "stack_answer_comment_id": "65920805", "comment_content": "Also, it would be surprising (to me) if a function of unknown complexity was called in addition to the function call I am making.", "user_id": "None"}, {"stack_answer_id": "29344819", "stack_answer_comment_id": "115930547", "comment_content": "@oriadam, your company needs code review and actual expert coders in the language they write in by the time they have development, staging and production environments. Newbie bugs and bad code habits should not make it to production code", "user_id": "None"}]}, {"stack_answer_id": "1133375", "answer_content": "\r\n This behavior is easy explained by: \n\n \n function (class etc.) declaration is executed only once, creating all default value objects \n everything is passed by reference \n \n\n So: \n\n def x(a=0, b=[], c=[], d=0):\n    a = a + 1\n    b = b + [1]\n    c.append(1)\n    print a, b, c\n \n\n \n a  doesn't change - every assignment call creates new int object - new object is printed \n b  doesn't change - new array is build from default value and printed \n c  changes - operation is performed on same object - and it is printed \n \n    ", "date_posted": "2017-10-24 06:34:34Z", "upvote": "\r\n            57\r\n        ", "accepted": "No", "user": {"stack_user_id": "4952130", "name": "Dimitris Fasarakis Hilliard", "reputation_score": "139k"}, "answer_comments": [{"stack_answer_id": "1133375", "stack_answer_comment_id": "952500", "comment_content": "(Actually, ", "user_id": "None"}, {"stack_answer_id": "1133375", "stack_answer_comment_id": "952539", "comment_content": "Realized it to my chagrin after checking to see that, with b set to [], b.__add__([1]) returns [1] but also leaves b still [] even though lists are mutable.  My bad.", "user_id": "None"}, {"stack_answer_id": "1133375", "stack_answer_comment_id": "36118858", "comment_content": "@ANon: there is ", "user_id": "None"}]}, {"stack_answer_id": "13518071", "answer_content": "\r\n 1)  The so-called problem of \"Mutable Default Argument\" is in general a special example demonstrating that: \n\"All functions with this problem  suffer also from similar side effect problem on the actual parameter ,\" \nThat is against the rules of functional programming, usually undesiderable and should be fixed both together. \n\n Example: \n\n def foo(a=[]):                 # the same problematic function\n    a.append(5)\n    return a\n\n>>> somevar = [1, 2]           # an example without a default parameter\n>>> foo(somevar)\n[1, 2, 5]\n>>> somevar\n[1, 2, 5]                      # usually expected [1, 2]\n \n\n Solution :  a  copy \nAn absolutely safe solution is to  copy  or  deepcopy  the input object first and then to do whatever with the copy. \n\n def foo(a=[]):\n    a = a[:]     # a copy\n    a.append(5)\n    return a     # or everything safe by one line: \"return a + [5]\"\n \n\n Many builtin mutable types have a copy method like  some_dict.copy()  or  some_set.copy()  or can be copied easy like  somelist[:]  or  list(some_list) . Every object can be also copied by  copy.copy(any_object)  or more thorough by  copy.deepcopy()  (the latter useful if the mutable object is composed from mutable objects). Some objects are fundamentally based on side effects like \"file\" object and can not be meaningfully reproduced by copy.  copying \n\n Example problem for  a similar SO question \n\n class Test(object):            # the original problematic class\n  def __init__(self, var1=[]):\n    self._var1 = var1\n\nsomevar = [1, 2]               # an example without a default parameter\nt1 = Test(somevar)\nt2 = Test(somevar)\nt1._var1.append([1])\nprint somevar                  # [1, 2, [1]] but usually expected [1, 2]\nprint t2._var1                 # [1, 2, [1]] but usually expected [1, 2]\n \n\n It shouldn't be neither saved in any  public  attribute of an instance returned by this function. (Assuming that  private  attributes of instance should not be modified from outside of this class or subclasses by convention. i.e.  _var1  is a private attribute ) \n\n Conclusion: \nInput parameters objects shouldn't be modified in place (mutated) nor they should not be binded into an object returned by the function. (If we prefere programming without side effects which is strongly recommended. see  Wiki about \"side effect\"  (The first two paragraphs are relevent in this context.)\n.) \n\n 2) \nOnly if the side effect on the actual parameter is required but unwanted on the default parameter then the useful solution is  def ...(var1=None):   if var1 is None:   var1 = []   More.. \n\n 3) In some cases is  the mutable behavior of default parameters useful . \n    ", "date_posted": "2017-05-23 11:47:32Z", "upvote": "\r\n            39\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": [{"stack_answer_id": "13518071", "stack_answer_comment_id": "36118939", "comment_content": "I hope you're aware that Python is ", "user_id": "None"}, {"stack_answer_id": "13518071", "stack_answer_comment_id": "36126140", "comment_content": "Yes, Python is a multi-paragigm language with some functional features. (\"Don't make every problem look like a nail just because you have a hammer.\") Many of them are in Python best practicies. Python has an interesting ", "user_id": "None"}, {"stack_answer_id": "13518071", "stack_answer_comment_id": "83550760", "comment_content": "I'd also add, at this late stage, that Python's assignment semantics have been designed explicitly to avoid data copying where necessary, so the creation of copies (and especially of deep copies) will affect both run-time and memory usage adversely. They should therefore be used only when necessary, but newcomers often have difficulty understanding when that is.", "user_id": "None"}, {"stack_answer_id": "13518071", "stack_answer_comment_id": "83606638", "comment_content": "@holdenweb I agree. A temporary copy is the most usual way and sometimes the only possible way how to protect the original mutable data from an extraneous function that modifies them potentially. Fortunately a function that unreasonably modifies data is considered a bug and therefore uncommon.", "user_id": "None"}, {"stack_answer_id": "13518071", "stack_answer_comment_id": "84665509", "comment_content": "I agree with this answer. And I don't understand why the ", "user_id": "None"}]}, {"stack_answer_id": "1133737", "answer_content": "\r\n What you're asking is why this: \n\n def func(a=[], b = 2):\n    pass\n \n\n isn't internally equivalent to this: \n\n def func(a=None, b = None):\n    a_default = lambda: []\n    b_default = lambda: 2\n    def actual_func(a=None, b=None):\n        if a is None: a = a_default()\n        if b is None: b = b_default()\n    return actual_func\nfunc = func()\n \n\n except for the case of explicitly calling func(None, None), which we'll ignore. \n\n In other words, instead of evaluating default parameters, why not store each of them, and evaluate them when the function is called? \n\n One answer is probably right there--it would effectively turn every function with default parameters into a closure.  Even if it's all hidden away in the interpreter and not a full-blown closure, the data's got to be stored somewhere.  It'd be slower and use more memory. \n    ", "date_posted": "2009-07-15 20:18:14Z", "upvote": "\r\n            38\r\n        ", "accepted": "No", "user": {"stack_user_id": "136829", "name": "Glenn Maynard", "reputation_score": "54k"}, "answer_comments": [{"stack_answer_id": "1133737", "stack_answer_comment_id": "954338", "comment_content": "It wouldn't need to be a closure - a better way to think of it would simply to make the bytecode creating defaults the first line of code - after all you're compiling the body at that point anyway - there's no real difference between code in the arguments and code in the body.", "user_id": "None"}, {"stack_answer_id": "1133737", "stack_answer_comment_id": "954824", "comment_content": "True, but it would still slow Python down, and it would actually be quite surprising, unless you do the same for class definitions, which would make it stupidly slow as you would have to re-run the whole class definition each time you instantiate a class.  As mentioned, the fix would be more surprising than the problem.", "user_id": "None"}, {"stack_answer_id": "1133737", "stack_answer_comment_id": "955297", "comment_content": "Agreed with Lennart.  As Guido is fond of saying, for every language feature or standard library, there's ", "user_id": "None"}, {"stack_answer_id": "1133737", "stack_answer_comment_id": "957116", "comment_content": "Changing it now would be insanity--we're just exploring why it is the way it is.  If it did late default evaluation to begin with, it wouldn't necessarily be surprising.  It's definitely true that such a core a difference of parsing would have sweeping, and probably many obscure, effects on the language as a whole.", "user_id": "None"}]}, {"stack_answer_id": "6092808", "answer_content": "\r\n This actually has nothing to do with default values, other than that it often comes up as an unexpected behaviour when you write functions with mutable default values. \n\n >>> def foo(a):\n    a.append(5)\n    print a\n\n>>> a  = [5]\n>>> foo(a)\n[5, 5]\n>>> foo(a)\n[5, 5, 5]\n>>> foo(a)\n[5, 5, 5, 5]\n>>> foo(a)\n[5, 5, 5, 5, 5]\n \n\n No default values in sight in this code, but you get exactly the same problem. \n\n The problem is that  foo  is  modifying  a mutable variable passed in from the caller, when the caller doesn't expect this. Code like this would be fine if the function was called something like  append_5 ; then the caller would be calling the function in order to modify the value they pass in, and the behaviour would be expected. But such a function would be very unlikely to take a default argument, and probably wouldn't return the list (since the caller already has a reference to that list; the one it just passed in). \n\n Your original  foo , with a default argument, shouldn't be modifying  a  whether it was explicitly passed in or got the default value. Your code should leave mutable arguments alone unless it is clear from the context/name/documentation that the arguments are supposed to be modified. Using mutable values passed in as arguments as local temporaries is an extremely bad idea, whether we're in Python or not and whether there are default arguments involved or not. \n\n If you need to destructively manipulate a local temporary in the course of computing something, and you need to start your manipulation from an argument value, you need to make a copy. \n    ", "date_posted": "2011-05-23 04:24:30Z", "upvote": "\r\n            30\r\n        ", "accepted": "No", "user": {"stack_user_id": "450128", "name": "Ben", "reputation_score": "63.9k"}, "answer_comments": [{"stack_answer_id": "6092808", "stack_answer_comment_id": "16186544", "comment_content": "Although related, I think this is distinct behaviour (as we expect ", "user_id": "None"}, {"stack_answer_id": "6092808", "stack_answer_comment_id": "80529225", "comment_content": "@AndyHayden if the function is ", "user_id": "None"}, {"stack_answer_id": "6092808", "stack_answer_comment_id": "80539521", "comment_content": "@AndyHayden I left my own answer here with an expansion of that sentiment. Let me know what you think. I might add your example of ", "user_id": "None"}, {"stack_answer_id": "6092808", "stack_answer_comment_id": "80546281", "comment_content": "@AndyHayden The point of my answer is that if you are ever astonished by accidentally mutating the default value of an argument, then you have another bug, which is that your code can accidentally mutate a caller's value when the default ", "user_id": "None"}, {"stack_answer_id": "6092808", "stack_answer_comment_id": "80548974", "comment_content": "@AndyHayden That's the subtle thing though, what happens in the case you describe if the caller of the constructor provides a value instead of using the default? Now you've gone and aliased your object's internal attribute to an external value owned by the caller! That sort of thing is a very rich source of hard-to-track-down bugs; it's almost ", "user_id": "None"}]}, {"stack_answer_id": "36968932", "answer_content": "\r\n Python: The Mutable Default Argument \n\n Default arguments get evaluated at the time the function is compiled into a function object. When used by the function, multiple times by that function, they are and remain the same object.  \n\n When they are mutable, when mutated (for example, by adding an element to it) they remain mutated on consecutive calls. \n\n They stay mutated because they are the same object each time. \n\n Equivalent code: \n\n Since the list is bound to the function when the function object is compiled and instantiated, this: \n\n def foo(mutable_default_argument=[]): # make a list the default argument\n    \"\"\"function that uses a list\"\"\"\n \n\n is almost exactly equivalent to this: \n\n _a_list = [] # create a list in the globals\n\ndef foo(mutable_default_argument=_a_list): # make it the default argument\n    \"\"\"function that uses a list\"\"\"\n\ndel _a_list # remove globals name binding\n \n\n Demonstration \n\n Here's a demonstration - you can verify that they are the same object each time they are referenced by  \n\n \n seeing that the list is created before the function has finished compiling to a function object, \n observing that the id is the same each time the list is referenced, \n observing that the list stays changed when the function that uses it is called a second time, \n observing the order in which the output is printed from the source (which I conveniently numbered for you): \n \n\n example.py \n\n print('1. Global scope being evaluated')\n\ndef create_list():\n    '''noisily create a list for usage as a kwarg'''\n    l = []\n    print('3. list being created and returned, id: ' + str(id(l)))\n    return l\n\nprint('2. example_function about to be compiled to an object')\n\ndef example_function(default_kwarg1=create_list()):\n    print('appending \"a\" in default default_kwarg1')\n    default_kwarg1.append(\"a\")\n    print('list with id: ' + str(id(default_kwarg1)) + \n          ' - is now: ' + repr(default_kwarg1))\n\nprint('4. example_function compiled: ' + repr(example_function))\n\n\nif __name__ == '__main__':\n    print('5. calling example_function twice!:')\n    example_function()\n    example_function()\n \n\n and running it with  python example.py : \n\n 1. Global scope being evaluated\n2. example_function about to be compiled to an object\n3. list being created and returned, id: 140502758808032\n4. example_function compiled: <function example_function at 0x7fc9590905f0>\n5. calling example_function twice!:\nappending \"a\" in default default_kwarg1\nlist with id: 140502758808032 - is now: ['a']\nappending \"a\" in default default_kwarg1\nlist with id: 140502758808032 - is now: ['a', 'a']\n \n\n Does this violate the principle of \"Least Astonishment\"? \n\n This order of execution is frequently confusing to new users of Python. If you understand the Python execution model, then it becomes quite expected.  \n\n The usual instruction to new Python users: \n\n But this is why the usual instruction to new users is to create their default arguments like this instead: \n\n def example_function_2(default_kwarg=None):\n    if default_kwarg is None:\n        default_kwarg = []\n \n\n This uses the None singleton as a sentinel object to tell the function whether or not we've gotten an argument other than the default. If we get no argument, then we actually want to use a new empty list,  [] , as the default. \n\n As the  tutorial section on control flow  says: \n\n \n   If you don\u2019t want the default to be shared between subsequent calls,\n  you can write the function like this instead: \n\n def f(a, L=None):\n    if L is None:\n        L = []\n    L.append(a)\n    return L\n \n \n    ", "date_posted": "2017-12-23 21:18:35Z", "upvote": "\r\n            28\r\n        ", "accepted": "No", "user": {"stack_user_id": "541136", "name": "Russia Must Remove Putin", "reputation_score": "347k"}, "answer_comments": []}, {"stack_answer_id": "1137164", "answer_content": "\r\n The shortest answer would probably be \"definition is execution\", therefore the whole argument makes no strict sense. As a more contrived example, you may cite this: \n\n def a(): return []\n\ndef b(x=a()):\n    print x\n \n\n Hopefully it's enough to show that not executing the default argument expressions at the execution time of the  def  statement isn't easy or doesn't make sense, or both. \n\n I agree it's a gotcha when you try to use default constructors, though. \n    ", "date_posted": "2018-05-20 23:22:19Z", "upvote": "\r\n            28\r\n        ", "accepted": "No", "user": {"stack_user_id": "3951861", "name": "Ashraf.Shk786", "reputation_score": "600"}, "answer_comments": []}, {"stack_answer_id": "29290566", "answer_content": "\r\n Already busy topic, but from what I read here, the following helped me realizing how it's working internally: \n\n def bar(a=[]):\n     print id(a)\n     a = a + [1]\n     print id(a)\n     return a\n\n>>> bar()\n4484370232\n4484524224\n[1]\n>>> bar()\n4484370232\n4484524152\n[1]\n>>> bar()\n4484370232 # Never change, this is 'class property' of the function\n4484523720 # Always a new object \n[1]\n>>> id(bar.func_defaults[0])\n4484370232\n \n    ", "date_posted": "2015-03-26 23:14:01Z", "upvote": "\r\n            27\r\n        ", "accepted": "No", "user": {"stack_user_id": "554374", "name": "St\u00e9phane", "reputation_score": "1,947"}, "answer_comments": [{"stack_answer_id": "29290566", "stack_answer_comment_id": "73656522", "comment_content": "actually this might be a bit confusing for newcomers as ", "user_id": "None"}]}, {"stack_answer_id": "1134613", "answer_content": "\r\n It's a performance optimization.  As a result of this functionality, which of these two function calls do you think is faster? \n\n def print_tuple(some_tuple=(1,2,3)):\n    print some_tuple\n\nprint_tuple()        #1\nprint_tuple((1,2,3)) #2\n \n\n I'll give you a hint.  Here's the disassembly (see  http://docs.python.org/library/dis.html ): \n\n # 1 \n\n 0 LOAD_GLOBAL              0 (print_tuple)\n3 CALL_FUNCTION            0\n6 POP_TOP\n7 LOAD_CONST               0 (None)\n10 RETURN_VALUE\n \n\n # 2 \n\n  0 LOAD_GLOBAL              0 (print_tuple)\n 3 LOAD_CONST               4 ((1, 2, 3))\n 6 CALL_FUNCTION            1\n 9 POP_TOP\n10 LOAD_CONST               0 (None)\n13 RETURN_VALUE\n \n\n \n   I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs ?) \n \n\n As you can see, there  is  a performance benefit when using immutable default arguments.  This can make a difference if it's a frequently called function or the default argument takes a long time to construct.  Also, bear in mind that Python isn't C.  In C you have constants that are pretty much free.  In Python you don't have this benefit. \n    ", "date_posted": "2013-04-02 21:52:30Z", "upvote": "\r\n            26\r\n        ", "accepted": "No", "user": {"stack_user_id": "2147", "name": "Jason Baker", "reputation_score": "184k"}, "answer_comments": []}, {"stack_answer_id": "10304917", "answer_content": "\r\n This behavior is not surprising if you take the following into consideration: \n \n The behavior of read-only class attributes upon assignment attempts, and that \n Functions are objects (explained well in the accepted answer). \n \n The role of  (2)  has been covered extensively in this thread.  (1)  is likely the astonishment causing factor, as this behavior is not \"intuitive\" when coming from other languages. \n (1)  is described in the Python  tutorial on classes . In an attempt to assign a value to a read-only class attribute: \n \n ...all variables found outside of the innermost scope are\nread-only ( an attempt to write to such a variable will simply create a\nnew local variable in the innermost scope, leaving the identically\nnamed outer variable unchanged ). \n \n Look back to the original example and consider the above points: \n def foo(a=[]):\n    a.append(5)\n    return a\n \n Here  foo  is an object and  a  is an attribute of  foo  (available at  foo.func_defs[0] ). Since  a  is a list,  a  is mutable and is thus a read-write attribute of  foo . It is initialized to the empty list as specified by the signature when the function is instantiated, and is available for reading and writing as long as the function object exists. \n Calling  foo  without overriding a default uses that default's value from  foo.func_defs . In this case,  foo.func_defs[0]  is used for  a  within function object's code scope. Changes to  a  change  foo.func_defs[0] , which is part of the  foo  object and persists between execution of the code in  foo . \n Now, compare this to the example from the documentation on  emulating the default argument behavior of other languages , such that the function signature defaults are used every time the function is executed: \n def foo(a, L=None):\n    if L is None:\n        L = []\n    L.append(a)\n    return L\n \n Taking  (1)  and  (2)  into account, one can see why this accomplishes the desired behavior: \n \n When the  foo  function object is instantiated,  foo.func_defs[0]  is set to  None , an immutable object. \n When the function is executed with defaults (with no parameter specified for  L  in the function call),  foo.func_defs[0]  ( None ) is available in the local scope as  L . \n Upon  L = [] , the assignment cannot succeed at  foo.func_defs[0] , because that attribute is read-only. \n Per  (1) ,  a new local variable also named  L  is created in the local scope  and used for the remainder of the function call.  foo.func_defs[0]  thus remains unchanged for future invocations of  foo . \n \n    ", "date_posted": "2020-08-27 20:44:25Z", "upvote": "\r\n            22\r\n        ", "accepted": "No", "user": {"stack_user_id": "2430549", "name": "HoldOffHunger", "reputation_score": "16.2k"}, "answer_comments": []}, {"stack_answer_id": "15133978", "answer_content": "\r\n A simple workaround using None \n\n >>> def bar(b, data=None):\n...     data = data or []\n...     data.append(b)\n...     return data\n... \n>>> bar(3)\n[3]\n>>> bar(3)\n[3]\n>>> bar(3)\n[3]\n>>> bar(3, [34])\n[34, 3]\n>>> bar(3, [34])\n[34, 3]\n \n    ", "date_posted": "2013-02-28 11:10:16Z", "upvote": "\r\n            21\r\n        ", "accepted": "No", "user": {"stack_user_id": "252135", "name": "hugo24", "reputation_score": "1,071"}, "answer_comments": [{"stack_answer_id": "15133978", "stack_answer_comment_id": "126670851", "comment_content": "This isn't an answer to the question.", "user_id": "None"}]}, {"stack_answer_id": "1139730", "answer_content": "\r\n It may be true that: \n\n \n Someone is using every language/library feature, and \n Switching the behavior here would be ill-advised, but \n \n\n it is entirely consistent to hold to both of the features above and still make another point: \n\n \n It is a confusing feature and it is unfortunate in Python. \n \n\n The other answers, or at least some of them either make points 1 and 2 but not 3, or make point 3 and downplay points 1 and 2.  But all three are true. \n\n It may be true that switching horses in midstream here would be asking for significant breakage, and that there could be more problems created by changing Python to intuitively handle Stefano's opening snippet. And it may be true that someone who knew Python internals well could explain a minefield of consequences.  However, \n\n The existing behavior is not Pythonic, and Python is successful because very little about the language violates the principle of least astonishment anywhere  near  this badly. It is a real problem, whether or not it would be wise to uproot it. It is a design flaw. If you understand the language much better by trying to trace out the behavior, I can say that C++ does all of this and more; you learn a lot by navigating, for instance, subtle pointer errors. But this is not Pythonic: people who care about Python enough to persevere in the face of this behavior are people who are drawn to the language because Python has far fewer surprises than other language. Dabblers and the curious become Pythonistas when they are astonished at how little time it takes to get something working--not because of a design fl--I mean, hidden logic puzzle--that cuts against the intuitions of programmers who are drawn to Python because it  Just Works . \n    ", "date_posted": "2009-07-16 19:17:59Z", "upvote": "\r\n            20\r\n        ", "accepted": "No", "user": {"stack_user_id": "116906", "name": "Christos Hayward", "reputation_score": "5,621"}, "answer_comments": [{"stack_answer_id": "1139730", "stack_answer_comment_id": "14994287", "comment_content": "-1 Although a defensible perspective, this not an answer, ", "user_id": "None"}, {"stack_answer_id": "1139730", "stack_answer_comment_id": "19435546", "comment_content": "So then, it is \"amazingly ignorant\" to say that in Python it would make more sense for a default argument of [] to remain [] every time the function is called?", "user_id": "None"}, {"stack_answer_id": "1139730", "stack_answer_comment_id": "19435596", "comment_content": "And it is ignorant to consider as an unfortunate idiom setting a default argument to None, and then in the body of the body of the function setting if argument == None: argument = []? Is it ignorant to consider this idiom unfortunate as often people want what a naive newcomer would expect, that if you assign f(argument = []), argument will automatically default to a value of []?", "user_id": "None"}, {"stack_answer_id": "1139730", "stack_answer_comment_id": "19436087", "comment_content": "But in Python, part of the spirit of the language is that you don't have to take too many deep dives; array.sort() works, and works  regardless of how little you understand about sorting, big-O, and constants. The beauty of Python in the array sorting mechanism, to give one of innumerable examples, is that you are not required to take a deep dive into internals. And to say it differently, the beauty of Python is that one is not ordinarily required to take a deep dive into implementation to get something that Just Works. And there is a workaround (...if argument == None: argument = []), FAIL.", "user_id": "None"}, {"stack_answer_id": "1139730", "stack_answer_comment_id": "28401661", "comment_content": "As a standalone, the statement ", "user_id": "None"}]}, {"stack_answer_id": "32535706", "answer_content": "\r\n I am going to demonstrate an alternative structure to pass a default list value to a function (it works equally well with dictionaries).   \n\n As others have extensively commented, the list parameter is bound to the function when it is defined as opposed to when it is executed.  Because lists and dictionaries are mutable, any alteration to this parameter will affect other calls to this function.  As a result, subsequent calls to the function will receive this shared list which may have been altered by any other calls to the function.  Worse yet, two parameters are using this function's shared parameter at the same time oblivious to the changes made by the other. \n\n Wrong Method (probably...) : \n\n def foo(list_arg=[5]):\n    return list_arg\n\na = foo()\na.append(6)\n>>> a\n[5, 6]\n\nb = foo()\nb.append(7)\n# The value of 6 appended to variable 'a' is now part of the list held by 'b'.\n>>> b\n[5, 6, 7]  \n\n# Although 'a' is expecting to receive 6 (the last element it appended to the list),\n# it actually receives the last element appended to the shared list.\n# It thus receives the value 7 previously appended by 'b'.\n>>> a.pop()             \n7\n \n\n You can verify that they are one and the same object by using  id : \n\n >>> id(a)\n5347866528\n\n>>> id(b)\n5347866528\n \n\n Per Brett Slatkin's \"Effective Python: 59 Specific Ways to Write Better Python\",  Item 20: Use  None  and Docstrings to specify dynamic default arguments  (p. 48) \n\n \n   The convention for achieving the desired result in Python is to\n  provide a default value of  None  and to document the actual behaviour\n  in the docstring. \n \n\n This implementation ensures that each call to the function either receives the default list or else the list passed to the function. \n\n Preferred Method : \n\n def foo(list_arg=None):\n   \"\"\"\n   :param list_arg:  A list of input values. \n                     If none provided, used a list with a default value of 5.\n   \"\"\"\n   if not list_arg:\n       list_arg = [5]\n   return list_arg\n\na = foo()\na.append(6)\n>>> a\n[5, 6]\n\nb = foo()\nb.append(7)\n>>> b\n[5, 7]\n\nc = foo([10])\nc.append(11)\n>>> c\n[10, 11]\n \n\n There may be legitimate use cases for the 'Wrong Method' whereby the programmer intended the default list parameter to be shared, but this is more likely the exception than the rule. \n    ", "date_posted": "2015-09-12 20:41:53Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "2411802", "name": "Alexander", "reputation_score": "98.5k"}, "answer_comments": []}, {"stack_answer_id": "9791799", "answer_content": "\r\n The solutions here are: \n\n \n Use  None  as your default value (or a nonce  object ), and switch on that to create your values at runtime; or \n Use a  lambda  as your default parameter, and call it within a try block to get the default value (this is the sort of thing that lambda abstraction is for). \n \n\n The second option is nice because users of the function can pass in a callable, which may be already existing (such as a  type ) \n    ", "date_posted": "2013-06-30 16:20:35Z", "upvote": "\r\n            17\r\n        ", "accepted": "No", "user": {"stack_user_id": "21640", "name": "Marcin", "reputation_score": "47.1k"}, "answer_comments": [{"stack_answer_id": "9791799", "stack_answer_comment_id": "126670870", "comment_content": "This doesn't answer the question.", "user_id": "None"}]}, {"stack_answer_id": "14336301", "answer_content": "\r\n You can get round this by replacing the object (and therefore the tie with the scope): \n\n def foo(a=[]):\n    a = list(a)\n    a.append(5)\n    return a\n \n\n Ugly, but it works. \n    ", "date_posted": "2013-01-15 11:02:03Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "734463", "name": "joedborg", "reputation_score": "16.6k"}, "answer_comments": [{"stack_answer_id": "14336301", "stack_answer_comment_id": "20074742", "comment_content": "This is a nice solution in cases where you're using automatic documentation generation software to document the types of arguments expected by the function.  Putting a=None and then setting a to [] if a is None doesn't help a reader understand at a glance what is expected.", "user_id": "None"}, {"stack_answer_id": "14336301", "stack_answer_comment_id": "83550838", "comment_content": "Cool idea: rebinding that name guarantees it can never be modified. I really like that.", "user_id": "None"}, {"stack_answer_id": "14336301", "stack_answer_comment_id": "88079491", "comment_content": "This is exactly the way to do it. Python doesn't make a copy of the parameter, so it's up to you to make the copy explicitly. Once you have a copy, it's yours to modify as you please without any unexpected side effects.", "user_id": "None"}, {"stack_answer_id": "14336301", "stack_answer_comment_id": "126670875", "comment_content": "This doesn't answer the question, though.", "user_id": "None"}]}, {"stack_answer_id": "25797695", "answer_content": "\r\n When we do this: \n\n def foo(a=[]):\n    ...\n \n\n ... we assign the argument  a  to an  unnamed  list, if the caller does not pass the value of a. \n\n To make things simpler for this discussion, let's temporarily give the unnamed list a name. How about  pavlo  ? \n\n def foo(a=pavlo):\n   ...\n \n\n At any time, if the caller doesn't tell us what  a  is, we reuse  pavlo . \n\n If  pavlo  is mutable (modifiable), and  foo  ends up modifying it, an effect we notice the next time  foo  is called without specifying  a . \n\n So this is what you see (Remember,  pavlo  is initialized to []): \n\n  >>> foo()\n [5]\n \n\n Now,  pavlo  is [5]. \n\n Calling  foo()  again modifies  pavlo  again: \n\n >>> foo()\n[5, 5]\n \n\n Specifying  a  when calling  foo()  ensures  pavlo  is not touched. \n\n >>> ivan = [1, 2, 3, 4]\n>>> foo(a=ivan)\n[1, 2, 3, 4, 5]\n>>> ivan\n[1, 2, 3, 4, 5]\n \n\n So,  pavlo  is still  [5, 5] . \n\n >>> foo()\n[5, 5, 5]\n \n    ", "date_posted": "2014-09-11 22:05:43Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "1639436", "name": "Saish", "reputation_score": "501"}, "answer_comments": []}, {"stack_answer_id": "28354667", "answer_content": "\r\n I sometimes exploit this behavior as an alternative to the following pattern: \n\n singleton = None\n\ndef use_singleton():\n    global singleton\n\n    if singleton is None:\n        singleton = _make_singleton()\n\n    return singleton.use_me()\n \n\n If  singleton  is only used by  use_singleton , I like the following pattern as a replacement: \n\n # _make_singleton() is called only once when the def is executed\ndef use_singleton(singleton=_make_singleton()):\n    return singleton.use_me()\n \n\n I've used this for instantiating client classes that access external resources, and also for creating dicts or lists for memoization. \n\n Since I don't think this pattern is well known, I do put a short comment in to guard against future misunderstandings. \n    ", "date_posted": "2015-02-06 12:56:53Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "4513367", "name": "bgreen-litl", "reputation_score": "414"}, "answer_comments": [{"stack_answer_id": "28354667", "stack_answer_comment_id": "45063880", "comment_content": "I prefer to add a decorator for memoization, and put the memoization cache onto the function object itself.", "user_id": "78374"}, {"stack_answer_id": "28354667", "stack_answer_comment_id": "81702357", "comment_content": "This example doesn't replace the more complex pattern you show, because you call ", "user_id": "None"}]}, {"stack_answer_id": "54018161", "answer_content": "\r\n Every other answer explains why this is actually a nice and desired behavior, or why you shouldn't be needing this anyway. Mine is for those stubborn ones who want to exercise their right to bend the language to their will, not the other way around. \n We will \"fix\" this behavior with a decorator that will copy the default value instead of reusing the same instance for each positional argument left at its default value. \n\n import inspect\nfrom copy import deepcopy  # copy would fail on deep arguments like nested dicts\n\ndef sanify(function):\n    def wrapper(*a, **kw):\n        # store the default values\n        defaults = inspect.getargspec(function).defaults # for python2\n        # construct a new argument list\n        new_args = []\n        for i, arg in enumerate(defaults):\n            # allow passing positional arguments\n            if i in range(len(a)):\n                new_args.append(a[i])\n            else:\n                # copy the value\n                new_args.append(deepcopy(arg))\n        return function(*new_args, **kw)\n    return wrapper\n \n Now let's redefine our function using this decorator: \n @sanify\ndef foo(a=[]):\n    a.append(5)\n    return a\n\nfoo() # '[5]'\nfoo() # '[5]' -- as desired\n \n This is particularly neat for functions that take multiple arguments. Compare: \n # the 'correct' approach\ndef bar(a=None, b=None, c=None):\n    if a is None:\n        a = []\n    if b is None:\n        b = []\n    if c is None:\n        c = []\n    # finally do the actual work\n \n with \n # the nasty decorator hack\n@sanify\ndef bar(a=[], b=[], c=[]):\n    # wow, works right out of the box!\n \n It's important to note that the above solution breaks if you try to use keyword args, like so: \n foo(a=[4])\n \n The decorator could be adjusted to allow for that, but we leave this as an exercise for the reader ;) \n    ", "date_posted": "2022-03-31 10:09:47Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "6919631", "name": "Przemek D", "reputation_score": "624"}, "answer_comments": [{"stack_answer_id": "54018161", "stack_answer_comment_id": "126670698", "comment_content": "This also breaks if the default argument is deep, like ", "user_id": "None"}, {"stack_answer_id": "54018161", "stack_answer_comment_id": "126698761", "comment_content": "@Flimm I find your phrase \"this breaks\" rather unfair as it seems to suggests the entire concept is somehow flawed, while it is in fact only a minor detail of the implementation. But thank you for the comment nonetheless, I shall edit and improve my answer.", "user_id": "None"}]}, {"stack_answer_id": "17782210", "answer_content": "\r\n This \"bug\" gave me a lot of overtime work hours! But I'm beginning to see a potential use of it (but I would have liked it to be at the execution time, still) \n\n I'm gonna give you what I see as a useful example. \n\n def example(errors=[]):\n    # statements\n    # Something went wrong\n    mistake = True\n    if mistake:\n        tryToFixIt(errors)\n        # Didn't work.. let's try again\n        tryToFixItAnotherway(errors)\n        # This time it worked\n    return errors\n\ndef tryToFixIt(err):\n    err.append('Attempt to fix it')\n\ndef tryToFixItAnotherway(err):\n    err.append('Attempt to fix it by another way')\n\ndef main():\n    for item in range(2):\n        errors = example()\n    print '\\n'.join(errors)\n\nmain()\n \n\n prints the following \n\n Attempt to fix it\nAttempt to fix it by another way\nAttempt to fix it\nAttempt to fix it by another way\n \n    ", "date_posted": "2013-07-23 10:07:58Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "618099", "name": "Norfeldt", "reputation_score": "6,648"}, "answer_comments": [{"stack_answer_id": "17782210", "stack_answer_comment_id": "119658319", "comment_content": "Your example doesn't seem very realistic.  Why would you pass ", "user_id": "None"}]}, {"stack_answer_id": "46796007", "answer_content": "\r\n This is not a design flaw . Anyone who trips over this is doing something wrong. \n\n There are 3 cases I see where you might run into this problem: \n\n \n You intend to modify the argument as a side effect of the function. In this case it  never makes sense  to have a default argument. The only exception is when you're abusing the argument list to have function attributes, e.g.  cache={} , and you wouldn't be expected to call the function with an actual argument at all. \n You intend to leave the argument unmodified, but you accidentally  did  modify it. That's a bug, fix it. \n You intend to modify the argument for use inside the function, but didn't expect the modification to be viewable outside of the function. In that case you need to make a  copy  of the argument, whether it was the default or not! Python is not a call-by-value language so it doesn't make the copy for you, you need to be explicit about it. \n \n\n The example in the question could fall into category 1 or 3. It's odd that it both modifies the passed list and returns it; you should pick one or the other. \n    ", "date_posted": "2017-10-17 18:04:59Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "5987", "name": "Mark Ransom", "reputation_score": "289k"}, "answer_comments": [{"stack_answer_id": "46796007", "stack_answer_comment_id": "80540093", "comment_content": "\"Doing something wrong\" is the diagnosis. That said, I think there are times were =None pattern is useful, but generally you don't want to modify if passed a mutable in that case (2). The ", "user_id": "None"}, {"stack_answer_id": "46796007", "stack_answer_comment_id": "119639032", "comment_content": "Totally disagree, its absolutely a design flaw in many cases and not the programmer doing something wong", "user_id": "None"}, {"stack_answer_id": "46796007", "stack_answer_comment_id": "119654728", "comment_content": "I have never run into the problem of the OP even though it is so highly upvoted, because having a default argument be mutable is weird design to me.", "user_id": "None"}, {"stack_answer_id": "46796007", "stack_answer_comment_id": "119879935", "comment_content": "@MarkRansom If we take it as given that side effects are OK, there's nothing wrong with modifying a default argument as part of a side-effect-ful function. Let's say you have a function that does ", "user_id": "None"}, {"stack_answer_id": "46796007", "stack_answer_comment_id": "119970601", "comment_content": "@MarkRansom No, they're not; for example, ", "user_id": "None"}]}, {"stack_answer_id": "30447095", "answer_content": "\r\n Just change the function to be: \n\n def notastonishinganymore(a = []): \n    '''The name is just a joke :)'''\n    a = a[:]\n    a.append(5)\n    return a\n \n    ", "date_posted": "2018-09-06 21:29:08Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "4785185", "name": "Prune", "reputation_score": "75.6k"}, "answer_comments": [{"stack_answer_id": "30447095", "stack_answer_comment_id": "126670893", "comment_content": "This doesn't answer the question, though.", "user_id": "None"}]}, {"stack_answer_id": "53792207", "answer_content": "\r\n TLDR: Define-time defaults are consistent and strictly more expressive. \n\n \n\n Defining a function affects two scopes: the defining scope  containing  the function, and the execution  scope  contained by  the function. While it is pretty clear how blocks map to scopes, the question is where  def <name>(<args=defaults>):  belongs to: \n\n ...                           # defining scope\ndef name(parameter=default):  # ???\n    ...                       # execution scope\n \n\n The  def name  part  must  evaluate in the defining scope - we want  name  to be available there, after all. Evaluating the function only inside itself would make it inaccessible. \n\n Since  parameter  is a constant name, we can \"evaluate\" it at the same time as  def name . This also has the advantage it produces the function with a known signature as  name(parameter=...): , instead of a bare  name(...): . \n\n Now, when to evaluate  default ? \n\n Consistency already says \"at definition\": everything else of  def <name>(<args=defaults>):  is best evaluated at definition as well. Delaying parts of it would be the astonishing choice. \n\n The two choices are not equivalent, either: If  default  is evaluated at definition time, it  can still  affect execution time. If  default  is evaluated at execution time, it  cannot  affect definition time. Choosing \"at definition\" allows expressing both cases, while choosing \"at execution\" can express only one: \n\n def name(parameter=defined):  # set default at definition time\n    ...\n\ndef name(parameter=default):     # delay default until execution time\n    parameter = default if parameter is None else parameter\n    ...\n \n    ", "date_posted": "2019-08-08 07:39:43Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "5349916", "name": "MisterMiyagi", "reputation_score": "38.6k"}, "answer_comments": [{"stack_answer_id": "53792207", "stack_answer_comment_id": "102525948", "comment_content": "\"Consistency already says \"at definition\": everything else of ", "user_id": "None"}, {"stack_answer_id": "53792207", "stack_answer_comment_id": "102527403", "comment_content": "@LarsH Function definitions are ", "user_id": "None"}, {"stack_answer_id": "53792207", "stack_answer_comment_id": "102560686", "comment_content": "OK, creating a function means evaluation in some sense, but obviously not in the sense that every expression within it is evaluated at the time of definition. Most aren't. It's not clear to me in what sense the signature is especially \"evaluated\" at definition time any more than the function body is \"evaluated\" (parsed into a suitable representation); whereas expressions in the function body are clearly not evaluated in the full sense. From this point of view, consistency would say that expressions in the signature shouldn't be \"fully\" evaluated either.", "user_id": "None"}, {"stack_answer_id": "53792207", "stack_answer_comment_id": "102560689", "comment_content": "I don't mean that you're wrong, only that your conclusion doesn't follow from consistency alone.", "user_id": "None"}, {"stack_answer_id": "53792207", "stack_answer_comment_id": "102560884", "comment_content": "@LarsH Defaults are neither part of the body, nor am I claiming that consistency is the only criteria. Can you make a suggestion how to clarify the answer?", "user_id": "None"}]}, {"stack_answer_id": "18372696", "answer_content": "\r\n I think the answer to this question lies in how python pass data to parameter (pass by value or by reference), not mutability or how python handle the \"def\" statement. \n\n A brief introduction. First, there are two type of data types in python, one is simple elementary data type, like numbers, and another data type is objects. Second, when passing data to parameters, python pass elementary data type by value, i.e., make a local copy of the value to a local variable, but pass object by reference, i.e., pointers to the object. \n\n Admitting the above two points, let's explain what happened to the python code. It's only because of passing by reference for objects, but has nothing to do with mutable/immutable, or arguably the fact that \"def\" statement is executed only once when it is defined. \n\n [] is an object, so python pass the reference of [] to  a , i.e.,  a  is only a pointer to [] which lies in memory as an object. There is only one copy of [] with, however, many references to it. For the first foo(), the list [] is changed to  1  by append method. But Note that there is only one copy of the list object and this object now becomes  1 . When running the second foo(), what effbot webpage says (items is not evaluated any more) is wrong.  a  is evaluated to be the list object, although now the content of the object is  1 . This is the effect of passing by reference! The result of foo(3) can be easily derived in the same way. \n\n To further validate my answer, let's take a look at two additional codes. \n\n ====== No. 2 ======== \n\n def foo(x, items=None):\n    if items is None:\n        items = []\n    items.append(x)\n    return items\n\nfoo(1)  #return [1]\nfoo(2)  #return [2]\nfoo(3)  #return [3]\n \n\n []  is an object, so is  None  (the former is mutable while the latter is immutable. But the mutability has nothing to do with the question). None is somewhere in the space but we know it's there and there is only one copy of None there. So every time foo is invoked, items is evaluated (as opposed to some answer that it is only evaluated once) to be None, to be clear, the reference (or the address) of None. Then in the foo, item is changed to [], i.e., points to another object which has a different address.  \n\n ====== No. 3 ======= \n\n def foo(x, items=[]):\n    items.append(x)\n    return items\n\nfoo(1)    # returns [1]\nfoo(2,[]) # returns [2]\nfoo(3)    # returns [1,3]\n \n\n The invocation of foo(1) make items point to a list object [] with an address, say, 11111111. the content of the list is changed to  1  in the foo function in the sequel, but the address is not changed, still 11111111. Then foo(2,[]) is coming. Although the [] in foo(2,[]) has the same content as the default parameter [] when calling foo(1), their address are different! Since we provide the parameter explicitly,  items  has to take the address of this new  [] , say 2222222, and return it after making some change. Now foo(3) is executed. since only  x  is provided, items has to take its default value again. What's the default value? It is set when defining the foo function: the list object located in 11111111. So the items is evaluated to be the address 11111111 having an element 1. The list located at 2222222 also contains one element 2, but it is not pointed by items any more. Consequently, An append of 3 will make  items  [1,3].  \n\n From the above explanations, we can see that the  effbot  webpage recommended in the accepted answer failed to give a relevant answer to this question. What is more, I think a point in the effbot webpage is wrong. I think the code regarding the UI.Button is correct: \n\n for i in range(10):\n    def callback():\n        print \"clicked button\", i\n    UI.Button(\"button %s\" % i, callback)\n \n\n Each button can hold a distinct callback function which will display different value of  i . I can provide an example to show this: \n\n x=[]\nfor i in range(10):\n    def callback():\n        print(i)\n    x.append(callback) \n \n\n If we execute  x[7]()  we'll get 7 as expected, and  x[9]()  will gives 9, another value of  i . \n    ", "date_posted": "2013-08-22 05:58:41Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "2384994", "name": "user2384994", "reputation_score": "1,669"}, "answer_comments": [{"stack_answer_id": "18372696", "stack_answer_comment_id": "28304217", "comment_content": "Your last point is wrong. Try it and you'll see that ", "user_id": "None"}, {"stack_answer_id": "18372696", "stack_answer_comment_id": "42551885", "comment_content": "\"python pass elementary data type by value, i.e., make a local copy of the value to a local variable\" is completely incorrect. I am astonished that someone can obviously know Python very well, yet have such horrible misunderstanding of fundamentals. :-(", "user_id": "None"}]}], "user": {"stack_user_id": "78374", "name": "Stefano Borini", "reputation_score": "133k"}, "question_comments": [{"stack_question_id": "1132941", "stack_question_comment_id": "11530621", "comment_content": "Complementary question - ", "user_id": "None"}, {"stack_question_id": "1132941", "stack_question_comment_id": "73589342", "comment_content": "I have not doubt mutable arguments violate least astonishment principle for an average person, and I have seen beginners stepping there, then heroically replacing mailing lists with mailing tuples. Nevertheless mutable arguments are still in line with Python Zen (Pep 20) and falls into \"obvious for Dutch\" (understood/exploited by hard core python programmers) clause.  The recommended  workaround with doc string is the best, yet resistance to doc strings and any (written) docs is not so uncommon nowadays. Personally, I would prefer a decorator (say @fixed_defaults).", "user_id": "None"}, {"stack_question_id": "1132941", "stack_question_comment_id": "75640338", "comment_content": "My argument when I come across this is:  \"Why do you need to create a function that returns a mutable that could optionally be a mutable you would pass to the function?  Either it alters a mutable or creates a new one.  Why do you need to do both with one function?  And why should the interpreter be rewritten to allow you to do that without adding three lines to your code?\" Because we are talking about rewriting the way the interpreter handles function definitions and evocations here.  That's a lot to do for a barely necessary use case.", "user_id": "None"}, {"stack_question_id": "1132941", "stack_question_comment_id": "76883169", "comment_content": "\"Python novices would expect this function to always return a list with only one element: ", "user_id": "None"}, {"stack_question_id": "1132941", "stack_question_comment_id": "98233496", "comment_content": "This question asks ", "user_id": "None"}]},
{"stack_question_id": "240178", "question_title": "List of lists changes reflected across sublists unexpectedly", "question_content": "\r\n                I created a list of lists:\nxs = [[1] * 4] * 3\n\n# xs == [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]  \n\nThen, I changed one of the innermost values:\nxs[0][0] = 5\n\n# xs == [[5, 1, 1, 1], [5, 1, 1, 1], [5, ...\r\n", "question_url": "/questions/240178/list-of-lists-changes-reflected-across-sublists-unexpectedly", "date_posted": "Oct 27, 2008 at 14:57", "upvote": "8", "view": "6", "tags": ["python", "list", "nested-lists", "mutable"], "answers_count": "1", "answers": [{"stack_answer_id": "240205", "answer_content": "\r\n When you write  [x]*3  you get, essentially, the list  [x, x, x] . That is, a list with 3 references to the same  x . When you then modify this single  x  it is visible via all three references to it: \n x = [1] * 4\nxs = [x] * 3\nprint(f\"id(x): {id(x)}\")\n# id(x): 140560897920048\nprint(\n    f\"id(xs[0]): {id(xs[0])}\\n\"\n    f\"id(xs[1]): {id(xs[1])}\\n\"\n    f\"id(xs[2]): {id(xs[2])}\"\n)\n# id(xs[0]): 140560897920048\n# id(xs[1]): 140560897920048\n# id(xs[2]): 140560897920048\n\nx[0] = 42\nprint(f\"x: {x}\")\n# x: [42, 1, 1, 1]\nprint(f\"xs: {xs}\")\n# xs: [[42, 1, 1, 1], [42, 1, 1, 1], [42, 1, 1, 1]]\n \n To fix it, you need to make sure that you create a new list at each position. One way to do it is \n [[1]*4 for _ in range(3)]\n \n which will reevaluate  [1]*4  each time instead of evaluating it once and making 3 references to 1 list. \n \n You might wonder why  *  can't make independent objects the way the list comprehension does. That's because the multiplication operator  *  operates on objects, without seeing expressions. When you use  *  to multiply  [[1] * 4]  by 3,  *  only sees the 1-element list  [[1] * 4]  evaluates to, not the  [[1] * 4  expression text.  *  has no idea how to make copies of that element, no idea how to reevaluate  [[1] * 4] , and no idea you even want copies, and in general, there might not even be a way to copy the element. \n The only option  *  has is to make new references to the existing sublist instead of trying to make new sublists. Anything else would be inconsistent or require major redesigning of fundamental language design decisions. \n In contrast, a list comprehension reevaluates the element expression on every iteration.  [[1] * 4 for n in range(3)]  reevaluates  [1] * 4  every time for the same reason  [x**2 for x in range(3)]  reevaluates  x**2  every time. Every evaluation of  [1] * 4  generates a new list, so the list comprehension does what you wanted. \n Incidentally,  [1] * 4  also doesn't copy the elements of  [1] , but that doesn't matter, since integers are immutable. You can't do something like  1.value = 2  and turn a 1 into a 2. \n    ", "date_posted": "2022-05-22 19:55:56Z", "upvote": "\r\n            754\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": [{"stack_answer_id": "240205", "stack_answer_comment_id": "48862076", "comment_content": "I am surprised that no body points out  that, the answer here is misleading. ", "user_id": "None"}, {"stack_answer_id": "240205", "stack_answer_comment_id": "48871095", "comment_content": "Technically, it's still correct. ", "user_id": "None"}, {"stack_answer_id": "240205", "stack_answer_comment_id": "60950287", "comment_content": "@Allanqunzi you are wrong. Do ", "user_id": "None"}, {"stack_answer_id": "240205", "stack_answer_comment_id": "126691081", "comment_content": "can anyone find documents about the ", "user_id": "None"}, {"stack_answer_id": "240205", "stack_answer_comment_id": "127789351", "comment_content": "@LeiYang It's listed under ", "user_id": "None"}]}, {"stack_answer_id": "18454568", "answer_content": "\r\n size = 3\nmatrix_surprise = [[0] * size] * size\nmatrix = [[0]*size for _ in range(size)]\n \n Live visualization  using Python Tutor: \n \n    ", "date_posted": "2021-06-18 17:12:23Z", "upvote": "\r\n            168\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": [{"stack_answer_id": "18454568", "stack_answer_comment_id": "76707168", "comment_content": "So, why if we write matrix= [[x] * 2] doesn't make 2 elemnts for the same object like the example you describe, it seems to be the same concept, what am i missing?", "user_id": "None"}, {"stack_answer_id": "18454568", "stack_answer_comment_id": "76720889", "comment_content": "@AhmedMohamed Indeed it does make a list with two elements of the exact same object that ", "user_id": "None"}, {"stack_answer_id": "18454568", "stack_answer_comment_id": "76721203", "comment_content": "@nadrimajstor so why the change in matrix[0] doesn't affect matrix[1] like the example above with 2d matrix.", "user_id": "None"}, {"stack_answer_id": "18454568", "stack_answer_comment_id": "76723575", "comment_content": "@AhmedMohamed Surprise come when you make a \"copy\" of mutable sequence (in our example it is a ", "user_id": "None"}, {"stack_answer_id": "18454568", "stack_answer_comment_id": "76724009", "comment_content": "@AhmedMohamed Take a look at ", "user_id": "None"}]}, {"stack_answer_id": "240215", "answer_content": "\r\n Actually, this is exactly what you would expect. Let's decompose what is happening here: \n You write \n lst = [[1] * 4] * 3\n \n This is equivalent to: \n lst1 = [1]*4\nlst = [lst1]*3\n \n This means  lst  is a list with 3 elements all pointing to  lst1 . This means the two following lines are equivalent: \n lst[0][0] = 5\nlst1[0] = 5\n \n As  lst[0]  is nothing but  lst1 . \n To obtain the desired behavior, you can use a list comprehension: \n lst = [ [1]*4 for n in range(3) ]\n \n In this case, the expression is re-evaluated for each  n , leading to a different list. \n    ", "date_posted": "2021-06-18 16:49:18Z", "upvote": "\r\n            70\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": [{"stack_answer_id": "240215", "stack_answer_comment_id": "75062949", "comment_content": "Just a small addition to the nice answer here: it's evident that you're dealing with same object if you do ", "user_id": "None"}, {"stack_answer_id": "240215", "stack_answer_comment_id": "128207126", "comment_content": "Doesn't explain why modifying a 1d list causes a copy while a 2d list doesn't cause any copy", "user_id": "None"}]}, {"stack_answer_id": "240202", "answer_content": "\r\n [[1] * 4] * 3\n \n\n or even: \n\n [[1, 1, 1, 1]] * 3\n \n\n Creates a list that references the internal  [1,1,1,1]  3 times - not three copies of the inner list, so any time you modify the list (in any position), you'll see the change three times. \n\n It's the same as this example: \n\n >>> inner = [1,1,1,1]\n>>> outer = [inner]*3\n>>> outer\n[[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]\n>>> inner[0] = 5\n>>> outer\n[[5, 1, 1, 1], [5, 1, 1, 1], [5, 1, 1, 1]]\n \n\n where it's probably a little less surprising. \n    ", "date_posted": "2017-01-14 07:54:00Z", "upvote": "\r\n            47\r\n        ", "accepted": "No", "user": {"stack_user_id": "4952130", "name": "Dimitris Fasarakis Hilliard", "reputation_score": "139k"}, "answer_comments": [{"stack_answer_id": "240202", "stack_answer_comment_id": "103503", "comment_content": "You can use the \"is\" operator to discover this. ls[0] is ls[1] returns True.", "user_id": "None"}]}, {"stack_answer_id": "43246520", "answer_content": "\r\n my_list = [[1]*4] * 3  creates one list object  [1,1,1,1]  in memory and copies its reference 3 times over. This is equivalent to  obj = [1,1,1,1]; my_list = [obj]*3 . Any modification to  obj  will be reflected at three places, wherever  obj  is referenced in the list.\nThe right statement would be: \n my_list = [[1]*4 for _ in range(3)]\n \n or \n my_list = [[1 for __ in range(4)] for _ in range(3)]\n \n Important thing to note here  is that the  *  operator is  mostly  used to create a  list of literals . Although  1  is immutable,  obj = [1]*4  will still create a list of  1  repeated 4 times over to form  [1,1,1,1] . But if any reference to an immutable object is made, the object is overwritten with a new one. \n This means if we do  obj[1] = 42 , then  obj  will become  [1,42,1,1]   not   [42,42,42,42]  as some may assume. This can also be verified: \n >>> my_list = [1]*4\n>>> my_list\n[1, 1, 1, 1]\n\n>>> id(my_list[0])\n4522139440\n>>> id(my_list[1])  # Same as my_list[0]\n4522139440\n \n \n >>> my_list[1] = 42  # Since my_list[1] is immutable, this operation overwrites my_list[1] with a new object changing its id.\n>>> my_list\n[1, 42, 1, 1]\n\n>>> id(my_list[0])\n4522139440\n>>> id(my_list[1])  # id changed\n4522140752\n>>> id(my_list[2])  # id still same as my_list[0], still referring to value `1`.\n4522139440\n \n    ", "date_posted": "2021-06-18 16:32:37Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": [{"stack_answer_id": "43246520", "stack_answer_comment_id": "90015086", "comment_content": "It's not about literals. ", "user_id": "None"}]}, {"stack_answer_id": "30898048", "answer_content": "\r\n Alongside the accepted answer that explained the problem correctly, instead of creating a list with duplicated elements using following code: \n [[1]*4 for _ in range(3)]\n \n Also, you can use  itertools.repeat()  to create an iterator object of repeated elements: \n >>> a = list(repeat(1,4))\n[1, 1, 1, 1]\n>>> a[0] = 5\n>>> a\n[5, 1, 1, 1]\n \n P.S. If you're using NumPy and you only want to create an array of ones or zeroes you can use  np.ones  and  np.zeros  and/or for other numbers use  np.repeat : \n >>> import numpy as np\n>>> np.ones(4)\narray([1., 1., 1., 1.])\n>>> np.ones((4, 2))\narray([[1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.]])\n>>> np.zeros((4, 2))\narray([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]])\n>>> np.repeat([7], 10)\narray([7, 7, 7, 7, 7, 7, 7, 7, 7, 7])\n \n    ", "date_posted": "2021-06-18 17:26:13Z", "upvote": "\r\n            10\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": []}, {"stack_answer_id": "36452923", "answer_content": "\r\n Python containers contain references to other objects. See this example: \n\n >>> a = []\n>>> b = [a]\n>>> b\n[[]]\n>>> a.append(1)\n>>> b\n[[1]]\n \n\n In this  b  is a list that contains one item that is a reference to list  a . The list  a  is mutable. \n\n The multiplication of a list by an integer is equivalent to adding the list to itself multiple times (see  common sequence operations ). So continuing with the example: \n\n >>> c = b + b\n>>> c\n[[1], [1]]\n>>>\n>>> a[0] = 2\n>>> c\n[[2], [2]]\n \n\n We can see that the list  c  now contains two references to list  a  which is equivalent to  c = b * 2 . \n\n Python FAQ also contains explanation of this behavior:  How do I create a multidimensional list? \n    ", "date_posted": "2016-04-06 13:40:43Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "3185929", "name": "Zbyn\u011bk Winkler", "reputation_score": "1,043"}, "answer_comments": []}, {"stack_answer_id": "30759580", "answer_content": "\r\n Let's rewrite your code in the following way: \n x = 1\ny = [x]\nz = y * 4\n\nmy_list = [z] * 3\n \n Then having this, run the following code to make everything more clear. What the code does is basically print the  id s of the obtained objects, which \n \n Return[s] the \u201cidentity\u201d of an object \n \n and will help us identify them and analyse what happens: \n print(\"my_list:\")\nfor i, sub_list in enumerate(my_list):\n    print(\"\\t[{}]: {}\".format(i, id(sub_list)))\n    for j, elem in enumerate(sub_list):\n        print(\"\\t\\t[{}]: {}\".format(j, id(elem)))\n \n And you will get the following output: \n x: 1\ny: [1]\nz: [1, 1, 1, 1]\nmy_list:\n    [0]: 4300763792\n        [0]: 4298171528\n        [1]: 4298171528\n        [2]: 4298171528\n        [3]: 4298171528\n    [1]: 4300763792\n        [0]: 4298171528\n        [1]: 4298171528\n        [2]: 4298171528\n        [3]: 4298171528\n    [2]: 4300763792\n        [0]: 4298171528\n        [1]: 4298171528\n        [2]: 4298171528\n        [3]: 4298171528\n \n \n So now let's go step-by-step. You have  x  which is  1 , and a single element list  y  containing  x . Your first step is  y * 4  which will get you a new list  z , which is basically  [x, x, x, x] , i.e. it creates a new list which will have 4 elements, which are references to the initial  x  object. The next step is pretty similar. You basically do  z * 3 , which is  [[x, x, x, x]] * 3  and returns  [[x, x, x, x], [x, x, x, x], [x, x, x, x]] , for the same reason as for the first step. \n    ", "date_posted": "2021-06-18 16:36:25Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": []}, {"stack_answer_id": "62497944", "answer_content": "\r\n I am adding my answer to explain the same diagrammatically. \n The way you created the 2D, creates a shallow list \n arr = [[0]*cols]*row\n \n Instead, if you want to update the elements of the list, you should use \n rows, cols = (5, 5) \narr = [[0 for i in range(cols)] for j in range(rows)] \n \n Explanation : \n One can create a list using: \n arr = [0]*N \n \n or \n arr = [0 for i in range(N)] \n \n In the first case all the indices of the array point to the same integer object \n \n and when you assign a value to a particular index, a new int object is created, for example  arr[4] = 5  creates \n \n Now let us see what happens when we create a list of list, in this case, all the elements of our top list will point to the same list \n \n And if you update the value of any index a new int object will be created. But since all the top-level list indexes are pointing at the same list, all the rows will look the same. And you will get the feeling that updating an element is updating all the elements in that column. \n \n Credits:  Thanks to  Pranav Devarakonda  for the easy explanation  here \n    ", "date_posted": "2022-05-19 09:56:29Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "4621513", "name": "mkrieger1", "reputation_score": "15.4k"}, "answer_comments": []}, {"stack_answer_id": "37804636", "answer_content": "\r\n In simple words this is happening because in python everything works  by reference , so when you create a list of list that way you basically end up with such problems. \n\n To solve your issue you can do either one of them:\n1. Use numpy array  documentation for numpy.empty \n2. Append the list as you get to a list.\n3. You can also use dictionary if you want   \n    ", "date_posted": "2016-06-14 06:36:52Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "5801215", "name": "Neeraj Komuravalli", "reputation_score": "176"}, "answer_comments": []}, {"stack_answer_id": "36823796", "answer_content": "\r\n Everyone is explaining what is happening. I'll suggest one way to solve it: \n my_list = [[1 for i in range(4)] for j in range(3)]\n\nmy_list[0][0] = 5\nprint(my_list)\n \n And then you get: \n [[5, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]\n \n    ", "date_posted": "2021-06-18 16:39:24Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": []}, {"stack_answer_id": "57426328", "answer_content": "\r\n @spelchekr from  Python list multiplication: [[...]]*3 makes 3 lists which mirror each other when modified  and I had the same question about\n\"Why does only the outer  *3  create more references while the inner one doesn't? Why isn't it all 1s?\" \n li = [0] * 3\nprint([id(v) for v in li])  # [140724141863728, 140724141863728, 140724141863728]\nli[0] = 1\nprint([id(v) for v in li])  # [140724141863760, 140724141863728, 140724141863728]\nprint(id(0))  # 140724141863728\nprint(id(1))  # 140724141863760\nprint(li)     # [1, 0, 0]\n\nma = [[0]*3] * 3  # mainly discuss inner & outer *3 here\nprint([id(li) for li in ma])  # [1987013355080, 1987013355080, 1987013355080]\nma[0][0] = 1\nprint([id(li) for li in ma])  # [1987013355080, 1987013355080, 1987013355080]\nprint(ma)  # [[1, 0, 0], [1, 0, 0], [1, 0, 0]]\n \n Here is my explanation after trying the code above: \n \n The inner  *3  also creates references, but its references are immutable, something like  [&0, &0, &0] , then when you change  li[0] , you can't change any underlying reference of const int  0 , so you can just change the reference address into the new one  &1 ; \n while  ma = [&li, &li, &li]  and  li  is mutable, so when you call  ma[0][0] = 1 ,  ma[0][0]  is equal to  &li[0] , so all the  &li  instances will change its 1st address into  &1 . \n \n    ", "date_posted": "2021-06-18 17:02:12Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": []}, {"stack_answer_id": "38866487", "answer_content": "\r\n Trying to explain it more descriptively, \n\n Operation 1: \n\n x = [[0, 0], [0, 0]]\nprint(type(x)) # <class 'list'>\nprint(x) # [[0, 0], [0, 0]]\n\nx[0][0] = 1\nprint(x) # [[1, 0], [0, 0]]\n \n\n Operation 2: \n\n y = [[0] * 2] * 2\nprint(type(y)) # <class 'list'>\nprint(y) # [[0, 0], [0, 0]]\n\ny[0][0] = 1\nprint(y) # [[1, 0], [1, 0]]\n \n\n Noticed why doesn't modifying the first element of the first list didn't modify the second element of each list? That's because  [0] * 2  really is a list of two numbers, and a reference to 0 cannot be modified. \n\n If you want to create clone copies, try Operation 3: \n\n import copy\ny = [0] * 2   \nprint(y)   # [0, 0]\n\ny = [y, copy.deepcopy(y)]  \nprint(y) # [[0, 0], [0, 0]]\n\ny[0][0] = 1\nprint(y) # [[1, 0], [0, 0]]\n \n\n another interesting way to create clone copies, Operation 4: \n\n import copy\ny = [0] * 2\nprint(y) # [0, 0]\n\ny = [copy.deepcopy(y) for num in range(1,5)]\nprint(y) # [[0, 0], [0, 0], [0, 0], [0, 0]]\n\ny[0][0] = 5\nprint(y) # [[5, 0], [0, 0], [0, 0], [0, 0]]\n \n    ", "date_posted": "2016-08-10 07:29:38Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "2285848", "name": "Adil Abbasi", "reputation_score": "3,101"}, "answer_comments": []}, {"stack_answer_id": "38397772", "answer_content": "\r\n By using the inbuilt list function you can do like this \n\n a\nout:[[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]\n#Displaying the list\n\na.remove(a[0])\nout:[[1, 1, 1, 1], [1, 1, 1, 1]]\n# Removed the first element of the list in which you want altered number\n\na.append([5,1,1,1])\nout:[[1, 1, 1, 1], [1, 1, 1, 1], [5, 1, 1, 1]]\n# append the element in the list but the appended element as you can see is appended in last but you want that in starting\n\na.reverse()\nout:[[5, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]\n#So at last reverse the whole list to get the desired list\n \n    ", "date_posted": "2016-07-25 09:09:59Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "5230702", "name": "Anand Tripathi", "reputation_score": "12.4k"}, "answer_comments": [{"stack_answer_id": "38397772", "stack_answer_comment_id": "92685565", "comment_content": "Note, fourth step can be dropped if you make second step: ", "user_id": "None"}]}, {"stack_answer_id": "64489659", "answer_content": "\r\n I arrived here because I was looking to see how I could nest an arbitrary number of lists. There are a lot of explanations and specific examples above, but you can generalize N dimensional list of lists of lists of ... with the following recursive function: \n import copy\n\ndef list_ndim(dim, el=None, init=None):\n    if init is None:\n        init = el\n\n    if len(dim)> 1:\n        return list_ndim(dim[0:-1], None, [copy.copy(init) for x in range(dim[-1])])\n\n    return [copy.deepcopy(init) for x in range(dim[0])]\n \n You make your first call to the function like this: \n dim = (3,5,2)\nel = 1.0\nl = list_ndim(dim, el)\n \n where  (3,5,2)  is a tuple of the dimensions of the structure (similar to numpy  shape  argument), and  1.0  is the element you want the structure to be initialized with (works with None as well). Note that the  init  argument is only provided by the recursive call to carry forward the nested child lists \n output of above: \n [[[1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0]],\n [[1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0]],\n [[1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0]]]\n \n set specific elements: \n l[1][3][1] = 56\nl[2][2][0] = 36.0+0.0j\nl[0][1][0] = 'abc'\n \n resulting output: \n [[[1.0, 1.0], ['abc', 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0]],\n [[1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 56.0], [1.0, 1.0]],\n [[1.0, 1.0], [1.0, 1.0], [(36+0j), 1.0], [1.0, 1.0], [1.0, 1.0]]]\n \n the non-typed nature of lists is demonstrated above \n    ", "date_posted": "2020-10-22 19:57:45Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "8126390", "name": "Brian", "reputation_score": "533"}, "answer_comments": []}, {"stack_answer_id": "65616429", "answer_content": "\r\n While the original question constructed the  sublists  with the multiplication operator, I'll add an example that uses the  same  list for the sublists. Adding this answer for completeness as this question is often used as a canonical for the issue \n node_count = 4\ncolors = [0,1,2,3]\nsol_dict = {node:colors for node in range(0,node_count)}\n \n The list in each dictionary value is the same object, trying to change one of the dictionaries values will be seen in all. \n >>> sol_dict\n{0: [0, 1, 2, 3], 1: [0, 1, 2, 3], 2: [0, 1, 2, 3], 3: [0, 1, 2, 3]}\n>>> [v is colors for v in sol_dict.values()]\n[True, True, True, True]\n>>> sol_dict[0].remove(1)\n>>> sol_dict\n{0: [0, 2, 3], 1: [0, 2, 3], 2: [0, 2, 3], 3: [0, 2, 3]}\n \n The correct way to construct the dictionary would be to use a copy of the list for each value. \n >>> colors = [0,1,2,3]\n>>> sol_dict = {node:colors[:] for node in range(0,node_count)}\n>>> sol_dict\n{0: [0, 1, 2, 3], 1: [0, 1, 2, 3], 2: [0, 1, 2, 3], 3: [0, 1, 2, 3]}\n>>> sol_dict[0].remove(1)\n>>> sol_dict\n{0: [0, 2, 3], 1: [0, 1, 2, 3], 2: [0, 1, 2, 3], 3: [0, 1, 2, 3]}\n \n    ", "date_posted": "2021-01-07 16:39:52Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "65616429", "name": "\r\n        wwii\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "64958758", "answer_content": "\r\n Note that items in the sequence are not copied; they are referenced multiple times . This often haunts new Python programmers; consider: \n >>> lists = [[]] * 3\n>>> lists\n[[], [], []]\n>>> lists[0].append(3)\n>>> lists\n[[3], [3], [3]]\n \n What has happened is that  [[]]  is a one-element list containing an empty list, so all three elements of  [[]] * 3  are references to this single empty list. Modifying any of the elements of lists modifies this single list. \n Another example to explain this is using  multi-dimensional arrays . \n You probably tried to make a multidimensional array like this: \n >>> A = [[None] * 2] * 3\n \n This looks correct if you print it: \n >>> A\n[[None, None], [None, None], [None, None]]\n \n But when you assign a value, it shows up in multiple places: \n >>> A[0][0] = 5\n>>> A\n[[5, None], [5, None], [5, None]]\n \n The reason is that replicating a list with\u00a0 * \u00a0doesn\u2019t create copies, it only creates references to the existing objects. The\u00a03\u00a0creates a list containing 3 references to the same list of length two. Changes to one row will show in all rows, which is almost certainly not what you want. \n    ", "date_posted": "2021-03-20 14:25:08Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "7841468", "name": "mishsx", "reputation_score": "1,275"}, "answer_comments": []}], "user": {"stack_user_id": "11677", "name": "Charles Anderson", "reputation_score": "18.3k"}, "question_comments": [{"stack_question_id": "240178", "stack_question_comment_id": "124422290", "comment_content": "Note that the same logic applies to a list of dicts, because of the same fundamental problem of aliasing a mutable object. See ", "user_id": "None"}, {"stack_question_id": "240178", "stack_question_comment_id": "127396210", "comment_content": "Are there more specific questions for when the list of lists is created in other ways (but has the same problem)? For example, by using ", "user_id": "None"}, {"stack_question_id": "240178", "stack_question_comment_id": "128071922", "comment_content": "See also ", "user_id": "None"}, {"stack_question_id": "240178", "stack_question_comment_id": "128430067", "comment_content": "Related: ", "user_id": "None"}]},
{"stack_question_id": "509211", "question_title": "Understanding slicing", "question_content": "\r\n                I need a good explanation (references are a plus) on Python slicing.\r\n", "question_url": "/questions/509211/understanding-slicing", "date_posted": "Feb 3, 2009 at 22:31", "upvote": "4", "view": "2", "tags": ["python", "slice", "sequence"], "answers_count": "3", "answers": [{"stack_answer_id": "509295", "answer_content": "\r\n The syntax is: \n a[start:stop]  # items start through stop-1\na[start:]      # items start through the rest of the array\na[:stop]       # items from the beginning through stop-1\na[:]           # a copy of the whole array\n \n There is also the  step  value, which can be used with any of the above: \n a[start:stop:step] # start through not past stop, by step\n \n The key point to remember is that the  :stop  value represents the first value that is  not  in the selected slice. So, the difference between  stop  and  start  is the number of elements selected (if  step  is 1, the default). \n The other feature is that  start  or  stop  may be a  negative  number, which means it counts from the end of the array instead of the beginning. So: \n a[-1]    # last item in the array\na[-2:]   # last two items in the array\na[:-2]   # everything except the last two items\n \n Similarly,  step  may be a negative number: \n a[::-1]    # all items in the array, reversed\na[1::-1]   # the first two items, reversed\na[:-3:-1]  # the last two items, reversed\na[-3::-1]  # everything except the last two items, reversed\n \n Python is kind to the programmer if there are fewer items than you ask for. For example, if you ask for  a[:-2]  and  a  only contains one element, you get an empty list instead of an error. Sometimes you would prefer the error, so you have to be aware that this may happen. \n Relationship with the  slice  object \n A  slice  object  can represent a slicing operation, i.e.: \n a[start:stop:step]\n \n is equivalent to: \n a[slice(start, stop, step)]\n \n Slice objects also behave slightly differently depending on the number of arguments, similarly to  range() , i.e. both  slice(stop)  and  slice(start, stop[, step])  are supported.\nTo skip specifying a given argument, one might use  None , so that e.g.  a[start:]  is equivalent to  a[slice(start, None)]  or  a[::-1]  is equivalent to  a[slice(None, None, -1)] . \n While the  : -based notation is very helpful for simple slicing, the explicit use of  slice()  objects simplifies the programmatic generation of slicing. \n    ", "date_posted": "2022-05-22 19:33:18Z", "upvote": "\r\n            6103\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": [{"stack_answer_id": "509295", "stack_answer_comment_id": "27984940", "comment_content": "Slicing builtin types returns a copy but that's not universal.  Notably, ", "user_id": "None"}, {"stack_answer_id": "509295", "stack_answer_comment_id": "95272803", "comment_content": "This is a beautiful answer with the votes to prove it, but it misses one thing: you can substitute ", "user_id": "None"}, {"stack_answer_id": "509295", "stack_answer_comment_id": "99325528", "comment_content": "Note that contrary to usual Python slices (see above), in Pandas Dataframes both the start and the stop are included when present in the index. For further info see the ", "user_id": "None"}, {"stack_answer_id": "509295", "stack_answer_comment_id": "100203161", "comment_content": "What really annoys me is that python says that when you don't set the start and the end, they default to 0 and the length of sequence. So, in theory, when you use \"abcdef\"[::-1] it should be transformed to \"abcdef\"[0:6:-1], but these two expressions does not get the same output. I feel that something is missing in python documentation since the creation of the language.", "user_id": "None"}, {"stack_answer_id": "509295", "stack_answer_comment_id": "100203434", "comment_content": "And I know that \"abcdef\"[::-1] is transformed to \"abcdef\"[6:-7:-1], so, the best way to explain would be: let ", "user_id": "None"}]}, {"stack_answer_id": "509297", "answer_content": "\r\n The  Python tutorial  talks about it (scroll down a bit until you get to the part about slicing). \n\n The ASCII art diagram is helpful too for remembering how slices work: \n\n  +---+---+---+---+---+---+\n | P | y | t | h | o | n |\n +---+---+---+---+---+---+\n 0   1   2   3   4   5   6\n-6  -5  -4  -3  -2  -1\n \n\n \n   One way to remember how slices work is to think of the indices as pointing  between  characters, with the left edge of the first character numbered 0. Then the right edge of the last character of a string of  n  characters has index  n . \n \n    ", "date_posted": "2017-09-18 11:02:56Z", "upvote": "\r\n            662\r\n        ", "accepted": "No", "user": {"stack_user_id": "55075", "name": "kenorb", "reputation_score": "141k"}, "answer_comments": [{"stack_answer_id": "509297", "stack_answer_comment_id": "99270489", "comment_content": "This suggestion works for positive stride, but does not for a negative stride. From the diagram, I expect ", "user_id": "None"}, {"stack_answer_id": "509297", "stack_answer_comment_id": "100377224", "comment_content": "But there's no way to collapse to an empty set starting from the end (like ", "user_id": "None"}, {"stack_answer_id": "509297", "stack_answer_comment_id": "118360396", "comment_content": "@aguadopd You are absolutely right. The solution is to have the indices shifted to the right, centered just below the characters, and notice that the stop is always excluded. See another response just below.", "user_id": "None"}, {"stack_answer_id": "509297", "stack_answer_comment_id": "118606940", "comment_content": "Addendum to my comment: see my answer with diagrams below: ", "user_id": "None"}]}, {"stack_answer_id": "509377", "answer_content": "\r\n Enumerating the possibilities allowed by the grammar for the sequence  x : \n >>> x[:]                # [x[0],   x[1],          ..., x[-1]    ]\n>>> x[low:]             # [x[low], x[low+1],      ..., x[-1]    ]\n>>> x[:high]            # [x[0],   x[1],          ..., x[high-1]]\n>>> x[low:high]         # [x[low], x[low+1],      ..., x[high-1]]\n>>> x[::stride]         # [x[0],   x[stride],     ..., x[-1]    ]\n>>> x[low::stride]      # [x[low], x[low+stride], ..., x[-1]    ]\n>>> x[:high:stride]     # [x[0],   x[stride],     ..., x[high-1]]\n>>> x[low:high:stride]  # [x[low], x[low+stride], ..., x[high-1]]\n \n Of course, if  (high-low)%stride != 0 , then the end point will be a little lower than  high-1 . \n If  stride  is negative, the ordering is changed a bit since we're counting down: \n >>> x[::-stride]        # [x[-1],   x[-1-stride],   ..., x[0]    ]\n>>> x[high::-stride]    # [x[high], x[high-stride], ..., x[0]    ]\n>>> x[:low:-stride]     # [x[-1],   x[-1-stride],   ..., x[low+1]]\n>>> x[high:low:-stride] # [x[high], x[high-stride], ..., x[low+1]]\n \n Extended slicing (with commas and ellipses) are mostly used only by special data structures (like NumPy); the basic sequences don't support them. \n >>> class slicee:\n...     def __getitem__(self, item):\n...         return repr(item)\n...\n>>> slicee()[0, 1:2, ::5, ...]\n'(0, slice(1, 2, None), slice(None, None, 5), Ellipsis)'\n \n    ", "date_posted": "2022-05-22 19:38:32Z", "upvote": "\r\n            498\r\n        ", "accepted": "No", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": [{"stack_answer_id": "509377", "stack_answer_comment_id": "83074550", "comment_content": "Actually there is still something left out e.g. if I type 'apple'[4:-4:-1] I get 'elp', python is translating the -4 to a 1 maybe?", "user_id": "None"}, {"stack_answer_id": "509377", "stack_answer_comment_id": "95581586", "comment_content": "note that backticks are deprecated in favour of ", "user_id": "None"}, {"stack_answer_id": "509377", "stack_answer_comment_id": "102170688", "comment_content": "@liyuan The type implementing ", "user_id": "None"}, {"stack_answer_id": "509377", "stack_answer_comment_id": "124476274", "comment_content": "The first two tables are pure gold.", "user_id": "None"}]}, {"stack_answer_id": "4729334", "answer_content": "\r\n The answers above don't discuss slice assignment. To understand slice assignment, it's helpful to add another concept to the ASCII art: \n\n                 +---+---+---+---+---+---+\n                | P | y | t | h | o | n |\n                +---+---+---+---+---+---+\nSlice position: 0   1   2   3   4   5   6\nIndex position:   0   1   2   3   4   5\n\n>>> p = ['P','y','t','h','o','n']\n# Why the two sets of numbers:\n# indexing gives items, not lists\n>>> p[0]\n 'P'\n>>> p[5]\n 'n'\n\n# Slicing gives lists\n>>> p[0:1]\n ['P']\n>>> p[0:2]\n ['P','y']\n \n\n One heuristic is, for a slice from zero to n, think: \"zero is the beginning, start at the beginning and take n items in a list\". \n\n >>> p[5] # the last of six items, indexed from zero\n 'n'\n>>> p[0:5] # does NOT include the last item!\n ['P','y','t','h','o']\n>>> p[0:6] # not p[0:5]!!!\n ['P','y','t','h','o','n']\n \n\n Another heuristic is, \"for any slice, replace the start by zero, apply the previous heuristic to get the end of the list, then count the first number back up to chop items off the beginning\" \n\n >>> p[0:4] # Start at the beginning and count out 4 items\n ['P','y','t','h']\n>>> p[1:4] # Take one item off the front\n ['y','t','h']\n>>> p[2:4] # Take two items off the front\n ['t','h']\n# etc.\n \n\n The first rule of slice assignment is that since slicing  returns  a list, slice assignment  requires  a list (or other iterable): \n\n >>> p[2:3]\n ['t']\n>>> p[2:3] = ['T']\n>>> p\n ['P','y','T','h','o','n']\n>>> p[2:3] = 't'\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: can only assign an iterable\n \n\n The second rule of slice assignment, which you can also see above, is that whatever portion of the list is returned by slice indexing, that's the same portion that is changed by slice assignment: \n\n >>> p[2:4]\n ['T','h']\n>>> p[2:4] = ['t','r']\n>>> p\n ['P','y','t','r','o','n']\n \n\n The third rule of slice assignment is, the assigned list (iterable) doesn't have to have the same length; the indexed slice is simply sliced out and replaced en masse by whatever is being assigned: \n\n >>> p = ['P','y','t','h','o','n'] # Start over\n>>> p[2:4] = ['s','p','a','m']\n>>> p\n ['P','y','s','p','a','m','o','n']\n \n\n The trickiest part to get used to is assignment to empty slices. Using heuristic 1 and 2 it's easy to get your head around  indexing  an empty slice: \n\n >>> p = ['P','y','t','h','o','n']\n>>> p[0:4]\n ['P','y','t','h']\n>>> p[1:4]\n ['y','t','h']\n>>> p[2:4]\n ['t','h']\n>>> p[3:4]\n ['h']\n>>> p[4:4]\n []\n \n\n And then once you've seen that, slice assignment to the empty slice makes sense too: \n\n >>> p = ['P','y','t','h','o','n']\n>>> p[2:4] = ['x','y'] # Assigned list is same length as slice\n>>> p\n ['P','y','x','y','o','n'] # Result is same length\n>>> p = ['P','y','t','h','o','n']\n>>> p[3:4] = ['x','y'] # Assigned list is longer than slice\n>>> p\n ['P','y','t','x','y','o','n'] # The result is longer\n>>> p = ['P','y','t','h','o','n']\n>>> p[4:4] = ['x','y']\n>>> p\n ['P','y','t','h','x','y','o','n'] # The result is longer still\n \n\n Note that, since we are not changing the second number of the slice (4), the inserted items always stack right up against the 'o', even when we're assigning to the empty slice. So the position for the empty slice assignment is the logical extension of the positions for the non-empty slice assignments. \n\n Backing up a little bit, what happens when you keep going with our procession of counting up the slice beginning? \n\n >>> p = ['P','y','t','h','o','n']\n>>> p[0:4]\n ['P','y','t','h']\n>>> p[1:4]\n ['y','t','h']\n>>> p[2:4]\n ['t','h']\n>>> p[3:4]\n ['h']\n>>> p[4:4]\n []\n>>> p[5:4]\n []\n>>> p[6:4]\n []\n \n\n With slicing, once you're done, you're done; it doesn't start slicing backwards. In Python you don't get negative strides unless you explicitly ask for them by using a negative number. \n\n >>> p[5:3:-1]\n ['n','o']\n \n\n There are some weird consequences to the \"once you're done, you're done\" rule: \n\n >>> p[4:4]\n []\n>>> p[5:4]\n []\n>>> p[6:4]\n []\n>>> p[6]\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nIndexError: list index out of range\n \n\n In fact, compared to indexing, Python slicing is bizarrely error-proof: \n\n >>> p[100:200]\n []\n>>> p[int(2e99):int(1e99)]\n []\n \n\n This can come in handy sometimes, but it can also lead to somewhat strange behavior: \n\n >>> p\n ['P', 'y', 't', 'h', 'o', 'n']\n>>> p[int(2e99):int(1e99)] = ['p','o','w','e','r']\n>>> p\n ['P', 'y', 't', 'h', 'o', 'n', 'p', 'o', 'w', 'e', 'r']\n \n\n Depending on your application, that might... or might not... be what you were hoping for there! \n\n \n\n Below is the text of my original answer. It has been useful to many people, so I didn't want to delete it. \n\n >>> r=[1,2,3,4]\n>>> r[1:1]\n[]\n>>> r[1:1]=[9,8]\n>>> r\n[1, 9, 8, 2, 3, 4]\n>>> r[1:1]=['blah']\n>>> r\n[1, 'blah', 9, 8, 2, 3, 4]\n \n\n This may also clarify the difference between slicing and indexing. \n    ", "date_posted": "2019-01-02 16:44:22Z", "upvote": "\r\n            418\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "4729334", "stack_answer_comment_id": "129107053", "comment_content": "If I wanted to remove the 1st x elements of a list, what will be better: ", "user_id": "None"}, {"stack_answer_id": "4729334", "stack_answer_comment_id": "129131819", "comment_content": "The first way works for a list or a string; the second way only works for a list, because slice assignment isn't allowed for strings. Other than that I think the only difference is speed: it looks like it's a little faster the first way. Try it yourself with timeit.timeit() or preferably  timeit.repeat(). They are ", "user_id": "None"}]}, {"stack_answer_id": "24713353", "answer_content": "\r\n \n Explain Python's slice notation \n \n In short, the colons ( : ) in subscript notation ( subscriptable[subscriptarg] ) make slice notation, which has the optional arguments  start ,  stop , and  step : \n sliceable[start:stop:step]\n \n Python slicing is a computationally fast way to methodically access parts of your data. In my opinion, to be even an intermediate Python programmer, it's one aspect of the language that it is necessary to be familiar with. \n Important Definitions \n To begin with, let's define a few terms: \n \n start :  the beginning index of the slice, it will include the element at this index unless it is the same as  stop , defaults to 0, i.e. the first index. If it's negative, it means to start  n  items from the end. \n stop :  the ending index of the slice, it does  not  include the element at this index, defaults to length of the sequence being sliced, that is, up to and including the end. \n step :  the amount by which the index increases, defaults to 1. If it's negative, you're slicing over the iterable in reverse. \n \n How Indexing Works \n You can make any of these positive or negative numbers. The meaning of the positive numbers is straightforward, but for negative numbers, just like indexes in Python, you count backwards from the end for the  start  and  stop , and for the  step , you simply decrement your index. This example is  from the documentation's tutorial , but I've modified it slightly to indicate which item in a sequence each index references: \n  +---+---+---+---+---+---+\n | P | y | t | h | o | n |\n +---+---+---+---+---+---+\n   0   1   2   3   4   5 \n  -6  -5  -4  -3  -2  -1\n \n How Slicing Works \n To use slice notation with a sequence that supports it, you must include at least one colon in the square brackets that follow the sequence (which actually  implement the  __getitem__  method of the sequence, according to the Python data model .) \n Slice notation works like this: \n sequence[start:stop:step]\n \n And recall that there are defaults for  start ,  stop , and  step , so to access the defaults, simply leave out the argument. \n Slice notation to get the last nine elements from a list (or any other sequence that supports it, like a string) would look like this: \n my_list[-9:]\n \n When I see this, I read the part in the brackets as \"9th from the end, to the end.\" (Actually, I abbreviate it mentally as \"-9, on\") \n Explanation: \n The full notation is \n my_list[-9:None:None]\n \n and to substitute the defaults (actually when  step  is negative,  stop 's default is  -len(my_list) - 1 , so  None  for stop really just means it goes to whichever end step takes it to): \n my_list[-9:len(my_list):1]\n \n The  colon ,  : ,  is what tells Python you're giving it a slice and not a regular index. That's why the idiomatic way of making a shallow copy of lists in Python 2 is \n list_copy = sequence[:]\n \n And clearing them is with: \n del my_list[:]\n \n (Python 3 gets a  list.copy  and  list.clear  method.) \n When  step  is negative, the defaults for  start  and  stop  change \n By default, when the  step  argument is empty (or  None ), it is assigned to  +1 . \n But you can pass in a negative integer, and the list (or most other standard sliceables) will be sliced from the end to the beginning. \n Thus a negative slice will change the defaults for  start  and  stop ! \n Confirming this in the source \n I like to encourage users to read the source as well as the documentation. The  source code for slice objects and this logic is found here . First we determine if  step  is negative: \n \n step_is_negative = step_sign < 0;\n \n \n If so, the lower bound is  -1   meaning we slice all the way up to and including the beginning, and the upper bound is the length minus 1, meaning we start at the end. (Note that the semantics of this  -1  is  different  from a  -1  that users may pass indexes in Python indicating the last item.) \n \n if (step_is_negative) {\n    lower = PyLong_FromLong(-1L);\n    if (lower == NULL)\n        goto error;\n\n    upper = PyNumber_Add(length, lower);\n    if (upper == NULL)\n        goto error;\n}\n \n \n Otherwise  step  is positive, and the lower bound will be zero and the upper bound (which we go up to but not including) the length of the sliced list. \n \n else {\n    lower = _PyLong_Zero;\n    Py_INCREF(lower);\n    upper = length;\n    Py_INCREF(upper);\n}\n \n \n Then, we may need to apply the defaults for  start  and  stop \u2014the default then for  start  is calculated as the upper bound when  step  is negative: \n \n if (self->start == Py_None) {\n    start = step_is_negative ? upper : lower;\n    Py_INCREF(start);\n}\n \n \n and  stop , the lower bound: \n \n if (self->stop == Py_None) {\n    stop = step_is_negative ? lower : upper;\n    Py_INCREF(stop);\n}\n \n \n Give your slices a descriptive name! \n You may find it useful to separate forming the slice from passing it to the  list.__getitem__  method ( that's what the square brackets do ). Even if you're not new to it, it keeps your code more readable so that others that may have to read your code can more readily understand what you're doing. \n However, you can't just assign some integers separated by colons to a variable. You need to use the slice object: \n last_nine_slice = slice(-9, None)\n \n The second argument,  None , is required, so that the first argument is interpreted as the  start  argument  otherwise it would be the  stop  argument . \n You can then pass the slice object to your sequence: \n >>> list(range(100))[last_nine_slice]\n[91, 92, 93, 94, 95, 96, 97, 98, 99]\n \n It's interesting that ranges also take slices: \n >>> range(100)[last_nine_slice]\nrange(91, 100)\n \n Memory Considerations: \n Since slices of Python lists create new objects in memory, another important function to be aware of is  itertools.islice . Typically you'll want to iterate over a slice, not just have it created statically in memory.  islice  is perfect for this. A caveat, it doesn't support negative arguments to  start ,  stop , or  step , so if that's an issue you may need to calculate indices or reverse the iterable in advance. \n length = 100\nlast_nine_iter = itertools.islice(list(range(length)), length-9, None, 1)\nlist_last_nine = list(last_nine_iter)\n \n and now: \n >>> list_last_nine\n[91, 92, 93, 94, 95, 96, 97, 98, 99]\n \n The fact that list slices make a copy is a feature of lists themselves. If you're slicing advanced objects like a Pandas DataFrame, it may return a view on the original, and not a copy. \n    ", "date_posted": "2022-04-30 17:20:06Z", "upvote": "\r\n            282\r\n        ", "accepted": "No", "user": {"stack_user_id": "241211", "name": "Michael", "reputation_score": "7,466"}, "answer_comments": [{"stack_answer_id": "24713353", "stack_answer_comment_id": "113402270", "comment_content": "I like the idea of naming slices. I would suggest ", "user_id": "None"}, {"stack_answer_id": "24713353", "stack_answer_comment_id": "113403311", "comment_content": "@WinEunuuchs2Unix that's great feedback - this is a standard Python behavior, but it could be made clearer in that sort of way, so I'll consider updating my material to include this semantic.", "user_id": "None"}]}, {"stack_answer_id": "509415", "answer_content": "\r\n And a couple of things that weren't immediately obvious to me when I first saw the slicing syntax: \n\n >>> x = [1,2,3,4,5,6]\n>>> x[::-1]\n[6,5,4,3,2,1]\n \n\n Easy way to reverse sequences! \n\n And if you wanted, for some reason, every second item in the reversed sequence: \n\n >>> x = [1,2,3,4,5,6]\n>>> x[::-2]\n[6,4,2]\n \n    ", "date_posted": "2009-02-03 23:15:02Z", "upvote": "\r\n            157\r\n        ", "accepted": "No", "user": {"stack_user_id": "7856", "name": "Dana", "reputation_score": "30.8k"}, "answer_comments": []}, {"stack_answer_id": "13005464", "answer_content": "\r\n In Python 2.7 \n\n Slicing in Python \n\n [a:b:c]\n\nlen = length of string, tuple or list\n\nc -- default is +1. The sign of c indicates forward or backward, absolute value of c indicates steps. Default is forward with step size 1. Positive means forward, negative means backward.\n\na --  When c is positive or blank, default is 0. When c is negative, default is -1.\n\nb --  When c is positive or blank, default is len. When c is negative, default is -(len+1).\n \n\n Understanding index assignment is very important. \n\n In forward direction, starts at 0 and ends at len-1\n\nIn backward direction, starts at -1 and ends at -len\n \n\n When you say [a:b:c], you are saying depending on the sign of c (forward or backward), start at a and end at b (excluding element at bth index). Use the indexing rule above and remember you will only find elements in this range: \n\n -len, -len+1, -len+2, ..., 0, 1, 2,3,4 , len -1\n \n\n But this range continues in both directions infinitely: \n\n ...,-len -2 ,-len-1,-len, -len+1, -len+2, ..., 0, 1, 2,3,4 , len -1, len, len +1, len+2 , ....\n \n\n For example: \n\n              0    1    2   3    4   5   6   7   8   9   10   11\n             a    s    t   r    i   n   g\n    -9  -8  -7   -6   -5  -4   -3  -2  -1\n \n\n If your choice of a, b, and c allows overlap with the range above as you traverse using rules for a,b,c above you will either get a list with elements (touched during traversal) or you will get an empty list. \n\n One last thing: if a and b are equal, then also you get an empty list: \n\n >>> l1\n[2, 3, 4]\n\n>>> l1[:]\n[2, 3, 4]\n\n>>> l1[::-1] # a default is -1 , b default is -(len+1)\n[4, 3, 2]\n\n>>> l1[:-4:-1] # a default is -1\n[4, 3, 2]\n\n>>> l1[:-3:-1] # a default is -1\n[4, 3]\n\n>>> l1[::] # c default is +1, so a default is 0, b default is len\n[2, 3, 4]\n\n>>> l1[::-1] # c is -1 , so a default is -1 and b default is -(len+1)\n[4, 3, 2]\n\n\n>>> l1[-100:-200:-1] # Interesting\n[]\n\n>>> l1[-1:-200:-1] # Interesting\n[4, 3, 2]\n\n\n>>> l1[-1:-1:1]\n[]\n\n\n>>> l1[-1:5:1] # Interesting\n[4]\n\n\n>>> l1[1:-7:1]\n[]\n\n>>> l1[1:-7:-1] # Interesting\n[3, 2]\n\n>>> l1[:-2:-2] # a default is -1, stop(b) at -2 , step(c) by 2 in reverse direction\n[4]\n \n    ", "date_posted": "2017-07-10 16:59:26Z", "upvote": "\r\n            109\r\n        ", "accepted": "No", "user": {"stack_user_id": "494074", "name": "Ankur Agarwal", "reputation_score": "22.2k"}, "answer_comments": [{"stack_answer_id": "13005464", "stack_answer_comment_id": "77001814", "comment_content": "another one interesting example: ", "user_id": "None"}]}, {"stack_answer_id": "7315935", "answer_content": "\r\n Found this great table at  http://wiki.python.org/moin/MovingToPythonFromOtherLanguages \n\n Python indexes and slices for a six-element list.\nIndexes enumerate the elements, slices enumerate the spaces between the elements.\n\nIndex from rear:    -6  -5  -4  -3  -2  -1      a=[0,1,2,3,4,5]    a[1:]==[1,2,3,4,5]\nIndex from front:    0   1   2   3   4   5      len(a)==6          a[:5]==[0,1,2,3,4]\n                   +---+---+---+---+---+---+    a[0]==0            a[:-2]==[0,1,2,3]\n                   | a | b | c | d | e | f |    a[5]==5            a[1:2]==[1]\n                   +---+---+---+---+---+---+    a[-1]==5           a[1:-1]==[1,2,3,4]\nSlice from front:  :   1   2   3   4   5   :    a[-2]==4\nSlice from rear:   :  -5  -4  -3  -2  -1   :\n                                                b=a[:]\n                                                b==[0,1,2,3,4,5] (shallow copy of a) \n    ", "date_posted": "2011-09-06 06:50:08Z", "upvote": "\r\n            101\r\n        ", "accepted": "No", "user": {"stack_user_id": "43769", "name": "AdrianoFerrari", "reputation_score": "2,110"}, "answer_comments": []}, {"stack_answer_id": "567094", "answer_content": "\r\n After using it a bit I realise that the simplest description is that it is exactly the same as the arguments in a  for  loop... \n\n (from:to:step)\n \n\n Any of them are optional: \n\n (:to:step)\n(from::step)\n(from:to)\n \n\n Then the negative indexing just needs you to add the length of the string to the negative indices to understand it. \n\n This works for me anyway... \n    ", "date_posted": "2019-01-02 16:40:20Z", "upvote": "\r\n            70\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "9923354", "answer_content": "\r\n I find it easier to remember how it works, and then I can figure out any specific start/stop/step combination. \n\n It's instructive to understand  range()  first: \n\n def range(start=0, stop, step=1):  # Illegal syntax, but that's the effect\n    i = start\n    while (i < stop if step > 0 else i > stop):\n        yield i\n        i += step\n \n\n Begin from  start , increment by  step , do not reach  stop .  Very simple. \n\n The thing to remember about negative step is that  stop  is always the excluded end, whether it's higher or lower. If you want same slice in opposite order, it's much cleaner to do the reversal separately: e.g.  'abcde'[1:-2][::-1]  slices off one char from left, two from right, then reverses. (See also  reversed() .) \n\n Sequence slicing is same, except it first normalizes negative indexes, and it can never go outside the sequence: \n\n TODO : The code below had a bug with \"never go outside the sequence\" when abs(step)>1; I  think  I patched it to be correct, but it's hard to understand. \n\n def this_is_how_slicing_works(seq, start=None, stop=None, step=1):\n    if start is None:\n        start = (0 if step > 0 else len(seq)-1)\n    elif start < 0:\n        start += len(seq)\n    if not 0 <= start < len(seq):  # clip if still outside bounds\n        start = (0 if step > 0 else len(seq)-1)\n    if stop is None:\n        stop = (len(seq) if step > 0 else -1)  # really -1, not last element\n    elif stop < 0:\n        stop += len(seq)\n    for i in range(start, stop, step):\n        if 0 <= i < len(seq):\n            yield seq[i]\n \n\n Don't worry about the  is None  details - just remember that omitting  start  and/or  stop  always does the right thing to give you the whole sequence. \n\n Normalizing negative indexes first allows start and/or stop to be counted from the end independently:  'abcde'[1:-2] == 'abcde'[1:3] == 'bc'  despite  range(1,-2) == [] .\nThe normalization is sometimes thought of as \"modulo the length\", but note it adds the length just once: e.g.  'abcde'[-53:42]  is just the whole string. \n    ", "date_posted": "2019-01-02 16:46:18Z", "upvote": "\r\n            54\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "9923354", "stack_answer_comment_id": "67894582", "comment_content": "The ", "user_id": "None"}, {"stack_answer_id": "9923354", "stack_answer_comment_id": "67913261", "comment_content": "@Eastsun Oops, you're right!  A clearer case: ", "user_id": "None"}]}, {"stack_answer_id": "522212", "answer_content": "\r\n I use the \"an index points between elements\" method of thinking about it myself, but one way of describing it which sometimes helps others get it is this: \n\n mylist[X:Y]\n \n\n X is the index of the first element you want. \nY is the index of the first element you  don't  want. \n    ", "date_posted": "2009-02-06 21:16:28Z", "upvote": "\r\n            43\r\n        ", "accepted": "No", "user": {"stack_user_id": "13498", "name": "Steve Losh", "reputation_score": "19.4k"}, "answer_comments": []}, {"stack_answer_id": "14682039", "answer_content": "\r\n Index:\n      ------------>\n  0   1   2   3   4\n+---+---+---+---+---+\n| a | b | c | d | e |\n+---+---+---+---+---+\n  0  -4  -3  -2  -1\n      <------------\n\nSlice:\n    <---------------|\n|--------------->\n:   1   2   3   4   :\n+---+---+---+---+---+\n| a | b | c | d | e |\n+---+---+---+---+---+\n:  -4  -3  -2  -1   :\n|--------------->\n    <---------------|\n \n\n I hope this will help you to model the list in Python. \n\n Reference:  http://wiki.python.org/moin/MovingToPythonFromOtherLanguages \n    ", "date_posted": "2017-02-11 19:56:15Z", "upvote": "\r\n            43\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "29237560", "answer_content": "\r\n This is how I teach slices to newbies: \n\n Understanding the difference between indexing and slicing: \n\n Wiki Python has this amazing picture which clearly distinguishes indexing and slicing. \n\n \n\n It is a list with six elements in it. To understand slicing better, consider that list as a set of six boxes placed together. Each box has an alphabet in it. \n\n Indexing is like dealing with the contents of box. You can check contents of any box. But you can't check the contents of multiple boxes at once. You can even replace the contents of the box. But you can't place two balls in one box or replace two balls at a time. \n\n In [122]: alpha = ['a', 'b', 'c', 'd', 'e', 'f']\n\nIn [123]: alpha\nOut[123]: ['a', 'b', 'c', 'd', 'e', 'f']\n\nIn [124]: alpha[0]\nOut[124]: 'a'\n\nIn [127]: alpha[0] = 'A'\n\nIn [128]: alpha\nOut[128]: ['A', 'b', 'c', 'd', 'e', 'f']\n\nIn [129]: alpha[0,1]\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n<ipython-input-129-c7eb16585371> in <module>()\n----> 1 alpha[0,1]\n\nTypeError: list indices must be integers, not tuple\n \n\n Slicing is like dealing with boxes themselves. You can pick up the first box and place it on another table. To pick up the box, all you need to know is the position of beginning and ending of the box. \n\n You can even pick up the first three boxes or the last two boxes or all boxes between 1 and 4. So, you can pick any set of boxes if you know the beginning and ending. These positions are called start and stop positions. \n\n The interesting thing is that you can replace multiple boxes at once. Also you can place multiple boxes wherever you like. \n\n In [130]: alpha[0:1]\nOut[130]: ['A']\n\nIn [131]: alpha[0:1] = 'a'\n\nIn [132]: alpha\nOut[132]: ['a', 'b', 'c', 'd', 'e', 'f']\n\nIn [133]: alpha[0:2] = ['A', 'B']\n\nIn [134]: alpha\nOut[134]: ['A', 'B', 'c', 'd', 'e', 'f']\n\nIn [135]: alpha[2:2] = ['x', 'xx']\n\nIn [136]: alpha\nOut[136]: ['A', 'B', 'x', 'xx', 'c', 'd', 'e', 'f']\n \n\n Slicing With Step: \n\n Till now you have picked boxes continuously. But sometimes you need to pick up discretely. For example, you can pick up every second box. You can even pick up every third box from the end. This value is called step size. This represents the gap between your successive pickups. The step size should be positive if You are picking boxes from the beginning to end and vice versa. \n\n In [137]: alpha = ['a', 'b', 'c', 'd', 'e', 'f']\n\nIn [142]: alpha[1:5:2]\nOut[142]: ['b', 'd']\n\nIn [143]: alpha[-1:-5:-2]\nOut[143]: ['f', 'd']\n\nIn [144]: alpha[1:5:-2]\nOut[144]: []\n\nIn [145]: alpha[-1:-5:2]\nOut[145]: []\n \n\n How Python Figures Out Missing Parameters: \n\n When slicing, if you leave out any parameter, Python tries to figure it out automatically. \n\n If you check the source code of  CPython , you will find a function called PySlice_GetIndicesEx() which figures out indices to a slice for any given parameters. Here is the logical equivalent code in Python. \n\n This function takes a Python object and optional parameters for slicing and returns the start, stop, step, and slice length for the requested slice. \n\n def py_slice_get_indices_ex(obj, start=None, stop=None, step=None):\n\n    length = len(obj)\n\n    if step is None:\n        step = 1\n    if step == 0:\n        raise Exception(\"Step cannot be zero.\")\n\n    if start is None:\n        start = 0 if step > 0 else length - 1\n    else:\n        if start < 0:\n            start += length\n        if start < 0:\n            start = 0 if step > 0 else -1\n        if start >= length:\n            start = length if step > 0 else length - 1\n\n    if stop is None:\n        stop = length if step > 0 else -1\n    else:\n        if stop < 0:\n            stop += length\n        if stop < 0:\n            stop = 0 if step > 0 else -1\n        if stop >= length:\n            stop = length if step > 0 else length - 1\n\n    if (step < 0 and stop >= start) or (step > 0 and start >= stop):\n        slice_length = 0\n    elif step < 0:\n        slice_length = (stop - start + 1)/(step) + 1\n    else:\n        slice_length = (stop - start - 1)/(step) + 1\n\n    return (start, stop, step, slice_length)\n \n\n This is the intelligence that is present behind slices. Since Python has an built-in function called slice, you can pass some parameters and check how smartly it calculates missing parameters. \n\n In [21]: alpha = ['a', 'b', 'c', 'd', 'e', 'f']\n\nIn [22]: s = slice(None, None, None)\n\nIn [23]: s\nOut[23]: slice(None, None, None)\n\nIn [24]: s.indices(len(alpha))\nOut[24]: (0, 6, 1)\n\nIn [25]: range(*s.indices(len(alpha)))\nOut[25]: [0, 1, 2, 3, 4, 5]\n\nIn [26]: s = slice(None, None, -1)\n\nIn [27]: range(*s.indices(len(alpha)))\nOut[27]: [5, 4, 3, 2, 1, 0]\n\nIn [28]: s = slice(None, 3, -1)\n\nIn [29]: range(*s.indices(len(alpha)))\nOut[29]: [5, 4]\n \n\n Note:  This post was originally written in my blog,  The Intelligence Behind Python Slices . \n    ", "date_posted": "2019-09-26 07:58:01Z", "upvote": "\r\n            39\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "29237560", "stack_answer_comment_id": "125358697", "comment_content": "At last, I found here some explanation on why the slicing parameters ", "user_id": "None"}]}, {"stack_answer_id": "16267103", "answer_content": "\r\n Python slicing notation: \n\n a[start:end:step]\n \n\n \n For  start  and  end , negative values are interpreted as being relative to the end of the sequence. \n Positive indices for  end  indicate the position  after  the last element to be included. \n Blank values are defaulted as follows:  [+0:-0:1] . \n Using a negative step reverses the interpretation of  start  and  end \n \n\n The notation extends to (numpy) matrices and multidimensional arrays.  For example, to slice entire columns you can use: \n\n m[::,0:2:] ## slice the first two columns\n \n\n Slices hold references, not copies, of the array elements.  If you want to make a separate copy an array, you can use  deepcopy() . \n    ", "date_posted": "2017-05-23 12:34:44Z", "upvote": "\r\n            38\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}, {"stack_answer_id": "15824717", "answer_content": "\r\n You can also use slice assignment to remove one or more elements from a list: \n\n r = [1, 'blah', 9, 8, 2, 3, 4]\n>>> r[1:4] = []\n>>> r\n[1, 2, 3, 4]\n \n    ", "date_posted": "2013-04-19 16:28:16Z", "upvote": "\r\n            34\r\n        ", "accepted": "No", "user": {"stack_user_id": "1355221", "name": "dansalmo", "reputation_score": "11.1k"}, "answer_comments": []}, {"stack_answer_id": "9827284", "answer_content": "\r\n This is just for some extra info...\nConsider the list below  \n\n >>> l=[12,23,345,456,67,7,945,467]\n \n\n Few other tricks for reversing the list: \n\n >>> l[len(l):-len(l)-1:-1]\n[467, 945, 7, 67, 456, 345, 23, 12]\n\n>>> l[:-len(l)-1:-1]\n[467, 945, 7, 67, 456, 345, 23, 12]\n\n>>> l[len(l)::-1]\n[467, 945, 7, 67, 456, 345, 23, 12]\n\n>>> l[::-1]\n[467, 945, 7, 67, 456, 345, 23, 12]\n\n>>> l[-1:-len(l)-1:-1]\n[467, 945, 7, 67, 456, 345, 23, 12]\n \n    ", "date_posted": "2019-05-08 08:35:55Z", "upvote": "\r\n            33\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": []}, {"stack_answer_id": "41548529", "answer_content": "\r\n 1. Slice Notation \n\n To make it simple, remember  slice has only one form\uff1a \n\n s[start:end:step]\n \n\n and here is how it works: \n\n \n s : an object that can be sliced \n start : first index to start iteration \n end : last index,  NOTE that  end  index will not be included in the resulted slice \n step : pick element every  step  index \n \n\n Another import thing:  all  start , end ,  step  can be omitted!  And if they are omitted, their default value will be used:  0 , len(s) , 1  accordingly. \n\n So possible variations are: \n\n # Mostly used variations\ns[start:end]\ns[start:]\ns[:end]\n\n# Step-related variations\ns[:end:step]\ns[start::step]\ns[::step]\n\n# Make a copy\ns[:]\n \n\n NOTE: If  start >= end  (considering only when  step>0 ), Python will return a empty slice  [] . \n\n 2. Pitfalls \n\n The above part explains the core features on how slice works, and it will work on most occasions. However, there can be pitfalls you should watch out, and this part explains them. \n\n Negative indexes \n\n The very first thing that confuses Python learners is that  an index can be negative! \nDon't panic:  a negative index means count backwards. \n\n For example: \n\n s[-5:]    # Start at the 5th index from the end of array,\n          # thus returning the last 5 elements.\ns[:-5]    # Start at index 0, and end until the 5th index from end of array,\n          # thus returning s[0:len(s)-5].\n \n\n Negative step \n\n Making things more confusing is that  step  can be negative too! \n\n A negative step means iterate the array backwards: from the end to start, with the end index included, and the start index excluded from the result. \n\n NOTE : when step is negative, the default value for  start  is  len(s)  (while  end  does not equal to  0 , because  s[::-1]  contains  s[0] ). For example: \n\n s[::-1]            # Reversed slice\ns[len(s)::-1]      # The same as above, reversed slice\ns[0:len(s):-1]     # Empty list\n \n\n Out of range error? \n\n Be surprised:  slice does not raise an IndexError when the index is out of range! \n\n If the index is out of range, Python will try its best to set the index to  0  or  len(s)  according to the situation. For example: \n\n s[:len(s)+5]      # The same as s[:len(s)]\ns[-len(s)-5::]    # The same as s[0:]\ns[len(s)+5::-1]   # The same as s[len(s)::-1], and the same as s[::-1]\n \n\n 3. Examples \n\n Let's finish this answer with examples, explaining everything we have discussed: \n\n # Create our array for demonstration\nIn [1]: s = [i for i in range(10)]\n\nIn [2]: s\nOut[2]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\nIn [3]: s[2:]   # From index 2 to last index\nOut[3]: [2, 3, 4, 5, 6, 7, 8, 9]\n\nIn [4]: s[:8]   # From index 0 up to index 8\nOut[4]: [0, 1, 2, 3, 4, 5, 6, 7]\n\nIn [5]: s[4:7]  # From index 4 (included) up to index 7(excluded)\nOut[5]: [4, 5, 6]\n\nIn [6]: s[:-2]  # Up to second last index (negative index)\nOut[6]: [0, 1, 2, 3, 4, 5, 6, 7]\n\nIn [7]: s[-2:]  # From second last index (negative index)\nOut[7]: [8, 9]\n\nIn [8]: s[::-1] # From last to first in reverse order (negative step)\nOut[8]: [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n\nIn [9]: s[::-2] # All odd numbers in reversed order\nOut[9]: [9, 7, 5, 3, 1]\n\nIn [11]: s[-2::-2] # All even numbers in reversed order\nOut[11]: [8, 6, 4, 2, 0]\n\nIn [12]: s[3:15]   # End is out of range, and Python will set it to len(s).\nOut[12]: [3, 4, 5, 6, 7, 8, 9]\n\nIn [14]: s[5:1]    # Start > end; return empty list\nOut[14]: []\n\nIn [15]: s[11]     # Access index 11 (greater than len(s)) will raise an IndexError\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\n<ipython-input-15-79ffc22473a3> in <module>()\n----> 1 s[11]\n\nIndexError: list index out of range\n \n    ", "date_posted": "2019-09-26 08:04:23Z", "upvote": "\r\n            30\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "20443928", "answer_content": "\r\n As a general rule, writing code with a lot of hardcoded index values leads to a readability\nand maintenance mess. For example, if you come back to the code a year later, you\u2019ll\nlook at it and wonder what you were thinking when you wrote it. The solution shown\nis simply a way of more clearly stating what your code is actually doing.\nIn general, the built-in slice() creates a slice object that can be used anywhere a slice\nis allowed. For example: \n\n >>> items = [0, 1, 2, 3, 4, 5, 6]\n>>> a = slice(2, 4)\n>>> items[2:4]\n[2, 3]\n>>> items[a]\n[2, 3]\n>>> items[a] = [10,11]\n>>> items\n[0, 1, 10, 11, 4, 5, 6]\n>>> del items[a]\n>>> items\n[0, 1, 4, 5, 6]\n \n\n If you have a slice instance s, you can get more information about it by looking at its\ns.start, s.stop, and s.step attributes, respectively. For example: \n\n \n >>> a = slice(10, 50, 2)\n>>> a.start\n10\n>>> a.stop\n50\n>>> a.step\n2\n>>>\n \n \n    ", "date_posted": "2013-12-07 16:52:45Z", "upvote": "\r\n            29\r\n        ", "accepted": "No", "user": {"stack_user_id": "3048166", "name": "Python_Dude", "reputation_score": "507"}, "answer_comments": []}, {"stack_answer_id": "42522149", "answer_content": "\r\n The previous answers don't discuss multi-dimensional array slicing which is possible using the famous  NumPy  package: \n\n Slicing can also be applied to multi-dimensional arrays. \n\n # Here, a is a NumPy array\n\n>>> a\narray([[ 1,  2,  3,  4],\n       [ 5,  6,  7,  8],\n       [ 9, 10, 11, 12]])\n>>> a[:2, 0:3:2]\narray([[1, 3],\n       [5, 7]])\n \n\n The \" :2 \" before the comma operates on the first dimension and the \" 0:3:2 \" after the comma operates on the second dimension. \n    ", "date_posted": "2019-09-26 08:08:54Z", "upvote": "\r\n            29\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "42522149", "stack_answer_comment_id": "100958827", "comment_content": "Just a friendly reminder that you cannot do this on Python ", "user_id": "None"}]}, {"stack_answer_id": "63047385", "answer_content": "\r\n The rules of slicing are as follows: \n [lower bound : upper bound : step size]\n \n I-  Convert  upper bound   and  lower bound  into common signs. \n II-  Then check if the  step size  is a  positive  or a  negative  value. \n (i)  If the  step size  is a  positive value ,  upper bound  should be  greater than   lower bound , otherwise  empty string  is printed.  For example : \n s=\"Welcome\"\ns1=s[0:3:1]\nprint(s1)\n \n The output: \n Wel\n \n However if we run the following code: \n s=\"Welcome\"\ns1=s[3:0:1]\nprint(s1)\n \n It will return an  empty string . \n (ii)  If the  step size  if a  negative value ,  upper bound  should be  lesser than   lower bound , otherwise  empty string  will be printed. For example: \n s=\"Welcome\"\ns1=s[3:0:-1]\nprint(s1)\n \n The output: \n cle\n \n But if we run the following code: \n s=\"Welcome\"\ns1=s[0:5:-1]\nprint(s1)\n \n The output will be an  empty string . \n Thus in the code: \n str = 'abcd'\nl = len(str)\nstr2 = str[l-1:0:-1]    #str[3:0:-1] \nprint(str2)\nstr2 = str[l-1:-1:-1]    #str[3:-1:-1]\nprint(str2)\n \n In the first  str2=str[l-1:0:-1] , the  upper bound  is  lesser than  the  lower bound , thus  dcb  is printed. \n However in  str2=str[l-1:-1:-1] , the  upper bound  is  not less than  the  lower bound  (upon converting  lower bound  into  negative value  which is  -1 : since  index  of last element is -1 as well as 3). \n    ", "date_posted": "2020-07-23 05:22:23Z", "upvote": "\r\n            20\r\n        ", "accepted": "No", "user": {"stack_user_id": "13737990", "name": "Anshika Singh", "reputation_score": "866"}, "answer_comments": []}, {"stack_answer_id": "47765245", "answer_content": "\r\n In my opinion, you will understand and memorize better the Python string slicing notation if you look at it the following way (read on). \n\n Let's work with the following string ... \n\n azString = \"abcdefghijklmnopqrstuvwxyz\"\n \n\n For those who don't know, you can create any substring from  azString  using the notation  azString[x:y] \n\n Coming from other programming languages, that's when the common sense gets compromised. What are x and y? \n\n I had to sit down and run several scenarios in my quest for a memorization technique that will help me remember what x and y are and help me slice strings properly at the first attempt. \n\n My conclusion is that x and y should be seen as the boundary indexes that are surrounding the strings that we want to extra. So we should see the expression as  azString[index1, index2]  or even more clearer as  azString[index_of_first_character, index_after_the_last_character] . \n\n Here is an example visualization of that ... \n\n Letters   a b c d e f g h i j ...\n         \u2191 \u2191 \u2191 \u2191 \u2191 \u2191 \u2191 \u2191 \u2191 \u2191\n             \u250a           \u250a\nIndexes  0 1 2 3 4 5 6 7 8 9 ...\n             \u250a           \u250a\ncdefgh    index1       index2\n \n\n So all you have to do is setting index1 and index2 to the values that will surround the desired substring. For instance, to get the substring \"cdefgh\", you can use  azString[2:8] , because the index on the left side of \"c\" is 2 and the one on the right size of \"h\" is 8. \n\n Remember that we are setting the boundaries. And those boundaries are the positions where you could place some brackets that will be wrapped around the substring like this ... \n\n a b  [  c d e f g h  ]  i j \n\n That trick works all the time and is easy to memorize. \n    ", "date_posted": "2020-01-08 16:12:41Z", "upvote": "\r\n            18\r\n        ", "accepted": "No", "user": {"stack_user_id": "609862", "name": "asiby", "reputation_score": "2,909"}, "answer_comments": []}, {"stack_answer_id": "57628026", "answer_content": "\r\n I personally think about it like a  for  loop: \n\n a[start:end:step]\n# for(i = start; i < end; i += step)\n \n\n Also, note that negative values for  start  and  end  are relative to the end of the list and computed in the example above by  given_index + a.shape[0] . \n    ", "date_posted": "2020-01-15 12:29:43Z", "upvote": "\r\n            18\r\n        ", "accepted": "No", "user": {"stack_user_id": "806202", "name": "Arsen Khachaturyan", "reputation_score": "7,445"}, "answer_comments": []}, {"stack_answer_id": "26442691", "answer_content": "\r\n #!/usr/bin/env python\n\ndef slicegraphical(s, lista):\n\n    if len(s) > 9:\n        print \"\"\"Enter a string of maximum 9 characters,\n    so the printig would looki nice\"\"\"\n        return 0;\n    # print \" \",\n    print '  '+'+---' * len(s) +'+'\n    print ' ',\n    for letter in s:\n        print '| {}'.format(letter),\n    print '|'\n    print \" \",; print '+---' * len(s) +'+'\n\n    print \" \",\n    for letter in range(len(s) +1):\n        print '{}  '.format(letter),\n    print \"\"\n    for letter in range(-1*(len(s)), 0):\n        print ' {}'.format(letter),\n    print ''\n    print ''\n\n\n    for triada in lista:\n        if len(triada) == 3:\n            if triada[0]==None and triada[1] == None and triada[2] == None:\n                # 000\n                print s+'[   :   :   ]' +' = ', s[triada[0]:triada[1]:triada[2]]\n            elif triada[0] == None and triada[1] == None and triada[2] != None:\n                # 001\n                print s+'[   :   :{0:2d} ]'.format(triada[2], '','') +' = ', s[triada[0]:triada[1]:triada[2]]\n            elif triada[0] == None and triada[1] != None and triada[2] == None:\n                # 010\n                print s+'[   :{0:2d} :   ]'.format(triada[1]) +' = ', s[triada[0]:triada[1]:triada[2]]\n            elif triada[0] == None and triada[1] != None and triada[2] != None:\n                # 011\n                print s+'[   :{0:2d} :{1:2d} ]'.format(triada[1], triada[2]) +' = ', s[triada[0]:triada[1]:triada[2]]\n            elif triada[0] != None and triada[1] == None and triada[2] == None:\n                # 100\n                print s+'[{0:2d} :   :   ]'.format(triada[0]) +' = ', s[triada[0]:triada[1]:triada[2]]\n            elif triada[0] != None and triada[1] == None and triada[2] != None:\n                # 101\n                print s+'[{0:2d} :   :{1:2d} ]'.format(triada[0], triada[2]) +' = ', s[triada[0]:triada[1]:triada[2]]\n            elif triada[0] != None and triada[1] != None and triada[2] == None:\n                # 110\n                print s+'[{0:2d} :{1:2d} :   ]'.format(triada[0], triada[1]) +' = ', s[triada[0]:triada[1]:triada[2]]\n            elif triada[0] != None and triada[1] != None and triada[2] != None:\n                # 111\n                print s+'[{0:2d} :{1:2d} :{2:2d} ]'.format(triada[0], triada[1], triada[2]) +' = ', s[triada[0]:triada[1]:triada[2]]\n\n        elif len(triada) == 2:\n            if triada[0] == None and triada[1] == None:\n                # 00\n                print s+'[   :   ]    ' + ' = ', s[triada[0]:triada[1]]\n            elif triada[0] == None and triada[1] != None:\n                # 01\n                print s+'[   :{0:2d} ]    '.format(triada[1]) + ' = ', s[triada[0]:triada[1]]\n            elif triada[0] != None and triada[1] == None:\n                # 10\n                print s+'[{0:2d} :   ]    '.format(triada[0]) + ' = ', s[triada[0]:triada[1]]\n            elif triada[0] != None and triada[1] != None:\n                # 11\n                print s+'[{0:2d} :{1:2d} ]    '.format(triada[0],triada[1]) + ' = ', s[triada[0]:triada[1]]\n\n        elif len(triada) == 1:\n            print s+'[{0:2d} ]        '.format(triada[0]) + ' = ', s[triada[0]]\n\n\nif __name__ == '__main__':\n    # Change \"s\" to what ever string you like, make it 9 characters for\n    # better representation.\n    s = 'COMPUTERS'\n\n    # add to this list different lists to experement with indexes\n    # to represent ex. s[::], use s[None, None,None], otherwise you get an error\n    # for s[2:] use s[2:None]\n\n    lista = [[4,7],[2,5,2],[-5,1,-1],[4],[-4,-6,-1], [2,-3,1],[2,-3,-1], [None,None,-1],[-5,None],[-5,0,-1],[-5,None,-1],[-1,1,-2]]\n\n    slicegraphical(s, lista)\n \n\n You can run this script and experiment with it, below is some samples that I got from the script. \n\n   +---+---+---+---+---+---+---+---+---+\n  | C | O | M | P | U | T | E | R | S |\n  +---+---+---+---+---+---+---+---+---+\n  0   1   2   3   4   5   6   7   8   9   \n -9  -8  -7  -6  -5  -4  -3  -2  -1 \n\nCOMPUTERS[ 4 : 7 ]     =  UTE\nCOMPUTERS[ 2 : 5 : 2 ] =  MU\nCOMPUTERS[-5 : 1 :-1 ] =  UPM\nCOMPUTERS[ 4 ]         =  U\nCOMPUTERS[-4 :-6 :-1 ] =  TU\nCOMPUTERS[ 2 :-3 : 1 ] =  MPUT\nCOMPUTERS[ 2 :-3 :-1 ] =  \nCOMPUTERS[   :   :-1 ] =  SRETUPMOC\nCOMPUTERS[-5 :   ]     =  UTERS\nCOMPUTERS[-5 : 0 :-1 ] =  UPMO\nCOMPUTERS[-5 :   :-1 ] =  UPMOC\nCOMPUTERS[-1 : 1 :-2 ] =  SEUM\n[Finished in 0.9s]\n \n\n When using a negative step, notice that the answer is shifted to the right by 1. \n    ", "date_posted": "2014-10-18 17:40:45Z", "upvote": "\r\n            17\r\n        ", "accepted": "No", "user": {"stack_user_id": "1471004", "name": "mahmoh", "reputation_score": "792"}, "answer_comments": []}, {"stack_answer_id": "37455246", "answer_content": "\r\n My brain seems happy to accept that  lst[start:end]  contains the  start -th item. I might even say that it is a 'natural assumption'. \n\n But occasionally a doubt creeps in and my brain asks for reassurance that it does not contain the  end -th element. \n\n In these moments I rely on this simple theorem: \n\n for any n,    lst = lst[:n] + lst[n:]\n \n\n This pretty property tells me that  lst[start:end]  does not contain the  end -th item because it is in  lst[end:] . \n\n Note that this theorem is true for any  n  at all. For example, you can check that \n\n lst = range(10)\nlst[:-42] + lst[-42:] == lst\n \n\n returns  True . \n    ", "date_posted": "2016-05-26 08:16:54Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "1243435", "name": "Robert", "reputation_score": "1,402"}, "answer_comments": []}, {"stack_answer_id": "46040689", "answer_content": "\r\n In Python, the most basic form for slicing is the following: \n\n l[start:end]\n \n\n where  l  is some collection,  start  is an inclusive index, and  end  is an exclusive index. \n\n In [1]: l = list(range(10))\n\nIn [2]: l[:5] # First five elements\nOut[2]: [0, 1, 2, 3, 4]\n\nIn [3]: l[-5:] # Last five elements\nOut[3]: [5, 6, 7, 8, 9]\n \n\n When slicing from the start, you can omit the zero index, and when slicing to the end, you can omit the final index since it is redundant, so do not be verbose: \n\n In [5]: l[:3] == l[0:3]\nOut[5]: True\n\nIn [6]: l[7:] == l[7:len(l)]\nOut[6]: True\n \n\n Negative integers are useful when doing offsets relative to the end of a collection: \n\n In [7]: l[:-1] # Include all elements but the last one\nOut[7]: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n\nIn [8]: l[-3:] # Take the last three elements\nOut[8]: [7, 8, 9]\n \n\n It is possible to provide indices that are out of bounds when slicing such as: \n\n In [9]: l[:20] # 20 is out of index bounds, and l[20] will raise an IndexError exception\nOut[9]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\nIn [11]: l[-20:] # -20 is out of index bounds, and l[-20] will raise an IndexError exception\nOut[11]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n \n\n Keep in mind that the result of slicing a collection is a whole new collection. In addition, when using slice notation in assignments, the length of the slice assignments do not need to be the same. The values before and after the assigned slice will be kept, and the collection will shrink or grow to contain the new values: \n\n In [16]: l[2:6] = list('abc') # Assigning fewer elements than the ones contained in the sliced collection l[2:6]\n\nIn [17]: l\nOut[17]: [0, 1, 'a', 'b', 'c', 6, 7, 8, 9]\n\nIn [18]: l[2:5] = list('hello') # Assigning more elements than the ones contained in the sliced collection l [2:5]\n\nIn [19]: l\nOut[19]: [0, 1, 'h', 'e', 'l', 'l', 'o', 6, 7, 8, 9]\n \n\n If you omit the start and end index, you will make a copy of the collection: \n\n In [14]: l_copy = l[:]\n\nIn [15]: l == l_copy and l is not l_copy\nOut[15]: True\n \n\n If the start and end indexes are omitted when performing an assignment operation, the entire content of the collection will be replaced with a copy of what is referenced: \n\n In [20]: l[:] = list('hello...')\n\nIn [21]: l\nOut[21]: ['h', 'e', 'l', 'l', 'o', '.', '.', '.']\n \n\n Besides basic slicing, it is also possible to apply the following notation: \n\n l[start:end:step]\n \n\n where  l  is a collection,  start  is an inclusive index,  end  is an exclusive index, and  step  is a stride that can be used to take every  nth  item in  l . \n\n In [22]: l = list(range(10))\n\nIn [23]: l[::2] # Take the elements which indexes are even\nOut[23]: [0, 2, 4, 6, 8]\n\nIn [24]: l[1::2] # Take the elements which indexes are odd\nOut[24]: [1, 3, 5, 7, 9]\n \n\n Using  step  provides a useful trick to reverse a collection in Python: \n\n In [25]: l[::-1]\nOut[25]: [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n \n\n It is also possible to use negative integers for  step  as the following example: \n\n In[28]:  l[::-2]\nOut[28]: [9, 7, 5, 3, 1]\n \n\n However, using a negative value for  step  could become very confusing. Moreover, in order to be  Pythonic , you should avoid using  start ,  end , and  step  in a single slice. In case this is required, consider doing this in two assignments (one to slice, and the other to stride). \n\n In [29]: l = l[::2] # This step is for striding\n\nIn [30]: l\nOut[30]: [0, 2, 4, 6, 8]\n\nIn [31]: l = l[1:-1] # This step is for slicing\n\nIn [32]: l\nOut[32]: [2, 4, 6]\n \n    ", "date_posted": "2019-09-26 08:16:53Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "49647978", "answer_content": "\r\n I want to add one  Hello, World!  example that explains the basics of slices for the very beginners. It helped me a lot. \n\n Let's have a list with six values  ['P', 'Y', 'T', 'H', 'O', 'N'] : \n\n +---+---+---+---+---+---+\n| P | Y | T | H | O | N |\n+---+---+---+---+---+---+\n  0   1   2   3   4   5\n \n\n Now the simplest slices of that list are its sublists. The notation is  [<index>:<index>]  and the key is to read it like this: \n\n [ start cutting before this index : end cutting before this index ]\n \n\n Now if you make a slice  [2:5]  of the list above, this will happen: \n\n         |           |\n+---+---|---+---+---|---+\n| P | Y | T | H | O | N |\n+---+---|---+---+---|---+\n  0   1 | 2   3   4 | 5\n \n\n You made a cut  before  the element with index  2  and another cut  before  the element with index  5 . So the result will be a slice between those two cuts, a list  ['T', 'H', 'O'] . \n    ", "date_posted": "2019-09-26 08:23:54Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "46614773", "answer_content": "\r\n Most of the previous answers clears up questions about slice notation. \n\n The extended indexing syntax used for slicing is  aList[start:stop:step] , and basic examples are: \n\n : \n\n More slicing examples:  15 Extended Slices \n    ", "date_posted": "2019-09-26 08:19:02Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "45370737", "answer_content": "\r\n The below is the example of an index of a string: \n\n  +---+---+---+---+---+\n | H | e | l | p | A |\n +---+---+---+---+---+\n 0   1   2   3   4   5\n-5  -4  -3  -2  -1\n\nstr=\"Name string\"\n \n\n Slicing example: [start:end:step] \n\n str[start:end] # Items start through end-1\nstr[start:]    # Items start through the rest of the array\nstr[:end]      # Items from the beginning through end-1\nstr[:]         # A copy of the whole array\n \n\n Below is the example usage: \n\n print str[0] = N\nprint str[0:2] = Na\nprint str[0:7] = Name st\nprint str[0:7:2] = Nm t\nprint str[0:-1:2] = Nm ti\n \n    ", "date_posted": "2019-09-26 08:10:54Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "47880987", "answer_content": "\r\n If you feel negative indices in slicing is confusing, here's a very easy way to think about it: just replace the negative index with  len - index . So for example, replace -3 with  len(list) - 3 . \n\n The best way to illustrate what slicing does internally is just show it in code that implements this operation: \n\n def slice(list, start = None, end = None, step = 1):\n  # Take care of missing start/end parameters\n  start = 0 if start is None else start\n  end = len(list) if end is None else end\n\n  # Take care of negative start/end parameters\n  start = len(list) + start if start < 0 else start\n  end = len(list) + end if end < 0 else end\n\n  # Now just execute a for-loop with start, end and step\n  return [list[i] for i in range(start, end, step)]\n \n    ", "date_posted": "2019-09-26 08:22:50Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "51479594", "answer_content": "\r\n The basic slicing technique is to define the starting point, the stopping point, and the step size\u2014also known as stride. \n First, we will create a list of values to use in our slicing. \n Create two lists to slice. The first is a numeric list from 1 to 9 (List A). The second is also a numeric list, from 0 to 9 (List B): \n A = list(range(1, 10, 1)) # Start, stop, and step\nB = list(range(9))\n\nprint(\"This is List A:\", A)\nprint(\"This is List B:\", B)\n \n Index the number 3 from A and the number 6 from B. \n print(A[2])\nprint(B[6])\n \n Basic Slicing \n Extended indexing syntax used for slicing is  aList[start:stop:step] . The start argument and the step argument both default to  None \u2014the only required argument is stop. Did you notice this is similar to how range was used to define lists A and B? This is because the slice object represents the set of indices specified by  range(start, stop, step) . \n As you can see, defining only stop returns one element. Since the start defaults to none, this translates into retrieving only one element. \n It is important to note, the first element is index 0,  not  index 1. This is why we are using 2 lists for this exercise. List A's elements are numbered according to the ordinal position (the first element is 1, the second element is 2, etc.) while List B's elements are the numbers that would be used to index them ( [0]  for the first element, 0, etc.). \n With extended indexing syntax, we retrieve a range of values. For example, all values are retrieved with a colon. \n A[:]\n \n To retrieve a subset of elements, the start and stop positions need to be defined. \n Given the pattern  aList[start:stop] , retrieve the first two elements from List A. \n    ", "date_posted": "2022-04-30 17:09:16Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "241211", "name": "Michael", "reputation_score": "7,466"}, "answer_comments": []}], "user": {"stack_user_id": "24039", "name": "Simon", "reputation_score": "76.1k"}, "question_comments": []},
{"stack_question_id": "1373164", "question_title": "How do I create variable variables?", "question_content": "\r\n                How do I create the equivalent of PHP variable variable names in Python?\nI hear this is a bad idea, in general, though. Is that true?\n\nIf you are just trying to look up an existing variable by its ...\r\n", "question_url": "/questions/1373164/how-do-i-create-variable-variables", "date_posted": "Sep 3, 2009 at 12:37", "upvote": "5", "view": "2", "tags": ["python", "variable-variables"], "answers_count": "1", "answers": [{"stack_answer_id": "1373185", "answer_content": "\r\n You can use  dictionaries  to accomplish this. Dictionaries are stores of keys and values. \n >>> dct = {'x': 1, 'y': 2, 'z': 3}\n>>> dct\n{'y': 2, 'x': 1, 'z': 3}\n>>> dct[\"y\"]\n2\n \n You can use variable key names to achieve the effect of variable variables without the security risk. \n >>> x = \"spam\"\n>>> z = {x: \"eggs\"}\n>>> z[\"spam\"]\n'eggs'\n \n For cases where you're thinking of doing something like \n var1 = 'foo'\nvar2 = 'bar'\nvar3 = 'baz'\n...\n \n a  list  may be more appropriate than a dict. A list represents an ordered sequence of objects, with integer indices: \n lst = ['foo', 'bar', 'baz']\nprint(lst[1])           # prints bar, because indices start at 0\nlst.append('potatoes')  # lst is now ['foo', 'bar', 'baz', 'potatoes']\n \n For ordered sequences, lists are more convenient than dicts with integer keys, because lists support iteration in index order,  slicing ,  append , and other operations that would require awkward key management with a dict. \n    ", "date_posted": "2022-06-04 20:15:44Z", "upvote": "\r\n            404\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "4518341", "name": "wjandrea", "reputation_score": "24.1k"}, "answer_comments": []}, {"stack_answer_id": "1373198", "answer_content": "\r\n Use the built-in  getattr  function to get an attribute on an object by name.  Modify the name as needed. \n\n obj.spam = 'eggs'\nname = 'spam'\ngetattr(obj, name)  # returns 'eggs'\n \n    ", "date_posted": "2016-04-21 15:23:52Z", "upvote": "\r\n            109\r\n        ", "accepted": "No", "user": {"stack_user_id": "400617", "name": "davidism", "reputation_score": "112k"}, "answer_comments": []}, {"stack_answer_id": "1373201", "answer_content": "\r\n It's not a good idea. If you are accessing a global variable you can use  globals() . \n\n >>> a = 10\n>>> globals()['a']\n10\n \n\n If you want to access a variable in the local scope you can use  locals() , but you cannot assign values to the returned dict. \n\n A better solution  is to use  getattr  or store your variables in a dictionary and then access them by name. \n    ", "date_posted": "2017-04-24 02:03:14Z", "upvote": "\r\n            86\r\n        ", "accepted": "No", "user": {"stack_user_id": "2470818", "name": "vallentin", "reputation_score": "21.7k"}, "answer_comments": [{"stack_answer_id": "1373201", "stack_answer_comment_id": "107489989", "comment_content": " works just fine for me in Python 3.7.6; so I'm not sure what you mean when you say you cannot assign values through it.", "user_id": "None"}, {"stack_answer_id": "1373201", "stack_answer_comment_id": "107816343", "comment_content": "Given ", "user_id": "None"}, {"stack_answer_id": "1373201", "stack_answer_comment_id": "120374898", "comment_content": "The documentation of ", "user_id": "None"}, {"stack_answer_id": "1373201", "stack_answer_comment_id": "123583256", "comment_content": "@JimDennis`locals()`` provides a dictionary ", "user_id": "None"}, {"stack_answer_id": "1373201", "stack_answer_comment_id": "124099678", "comment_content": "The reason it doesn't work, at least on CPython, is that CPython allocates a fixed size array for locals, and the size of said array is determined when the function is defined, not when its run, and can't be changed (access to true locals doesn't even use the name; the name is replaced with the index into the array at function compile time). ", "user_id": "None"}]}, {"stack_answer_id": "38972761", "answer_content": "\r\n New coders sometimes write code like this: \n\n my_calculator.button_0 = tkinter.Button(root, text=0)\nmy_calculator.button_1 = tkinter.Button(root, text=1)\nmy_calculator.button_2 = tkinter.Button(root, text=2)\n...\n \n\n The coder is then left with a pile of named variables, with a coding effort of O( m  *  n ), where  m  is the number of named variables and  n  is the number of times that group of variables needs to be accessed (including creation). The more astute beginner observes that the only difference in each of those lines is a number that changes based on a rule, and decides to use a loop. However, they get stuck on how to dynamically create those variable names, and may try something like this: \n\n for i in range(10):\n    my_calculator.('button_%d' % i) = tkinter.Button(root, text=i)\n \n\n They soon find that this does not work. \n\n If the program requires arbitrary variable \"names,\" a dictionary is the best choice, as explained in other answers. However, if you're simply trying to create many variables and you don't mind referring to them with a sequence of integers, you're probably looking for a  list . This is particularly true if your data are homogeneous, such as daily temperature readings, weekly quiz scores, or a grid of graphical widgets. \n\n This can be assembled as follows: \n\n my_calculator.buttons = []\nfor i in range(10):\n    my_calculator.buttons.append(tkinter.Button(root, text=i))\n \n\n This  list  can also be created in one line with a comprehension: \n\n my_calculator.buttons = [tkinter.Button(root, text=i) for i in range(10)]\n \n\n The result in either case is a populated  list , with the first element accessed with  my_calculator.buttons[0] , the next with  my_calculator.buttons[1] , and so on. The \"base\" variable name becomes the name of the  list  and the varying identifier is used to access it. \n\n Finally, don't forget other data structures, such as the  set  - this is similar to a dictionary, except that each \"name\" doesn't have a value attached to it. If you simply need a \"bag\" of objects, this can be a great choice. Instead of something like this: \n\n keyword_1 = 'apple'\nkeyword_2 = 'banana'\n\nif query == keyword_1 or query == keyword_2:\n    print('Match.')\n \n\n You will have this: \n\n keywords = {'apple', 'banana'}\nif query in keywords:\n    print('Match.')\n \n\n Use a  list  for a sequence of similar objects, a  set  for an arbitrarily-ordered bag of objects, or a  dict  for a bag of names with associated values. \n    ", "date_posted": "2016-08-16 10:41:07Z", "upvote": "\r\n            67\r\n        ", "accepted": "No", "user": {"stack_user_id": "2617068", "name": "TigerhawkT3", "reputation_score": "47.3k"}, "answer_comments": []}, {"stack_answer_id": "1373192", "answer_content": "\r\n Whenever you want to use variable variables, it's probably better to use a dictionary. So instead of writing \n\n $foo = \"bar\"\n$$foo = \"baz\"\n \n\n you write  \n\n mydict = {}\nfoo = \"bar\"\nmydict[foo] = \"baz\"\n \n\n This way you won't accidentally overwrite previously existing variables (which is the security aspect) and you can have different \"namespaces\". \n    ", "date_posted": "2009-09-03 12:42:00Z", "upvote": "\r\n            43\r\n        ", "accepted": "No", "user": {"stack_user_id": "149392", "name": "sepp2k", "reputation_score": "356k"}, "answer_comments": []}, {"stack_answer_id": "53503041", "answer_content": "\r\n Use  globals()  (disclaimer: this is a bad practice, but is the most straightforward answer to your question, please use other data structure as in the accepted answer). \n You can actually assign variables to global scope dynamically, for instance, if you want 10 variables that can be accessed on a global scope  i_1 ,  i_2  ...  i_10 : \n for i in range(10):\n    globals()['i_{}'.format(i)] = 'a'\n \n This will assign 'a' to all of these 10 variables, of course you can change the value dynamically as well. All of these variables can be accessed now like other globally declared variable: \n >>> i_5\n'a'\n \n    ", "date_posted": "2022-08-07 18:16:34Z", "upvote": "\r\n            22\r\n        ", "accepted": "No", "user": {"stack_user_id": "8046232", "name": "Rocky Li", "reputation_score": "5,197"}, "answer_comments": [{"stack_answer_id": "53503041", "stack_answer_comment_id": "129164890", "comment_content": "Thanks for putting it in a minimal yet well explained form.", "user_id": "None"}]}, {"stack_answer_id": "37971967", "answer_content": "\r\n Instead of a dictionary you can also use  namedtuple  from the collections module, which makes access easier. \n\n For example: \n\n # using dictionary\nvariables = {}\nvariables[\"first\"] = 34\nvariables[\"second\"] = 45\nprint(variables[\"first\"], variables[\"second\"])\n\n# using namedtuple\nVariables = namedtuple('Variables', ['first', 'second'])\nvars = Variables(34, 45)\nprint(vars.first, vars.second)\n \n    ", "date_posted": "2019-05-13 14:39:12Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "37971967", "stack_answer_comment_id": "113874390", "comment_content": "Keep in mind ", "user_id": "None"}]}, {"stack_answer_id": "46269502", "answer_content": "\r\n The  SimpleNamespace  class could be used to create new attributes with  setattr , or subclass  SimpleNamespace  and create your own function to add new attribute names (variables).  \n\n from types import SimpleNamespace\n\nvariables = {\"b\":\"B\",\"c\":\"C\"}\na = SimpleNamespace(**variables)\nsetattr(a,\"g\",\"G\")\na.g = \"G+\"\nsomething = a.a\n \n    ", "date_posted": "2019-05-24 13:22:33Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "7212665", "name": "Demi-Lune", "reputation_score": "1,738"}, "answer_comments": []}, {"stack_answer_id": "46897025", "answer_content": "\r\n If you don't want to use any object, you can still use  setattr()  inside your current module: \n\n import sys\ncurrent_module = module = sys.modules[__name__]  # i.e the \"file\" where your code is written\nsetattr(current_module, 'variable_name', 15)  # 15 is the value you assign to the var\nprint(variable_name)  # >>> 15, created from a string\n \n    ", "date_posted": "2017-10-23 19:24:10Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "5823489", "name": "Guillaume Lebreton", "reputation_score": "2,178"}, "answer_comments": [{"stack_answer_id": "46897025", "stack_answer_comment_id": "84051166", "comment_content": "This does not work with ", "user_id": "None"}, {"stack_answer_id": "46897025", "stack_answer_comment_id": "84068764", "comment_content": " can do this", "user_id": "None"}]}, {"stack_answer_id": "37725729", "answer_content": "\r\n You have to use  globals()  built in method   to achieve that behaviour: \n def var_of_var(k, v):\n    globals()[k] = v\n\nprint variable_name # NameError: name 'variable_name' is not defined\nsome_name = 'variable_name'\nglobals()[some_name] = 123\nprint(variable_name) # 123\n\nsome_name = 'variable_name2'\nvar_of_var(some_name, 456)\nprint(variable_name2) # 456\n \n    ", "date_posted": "2020-10-17 07:06:59Z", "upvote": "\r\n            10\r\n        ", "accepted": "No", "user": {"stack_user_id": "2067976", "name": "Andriy Ivaneyko", "reputation_score": "18.9k"}, "answer_comments": []}, {"stack_answer_id": "40384282", "answer_content": "\r\n I'm am answering the question:  How to get the value of a variable given its name in a string? \nwhich is closed as a duplicate with a link to this question.  \n\n If the variables in question are part of an object (part of a class for example) then some useful functions to achieve exactly that are  hasattr ,  getattr , and  setattr .  \n\n So for example you can have: \n\n class Variables(object):\n    def __init__(self):\n        self.foo = \"initial_variable\"\n    def create_new_var(self,name,value):\n        setattr(self,name,value)\n    def get_var(self,name):\n        if hasattr(self,name):\n            return getattr(self,name)\n        else:\n            raise(\"Class does not have a variable named: \"+name)\n \n\n Then you can do: \n\n v = Variables()\nv.get_var(\"foo\")\n \n\n \n   \"initial_variable\" \n \n\n v.create_new_var(v.foo,\"is actually not initial\")\nv.initial_variable\n \n\n \n   \"is actually not initial\" \n \n    ", "date_posted": "2017-05-23 12:10:47Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}, {"stack_answer_id": "65673959", "answer_content": "\r\n # Python 3.8.2 (default, Feb 26 2020, 02:56:10)\n \n Variable variables in Python \n \"\"\"\n<?php\n$a = 'hello';\n$e = 'wow'\n?>\n<?php\n$$a = 'world';\n?>\n<?php\necho \"$a ${$a}\\n\";\necho \"$a ${$a[1]}\\n\";\n?>\n<?php\necho \"$a $hello\";\n?>\n\"\"\"\n\na = 'hello'  #<?php $a = 'hello'; ?>\ne = 'wow'   #<?php $e = 'wow'; ?>\nvars()[a] = 'world' #<?php $$a = 'world'; ?>\nprint(a, vars()[a]) #<?php echo \"$a ${$a}\\n\"; ?>\nprint(a, vars()[vars()['a'][1]]) #<?php echo \"$a ${$a[1]}\\n\"; ?>\nprint(a, hello) #<?php echo \"$a $hello\"; ?>\n \n Output: \n hello world\nhello wow\nhello world\n \n \n Using globals(), locals(), or vars() will produce the same results \n # Python 3.8.2 (default, Feb 26 2020, 02:56:10)\n\n#<?php $a = 'hello'; ?>\n#<?php $e = 'wow'; ?>\n#<?php $$a = 'world'; ?>\n#<?php echo \"$a ${$a}\\n\"; ?>\n#<?php echo \"$a ${$a[1]}\\n\"; ?>\n#<?php echo \"$a $hello\"; ?>\n\nprint('locals():\\n')\na = 'hello'\ne = 'wow'\nlocals()[a] = 'world'\nprint(a, locals()[a])\nprint(a, locals()[locals()['a'][1]])\nprint(a, hello)\n\nprint('\\n\\nglobals():\\n')\na = 'hello'\ne = 'wow'\nglobals()[a] = 'world'\nprint(a, globals()[a])\nprint(a, globals()[globals()['a'][1]])\nprint(a, hello)\n \n Output: \n locals():\n\nhello world\nhello wow\nhello world\n\n\nglobals():\n\nhello world\nhello wow\nhello world\n \n \n Bonus (creating variables from strings) \n # Python 2.7.16 (default, Jul 13 2019, 16:01:51)\n# [GCC 8.3.0] on linux2\n \n Creating variables and unpacking tuple: \n g = globals()\nlistB = []\nfor i in range(10):\n    g[\"num%s\" % i] = i ** 10\n    listB.append(\"num{0}\".format(i))\n\ndef printNum():\n    print \"Printing num0 to num9:\"\n    for i in range(10):\n        print \"num%s = \" % i, \n        print g[\"num%s\" % i]\n\nprintNum()\n\nlistA = []\nfor i in range(10):\n    listA.append(i)\n\nlistA = tuple(listA)\nprint listA, '\"Tuple to unpack\"'\n\nlistB = str(str(listB).strip(\"[]\").replace(\"'\", \"\") + \" = listA\")\n\nprint listB\n\nexec listB\n\nprintNum()\n \n Output: \n Printing num0 to num9:\nnum0 =  0\nnum1 =  1\nnum2 =  1024\nnum3 =  59049\nnum4 =  1048576\nnum5 =  9765625\nnum6 =  60466176\nnum7 =  282475249\nnum8 =  1073741824\nnum9 =  3486784401\n(0, 1, 2, 3, 4, 5, 6, 7, 8, 9) \"Tuple to unpack\"\nnum0, num1, num2, num3, num4, num5, num6, num7, num8, num9 = listA\nPrinting num0 to num9:\nnum0 =  0\nnum1 =  1\nnum2 =  2\nnum3 =  3\nnum4 =  4\nnum5 =  5\nnum6 =  6\nnum7 =  7\nnum8 =  8\nnum9 =  9\n \n    ", "date_posted": "2021-03-09 16:18:44Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "14916988", "name": "mOmOney", "reputation_score": "175"}, "answer_comments": []}, {"stack_answer_id": "59333920", "answer_content": "\r\n I have tried both in python 3.7.3, you can use either globals() or vars() \n\n >>> food #Error\n>>> milkshake #Error\n>>> food=\"bread\"\n>>> drink=\"milkshake\"\n>>> globals()[food] = \"strawberry flavor\"\n>>> vars()[drink] = \"chocolate flavor\"\n>>> bread\n'strawberry flavor'\n>>> milkshake\n'chocolate flavor'\n>>> globals()[drink]\n'chocolate flavor'\n>>> vars()[food]\n'strawberry flavor'\n \n\n \n\n Reference: \n https://www.daniweb.com/programming/software-development/threads/111526/setting-a-string-as-a-variable-name#post548936 \n    ", "date_posted": "2019-12-14 09:39:02Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "7069108", "name": "Hzzkygcs", "reputation_score": "1,091"}, "answer_comments": []}, {"stack_answer_id": "37725113", "answer_content": "\r\n The consensus is to use a dictionary for this - see the other answers. This is a good idea for most cases, however, there are many aspects arising from this: \n\n \n you'll yourself be responsible for this dictionary, including garbage collection (of in-dict variables) etc. \n there's either no locality or globality for variable variables, it depends on the globality of the dictionary \n if you want to rename a variable name, you'll have to do it manually \n however, you are much more flexible, e.g. \n\n \n you can decide to overwrite existing variables or  ... \n ... choose to implement const variables \n to raise an exception on overwriting for different types \n etc. \n \n \n\n That said, I've implemented a  variable variables manager -class which provides some of the above ideas. It works for python 2 and 3. \n\n You'd use  the class  like this: \n\n from variableVariablesManager import VariableVariablesManager\n\nmyVars = VariableVariablesManager()\nmyVars['test'] = 25\nprint(myVars['test'])\n\n# define a const variable\nmyVars.defineConstVariable('myconst', 13)\ntry:\n    myVars['myconst'] = 14 # <- this raises an error, since 'myconst' must not be changed\n    print(\"not allowed\")\nexcept AttributeError as e:\n    pass\n\n# rename a variable\nmyVars.renameVariable('myconst', 'myconstOther')\n\n# preserve locality\ndef testLocalVar():\n    myVars = VariableVariablesManager()\n    myVars['test'] = 13\n    print(\"inside function myVars['test']:\", myVars['test'])\ntestLocalVar()\nprint(\"outside function myVars['test']:\", myVars['test'])\n\n# define a global variable\nmyVars.defineGlobalVariable('globalVar', 12)\ndef testGlobalVar():\n    myVars = VariableVariablesManager()\n    print(\"inside function myVars['globalVar']:\", myVars['globalVar'])\n    myVars['globalVar'] = 13\n    print(\"inside function myVars['globalVar'] (having been changed):\", myVars['globalVar'])\ntestGlobalVar()\nprint(\"outside function myVars['globalVar']:\", myVars['globalVar'])\n \n\n If you wish to allow overwriting of variables with the same type only: \n\n myVars = VariableVariablesManager(enforceSameTypeOnOverride = True)\nmyVars['test'] = 25\nmyVars['test'] = \"Cat\" # <- raises Exception (different type on overwriting)\n \n    ", "date_posted": "2016-06-09 12:10:59Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "1150303", "name": "DomTomCat", "reputation_score": "7,753"}, "answer_comments": []}, {"stack_answer_id": "45643867", "answer_content": "\r\n Any set of variables can also be wrapped up in a class. \n\"Variable\" variables may be added to the class instance during runtime by directly accessing the built-in dictionary through __dict__ attribute.  \n\n The following code defines Variables class, which adds variables (in this case attributes) to its instance during the construction. Variable names are taken from a specified list (which, for example, could have been generated by program code): \n\n # some list of variable names\nL = ['a', 'b', 'c']\n\nclass Variables:\n    def __init__(self, L):\n        for item in L:\n            self.__dict__[item] = 100\n\nv = Variables(L)\nprint(v.a, v.b, v.c)\n#will produce 100 100 100\n \n    ", "date_posted": "2017-08-11 21:13:57Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "8418961", "name": "ru13r", "reputation_score": "174"}, "answer_comments": []}, {"stack_answer_id": "65963716", "answer_content": "\r\n It should be extremely risky...\nbut you can use exec(): \n a = 'b=5'\nexec(a)\nc = b*2\nprint (c)\n \n Result:\n10 \n    ", "date_posted": "2021-01-30 01:15:36Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "5832844", "name": "Ruben Medrano", "reputation_score": "141"}, "answer_comments": [{"stack_answer_id": "65963716", "stack_answer_comment_id": "122682749", "comment_content": "This won't work inside a function. It's essentially equivalent to the safer ", "user_id": "None"}, {"stack_answer_id": "65963716", "stack_answer_comment_id": "127047992", "comment_content": "@benrg Do you know how to get around Rubens failed suggestion because I'm stuck with the same situation? I have a file containing a long list of variable assignments as a collective string. I need to turn them into python assignments but eval() and exec() both fails.", "user_id": "None"}]}, {"stack_answer_id": "71715887", "answer_content": "\r\n The  setattr()  method sets the value of the specified attribute of the specified object. \n Syntax goes like this \u2013 \n setattr(object, name, value)\nExample \u2013\n\nsetattr(self,id,123)\n \n which is equivalent to  self.id = 123 \n As you might have observed, setattr() expects an object to be passed along with the value to generate/modify a new attribute. \n We can use setattr() with a workaround to be able to use within modules. Here\u2019 how \u2013 \n import sys\nx = \"pikachu\"\nvalue = 46\nthismodule = sys.modules[__name__]\nsetattr(thismodule, x, value)\nprint(pikachu)\n \n    ", "date_posted": "2022-04-02 08:12:48Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "14399724", "name": "kannappan", "reputation_score": "199"}, "answer_comments": []}], "user": {"stack_user_id": null, "name": null, "reputation_score": 0}, "question_comments": [{"stack_question_id": "1373164", "stack_question_comment_id": "1212436", "comment_content": "it's the maintainance and debugging aspects that cause the horror. Imagine trying to find out where variable 'foo' changed when there's no place in your code where you actually change 'foo'. Imagine further that it's someone else's code that you have to maintain... OK, you can go to your happy place now.", "user_id": "None"}, {"stack_question_id": "1373164", "stack_question_comment_id": "43554197", "comment_content": "A further pitfall that hasn't been mentioned so far is if such a dynamically-created variable has the same name as a variable used in your logic. You essentially open up your software as a hostage to the input it is given.", "user_id": "None"}, {"stack_question_id": "1373164", "stack_question_comment_id": "107490205", "comment_content": "You can modify your global and local variables by accessing the underlying dictionaries for them; it's a horrible idea from a maintenance perspective ... but it can be done via ", "user_id": "None"}, {"stack_question_id": "1373164", "stack_question_comment_id": "109448744", "comment_content": "@JimDennis actually, no it can't. Modifications to the dict returned by ", "user_id": "None"}, {"stack_question_id": "1373164", "stack_question_comment_id": "109570795", "comment_content": "@juanpa.arrivillaga: I had tried testing this in an IPython shell, but did so at the top level (where locals() behaves like globsls()).  Redoing that test within a nested code (within the definition of a function) does show that I can't modify locals() from within that.  As you say, the help for locals (3.7.6) does warn: ", "user_id": "None"}]},
{"stack_question_id": "23294658", "question_title": "Asking the user for input until they give a valid response", "question_content": "\r\n                I am writing a program that accepts user input.\n#note: Python 2.7 users should use `raw_input`, the equivalent of 3.X's `input`\nage = int(input(\"Please enter your age: \"))\nif age >= 18: \n ...\r\n", "question_url": "/questions/23294658/asking-the-user-for-input-until-they-give-a-valid-response", "date_posted": null, "upvote": "7", "view": "8", "tags": ["python", "validation", "input"], "answers_count": "2", "answers": [{"stack_answer_id": "23294659", "answer_content": "\r\n The simplest way to accomplish this is to put the  input  method in a while loop. Use  continue  when you get bad input, and  break  out of the loop when you're satisfied. \n\n When Your Input Might Raise an Exception \n\n Use  try  and  except  to detect when the user enters data that can't be parsed. \n\n while True:\n    try:\n        # Note: Python 2.x users should use raw_input, the equivalent of 3.x's input\n        age = int(input(\"Please enter your age: \"))\n    except ValueError:\n        print(\"Sorry, I didn't understand that.\")\n        #better try again... Return to the start of the loop\n        continue\n    else:\n        #age was successfully parsed!\n        #we're ready to exit the loop.\n        break\nif age >= 18: \n    print(\"You are able to vote in the United States!\")\nelse:\n    print(\"You are not able to vote in the United States.\")\n \n\n Implementing Your Own Validation Rules \n\n If you want to reject values that Python can successfully parse, you can add your own validation logic. \n\n while True:\n    data = input(\"Please enter a loud message (must be all caps): \")\n    if not data.isupper():\n        print(\"Sorry, your response was not loud enough.\")\n        continue\n    else:\n        #we're happy with the value given.\n        #we're ready to exit the loop.\n        break\n\nwhile True:\n    data = input(\"Pick an answer from A to D:\")\n    if data.lower() not in ('a', 'b', 'c', 'd'):\n        print(\"Not an appropriate choice.\")\n    else:\n        break\n \n\n Combining Exception Handling and Custom Validation \n\n Both of the above techniques can be combined into one loop. \n\n while True:\n    try:\n        age = int(input(\"Please enter your age: \"))\n    except ValueError:\n        print(\"Sorry, I didn't understand that.\")\n        continue\n\n    if age < 0:\n        print(\"Sorry, your response must not be negative.\")\n        continue\n    else:\n        #age was successfully parsed, and we're happy with its value.\n        #we're ready to exit the loop.\n        break\nif age >= 18: \n    print(\"You are able to vote in the United States!\")\nelse:\n    print(\"You are not able to vote in the United States.\")\n \n\n Encapsulating it All in a Function \n\n If you need to ask your user for a lot of different values, it might be useful to put this code in a function, so you don't have to retype it every time. \n\n def get_non_negative_int(prompt):\n    while True:\n        try:\n            value = int(input(prompt))\n        except ValueError:\n            print(\"Sorry, I didn't understand that.\")\n            continue\n\n        if value < 0:\n            print(\"Sorry, your response must not be negative.\")\n            continue\n        else:\n            break\n    return value\n\nage = get_non_negative_int(\"Please enter your age: \")\nkids = get_non_negative_int(\"Please enter the number of children you have: \")\nsalary = get_non_negative_int(\"Please enter your yearly earnings, in dollars: \")\n \n\n Putting It All Together \n\n You can extend this idea to make a very generic input function: \n\n def sanitised_input(prompt, type_=None, min_=None, max_=None, range_=None):\n    if min_ is not None and max_ is not None and max_ < min_:\n        raise ValueError(\"min_ must be less than or equal to max_.\")\n    while True:\n        ui = input(prompt)\n        if type_ is not None:\n            try:\n                ui = type_(ui)\n            except ValueError:\n                print(\"Input type must be {0}.\".format(type_.__name__))\n                continue\n        if max_ is not None and ui > max_:\n            print(\"Input must be less than or equal to {0}.\".format(max_))\n        elif min_ is not None and ui < min_:\n            print(\"Input must be greater than or equal to {0}.\".format(min_))\n        elif range_ is not None and ui not in range_:\n            if isinstance(range_, range):\n                template = \"Input must be between {0.start} and {0.stop}.\"\n                print(template.format(range_))\n            else:\n                template = \"Input must be {0}.\"\n                if len(range_) == 1:\n                    print(template.format(*range_))\n                else:\n                    expected = \" or \".join((\n                        \", \".join(str(x) for x in range_[:-1]),\n                        str(range_[-1])\n                    ))\n                    print(template.format(expected))\n        else:\n            return ui\n \n\n With usage such as: \n\n age = sanitised_input(\"Enter your age: \", int, 1, 101)\nanswer = sanitised_input(\"Enter your answer: \", str.lower, range_=('a', 'b', 'c', 'd'))\n \n\n Common Pitfalls, and Why you Should Avoid Them \n\n The Redundant Use of Redundant  input  Statements \n\n This method works but is generally considered poor style: \n\n data = input(\"Please enter a loud message (must be all caps): \")\nwhile not data.isupper():\n    print(\"Sorry, your response was not loud enough.\")\n    data = input(\"Please enter a loud message (must be all caps): \")\n \n\n It might look attractive initially because it's shorter than the  while True  method, but it violates the  Don't Repeat Yourself  principle of software development. This increases the likelihood of bugs in your system. What if you want to backport to 2.7 by changing  input  to  raw_input , but accidentally change only the first  input  above? It's a  SyntaxError  just waiting to happen. \n\n Recursion Will Blow Your Stack \n\n If you've just learned about recursion, you might be tempted to use it in  get_non_negative_int  so you can dispose of the while loop. \n\n def get_non_negative_int(prompt):\n    try:\n        value = int(input(prompt))\n    except ValueError:\n        print(\"Sorry, I didn't understand that.\")\n        return get_non_negative_int(prompt)\n\n    if value < 0:\n        print(\"Sorry, your response must not be negative.\")\n        return get_non_negative_int(prompt)\n    else:\n        return value\n \n\n This appears to work fine most of the time, but if the user enters invalid data enough times, the script will terminate with a  RuntimeError: maximum recursion depth exceeded . You may think \"no fool would make 1000 mistakes in a row\", but you're underestimating the ingenuity of fools! \n    ", "date_posted": "2020-06-06 17:56:58Z", "upvote": "\r\n            926\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "23294659", "name": "\r\n        9 revs, 7 users 73%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "23294659", "stack_answer_comment_id": "70076872", "comment_content": "Its fun reading it with many examples, kudos. Underrated lesson: \"Don't underestimate the ingenuity of fools!\"", "user_id": "None"}, {"stack_answer_id": "23294659", "stack_answer_comment_id": "84169769", "comment_content": "Not only would I have upvoted both the Q&A anyway, as they're great, but you sealed the deal with \"dickety six\". Well done, @Kevin.", "user_id": "None"}, {"stack_answer_id": "23294659", "stack_answer_comment_id": "98430983", "comment_content": "Don't estimate the ingenuity of fools... and clever attackers. A DOS attack would be easiest for this sort of thing, but others may be possible.", "user_id": "None"}, {"stack_answer_id": "23294659", "stack_answer_comment_id": "109126499", "comment_content": "@JArunMani I don't think it would be poor style, but might be a little less readable. You will indeed have only one ", "user_id": "None"}, {"stack_answer_id": "23294659", "stack_answer_comment_id": "111538982", "comment_content": "@laundmo,certainly I release the code blocks that I wrote into the public domain. Feel free to use them in any context, without my explicit permission or knowledge. Regarding the non-code-block segments, If you want to paste my entire answer into a \"Learn Python\" book you're writing, let's talk royalties ;-)", "user_id": "953482"}]}, {"stack_answer_id": "34789951", "answer_content": "\r\n Why would you do a  while True  and then break out of this loop while you can also just put your requirements in the while statement since all you want is to stop once you have the age? \n\n age = None\nwhile age is None:\n    input_value = input(\"Please enter your age: \")\n    try:\n        # try and convert the string input to a number\n        age = int(input_value)\n    except ValueError:\n        # tell the user off\n        print(\"{input} is not a number, please enter a number only\".format(input=input_value))\nif age >= 18:\n    print(\"You are able to vote in the United States!\")\nelse:\n    print(\"You are not able to vote in the United States.\")\n \n\n This would result in the following: \n\n Please enter your age: *potato*\npotato is not a number, please enter a number only\nPlease enter your age: *5*\nYou are not able to vote in the United States.\n \n\n this will work since age will never have a value that will not make sense and the code follows the logic of your \"business process\" \n    ", "date_posted": "2018-02-24 16:44:54Z", "upvote": "\r\n            56\r\n        ", "accepted": "No", "user": {"stack_user_id": "34789951", "name": "\r\n        2 revs, 2 users 96%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "34789951", "stack_answer_comment_id": "128352468", "comment_content": "A well-designed ", "user_id": "None"}]}, {"stack_answer_id": "31105868", "answer_content": "\r\n Though the accepted answer is amazing. I would also like to share a quick hack for this problem. (This takes care of the negative age problem as well.)  \n\n f=lambda age: (age.isdigit() and ((int(age)>=18  and \"Can vote\" ) or \"Cannot vote\")) or \\\nf(input(\"invalid input. Try again\\nPlease enter your age: \"))\nprint(f(input(\"Please enter your age: \")))\n \n\n P.S. This code is for python 3.x. \n    ", "date_posted": "2018-12-21 18:25:22Z", "upvote": "\r\n            28\r\n        ", "accepted": "No", "user": {"stack_user_id": "31105868", "name": "\r\n        2 revs, 2 users 78%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "31105868", "stack_answer_comment_id": "57944049", "comment_content": "Note that this code is recursive, but recursion isn't necessary here, and as Kevin said, it can blow your stack.", "user_id": "None"}, {"stack_answer_id": "31105868", "stack_answer_comment_id": "58062327", "comment_content": "@PM2Ring - you are right. But my purpose here was just to show how \"short circuiting\" can minimise (beautify) long pieces of code.", "user_id": "None"}, {"stack_answer_id": "31105868", "stack_answer_comment_id": "75053395", "comment_content": "Why would you assign a lambda to a variable, just use ", "user_id": "None"}, {"stack_answer_id": "31105868", "stack_answer_comment_id": "75054358", "comment_content": "In some cases, you may need the age just once and then there is no use of that function. One may want to use a function and throw it away after the job is done. Also, this may not be the best way, but it definitely is a different way of doing it (which was the purpose of my solution).", "user_id": "None"}, {"stack_answer_id": "31105868", "stack_answer_comment_id": "100333779", "comment_content": "@aaveg how would you turn this code to actually save the age provided by the user?", "user_id": "None"}]}, {"stack_answer_id": "56081775", "answer_content": "\r\n Functional approach  or \" look mum no loops! \": \n from itertools import chain, repeat\n\nprompts = chain([\"Enter a number: \"], repeat(\"Not a number! Try again: \"))\nreplies = map(input, prompts)\nvalid_response = next(filter(str.isdigit, replies))\nprint(valid_response)\n \n Enter a number:  a\nNot a number! Try again:  b\nNot a number! Try again:  1\n1\n \n or if you want to have a \"bad input\" message separated from an input prompt as in other answers: \n prompt_msg = \"Enter a number: \"\nbad_input_msg = \"Sorry, I didn't understand that.\"\nprompts = chain([prompt_msg], repeat('\\n'.join([bad_input_msg, prompt_msg])))\nreplies = map(input, prompts)\nvalid_response = next(filter(str.isdigit, replies))\nprint(valid_response)\n \n Enter a number:  a\nSorry, I didn't understand that.\nEnter a number:  b\nSorry, I didn't understand that.\nEnter a number:  1\n1\n \n How does it work? \n \n \n prompts = chain([\"Enter a number: \"], repeat(\"Not a number! Try again: \"))\n \nThis combination of  itertools.chain  and  itertools.repeat  will create an iterator\nwhich will yield strings  \"Enter a number: \"  once, and  \"Not a number! Try again: \"  an infinite number of times:\n for prompt in prompts:\n    print(prompt)\n \n Enter a number: \nNot a number! Try again: \nNot a number! Try again: \nNot a number! Try again: \n# ... and so on\n \n \n replies = map(input, prompts)  - here  map  will apply all the  prompts  strings from the previous step to the  input  function. E.g.:\n for reply in replies:\n    print(reply)\n \n Enter a number:  a\na\nNot a number! Try again:  1\n1\nNot a number! Try again:  it doesn't care now\nit doesn't care now\n# and so on...\n \n \n We use  filter  and  str.isdigit  to filter out those strings that contain only digits:\n only_digits = filter(str.isdigit, replies)\nfor reply in only_digits:\n    print(reply)\n \n Enter a number:  a\nNot a number! Try again:  1\n1\nNot a number! Try again:  2\n2\nNot a number! Try again:  b\nNot a number! Try again: # and so on...\n \nAnd to get only the first digits-only string we use  next . \n \n Other validation rules: \n \n String methods:  Of course you can use other string methods like  str.isalpha  to get only alphabetic strings, or  str.isupper  to get only uppercase. See  docs  for the full list. \n \n Membership testing: \nThere are several different ways to perform it. One of them is by using  __contains__  method: \n from itertools import chain, repeat\n\nfruits = {'apple', 'orange', 'peach'}\nprompts = chain([\"Enter a fruit: \"], repeat(\"I don't know this one! Try again: \"))\nreplies = map(input, prompts)\nvalid_response = next(filter(fruits.__contains__, replies))\nprint(valid_response)\n \n Enter a fruit:  1\nI don't know this one! Try again:  foo\nI don't know this one! Try again:  apple\napple\n \n \n Numbers comparison: \nThere are useful comparison methods which we can use here. For example, for  __lt__  ( < ): \n from itertools import chain, repeat\n\nprompts = chain([\"Enter a positive number:\"], repeat(\"I need a positive number! Try again:\"))\nreplies = map(input, prompts)\nnumeric_strings = filter(str.isnumeric, replies)\nnumbers = map(float, numeric_strings)\nis_positive = (0.).__lt__\nvalid_response = next(filter(is_positive, numbers))\nprint(valid_response)\n \n Enter a positive number: a\nI need a positive number! Try again: -5\nI need a positive number! Try again: 0\nI need a positive number! Try again: 5\n5.0\n \n Or, if you don't like using dunder methods (dunder = double-underscore), you can always define your own function, or use the ones from the  operator  module. \n \n Path existance: \nHere one can use  pathlib  library and its  Path.exists  method: \n from itertools import chain, repeat\nfrom pathlib import Path\n\nprompts = chain([\"Enter a path: \"], repeat(\"This path doesn't exist! Try again: \"))\nreplies = map(input, prompts)\npaths = map(Path, replies)\nvalid_response = next(filter(Path.exists, paths))\nprint(valid_response)\n \n Enter a path:  a b c\nThis path doesn't exist! Try again:  1\nThis path doesn't exist! Try again:  existing_file.txt\nexisting_file.txt\n \n \n \n Limiting number of tries: \n If you don't want to torture a user by asking him something an infinite number of times, you can specify a limit in a call of  itertools.repeat . This can be combined with providing a default value to the  next  function: \n from itertools import chain, repeat\n\nprompts = chain([\"Enter a number:\"], repeat(\"Not a number! Try again:\", 2))\nreplies = map(input, prompts)\nvalid_response = next(filter(str.isdigit, replies), None)\nprint(\"You've failed miserably!\" if valid_response is None else 'Well done!')\n \n Enter a number: a\nNot a number! Try again: b\nNot a number! Try again: c\nYou've failed miserably!\n \n Preprocessing input data: \n Sometimes we don't want to reject an input if the user accidentally supplied it  IN CAPS  or with a space in the beginning or an end of the string. To take these simple mistakes into account we can preprocess the input data by applying  str.lower  and  str.strip  methods. For example, for the case of membership testing the code will look like this: \n from itertools import chain, repeat\n\nfruits = {'apple', 'orange', 'peach'}\nprompts = chain([\"Enter a fruit: \"], repeat(\"I don't know this one! Try again: \"))\nreplies = map(input, prompts)\nlowercased_replies = map(str.lower, replies)\nstripped_replies = map(str.strip, lowercased_replies)\nvalid_response = next(filter(fruits.__contains__, stripped_replies))\nprint(valid_response)\n \n Enter a fruit:  duck\nI don't know this one! Try again:     Orange\norange\n \n In the case when you have many functions to use for preprocessing, it might be easier to use a function performing a  function composition . For example, using the one from  here : \n from itertools import chain, repeat\n\nfrom lz.functional import compose\n\nfruits = {'apple', 'orange', 'peach'}\nprompts = chain([\"Enter a fruit: \"], repeat(\"I don't know this one! Try again: \"))\nreplies = map(input, prompts)\nprocess = compose(str.strip, str.lower)  # you can add more functions here\nprocessed_replies = map(process, replies)\nvalid_response = next(filter(fruits.__contains__, processed_replies))\nprint(valid_response)\n \n Enter a fruit:  potato\nI don't know this one! Try again:   PEACH\npeach\n \n Combining validation rules: \n For a simple case, for example, when the program asks for age between 1 and 120, one can just add another  filter : \n from itertools import chain, repeat\n\nprompt_msg = \"Enter your age (1-120): \"\nbad_input_msg = \"Wrong input.\"\nprompts = chain([prompt_msg], repeat('\\n'.join([bad_input_msg, prompt_msg])))\nreplies = map(input, prompts)\nnumeric_replies = filter(str.isdigit, replies)\nages = map(int, numeric_replies)\npositive_ages = filter((0).__lt__, ages)\nnot_too_big_ages = filter((120).__ge__, positive_ages)\nvalid_response = next(not_too_big_ages)\nprint(valid_response)\n \n But in the case when there are many rules, it's better to implement a function performing a  logical conjunction . In the following example I will use a ready one from  here : \n from functools import partial\nfrom itertools import chain, repeat\n\nfrom lz.logical import conjoin\n\n\ndef is_one_letter(string: str) -> bool:\n    return len(string) == 1\n\n\nrules = [str.isalpha, str.isupper, is_one_letter, 'C'.__le__, 'P'.__ge__]\n\nprompt_msg = \"Enter a letter (C-P): \"\nbad_input_msg = \"Wrong input.\"\nprompts = chain([prompt_msg], repeat('\\n'.join([bad_input_msg, prompt_msg])))\nreplies = map(input, prompts)\nvalid_response = next(filter(conjoin(*rules), replies))\nprint(valid_response)\n \n Enter a letter (C-P):  5\nWrong input.\nEnter a letter (C-P):  f\nWrong input.\nEnter a letter (C-P):  CDE\nWrong input.\nEnter a letter (C-P):  Q\nWrong input.\nEnter a letter (C-P):  N\nN\n \n Unfortunately, if someone needs a custom message for each failed case, then, I'm afraid, there is no  pretty  functional way. Or, at least, I couldn't find one. \n    ", "date_posted": "2020-06-20 09:12:55Z", "upvote": "\r\n            28\r\n        ", "accepted": "No", "user": {"stack_user_id": "56081775", "name": "\r\n        3 revs", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "56081775", "stack_answer_comment_id": "102050848", "comment_content": "What a thorough and wonderful answer, the explanation breakdown was great.", "user_id": "None"}, {"stack_answer_id": "56081775", "stack_answer_comment_id": "102061971", "comment_content": "Using your style, how would one go about stripping whitespace and lower-casing the input for membership testing? I don't want to create a set that must include both upper and lowercase examples. I would also like to allow for whitespace input mistakes.", "user_id": "None"}, {"stack_answer_id": "56081775", "stack_answer_comment_id": "102075725", "comment_content": "@Austin I added a new section on preprocessing. Take a look.", "user_id": "None"}, {"stack_answer_id": "56081775", "stack_answer_comment_id": "110069223", "comment_content": "That reminds me of ReactiveX. But perhaps that was inspired by functional languages in the first place?", "user_id": "None"}]}, {"stack_answer_id": "56084305", "answer_content": "\r\n Using  Click : \n Click  is a library for command-line interfaces and it provides functionality for asking a valid response from a user. \n Simple example: \n import click\n\nnumber = click.prompt('Please enter a number', type=float)\nprint(number)\n \n Please enter a number: \n a\nError: a is not a valid floating point value\nPlease enter a number: \n 10\n10.0\n \n Note how it converted the string value to a float automatically. \n Checking if a value is within a range: \n There are different  custom types  provided. To get a number in a specific range we can use  IntRange : \n age = click.prompt(\"What's your age?\", type=click.IntRange(1, 120))\nprint(age)\n \n What's your age?: \n a\nError: a is not a valid integer\nWhat's your age?: \n 0\nError: 0 is not in the valid range of 1 to 120.\nWhat's your age?: \n 5\n5\n \n We can also specify just one of the limits,  min  or  max : \n age = click.prompt(\"What's your age?\", type=click.IntRange(min=14))\nprint(age)\n \n What's your age?: \n 0\nError: 0 is smaller than the minimum valid value 14.\nWhat's your age?: \n 18\n18\n \n Membership testing: \n Using  click.Choice  type. By default this check is case-sensitive. \n choices = {'apple', 'orange', 'peach'}\nchoice = click.prompt('Provide a fruit', type=click.Choice(choices, case_sensitive=False))\nprint(choice)\n \n Provide a fruit (apple, peach, orange): \n banana\nError: invalid choice: banana. (choose from apple, peach, orange)\nProvide a fruit (apple, peach, orange): \n OrAnGe\norange\n \n Working with paths and files: \n Using a  click.Path  type we can check for existing paths and also resolve them: \n path = click.prompt('Provide path', type=click.Path(exists=True, resolve_path=True))\nprint(path)\n \n Provide path: \n nonexistent\nError: Path \"nonexistent\" does not exist.\nProvide path: \n existing_folder\n'/path/to/existing_folder\n \n Reading and writing files can be done by  click.File : \n file = click.prompt('In which file to write data?', type=click.File('w'))\nwith file.open():\n    file.write('Hello!')\n# More info about `lazy=True` at:\n# https://click.palletsprojects.com/en/7.x/arguments/#file-opening-safety\nfile = click.prompt('Which file you wanna read?', type=click.File(lazy=True))\nwith file.open():\n    print(file.read())\n \n In which file to write data?: \n         # <-- provided an empty string, which is an illegal name for a file\nIn which file to write data?: \n some_file.txt\nWhich file you wanna read?: \n nonexistent.txt\nError: Could not open file: nonexistent.txt: No such file or directory\nWhich file you wanna read?: \n some_file.txt\nHello!\n \n Other examples: \n Password confirmation: \n password = click.prompt('Enter password', hide_input=True, confirmation_prompt=True)\nprint(password)\n \n Enter password: \n \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\nRepeat for confirmation: \n \u00b7\nError: the two entered values do not match\nEnter password: \n \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\nRepeat for confirmation: \n \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\nqwerty\n \n Default values: \n In this case, simply pressing  Enter  (or whatever key you use) without entering a value, will give you a default one: \n number = click.prompt('Please enter a number', type=int, default=42)\nprint(number)\n \n Please enter a number [42]: \n a\nError: a is not a valid integer\nPlease enter a number [42]: \n \n42\n \n    ", "date_posted": "2020-06-20 09:12:55Z", "upvote": "\r\n            20\r\n        ", "accepted": "No", "user": {"stack_user_id": "56084305", "name": "\r\n        2 revs", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "56084305", "stack_answer_comment_id": "110338437", "comment_content": "Thanks, this is perfect. Looping with a number selection in a valid range was exactly what i was looking for.", "user_id": "None"}]}, {"stack_answer_id": "35110110", "answer_content": "\r\n So, I was messing around with something similar to this recently, and I came up with the following solution, which uses a way of getting input that rejects junk, before it's even checked in any logical way. \n\n read_single_keypress()  courtesy  https://stackoverflow.com/a/6599441/4532996 \n\n def read_single_keypress() -> str:\n    \"\"\"Waits for a single keypress on stdin.\n    -- from :: https://stackoverflow.com/a/6599441/4532996\n    \"\"\"\n\n    import termios, fcntl, sys, os\n    fd = sys.stdin.fileno()\n    # save old state\n    flags_save = fcntl.fcntl(fd, fcntl.F_GETFL)\n    attrs_save = termios.tcgetattr(fd)\n    # make raw - the way to do this comes from the termios(3) man page.\n    attrs = list(attrs_save) # copy the stored version to update\n    # iflag\n    attrs[0] &= ~(termios.IGNBRK | termios.BRKINT | termios.PARMRK\n                  | termios.ISTRIP | termios.INLCR | termios. IGNCR\n                  | termios.ICRNL | termios.IXON )\n    # oflag\n    attrs[1] &= ~termios.OPOST\n    # cflag\n    attrs[2] &= ~(termios.CSIZE | termios. PARENB)\n    attrs[2] |= termios.CS8\n    # lflag\n    attrs[3] &= ~(termios.ECHONL | termios.ECHO | termios.ICANON\n                  | termios.ISIG | termios.IEXTEN)\n    termios.tcsetattr(fd, termios.TCSANOW, attrs)\n    # turn off non-blocking\n    fcntl.fcntl(fd, fcntl.F_SETFL, flags_save & ~os.O_NONBLOCK)\n    # read a single keystroke\n    try:\n        ret = sys.stdin.read(1) # returns a single character\n    except KeyboardInterrupt:\n        ret = 0\n    finally:\n        # restore old state\n        termios.tcsetattr(fd, termios.TCSAFLUSH, attrs_save)\n        fcntl.fcntl(fd, fcntl.F_SETFL, flags_save)\n    return ret\n\ndef until_not_multi(chars) -> str:\n    \"\"\"read stdin until !(chars)\"\"\"\n    import sys\n    chars = list(chars)\n    y = \"\"\n    sys.stdout.flush()\n    while True:\n        i = read_single_keypress()\n        _ = sys.stdout.write(i)\n        sys.stdout.flush()\n        if i not in chars:\n            break\n        y += i\n    return y\n\ndef _can_you_vote() -> str:\n    \"\"\"a practical example:\n    test if a user can vote based purely on keypresses\"\"\"\n    print(\"can you vote? age : \", end=\"\")\n    x = int(\"0\" + until_not_multi(\"0123456789\"))\n    if not x:\n        print(\"\\nsorry, age can only consist of digits.\")\n        return\n    print(\"your age is\", x, \"\\nYou can vote!\" if x >= 18 else \"Sorry! you can't vote\")\n\n_can_you_vote()\n \n\n You can find the complete module  here . \n\n Example: \n\n $ ./input_constrain.py\ncan you vote? age : a\nsorry, age can only consist of digits.\n$ ./input_constrain.py \ncan you vote? age : 23<RETURN>\nyour age is 23\nYou can vote!\n$ _\n \n\n Note that the nature of this implementation is it closes stdin as soon as something that isn't a digit is read. I didn't hit enter after  a , but I needed to after the numbers. \n\n You could merge this with the  thismany()  function in the same module to only allow, say, three digits. \n    ", "date_posted": "2017-05-23 12:34:45Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "35110110", "name": "\r\n        3 revs", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "35110110", "stack_answer_comment_id": "114263253", "comment_content": "If you're already detecting key strokes, why allow characters at all and throw errors around, when you can just silently ignore them, until you get the desired number?", "user_id": "None"}, {"stack_answer_id": "35110110", "stack_answer_comment_id": "114279945", "comment_content": "@Kebman you could do that but it might be less obvious to the user what they can type", "user_id": "None"}]}, {"stack_answer_id": "64604056", "answer_content": "\r\n I am a big fan of Unix philosophy \"Do one thing and do it well\". Capturing user input and validating it are two separate steps: \n \n prompting the user for input with  get_input  until the input is ok \n validating using a  validator  function that can be passed to  get_input \n \n It can be kept as simple as (Python 3.8+, with  the walrus operator): \n def get_input(\n    prompt=\"Enter a value: \",\n    validator=lambda x: True,\n    error_message=\"Invalid input. Please try again.\",\n):\n    while not validator(value := input(prompt)):\n        print(error_message)\n    return value\n\ndef is_positive_int(value):\n    try:\n        return int(value) >= 0\n    except ValueError:\n        return False\n\nif __name__ == \"__main__\":\n    val = get_input(\"Give a positive number: \", is_positive_int)\n    print(f\"OK, thanks for {val}\")\n \n Sample run: \n Give a positive number: -5\nInvalid input. Please try again.\nGive a positive number: asdf\nInvalid input. Please try again.\nGive a positive number:\nInvalid input. Please try again.\nGive a positive number: 42\nOK, thanks for 42\n \n \n In Python < 3.8 you could use  get_input  like this: \n def get_input(\n    prompt=\"Enter a value: \",\n    validator=lambda x: True,\n    error_message=\"Invalid input. Please try again.\",\n):\n    while True:\n        value = input(prompt)\n        if validator(value):\n            return value\n        print(error_message)\n \n You might also handle  KeyboardInterrupt  and print a friendly exit message before terminating the application. A counter can be used to limit the allowed retries if desired. \n    ", "date_posted": "2022-01-28 06:18:26Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "64604056", "name": "\r\n        3 revs, 2 users 73%", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "63811753", "answer_content": "\r\n Use try-except to handle the error and repeat it again: \n while True:\n    try:\n        age = int(input(\"Please enter your age: \"))\n        if age >= 18:\n            print(\"You are able to vote in the United States!\")\n        else:\n            print(\"You are not able to vote in the United States.\")\n    except Exception as e:\n        print(\"please enter number\")\n \n    ", "date_posted": "2020-09-11 14:11:56Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "63811753", "name": "\r\n        2 revs, 2 users 62%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "63811753", "stack_answer_comment_id": "112906023", "comment_content": "You are missing a ", "user_id": "None"}]}, {"stack_answer_id": "53522191", "answer_content": "\r\n Building upon Daniel Q's and Patrick Artner's excellent suggestions,\nhere is an even more generalized solution. \n\n # Assuming Python3\nimport sys\n\nclass ValidationError(ValueError):  # thanks Patrick Artner\n    pass\n\ndef validate_input(prompt, cast=str, cond=(lambda x: True), onerror=None):\n    if onerror==None: onerror = {}\n    while True:\n        try:\n            data = cast(input(prompt))\n            if not cond(data): raise ValidationError\n            return data\n        except tuple(onerror.keys()) as e:  # thanks Daniel Q\n            print(onerror[type(e)], file=sys.stderr)\n \n\n I opted for explicit  if  and  raise  statements instead of an  assert ,\nbecause assertion checking may be turned off,\nwhereas validation should always be on to provide robustness. \n\n This may be used to get different kinds of input,\nwith different validation conditions.\nFor example: \n\n # No validation, equivalent to simple input:\nanystr = validate_input(\"Enter any string: \")\n\n# Get a string containing only letters:\nletters = validate_input(\"Enter letters: \",\n    cond=str.isalpha,\n    onerror={ValidationError: \"Only letters, please!\"})\n\n# Get a float in [0, 100]:\npercentage = validate_input(\"Percentage? \",\n    cast=float, cond=lambda x: 0.0<=x<=100.0,\n    onerror={ValidationError: \"Must be between 0 and 100!\",\n             ValueError: \"Not a number!\"})\n \n\n Or, to answer the original question: \n\n age = validate_input(\"Please enter your age: \",\n        cast=int, cond=lambda a:0<=a<150,\n        onerror={ValidationError: \"Enter a plausible age, please!\",\n                 ValueError: \"Enter an integer, please!\"})\nif age >= 18: \n    print(\"You are able to vote in the United States!\")\nelse:\n    print(\"You are not able to vote in the United States.\")\n \n    ", "date_posted": "2018-12-01 11:17:14Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "53522191", "name": "\r\n        3 revs", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "37989154", "answer_content": "\r\n def validate_age(age):\n    if age >=0 :\n        return True\n    return False\n\nwhile True:\n    try:\n        age = int(raw_input(\"Please enter your age:\"))\n        if validate_age(age): break\n    except ValueError:\n        print \"Error: Invalid age.\"\n \n    ", "date_posted": "2016-06-23 10:34:14Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "37989154", "name": "\r\n        ojas mohril\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "43704910", "answer_content": "\r\n Try this one:-  \n\n def takeInput(required):\n  print 'ooo or OOO to exit'\n  ans = raw_input('Enter: ')\n\n  if not ans:\n      print \"You entered nothing...!\"\n      return takeInput(required) \n\n      ##  FOR Exit  ## \n  elif ans in ['ooo', 'OOO']:\n    print \"Closing instance.\"\n    exit()\n\n  else:\n    if ans.isdigit():\n      current = 'int'\n    elif set('[~!@#$%^&*()_+{}\":/\\']+$').intersection(ans):\n      current = 'other'\n    elif isinstance(ans,basestring):\n      current = 'str'        \n    else:\n      current = 'none'\n\n  if required == current :\n    return ans\n  else:\n    return takeInput(required)\n\n## pass the value in which type you want [str/int/special character(as other )]\nprint \"input: \", takeInput('str')\n \n    ", "date_posted": "2017-04-30 09:29:28Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "43704910", "name": "\r\n        Pratik Anand\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "53827366", "answer_content": "\r\n Good question! You can try the following code for this. =) \n\n This code uses  ast.literal_eval()  to  find the data type of the input  ( age ). Then it follows the following algorithm: \n\n \n   \n   Ask user to input her/his  age . \n  \n   1.1. If  age  is  float  or  int  data type: \n  \n   \n   Check if  age>=18 . If  age>=18 , print appropriate output and exit. \n   Check if  0<age<18 . If  0<age<18 , print appropriate output and exit. \n   If  age<=0 , ask the user to input a valid number for age again, ( i.e.  go back to step 1.)  \n   \n  \n   1.2. If  age  is not  float  or  int  data type, then ask user to input her/his age again ( i.e.  go back to step 1.)  \n   \n \n\n Here is the code. \n\n from ast import literal_eval\n\n''' This function is used to identify the data type of input data.'''\ndef input_type(input_data):\n    try:\n        return type(literal_eval(input_data))\n    except (ValueError, SyntaxError):\n        return str\n\nflag = True\n\nwhile(flag):\n    age = raw_input(\"Please enter your age: \")\n\n    if input_type(age)==float or input_type(age)==int:\n        if eval(age)>=18: \n            print(\"You are able to vote in the United States!\") \n            flag = False \n        elif eval(age)>0 and eval(age)<18: \n            print(\"You are not able to vote in the United States.\") \n            flag = False\n        else: print(\"Please enter a valid number as your age.\")\n\n    else: print(\"Sorry, I didn't understand that.\") \n \n    ", "date_posted": "2018-12-18 06:54:35Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "53827366", "name": "\r\n        4 revs", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "46903575", "answer_content": "\r\n Use \"while\" statement till user enter a true value and if the input value is not a number or it's a null value skip it and try to ask again and so on.\nIn example I tried to answer truly your question. If we suppose that our age is between 1 and 150 then input value accepted, else it's a wrong value.\nFor terminating program, the user can use 0 key and enter it as a value. \n \n Note: Read comments top of code. \n \n # If your input value is only a number then use \"Value.isdigit() == False\".\n# If you need an input that is a text, you should remove \"Value.isdigit() == False\".\ndef Input(Message):\n    Value = None\n    while Value == None or Value.isdigit() == False:\n        try:        \n            Value = str(input(Message)).strip()\n        except Exception:\n            Value = None\n    return Value\n\n# Example:\nage = 0\n# If we suppose that our age is between 1 and 150 then input value accepted,\n# else it's a wrong value.\nwhile age <=0 or age >150:\n    age = int(Input(\"Please enter your age: \"))\n    # For terminating program, the user can use 0 key and enter it as an a value.\n    if age == 0:\n        print(\"Terminating ...\")\n        exit(0)\n        \nif age >= 18 and age <=150: \n    print(\"You are able to vote in the United States!\")\nelse:\n    print(\"You are not able to vote in the United States.\")\n \n    ", "date_posted": "2022-05-15 21:23:27Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "46903575", "name": "\r\n        6 revs, 2 users 99%", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "56833260", "answer_content": "\r\n You can always apply simple if-else logic and add one more  if  logic to your code along with a  for  loop. \n\n while True:\n     age = int(input(\"Please enter your age: \"))\n     if (age >= 18)  : \n         print(\"You are able to vote in the United States!\")\n     if (age < 18) & (age > 0):\n         print(\"You are not able to vote in the United States.\")\n     else:\n         print(\"Wrong characters, the input must be numeric\")\n         continue\n \n\n This will be an infinite loo and you would be asked to enter the age, indefinitely. \n    ", "date_posted": "2019-07-01 14:17:43Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "56833260", "name": "\r\n        2 revs", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "56833260", "stack_answer_comment_id": "100220085", "comment_content": "This doesn't really answer the question. The question was about getting a user input ", "user_id": "None"}]}, {"stack_answer_id": "37533486", "answer_content": "\r\n While a  try / except  block will work, a much faster and cleaner way to accomplish this task would be to use  str.isdigit() . \n\n while True:\n    age = input(\"Please enter your age: \")\n    if age.isdigit():\n        age = int(age)\n        break\n    else:\n        print(\"Invalid number '{age}'. Try again.\".format(age=age))\n\nif age >= 18: \n    print(\"You are able to vote in the United States!\")\nelse:\n    print(\"You are not able to vote in the United States.\")\n \n    ", "date_posted": "2016-06-06 07:15:17Z", "upvote": "\r\n            -1\r\n        ", "accepted": "No", "user": {"stack_user_id": "37533486", "name": "\r\n        2 revs", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "40396280", "answer_content": "\r\n You can write more general logic to allow user to enter only specific number of times, as the same use-case arises in many real-world applications. \n\n def getValidInt(iMaxAttemps = None):\n  iCount = 0\n  while True:\n    # exit when maximum attempt limit has expired\n    if iCount != None and iCount > iMaxAttemps:\n       return 0     # return as default value\n\n    i = raw_input(\"Enter no\")\n    try:\n       i = int(i)\n    except ValueError as e:\n       print \"Enter valid int value\"\n    else:\n       break\n\n    return i\n\nage = getValidInt()\n# do whatever you want to do.\n \n    ", "date_posted": "2016-11-03 07:49:29Z", "upvote": "\r\n            -1\r\n        ", "accepted": "No", "user": {"stack_user_id": "40396280", "name": "\r\n        Mangu Singh Rajpurohit\r\n        ", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "40396280", "stack_answer_comment_id": "72189955", "comment_content": "you forget to increase the iCount value after each loop", "user_id": "None"}]}, {"stack_answer_id": "48069871", "answer_content": "\r\n You can make the input statement a while True loop so it repeatedly asks for the users input and then break that loop if the user enters the response you would like. And you can use try and except blocks to handle invalid responses. \n\n while True:\n\n    var = True\n\n    try:\n        age = int(input(\"Please enter your age: \"))\n\n    except ValueError:\n        print(\"Invalid input.\")\n        var = False\n\n    if var == True:\n        if age >= 18:\n                print(\"You are able to vote in the United States.\")\n                break\n        else:\n            print(\"You are not able to vote in the United States.\")\n \n\n The var variable is just so that if the user enters a string instead of a integer the program wont return \"You are not able to vote in the United States.\" \n    ", "date_posted": "2018-01-03 00:59:37Z", "upvote": "\r\n            -1\r\n        ", "accepted": "No", "user": {"stack_user_id": "48069871", "name": "\r\n        user9142415\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "53207215", "answer_content": "\r\n One more solution for using input validation using a customized  ValidationError  and a (optional) range validation for integer inputs: \n\n class ValidationError(ValueError): \n    \"\"\"Special validation error - its message is supposed to be printed\"\"\"\n    pass\n\ndef RangeValidator(text,num,r):\n    \"\"\"Generic validator - raises 'text' as ValidationError if 'num' not in range 'r'.\"\"\"\n    if num in r:\n        return num\n    raise ValidationError(text)\n\ndef ValidCol(c): \n    \"\"\"Specialized column validator providing text and range.\"\"\"\n    return RangeValidator(\"Columns must be in the range of 0 to 3 (inclusive)\", \n                          c, range(4))\n\ndef ValidRow(r): \n    \"\"\"Specialized row validator providing text and range.\"\"\"\n    return RangeValidator(\"Rows must be in the range of 5 to 15(exclusive)\",\n                          r, range(5,15))\n \n\n Usage: \n\n def GetInt(text, validator=None):\n    \"\"\"Aks user for integer input until a valid integer is given. If provided, \n    a 'validator' function takes the integer and either raises a \n    ValidationError to be printed or returns the valid number. \n    Non integers display a simple error message.\"\"\"\n    print()\n    while True:\n        n = input(text)\n        try:\n            n = int(n)\n\n            return n if validator is None else validator(n)\n\n        except ValueError as ve:\n            # prints ValidationErrors directly - else generic message:\n            if isinstance(ve, ValidationError):\n                print(ve)\n            else:\n                print(\"Invalid input: \", n)\n\n\ncolumn = GetInt(\"Pleased enter column: \", ValidCol)\nrow = GetInt(\"Pleased enter row: \", ValidRow)\nprint( row, column)\n \n\n Output: \n\n Pleased enter column: 22\nColumns must be in the range of 0 to 3 (inclusive)\nPleased enter column: -2\nColumns must be in the range of 0 to 3 (inclusive)\nPleased enter column: 2\nPleased enter row: a\nInvalid input:  a\nPleased enter row: 72\nRows must be in the range of 5 to 15(exclusive)\nPleased enter row: 9  \n\n9, 2\n \n    ", "date_posted": "2018-11-08 12:04:20Z", "upvote": "\r\n            -1\r\n        ", "accepted": "No", "user": {"stack_user_id": "53207215", "name": "\r\n        3 revs", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "55681134", "answer_content": "\r\n Persistent user input using  recursive function : \n\n String \n\n def askName():\n    return input(\"Write your name: \").strip() or askName()\n\nname = askName()\n \n\n Integer \n\n def askAge():\n    try: return int(input(\"Enter your age: \"))\n    except ValueError: return askAge()\n\nage = askAge()\n \n\n and finally, the question requirement: \n\n def askAge():\n    try: return int(input(\"Enter your age: \"))\n    except ValueError: return askAge()\n\nage = askAge()\n\nresponseAge = [\n    \"You are able to vote in the United States!\",\n    \"You are not able to vote in the United States.\",\n][int(age < 18)]\n\nprint(responseAge)\n \n    ", "date_posted": "2019-04-15 13:56:05Z", "upvote": "\r\n            -1\r\n        ", "accepted": "No", "user": {"stack_user_id": "55681134", "name": "\r\n        4 revs", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "71106291", "answer_content": "\r\n You can try to convert it to a integer, but ask the user to repeat if it doesn't work. \n while True:\n    age = input('Please enter your age: ')\n    try:\n        age_int = int(age)\n        if age_int >= 18:\n            print('You can vote in the United States!')\n        else:\n            print('You cannot vote in the United States.')\n        break\n    except:\n        print('Please enter a meaningful answer.')\n        \n \n The while loop runs as long as the user has not inputted a meaningful answer, but breaks if it makes sense. \n    ", "date_posted": "2022-02-14 01:28:25Z", "upvote": "\r\n            -1\r\n        ", "accepted": "No", "user": {"stack_user_id": "71106291", "name": "\r\n        Python\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "67387649", "answer_content": "\r\n Use  isdigit()  to check if a string represents a valid integer. \n You could use a recursive function. \n def ask():\n    answer = input(\"Please enter amount to convert: \")\n    if not answer.isdigit():\n        print(\"Invalid\")\n        return ask()\n\n    return int(answer)\n\nGdp = ask()\n \n Or a while loop \n while True:\n    answer = input(\"Please enter amount to convert: \")\n    if not answer.isdigit():\n        print(\"Invalid\")\n        continue\n\n    Gbp = int(answer)\n \n    ", "date_posted": "2021-06-30 00:03:48Z", "upvote": "\r\n            -2\r\n        ", "accepted": "No", "user": {"stack_user_id": "67387649", "name": "\r\n        3 revs, 2 users 96%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "67387649", "stack_answer_comment_id": "119116330", "comment_content": "You're missing a ", "user_id": "None"}, {"stack_answer_id": "67387649", "stack_answer_comment_id": "119141460", "comment_content": "@Tomerikoo It recursively asks until the answer is valid, which I think is what was asked. I meant to write it in a way where you can put any code ", "user_id": "None"}, {"stack_answer_id": "67387649", "stack_answer_comment_id": "119142515", "comment_content": "What I mean is that you should test your code with some scenarios. In the first case, the ", "user_id": "None"}]}, {"stack_answer_id": "63447176", "answer_content": "\r\n Below code may help. \n age=(lambda i,f: f(i,f))(input(\"Please enter your age: \"),lambda i,f: i if i.isdigit() else f(input(\"Please enter your age: \"),f))\nprint(\"You are able to vote in the united states\" if int(age)>=18 else \"You are not able to vote in the united states\",end='')\n \n If you want to have maximum tries, say 3, use below code \n age=(lambda i,n,f: f(i,n,f))(input(\"Please enter your age: \"),1,lambda i,n,f: i if i.isdigit() else (None if n==3 else f(input(\"Please enter your age: \"),n+1,f)))\nprint(\"You are able to vote in the united states\" if age and int(age)>=18 else \"You are not able to vote in the united states\",end='')\n \n Note: This uses recursion. \n    ", "date_posted": "2020-08-17 17:21:22Z", "upvote": "\r\n            -4\r\n        ", "accepted": "No", "user": {"stack_user_id": "63447176", "name": "\r\n        3 revs", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "63447176", "stack_answer_comment_id": "125313509", "comment_content": "Don't use recursion to collect user input. Given enough retries, the app crashes. I don't understand the golfed code. Why not make it comprehensible?", "user_id": "None"}, {"stack_answer_id": "63447176", "stack_answer_comment_id": "125637607", "comment_content": "Teaching this to new users instead of a simple while-loop is obfuscatory and confusing.", "user_id": "None"}]}], "user": {"stack_user_id": null, "name": null, "reputation_score": 0}, "question_comments": []},
{"stack_question_id": "15112125", "question_title": "How to test multiple variables for equality against a single value?", "question_content": "\r\n                I'm trying to make a function that will compare multiple variables to an integer and output a string of three letters. I was wondering if there was a way to translate this into Python. So say:\nx = 0\ny ...\r\n", "question_url": "/questions/15112125/how-to-test-multiple-variables-for-equality-against-a-single-value", "date_posted": "Feb 27, 2013 at 12:26", "upvote": "8", "view": "4", "tags": ["python", "if-statement", "comparison", "match", "boolean-logic"], "answers_count": "3", "answers": [{"stack_answer_id": "15112149", "answer_content": "\r\n You misunderstand how boolean expressions work; they don't work like an English sentence and guess that you are talking about the same comparison for all names here. You are looking for: \n if x == 1 or y == 1 or z == 1:\n \n x  and  y  are otherwise evaluated on their own ( False  if  0 ,  True  otherwise). \n You can shorten that using a containment test against  a tuple : \n if 1 in (x, y, z):\n \n or better still: \n if 1 in {x, y, z}:\n \n using  a  set  to take advantage of the constant-cost membership test (i.e.  in  takes a fixed amount of time whatever the left-hand operand is). \n Explanation \n When you use  or , python sees each side of the operator as  separate  expressions. The expression  x or y == 1  is treated as first a boolean test for  x , then if that is False, the expression  y == 1  is tested. \n This is due to  operator precedence . The  or  operator has a lower precedence than the  ==  test, so the latter is evaluated  first . \n However, even if this were  not  the case, and the expression  x or y or z == 1  was actually interpreted as  (x or y or z) == 1  instead, this would still not do what you expect it to do. \n x or y or z  would evaluate to the first argument that is 'truthy', e.g. not  False , numeric 0 or empty (see  boolean expressions  for details on what Python considers false in a boolean context). \n So for the values  x = 2; y = 1; z = 0 ,  x or y or z  would resolve to  2 , because that is the first true-like value in the arguments. Then  2 == 1  would be  False , even though  y == 1  would be  True . \n The same would apply to the inverse; testing multiple values against a single variable;  x == 1 or 2 or 3  would fail for the same reasons. Use  x == 1 or x == 2 or x == 3  or  x in {1, 2, 3} . \n    ", "date_posted": "2021-04-02 01:51:27Z", "upvote": "\r\n            1068\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "4518341", "name": "wjandrea", "reputation_score": "24.1k"}, "answer_comments": [{"stack_answer_id": "15112149", "stack_answer_comment_id": "29042397", "comment_content": "I wouldn't be so quick to go for the ", "user_id": "None"}, {"stack_answer_id": "15112149", "stack_answer_comment_id": "29042516", "comment_content": "@dequestarmappartialsetattr: In Python 3.3 and up, the set is stored as a constant, bypassing the creation time altogether, eliminating the creation time. Tuples ", "user_id": "None"}, {"stack_answer_id": "15112149", "stack_answer_comment_id": "29042794", "comment_content": "@dequestarmappartialsetattr: If you time ", "user_id": "None"}, {"stack_answer_id": "15112149", "stack_answer_comment_id": "65957961", "comment_content": "@MartijnPieters: Using the ", "user_id": "None"}, {"stack_answer_id": "15112149", "stack_answer_comment_id": "65961841", "comment_content": "@ShadowRanger: yes, peephole optimisation (be it for ", "user_id": "None"}]}, {"stack_answer_id": "17604212", "answer_content": "\r\n Your problem is more easily addressed with a dictionary structure like: \n\n x = 0\ny = 1\nz = 3\nd = {0: 'c', 1:'d', 2:'e', 3:'f'}\nmylist = [d[k] for k in [x, y, z]]\n \n    ", "date_posted": "2017-10-25 14:45:52Z", "upvote": "\r\n            116\r\n        ", "accepted": "No", "user": {"stack_user_id": "3745896", "name": "River", "reputation_score": "8,150"}, "answer_comments": [{"stack_answer_id": "17604212", "stack_answer_comment_id": "29042877", "comment_content": "Or even ", "user_id": "None"}, {"stack_answer_id": "17604212", "stack_answer_comment_id": "36122660", "comment_content": "or ", "user_id": "None"}, {"stack_answer_id": "17604212", "stack_answer_comment_id": "96927060", "comment_content": "Aside from the list comprehension which I'm not yet fully accustomed to, most of us had the same reflex: build that dict !", "user_id": "None"}]}, {"stack_answer_id": "32085628", "answer_content": "\r\n As stated by Martijn Pieters, the correct, and fastest, format is: \n\n if 1 in {x, y, z}:\n \n\n Using his advice you would now have separate if-statements so that Python will read each statement whether the former were  True  or  False . Such as: \n\n if 0 in {x, y, z}:\n    mylist.append(\"c\")\nif 1 in {x, y, z}:\n    mylist.append(\"d\")\nif 2 in {x, y, z}:\n    mylist.append(\"e\")\n...\n \n\n This will work, but  if  you are comfortable using dictionaries (see what I did there), you can clean this up by making an initial dictionary mapping the numbers to the letters you want, then just using a for-loop: \n\n num_to_letters = {0: \"c\", 1: \"d\", 2: \"e\", 3: \"f\"}\nfor number in num_to_letters:\n    if number in {x, y, z}:\n        mylist.append(num_to_letters[number])\n \n    ", "date_posted": "2019-05-07 09:30:20Z", "upvote": "\r\n            76\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "32085628", "stack_answer_comment_id": "115011428", "comment_content": "@VisioN You mean ", "user_id": "None"}, {"stack_answer_id": "32085628", "stack_answer_comment_id": "115018668", "comment_content": "@wjandrea Yes, you are right, it's my mistake! I completely forgot about the default behaviour. Unfortunately, I cannot edit my comment, so I have deleted it since you have highlighted the better approach in your comment.", "user_id": "None"}]}, {"stack_answer_id": "17603667", "answer_content": "\r\n The direct way to write  x or y or z == 0  is \n\n if any(map((lambda value: value == 0), (x,y,z))):\n    pass # write your logic.\n \n\n But I dont think, you like it. :)\nAnd this way is ugly. \n\n The other way (a better) is: \n\n 0 in (x, y, z)\n \n\n BTW lots of  if s could be written as something like this \n\n my_cases = {\n    0: Mylist.append(\"c\"),\n    1: Mylist.append(\"d\")\n    # ..\n}\n\nfor key in my_cases:\n    if key in (x,y,z):\n        my_cases[key]()\n        break\n \n    ", "date_posted": "2013-07-11 21:24:59Z", "upvote": "\r\n            53\r\n        ", "accepted": "No", "user": {"stack_user_id": "1243636", "name": "akaRem", "reputation_score": "6,886"}, "answer_comments": [{"stack_answer_id": "17603667", "stack_answer_comment_id": "32723572", "comment_content": "In your example of the ", "user_id": "None"}, {"stack_answer_id": "17603667", "stack_answer_comment_id": "97810895", "comment_content": "the dict instead of a key is wrong, you will get Mylist=['c', 'd'] when the dictionary get initialized even if you commented out \"for..loop\" part", "user_id": "None"}, {"stack_answer_id": "17603667", "stack_answer_comment_id": "102313779", "comment_content": "In your first example ", "user_id": "None"}, {"stack_answer_id": "17603667", "stack_answer_comment_id": "106339378", "comment_content": "A comprehension is much simpler than a map of a lambda: ", "user_id": "None"}]}, {"stack_answer_id": "30430962", "answer_content": "\r\n If you ARE very very lazy, you can put the values inside an array. Such as \n\n list = []\nlist.append(x)\nlist.append(y)\nlist.append(z)\nnums = [add numbers here]\nletters = [add corresponding letters here]\nfor index in range(len(nums)):\n    for obj in list:\n        if obj == num[index]:\n            MyList.append(letters[index])\n            break\n \n\n You can also put the numbers and letters in a dictionary and do it, but this is probably a LOT more complicated than simply if statements. That's what you get for trying to be extra lazy :) \n\n One more thing, your  \n\n if x or y or z == 0:\n \n\n will compile, but not in the way you want it to. When you simply put a variable in an if statement (example) \n\n if b\n \n\n the program will check if the variable is not null. Another way to write the above statement (which makes more sense) is  \n\n if bool(b)\n \n\n Bool is an inbuilt function in python which basically does the command of verifying a boolean statement (If you don't know what that is, it is what you are trying to make in your if statement right now :)) \n\n Another lazy way I found is : \n\n if any([x==0, y==0, z==0])\n \n    ", "date_posted": "2015-08-13 18:06:52Z", "upvote": "\r\n            34\r\n        ", "accepted": "No", "user": {"stack_user_id": "4871483", "name": "rassa45", "reputation_score": "3,406"}, "answer_comments": [{"stack_answer_id": "30430962", "stack_answer_comment_id": "106339486", "comment_content": "-1 There's a lot of bad practice here. ", "user_id": "None"}]}, {"stack_answer_id": "24043508", "answer_content": "\r\n To check if a value is contained within a set of variables you can use the inbuilt modules            itertools  and  operator . \n\n For example: \n\n Imports: \n\n from itertools import repeat\nfrom operator import contains\n \n\n Declare variables: \n\n x = 0\ny = 1\nz = 3\n \n\n Create mapping of values (in the order you want to check): \n\n check_values = (0, 1, 3)\n \n\n Use  itertools  to allow repetition of the variables: \n\n check_vars = repeat((x, y, z))\n \n\n Finally, use the  map  function to create an iterator: \n\n checker = map(contains, check_vars, check_values)\n \n\n Then, when checking for the values (in the original order), use  next() : \n\n if next(checker)  # Checks for 0\n    # Do something\n    pass\nelif next(checker)  # Checks for 1\n    # Do something\n    pass\n \n\n etc... \n\n This has an advantage over the  lambda x: x in (variables)  because  operator  is an inbuilt module and is faster and more efficient than using  lambda  which has to create a custom in-place function. \n\n Another option for checking if there is a non-zero (or False) value in a list: \n\n not (x and y and z)\n \n\n Equivalent: \n\n not all((x, y, z))\n \n    ", "date_posted": "2014-06-05 11:31:39Z", "upvote": "\r\n            33\r\n        ", "accepted": "No", "user": {"stack_user_id": "3551468", "name": "GuiltyDolphin", "reputation_score": "738"}, "answer_comments": [{"stack_answer_id": "24043508", "stack_answer_comment_id": "37069084", "comment_content": "This doesn't answer the OP's question.  It only covers the first case in the provided example.", "user_id": "None"}]}, {"stack_answer_id": "30742519", "answer_content": "\r\n Set is the good approach here, because it orders the variables, what seems to be your goal here.  {z,y,x}  is  {0,1,3}  whatever the order of the parameters. \n\n >>> [\"cdef\"[i] for i in {z,x,y}]\n['c', 'd', 'f']\n \n\n This way, the whole solution is O(n). \n    ", "date_posted": "2018-04-01 13:10:46Z", "upvote": "\r\n            31\r\n        ", "accepted": "No", "user": {"stack_user_id": "4016285", "name": "B. M.", "reputation_score": "17.6k"}, "answer_comments": []}, {"stack_answer_id": "27921870", "answer_content": "\r\n I think this will handle it better: \n\n my_dict = {0: \"c\", 1: \"d\", 2: \"e\", 3: \"f\"}\n\ndef validate(x, y, z):\n    for ele in [x, y, z]:\n        if ele in my_dict.keys():\n            return my_dict[ele]\n \n\n Output: \n\n print validate(0, 8, 9)\nc\nprint validate(9, 8, 9)\nNone\nprint validate(9, 8, 2)\ne\n \n    ", "date_posted": "2015-02-10 14:58:02Z", "upvote": "\r\n            30\r\n        ", "accepted": "No", "user": {"stack_user_id": "296460", "name": "shuttle87", "reputation_score": "14.9k"}, "answer_comments": []}, {"stack_answer_id": "29552841", "answer_content": "\r\n If you want to use if, else statements following is another solution: \n\n myList = []\naList = [0, 1, 3]\n\nfor l in aList:\n    if l==0: myList.append('c')\n    elif l==1: myList.append('d')\n    elif l==2: myList.append('e')\n    elif l==3: myList.append('f')\n\nprint(myList)\n \n    ", "date_posted": "2018-09-04 03:53:17Z", "upvote": "\r\n            30\r\n        ", "accepted": "No", "user": {"stack_user_id": "1794144", "name": "Vishvajit Pathak", "reputation_score": "2,963"}, "answer_comments": []}, {"stack_answer_id": "39427752", "answer_content": "\r\n All of the excellent answers provided here concentrate on the specific requirement of the original poster and concentrate on the  if 1 in {x,y,z}  solution put forward by Martijn Pieters. \nWhat they ignore is the broader implication of the question: \n How do I test one variable against multiple values? \nThe solution provided will not work for partial hits if using strings for example: \nTest if the string \"Wild\" is in multiple values \n\n >>> x = \"Wild things\"\n>>> y = \"throttle it back\"\n>>> z = \"in the beginning\"\n>>> if \"Wild\" in {x, y, z}: print (True)\n... \n \n\n or \n\n >>> x = \"Wild things\"\n>>> y = \"throttle it back\"\n>>> z = \"in the beginning\"\n>>> if \"Wild\" in [x, y, z]: print (True)\n... \n \n\n for this scenario it's easiest to convert to a string \n\n >>> [x, y, z]\n['Wild things', 'throttle it back', 'in the beginning']\n>>> {x, y, z}\n{'in the beginning', 'throttle it back', 'Wild things'}\n>>> \n\n>>> if \"Wild\" in str([x, y, z]): print (True)\n... \nTrue\n>>> if \"Wild\" in str({x, y, z}): print (True)\n... \nTrue\n \n\n It should be noted however, as mentioned by  @codeforester , that word boundries are lost with this method, as in:     \n\n >>> x=['Wild things', 'throttle it back', 'in the beginning']\n>>> if \"rot\" in str(x): print(True)\n... \nTrue\n \n\n the 3 letters  rot  do exist in combination in the list but not as an individual word. Testing for \" rot \" would fail but if one of the list items were \"rot in hell\", that would fail as well. \nThe upshot being, be careful with your search criteria if using this method and be aware that it does have this limitation. \n    ", "date_posted": "2018-09-04 11:59:05Z", "upvote": "\r\n            30\r\n        ", "accepted": "No", "user": {"stack_user_id": "1794144", "name": "Vishvajit Pathak", "reputation_score": "2,963"}, "answer_comments": []}, {"stack_answer_id": "28756031", "answer_content": "\r\n d = {0:'c', 1:'d', 2:'e', 3: 'f'}\nx, y, z = (0, 1, 3)\nprint [v for (k,v) in d.items() if x==k or y==k or z==k]\n \n    ", "date_posted": "2015-02-27 01:48:29Z", "upvote": "\r\n            26\r\n        ", "accepted": "No", "user": {"stack_user_id": "4596008", "name": "Saksham Varma", "reputation_score": "2,072"}, "answer_comments": []}, {"stack_answer_id": "31109647", "answer_content": "\r\n This code may be helpful \n\n L ={x, y, z}\nT= ((0,\"c\"),(1,\"d\"),(2,\"e\"),(3,\"f\"),)\nList2=[]\nfor t in T :\nif t[0] in L :\n    List2.append(t[1])\n    break;\n \n    ", "date_posted": "2015-06-29 07:03:58Z", "upvote": "\r\n            26\r\n        ", "accepted": "No", "user": {"stack_user_id": "4621874", "name": "michael zxc858", "reputation_score": "385"}, "answer_comments": []}, {"stack_answer_id": "53587823", "answer_content": "\r\n You can try the method shown below. In this method, you will have the freedom to specify/input the number of variables that you wish to enter. \n\n mydict = {0:\"c\", 1:\"d\", 2:\"e\", 3:\"f\"}\nmylist= []\n\nnum_var = int(raw_input(\"How many variables? \")) #Enter 3 when asked for input.\n\nfor i in range(num_var): \n    ''' Enter 0 as first input, 1 as second input and 3 as third input.'''\n    globals()['var'+str('i').zfill(3)] = int(raw_input(\"Enter an integer between 0 and 3 \"))\n    mylist += mydict[globals()['var'+str('i').zfill(3)]]\n\nprint mylist\n>>> ['c', 'd', 'f']\n \n    ", "date_posted": "2018-12-03 05:13:18Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "10626090", "name": "Siddharth Satpathy", "reputation_score": "2,513"}, "answer_comments": []}, {"stack_answer_id": "44363221", "answer_content": "\r\n One line solution: \n\n mylist = [{0: 'c', 1: 'd', 2: 'e', 3: 'f'}[i] for i in [0, 1, 2, 3] if i in (x, y, z)]\n \n\n Or: \n\n mylist = ['cdef'[i] for i in range(4) if i in (x, y, z)]\n \n    ", "date_posted": "2017-06-05 06:50:28Z", "upvote": "\r\n            10\r\n        ", "accepted": "No", "user": {"stack_user_id": "3857234", "name": "Vinayak Kaniyarakkal", "reputation_score": "1,052"}, "answer_comments": []}, {"stack_answer_id": "54736001", "answer_content": "\r\n Maybe you need direct formula for output bits set. \n\n x=0 or y=0 or z=0   is equivalent to x*y*z = 0\n\nx=1 or y=1 or z=1   is equivalent to (x-1)*(y-1)*(z-1)=0\n\nx=2 or y=2 or z=2   is equivalent to (x-2)*(y-2)*(z-2)=0\n \n\n Let's map to bits:  'c':1 'd':0xb10 'e':0xb100 'f':0xb1000 \n\n Relation of isc (is 'c'): \n\n if xyz=0 then isc=1 else isc=0\n \n\n Use math if formula  https://youtu.be/KAdKCgBGK0k?list=PLnI9xbPdZUAmUL8htSl6vToPQRRN3hhFp&t=315 \n\n [c]:  (xyz=0 and isc=1) or (((xyz=0 and isc=1) or (isc=0)) and (isc=0)) \n\n [d]:  ((x-1)(y-1)(z-1)=0 and isc=2) or (((xyz=0 and isd=2) or (isc=0)) and (isc=0)) \n\n ... \n\n Connect these formulas by following logic: \n\n \n logic  and  is the sum of squares of equations \n logic  or  is the product of equations \n \n\n and you'll have a total equation\nexpress sum and you have total formula of sum \n\n then sum&1 is c, sum&2 is d, sum&4 is e, sum&5 is f \n\n After this you may form predefined array where index of string elements would correspond to ready string. \n\n array[sum]  gives you the string. \n    ", "date_posted": "2019-04-10 17:49:04Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "874188", "name": "tripleee", "reputation_score": "162k"}, "answer_comments": []}, {"stack_answer_id": "51701671", "answer_content": "\r\n The most pythonic way of representing your pseudo-code in Python would be: \n x = 0\ny = 1\nz = 3\nmylist = []\n\nif any(v == 0 for v in (x, y, z)):\n    mylist.append(\"c\")\nif any(v == 1 for v in (x, y, z)):\n    mylist.append(\"d\")\nif any(v == 2 for v in (x, y, z)):\n    mylist.append(\"e\")\nif any(v == 3 for v in (x, y, z)):\n    mylist.append(\"f\")\n \n    ", "date_posted": "2020-07-11 00:08:50Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "1296256", "name": "rsalmei", "reputation_score": "2,573"}, "answer_comments": [{"stack_answer_id": "51701671", "stack_answer_comment_id": "98608899", "comment_content": "This approach is more universal than ` if 2 in (x, y, z): mylist.append('e')` because allows arbitrary comparisons (e.g. ", "user_id": "None"}]}, {"stack_answer_id": "53173901", "answer_content": "\r\n It can be done easily as  \n\n for value in [var1,var2,var3]:\n     li.append(\"targetValue\")\n \n    ", "date_posted": "2018-11-06 14:26:24Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "6489768", "name": "Seeni", "reputation_score": "1,384"}, "answer_comments": []}, {"stack_answer_id": "52416636", "answer_content": "\r\n To test multiple variables with one single value:  if 1 in {a,b,c}: \n\n To test multiple values with one variable:  if a in {1, 2, 3}: \n    ", "date_posted": "2018-09-20 02:18:55Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "4813600", "name": "alamin", "reputation_score": "2,269"}, "answer_comments": []}, {"stack_answer_id": "52036618", "answer_content": "\r\n Looks like you're building some kind of Caesar cipher. \n\n A much more generalized approach is this: \n\n input_values = (0, 1, 3)\norigo = ord('c')\n[chr(val + origo) for val in inputs]\n \n\n outputs \n\n ['c', 'd', 'f']\n \n\n Not sure if it's a desired side effect of your code, but the order of your output will always be sorted. \n\n If this is what you want, the final line can be changed to: \n\n sorted([chr(val + origo) for val in inputs])\n \n    ", "date_posted": "2018-08-27 09:45:00Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "3730397", "name": "firelynx", "reputation_score": "29.2k"}, "answer_comments": []}, {"stack_answer_id": "51618459", "answer_content": "\r\n You can use dictionary : \n\n x = 0\ny = 1\nz = 3\nlist=[]\ndict = {0: 'c', 1: 'd', 2: 'e', 3: 'f'}\nif x in dict:\n    list.append(dict[x])\nelse:\n    pass\n\nif y in dict:\n    list.append(dict[y])\nelse:\n    pass\nif z in dict:\n    list.append(dict[z])\nelse:\n    pass\n\nprint list\n \n    ", "date_posted": "2018-07-31 16:54:00Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "9010283", "name": "Rohit Gawas", "reputation_score": "237"}, "answer_comments": [{"stack_answer_id": "51618459", "stack_answer_comment_id": "96299106", "comment_content": "This may append same more then once this. Set?", "user_id": "None"}]}, {"stack_answer_id": "58341108", "answer_content": "\r\n Without dict, try this solution: \n\n x, y, z = 0, 1, 3    \noffset = ord('c')\n[chr(i + offset) for i in (x,y,z)]\n \n\n and gives: \n\n ['c', 'd', 'f']\n \n    ", "date_posted": "2019-10-11 12:17:15Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "9302488", "name": "Massifox", "reputation_score": "3,921"}, "answer_comments": []}, {"stack_answer_id": "55543926", "answer_content": "\r\n This will help you. \n\n def test_fun(val):\n    x = 0\n    y = 1\n    z = 2\n    myList = []\n    if val in (x, y, z) and val == 0:\n        myList.append(\"C\")\n    if val in (x, y, z) and val == 1:\n        myList.append(\"D\")\n    if val in (x, y, z) and val == 2:\n        myList.append(\"E\")\n\ntest_fun(2);\n \n    ", "date_posted": "2019-04-08 05:18:38Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "9896794", "name": "Karan Shah", "reputation_score": "91"}, "answer_comments": []}, {"stack_answer_id": "57859331", "answer_content": "\r\n You can unite this \n\n x = 0\ny = 1\nz = 3\n \n\n in one variable. \n\n In [1]: xyz = (0,1,3,) \nIn [2]: mylist = []\n \n\n Change our conditions as: \n\n In [3]: if 0 in xyz: \n    ...:     mylist.append(\"c\") \n    ...: if 1 in xyz: \n    ...:     mylist.append(\"d\") \n    ...: if 2 in xyz: \n    ...:     mylist.append(\"e\") \n    ...: if 3 in xyz:  \n    ...:     mylist.append(\"f\") \n \n\n Output: \n\n In [21]: mylist                                                                                \nOut[21]: ['c', 'd', 'f']\n \n    ", "date_posted": "2019-09-09 18:23:24Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "9093112", "name": "Serhii", "reputation_score": "1,033"}, "answer_comments": []}, {"stack_answer_id": "63811246", "answer_content": "\r\n you can develop it through two ways \n     def compareVariables(x,y,z):\n        mylist = []\n        if x==0 or y==0 or z==0:\n            mylist.append('c')\n        if  x==1 or y==1 or z==1:\n            mylist.append('d')\n        if  x==2 or y==2 or z==2:\n            mylist.append('e')\n        if  x==3 or y==3 or z==3:\n            mylist.append('f')\n        else:\n            print(\"wrong input value!\")\n        print('first:',mylist)\n\n        compareVariables(1, 3, 2)\n \n Or \n     def compareVariables(x,y,z):\n        mylist = []\n        if 0 in (x,y,z):\n             mylist.append('c')\n        if 1 in (x,y,z):\n             mylist.append('d')\n        if 2 in (x,y,z):\n             mylist.append('e')\n        if 3 in (x,y,z):\n             mylist.append('f')\n        else:\n             print(\"wrong input value!\")\n        print('second:',mylist)\n\n        compareVariables(1, 3, 2)\n \n    ", "date_posted": "2020-09-24 15:21:04Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "2308683", "name": "OneCricketeer", "reputation_score": "157k"}, "answer_comments": []}, {"stack_answer_id": "67049356", "answer_content": "\r\n The  or  does not work like that, as  explained by this answer . \n While the generic answer would be use \n if 0 in (x, y, z):\n    ...\n \n this is not the best one for the  specific  problem. In your case you're doing  repeated tests , therefore it is worthwhile to compose a  set  of these variables: \n values = {x, y, z}\n\nif 0 in values:\n    mylist.append(\"c\")\n\nif 1 in values:\n    mylist.append(\"d\")\n \n We can simplify this using a dictionary - this will result in the same values: \n mappings = {0: \"c\", 1: \"d\", ...}\nfor k in mappings:\n    if k in values:\n        mylist.append(mappings[k])\n \n Or if the ordering of the  mylist  is arbitrary, you can loop over the  values  instead and match them to the mappings: \n mappings = {0: \"c\", 1: \"d\", ...}\nfor v in (x, y, z):\n    if v in mappings:\n        mylist.append(mappings[v])\n \n    ", "date_posted": "2021-04-11 19:30:17Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "918959", "name": "Antti Haapala -- \u0421\u043b\u0430\u0432\u0430 \u0423\u043a\u0440\u0430\u0457\u043d\u0456", "reputation_score": "125k"}, "answer_comments": []}, {"stack_answer_id": "58728816", "answer_content": "\r\n Problem \n\n While the pattern for testing multiple values \n\n >>> 2 in {1, 2, 3}\nTrue\n>>> 5 in {1, 2, 3}\nFalse\n \n\n is very readable and is working in many situation, there is one pitfall: \n\n >>> 0 in {True, False}\nTrue\n \n\n But we want to have \n\n >>> (0 is True) or (0 is False)\nFalse\n \n\n Solution \n\n One generalization of the previous expression is based on the answer from  ytpillai : \n\n >>> any([0 is True, 0 is False])\nFalse\n \n\n which can be written as \n\n >>> any(0 is item for item in (True, False))\nFalse\n \n\n While this expression returns the right result it is not as readable as the first expression :-( \n    ", "date_posted": "2019-11-06 11:20:35Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "5599281", "name": "fhgd", "reputation_score": "392"}, "answer_comments": []}, {"stack_answer_id": "66398859", "answer_content": "\r\n Here is one more way to do it: \n x = 0\ny = 1\nz = 3\nmylist = []\n\nif any(i in [0] for i in[x,y,z]):\n    mylist.append(\"c\")\nif any(i in [1] for i in[x,y,z]):\n    mylist.append(\"d\")\nif any(i in [2] for i in[x,y,z]):\n    mylist.append(\"e\")\nif any(i in [3] for i in[x,y,z]):\n    mylist.append(\"f\")\n \n It is a mix of  list comprehension  and  any  keyword. \n    ", "date_posted": "2021-04-12 01:33:17Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "15127315", "name": "Abhishek Kumar Saw", "reputation_score": "349"}, "answer_comments": [{"stack_answer_id": "66398859", "stack_answer_comment_id": "118539367", "comment_content": "Why ", "user_id": "None"}, {"stack_answer_id": "66398859", "stack_answer_comment_id": "118547903", "comment_content": "For a single comparison like in this question, you can use \"==\" but if you want multiple comparisons with multiple variables, then you can use the \"in\" operator like: if any(i in [0,5,4,9,7] for i in[x,y,z] )", "user_id": "None"}]}, {"stack_answer_id": "70816486", "answer_content": "\r\n usage without if example: \n x,y,z = 0,1,3\nvalues = {0:\"c\",1:\"d\",2:\"e\",3:\"f\"} # => as if usage\nmy_list = [values[i] for i in (x,y,z)]\n\nprint(my_list)\n \n    ", "date_posted": "2022-01-22 19:40:34Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "15343205", "name": "SimoN SavioR", "reputation_score": "469"}, "answer_comments": []}, {"stack_answer_id": "72422109", "answer_content": "\r\n FIRST, A CORRECTION TO THE  OR  CONDITIONAL: \n You need to say: \n if x == 0 or y == 0 or z == 0:\n \n The reason is that \"or\" splits up the condition into separate logical parts. The way your original statement was written, those parts were: \n x\ny\nz == 0   // or 1, 2, 3 depending on the if statement\n \n The last part was fine --- checking to see if z == 0, for instance --- but the first two parts just said essentially  if x  and  if y . Since integers always evaluate to  True  unless they're 0, that means the first part of your condition was always  True  when  x  or  y  didn't equal 0 (which in the case of y was always, since you had  y = 1 , causing your whole condition (because of how  OR  works) to always be  True . \n To avoid that, you need to make sure all parts of your condition (each side of the  OR ) make sense on their own (you can do that by pretending that the other side(s) of the  OR  statement doesn't exist). That's how you can confirm whether or not your  OR  condition is correctly defined. \n You would write the statements individually like so: \n if x == 0\nif y == 0\nif z == 0\n \n which means the correct mergin with the  OR  keyword would be: \n if x == 0 or y == 0 or z == 0\n \n SECOND, HOW TO SOLVE THE PROBLEM: \n You're basically wanting to check to see if any of the variables match a given integer and if so, assign it a letter that matches it in a one-to-one mapping. You want to do that for a certain list of integers so that the output is a list of letters. You'd do that like this: \n def func(x, y, z):\n\n    result = []\n\n    for integer, letter in zip([0, 1, 2, 3], ['c', 'd', 'e', 'f']):\n        if x == integer or y == integer or z == integer:\n            result.append(letter)\n            \n    return result\n        \n \n Similarly, you could use LIST COMPREHENSION to achieve the same result faster: \n def func(x, y, z):\n\n    return [ \n                letter \n                for integer, letter in zip([0, 1, 2, 3], ['c', 'd', 'e', 'f'])\n                if x == integer or y == integer or z == integer\n           ]\n    \n    \n \n    ", "date_posted": "2022-05-29 08:35:13Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "5026136", "name": "Elliptica", "reputation_score": "3,266"}, "answer_comments": []}, {"stack_answer_id": "72539339", "answer_content": "\r\n #selection\n: a=np.array([0,1,3])                                                                                                                                                 \n\n#options\n: np.diag(['c','d','e','f']) \narray([['c', '', '', ''],\n       ['', 'd', '', ''],\n       ['', '', 'e', ''],\n       ['', '', '', 'f']], dtype='<U1')\n \n now we can use  a  as [row,col] selector, which acts as if any(...) condition : \n #list of options[sel,sel]\n: np.diag(['c','d','e','f'])[a,a]                                                                                                                                     \n\n array(['c', 'd', 'f'], dtype='<U1')\n \n    ", "date_posted": "2022-07-18 23:51:34Z", "upvote": "\r\n            -1\r\n        ", "accepted": "No", "user": {"stack_user_id": "1019129", "name": "sten", "reputation_score": "6,476"}, "answer_comments": [{"stack_answer_id": "72539339", "stack_answer_comment_id": "129689739", "comment_content": "I don't think the question is asking about numpy", "user_id": "None"}]}], "user": {"stack_user_id": "1877442", "name": "user1877442", "reputation_score": "8,201"}, "question_comments": [{"stack_question_id": "15112125", "stack_question_comment_id": "82285672", "comment_content": "use ", "user_id": "None"}, {"stack_question_id": "15112125", "stack_question_comment_id": "88379334", "comment_content": "When you want to evaluate a list of statements in a any/all manner you can use ", "user_id": "None"}, {"stack_question_id": "15112125", "stack_question_comment_id": "97914247", "comment_content": "This question is a very popular duplicate target, but I think it's suboptimal for that purpose. Most people try to do something like ", "user_id": "None"}, {"stack_question_id": "15112125", "stack_question_comment_id": "97914372", "comment_content": "Take extra care when comparing to \"falsey\" values like ", "user_id": "None"}, {"stack_question_id": "15112125", "stack_question_comment_id": "105448818", "comment_content": "For the opposite, see ", "user_id": "None"}]},
{"stack_question_id": "20449427", "question_title": "How can I read inputs as numbers?", "question_content": "\r\n                Why are x and y strings instead of ints in the below code?\n\n(Note: in Python 2.x use raw_input(). In Python 3.x use input(). raw_input() was renamed to input() in Python 3.x)\n\nplay = True\n\nwhile play:\n...\r\n", "question_url": "/questions/20449427/how-can-i-read-inputs-as-numbers", "date_posted": "Dec 8, 2013 at 3:08", "upvote": "2", "view": "1", "tags": ["python", "python-3.x", "python-2.7", "input", "int"], "answers_count": "1", "answers": [{"stack_answer_id": "20449433", "answer_content": "\r\n Solution \n Since Python 3,  input  returns a string which you have to explicitly convert to  int s, with  int , like this \n x = int(input(\"Enter a number: \"))\ny = int(input(\"Enter a number: \"))\n \n You can accept numbers of any base and convert them directly to base-10 with the  int  function, like this \n >>> data = int(input(\"Enter a number: \"), 8)\nEnter a number: 777\n>>> data\n511\n>>> data = int(input(\"Enter a number: \"), 16)\nEnter a number: FFFF\n>>> data\n65535\n>>> data = int(input(\"Enter a number: \"), 2)\nEnter a number: 10101010101\n>>> data\n1365\n \n The second parameter tells what is the base of the numbers entered and then internally it understands and converts it. If the entered data is wrong it will throw a  ValueError . \n >>> data = int(input(\"Enter a number: \"), 2)\nEnter a number: 1234\nTraceback (most recent call last):\n  File \"<input>\", line 1, in <module>\nValueError: invalid literal for int() with base 2: '1234'\n \n For values that can have a fractional component, the type would be  float  rather than  int : \n x = float(input(\"Enter a number:\"))\n \n Differences between Python 2 and 3 \n Summary \n \n Python 2's  input  function evaluated the received data, converting it to an integer implicitly (read the next section to understand the implication), but Python 3's  input  function does not do that anymore. \n Python 2's equivalent of Python 3's  input  is the  raw_input  function. \n \n Python 2.x \n There were two functions to get user input, called  input  and  raw_input . The difference between them is,  raw_input  doesn't evaluate the data and returns as it is, in string form. But,  input  will evaluate whatever you entered and the result of evaluation will be returned. For example, \n >>> import sys\n>>> sys.version\n'2.7.6 (default, Mar 22 2014, 22:59:56) \\n[GCC 4.8.2]'\n>>> data = input(\"Enter a number: \")\nEnter a number: 5 + 17\n>>> data, type(data)\n(22, <type 'int'>)\n \n The data  5 + 17  is evaluated and the result is  22 . When it evaluates the expression  5 + 17 , it detects that you are adding two numbers and so the result will also be of the same  int  type. So, the type conversion is done for free and  22  is returned as the result of  input  and stored in  data  variable. You can think of  input  as the  raw_input  composed with an  eval  call. \n >>> data = eval(raw_input(\"Enter a number: \"))\nEnter a number: 5 + 17\n>>> data, type(data)\n(22, <type 'int'>)\n \n Note:  you should be careful when you are using  input  in Python 2.x. I explained why one should be careful when using it, in  this answer . \n But,  raw_input  doesn't evaluate the input and returns as it is, as a string. \n >>> import sys\n>>> sys.version\n'2.7.6 (default, Mar 22 2014, 22:59:56) \\n[GCC 4.8.2]'\n>>> data = raw_input(\"Enter a number: \")\nEnter a number: 5 + 17\n>>> data, type(data)\n('5 + 17', <type 'str'>)\n \n Python 3.x \n Python 3.x's  input  and Python 2.x's  raw_input  are similar and  raw_input  is not available in Python 3.x. \n >>> import sys\n>>> sys.version\n'3.4.0 (default, Apr 11 2014, 13:05:11) \\n[GCC 4.8.2]'\n>>> data = input(\"Enter a number: \")\nEnter a number: 5 + 17\n>>> data, type(data)\n('5 + 17', <class 'str'>)\n \n    ", "date_posted": "2021-01-28 13:45:16Z", "upvote": "\r\n            376\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "4621513", "name": "mkrieger1", "reputation_score": "15.4k"}, "answer_comments": [{"stack_answer_id": "20449433", "stack_answer_comment_id": "60632844", "comment_content": "Is there any other way, like a function or something so that we dont need to convert to int in 3.x other than doing explicit conversion to int??", "user_id": "None"}, {"stack_answer_id": "20449433", "stack_answer_comment_id": "60633361", "comment_content": "@ShreyanMehta ", "user_id": "None"}, {"stack_answer_id": "20449433", "stack_answer_comment_id": "86398645", "comment_content": "@thefourtheye at least use ", "user_id": "None"}]}, {"stack_answer_id": "20449436", "answer_content": "\r\n In Python 3.x,  raw_input  was renamed to  input  and the Python 2.x  input  was removed.   \n\n This means that, just like  raw_input ,  input  in Python 3.x always returns a string object. \n\n To fix the problem, you need to explicitly make those inputs into integers by putting them in  int : \n\n x = int(input(\"Enter a number: \"))\ny = int(input(\"Enter a number: \"))\n \n    ", "date_posted": "2019-05-17 12:08:00Z", "upvote": "\r\n            50\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": []}, {"stack_answer_id": "26855555", "answer_content": "\r\n For multiple integer in a single line,  map  might be better. \n\n arr = map(int, raw_input().split())\n \n\n If the number is already known, (like 2 integers), you can use \n\n num1, num2 = map(int, raw_input().split())\n \n    ", "date_posted": "2019-05-17 12:11:57Z", "upvote": "\r\n            34\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": []}, {"stack_answer_id": "20449435", "answer_content": "\r\n input()  (Python 3) and  raw_input()  (Python 2)  always  return strings. Convert the result to integer explicitly with  int() . \n\n x = int(input(\"Enter a number: \"))\ny = int(input(\"Enter a number: \"))\n \n    ", "date_posted": "2019-05-17 12:12:35Z", "upvote": "\r\n            18\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": []}, {"stack_answer_id": "24621885", "answer_content": "\r\n Multiple questions require multiple integers to be entered on a single line. The best way is to enter the entire string of numbers line by line and split them into integers. Here is the Python 3 version: \n a = []\np = input()\np = p.split()      \nfor i in p:\n    a.append(int(i))\n \n You can also use list comprehensions: \n p = input().split(\"whatever the seperator is\")\n \n To convert all input from string to int we do the following: \n x = [int(i) for i in p]\nprint(x, end=' ')\n \n List elements should be printed in straight lines. \n    ", "date_posted": "2022-03-18 02:20:10Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "3750257", "name": "pppery", "reputation_score": "3,606"}, "answer_comments": []}, {"stack_answer_id": "36679044", "answer_content": "\r\n Convert to integers: \n\n my_number = int(input(\"enter the number\"))\n \n\n Similarly for floating point numbers: \n\n my_decimalnumber = float(input(\"enter the number\"))\n \n    ", "date_posted": "2017-01-26 04:28:51Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "885922", "name": "xlm", "reputation_score": "5,754"}, "answer_comments": []}, {"stack_answer_id": "51676769", "answer_content": "\r\n n=int(input())\nfor i in range(n):\n    n=input()\n    n=int(n)\n    arr1=list(map(int,input().split()))\n \n\n the for loop shall run 'n' number of times . the second 'n' is the length of the array.\nthe last statement maps the integers to a list and takes input in space separated form .\nyou can also return the array at the end of for loop. \n    ", "date_posted": "2018-08-03 16:30:31Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "6481925", "name": "ravi tanwar", "reputation_score": "572"}, "answer_comments": []}, {"stack_answer_id": "23828100", "answer_content": "\r\n I encountered a problem of taking integer input while solving a problem on  CodeChef , where two integers - separated by space - should be read from one line. \n While  int(input())  is sufficient for a single integer, I did not find a direct way to input two integers.  I tried this: \n num = input()\nnum1 = 0\nnum2 = 0\n\nfor i in range(len(num)):\n    if num[i] == ' ':\n        break\n\nnum1 = int(num[:i])\nnum2 = int(num[i+1:])\n \n Now I use  num1  and  num2  as integers. \n    ", "date_posted": "2021-12-02 02:35:17Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "10794031", "name": "bad_coder", "reputation_score": "9,051"}, "answer_comments": [{"stack_answer_id": "23828100", "stack_answer_comment_id": "36673308", "comment_content": "This looks very interesting.  However, isn't ", "user_id": "None"}, {"stack_answer_id": "23828100", "stack_answer_comment_id": "36696794", "comment_content": " When a loop is exited, the value of the index variable (here, ", "user_id": "None"}, {"stack_answer_id": "23828100", "stack_answer_comment_id": "89589223", "comment_content": "For this kind of input manipulation, you can either ", "user_id": "None"}]}, {"stack_answer_id": "31134209", "answer_content": "\r\n def dbz():\n    try:\n        r = raw_input(\"Enter number:\")\n        if r.isdigit():\n            i = int(raw_input(\"Enter divident:\"))\n            d = int(r)/i\n            print \"O/p is -:\",d\n        else:\n            print \"Not a number\"\n    except Exception ,e:\n        print \"Program halted incorrect data entered\",type(e)\ndbz()\n\nOr \n\nnum = input(\"Enter Number:\")#\"input\" will accept only numbers\n \n    ", "date_posted": "2019-04-04 08:47:19Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "4628770", "name": "Sanyal", "reputation_score": "836"}, "answer_comments": []}, {"stack_answer_id": "40764414", "answer_content": "\r\n While in your example,  int(input(...))  does the trick in any case,  python-future 's  builtins.input  is worth consideration since that makes sure your code works for both Python 2 and 3  and  disables Python2's default behaviour of  input  trying to be \"clever\" about the input data type ( builtins.input  basically just behaves like  raw_input ). \n    ", "date_posted": "2016-11-23 12:19:52Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "321973", "name": "Tobias Kienzler", "reputation_score": "24.1k"}, "answer_comments": []}], "user": {"stack_user_id": null, "name": null, "reputation_score": 0}, "question_comments": [{"stack_question_id": "20449427", "stack_question_comment_id": "91590863", "comment_content": " ", "user_id": "None"}]},
{"stack_question_id": "1207406", "question_title": "How to remove items from a list while iterating?", "question_content": "\r\n                I'm iterating over a list of tuples in Python, and am attempting to remove them if they meet certain criteria. \n\nfor tup in somelist:\n    if determine(tup):\n         code_to_remove_tup\r\nWhat should I ...\r\n", "question_url": "/questions/1207406/how-to-remove-items-from-a-list-while-iterating", "date_posted": "Jul 30, 2009 at 15:36", "upvote": "9", "view": "7", "tags": ["python", "iteration"], "answers_count": "2", "answers": [{"stack_answer_id": "1207461", "answer_content": "\r\n You can use a list comprehension to create a new list containing only the elements you don't want to remove: \n somelist = [x for x in somelist if not determine(x)]\n \n Or, by assigning to the slice  somelist[:] , you can mutate the existing list to contain only the items you want: \n somelist[:] = [x for x in somelist if not determine(x)]\n \n This approach could be useful if there are other references to  somelist  that need to reflect the changes. \n Instead of a comprehension, you could also use  itertools . In Python 2: \n from itertools import ifilterfalse\nsomelist[:] = ifilterfalse(determine, somelist)\n \n Or in Python 3: \n from itertools import filterfalse\nsomelist[:] = filterfalse(determine, somelist)\n \n    ", "date_posted": "2021-03-19 21:52:42Z", "upvote": "\r\n            1035\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "2357112", "name": "user2357112", "reputation_score": "240k"}, "answer_comments": [{"stack_answer_id": "1207461", "stack_answer_comment_id": "6561137", "comment_content": "Can you make it faster if you know only a few will be deleted, i.e., only delete those and leave the others in-place rather than re-writing them?", "user_id": "None"}, {"stack_answer_id": "1207461", "stack_answer_comment_id": "42444805", "comment_content": "What if my list is huge and can't afford making a copy?", "user_id": "None"}, {"stack_answer_id": "1207461", "stack_answer_comment_id": "48015591", "comment_content": "@jpcgt You should use ", "user_id": "None"}, {"stack_answer_id": "1207461", "stack_answer_comment_id": "48333544", "comment_content": "@RostislavKondratenko: ", "user_id": "None"}, {"stack_answer_id": "1207461", "stack_answer_comment_id": "91913010", "comment_content": "Would you care to explain what the differences are between assigning the list comprehension to the list and list clone please? Wouldn't the original list ", "user_id": "None"}]}, {"stack_answer_id": "1208792", "answer_content": "\r\n The answers suggesting list comprehensions are ALMOST correct -- except that they build a completely new list and then give it the same name the old list as, they do NOT modify the old list in place. That's different from what you'd be doing by selective removal, as in  @Lennart's suggestion  -- it's faster, but if your list is accessed via multiple references the fact that you're just reseating one of the references and NOT altering the list object itself can lead to subtle, disastrous bugs. \n\n Fortunately, it's extremely easy to get both the speed of list comprehensions AND the required semantics of in-place alteration -- just code: \n\n somelist[:] = [tup for tup in somelist if determine(tup)]\n \n\n Note the subtle difference with other answers: this one is NOT assigning to a barename - it's assigning to a list slice that just happens to be the entire list, thereby replacing the list  contents   within the same Python list object , rather than just reseating one reference (from previous list object to new list object) like the other answers. \n    ", "date_posted": "2019-05-17 06:05:40Z", "upvote": "\r\n            674\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": [{"stack_answer_id": "1208792", "stack_answer_comment_id": "6156944", "comment_content": "How do I do the same sliced assignment with a dict? In Python 2.6?", "user_id": "None"}, {"stack_answer_id": "1208792", "stack_answer_comment_id": "6269193", "comment_content": "@Paul: Since dicts are unordered, slices are meaningless for dicts.  If your want to replace the contents of dict ", "user_id": "None"}, {"stack_answer_id": "1208792", "stack_answer_comment_id": "8322580", "comment_content": "Why can 'reseating' one of the references by replacing what the variable refers to cause bugs?  It seems like that would only be a potential problem in multi-threaded applications, not single-threaded.", "user_id": "None"}, {"stack_answer_id": "1208792", "stack_answer_comment_id": "9992070", "comment_content": "@Derek ", "user_id": "None"}, {"stack_answer_id": "1208792", "stack_answer_comment_id": "64106747", "comment_content": "in fact, using ", "user_id": "None"}]}, {"stack_answer_id": "1207427", "answer_content": "\r\n You need to take a copy of the list and iterate over it first, or the iteration will fail with what may be unexpected results. \n\n For example (depends on what type of list): \n\n for tup in somelist[:]:\n    etc....\n \n\n An example: \n\n >>> somelist = range(10)\n>>> for x in somelist:\n...     somelist.remove(x)\n>>> somelist\n[1, 3, 5, 7, 9]\n\n>>> somelist = range(10)\n>>> for x in somelist[:]:\n...     somelist.remove(x)\n>>> somelist\n[]\n \n    ", "date_posted": "2019-12-02 14:50:05Z", "upvote": "\r\n            376\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "1207427", "stack_answer_comment_id": "37528195", "comment_content": "@Zen Because the second one iterates over a copy of the list. So when you modify the original list, you do not modify the copy that you iterate over.", "user_id": "None"}, {"stack_answer_id": "1207427", "stack_answer_comment_id": "44985743", "comment_content": "What's better in doing somelist[:] compared to list(somelist) ?", "user_id": "None"}, {"stack_answer_id": "1207427", "stack_answer_comment_id": "45032005", "comment_content": " will convert an iterable into a list. ", "user_id": "None"}, {"stack_answer_id": "1207427", "stack_answer_comment_id": "45258605", "comment_content": "Note to anyone reading this, this is VERY slow for lists. ", "user_id": "None"}, {"stack_answer_id": "1207427", "stack_answer_comment_id": "64982024", "comment_content": "Big O time doesn't matter when dealing with lists of only a dozen items.  Often clear and simple for future programmers to understand is far more valuable than performance.", "user_id": "None"}]}, {"stack_answer_id": "1207485", "answer_content": "\r\n for i in range(len(somelist) - 1, -1, -1):\n    if some_condition(somelist, i):\n        del somelist[i]\n \n\n You need to go backwards otherwise it's a bit like sawing off the tree-branch that you are sitting on :-) \n\n Python 2 users: replace  range  by  xrange  to avoid creating a hardcoded list \n    ", "date_posted": "2018-10-26 15:10:03Z", "upvote": "\r\n            174\r\n        ", "accepted": "No", "user": {"stack_user_id": "6451573", "name": "Jean-Fran\u00e7ois Fabre", "reputation_score": "133k"}, "answer_comments": [{"stack_answer_id": "1207485", "stack_answer_comment_id": "6110404", "comment_content": "In recent versions of Python, you can do this even more cleanly by using the ", "user_id": "None"}, {"stack_answer_id": "1207485", "stack_answer_comment_id": "45266349", "comment_content": "reversed() does not create a new list, it creates a reverse iterator over the supplied sequence. Like enumerate(), you have to wrap it in list() to actually get a list out of it.  You may be thinking of sorted(), which ", "user_id": "None"}, {"stack_answer_id": "1207485", "stack_answer_comment_id": "51485366", "comment_content": "@Mauris because ", "user_id": "None"}, {"stack_answer_id": "1207485", "stack_answer_comment_id": "53032679", "comment_content": "This is O(N*M) for arrays, it is very slow if you remove many items from a large list.  So not recommended.", "user_id": "None"}, {"stack_answer_id": "1207485", "stack_answer_comment_id": "58231194", "comment_content": "@SamWatkins Yeah, this answer is for when you're removing a couple of elements from a very large array. Less memory usage, but it can be ", "user_id": "None"}]}, {"stack_answer_id": "34238688", "answer_content": "\r\n Overview of workarounds \n Either: \n \n use a linked list implementation/roll your own. \n A linked list is the proper data structure to support efficient item removal, and does not force you to make space/time tradeoffs. \n A CPython  list  is implemented with  dynamic arrays  as  mentioned here , which is not a good data type to support removals. \n There doesn't seem to be a linked list in the standard library however: \n \n Is there a linked list predefined library in Python? \n https://github.com/ajakubek/python-llist \n \n \n start a new  list()  from scratch, and  .append()  back at the end as mentioned at:  https://stackoverflow.com/a/1207460/895245 \n This time efficient, but less space efficient because it keeps an extra copy of the array around during iteration. \n \n use  del  with an index as mentioned at:  https://stackoverflow.com/a/1207485/895245 \n This is more space efficient since it dispenses the array copy, but it is less time efficient, because removal from dynamic arrays requires shifting all following items back by one, which is O(N). \n \n \n Generally, if you are doing it quick and dirty and don't want to add a custom  LinkedList  class, you just want to go for the faster  .append()  option by default unless memory is a big concern. \n Official Python 2 tutorial 4.2. \"for Statements\" \n https://docs.python.org/2/tutorial/controlflow.html#for-statements \n This part of the docs makes it clear that: \n \n you need to make a copy of the iterated list to modify it \n one way to do it is with the slice notation  [:] \n \n \n If you need to modify the sequence you are iterating over while inside the loop (for example to duplicate selected items), it is recommended that you first make a copy. Iterating over a sequence does not implicitly make a copy. The slice notation makes this especially convenient: \n >>> words = ['cat', 'window', 'defenestrate']\n>>> for w in words[:]:  # Loop over a slice copy of the entire list.\n...     if len(w) > 6:\n...         words.insert(0, w)\n...\n>>> words\n['defenestrate', 'cat', 'window', 'defenestrate']\n \n \n Python 2 documentation 7.3. \"The for statement\" \n https://docs.python.org/2/reference/compound_stmts.html#for \n This part of the docs says once again that you have to make a copy, and gives an actual removal example: \n \n Note: There is a subtlety when the sequence is being modified by the loop (this can only occur for mutable sequences, i.e. lists). An internal counter is used to keep track of which item is used next, and this is incremented on each iteration. When this counter has reached the length of the sequence the loop terminates. This means that if the suite deletes the current (or a previous) item from the sequence, the next item will be skipped (since it gets the index of the current item which has already been treated). Likewise, if the suite inserts an item in the sequence before the current item, the current item will be treated again the next time through the loop. This can lead to nasty bugs that can be avoided by making a temporary copy using a slice of the whole sequence, e.g., \n for x in a[:]:\n \n \n     if x < 0: a.remove(x)\n \n However, I disagree with this implementation, since  .remove()  has to iterate the  entire list  to find the value. \n Could Python do this better? \n It seems like this particular Python API could be improved. Compare it, for instance, with: \n \n Java  ListIterator::remove  which documents \"This call can only be made once per call to next or previous\" \n C++  std::vector::erase  which returns a valid interator to the element after the one removed \n \n both of which make it crystal clear that you cannot modify a list being iterated except with the iterator itself, and gives you efficient ways to do so without copying the list. \n Perhaps the underlying rationale is that Python lists are assumed to be dynamic array backed, and therefore any type of removal will be time inefficient anyways, while Java has a nicer interface hierarchy with both  ArrayList  and  LinkedList  implementations of  ListIterator . \n There doesn't seem to be an explicit linked list type in the Python stdlib either:  Python Linked List \n    ", "date_posted": "2020-09-25 05:15:39Z", "upvote": "\r\n            66\r\n        ", "accepted": "No", "user": {"stack_user_id": "895245", "name": "Ciro Santilli \u041f\u0443\u0442\u043b\u0435\u0440 \u041a\u0430\u043f\u0443\u0442 \u516d\u56db\u4e8b", "reputation_score": "312k"}, "answer_comments": [{"stack_answer_id": "34238688", "stack_answer_comment_id": "120740698", "comment_content": "Finally someone pointed out the actual documentation. I couldn't understand any answers before this one.", "user_id": "None"}]}, {"stack_answer_id": "1207460", "answer_content": "\r\n Your best approach for such an example would be a  list comprehension \n\n somelist = [tup for tup in somelist if determine(tup)]\n \n\n In cases where you're doing something more complex than calling a  determine  function, I prefer constructing a new list and simply appending to it as I go.  For example \n\n newlist = []\nfor tup in somelist:\n    # lots of code here, possibly setting things up for calling determine\n    if determine(tup):\n        newlist.append(tup)\nsomelist = newlist\n \n\n Copying the list using  remove  might make your code look a little cleaner, as described in one of the answers below.  You should definitely not do this for extremely large lists, since this involves first copying the entire list, and also performing an  O(n)   remove  operation for each element being removed, making this an  O(n^2)  algorithm. \n\n for tup in somelist[:]:\n    # lots of code here, possibly setting things up for calling determine\n    if determine(tup):\n        newlist.append(tup)\n \n    ", "date_posted": "2009-07-30 17:30:54Z", "upvote": "\r\n            51\r\n        ", "accepted": "No", "user": {"stack_user_id": "1694", "name": "Eli Courtwright", "reputation_score": "178k"}, "answer_comments": []}, {"stack_answer_id": "1207500", "answer_content": "\r\n For those that like functional programming: \n\n somelist[:] = filter(lambda tup: not determine(tup), somelist)\n \n\n or \n\n from itertools import ifilterfalse\nsomelist[:] = list(ifilterfalse(determine, somelist))\n \n    ", "date_posted": "2016-05-24 12:50:20Z", "upvote": "\r\n            41\r\n        ", "accepted": "No", "user": {"stack_user_id": "1843331", "name": "Tim", "reputation_score": "40.2k"}, "answer_comments": [{"stack_answer_id": "1207500", "stack_answer_comment_id": "67641698", "comment_content": "1. List comprehension and generator expressions are borrowed from Haskell, a pure functional language; they're exactly as functional as ", "user_id": "None"}]}, {"stack_answer_id": "42773232", "answer_content": "\r\n I needed to do this with a huge list, and duplicating the list seemed expensive, especially since in my case the number of deletions would be few compared to the items that remain. I took this low-level approach. \n\n array = [lots of stuff]\narraySize = len(array)\ni = 0\nwhile i < arraySize:\n    if someTest(array[i]):\n        del array[i]\n        arraySize -= 1\n    else:\n        i += 1\n \n\n What I don't know is how efficient a couple of deletes are compared to copying a large list. Please comment if you have any insight. \n    ", "date_posted": "2017-03-13 20:54:41Z", "upvote": "\r\n            23\r\n        ", "accepted": "No", "user": {"stack_user_id": "1031265", "name": "Michael", "reputation_score": "499"}, "answer_comments": [{"stack_answer_id": "42773232", "stack_answer_comment_id": "74631480", "comment_content": "In my case I need to move those 'unwanted' elements into another list. Do you have any new comment about this solution? I also think that it is better to use some deletions instead of duplicate the list.", "user_id": "None"}, {"stack_answer_id": "42773232", "stack_answer_comment_id": "74646602", "comment_content": "This is the right answer if performance is an issue (although same as @Alexey). That said, the choice of ", "user_id": "None"}, {"stack_answer_id": "42773232", "stack_answer_comment_id": "74646698", "comment_content": "@GVelascoh why not create ", "user_id": "None"}, {"stack_answer_id": "42773232", "stack_answer_comment_id": "75747098", "comment_content": "Note that this is likely time inefficient: if ", "user_id": "None"}, {"stack_answer_id": "42773232", "stack_answer_comment_id": "115963470", "comment_content": "@CiroSantilli\u90dd\u6d77\u4e1c\u51a0\u72b6\u75c5\u516d\u56db\u4e8b\u4ef6\u6cd5\u8f6e\u529f : The pop(i) operation is still O(n). I'll take storage efficiency over incremental improvements in O(n), but I can see why someone might do this differently.", "user_id": "None"}]}, {"stack_answer_id": "52947607", "answer_content": "\r\n Most of the answers here want you to create a copy of the list. I had a use case where the list was quite long (110K items) and it was smarter to keep reducing the list instead. \n\n First of all you'll need to  replace foreach loop with while loop , \n\n i = 0\nwhile i < len(somelist):\n    if determine(somelist[i]):\n         del somelist[i]\n    else:\n        i += 1\n \n\n The value of  i  is not changed in the if block because you'll want to get value of the new item FROM THE SAME INDEX, once the old item is deleted. \n    ", "date_posted": "2018-10-23 11:13:00Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "4008392", "name": "Mujeeb", "reputation_score": "805"}, "answer_comments": [{"stack_answer_id": "52947607", "stack_answer_comment_id": "124290302", "comment_content": "I don't want to like this but I do :)", "user_id": "None"}, {"stack_answer_id": "52947607", "stack_answer_comment_id": "126884873", "comment_content": "I think this is very creative! I would like to see more community input on this algorithm. It's easy to understand and appears to be overlooked by the contributors!", "user_id": "None"}, {"stack_answer_id": "52947607", "stack_answer_comment_id": "126900456", "comment_content": "@tonysepia glad to see this solution is still helpful :)", "user_id": "None"}, {"stack_answer_id": "52947607", "stack_answer_comment_id": "126900474", "comment_content": "@Mujeeb oh Yes, you can see me using it in my algo here: ", "user_id": "None"}]}, {"stack_answer_id": "36096883", "answer_content": "\r\n It might be smart to also just create a new list if the current list item meets the desired criteria.  \n\n so: \n\n for item in originalList:\n   if (item != badValue):\n        newList.append(item)\n \n\n and to avoid having to re-code the entire project with the new lists name: \n\n originalList[:] = newList\n \n\n note, from Python documentation:  \n\n \n   copy.copy(x) \n  Return a shallow copy of x. \n  \n   copy.deepcopy(x) \n  Return a deep copy of x. \n \n    ", "date_posted": "2016-10-23 02:33:13Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "5425664", "name": "ntk4", "reputation_score": "1,199"}, "answer_comments": [{"stack_answer_id": "36096883", "stack_answer_comment_id": "63359622", "comment_content": "This adds no new information that wasn't in the accepted answer years earlier.", "user_id": "None"}, {"stack_answer_id": "36096883", "stack_answer_comment_id": "63408517", "comment_content": "It's simple and just another way to look at a problem @MarkAmery. It's less condensed for those people that don't like compressed coding syntax.", "user_id": "None"}]}, {"stack_answer_id": "40177544", "answer_content": "\r\n This answer was originally written in response to a question which has since been marked as duplicate:\n Removing coordinates from list on python \n\n There are two problems in your code: \n\n 1) When using remove(), you attempt to remove integers whereas you need to remove a tuple. \n\n 2) The for loop will skip items in your list. \n\n Let's run through what happens when we execute your code: \n\n >>> L1 = [(1,2), (5,6), (-1,-2), (1,-2)]\n>>> for (a,b) in L1:\n...   if a < 0 or b < 0:\n...     L1.remove(a,b)\n... \nTraceback (most recent call last):\n  File \"<stdin>\", line 3, in <module>\nTypeError: remove() takes exactly one argument (2 given)\n \n\n The first problem is that you are passing both 'a' and 'b' to remove(), but remove() only accepts a single argument. So how can we get remove() to work properly with your list? We need to figure out what each element of your list is. In this case, each one is a tuple. To see this, let's access one element of the list (indexing starts at 0): \n\n >>> L1[1]\n(5, 6)\n>>> type(L1[1])\n<type 'tuple'>\n \n\n Aha! Each element of L1 is actually a tuple. So that's what we need to be passing to remove(). Tuples in python are very easy, they're simply made by enclosing values in parentheses. \"a, b\" is not a tuple, but \"(a, b)\" is a tuple. So we modify your code and run it again: \n\n # The remove line now includes an extra \"()\" to make a tuple out of \"a,b\"\nL1.remove((a,b))\n \n\n This code runs without any error, but let's look at the list it outputs:  \n\n L1 is now: [(1, 2), (5, 6), (1, -2)]\n \n\n Why is (1,-2) still in your list? It turns out modifying the list while using a loop to iterate over it is a very bad idea without special care. The reason that (1, -2) remains in the list is that the locations of each item within the list changed between iterations of the for loop. Let's look at what happens if we feed the above code a longer list: \n\n L1 = [(1,2),(5,6),(-1,-2),(1,-2),(3,4),(5,7),(-4,4),(2,1),(-3,-3),(5,-1),(0,6)]\n### Outputs:\nL1 is now: [(1, 2), (5, 6), (1, -2), (3, 4), (5, 7), (2, 1), (5, -1), (0, 6)]\n \n\n As you can infer from that result, every time that the conditional statement evaluates to true and a list item is removed, the next iteration of the loop will skip evaluation of the next item in the list because its values are now located at different indices. \n\n The most intuitive solution is to copy the list, then iterate over the original list and only modify the copy. You can try doing so like this: \n\n L2 = L1\nfor (a,b) in L1:\n    if a < 0 or b < 0 :\n        L2.remove((a,b))\n# Now, remove the original copy of L1 and replace with L2\nprint L2 is L1\ndel L1\nL1 = L2; del L2\nprint (\"L1 is now: \", L1)\n \n\n However, the output will be identical to before: \n\n 'L1 is now: ', [(1, 2), (5, 6), (1, -2), (3, 4), (5, 7), (2, 1), (5, -1), (0, 6)]\n \n\n This is because when we created L2, python did not actually create a new object. Instead, it merely referenced L2 to the same object as L1. We can verify this with 'is' which is different from merely \"equals\" (==). \n\n >>> L2=L1\n>>> L1 is L2\nTrue\n \n\n We can make a true copy using copy.copy(). Then everything works as expected: \n\n import copy\nL1 = [(1,2), (5,6),(-1,-2), (1,-2),(3,4),(5,7),(-4,4),(2,1),(-3,-3),(5,-1),(0,6)]\nL2 = copy.copy(L1)\nfor (a,b) in L1:\n    if a < 0 or b < 0 :\n        L2.remove((a,b))\n# Now, remove the original copy of L1 and replace with L2\ndel L1\nL1 = L2; del L2\n>>> L1 is now: [(1, 2), (5, 6), (3, 4), (5, 7), (2, 1), (0, 6)]\n \n\n Finally, there is one cleaner solution than having to make an entirely new copy of L1. The reversed() function: \n\n L1 = [(1,2), (5,6),(-1,-2), (1,-2),(3,4),(5,7),(-4,4),(2,1),(-3,-3),(5,-1),(0,6)]\nfor (a,b) in reversed(L1):\n    if a < 0 or b < 0 :\n        L1.remove((a,b))\nprint (\"L1 is now: \", L1)\n>>> L1 is now: [(1, 2), (5, 6), (3, 4), (5, 7), (2, 1), (0, 6)]\n \n\n Unfortunately, I cannot adequately describe how reversed() works. It returns a 'listreverseiterator' object when a list is passed to it. For practical purposes, you can think of it as creating a reversed copy of its argument. This is the solution I recommend. \n    ", "date_posted": "2017-05-23 12:18:24Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}, {"stack_answer_id": "58314595", "answer_content": "\r\n If you want to delete elements from a list while iterating, use a while-loop so you can alter the current index and end index after each deletion. \n\n Example: \n\n i = 0\nlength = len(list1)\n\nwhile i < length:\n    if condition:\n        list1.remove(list1[i])\n        i -= 1\n        length -= 1\n\n    i += 1\n \n    ", "date_posted": "2019-10-10 02:24:59Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "2619038", "name": "NoName", "reputation_score": "9,114"}, "answer_comments": []}, {"stack_answer_id": "25363359", "answer_content": "\r\n If you want to do anything else during the iteration, it may be nice to get both the index (which guarantees you being able to reference it, for example if you have a list of dicts) and the actual list item contents. \n\n inlist = [{'field1':10, 'field2':20}, {'field1':30, 'field2':15}]    \nfor idx, i in enumerate(inlist):\n    do some stuff with i['field1']\n    if somecondition:\n        xlist.append(idx)\nfor i in reversed(xlist): del inlist[i]\n \n\n enumerate  gives you access to the item and the index at once.  reversed  is so that the indices that you're going to later delete don't change on you.  \n    ", "date_posted": "2014-08-18 12:30:16Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "3427777", "name": "fantabolous", "reputation_score": "19.5k"}, "answer_comments": [{"stack_answer_id": "25363359", "stack_answer_comment_id": "63359580", "comment_content": "Why is getting the index any more relevant in the case where you have a list of dicts than in the case of any other kind of list? This doesn't make sense as far as I can tell.", "user_id": "None"}]}, {"stack_answer_id": "39293411", "answer_content": "\r\n One possible solution, useful if you want not only remove some things, but also do something with all elements in a single loop: \n\n alist = ['good', 'bad', 'good', 'bad', 'good']\ni = 0\nfor x in alist[:]:\n    if x == 'bad':\n        alist.pop(i)\n        i -= 1\n    # do something cool with x or just print x\n    print(x)\n    i += 1\n \n    ", "date_posted": "2018-06-13 19:38:52Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "6740698", "name": "Xenolion", "reputation_score": "11.1k"}, "answer_comments": [{"stack_answer_id": "39293411", "stack_answer_comment_id": "85623994", "comment_content": "You should really just use comprehensions. They're much easier to understand.", "user_id": "None"}, {"stack_answer_id": "39293411", "stack_answer_comment_id": "85632089", "comment_content": "What if I want to remove ", "user_id": "None"}, {"stack_answer_id": "39293411", "stack_answer_comment_id": "86135096", "comment_content": "Actually, I realized there's some cleverness here in that you make a copy of the list with an open slice (", "user_id": "None"}]}, {"stack_answer_id": "55915047", "answer_content": "\r\n for loop will be iterate through index.. \n\n consider you have a list, \n\n [5, 7, 13, 29, 65, 91]\n \n\n you have using list variable called  lis . and you using same to remove.. \n\n your variable  \n\n lis = [5, 7, 13, 29, 35, 65, 91]\n       0  1   2   3   4   5   6\n \n\n during 5th iteration, \n\n your  number 35  was not a prime so you removed it from a list. \n\n lis.remove(y)\n \n\n and then  next value (65)  move on to previous index. \n\n lis = [5, 7, 13, 29, 65, 91]\n       0  1   2   3   4   5\n \n\n so 4th iteration done pointer moved onto 5th..  \n\n thats why your loop doesnt cover 65 since its moved into previous index. \n\n so you shouldn't reference list into another variable which still reference original instead of copy. \n\n ite = lis #dont do it will reference instead copy\n \n\n so do copy of list using  list[::] \n\n now you it will give, \n\n [5, 7, 13, 29]\n \n\n Problem is you removed a value from a list during iteration then your list index will collapse. \n\n so you can try comprehension instead. \n\n which supports all the iterable like, list, tuple, dict, string etc  \n    ", "date_posted": "2019-04-30 06:25:49Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "4453737", "name": "Mohideen bin Mohammed", "reputation_score": "17.2k"}, "answer_comments": [{"stack_answer_id": "55915047", "stack_answer_comment_id": "128054348", "comment_content": "To put in a simpler way: do ", "user_id": "None"}]}, {"stack_answer_id": "49311061", "answer_content": "\r\n The other answers are correct that it is usually a bad idea to delete from a list that you're iterating. Reverse iterating avoids some of the pitfalls, but it is much more difficult to follow code that does that, so usually you're better off using a list comprehension or  filter . \n There is, however, one case where it is safe to remove elements from a sequence that you are iterating: if you're only removing one item while you're iterating. This can be ensured using a  return  or a  break . For example: \n for i, item in enumerate(lst):\n    if item % 4 == 0:\n        foo(item)\n        del lst[i]\n        break\n \n This is often easier to understand than a list comprehension when you're doing some operations with side effects on the first item in a list that meets some condition and then removing that item from the list immediately after. \n    ", "date_posted": "2022-05-16 21:25:13Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "5079779", "name": "Beefster", "reputation_score": "665"}, "answer_comments": []}, {"stack_answer_id": "4639072", "answer_content": "\r\n You might want to use  filter()  available as the built-in. \n\n For more details  check here \n    ", "date_posted": "2017-07-27 07:40:53Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "5872484", "name": "Bharat Mane", "reputation_score": "296"}, "answer_comments": []}, {"stack_answer_id": "31350162", "answer_content": "\r\n You can try for-looping in reverse so for some_list you'll do something like: \n\n list_len = len(some_list)\nfor i in range(list_len):\n    reverse_i = list_len - 1 - i\n    cur = some_list[reverse_i]\n\n    # some logic with cur element\n\n    if some_condition:\n        some_list.pop(reverse_i)\n \n\n This way the index is aligned and doesn't suffer from the list updates (regardless whether you pop cur element or not). \n    ", "date_posted": "2015-07-10 20:58:49Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "975975", "name": "Queequeg", "reputation_score": "939"}, "answer_comments": [{"stack_answer_id": "31350162", "stack_answer_comment_id": "63359845", "comment_content": "Looping over ", "user_id": "None"}, {"stack_answer_id": "31350162", "stack_answer_comment_id": "63603723", "comment_content": "@MarkAmery don't think you can alter the list this way.", "user_id": "None"}]}, {"stack_answer_id": "53236774", "answer_content": "\r\n The most effective method is list comprehension, many people show their case, of course, it is also a good way to get an  iterator  through  filter . \n\n \n   Filter  receives a function and a sequence.  Filter  applies the passed function to each element in turn, and then decides whether to retain or discard the element depending on whether the function return value is  True  or  False . \n \n\n There is an example  (get the odds in the tuple): \n\n list(filter(lambda x:x%2==1, (1, 2, 4, 5, 6, 9, 10, 15)))  \n# result: [1, 5, 9, 15]\n \n\n Caution: You can also not handle iterators. Iterators are sometimes better than sequences. \n    ", "date_posted": "2018-11-10 07:05:16Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "10599390", "name": "chseng", "reputation_score": "116"}, "answer_comments": [{"stack_answer_id": "53236774", "stack_answer_comment_id": "121449764", "comment_content": "I probably think this is the most idiomatic way of removing the items from list. This behaviour will also be thread safe since your application is not mutating the variable.", "user_id": "None"}]}, {"stack_answer_id": "34310158", "answer_content": "\r\n I needed to do something similar and in my case the problem was memory - I needed to merge multiple dataset objects within a list, after doing some stuff with them, as a new object, and needed to get rid of each entry I was merging to avoid duplicating all of them and blowing up memory. In my case having the objects in a dictionary instead of a list worked fine: \n\n ``` \n\n k = range(5)\nv = ['a','b','c','d','e']\nd = {key:val for key,val in zip(k, v)}\n\nprint d\nfor i in range(5):\n    print d[i]\n    d.pop(i)\nprint d\n \n\n ``` \n    ", "date_posted": "2015-12-16 11:05:41Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "4577738", "name": "rafa", "reputation_score": "205"}, "answer_comments": []}, {"stack_answer_id": "37277264", "answer_content": "\r\n TLDR: \n\n I wrote a library that allows you to do this: \n\n from fluidIter import FluidIterable\nfSomeList = FluidIterable(someList)  \nfor tup in fSomeList:\n    if determine(tup):\n        # remove 'tup' without \"breaking\" the iteration\n        fSomeList.remove(tup)\n        # tup has also been removed from 'someList'\n        # as well as 'fSomeList'\n \n\n It's best to use another method if possible that doesn't require modifying your iterable while iterating over it, but for some algorithms it might not be that straight forward. And so if you are sure that you really do want the code pattern described in the original question, it is possible. \n\n Should work on all mutable sequences not just lists. \n\n \n\n Full answer: \n\n Edit: The last code example in this answer gives a use case for  why  you might sometimes want to modify a list in place rather than use a list comprehension. The first part of the answers serves as tutorial of  how  an array can be modified in place. \n\n The solution follows on from  this  answer (for a related question) from senderle. Which explains how the the array index is updated while iterating through a list that has been modified. The solution below is designed to correctly track the array index even if the list is modified. \n\n Download  fluidIter.py  from  here   https://github.com/alanbacon/FluidIterator , it is just a single file so no need to install git. There is no installer so you will need to make sure that the file is in the python path your self. The code has been written for python 3 and is untested on python 2. \n\n from fluidIter import FluidIterable\nl = [0,1,2,3,4,5,6,7,8]  \nfluidL = FluidIterable(l)                       \nfor i in fluidL:\n    print('initial state of list on this iteration: ' + str(fluidL)) \n    print('current iteration value: ' + str(i))\n    print('popped value: ' + str(fluidL.pop(2)))\n    print(' ')\n\nprint('Final List Value: ' + str(l))\n \n\n This will produce the following output: \n\n initial state of list on this iteration: [0, 1, 2, 3, 4, 5, 6, 7, 8]\ncurrent iteration value: 0\npopped value: 2\n\ninitial state of list on this iteration: [0, 1, 3, 4, 5, 6, 7, 8]\ncurrent iteration value: 1\npopped value: 3\n\ninitial state of list on this iteration: [0, 1, 4, 5, 6, 7, 8]\ncurrent iteration value: 4\npopped value: 4\n\ninitial state of list on this iteration: [0, 1, 5, 6, 7, 8]\ncurrent iteration value: 5\npopped value: 5\n\ninitial state of list on this iteration: [0, 1, 6, 7, 8]\ncurrent iteration value: 6\npopped value: 6\n\ninitial state of list on this iteration: [0, 1, 7, 8]\ncurrent iteration value: 7\npopped value: 7\n\ninitial state of list on this iteration: [0, 1, 8]\ncurrent iteration value: 8\npopped value: 8\n\nFinal List Value: [0, 1]\n \n\n Above we have used the  pop  method on the fluid list object. Other common iterable methods are also implemented such as  del fluidL[i] ,  .remove ,  .insert ,  .append ,  .extend . The list can also be modified using slices ( sort  and  reverse  methods are not implemented). \n\n The only condition is that you must only modify the list in place, if at any point  fluidL  or  l  were reassigned to a different list object the code would not work. The original  fluidL  object would still be used by the for loop but would become out of scope for us to modify. \n\n i.e. \n\n fluidL[2] = 'a'   # is OK\nfluidL = [0, 1, 'a', 3, 4, 5, 6, 7, 8]  # is not OK\n \n\n If we want to access the current index value of the list we cannot use enumerate, as this only counts how many times the for loop has run. Instead we will use the iterator object directly. \n\n fluidArr = FluidIterable([0,1,2,3])\n# get iterator first so can query the current index\nfluidArrIter = fluidArr.__iter__()\nfor i, v in enumerate(fluidArrIter):\n    print('enum: ', i)\n    print('current val: ', v)\n    print('current ind: ', fluidArrIter.currentIndex)\n    print(fluidArr)\n    fluidArr.insert(0,'a')\n    print(' ')\n\nprint('Final List Value: ' + str(fluidArr))\n \n\n This will output the following: \n\n enum:  0\ncurrent val:  0\ncurrent ind:  0\n[0, 1, 2, 3]\n\nenum:  1\ncurrent val:  1\ncurrent ind:  2\n['a', 0, 1, 2, 3]\n\nenum:  2\ncurrent val:  2\ncurrent ind:  4\n['a', 'a', 0, 1, 2, 3]\n\nenum:  3\ncurrent val:  3\ncurrent ind:  6\n['a', 'a', 'a', 0, 1, 2, 3]\n\nFinal List Value: ['a', 'a', 'a', 'a', 0, 1, 2, 3]\n \n\n The  FluidIterable  class just provides a wrapper for the original list object. The original object can be accessed as a property of the fluid object like so: \n\n originalList = fluidArr.fixedIterable\n \n\n More examples / tests can be found in the  if __name__ is \"__main__\":  section at the bottom of  fluidIter.py . These are worth looking at because they explain what happens in various situations. Such as: Replacing a large sections of the list using a slice. Or using (and modifying) the same iterable in nested for loops. \n\n As I stated to start with: this is a complicated solution that will hurt the readability of your code and make it more difficult to debug. Therefore other solutions such as the list comprehensions mentioned in David Raznick's  answer  should be considered first. That being said, I have found times where this class has been useful to me and has been easier to use than keeping track of the indices of elements that need deleting. \n\n \n\n Edit: As mentioned in the comments, this answer does not really present a problem for which this approach provides a solution. I will try to address that here: \n\n List comprehensions provide a way to generate a new list but these approaches tend to look at each element in isolation rather than the current state of the list as a whole. \n\n i.e. \n\n newList = [i for i in oldList if testFunc(i)]\n \n\n But what if the result of the  testFunc  depends on the elements that have been added to  newList  already? Or the elements still in  oldList  that might be added next? There might still be a way to use a list comprehension but it will begin to lose it's elegance, and for me it feels easier to modify a list in place. \n\n The code below is one example of an algorithm that suffers from the above problem. The algorithm will reduce a list so that no element is a multiple of any other element. \n\n randInts = [70, 20, 61, 80, 54, 18, 7, 18, 55, 9]\nfRandInts = FluidIterable(randInts)\nfRandIntsIter = fRandInts.__iter__()\n# for each value in the list (outer loop)\n# test against every other value in the list (inner loop)\nfor i in fRandIntsIter:\n    print(' ')\n    print('outer val: ', i)\n    innerIntsIter = fRandInts.__iter__()\n    for j in innerIntsIter:\n        innerIndex = innerIntsIter.currentIndex\n        # skip the element that the outloop is currently on\n        # because we don't want to test a value against itself\n        if not innerIndex == fRandIntsIter.currentIndex:\n            # if the test element, j, is a multiple \n            # of the reference element, i, then remove 'j'\n            if j%i == 0:\n                print('remove val: ', j)\n                # remove element in place, without breaking the\n                # iteration of either loop\n                del fRandInts[innerIndex]\n            # end if multiple, then remove\n        # end if not the same value as outer loop\n    # end inner loop\n# end outerloop\n\nprint('')\nprint('final list: ', randInts)\n \n\n The output and the final reduced list are shown below \n\n outer val:  70\n\nouter val:  20\nremove val:  80\n\nouter val:  61\n\nouter val:  54\n\nouter val:  18\nremove val:  54\nremove val:  18\n\nouter val:  7\nremove val:  70\n\nouter val:  55\n\nouter val:  9\nremove val:  18\n\nfinal list:  [20, 61, 7, 55, 9]\n \n    ", "date_posted": "2017-05-23 12:18:24Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": [{"stack_answer_id": "37277264", "stack_answer_comment_id": "63359804", "comment_content": "It's hard to tell whether this is over-engineered because it's unclear what problem it's trying to solve; what does removing elements using this approach achieve that ", "user_id": "None"}, {"stack_answer_id": "37277264", "stack_answer_comment_id": "63591681", "comment_content": "@MarkAmery. The main use case for when this is when trying to determine if an item should be removed (or added or moved) based not on just the item itself, but on the state of another item in the list or the state of the list as a whole. For example, it is not possible with list comprehensions to write something like ", "user_id": "None"}]}, {"stack_answer_id": "52447608", "answer_content": "\r\n In some situations, where you're doing more than simply filtering a list one item at time, you want your iteration to change while iterating. \n\n Here is an example where copying the list beforehand is incorrect, reverse iteration is impossible and a list comprehension is also not an option. \n\n \"\"\" Sieve of Eratosthenes \"\"\"\n\ndef generate_primes(n):\n    \"\"\" Generates all primes less than n. \"\"\"\n    primes = list(range(2,n))\n    idx = 0\n    while idx < len(primes):\n        p = primes[idx]\n        for multiple in range(p+p, n, p):\n            try:\n                primes.remove(multiple)\n            except ValueError:\n                pass #EAFP\n        idx += 1\n        yield p\n \n    ", "date_posted": "2018-09-21 16:14:52Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "2780179", "name": "MathKid", "reputation_score": "1,513"}, "answer_comments": []}, {"stack_answer_id": "53600740", "answer_content": "\r\n I can think of three approaches to solve your problem. As an example, I will create a random list of tuples  somelist = [(1,2,3), (4,5,6), (3,6,6), (7,8,9), (15,0,0), (10,11,12)] . The condition that I choose is  sum of elements of a tuple = 15 . In the final list we will only have those tuples whose sum is not equal to 15.  \n\n What I have chosen is a randomly chosen example.  Feel free to change  the  list of tuples  and the  condition  that I have chosen.   \n\n Method 1.>  Use the framework that you had suggested (where one fills in a code inside a for loop). I use a small code with  del  to delete a tuple that meets the said condition. However, this method will miss a tuple (which satisfies the said condition) if two consecutively placed tuples meet the given condition.  \n\n for tup in somelist:\n    if ( sum(tup)==15 ): \n        del somelist[somelist.index(tup)]\n\nprint somelist\n>>> [(1, 2, 3), (3, 6, 6), (7, 8, 9), (10, 11, 12)]\n \n\n Method 2.>  Construct a new list which contains elements (tuples) where the given condition is not met (this is the same thing as removing elements of list where the given condition is met). Following is the code for that: \n\n newlist1 = [somelist[tup] for tup in range(len(somelist)) if(sum(somelist[tup])!=15)]\n\nprint newlist1\n>>>[(1, 2, 3), (7, 8, 9), (10, 11, 12)]\n \n\n Method 3.>  Find indices where the given condition is met, and then use remove elements (tuples) corresponding to those indices. Following is the code for that. \n\n indices = [i for i in range(len(somelist)) if(sum(somelist[i])==15)]\nnewlist2 = [tup for j, tup in enumerate(somelist) if j not in indices]\n\nprint newlist2\n>>>[(1, 2, 3), (7, 8, 9), (10, 11, 12)]\n \n\n Method 1 and method 2 are faster than method 3 . Method2 and method3 are more efficient than method1. I  prefer method2 . For the aforementioned example,  time(method1) : time(method2) : time(method3) = 1 : 1 : 1.7 \n    ", "date_posted": "2018-12-03 21:04:05Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "10626090", "name": "Siddharth Satpathy", "reputation_score": "2,513"}, "answer_comments": []}, {"stack_answer_id": "55704504", "answer_content": "\r\n If you will use the new list later, you can simply set the elem to None, and then judge it in the later loop, like this \n\n for i in li:\n    i = None\n\nfor elem in li:\n    if elem is None:\n        continue\n \n\n In this way, you dont't need copy the list and it's easier to understand.  \n    ", "date_posted": "2019-04-16 09:08:13Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "2899160", "name": "Mark Zhang", "reputation_score": "918"}, "answer_comments": []}, {"stack_answer_id": "51976515", "answer_content": "\r\n For anything that has the potential to be really big, I use the following.  \n\n import numpy as np\n\norig_list = np.array([1, 2, 3, 4, 5, 100, 8, 13])\n\nremove_me = [100, 1]\n\ncleaned = np.delete(orig_list, remove_me)\nprint(cleaned)\n \n\n That should be significantly faster than anything else.  \n    ", "date_posted": "2018-08-22 23:36:31Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "5893677", "name": "CENTURION", "reputation_score": "325"}, "answer_comments": [{"stack_answer_id": "51976515", "stack_answer_comment_id": "98893393", "comment_content": "From what I measured, NumPy starts to be faster for lists of more than 20 elements, and reaches >12x faster filtering for big lists of 1000 elements and more.", "user_id": "None"}]}], "user": {"stack_user_id": "90777", "name": "lfaraone", "reputation_score": "48.3k"}, "question_comments": [{"stack_question_id": "1207406", "stack_question_comment_id": "104658488", "comment_content": "Most answers on this page don't really explain why removing elements while iterating over a list produces strange results, but the ", "user_id": "None"}]},
{"stack_question_id": "53645882", "question_title": "Pandas Merging 101", "question_content": "\r\n                How can I perform a (INNER| (LEFT|RIGHT|FULL) OUTER) JOIN with pandas?\nHow do I add NaNs for missing rows after a merge?\nHow do I get rid of NaNs after merging?\nCan I merge on the index?\nHow do I ...\r\n", "question_url": "/questions/53645882/pandas-merging-101", "date_posted": "Dec 6, 2018 at 6:41", "upvote": "7", "view": "3", "tags": ["python", "pandas", "join", "merge", "concatenation"], "answers_count": "8", "answers": [{"stack_answer_id": "53645883", "answer_content": "\r\n This post aims to give readers a primer on SQL-flavored merging with Pandas, how to use it, and when not to use it. \n In particular, here's what this post will go through: \n \n The basics - types of joins (LEFT, RIGHT, OUTER, INNER) \n \n merging with different column names \n merging with multiple columns \n avoiding duplicate merge key column in output \n \n \n \n What this post (and other posts by me on this thread) will not go through: \n \n Performance-related discussions and timings (for now). Mostly notable mentions of better alternatives, wherever appropriate. \n Handling suffixes, removing extra columns, renaming outputs, and other specific use cases. There are other (read: better) posts that deal with that, so figure it out! \n \n \n Note \nMost examples default to INNER JOIN operations while demonstrating various features, unless otherwise specified. \n Furthermore, all the DataFrames here can be copied and replicated so\nyou can play with them. Also, see  this\npost \non how to read DataFrames from your clipboard. \n Lastly, all visual representation of JOIN operations have been hand-drawn using Google Drawings. Inspiration from  here . \n \n \n \n Enough talk - just show me how to use  merge ! \n Setup & Basics \n np.random.seed(0)\nleft = pd.DataFrame({'key': ['A', 'B', 'C', 'D'], 'value': np.random.randn(4)})\nright = pd.DataFrame({'key': ['B', 'D', 'E', 'F'], 'value': np.random.randn(4)})\n\nleft\n\n  key     value\n0   A  1.764052\n1   B  0.400157\n2   C  0.978738\n3   D  2.240893\n\nright\n\n  key     value\n0   B  1.867558\n1   D -0.977278\n2   E  0.950088\n3   F -0.151357\n \n For the sake of simplicity, the key column has the same name (for now). \n An  INNER JOIN  is represented by \n \n \n Note \nThis, along with the forthcoming figures all follow this convention: \n \n blue  indicates rows that are present in the merge result \n red  indicates rows that are excluded from the result (i.e., removed) \n green  indicates missing values that are replaced with  NaN s in the result \n \n \n To perform an INNER JOIN, call  merge  on the left DataFrame, specifying the right DataFrame and the join key (at the very least) as arguments. \n left.merge(right, on='key')\n# Or, if you want to be explicit\n# left.merge(right, on='key', how='inner')\n\n  key   value_x   value_y\n0   B  0.400157  1.867558\n1   D  2.240893 -0.977278\n \n This returns only rows from  left  and  right  which share a common key (in this example, \"B\" and \"D). \n A  LEFT OUTER JOIN , or LEFT JOIN  is represented by \n \n This can be performed by specifying  how='left' . \n left.merge(right, on='key', how='left')\n\n  key   value_x   value_y\n0   A  1.764052       NaN\n1   B  0.400157  1.867558\n2   C  0.978738       NaN\n3   D  2.240893 -0.977278\n \n Carefully note the placement of NaNs here. If you specify  how='left' , then only keys from  left  are used, and missing data from  right  is replaced by NaN. \n And similarly, for a  RIGHT OUTER JOIN , or RIGHT JOIN which is... \n \n ...specify  how='right' : \n left.merge(right, on='key', how='right')\n\n  key   value_x   value_y\n0   B  0.400157  1.867558\n1   D  2.240893 -0.977278\n2   E       NaN  0.950088\n3   F       NaN -0.151357\n \n Here, keys from  right  are used, and missing data from  left  is replaced by NaN. \n Finally, for the  FULL OUTER JOIN , given by \n \n specify  how='outer' . \n left.merge(right, on='key', how='outer')\n\n  key   value_x   value_y\n0   A  1.764052       NaN\n1   B  0.400157  1.867558\n2   C  0.978738       NaN\n3   D  2.240893 -0.977278\n4   E       NaN  0.950088\n5   F       NaN -0.151357\n \n This uses the keys from both frames, and NaNs are inserted for missing rows in both. \n The documentation summarizes these various merges nicely: \n \n \n Other JOINs - LEFT-Excluding, RIGHT-Excluding, and FULL-Excluding/ANTI JOINs \n If you need  LEFT-Excluding JOINs  and  RIGHT-Excluding JOINs  in two steps. \n For LEFT-Excluding JOIN, represented as \n \n Start by performing a LEFT OUTER JOIN and then filtering to rows coming from  left  only (excluding everything from the right), \n (left.merge(right, on='key', how='left', indicator=True)\n     .query('_merge == \"left_only\"')\n     .drop('_merge', 1))\n\n  key   value_x  value_y\n0   A  1.764052      NaN\n2   C  0.978738      NaN\n \n Where, \n left.merge(right, on='key', how='left',  indicator=True )\n\n  key   value_x   value_y     _merge\n0   A  1.764052       NaN  left_only\n1   B  0.400157  1.867558       both\n2   C  0.978738       NaN  left_only\n3   D  2.240893 -0.977278       both \n And similarly, for a RIGHT-Excluding JOIN, \n \n (left.merge(right, on='key', how='right',  indicator=True )\n     .query('_merge == \"right_only\"')\n     .drop('_merge', 1))\n\n  key  value_x   value_y\n2   E      NaN  0.950088\n3   F      NaN -0.151357 \n Lastly, if you are required to do a merge that only retains keys from the left or right, but not both (IOW, performing an  ANTI-JOIN ), \n \n You can do this in similar fashion\u2014 \n (left.merge(right, on='key', how='outer', indicator=True)\n     .query('_merge != \"both\"')\n     .drop('_merge', 1))\n\n  key   value_x   value_y\n0   A  1.764052       NaN\n2   C  0.978738       NaN\n4   E       NaN  0.950088\n5   F       NaN -0.151357\n \n \n Different names for key columns \n If the key columns are named differently\u2014for example,  left  has  keyLeft , and  right  has  keyRight  instead of  key \u2014then you will have to specify  left_on  and  right_on  as arguments instead of  on : \n left2 = left.rename({'key':'keyLeft'}, axis=1)\nright2 = right.rename({'key':'keyRight'}, axis=1)\n\nleft2\n\n  keyLeft     value\n0       A  1.764052\n1       B  0.400157\n2       C  0.978738\n3       D  2.240893\n\nright2\n\n  keyRight     value\n0        B  1.867558\n1        D -0.977278\n2        E  0.950088\n3        F -0.151357\n \n\n left2.merge(right2, left_on='keyLeft', right_on='keyRight', how='inner')\n\n  keyLeft   value_x keyRight   value_y\n0       B  0.400157        B  1.867558\n1       D  2.240893        D -0.977278\n \n \n Avoiding duplicate key column in output \n When merging on  keyLeft  from  left  and  keyRight  from  right , if you only want either of the  keyLeft  or  keyRight  (but not both) in the output, you can start by setting the index as a preliminary step. \n left3 = left2.set_index('keyLeft')\nleft3.merge(right2, left_index=True, right_on='keyRight')\n\n    value_x keyRight   value_y\n0  0.400157        B  1.867558\n1  2.240893        D -0.977278\n \n Contrast this with the output of the command just before (that is, the output of  left2.merge(right2, left_on='keyLeft', right_on='keyRight', how='inner') ), you'll notice  keyLeft  is missing. You can figure out what column to keep based on which frame's index is set as the key. This may matter when, say, performing some OUTER JOIN operation. \n \n Merging only a single column from one of the  DataFrames \n For example, consider \n right3 = right.assign(newcol=np.arange(len(right)))\nright3\n  key     value  newcol\n0   B  1.867558       0\n1   D -0.977278       1\n2   E  0.950088       2\n3   F -0.151357       3\n \n If you are required to merge only \"newcol\" (without any of the other columns), you can usually just subset columns before merging: \n left.merge(right3[['key', 'newcol']], on='key')\n\n  key     value  newcol\n0   B  0.400157       0\n1   D  2.240893       1\n \n If you're doing a LEFT OUTER JOIN, a more performant solution would involve  map : \n # left['newcol'] = left['key'].map(right3.set_index('key')['newcol']))\nleft.assign(newcol=left['key'].map(right3.set_index('key')['newcol']))\n\n  key     value  newcol\n0   A  1.764052     NaN\n1   B  0.400157     0.0\n2   C  0.978738     NaN\n3   D  2.240893     1.0\n \n As mentioned, this is similar to, but faster than \n left.merge(right3[['key', 'newcol']], on='key', how='left')\n\n  key     value  newcol\n0   A  1.764052     NaN\n1   B  0.400157     0.0\n2   C  0.978738     NaN\n3   D  2.240893     1.0\n \n \n Merging on multiple columns \n To join on more than one column, specify a list for  on  (or  left_on  and  right_on , as appropriate). \n left.merge(right, on=['key1', 'key2'] ...)\n \n Or, in the event the names are different, \n left.merge(right, left_on=['lkey1', 'lkey2'], right_on=['rkey1', 'rkey2'])\n \n \n Other useful  merge*  operations and functions \n \n Merging a DataFrame with Series on index: See  this answer . \n \n Besides  merge ,  DataFrame.update  and  DataFrame.combine_first  are also used in certain cases to update one DataFrame with another. \n \n pd.merge_ordered  is a useful function for ordered JOINs. \n \n pd.merge_asof  (read: merge_asOf) is useful for  approximate  joins. \n \n \n This section only covers the very basics, and is designed to only whet your appetite. For more examples and cases, see the  documentation on  merge ,  join , and  concat  as well as the links to the function specifications. \n \n \n Continue Reading \n Jump to other topics in Pandas Merging 101 to continue learning: \n \n Merging basics - basic types of joins   * \n \n Index-based joins \n \n Generalizing to multiple DataFrames \n \n Cross join \n \n \n *You are here. \n    ", "date_posted": "2022-07-01 21:01:48Z", "upvote": "\r\n            1112\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "7967588", "name": "creanion", "reputation_score": "1,821"}, "answer_comments": [{"stack_answer_id": "53645883", "stack_answer_comment_id": "115512450", "comment_content": "If anyone is confused by the table of contents at the end of each post, I split up this massive answer into 4 separate ones, 3 on this question and 1 on another. The way it was setup previously made it harder to reference folks to specific topics. This allows you to bookmark separate topics easily now!", "user_id": "4909087"}, {"stack_answer_id": "53645883", "stack_answer_comment_id": "118452869", "comment_content": "This is an awesome resource! The only question I still have is why call it merge instead of join, and join instead of merge?", "user_id": "None"}]}, {"stack_answer_id": "55858991", "answer_content": "\r\n A supplemental visual view of  pd.concat([df0, df1], kwargs) . \nNotice that, kwarg  axis=0  or  axis=1  's meaning is not as intuitive as  df.mean()  or  df.apply(func) \n\n \n\n \n    ", "date_posted": "2019-10-11 17:36:29Z", "upvote": "\r\n            89\r\n        ", "accepted": "No", "user": {"stack_user_id": "11884237", "name": "ansev", "reputation_score": "29.3k"}, "answer_comments": [{"stack_answer_id": "55858991", "stack_answer_comment_id": "99071795", "comment_content": "This is a nice diagram. May I ask how you produced it?", "user_id": "4909087"}, {"stack_answer_id": "55858991", "stack_answer_comment_id": "99107100", "comment_content": "google doc's built-in \"insert ==> drawing... ==> new\" (as of 2019-May). But, to be clear: the only reason I used google doc for this picture  is because my notes is stored in google doc, and I would like a picture that can be modified quickly within google doc itself. Actually now you mentioned it, the google doc's drawing tool is pretty neat.", "user_id": "None"}, {"stack_answer_id": "55858991", "stack_answer_comment_id": "101107976", "comment_content": "Wow, this is great. Coming from the SQL world, \"vertical\" join is not a join in my head, as the table's structure is always fixed. Now even think pandas should consolidate ", "user_id": "None"}, {"stack_answer_id": "55858991", "stack_answer_comment_id": "101246910", "comment_content": "@Ufos Isn't that exactly what ", "user_id": "4909087"}, {"stack_answer_id": "55858991", "stack_answer_comment_id": "101569956", "comment_content": "yes, there're now ", "user_id": "None"}]}, {"stack_answer_id": "69115959", "answer_content": "\r\n Joins 101 \n These animations might be better to explain you visually.\nCredits:  Garrick Aden-Buie tidyexplain repo \n Inner Join \n \n Outer Join or Full Join \n \n Right Join \n \n Left Join \n \n    ", "date_posted": "2021-09-18 04:58:49Z", "upvote": "\r\n            54\r\n        ", "accepted": "No", "user": {"stack_user_id": "8277795", "name": "Anurag Dhadse", "reputation_score": "1,340"}, "answer_comments": [{"stack_answer_id": "69115959", "stack_answer_comment_id": "124057875", "comment_content": "These are awesome!", "user_id": "None"}, {"stack_answer_id": "69115959", "stack_answer_comment_id": "125963015", "comment_content": "I appreciate the effort put in to achieve this. Beautifully done.", "user_id": "None"}]}, {"stack_answer_id": "63338203", "answer_content": "\r\n In this answer, I will consider practical examples. \n The first one, is of  pandas.concat . \n The second one, of merging dataframes from the index of one and the column of another one. \n \n 1 .  pandas.concat \n Considering the following  DataFrames  with the same column names: \n Preco2018  with size (8784, 5) \n \n Preco 2019  with size (8760, 5) \n \n That have the same column names. \n You can combine them using  pandas.concat , by simply \n import pandas as pd\n\nframes = [Preco2018, Preco2019]\n\ndf_merged = pd.concat(frames)\n \n Which results in a DataFrame with the following size (17544, 5) \n \n If you want to visualize, it ends up working like this \n \n ( Source ) \n \n 2 . Merge by Column and Index \n In this part, I will consider a specific case: If one wants to merge the index of one dataframe and the column of another dataframe. \n Let's say one has the dataframe  Geo  with 54 columns, being one of the columns the Date  Data , which is of type  datetime64[ns] . \n \n And the dataframe  Price  that has one column with the price and the index corresponds to the dates \n \n In this specific case, to merge them, one uses  pd.merge \n merged = pd.merge(Price, Geo, left_index=True, right_on='Data')\n \n Which results in the following dataframe \n \n    ", "date_posted": "2021-01-24 00:26:49Z", "upvote": "\r\n            22\r\n        ", "accepted": "No", "user": {"stack_user_id": "7109869", "name": "Gon\u00e7alo Peres", "reputation_score": "6,422"}, "answer_comments": []}, {"stack_answer_id": "65167356", "answer_content": "\r\n This post will go through the following topics: \n \n Merging with index under different conditions\n \n options for index-based joins:  merge ,  join ,  concat \n merging on indexes \n merging on index of one, column of other \n \n \n effectively using named indexes to simplify merging syntax \n \n BACK TO TOP \n \n \n Index-based joins \n TL;DR \n \n There are a few options, some simpler than others depending on the use\ncase. \n \n DataFrame.merge  with  left_index  and  right_index  (or  left_on  and  right_on  using named indexes)\n \n supports inner/left/right/full \n can only join two at a time \n supports column-column, index-column, index-index joins \n \n \n DataFrame.join  (join on index)\n \n supports inner/left (default)/right/full \n can join multiple DataFrames at a time \n supports index-index joins \n \n \n pd.concat  (joins on index)\n \n supports inner/full (default) \n can join multiple DataFrames at a time \n supports index-index joins \n \n \n \n \n \n Index to index joins \n Setup & Basics \n import pandas as pd\nimport numpy as np\n\nnp.random.seed([3, 14])\nleft = pd.DataFrame(data={'value': np.random.randn(4)}, \n                    index=['A', 'B', 'C', 'D'])    \nright = pd.DataFrame(data={'value': np.random.randn(4)},  \n                     index=['B', 'D', 'E', 'F'])\nleft.index.name = right.index.name = 'idxkey'\n\nleft\n           value\nidxkey          \nA      -0.602923\nB      -0.402655\nC       0.302329\nD      -0.524349\n\nright\n \n           value\nidxkey          \nB       0.543843\nD       0.013135\nE      -0.326498\nF       1.385076\n \n Typically, an  inner join on index  would look like this: \n left.merge(right, left_index=True, right_index=True)\n\n         value_x   value_y\nidxkey                    \nB      -0.402655  0.543843\nD      -0.524349  0.013135\n \n Other joins follow similar syntax. \n Notable Alternatives \n \n DataFrame.join  defaults to joins on the index.  DataFrame.join  does a LEFT OUTER JOIN by default, so  how='inner'  is necessary here. \n  left.join(right, how='inner', lsuffix='_x', rsuffix='_y')\n\n          value_x   value_y\n idxkey                    \n B      -0.402655  0.543843\n D      -0.524349  0.013135\n \n Note that I needed to specify the  lsuffix  and  rsuffix  arguments since  join  would otherwise error out: \n  left.join(right)\n ValueError: columns overlap but no suffix specified: Index(['value'], dtype='object')\n \n Since the column names are the same. This would not be a problem if they were differently named. \n  left.rename(columns={'value':'leftvalue'}).join(right, how='inner')\n\n         leftvalue     value\n idxkey                     \n B       -0.402655  0.543843\n D       -0.524349  0.013135\n \n \n pd.concat  joins on the index and can join two or more DataFrames at once. It does a full outer join by default, so  how='inner'  is required here.. \n  pd.concat([left, right], axis=1, sort=False, join='inner')\n\n            value     value\n idxkey                    \n B      -0.402655  0.543843\n D      -0.524349  0.013135\n \n For more information on  concat , see  this post . \n \n \n \n Index to Column joins \n To perform an inner join using index of left, column of right, you will use  DataFrame.merge  a combination of  left_index=True  and  right_on=... . \n right2 = right.reset_index().rename({'idxkey' : 'colkey'}, axis=1)\nright2\n \n  colkey     value\n0      B  0.543843\n1      D  0.013135\n2      E -0.326498\n3      F  1.385076\n\nleft.merge(right2, left_index=True, right_on='colkey')\n\n    value_x colkey   value_y\n0 -0.402655      B  0.543843\n1 -0.524349      D  0.013135\n \n Other joins follow a similar structure. Note that only  merge  can perform index to column joins. You can join on multiple columns, provided the number of index levels on the left equals the number of columns on the right. \n join  and  concat  are not capable of mixed merges. You will need to set the index as a pre-step using  DataFrame.set_index . \n \n Effectively using Named Index [pandas >= 0.23] \n If your index is named, then from pandas >= 0.23,  DataFrame.merge  allows you to specify the index name to  on  (or  left_on  and  right_on  as necessary). \n left.merge(right, on='idxkey')\n\n         value_x   value_y\nidxkey                    \nB      -0.402655  0.543843\nD      -0.524349  0.013135\n \n For the previous example of merging with the index of left, column of right, you can use  left_on  with the index name of left: \n left.merge(right2, left_on='idxkey', right_on='colkey')\n\n    value_x colkey   value_y\n0 -0.402655      B  0.543843\n1 -0.524349      D  0.013135\n \n \n \n Continue Reading \n Jump to other topics in Pandas Merging 101 to continue learning: \n \n Merging basics - basic types of joins \n \n Index-based joins * \n \n Generalizing to multiple DataFrames \n \n Cross join \n \n \n * you are here  \n    ", "date_posted": "2022-06-05 19:09:34Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "65167356", "name": "\r\n        6 revs, 2 users 100%", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "65167327", "answer_content": "\r\n This post will go through the following topics: \n \n how to correctly generalize to multiple DataFrames (and why  merge  has shortcomings here) \n merging on unique keys \n merging on non-unqiue keys \n \n BACK TO TOP \n \n \n Generalizing to multiple DataFrames \n Oftentimes, the situation arises when multiple DataFrames are to be merged together. Naively, this can be done by chaining  merge  calls: \n df1.merge(df2, ...).merge(df3, ...)\n \n However, this quickly gets out of hand for many DataFrames. Furthermore, it may be necessary to generalise for an unknown number of DataFrames. \n Here I introduce  pd.concat  for multi-way joins on  unique  keys, and  DataFrame.join  for multi-way joins on  non-unique  keys. First, the setup. \n # Setup.\nnp.random.seed(0)\nA = pd.DataFrame({'key': ['A', 'B', 'C', 'D'], 'valueA': np.random.randn(4)})    \nB = pd.DataFrame({'key': ['B', 'D', 'E', 'F'], 'valueB': np.random.randn(4)})\nC = pd.DataFrame({'key': ['D', 'E', 'J', 'C'], 'valueC': np.ones(4)})\ndfs = [A, B, C] \n\n# Note: the \"key\" column values are unique, so the index is unique.\nA2 = A.set_index('key')\nB2 = B.set_index('key')\nC2 = C.set_index('key')\n\ndfs2 = [A2, B2, C2]\n \n \n Multiway merge on unique keys \n If your keys (here, the key could either be a column or an index) are unique, then you can use  pd.concat . Note that  pd.concat  joins DataFrames on the index . \n # Merge on `key` column. You'll need to set the index before concatenating\npd.concat(\n    [df.set_index('key') for df in dfs], axis=1, join='inner'\n).reset_index()\n\n  key    valueA    valueB  valueC\n0   D  2.240893 -0.977278     1.0\n\n# Merge on `key` index.\npd.concat(dfs2, axis=1, sort=False, join='inner')\n\n       valueA    valueB  valueC\nkey                            \nD    2.240893 -0.977278     1.0\n \n Omit  join='inner'  for a FULL OUTER JOIN. Note that you cannot specify LEFT or RIGHT OUTER joins (if you need these, use  join , described below). \n \n Multiway merge on keys with duplicates \n concat  is fast, but has its shortcomings. It cannot handle duplicates. \n A3 = pd.DataFrame({'key': ['A', 'B', 'C', 'D', 'D'], 'valueA': np.random.randn(5)})\npd.concat([df.set_index('key') for df in [A3, B, C]], axis=1, join='inner')\n \n ValueError: Shape of passed values is (3, 4), indices imply (3, 2)\n \n In this situation, we can use  join  since it can handle non-unique keys (note that  join  joins DataFrames on their index; it calls  merge  under the hood and does a LEFT OUTER JOIN unless otherwise specified). \n # Join on `key` column. Set as the index first.\n# For inner join. For left join, omit the \"how\" argument.\nA.set_index('key').join([B2, C2], how='inner').reset_index()\n\n  key    valueA    valueB  valueC\n0   D  2.240893 -0.977278     1.0\n\n# Join on `key` index.\nA3.set_index('key').join([B2, C2], how='inner')\n\n       valueA    valueB  valueC\nkey                            \nD    1.454274 -0.977278     1.0\nD    0.761038 -0.977278     1.0\n \n \n \n Continue Reading \n Jump to other topics in Pandas Merging 101 to continue learning: \n \n Merging basics - basic types of joins \n \n Index-based joins \n \n Generalizing to multiple DataFrames   * \n \n Cross join \n \n \n * you are here  \n    ", "date_posted": "2022-06-05 19:24:17Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "65167327", "name": "\r\n        6 revs, 2 users 87%", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "73285069", "answer_content": "\r\n Pandas at the moment does not support inequality joins within the merge syntax; one option is with the  conditional_join  function from  pyjanitor  - I am a contributor to this library: \n # pip install pyjanitor\nimport pandas as pd\nimport janitor \n\nleft.conditional_join(right, ('value', 'value', '>'))\n\n   left           right\n    key     value   key     value\n0     A  1.764052     D -0.977278\n1     A  1.764052     F -0.151357\n2     A  1.764052     E  0.950088\n3     B  0.400157     D -0.977278\n4     B  0.400157     F -0.151357\n5     C  0.978738     D -0.977278\n6     C  0.978738     F -0.151357\n7     C  0.978738     E  0.950088\n8     D  2.240893     D -0.977278\n9     D  2.240893     F -0.151357\n10    D  2.240893     E  0.950088\n11    D  2.240893     B  1.867558\n\nleft.conditional_join(right, ('value', 'value', '<'))\n\n  left           right\n   key     value   key     value\n0    A  1.764052     B  1.867558\n1    B  0.400157     E  0.950088\n2    B  0.400157     B  1.867558\n3    C  0.978738     B  1.867558\n \n The columns are passed as a variable argument of tuples, each tuple comprising of a column from the left dataframe, column from the right dataframe, and the join operator, which can be any of  (>, <, >=, <=, !=) . In the example above, a MultiIndex column is returned, because of overlaps in the column names. \n Performance wise, this is better than a naive cross join: \n np.random.seed(0)\ndd = pd.DataFrame({'value':np.random.randint(100000, size=50_000)})\ndf = pd.DataFrame({'start':np.random.randint(100000, size=1_000), \n                   'end':np.random.randint(100000, size=1_000)})\n\ndd.head()\n\n   value\n0  68268\n1  43567\n2  42613\n3  45891\n4  21243\n\ndf.head()\n\n   start    end\n0  71915  47005\n1  64284  44913\n2  13377  96626\n3  75823  38673\n4  29151    575\n\n\n%%timeit\nout = df.merge(dd, how='cross')\nout.loc[(out.start < out.value) & (out.end > out.value)]\n5.12 s \u00b1 19 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n\n%timeit df.conditional_join(dd, ('start', 'value' ,'<'), ('end', 'value' ,'>'))\n280 ms \u00b1 5.56 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n\nout = df.merge(dd, how='cross')\nout = out.loc[(out.start < out.value) & (out.end > out.value)]\nA = df.conditional_join(dd, ('start', 'value' ,'<'), ('end', 'value' ,'>'))\ncolumns = A.columns.tolist()\nA = A.sort_values(columns, ignore_index = True)\nout = out.sort_values(columns, ignore_index = True)\n\nA.equals(out)\nTrue\n \n    ", "date_posted": "2022-08-08 23:35:35Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "7175713", "name": "sammywemmy", "reputation_score": "23.6k"}, "answer_comments": []}, {"stack_answer_id": "53787691", "answer_content": "\r\n I think you should include this in your explanation as it is a relevant merge that I see fairly often, which is termed  cross-join  I believe. This is a merge that occurs when unique df's share no columns, and it simply merging 2 dfs side-by-side: \n The setup: \n names1 = [{'A':'Jack', 'B':'Jill'}]\n\nnames2 = [{'C':'Tommy', 'D':'Tammy'}]\n\ndf1=pd.DataFrame(names1)\ndf2=pd.DataFrame(names2)\ndf_merged= pd.merge(df1.assign(X=1), df2.assign(X=1), on='X').drop('X', 1)\n \n This creates a dummy X column, merges on the X, and then drops it to produce \n df_merged: \n       A     B      C      D\n0  Jack  Jill  Tommy  Tammy\n \n    ", "date_posted": "2022-08-09 07:20:23Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "6296561", "name": "Zoe stands with Ukraine", "reputation_score": "25.5k"}, "answer_comments": [{"stack_answer_id": "53787691", "stack_answer_comment_id": "94427861", "comment_content": "Please check the second comment under the question. Cross join was initially a part of this (see edit history) but was later edited out into it's own post for volume.", "user_id": "4909087"}, {"stack_answer_id": "53787691", "stack_answer_comment_id": "94427874", "comment_content": "I see! do you want me to delete this so it is not convoluted?", "user_id": "None"}, {"stack_answer_id": "53787691", "stack_answer_comment_id": "94427904", "comment_content": "Seeing as cross join was not meant to be covered here, yes... However I appreciate your intent to contribute in good faith :)", "user_id": "4909087"}]}], "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "question_comments": []},
{"stack_question_id": "47152691", "question_title": "How can I pivot a dataframe?", "question_content": "\r\n                What is pivot?\nHow do I pivot?\nIs this a pivot?\nLong format to wide format?\n\nI've seen a lot of questions that ask about pivot tables.  Even if they don't know that they are asking about pivot tables, ...\r\n", "question_url": "/questions/47152691/how-can-i-pivot-a-dataframe", "date_posted": "Nov 7, 2017 at 8:00", "upvote": "5", "view": "5", "tags": ["python", "pandas", "group-by", "pivot", "pandas-groupby"], "answers_count": "4", "answers": [{"stack_answer_id": "47152692", "answer_content": "\r\n We start by answering the first question: \n Question 1 \n \n Why do I get  ValueError: Index contains duplicate entries, cannot reshape \n \n This occurs because pandas is attempting to reindex either a  columns  or  index  object with duplicate entries.  There are varying methods to use that can perform a pivot.  Some of them are not well suited to when there are duplicates of the keys in which it is being asked to pivot on.  For example.  Consider  pd.DataFrame.pivot .  I know there are duplicate entries that share the  row  and  col  values: \n df.duplicated(['row', 'col']).any()\n\nTrue\n \n So when I  pivot  using \n df.pivot(index='row', columns='col', values='val0')\n \n I get the error mentioned above.  In fact, I get the same error when I try to perform the same task with: \n df.set_index(['row', 'col'])['val0'].unstack()\n \n Here is a list of idioms we can use to pivot \n \n pd.DataFrame.groupby  +  pd.DataFrame.unstack \n \n Good general approach for doing just about any type of pivot \n You specify all columns that will constitute the pivoted row levels and column levels in one group by.  You follow that by selecting the remaining columns you want to aggregate and the function(s) you want to perform the aggregation.  Finally, you  unstack  the levels that you want to be in the column index. \n \n \n pd.DataFrame.pivot_table \n \n A glorified version of  groupby  with more intuitive API.  For many people, this is the preferred approach.  And is the intended approach by the developers. \n Specify row level, column levels, values to be aggregated, and function(s) to perform aggregations. \n \n \n pd.DataFrame.set_index  +  pd.DataFrame.unstack \n \n Convenient and intuitive for some (myself included).  Cannot handle duplicate grouped keys. \n Similar to the  groupby  paradigm, we specify all columns that will eventually be either row or column levels and set those to be the index.  We then  unstack  the levels we want in the columns.  If either the remaining index levels or column levels are not unique, this method will fail. \n \n \n pd.DataFrame.pivot \n \n Very similar to  set_index  in that it shares the duplicate key limitation.  The API is very limited as well.  It only takes scalar values for  index ,  columns ,  values . \n Similar to the  pivot_table  method in that we select rows, columns, and values on which to pivot.  However, we cannot aggregate and if either rows or columns are not unique, this method will fail. \n \n \n pd.crosstab \n \n This a specialized version of  pivot_table  and in its purest form is the most intuitive way to perform several tasks. \n \n \n pd.factorize  +  np.bincount \n \n This is a highly advanced technique that is very obscure but is very fast.  It cannot be used in all circumstances, but when it can be used and you are comfortable using it, you will reap the performance rewards. \n \n \n pd.get_dummies  +  pd.DataFrame.dot \n \n I use this for cleverly performing cross tabulation. \n \n \n \n \n Examples \n What I'm going to do for each subsequent answer and question is to answer it using  pd.DataFrame.pivot_table .  Then I'll provide alternatives to perform the same task. \n Question 3 \n \n How do I pivot  df  such that the  col  values are columns,  row  values are the index, mean of  val0  are the values, and missing values are  0 ? \n \n \n pd.DataFrame.pivot_table \n \n fill_value  is not set by default.  I tend to set it appropriately.  In this case I set it to  0 .  Notice I skipped  question 2  as it's the same as this answer without the  fill_value \n \n aggfunc='mean'  is the default and I didn't have to set it.  I included it to be explicit. \n     df.pivot_table(\n        values='val0', index='row', columns='col',\n        fill_value=0, aggfunc='mean')\n\n    col   col0   col1   col2   col3  col4\n    row\n    row0  0.77  0.605  0.000  0.860  0.65\n    row2  0.13  0.000  0.395  0.500  0.25\n    row3  0.00  0.310  0.000  0.545  0.00\n    row4  0.00  0.100  0.395  0.760  0.24\n \n \n \n \n pd.DataFrame.groupby \n   df.groupby(['row', 'col'])['val0'].mean().unstack(fill_value=0)\n \n \n pd.crosstab \n   pd.crosstab(\n      index=df['row'], columns=df['col'],\n      values=df['val0'], aggfunc='mean').fillna(0)\n \n \n \n \n Question 4 \n \n Can I get something other than  mean , like maybe  sum ? \n \n \n pd.DataFrame.pivot_table \n   df.pivot_table(\n      values='val0', index='row', columns='col',\n      fill_value=0, aggfunc='sum')\n\n  col   col0  col1  col2  col3  col4\n  row\n  row0  0.77  1.21  0.00  0.86  0.65\n  row2  0.13  0.00  0.79  0.50  0.50\n  row3  0.00  0.31  0.00  1.09  0.00\n  row4  0.00  0.10  0.79  1.52  0.24\n \n \n pd.DataFrame.groupby \n   df.groupby(['row', 'col'])['val0'].sum().unstack(fill_value=0)\n \n \n pd.crosstab \n   pd.crosstab(\n      index=df['row'], columns=df['col'],\n      values=df['val0'], aggfunc='sum').fillna(0)\n \n \n \n \n Question 5 \n \n Can I do more that one aggregation at a time? \n \n Notice that for  pivot_table  and  crosstab  I needed to pass list of callables.  On the other hand,  groupby.agg  is able to take strings for a limited number of special functions.   groupby.agg  would also have taken the same callables we passed to the others, but it is often more efficient to leverage the string function names as there are efficiencies to be gained. \n \n pd.DataFrame.pivot_table \n   df.pivot_table(\n      values='val0', index='row', columns='col',\n      fill_value=0, aggfunc=[np.size, np.mean])\n\n       size                      mean\n  col  col0 col1 col2 col3 col4  col0   col1   col2   col3  col4\n  row\n  row0    1    2    0    1    1  0.77  0.605  0.000  0.860  0.65\n  row2    1    0    2    1    2  0.13  0.000  0.395  0.500  0.25\n  row3    0    1    0    2    0  0.00  0.310  0.000  0.545  0.00\n  row4    0    1    2    2    1  0.00  0.100  0.395  0.760  0.24\n \n \n pd.DataFrame.groupby \n   df.groupby(['row', 'col'])['val0'].agg(['size', 'mean']).unstack(fill_value=0)\n \n \n pd.crosstab \n   pd.crosstab(\n      index=df['row'], columns=df['col'],\n      values=df['val0'], aggfunc=[np.size, np.mean]).fillna(0, downcast='infer')\n \n \n \n \n Question 6 \n \n Can I aggregate over multiple value columns? \n \n \n pd.DataFrame.pivot_table  we pass  values=['val0', 'val1']  but we could've left that off completely \n   df.pivot_table(\n      values=['val0', 'val1'], index='row', columns='col',\n      fill_value=0, aggfunc='mean')\n\n        val0                             val1\n  col   col0   col1   col2   col3  col4  col0   col1  col2   col3  col4\n  row\n  row0  0.77  0.605  0.000  0.860  0.65  0.01  0.745  0.00  0.010  0.02\n  row2  0.13  0.000  0.395  0.500  0.25  0.45  0.000  0.34  0.440  0.79\n  row3  0.00  0.310  0.000  0.545  0.00  0.00  0.230  0.00  0.075  0.00\n  row4  0.00  0.100  0.395  0.760  0.24  0.00  0.070  0.42  0.300  0.46\n \n \n pd.DataFrame.groupby \n   df.groupby(['row', 'col'])['val0', 'val1'].mean().unstack(fill_value=0)\n \n \n \n \n Question 7 \n \n Can Subdivide by multiple columns? \n \n \n pd.DataFrame.pivot_table \n   df.pivot_table(\n      values='val0', index='row', columns=['item', 'col'],\n      fill_value=0, aggfunc='mean')\n\n  item item0             item1                         item2\n  col   col2  col3  col4  col0  col1  col2  col3  col4  col0   col1  col3  col4\n  row\n  row0  0.00  0.00  0.00  0.77  0.00  0.00  0.00  0.00  0.00  0.605  0.86  0.65\n  row2  0.35  0.00  0.37  0.00  0.00  0.44  0.00  0.00  0.13  0.000  0.50  0.13\n  row3  0.00  0.00  0.00  0.00  0.31  0.00  0.81  0.00  0.00  0.000  0.28  0.00\n  row4  0.15  0.64  0.00  0.00  0.10  0.64  0.88  0.24  0.00  0.000  0.00  0.00\n \n \n pd.DataFrame.groupby \n   df.groupby(\n      ['row', 'item', 'col']\n  )['val0'].mean().unstack(['item', 'col']).fillna(0).sort_index(1)\n \n \n \n \n Question 8 \n \n Can Subdivide by multiple columns? \n \n \n pd.DataFrame.pivot_table \n   df.pivot_table(\n      values='val0', index=['key', 'row'], columns=['item', 'col'],\n      fill_value=0, aggfunc='mean')\n\n  item      item0             item1                         item2\n  col        col2  col3  col4  col0  col1  col2  col3  col4  col0  col1  col3  col4\n  key  row\n  key0 row0  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.86  0.00\n       row2  0.00  0.00  0.37  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.50  0.00\n       row3  0.00  0.00  0.00  0.00  0.31  0.00  0.81  0.00  0.00  0.00  0.00  0.00\n       row4  0.15  0.64  0.00  0.00  0.00  0.00  0.00  0.24  0.00  0.00  0.00  0.00\n  key1 row0  0.00  0.00  0.00  0.77  0.00  0.00  0.00  0.00  0.00  0.81  0.00  0.65\n       row2  0.35  0.00  0.00  0.00  0.00  0.44  0.00  0.00  0.00  0.00  0.00  0.13\n       row3  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.28  0.00\n       row4  0.00  0.00  0.00  0.00  0.10  0.00  0.00  0.00  0.00  0.00  0.00  0.00\n  key2 row0  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.40  0.00  0.00\n       row2  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.13  0.00  0.00  0.00\n       row4  0.00  0.00  0.00  0.00  0.00  0.64  0.88  0.00  0.00  0.00  0.00  0.00\n \n \n pd.DataFrame.groupby \n   df.groupby(\n      ['key', 'row', 'item', 'col']\n  )['val0'].mean().unstack(['item', 'col']).fillna(0).sort_index(1)\n \n \n pd.DataFrame.set_index  because the set of keys are unique for both rows and columns \n   df.set_index(\n      ['key', 'row', 'item', 'col']\n  )['val0'].unstack(['item', 'col']).fillna(0).sort_index(1)\n \n \n \n \n Question 9 \n \n Can I aggregate the frequency in which the column and rows occur together, aka \"cross tabulation\"? \n \n \n pd.DataFrame.pivot_table \n   df.pivot_table(index='row', columns='col', fill_value=0, aggfunc='size')\n\n      col   col0  col1  col2  col3  col4\n  row\n  row0     1     2     0     1     1\n  row2     1     0     2     1     2\n  row3     0     1     0     2     0\n  row4     0     1     2     2     1\n \n \n pd.DataFrame.groupby \n   df.groupby(['row', 'col'])['val0'].size().unstack(fill_value=0)\n \n \n pd.crosstab \n   pd.crosstab(df['row'], df['col'])\n \n \n pd.factorize  +  np.bincount \n   # get integer factorization `i` and unique values `r`\n  # for column `'row'`\n  i, r = pd.factorize(df['row'].values)\n  # get integer factorization `j` and unique values `c`\n  # for column `'col'`\n  j, c = pd.factorize(df['col'].values)\n  # `n` will be the number of rows\n  # `m` will be the number of columns\n  n, m = r.size, c.size\n  # `i * m + j` is a clever way of counting the\n  # factorization bins assuming a flat array of length\n  # `n * m`.  Which is why we subsequently reshape as `(n, m)`\n  b = np.bincount(i * m + j, minlength=n * m).reshape(n, m)\n  # BTW, whenever I read this, I think 'Bean, Rice, and Cheese'\n  pd.DataFrame(b, r, c)\n\n        col3  col2  col0  col1  col4\n  row3     2     0     0     1     0\n  row2     1     2     1     0     2\n  row0     1     0     1     2     1\n  row4     2     2     0     1     1\n \n \n pd.get_dummies \n   pd.get_dummies(df['row']).T.dot(pd.get_dummies(df['col']))\n\n        col0  col1  col2  col3  col4\n  row0     1     2     0     1     1\n  row2     1     0     2     1     2\n  row3     0     1     0     2     0\n  row4     0     1     2     2     1\n \n \n \n \n Question 10 \n \n How do I convert a DataFrame from long to wide by pivoting on ONLY two\ncolumns? \n \n \n DataFrame.pivot \n The first step is to assign a number to each row - this number will be the row index of that value in the pivoted result. This is done using  GroupBy.cumcount : \n   df2.insert(0, 'count', df2.groupby('A').cumcount())\n  df2\n\n     count  A   B\n  0      0  a   0\n  1      1  a  11\n  2      2  a   2\n  3      3  a  11\n  4      0  b  10\n  5      1  b  10\n  6      2  b  14\n  7      0  c   7\n \n The second step is to use the newly created column as the index to call  DataFrame.pivot . \n   df2.pivot(*df2)\n  # df2.pivot(index='count', columns='A', values='B')\n\n  A         a     b    c\n  count\n  0       0.0  10.0  7.0\n  1      11.0  10.0  NaN\n  2       2.0  14.0  NaN\n  3      11.0   NaN  NaN\n \n \n DataFrame.pivot_table \n Whereas  DataFrame.pivot  only accepts columns,  DataFrame.pivot_table  also accepts arrays, so the  GroupBy.cumcount  can be passed directly as the  index  without creating an explicit column. \n   df2.pivot_table(index=df2.groupby('A').cumcount(), columns='A', values='B')\n\n  A         a     b    c\n  0       0.0  10.0  7.0\n  1      11.0  10.0  NaN\n  2       2.0  14.0  NaN\n  3      11.0   NaN  NaN\n \n \n \n \n Question 11 \n \n How do I flatten the multiple index to single index after  pivot \n \n If  columns  type  object  with string  join \n df.columns = df.columns.map('|'.join)\n \n else  format \n df.columns = df.columns.map('{0[0]}|{0[1]}'.format)\n \n    ", "date_posted": "2021-08-07 11:42:55Z", "upvote": "\r\n            415\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "13138364", "name": "tdy", "reputation_score": "28.3k"}, "answer_comments": [{"stack_answer_id": "47152692", "stack_answer_comment_id": "82623451", "comment_content": "Could you please consider extending ", "user_id": "None"}, {"stack_answer_id": "47152692", "stack_answer_comment_id": "102665493", "comment_content": "what happened with the answer to Question #10? I get ", "user_id": "None"}, {"stack_answer_id": "47152692", "stack_answer_comment_id": "107880395", "comment_content": "it is not necessary to insert the column in question 10, it can be passed directly as an argument in the pivot table", "user_id": "None"}, {"stack_answer_id": "47152692", "stack_answer_comment_id": "108269681", "comment_content": "@MonicaHeddneck I believe the references to ", "user_id": "None"}, {"stack_answer_id": "47152692", "stack_answer_comment_id": "124327698", "comment_content": "When I would want to pivot a DataFrame, my first question would not be \"Why do I get some error\", but rather: given some input and some desired pivoted output, what function do I need to call and which parameters do I need to pass to get that output? If you already know it's called \"pivot\", that probably isn't too difficult to figure out, but a basic example can still help and perhaps the bigger problem is when questions that just ask ", "user_id": "None"}]}, {"stack_answer_id": "62219652", "answer_content": "\r\n To extend  @piRSquared's answer  another version of  Question 10 \n\n Question 10.1 \n\n DataFrame: \n\n d = data = {'A': {0: 1, 1: 1, 2: 1, 3: 2, 4: 2, 5: 3, 6: 5},\n 'B': {0: 'a', 1: 'b', 2: 'c', 3: 'a', 4: 'b', 5: 'a', 6: 'c'}}\ndf = pd.DataFrame(d)\n\n   A  B\n0  1  a\n1  1  b\n2  1  c\n3  2  a\n4  2  b\n5  3  a\n6  5  c\n \n\n Output: \n\n    0     1     2\nA\n1  a     b     c\n2  a     b  None\n3  a  None  None\n5  c  None  None\n \n\n \n\n Using  df.groupby  and  pd.Series.tolist \n\n t = df.groupby('A')['B'].apply(list)\nout = pd.DataFrame(t.tolist(),index=t.index)\nout\n   0     1     2\nA\n1  a     b     c\n2  a     b  None\n3  a  None  None\n5  c  None  None\n \n\n Or \nA much better alternative using  pd.pivot_table  with  df.squeeze. \n\n t = df.pivot_table(index='A',values='B',aggfunc=list).squeeze()\nout = pd.DataFrame(t.tolist(),index=t.index)\n \n    ", "date_posted": "2020-06-05 20:59:49Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "12416453", "name": "Ch3steR", "reputation_score": "19.3k"}, "answer_comments": []}, {"stack_answer_id": "66237613", "answer_content": "\r\n To better understand how  pivot  works you can look at the  example  from Pandas documentation: \n \n df = pd.DataFrame({\n    'foo': ['one', 'one', 'one', 'two', 'two', 'two'],\n    'bar': ['A', 'B', 'C', 'A', 'B', 'C'],\n    'baz': [1, 2, 3, 4, 5, 6],\n    'zoo': ['x', 'y', 'z', 'q', 'w', 't']\n})\n \n Input Table: \n    foo bar  baz zoo\n0  one   A    1   x\n1  one   B    2   y\n2  one   C    3   z\n3  two   A    4   q\n4  two   B    5   w\n5  two   C    6   t\n \n Pivot : \n pd.pivot(\n    data=df,        \n    index='foo',    # Column to use to make new frame\u2019s index. If None, uses existing index.\n    columns='bar',  # Column to use to make new frame\u2019s columns.\n    values='baz'    # Column(s) to use for populating new frame\u2019s values.\n)\n \n Output table: \n bar  A  B  C\nfoo         \none  1  2  3\ntwo  4  5  6\n \n    ", "date_posted": "2021-02-17 07:42:14Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "8973620", "name": "Mykola Zotko", "reputation_score": "12.6k"}, "answer_comments": []}, {"stack_answer_id": "73060100", "answer_content": "\r\n You can use list of column names as  index ,  columns  and  values  arguments. \n rows, cols, vals, aggfuncs = ['row', 'key'], ['col', 'item'], ['val0', 'val1'], ['mean', 'sum']\n\ndf.groupby(rows+cols)[vals].agg(aggfuncs).unstack(cols)\n# equivalently,\ndf.pivot_table(vals, rows, cols, aggfuncs)\n\n\ndf.set_index(rows+cols)[vals].unstack(cols)\n# equivalently, \ndf.pivot(rows, cols, vals)\n \n You can also apply the insight from Question 10 to multi-column pivot operation as well. Simply append the auxiliary index from  groupby().cumcount()  to either  rows  or  cols  depending on how you want your result to be (appending it to  rows  makes the result \"long\", and appending it to  cols  makes it \"wide\"). Additionally, calling  droplevel().reset_index()  fixes the surplus and duplicate index issue. \n # for \"long\" result\ndf.assign(ix=df.groupby(rows+cols).cumcount()).pivot(rows+['ix'], cols, vals).droplevel(-1).reset_index()\n\n# for \"wide\" result\ndf.assign(ix=df.groupby(rows+cols).cumcount()).pivot(rows, cols+['ix'], vals).droplevel(-1, axis=1).reset_index()\n \n For example, the following doesn't work. \n df = pd.DataFrame({'A': [1, 1, 2], 'B': ['a', 'a', 'b'], 'C': range(3)})\ndf.pivot('A','B','C')\n \n But the following work: \n # long\n(\n    df.assign(ix=df.groupby(['A','B']).cumcount())\n    .pivot(['A','ix'], 'B', 'C')\n    .droplevel(-1).reset_index()\n)\n\nB  A    a    b\n0  1  0.0  NaN\n1  1  1.0  NaN\n2  2  NaN  2.0\n\n\n\n# wide\n(\n    df.assign(ix=df.groupby(['A','B']).cumcount())\n    .pivot('A', ['B', 'ix'], 'C')\n    .droplevel(-1, axis=1).reset_index()\n)\n\nB  A    a    a    b\n0  1  0.0  1.0  NaN\n1  2  NaN  NaN  2.0\n \n \n pivot_table()  with  aggfunc  results in aggregated data, which is very similar to a  groupby.agg() .  pivot()  is simply reshaping and/or stacking data (reminiscent of numpy reshape and stack methods), so naturally, it's related to their pandas cousins,  unstack()  and  stack() . \n In fact, if we check the  source code , internally, each method pair are the same. \n \n pivot_table = groupby + unstack \n pivot = set_index + unstack \n crosstab = pivot_table \n \n Using the setup in the OP: \n from numpy.core.defchararray import add\nnp.random.seed([3,1415])\nn = 20\n\ncols = np.array(['key', 'row', 'item', 'col'])\narr1 = (np.random.randint(5, size=(n, 4)) // [2, 1, 2, 1]).astype(str)\n\ndf = pd.DataFrame(add(cols, arr1), columns=cols).join(pd.DataFrame(np.random.rand(n, 2).round(2)).add_prefix('val'))\n\nrows, cols, vals, aggfuncs = ['row', 'key'], ['col', 'val1'], ['val0'], ['mean', 'sum']\n \n \n pivot_table()  aggregates the values and unstacks it. Specifically, it creates a single flat list out of index and columns, calls  groupby()  with this list as the grouper and aggregates using the passed aggregator methods (the default is  mean ). Then after aggregation, it calls  unstack()  by the list of columns. So internally,  pivot_table = groupby + unstack . Moreover, if  fill_value  is passed,  fillna()  is called. \n In other words, the method that produces  pv_1  is the same as the method that produces  gb_1  in the example below. \n \n \n pv_1 = df.pivot_table(index=rows, columns=cols, values=vals, aggfunc=aggfuncs, fill_value=0)\n# internal operation of `pivot_table()`\ngb_1 = df.groupby(rows+cols)[vals].agg(aggfuncs).unstack(cols).fillna(0, downcast=\"infer\")\npv_1.equals(gb_1) # True\n \n \n pivot()  creates a MultiIndex from the column values passed as index and columns, builds a MultiIndex DataFrame and calls  unstack()  by the list of columns. So internally,  pivot = set_index + unstack . \n In other words, all of the following are True: \n \n \n # if the entire df needs to be pivoted\npv_2 = df.pivot(index=rows, columns=cols)\n# internal operation of `pivot()`\nsu_2 = df.set_index(rows+cols).unstack(cols)\npv_2.equals(su_2) # True\n\n# if only subset of df.columns need to be considered for pivot, specify so\npv_3 = df.pivot(index=rows, columns=cols, values=vals)\nsu_3 = df.set_index(rows+cols)[vals].unstack(cols)\npv_3.equals(su_3) # True\n\n# this is the precise method used internally (building a new DF seems to be faster than set_index of an existing one)\npv_4 = df.pivot(index=rows, columns=cols, values=vals)\nsu_4 = pd.DataFrame(df[vals].values, index=pd.MultiIndex.from_arrays([df[c] for c in rows+cols]), columns=vals).unstack(cols)\npv_4.equals(su_4) # True\n \n \n crosstab()  calls  pivot_table() , i.e.,  crosstab = pivot_table . Specifically, it builds a DataFrame out of the passed arrays of values, filters it by the common indices and calls  pivot_table() . It's more limited than  pivot_table()  because it only allows a one-dimensional array-like as  values , unlike  pivot_table()  that can have multiple columns as  values . \n In other words, the following is True. \n \n \n indexes, columns, values = [df[r] for r in rows], [df[c] for c in cols], next(df[v] for v in vals)\n# crosstab\nct_5 = pd.crosstab(indexes, columns, values, aggfunc=aggfuncs)\n# internal operation (abbreviated)\nfrom functools import reduce\ndata = pd.DataFrame({f'row_{i}': r for i, r in enumerate(indexes)} | {f'col_{i}': c for i, c in enumerate(columns)} | {'v': values}, \n                    index = reduce(lambda x, y: x.intersection(y.index), indexes[1:]+columns, indexes[0].index)\n                   )\npv_5 = data.pivot_table('v', [k for k in data if k[:4]=='row_'], [k for k in data if k[:4]=='col_'], aggfuncs)\nct_5.equals(pv_5) # True\n \n    ", "date_posted": "2022-07-21 02:41:29Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "19123103", "name": "not a robot", "reputation_score": "4,023"}, "answer_comments": []}], "user": {"stack_user_id": "2336654", "name": "piRSquared", "reputation_score": "270k"}, "question_comments": []},
{"stack_question_id": "2612802", "question_title": "How do I clone a list so that it doesn't change unexpectedly after assignment?", "question_content": "\r\n                While using new_list = my_list, any modifications to new_list changes my_list every time. Why is this, and how can I clone or copy the list to prevent it?\r\n", "question_url": "/questions/2612802/how-do-i-clone-a-list-so-that-it-doesnt-change-unexpectedly-after-assignment", "date_posted": "Apr 10, 2010 at 8:49", "upvote": "3", "view": "2", "tags": ["python", "list", "reference", "copy", "clone"], "answers_count": "2", "answers": [{"stack_answer_id": "2612815", "answer_content": "\r\n new_list = my_list  doesn't actually create a second list. The assignment just copies the reference to the list, not the actual list, so both  new_list  and  my_list  refer to the same list after the assignment. \n To actually copy the list, you have several options: \n \n You can use the builtin  list.copy()  method (available since Python 3.3): \n new_list = old_list.copy()\n \n \n You can slice it: \n new_list = old_list[:]\n \n Alex Martelli 's opinion (at least  back in 2007 ) about this is, that  it is a weird syntax and it does not make sense to use it ever . ;) (In his opinion, the next one is more readable). \n \n You can use the built in  list()  constructor: \n new_list = list(old_list)\n \n \n You can use generic  copy.copy() : \n import copy\nnew_list = copy.copy(old_list)\n \n This is a little slower than  list()  because it has to find out the datatype of  old_list  first. \n \n If you need to copy the elements of the list as well, use generic  copy.deepcopy() : \n import copy\nnew_list = copy.deepcopy(old_list)\n \n Obviously the slowest and most memory-needing method, but sometimes unavoidable. This operates recursively; it will handle any number of levels of nested lists (or other containers). \n \n \n Example: \n import copy\n\nclass Foo(object):\n    def __init__(self, val):\n         self.val = val\n\n    def __repr__(self):\n        return f'Foo({self.val!r})'\n\nfoo = Foo(1)\n\na = ['foo', foo]\nb = a.copy()\nc = a[:]\nd = list(a)\ne = copy.copy(a)\nf = copy.deepcopy(a)\n\n# edit orignal list and instance \na.append('baz')\nfoo.val = 5\n\nprint(f'original: {a}\\nlist.copy(): {b}\\nslice: {c}\\nlist(): {d}\\ncopy: {e}\\ndeepcopy: {f}')\n \n Result: \n original: ['foo', Foo(5), 'baz']\nlist.copy(): ['foo', Foo(5)]\nslice: ['foo', Foo(5)]\nlist(): ['foo', Foo(5)]\ncopy: ['foo', Foo(5)]\ndeepcopy: ['foo', Foo(1)]\n \n    ", "date_posted": "2022-08-16 00:48:58Z", "upvote": "\r\n            3875\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "4518341", "name": "wjandrea", "reputation_score": "24.1k"}, "answer_comments": [{"stack_answer_id": "2612815", "stack_answer_comment_id": "115618926", "comment_content": "As @Georgy points out correctly in the answer below, any changes to the new_list values will also change the values in my_list. So actually the copy.deepcopy() method is the only real copy without reference to the original list and it's values.", "user_id": "None"}, {"stack_answer_id": "2612815", "stack_answer_comment_id": "129567928", "comment_content": "@moojen If ", "user_id": "None"}, {"stack_answer_id": "2612815", "stack_answer_comment_id": "129602871", "comment_content": "@wjandrea Why copy a list of immutable objects?", "user_id": "None"}, {"stack_answer_id": "2612815", "stack_answer_comment_id": "129605566", "comment_content": "@moojen Because the list itself is mutable, and a new assignment only creates a reference. E.g. ", "user_id": "None"}]}, {"stack_answer_id": "2612990", "answer_content": "\r\n Felix already provided an excellent answer, but I thought I'd do a speed comparison of the various methods: \n \n 10.59 sec (105.9 \u00b5s/itn) -   copy.deepcopy(old_list) \n 10.16 sec (101.6 \u00b5s/itn) - pure Python  Copy()  method copying classes with deepcopy \n 1.488 sec (14.88 \u00b5s/itn) - pure Python  Copy()  method not copying classes (only dicts/lists/tuples) \n 0.325 sec (3.25 \u00b5s/itn) -  for item in old_list: new_list.append(item) \n 0.217 sec (2.17 \u00b5s/itn) -  [i for i in old_list]  (a  list comprehension ) \n 0.186 sec (1.86 \u00b5s/itn) -  copy.copy(old_list) \n 0.075 sec (0.75 \u00b5s/itn) -  list(old_list) \n 0.053 sec (0.53 \u00b5s/itn) -  new_list = []; new_list.extend(old_list) \n 0.039 sec (0.39 \u00b5s/itn) -  old_list[:]  ( list slicing ) \n \n So the fastest is list slicing. But be aware that  copy.copy() ,  list[:]  and  list(list) , unlike  copy.deepcopy()  and the python version don't copy any lists, dictionaries and class instances in the list, so if the originals change, they will change in the copied list too and vice versa. \n (Here's the script if anyone's interested or wants to raise any issues:) \n from copy import deepcopy\n\nclass old_class:\n    def __init__(self):\n        self.blah = 'blah'\n\nclass new_class(object):\n    def __init__(self):\n        self.blah = 'blah'\n\ndignore = {str: None, unicode: None, int: None, type(None): None}\n\ndef Copy(obj, use_deepcopy=True):\n    t = type(obj)\n\n    if t in (list, tuple):\n        if t == tuple:\n            # Convert to a list if a tuple to\n            # allow assigning to when copying\n            is_tuple = True\n            obj = list(obj)\n        else:\n            # Otherwise just do a quick slice copy\n            obj = obj[:]\n            is_tuple = False\n\n        # Copy each item recursively\n        for x in xrange(len(obj)):\n            if type(obj[x]) in dignore:\n                continue\n            obj[x] = Copy(obj[x], use_deepcopy)\n\n        if is_tuple:\n            # Convert back into a tuple again\n            obj = tuple(obj)\n\n    elif t == dict:\n        # Use the fast shallow dict copy() method and copy any\n        # values which aren't immutable (like lists, dicts etc)\n        obj = obj.copy()\n        for k in obj:\n            if type(obj[k]) in dignore:\n                continue\n            obj[k] = Copy(obj[k], use_deepcopy)\n\n    elif t in dignore:\n        # Numeric or string/unicode?\n        # It's immutable, so ignore it!\n        pass\n\n    elif use_deepcopy:\n        obj = deepcopy(obj)\n    return obj\n\nif __name__ == '__main__':\n    import copy\n    from time import time\n\n    num_times = 100000\n    L = [None, 'blah', 1, 543.4532,\n         ['foo'], ('bar',), {'blah': 'blah'},\n         old_class(), new_class()]\n\n    t = time()\n    for i in xrange(num_times):\n        Copy(L)\n    print 'Custom Copy:', time()-t\n\n    t = time()\n    for i in xrange(num_times):\n        Copy(L, use_deepcopy=False)\n    print 'Custom Copy Only Copying Lists/Tuples/Dicts (no classes):', time()-t\n\n    t = time()\n    for i in xrange(num_times):\n        copy.copy(L)\n    print 'copy.copy:', time()-t\n\n    t = time()\n    for i in xrange(num_times):\n        copy.deepcopy(L)\n    print 'copy.deepcopy:', time()-t\n\n    t = time()\n    for i in xrange(num_times):\n        L[:]\n    print 'list slicing [:]:', time()-t\n\n    t = time()\n    for i in xrange(num_times):\n        list(L)\n    print 'list(L):', time()-t\n\n    t = time()\n    for i in xrange(num_times):\n        [i for i in L]\n    print 'list expression(L):', time()-t\n\n    t = time()\n    for i in xrange(num_times):\n        a = []\n        a.extend(L)\n    print 'list extend:', time()-t\n\n    t = time()\n    for i in xrange(num_times):\n        a = []\n        for y in L:\n            a.append(y)\n    print 'list append:', time()-t\n\n    t = time()\n    for i in xrange(num_times):\n        a = []\n        a.extend(i for i in L)\n    print 'generator expression extend:', time()-t\n \n    ", "date_posted": "2021-05-11 21:36:34Z", "upvote": "\r\n            732\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "2612990", "stack_answer_comment_id": "119115083", "comment_content": "Does it mean that append and list comprehension are the best options?", "user_id": "None"}, {"stack_answer_id": "2612990", "stack_answer_comment_id": "124242121", "comment_content": "I keep on coming back to this answer to make sure that I am using the most efficient method. What is the easiest way to test this? Or is there a database with all of the best ways to minimise run time?", "user_id": "None"}, {"stack_answer_id": "2612990", "stack_answer_comment_id": "129567914", "comment_content": "These numbers might be outdated. I tried running ", "user_id": "None"}]}, {"stack_answer_id": "17810305", "answer_content": "\r\n I've  been told  that Python 3.3+  adds the  list.copy()  method, which should be as fast as slicing: \n newlist = old_list.copy()\n \n    ", "date_posted": "2021-05-11 21:37:30Z", "upvote": "\r\n            178\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "17810305", "stack_answer_comment_id": "91949096", "comment_content": "Yes, and as per docs ", "user_id": "None"}, {"stack_answer_id": "17810305", "stack_answer_comment_id": "108624099", "comment_content": "Actually it seems that currently, ", "user_id": "None"}, {"stack_answer_id": "17810305", "stack_answer_comment_id": "115053799", "comment_content": "@loved.by.Jesus: Yeah, they ", "user_id": "None"}, {"stack_answer_id": "17810305", "stack_answer_comment_id": "115053871", "comment_content": "Of course, they're working on ", "user_id": "None"}]}, {"stack_answer_id": "26562235", "answer_content": "\r\n \n   What are the options to clone or copy a list in Python? \n \n\n In Python 3, a shallow copy can be made with: \n\n a_copy = a_list.copy()\n \n\n In Python 2 and 3, you can get a shallow copy with a full slice of the original: \n\n a_copy = a_list[:]\n \n\n Explanation \n\n There are two semantic ways to copy a list. A shallow copy creates a new list of the same objects, a deep copy creates a new list containing new equivalent objects. \n\n Shallow list copy \n\n A shallow copy only copies the list itself, which is a container of references to the objects in the list. If the objects contained themselves are mutable and one is changed, the change will be reflected in both lists.  \n\n There are different ways to do this in Python 2 and 3. The Python 2 ways will also work in Python 3. \n\n Python 2 \n\n In Python 2, the idiomatic way of making a shallow copy of a list is with a complete slice of the original: \n\n a_copy = a_list[:]\n \n\n You can also accomplish the same thing by passing the list through the list constructor,  \n\n a_copy = list(a_list)\n \n\n but using the constructor is less efficient: \n\n >>> timeit\n>>> l = range(20)\n>>> min(timeit.repeat(lambda: l[:]))\n0.30504298210144043\n>>> min(timeit.repeat(lambda: list(l)))\n0.40698814392089844\n \n\n Python 3 \n\n In Python 3, lists get the  list.copy  method: \n\n a_copy = a_list.copy()\n \n\n In Python 3.5: \n\n >>> import timeit\n>>> l = list(range(20))\n>>> min(timeit.repeat(lambda: l[:]))\n0.38448613602668047\n>>> min(timeit.repeat(lambda: list(l)))\n0.6309100328944623\n>>> min(timeit.repeat(lambda: l.copy()))\n0.38122922903858125\n \n\n Making another pointer does  not  make a copy \n\n \n   Using new_list = my_list then modifies new_list every time my_list changes. Why is this? \n \n\n my_list  is just a name that points to the actual list in memory. When you say  new_list = my_list  you're not making a copy, you're just adding another name that points at that original list in memory. We can have similar issues when we make copies of lists.  \n\n >>> l = [[], [], []]\n>>> l_copy = l[:]\n>>> l_copy\n[[], [], []]\n>>> l_copy[0].append('foo')\n>>> l_copy\n[['foo'], [], []]\n>>> l\n[['foo'], [], []]\n \n\n The list is just an array of pointers to the contents, so a shallow copy just copies the pointers, and so you have two different lists, but they have the same contents. To make copies of the contents, you need a deep copy. \n\n Deep copies \n\n To make a  deep copy of a list, in Python 2 or 3, use  deepcopy  in the  copy  module : \n\n import copy\na_deep_copy = copy.deepcopy(a_list)\n \n\n To demonstrate how this allows us to make new sub-lists: \n\n >>> import copy\n>>> l\n[['foo'], [], []]\n>>> l_deep_copy = copy.deepcopy(l)\n>>> l_deep_copy[0].pop()\n'foo'\n>>> l_deep_copy\n[[], [], []]\n>>> l\n[['foo'], [], []]\n \n\n And so we see that the deep copied list is an entirely different list from the original. You could roll your own function - but don't. You're likely to create bugs you otherwise wouldn't have by using the standard library's deepcopy function. \n\n Don't use  eval \n\n You may see this used as a way to deepcopy, but don't do it: \n\n problematic_deep_copy = eval(repr(a_list))\n \n\n \n It's dangerous, particularly if you're evaluating something from a source you don't trust. \n It's not reliable, if a subelement you're copying doesn't have a representation that can be eval'd to reproduce an equivalent element. \n It's also less performant.  \n \n\n In 64 bit Python 2.7: \n\n >>> import timeit\n>>> import copy\n>>> l = range(10)\n>>> min(timeit.repeat(lambda: copy.deepcopy(l)))\n27.55826997756958\n>>> min(timeit.repeat(lambda: eval(repr(l))))\n29.04534101486206\n \n\n on 64 bit Python 3.5: \n\n >>> import timeit\n>>> import copy\n>>> l = list(range(10))\n>>> min(timeit.repeat(lambda: copy.deepcopy(l)))\n16.84255409205798\n>>> min(timeit.repeat(lambda: eval(repr(l))))\n34.813894678023644\n \n    ", "date_posted": "2018-01-09 15:33:11Z", "upvote": "\r\n            148\r\n        ", "accepted": "No", "user": {"stack_user_id": "541136", "name": "Russia Must Remove Putin", "reputation_score": "347k"}, "answer_comments": [{"stack_answer_id": "26562235", "stack_answer_comment_id": "95089106", "comment_content": "You don't need a deepcopy if the list is 2D. If it is a list of lists, and those lists don't have lists inside of them, you can use a for loop. Presently, I am using   ", "user_id": "None"}]}, {"stack_answer_id": "47258728", "answer_content": "\r\n Let's start from the beginning and explore this question. \n So let's suppose you have two lists: \n list_1 = ['01', '98']\nlist_2 = [['01', '98']]\n \n And we have to copy both lists, now starting from the first list: \n So first let's try by setting the variable  copy  to our original list,  list_1 : \n copy = list_1\n \n Now if you are thinking copy copied the  list_1 , then you are wrong. The  id  function can show us if two variables can point to the same object. Let's try this: \n print(id(copy))\nprint(id(list_1))\n \n The output is: \n 4329485320\n4329485320\n \n Both variables are the exact same argument. Are you surprised? \n So as we know, Python doesn't store anything in a variable, Variables are just referencing to the object and object store the value. Here object is a  list  but we created two references to that same object by two different variable names. This means that both variables are pointing to the same object, just with different names. \n When you do  copy = list_1 , it is actually doing: \n \n Here in the image  list_1  and  copy  are two variable names, but the object is same for both variable which is  list . \n So if you try to modify copied list then it will modify the original list too because the list is only one there, you will modify that list no matter you do from the copied list or from the original list: \n copy[0] = \"modify\"\n\nprint(copy)\nprint(list_1)\n \n Output: \n ['modify', '98']\n['modify', '98']\n \n So it modified the original list: \n Now let's move onto a Pythonic method for copying lists. \n copy_1 = list_1[:]\n \n This method fixes the first issue we had: \n print(id(copy_1))\nprint(id(list_1))\n\n4338792136\n4338791432\n \n So as we can see our both list having different id and it means that both variables are pointing to different objects. So what actually going on here is: \n \n Now let's try to modify the list and let's see if we still face the previous problem: \n copy_1[0] = \"modify\"\n\nprint(list_1)\nprint(copy_1)\n \n The output is: \n ['01', '98']\n['modify', '98']\n \n As you can see, it only modified the copied list. That means it worked. \n Do you think we're done? No. Let's try to copy our nested list. \n copy_2 = list_2[:]\n \n list_2  should reference to another object which is copy of  list_2 . Let's check: \n print(id((list_2)), id(copy_2))\n \n We get the output: \n 4330403592 4330403528\n \n Now we can assume both lists are pointing different object, so now let's try to modify it and let's see it is giving what we want: \n copy_2[0][1] = \"modify\"\n\nprint(list_2, copy_2)\n \n This gives us the output: \n [['01', 'modify']] [['01', 'modify']]\n \n This may seem a little bit confusing, because the same method we previously used worked. Let's try to understand this. \n When you do: \n copy_2 = list_2[:]\n \n You're only copying the outer list, not the inside list. We can use the  id  function once again to check this. \n print(id(copy_2[0]))\nprint(id(list_2[0]))\n \n The output is: \n 4329485832\n4329485832\n \n When we do  copy_2 = list_2[:] , this happens: \n \n It creates the copy of list, but only outer list copy, not the nested list copy. The nested list is same for both variable, so if you try to modify the nested list then it will modify the original list too as the nested list object is same for both lists. \n What is the solution? The solution is the  deepcopy  function. \n from copy import deepcopy\ndeep = deepcopy(list_2)\n \n Let's check this: \n print(id((list_2)), id(deep))\n\n4322146056 4322148040\n \n Both outer lists have different IDs. Let's try this on the inner nested lists. \n print(id(deep[0]))\nprint(id(list_2[0]))\n \n The output is: \n 4322145992\n4322145800\n \n As you can see both IDs are different, meaning we can assume that both nested lists are pointing different object now. \n This means when you do  deep = deepcopy(list_2)  what actually happens: \n \n Both nested lists are pointing different object and they have separate copy of nested list now. \n Now let's try to modify the nested list and see if it solved the previous issue or not: \n deep[0][1] = \"modify\"\nprint(list_2, deep)\n \n It outputs: \n [['01', '98']] [['01', 'modify']]\n \n As you can see, it didn't modify the original nested list, it only modified the copied list. \n    ", "date_posted": "2021-05-11 21:53:58Z", "upvote": "\r\n            71\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "27091494", "answer_content": "\r\n There are many answers already that tell you how to make a proper copy, but none of them say why your original 'copy' failed.  \n\n Python doesn't store values in variables; it binds names to objects. Your original assignment took the object referred to by  my_list  and bound it to  new_list  as well. No matter which name you use there is still only one list, so changes made when referring to it as  my_list  will persist when referring to it as  new_list . Each of the other answers to this question give you different ways of creating a new object to bind to  new_list .  \n\n Each element of a list acts like a name, in that each element binds non-exclusively to an object. A shallow copy creates a new list whose elements bind to the same objects as before. \n\n new_list = list(my_list)  # or my_list[:], but I prefer this syntax\n# is simply a shorter way of:\nnew_list = [element for element in my_list]\n \n\n To take your list copy one step further, copy each object that your list refers to, and bind those element copies to a new list.  \n\n import copy  \n# each element must have __copy__ defined for this...\nnew_list = [copy.copy(element) for element in my_list]\n \n\n This is not yet a deep copy, because each element of a list may refer to other objects, just like the list is bound to its elements. To recursively copy every element in the list, and then each other object referred to by each element, and so on: perform a deep copy.  \n\n import copy\n# each element must have __deepcopy__ defined for this...\nnew_list = copy.deepcopy(my_list)\n \n\n See  the documentation  for more information about corner cases in copying. \n    ", "date_posted": "2020-06-05 16:01:12Z", "upvote": "\r\n            65\r\n        ", "accepted": "No", "user": {"stack_user_id": "894381", "name": "jack", "reputation_score": "1,984"}, "answer_comments": []}, {"stack_answer_id": "2612808", "answer_content": "\r\n Use  thing[:] \n\n >>> a = [1,2]\n>>> b = a[:]\n>>> a += [3]\n>>> a\n[1, 2, 3]\n>>> b\n[1, 2]\n>>> \n \n    ", "date_posted": "2010-04-10 08:53:06Z", "upvote": "\r\n            48\r\n        ", "accepted": "No", "user": {"stack_user_id": "90025", "name": "Paul Tarjan", "reputation_score": "47.3k"}, "answer_comments": []}, {"stack_answer_id": "43220129", "answer_content": "\r\n Python 3.6 Timings \n Here are the timing results using Python 3.6.8. Keep in mind these times are relative to one another, not absolute. \n I stuck to only doing shallow copies, and also added some new methods that weren't possible in Python\u00a02, such as  list.copy()  (the Python\u00a03  slice equivalent ) and two forms of  list unpacking  ( *new_list, = list  and  new_list = [*list] ): \n METHOD                TIME TAKEN\nb = [*a]               2.75180600000021\nb = a * 1              3.50215399999990\nb = a[:]               3.78278899999986  # Python 2 winner (see above)\nb = a.copy()           4.20556500000020  # Python 3 \"slice equivalent\" (see above)\nb = []; b.extend(a)    4.68069800000012\nb = a[0:len(a)]        6.84498999999959\n*b, = a                7.54031799999984\nb = list(a)            7.75815899999997\nb = [i for i in a]    18.4886440000000\nb = copy.copy(a)      18.8254879999999\nb = []\nfor item in a:\n  b.append(item)      35.4729199999997\n \n We can see the Python 2 winner still does well, but doesn't edge out Python 3  list.copy()  by much, especially considering the superior readability of the latter. \n The dark horse is the unpacking and repacking method ( b = [*a] ), which is ~25% faster than raw slicing, and more than twice as fast as the other unpacking method ( *b, = a ). \n b = a * 1  also does surprisingly well. \n Note that these methods do  not  output equivalent results for any input other than lists.  They all work for sliceable objects, a few work for any iterable, but only  copy.copy()  works for more general Python objects. \n \n Here is the testing code for interested parties ( Template from here ): \n import timeit\n\nCOUNT = 50000000\nprint(\"Array duplicating. Tests run\", COUNT, \"times\")\nsetup = 'a = [0,1,2,3,4,5,6,7,8,9]; import copy'\n\nprint(\"b = list(a)\\t\\t\", timeit.timeit(stmt='b = list(a)', setup=setup, number=COUNT))\nprint(\"b = copy.copy(a)\\t\", timeit.timeit(stmt='b = copy.copy(a)', setup=setup, number=COUNT))\nprint(\"b = a.copy()\\t\\t\", timeit.timeit(stmt='b = a.copy()', setup=setup, number=COUNT))\nprint(\"b = a[:]\\t\\t\", timeit.timeit(stmt='b = a[:]', setup=setup, number=COUNT))\nprint(\"b = a[0:len(a)]\\t\\t\", timeit.timeit(stmt='b = a[0:len(a)]', setup=setup, number=COUNT))\nprint(\"*b, = a\\t\\t\\t\", timeit.timeit(stmt='*b, = a', setup=setup, number=COUNT))\nprint(\"b = []; b.extend(a)\\t\", timeit.timeit(stmt='b = []; b.extend(a)', setup=setup, number=COUNT))\nprint(\"b = []; for item in a: b.append(item)\\t\", timeit.timeit(stmt='b = []\\nfor item in a:  b.append(item)', setup=setup, number=COUNT))\nprint(\"b = [i for i in a]\\t\", timeit.timeit(stmt='b = [i for i in a]', setup=setup, number=COUNT))\nprint(\"b = [*a]\\t\\t\", timeit.timeit(stmt='b = [*a]', setup=setup, number=COUNT))\nprint(\"b = a * 1\\t\\t\", timeit.timeit(stmt='b = a * 1', setup=setup, number=COUNT))\n \n    ", "date_posted": "2021-05-11 21:40:12Z", "upvote": "\r\n            42\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "43220129", "stack_answer_comment_id": "106994593", "comment_content": "Can confirm still a similar story on 3.8 ", "user_id": "None"}, {"stack_answer_id": "43220129", "stack_answer_comment_id": "114824554", "comment_content": "Some of these timing comparisons aren't particularly meaningful when copying such tiny lists. It would be more informative to test with a range of list lengths (including some very large ones).", "user_id": "None"}, {"stack_answer_id": "43220129", "stack_answer_comment_id": "119298412", "comment_content": "The timing numbers ought to rounded to the appropriate number of significant digits. 15 significant digits do not make any sense.", "user_id": "None"}, {"stack_answer_id": "43220129", "stack_answer_comment_id": "119447900", "comment_content": "I've essentially just pasted the raw output of the timing code here. Seems like your gripe is more about how ", "user_id": "None"}, {"stack_answer_id": "43220129", "stack_answer_comment_id": "128722434", "comment_content": "Is the ", "user_id": "None"}]}, {"stack_answer_id": "2612810", "answer_content": "\r\n Python's idiom for doing this is  newList = oldList[:] \n    ", "date_posted": "2010-04-10 08:53:19Z", "upvote": "\r\n            36\r\n        ", "accepted": "No", "user": {"stack_user_id": "260584", "name": "erisco", "reputation_score": "13.9k"}, "answer_comments": []}, {"stack_answer_id": "31332158", "answer_content": "\r\n All of the other contributors gave  great  answers, which work when you have a single dimension (leveled) list, however of the methods mentioned so far, only  copy.deepcopy()  works to clone/copy a list and not have it point to the nested  list  objects when you are working with multidimensional, nested lists (list of lists). While  Felix Kling  refers to it in his answer, there is a little bit more to the issue and possibly a workaround using built-ins that might prove a faster alternative to  deepcopy . \n While  new_list = old_list[:] ,  copy.copy(old_list)'  and for Py3k  old_list.copy()  work for single-leveled lists, they revert to pointing at the  list  objects nested within the  old_list  and the  new_list , and changes to one of the  list  objects are perpetuated in the other. \n Edit: New information brought to light \n \n As was pointed out by both  Aaron Hall  and  PM 2Ring   using  eval()  is not only a bad idea, it is also much slower than  copy.deepcopy() . \n This means that for multidimensional lists, the only option is  copy.deepcopy() . With that being said, it really isn't an option as the performance goes way south when you try to use it on a moderately sized multidimensional array.  I tried to  timeit  using a 42x42 array, not unheard of or even that large for bioinformatics applications, and I gave up on waiting for a response and just started typing my edit to this post. \n It would seem that the only real option then is to initialize multiple lists and work on them independently. If anyone has any other suggestions, for how to handle multidimensional list copying, it would be appreciated. \n \n As others have stated, there   are significant  performance issues using the  copy  module and  copy.deepcopy   for multidimensional lists . \n    ", "date_posted": "2020-06-20 09:12:55Z", "upvote": "\r\n            21\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": [{"stack_answer_id": "31332158", "stack_answer_comment_id": "50671649", "comment_content": "This won't always work, since there's no guarantee that the string returned by ", "user_id": "None"}, {"stack_answer_id": "31332158", "stack_answer_comment_id": "50675773", "comment_content": "Fair point. Though I think that Batchelder's point is that the having the ", "user_id": "None"}, {"stack_answer_id": "31332158", "stack_answer_comment_id": "50676956", "comment_content": "As @AaronHall has pointed out, there is likely a significant performance issue to using ", "user_id": "None"}]}, {"stack_answer_id": "48980683", "answer_content": "\r\n It surprises me that this hasn't been mentioned yet, so for the sake of completeness... \n\n You can perform list unpacking with the \"splat operator\":  * , which will also copy elements of your list. \n\n old_list = [1, 2, 3]\n\nnew_list = [*old_list]\n\nnew_list.append(4)\nold_list == [1, 2, 3]\nnew_list == [1, 2, 3, 4]\n \n\n The obvious downside to this method is that it is only available in Python 3.5+. \n\n Timing wise though, this appears to perform better than other common methods. \n\n x = [random.random() for _ in range(1000)]\n\n%timeit a = list(x)\n%timeit a = x.copy()\n%timeit a = x[:]\n\n%timeit a = [*x]\n\n#: 2.47 \u00b5s \u00b1 38.1 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n#: 2.47 \u00b5s \u00b1 54.6 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n#: 2.39 \u00b5s \u00b1 58.2 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n\n#: 2.22 \u00b5s \u00b1 43.2 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n \n    ", "date_posted": "2018-02-26 02:33:47Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "1112586", "name": "SCB", "reputation_score": "5,501"}, "answer_comments": [{"stack_answer_id": "48980683", "stack_answer_comment_id": "91902477", "comment_content": "How does this method behave when modifying copies?", "user_id": "None"}, {"stack_answer_id": "48980683", "stack_answer_comment_id": "91940819", "comment_content": "@not2qubit do you mean appending to or editing elements of the new list. In the example ", "user_id": "None"}]}, {"stack_answer_id": "44768652", "answer_content": "\r\n new_list = my_list[:]\n \n new_list = my_list \n Try to understand this. Let's say that  my_list  is in the heap memory at location X, i.e.,  my_list  is pointing to the X. Now by assigning  new_list = my_list  you're letting  new_list  point to the X. This is known as a  shallow copy . \n Now if you assign  new_list = my_list[:] , you're simply copying each object of  my_list  to  new_list . This is known as a  deep copy . \n The  other  ways you can do this are: \n \n \n new_list = list(old_list)\n \n \n \n import copy\nnew_list = copy.deepcopy(old_list)\n \n \n \n    ", "date_posted": "2021-11-19 17:44:52Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "1871033", "name": "CherryDT", "reputation_score": "21.9k"}, "answer_comments": [{"stack_answer_id": "44768652", "stack_answer_comment_id": "125710533", "comment_content": "Technically, ", "user_id": "None"}]}, {"stack_answer_id": "47050612", "answer_content": "\r\n A very simple approach independent of python version was missing in already-given answers which you can use most of the time (at least I do): \n new_list = my_list * 1       # Solution 1 when you are not using nested lists\n \n However,  if   my_list  contains other containers (for example, nested lists) you must use  deepcopy  as others suggested in the answers above from the copy library. For example: \n import copy\nnew_list = copy.deepcopy(my_list)   # Solution 2 when you are using nested lists\n \n . Bonus : If you don't want to copy elements use (AKA shallow copy): \n new_list = my_list[:]\n \n \n Let's understand difference between solution #1 and solution #2 \n >>> a = range(5)\n>>> b = a*1\n>>> a,b\n([0, 1, 2, 3, 4], [0, 1, 2, 3, 4])\n>>> a[2] = 55\n>>> a,b\n([0, 1, 55, 3, 4], [0, 1, 2, 3, 4])\n \n As you can see, solution #1 worked perfectly when we were not using the nested lists. Let's check what will happen when we apply solution #1 to nested lists. \n >>> from copy import deepcopy\n>>> a = [range(i,i+4) for i in range(3)]\n>>> a\n[[0, 1, 2, 3], [1, 2, 3, 4], [2, 3, 4, 5]]\n>>> b = a*1\n>>> c = deepcopy(a)\n>>> for i in (a, b, c): print i\n[[0, 1, 2, 3], [1, 2, 3, 4], [2, 3, 4, 5]]\n[[0, 1, 2, 3], [1, 2, 3, 4], [2, 3, 4, 5]]\n[[0, 1, 2, 3], [1, 2, 3, 4], [2, 3, 4, 5]]\n>>> a[2].append('99')\n>>> for i in (a, b, c): print i\n[[0, 1, 2, 3], [1, 2, 3, 4], [2, 3, 4, 5, 99]]\n[[0, 1, 2, 3], [1, 2, 3, 4], [2, 3, 4, 5, 99]]   # Solution #1 didn't work in nested list\n[[0, 1, 2, 3], [1, 2, 3, 4], [2, 3, 4, 5]]       # Solution #2 - DeepCopy worked in nested list\n \n    ", "date_posted": "2021-05-11 21:48:59Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "57838754", "answer_content": "\r\n I wanted to post something a bit different than some of the other answers. Even though this is most likely not the most understandable, or fastest option, it provides a bit of an inside view of how deep copy works, as well as being another alternative option for deep copying. It doesn't really matter if my function has bugs, since the point of this is to show a way to copy objects like the question answers, but also to use this as a point to explain how deepcopy works at its core. \n At the core of any deep copy function is way to make a shallow copy. How? Simple. Any deep copy function only duplicates the containers of immutable objects. When you deepcopy a nested list, you are only duplicating the outer lists, not the mutable objects inside of the lists. You are only duplicating the containers. The same works for classes, too. When you deepcopy a class, you deepcopy all of its mutable attributes. So, how? How come you only have to copy the containers, like lists, dicts, tuples, iters, classes, and class instances? \n It's simple. A mutable object can't really be duplicated. It can never be changed, so it is only a single value. That means you never have to duplicate strings, numbers, bools, or any of those. But how would you duplicate the containers? Simple. You make just initialize a new container with all of the values. Deepcopy relies on recursion. It duplicates all the containers, even ones with containers inside of them, until no containers are left. A container is an immutable object. \n Once you know that, completely duplicating an object without any references is pretty easy. Here's a function for deepcopying basic data-types (wouldn't work for custom classes but you could always add that) \n def deepcopy(x):\n  immutables = (str, int, bool, float)\n  mutables = (list, dict, tuple)\n  if isinstance(x, immutables):\n    return x\n  elif isinstance(x, mutables):\n    if isinstance(x, tuple):\n      return tuple(deepcopy(list(x)))\n    elif isinstance(x, list):\n      return [deepcopy(y) for y in x]\n    elif isinstance(x, dict):\n      values = [deepcopy(y) for y in list(x.values())]\n      keys = list(x.keys())\n      return dict(zip(keys, values))\n \n Python's own built-in deepcopy is based around that example. The only difference is it supports other types, and also supports user-classes by duplicating the attributes into a new duplicate class, and also blocks infinite-recursion with a reference to an object it's already seen using a memo list or dictionary. And that's really it for making deep copies. At its core, making a deep copy is just making shallow copies. I hope this answer adds something to the question. \n EXAMPLES \n Say you have this list:  [1, 2, 3] . The immutable numbers cannot be duplicated, but the other layer can. You can duplicate it using a list comprehension:  [x for x in [1, 2, 3]] \n Now, imagine you have this list:  [[1, 2], [3, 4], [5, 6]] . This time, you want to make a function, which uses recursion to deep copy all layers of the list. Instead of the previous list comprehension: \n [x for x in _list]\n \n It uses a new one for lists: \n [deepcopy_list(x) for x in _list]\n \n And  deepcopy_list  looks like this: \n def deepcopy_list(x):\n  if isinstance(x, (str, bool, float, int)):\n    return x\n  else:\n    return [deepcopy_list(y) for y in x]\n \n Then now you have a function which can deepcopy any list of  strs, bools, floast, ints  and even  lists  to infinitely many layers using recursion. And there you have it, deepcopying. \n TLDR : Deepcopy uses recursion to duplicate objects, and merely returns the same immutable objects as before, as immutable objects cannot be duplicated. However, it deepcopies the most inner layers of mutable objects until it reaches the outermost mutable layer of an object. \n    ", "date_posted": "2021-08-26 16:10:55Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "11741338", "name": "Corman", "reputation_score": "669"}, "answer_comments": []}, {"stack_answer_id": "50373643", "answer_content": "\r\n Note that there are some cases where if you have defined your own custom class and you want to keep the attributes then you should use  copy.copy()  or  copy.deepcopy()  rather than the alternatives, for example in Python 3: \n\n import copy\n\nclass MyList(list):\n    pass\n\nlst = MyList([1,2,3])\n\nlst.name = 'custom list'\n\nd = {\n'original': lst,\n'slicecopy' : lst[:],\n'lstcopy' : lst.copy(),\n'copycopy': copy.copy(lst),\n'deepcopy': copy.deepcopy(lst)\n}\n\n\nfor k,v in d.items():\n    print('lst: {}'.format(k), end=', ')\n    try:\n        name = v.name\n    except AttributeError:\n        name = 'NA'\n    print('name: {}'.format(name))\n \n\n Outputs: \n\n lst: original, name: custom list\nlst: slicecopy, name: NA\nlst: lstcopy, name: NA\nlst: copycopy, name: custom list\nlst: deepcopy, name: custom list\n \n    ", "date_posted": "2018-05-16 14:31:22Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "6260170", "name": "Chris_Rands", "reputation_score": "35.9k"}, "answer_comments": []}, {"stack_answer_id": "60352267", "answer_content": "\r\n Remember that in Python when you do: \n\n     list1 = ['apples','bananas','pineapples']\n    list2 = list1\n \n\n List2 isn't storing the actual list, but a reference to list1. So when you do anything to list1, list2 changes as well. use the copy module (not default, download on pip) to make an original copy of the list( copy.copy()  for simple lists,  copy.deepcopy()  for nested ones). This makes a copy that doesn't change with the first list. \n    ", "date_posted": "2020-02-22 12:44:40Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "12908850", "name": "Dr. Hippo", "reputation_score": "61"}, "answer_comments": []}, {"stack_answer_id": "59011118", "answer_content": "\r\n A slight practical perspective to look into memory through id and gc.  \n\n >>> b = a = ['hell', 'word']\n>>> c = ['hell', 'word']\n\n>>> id(a), id(b), id(c)\n(4424020872, 4424020872, 4423979272) \n     |           |\n      -----------\n\n>>> id(a[0]), id(b[0]), id(c[0])\n(4424018328, 4424018328, 4424018328) # all referring to same 'hell'\n     |           |           |\n      -----------------------\n\n>>> id(a[0][0]), id(b[0][0]), id(c[0][0])\n(4422785208, 4422785208, 4422785208) # all referring to same 'h'\n     |           |           |\n      -----------------------\n\n>>> a[0] += 'o'\n>>> a,b,c\n(['hello', 'word'], ['hello', 'word'], ['hell', 'word'])  # b changed too\n>>> id(a[0]), id(b[0]), id(c[0])\n(4424018384, 4424018384, 4424018328) # augmented assignment changed a[0],b[0]\n     |           |\n      -----------\n\n>>> b = a = ['hell', 'word']\n>>> id(a[0]), id(b[0]), id(c[0])\n(4424018328, 4424018328, 4424018328) # the same hell\n     |           |           |\n      -----------------------\n\n>>> import gc\n>>> gc.get_referrers(a[0]) \n[['hell', 'word'], ['hell', 'word']]  # one copy belong to a,b, the another for c\n>>> gc.get_referrers(('hell'))\n[['hell', 'word'], ['hell', 'word'], ('hell', None)] # ('hello', None) \n \n    ", "date_posted": "2019-11-23 19:01:46Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "1953475", "name": "B.Mr.W.", "reputation_score": "17.9k"}, "answer_comments": []}, {"stack_answer_id": "62716254", "answer_content": "\r\n There is another way of copying a list that was not listed until now: adding an empty list:  l2 = l + [] . \n I tested it with Python 3.8: \n l = [1,2,3]\nl2 = l + []\nprint(l,l2)\nl[0] = 'a'\nprint(l,l2)\n \n It is not the best answer, but it works. \n    ", "date_posted": "2021-11-19 23:13:45Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "6296561", "name": "Zoe stands with Ukraine", "reputation_score": "25.5k"}, "answer_comments": [{"stack_answer_id": "62716254", "stack_answer_comment_id": "128722772", "comment_content": "This works and, in my testing, is as fast as the fastest options for longer lists, and only slightly worse than ", "user_id": "None"}]}, {"stack_answer_id": "61155939", "answer_content": "\r\n The deepcopy option is the only method that works for me: \n\n from copy import deepcopy\n\na = [   [ list(range(1, 3)) for i in range(3) ]   ]\nb = deepcopy(a)\nb[0][1]=[3]\nprint('Deep:')\nprint(a)\nprint(b)\nprint('-----------------------------')\na = [   [ list(range(1, 3)) for i in range(3) ]   ]\nb = a*1\nb[0][1]=[3]\nprint('*1:')\nprint(a)\nprint(b)\nprint('-----------------------------')\na = [   [ list(range(1, 3)) for i in range(3) ] ]\nb = a[:]\nb[0][1]=[3]\nprint('Vector copy:')\nprint(a)\nprint(b)\nprint('-----------------------------')\na = [   [ list(range(1, 3)) for i in range(3) ]  ]\nb = list(a)\nb[0][1]=[3]\nprint('List copy:')\nprint(a)\nprint(b)\nprint('-----------------------------')\na = [   [ list(range(1, 3)) for i in range(3) ]  ]\nb = a.copy()\nb[0][1]=[3]\nprint('.copy():')\nprint(a)\nprint(b)\nprint('-----------------------------')\na = [   [ list(range(1, 3)) for i in range(3) ]  ]\nb = a\nb[0][1]=[3]\nprint('Shallow:')\nprint(a)\nprint(b)\nprint('-----------------------------')\n \n\n leads to output of: \n\n Deep:\n[[[1, 2], [1, 2], [1, 2]]]\n[[[1, 2], [3], [1, 2]]]\n-----------------------------\n*1:\n[[[1, 2], [3], [1, 2]]]\n[[[1, 2], [3], [1, 2]]]\n-----------------------------\nVector copy:\n[[[1, 2], [3], [1, 2]]]\n[[[1, 2], [3], [1, 2]]]\n-----------------------------\nList copy:\n[[[1, 2], [3], [1, 2]]]\n[[[1, 2], [3], [1, 2]]]\n-----------------------------\n.copy():\n[[[1, 2], [3], [1, 2]]]\n[[[1, 2], [3], [1, 2]]]\n-----------------------------\nShallow:\n[[[1, 2], [3], [1, 2]]]\n[[[1, 2], [3], [1, 2]]]\n-----------------------------\n \n    ", "date_posted": "2020-04-11 11:19:40Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "662770", "name": "shahar_m", "reputation_score": "3,236"}, "answer_comments": [{"stack_answer_id": "61155939", "stack_answer_comment_id": "114764971", "comment_content": "deepcopy must be used only when needed and one should be aware of what it really does.", "user_id": "None"}]}, {"stack_answer_id": "62192645", "answer_content": "\r\n This is because, the line  new_list = my_list  assigns a new reference to the variable  my_list  which is  new_list \nThis is similar to the  C  code given below, \n\n int my_list[] = [1,2,3,4];\nint *new_list;\nnew_list = my_list;\n \n\n You should use the copy module to create a new list by \n\n import copy\nnew_list = copy.deepcopy(my_list)\n \n    ", "date_posted": "2020-06-04 10:40:28Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "13328195", "name": "Roshin Raphel", "reputation_score": "2,506"}, "answer_comments": []}, {"stack_answer_id": "65972710", "answer_content": "\r\n The method to use depends on the contents of the list being copied. If the list contains nested  dicts  than deepcopy is the only method that works, otherwise most of the methods listed in the answers (slice, loop [for], copy, extend, combine, or unpack) will work and execute in similar time (except for loop and deepcopy, which preformed the worst). \n Script \n from random import randint\nfrom time import time\nimport copy\n\nitem_count = 100000\n\ndef copy_type(l1: list, l2: list):\n  if l1 == l2:\n    return 'shallow'\n  return 'deep'\n\ndef run_time(start, end):\n  run = end - start\n  return int(run * 1000000)\n\ndef list_combine(data):\n  l1 = [data for i in range(item_count)]\n  start = time()\n  l2 = [] + l1\n  end = time()\n  if type(data) == dict:\n    l2[0]['test'].append(1)\n  elif type(data) == list:\n    l2.append(1)\n  return {'method': 'combine', 'copy_type': copy_type(l1, l2), \n          'time_\u00b5s': run_time(start, end)}\n\ndef list_extend(data):\n  l1 = [data for i in range(item_count)]\n  start = time()\n  l2 = []\n  l2.extend(l1)\n  end = time()\n  if type(data) == dict:\n    l2[0]['test'].append(1)\n  elif type(data) == list:\n    l2.append(1)\n  return {'method': 'extend', 'copy_type': copy_type(l1, l2), \n          'time_\u00b5s': run_time(start, end)}\n\ndef list_unpack(data):\n  l1 = [data for i in range(item_count)]\n  start = time()\n  l2 = [*l1]\n  end = time()\n  if type(data) == dict:\n    l2[0]['test'].append(1)\n  elif type(data) == list:\n    l2.append(1)\n  return {'method': 'unpack', 'copy_type': copy_type(l1, l2), \n          'time_\u00b5s': run_time(start, end)}\n\ndef list_deepcopy(data):\n  l1 = [data for i in range(item_count)]\n  start = time()\n  l2 = copy.deepcopy(l1)\n  end = time()\n  if type(data) == dict:\n    l2[0]['test'].append(1)\n  elif type(data) == list:\n    l2.append(1)\n  return {'method': 'deepcopy', 'copy_type': copy_type(l1, l2), \n          'time_\u00b5s': run_time(start, end)}\n\ndef list_copy(data):\n  l1 = [data for i in range(item_count)]\n  start = time()\n  l2 = list.copy(l1)\n  end = time()\n  if type(data) == dict:\n    l2[0]['test'].append(1)\n  elif type(data) == list:\n    l2.append(1)\n  return {'method': 'copy', 'copy_type': copy_type(l1, l2), \n          'time_\u00b5s': run_time(start, end)}\n\ndef list_slice(data):\n  l1 = [data for i in range(item_count)]\n  start = time()\n  l2 = l1[:]\n  end = time()\n  if type(data) == dict:\n    l2[0]['test'].append(1)\n  elif type(data) == list:\n    l2.append(1)\n  return {'method': 'slice', 'copy_type': copy_type(l1, l2), \n          'time_\u00b5s': run_time(start, end)}\n\ndef list_loop(data):\n  l1 = [data for i in range(item_count)]\n  start = time()\n  l2 = []\n  for i in range(len(l1)):\n    l2.append(l1[i])\n  end = time()\n  if type(data) == dict:\n    l2[0]['test'].append(1)\n  elif type(data) == list:\n    l2.append(1)\n  return {'method': 'loop', 'copy_type': copy_type(l1, l2), \n          'time_\u00b5s': run_time(start, end)}\n\ndef list_list(data):\n  l1 = [data for i in range(item_count)]\n  start = time()\n  l2 = list(l1)\n  end = time()\n  if type(data) == dict:\n    l2[0]['test'].append(1)\n  elif type(data) == list:\n    l2.append(1)\n  return {'method': 'list()', 'copy_type': copy_type(l1, l2), \n          'time_\u00b5s': run_time(start, end)}\n\nif __name__ == '__main__':\n  list_type = [{'list[dict]': {'test': [1, 1]}}, \n          {'list[list]': [1, 1]}]\n  store = []\n  for data in list_type:\n    key = list(data.keys())[0]\n    store.append({key: [list_unpack(data[key]), list_extend(data[key]), \n                list_combine(data[key]), list_deepcopy(data[key]), \n                list_copy(data[key]), list_slice(data[key]),           \n                list_loop(data[key])]})\n  print(store)\n \n Results \n [{\"list[dict]\": [\n  {\"method\": \"unpack\", \"copy_type\": \"shallow\", \"time_\u00b5s\": 56149},\n  {\"method\": \"extend\", \"copy_type\": \"shallow\", \"time_\u00b5s\": 52991},\n  {\"method\": \"combine\", \"copy_type\": \"shallow\", \"time_\u00b5s\": 53726},\n  {\"method\": \"deepcopy\", \"copy_type\": \"deep\", \"time_\u00b5s\": 2702616},\n  {\"method\": \"copy\", \"copy_type\": \"shallow\", \"time_\u00b5s\": 52204},\n  {\"method\": \"slice\", \"copy_type\": \"shallow\", \"time_\u00b5s\": 52223},\n  {\"method\": \"loop\", \"copy_type\": \"shallow\", \"time_\u00b5s\": 836928}]},\n{\"list[list]\": [\n  {\"method\": \"unpack\", \"copy_type\": \"deep\", \"time_\u00b5s\": 52313},\n  {\"method\": \"extend\", \"copy_type\": \"deep\", \"time_\u00b5s\": 52550},\n  {\"method\": \"combine\", \"copy_type\": \"deep\", \"time_\u00b5s\": 53203},\n  {\"method\": \"deepcopy\", \"copy_type\": \"deep\", \"time_\u00b5s\": 2608560},\n  {\"method\": \"copy\", \"copy_type\": \"deep\", \"time_\u00b5s\": 53210},\n  {\"method\": \"slice\", \"copy_type\": \"deep\", \"time_\u00b5s\": 52937},\n  {\"method\": \"loop\", \"copy_type\": \"deep\", \"time_\u00b5s\": 834774}\n]}]\n \n    ", "date_posted": "2021-01-30 20:17:42Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "10773184", "name": "fjemi", "reputation_score": "11"}, "answer_comments": []}], "user": {"stack_user_id": "187730", "name": "aF.", "reputation_score": "63.1k"}, "question_comments": [{"stack_question_id": "2612802", "stack_question_comment_id": "123683957", "comment_content": " just assigns the name ", "user_id": "None"}, {"stack_question_id": "2612802", "stack_question_comment_id": "125187420", "comment_content": "See the ", "user_id": "None"}, {"stack_question_id": "2612802", "stack_question_comment_id": "128071906", "comment_content": "See also: ", "user_id": "None"}, {"stack_question_id": "2612802", "stack_question_comment_id": "128097571", "comment_content": "Related: ", "user_id": "None"}]},
{"stack_question_id": "20002503", "question_title": "Why does \"a == x or y or z\" always evaluate to True? How can I compare \"a\" to all of those?", "question_content": "\r\n                I am writing a security system that denies access to unauthorized users.\nname = input(\"Hello. Please enter your name: \")\nif name == \"Kevin\" or \"Jon\" or \"Inbar\":\n...\r\n", "question_url": "/questions/20002503/why-does-a-x-or-y-or-z-always-evaluate-to-true-how-can-i-compare-a-to-al", "date_posted": "Nov 15, 2013 at 13:45", "upvote": "1", "view": "3", "tags": ["python", "boolean", "boolean-expression"], "answers_count": "6", "answers": [{"stack_answer_id": "20002504", "answer_content": "\r\n In many cases, Python looks and behaves like natural English, but this is one case where that abstraction fails. People can use context clues to determine that \"Jon\" and \"Inbar\" are objects joined to the verb \"equals\", but the Python interpreter is more literal minded. \n if name == \"Kevin\" or \"Jon\" or \"Inbar\":\n \n is logically equivalent to: \n if (name == \"Kevin\") or (\"Jon\") or (\"Inbar\"):\n \n Which, for user Bob, is equivalent to: \n if (False) or (\"Jon\") or (\"Inbar\"):\n \n The  or  operator chooses the first argument with a positive  truth value : \n if \"Jon\":\n \n And since \"Jon\" has a positive truth value, the  if  block executes. That is what causes \"Access granted\" to be printed regardless of the name given. \n All of this reasoning also applies to the expression  if \"Kevin\" or \"Jon\" or \"Inbar\" == name . the first value,  \"Kevin\" , is true, so the  if  block executes. \n \n There are two common ways to properly construct this conditional. \n \n Use multiple  ==  operators to explicitly check against each value: \n if name == \"Kevin\" or name == \"Jon\" or name == \"Inbar\":\n \n \n Compose a collection of valid values (a set, a list or a tuple for example), and use the  in  operator to test for membership: \n if name in {\"Kevin\", \"Jon\", \"Inbar\"}:\n \n \n \n In general of the two the second should be preferred as it's easier to read and also faster: \n >>> import timeit\n>>> timeit.timeit('name == \"Kevin\" or name == \"Jon\" or name == \"Inbar\"',\n    setup=\"name='Inbar'\")\n0.4247764749999945\n>>> timeit.timeit('name in {\"Kevin\", \"Jon\", \"Inbar\"}', setup=\"name='Inbar'\")\n0.18493307199999265\n \n \n For those who may want proof that  if a == b or c or d or e: ...  is indeed parsed like this. The built-in  ast  module provides an answer: \n >>> import ast\n>>> ast.parse(\"a == b or c or d or e\", \"<string>\", \"eval\")\n<ast.Expression object at 0x7f929c898220>\n>>> print(ast.dump(_, indent=4))\nExpression(\n    body=BoolOp(\n        op=Or(),\n        values=[\n            Compare(\n                left=Name(id='a', ctx=Load()),\n                ops=[\n                    Eq()],\n                comparators=[\n                    Name(id='b', ctx=Load())]),\n            Name(id='c', ctx=Load()),\n            Name(id='d', ctx=Load()),\n            Name(id='e', ctx=Load())]))\n \n As one can see, it's the boolean operator  or  applied to four sub-expressions: comparison  a == b ; and simple expressions  c ,  d , and  e . \n    ", "date_posted": "2021-04-11 18:47:35Z", "upvote": "\r\n            198\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "20002504", "name": "\r\n        7 revs, 5 users 42%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "20002504", "stack_answer_comment_id": "99771573", "comment_content": "Is there a specific reason to choose a tuple ", "user_id": "None"}, {"stack_answer_id": "20002504", "stack_answer_comment_id": "99771840", "comment_content": "Not really, since both work if the values are all hashable. Set membership testing has better big-O complexity than tuple membership testing, but constructing a set is a little more expensive than constructing a tuple. I think it's largely a wash for small collections like these. Playing around with timeit, ", "user_id": "953482"}, {"stack_answer_id": "20002504", "stack_answer_comment_id": "99772058", "comment_content": " recommends set literals for membership testing. I'll update my post.", "user_id": "953482"}, {"stack_answer_id": "20002504", "stack_answer_comment_id": "109380603", "comment_content": "In modern Python, it recognizes that the set is a constant and makes it a ", "user_id": "None"}]}, {"stack_answer_id": "62545337", "answer_content": "\r\n There are 3 condition checks in  if name == \"Kevin\" or \"Jon\" or \"Inbar\": \n \n name == \"Kevin\" \n \"Jon\" \n \"Inbar\" \n \n and this if statement is equivalent to \n if name == \"Kevin\":\n    print(\"Access granted.\")\nelif \"Jon\":\n    print(\"Access granted.\")\nelif \"Inbar\":\n    print(\"Access granted.\")\nelse:\n    print(\"Access denied.\")\n \n Since  elif \"Jon\"  will always be true so access to any user is granted \n Solution \n \n You can use any one method below \n Fast \n if name in [\"Kevin\", \"Jon\", \"Inbar\"]:\n    print(\"Access granted.\")\nelse:\n    print(\"Access denied.\")\n \n Slow \n if name == \"Kevin\" or name == \"Jon\" or name == \"Inbar\":\n    print(\"Access granted.\")\nelse:\n    print(\"Access denied.\")\n \n Slow + Unnecessary code \n if name == \"Kevin\":\n    print(\"Access granted.\")\nelif name == \"Jon\":\n    print(\"Access granted.\")\nelif name == \"Inbar\":\n    print(\"Access granted.\")\nelse:\n    print(\"Access denied.\")\n \n    ", "date_posted": "2020-06-24 00:30:08Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "13751567", "name": "7u5h4r", "reputation_score": "439"}, "answer_comments": []}, {"stack_answer_id": "71188001", "answer_content": "\r\n Summarising all existing answers \n (And adding a few of my points) \n Explanation : \n if name == \"Kevin\" or \"Jon\" or \"Inbar\":\n \n is logically equivalent to: \n if (name == \"Kevin\") or (\"Jon\") or (\"Inbar\"):\n \n Which, for user Bob, is equivalent to: \n if (False) or (\"Jon\") or (\"Inbar\"):\n \n NOTE : Python evaluates the logical value of any non-zero integer as  True . Therefore, all Non-empty lists, sets, strings, etc. are evaluable and return  True \n The  or  operator chooses the first argument with a positive truth value. \n Therefore, \"Jon\" has a positive truth value and the if block executes, since it is now equivalent to \n if (False) or (True) or (True):\n \n That is what causes \"Access granted\" to be printed regardless of the name input. \n Solutions : \n Solution 1 :  Use multiple  ==  operators to explicitly check against each value \n if name == \"Kevin\" or name == \"Jon\" or name == \"Inbar\":\n    print(\"Access granted.\")\nelse:\n    print(\"Access denied.\")\n \n Solution 2 :  Compose a collection of valid values (a set, a list or a tuple for example), and use the  in  operator to test for membership  (faster, preferred method) \n if name in {\"Kevin\", \"Jon\", \"Inbar\"}:\n    print(\"Access granted.\")\nelse:\n    print(\"Access denied.\")\n \n OR \n if name in [\"Kevin\", \"Jon\", \"Inbar\"]:\n    print(\"Access granted.\")\nelse:\n    print(\"Access denied.\")\n \n Solution 3 :  Use the basic  (and not very efficient)   if-elif-else  structure \n if name == \"Kevin\":\n    print(\"Access granted.\")\nelif name == \"Jon\":\n    print(\"Access granted.\")\nelif name == \"Inbar\":\n    print(\"Access granted.\")\nelse:\n    print(\"Access denied.\")\n \n    ", "date_posted": "2022-02-25 06:21:43Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "17112163", "name": "Deepthi Tabitha Bennet", "reputation_score": "534"}, "answer_comments": []}, {"stack_answer_id": "56186060", "answer_content": "\r\n Simple engineering problem, let's simply it a bit further. \n\n In [1]: a,b,c,d=1,2,3,4\nIn [2]: a==b\nOut[2]: False\n \n\n But, inherited from the language C, Python evaluates the logical value of a non zero integer as True. \n\n In [11]: if 3:\n    ...:     print (\"yey\")\n    ...:\nyey\n \n\n Now, Python builds on that logic and let you use logic literals such as or on integers, and so  \n\n In [9]: False or 3\nOut[9]: 3\n \n\n Finally \n\n In [4]: a==b or c or d\nOut[4]: 3\n \n\n The proper way to write it would be: \n\n In [13]: if a in (b,c,d):\n    ...:     print('Access granted')\n \n\n For safety I'd also suggest you don't hard code passwords. \n    ", "date_posted": "2019-05-17 12:05:58Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "1854182", "name": "user1854182", "reputation_score": "641"}, "answer_comments": []}, {"stack_answer_id": "65071388", "answer_content": "\r\n Not-empty lists, sets, strings, etc. are evaluable and, therefore, return True. \n Therefore, when you say: \n a = \"Raul\"\nif a == \"Kevin\" or \"John\" or \"Inbar\":\n    pass\n \n You are actually saying: \n if \"Raul\" == \"Kevin\" or \"John\" != \"\" or \"Inbar\" != \"\":\n    pass\n \n Since at least one of \"John\" and \"Inbar\" is not an empty string, the whole expression always returns True! \n The solution: \n a = \"Raul\"\nif a == \"Kevin\" or a == \"John\" or a == \"Inbar\":\n    pass\n \n or: \n a = \"Raul\"\nif a in {\"Kevin\", \"John\", \"Inbar\"}:\n    pass\n \n    ", "date_posted": "2020-11-30 13:23:54Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "6251742", "name": "Dorian Turba", "reputation_score": "1,847"}, "answer_comments": [{"stack_answer_id": "65071388", "stack_answer_comment_id": "118514393", "comment_content": "good otherwise but \"You are actually saying:\" is ", "user_id": "None"}]}, {"stack_answer_id": "65199768", "answer_content": "\r\n Approaches \n How a data scientist approaches this problem \n The simplest way possible is to eliminate the need for comparison operators and use a list. This looks impressive on security systems because you learn to access ORMs. \n user = input(\"Enter name: \")\n\nif user in {\"Bob\", \"Kevin\", \"Joe\"}:\n   print(\"Access granted, \" + str(user) + \".\")\nelse:\n   print(\"Access denied.\")\n \n Or, you can resemble the  exact  same code above, just put the list of registered users in their own list: \n user = input(\"Enter name: \")\nusers = {\"Bob\", \"Kevin\", \"Joe\", \"a million more users if you like\"}\n\nif user in users:\n   print(\"Access granted, \" + str(user) + \".\")\nelse:\n   print(\"Access denied.\")\n \n If you wanted to complete this protocol safely without the risk of attack, set up double parameters. This would check your mini-ORM for  first  and  last  name fields, as well as a  password  or  secret question  key. Objects can be sorted like this if you want to efficiently lazy-load user credentials without hashing: \n def lazy(i):\n   j = 0 # For example\n   while j < i:\n      yield j\n      j += 1\n \n The loop will consume  only  the yielded values to save time and energy on your system: \n You can then do something with the iterated list: \n for j in lazy_range(10):\n   do_something_here(j)\n \n This problem can be approached from any angle: memory management, security, or simply by an organic list or packaged ORM. \n    ", "date_posted": "2022-01-02 09:47:13Z", "upvote": "\r\n            -1\r\n        ", "accepted": "No", "user": {"stack_user_id": "4621513", "name": "mkrieger1", "reputation_score": "15.4k"}, "answer_comments": []}], "user": {"stack_user_id": "953482", "name": "Kevin", "reputation_score": "72.8k"}, "question_comments": [{"stack_question_id": "20002503", "stack_question_comment_id": "97948491", "comment_content": "Variations of this problem include ", "user_id": "None"}]},
{"stack_question_id": "423379", "question_title": "Using global variables in a function", "question_content": "\r\n                How do I create or use a global variable inside a function?\nHow do I use a global variable that was defined in one function inside other functions?\r\n", "question_url": "/questions/423379/using-global-variables-in-a-function", "date_posted": "Jan 8, 2009 at 5:45", "upvote": "3", "view": "3", "tags": ["python", "global-variables", "scope"], "answers_count": "2", "answers": [{"stack_answer_id": "423596", "answer_content": "\r\n You can use a global variable within other functions by declaring it as  global  within each function that assigns a value to it: \n globvar = 0\n\ndef set_globvar_to_one():\n    global globvar    # Needed to modify global copy of globvar\n    globvar = 1\n\ndef print_globvar():\n    print(globvar)     # No need for global declaration to read value of globvar\n\nset_globvar_to_one()\nprint_globvar()       # Prints 1\n \n Since it's unclear whether  globvar = 1  is creating a local variable or changing a global variable, Python defaults to creating a local variable, and makes you explicitly choose the other behavior with the  global  keyword. \n See other answers if you want to share a global variable across modules. \n    ", "date_posted": "2022-01-28 21:03:06Z", "upvote": "\r\n            4936\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "128023", "name": "Zarel", "reputation_score": "2,201"}, "answer_comments": [{"stack_answer_id": "423596", "stack_answer_comment_id": "19339130", "comment_content": "It's extreme exaggeration to refer to globals as \"so dangerous.\" Globals are perfectly fine in every language that has ever existed and ever will exist. They have their place. What you should have said is they can cause issues if you have no clue how to program.", "user_id": "None"}, {"stack_answer_id": "423596", "stack_answer_comment_id": "20143828", "comment_content": "I think they are fairly dangerous. However in python \"global\" variables are actually module-level, which solves a lot of issues.", "user_id": "None"}]}, {"stack_answer_id": "423668", "answer_content": "\r\n If I'm understanding your situation correctly, what you're seeing is the result of how Python handles local (function) and global (module) namespaces. \n Say you've got a module like this: \n # sample.py\n_my_global = 5\n\ndef func1():\n    _my_global = 42\n\ndef func2():\n    print _my_global\n\nfunc1()\nfunc2()\n \n You might expecting this to print 42, but instead it prints 5.  As has already been mentioned, if you add a ' global ' declaration to  func1() , then  func2()  will print 42. \n def func1():\n    global _my_global \n    _my_global = 42\n \n What's going on here is that Python assumes that any name that is  assigned to , anywhere within a function, is local to that function unless explicitly told otherwise.  If it is only  reading  from a name, and the name doesn't exist locally, it will try to look up the name in any containing scopes (e.g. the module's global scope). \n When you assign 42 to the name  _my_global , therefore, Python creates a local variable that shadows the global variable of the same name.  That local goes out of scope and is  garbage-collected  when  func1()  returns; meanwhile,  func2()  can never see anything other than the (unmodified) global name.  Note that this namespace decision happens at compile time, not at runtime -- if you were to read the value of  _my_global  inside  func1()  before you assign to it, you'd get an  UnboundLocalError , because Python has already decided that it must be a local variable but it has not had any value associated with it yet.  But by using the ' global ' statement, you tell Python that it should look elsewhere for the name instead of assigning to it locally. \n (I believe that this behavior originated largely through an optimization of local namespaces -- without this behavior,  Python's VM would need to perform at least three name lookups each time a new name is assigned to inside a function (to ensure that the name didn't already exist at module/builtin level), which would significantly slow down a very common operation.) \n    ", "date_posted": "2022-06-13 10:11:24Z", "upvote": "\r\n            861\r\n        ", "accepted": "No", "user": {"stack_user_id": "4298200", "name": "Neuron", "reputation_score": "4,509"}, "answer_comments": [{"stack_answer_id": "423668", "stack_answer_comment_id": "53998527", "comment_content": "You mentioned that the namespace decision happens at ", "user_id": "None"}, {"stack_answer_id": "423668", "stack_answer_comment_id": "83833173", "comment_content": "It is common to use a capital letter for global variables like ", "user_id": "None"}, {"stack_answer_id": "423668", "stack_answer_comment_id": "83890430", "comment_content": "@watashiSHUN: The namespace decision ", "user_id": "None"}, {"stack_answer_id": "423668", "stack_answer_comment_id": "83890525", "comment_content": "@Vassilis: It is common to upper case ", "user_id": "None"}]}, {"stack_answer_id": "423401", "answer_content": "\r\n You may want to explore the notion of  namespaces . In Python, the  module  is the natural place for  global  data: \n \n Each module has its own private symbol table, which is used as the global symbol table by all functions defined in the module. Thus, the author of a module can use global variables in the module without worrying about accidental clashes with a user\u2019s global variables. On the other hand, if you know what you are doing you can touch a module\u2019s global variables with the same notation used to refer to its functions,  modname.itemname . \n \n A specific use of global-in-a-module is described here -  How do I share global variables across modules? , and for completeness the contents are shared here: \n \n The canonical way to share information across modules within a single program is to create a special configuration module (often called  config  or  cfg ). Just import the configuration module in all modules of your application; the module then becomes available as a global name. Because there is only one instance of each module, any changes made to the module object get reflected everywhere. For example: \n \n \n File: config.py \n \n \n x = 0   # Default value of the 'x' configuration setting\n \n \n \n File: mod.py \n \n import config\nconfig.x = 1\n \n \n File: main.py \n \n import config\nimport mod\nprint config.x\n \n    ", "date_posted": "2020-12-16 04:50:21Z", "upvote": "\r\n            262\r\n        ", "accepted": "No", "user": {"stack_user_id": "2038264", "name": "congusbongus", "reputation_score": "12.3k"}, "answer_comments": [{"stack_answer_id": "423401", "stack_answer_comment_id": "83098999", "comment_content": "for a reason I don't like the ", "user_id": "None"}, {"stack_answer_id": "423401", "stack_answer_comment_id": "94196170", "comment_content": "@vladosaurus does  ", "user_id": "None"}]}, {"stack_answer_id": "6664227", "answer_content": "\r\n Python uses a simple heuristic to decide which scope it should load a variable from, between local and global.  If a variable name appears on the left hand side of an assignment, but is not declared global, it is assumed to be local.  If it does not appear on the left hand side of an assignment, it is assumed to be global.   \n\n >>> import dis\n>>> def foo():\n...     global bar\n...     baz = 5\n...     print bar\n...     print baz\n...     print quux\n... \n>>> dis.disassemble(foo.func_code)\n  3           0 LOAD_CONST               1 (5)\n              3 STORE_FAST               0 (baz)\n\n  4           6 LOAD_GLOBAL              0 (bar)\n              9 PRINT_ITEM          \n             10 PRINT_NEWLINE       \n\n  5          11 LOAD_FAST                0 (baz)\n             14 PRINT_ITEM          \n             15 PRINT_NEWLINE       \n\n  6          16 LOAD_GLOBAL              1 (quux)\n             19 PRINT_ITEM          \n             20 PRINT_NEWLINE       \n             21 LOAD_CONST               0 (None)\n             24 RETURN_VALUE        \n>>> \n \n\n See how baz, which appears on the left side of an assignment in  foo() , is the only  LOAD_FAST  variable. \n    ", "date_posted": "2011-07-12 12:35:08Z", "upvote": "\r\n            109\r\n        ", "accepted": "No", "user": {"stack_user_id": "65696", "name": "SingleNegationElimination", "reputation_score": "146k"}, "answer_comments": [{"stack_answer_id": "6664227", "stack_answer_comment_id": "51714387", "comment_content": "The heuristic looks for ", "user_id": "None"}, {"stack_answer_id": "6664227", "stack_answer_comment_id": "106317214", "comment_content": "@MartijnPieters For the name after ", "user_id": "None"}, {"stack_answer_id": "6664227", "stack_answer_comment_id": "106317485", "comment_content": "@Robert: not to save memory, but to avoid creating a circular reference, which can lead to memory leaks. That's because an exception references a traceback, and the traceback references every local and global namespace along the whole call stack, including the ", "user_id": "None"}]}, {"stack_answer_id": "423641", "answer_content": "\r\n If you want to refer to a global variable in a function, you can use the  global  keyword to declare which variables are global. You don't have to use it in all cases (as someone here incorrectly claims) - if the name referenced in an expression cannot be found in local scope or scopes in the functions in which this function is defined, it is looked up among global variables. \n\n However, if you assign to a new variable not declared as global in the function, it is implicitly declared as local, and it can overshadow any existing global variable with the same name. \n\n Also, global variables are useful, contrary to some OOP zealots who claim otherwise - especially for smaller scripts, where OOP is overkill. \n    ", "date_posted": "2017-03-04 22:00:48Z", "upvote": "\r\n            70\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "423641", "stack_answer_comment_id": "102505940", "comment_content": "Absolutely re. zealots.  Most Python users use it for scripting and create little functions to separate out small bits of code.", "user_id": "None"}]}, {"stack_answer_id": "34559513", "answer_content": "\r\n \n   If I create a global variable in one function, how can I use that variable in another function? \n \n\n We can create a global with the following function: \n\n def create_global_variable():\n    global global_variable # must declare it to be a global first\n    # modifications are thus reflected on the module's global scope\n    global_variable = 'Foo' \n \n\n Writing a function does not actually run its code. So we call the  create_global_variable  function: \n\n >>> create_global_variable()\n \n\n Using globals without modification \n\n You can just use it, so long as you don't expect to change which object it points to:  \n\n For example,  \n\n def use_global_variable():\n    return global_variable + '!!!'\n \n\n and now we can use the global variable: \n\n >>> use_global_variable()\n'Foo!!!'\n \n\n Modification of the global variable from inside a function \n\n To point the global variable at a different object, you are required to use the global keyword again: \n\n def change_global_variable():\n    global global_variable\n    global_variable = 'Bar'\n \n\n Note that after writing this function, the code actually changing it has still not run: \n\n >>> use_global_variable()\n'Foo!!!'\n \n\n So after calling the function: \n\n >>> change_global_variable()\n \n\n we can see that the global variable has been changed. The  global_variable  name now points to  'Bar' : \n\n >>> use_global_variable()\n'Bar!!!'\n \n\n Note that \"global\" in Python is not truly global - it's only global to the module level. So it is only available to functions written in the modules in which it is global. Functions remember the module in which they are written, so when they are exported into other modules, they still look in the module in which they were created to find global variables. \n\n Local variables with the same name \n\n If you create a local variable with the same name, it will overshadow a global variable: \n\n def use_local_with_same_name_as_global():\n    # bad name for a local variable, though.\n    global_variable = 'Baz' \n    return global_variable + '!!!'\n\n>>> use_local_with_same_name_as_global()\n'Baz!!!'\n \n\n But using that misnamed local variable does not change the global variable: \n\n >>> use_global_variable()\n'Bar!!!'\n \n\n Note that you should avoid using the local variables with the same names as globals unless you know precisely what you are doing and have a very good reason to do so. I have not yet encountered such a reason. \n\n We get the same behavior in classes \n\n A follow on comment asks: \n\n \n   what to do if I want to create a global variable inside a function inside a class and want to use that variable inside another function inside another class? \n \n\n Here I demonstrate we get the same behavior in methods as we do in regular functions: \n\n class Foo:\n    def foo(self):\n        global global_variable\n        global_variable = 'Foo'\n\nclass Bar:\n    def bar(self):\n        return global_variable + '!!!'\n\nFoo().foo()\n \n\n And now: \n\n >>> Bar().bar()\n'Foo!!!'\n \n\n But I would suggest instead of using global variables you use class attributes, to avoid cluttering the module namespace. Also note we don't use  self  arguments here - these could be class methods (handy if mutating the class attribute from the usual  cls  argument) or static methods (no  self  or  cls ). \n    ", "date_posted": "2020-01-19 14:41:24Z", "upvote": "\r\n            65\r\n        ", "accepted": "No", "user": {"stack_user_id": "541136", "name": "Russia Must Remove Putin", "reputation_score": "347k"}, "answer_comments": [{"stack_answer_id": "34559513", "stack_answer_comment_id": "105760662", "comment_content": "Cool, but what to do if I want to create a global variable inside a function inside a class and want to use that variable inside another function inside another class? Kinda stuck here", "user_id": "None"}, {"stack_answer_id": "34559513", "stack_answer_comment_id": "105760720", "comment_content": "@anonmanx I don't know why you're stuck, it's the same behavior in a method as in a regular function. But I'll update my answer with your remark and some demo code, ok?", "user_id": "None"}, {"stack_answer_id": "34559513", "stack_answer_comment_id": "105760875", "comment_content": "okay, got it. So I will have to explicitly call that function for using that global variable.", "user_id": "None"}]}, {"stack_answer_id": "24572187", "answer_content": "\r\n In addition to already existing answers and to make this more confusing: \n\n \n   In Python, variables that are only referenced inside a function are\n   implicitly global . If a variable is assigned a new value anywhere\n  within the function\u2019s body, it\u2019s assumed to be a  local . If a variable\n  is ever assigned a new value inside the function, the variable is\n  implicitly local, and you need to explicitly declare it as \u2018global\u2019. \n  \n   Though a bit surprising at first, a moment\u2019s consideration explains\n  this. On one hand, requiring global for assigned variables provides a\n  bar against unintended side-effects. On the other hand, if global was\n  required for all global references, you\u2019d be using global all the\n  time. You\u2019d have to declare as global every reference to a built-in\n  function or to a component of an imported module. This clutter would\n  defeat the usefulness of the global declaration for identifying\n  side-effects. \n \n\n Source:  What are the rules for local and global variables in Python? . \n    ", "date_posted": "2014-07-20 10:36:29Z", "upvote": "\r\n            54\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "19151605", "answer_content": "\r\n With parallel execution, global variables can cause unexpected results if you don't understand what is happening. Here is an example of using a global variable within multiprocessing. We can clearly see that each process works with its own copy of the variable: \n\n import multiprocessing\nimport os\nimport random\nimport sys\nimport time\n\ndef worker(new_value):\n    old_value = get_value()\n    set_value(random.randint(1, 99))\n    print('pid=[{pid}] '\n          'old_value=[{old_value:2}] '\n          'new_value=[{new_value:2}] '\n          'get_value=[{get_value:2}]'.format(\n          pid=str(os.getpid()),\n          old_value=old_value,\n          new_value=new_value,\n          get_value=get_value()))\n\ndef get_value():\n    global global_variable\n    return global_variable\n\ndef set_value(new_value):\n    global global_variable\n    global_variable = new_value\n\nglobal_variable = -1\n\nprint('before set_value(), get_value() = [%s]' % get_value())\nset_value(new_value=-2)\nprint('after  set_value(), get_value() = [%s]' % get_value())\n\nprocessPool = multiprocessing.Pool(processes=5)\nprocessPool.map(func=worker, iterable=range(15))\n \n\n Output: \n\n before set_value(), get_value() = [-1]\nafter  set_value(), get_value() = [-2]\npid=[53970] old_value=[-2] new_value=[ 0] get_value=[23]\npid=[53971] old_value=[-2] new_value=[ 1] get_value=[42]\npid=[53970] old_value=[23] new_value=[ 4] get_value=[50]\npid=[53970] old_value=[50] new_value=[ 6] get_value=[14]\npid=[53971] old_value=[42] new_value=[ 5] get_value=[31]\npid=[53972] old_value=[-2] new_value=[ 2] get_value=[44]\npid=[53973] old_value=[-2] new_value=[ 3] get_value=[94]\npid=[53970] old_value=[14] new_value=[ 7] get_value=[21]\npid=[53971] old_value=[31] new_value=[ 8] get_value=[34]\npid=[53972] old_value=[44] new_value=[ 9] get_value=[59]\npid=[53973] old_value=[94] new_value=[10] get_value=[87]\npid=[53970] old_value=[21] new_value=[11] get_value=[21]\npid=[53971] old_value=[34] new_value=[12] get_value=[82]\npid=[53972] old_value=[59] new_value=[13] get_value=[ 4]\npid=[53973] old_value=[87] new_value=[14] get_value=[70]\n \n    ", "date_posted": "2017-01-03 02:34:20Z", "upvote": "\r\n            39\r\n        ", "accepted": "No", "user": {"stack_user_id": "875915", "name": "Rob Bednark", "reputation_score": "23.5k"}, "answer_comments": []}, {"stack_answer_id": "19347254", "answer_content": "\r\n As it turns out the answer is always simple. \n\n Here is a small sample module with a simple way to show it in a  main  definition: \n\n def five(enterAnumber,sumation):\n    global helper\n    helper  = enterAnumber + sumation\n\ndef isTheNumber():\n    return helper\n \n\n Here is how to show it in a  main  definition: \n\n import TestPy\n\ndef main():\n    atest  = TestPy\n    atest.five(5,8)\n    print(atest.isTheNumber())\n\nif __name__ == '__main__':\n    main()\n \n\n This simple code works just like that, and it will execute. I hope it helps. \n    ", "date_posted": "2018-09-28 11:34:54Z", "upvote": "\r\n            32\r\n        ", "accepted": "No", "user": {"stack_user_id": "6664578", "name": "AEF", "reputation_score": "5,143"}, "answer_comments": [{"stack_answer_id": "19347254", "stack_answer_comment_id": "28873293", "comment_content": "thanks, i'm new to python, but know a bit of java.  what you said worked for me. and writing global a<ENTER> within the class.. seems to make more sense to me than within a function writing 'global a'..  I notice you can't say  global a=4", "user_id": "None"}, {"stack_answer_id": "19347254", "stack_answer_comment_id": "40543494", "comment_content": "This is probably the simplest yet very useful python trick for me. I name this module ", "user_id": "None"}, {"stack_answer_id": "19347254", "stack_answer_comment_id": "47268475", "comment_content": "What if there are many many global variables and I don't want to have to list them one-by-one after a global statement?", "user_id": "None"}]}, {"stack_answer_id": "27287648", "answer_content": "\r\n What you are saying is to use the method like this: \n globvar = 5\n\ndef f():\n    var = globvar\n    print(var)\n\nf()  # Prints 5\n \n But the better way is to use the global variable like this: \n globvar = 5\ndef f():\n    global globvar\n    print(globvar)\nf()   #prints 5\n \n Both give the same output. \n    ", "date_posted": "2020-12-01 07:45:16Z", "upvote": "\r\n            31\r\n        ", "accepted": "No", "user": {"stack_user_id": "8873143", "name": "funie200", "reputation_score": "3,384"}, "answer_comments": []}, {"stack_answer_id": "27580376", "answer_content": "\r\n You need to reference the global variable in every function you want to use. \n\n As follows: \n\n var = \"test\"\n\ndef printGlobalText():\n    global var #wWe are telling to explicitly use the global version\n    var = \"global from printGlobalText fun.\"\n    print \"var from printGlobalText: \" + var\n\ndef printLocalText():\n    #We are NOT telling to explicitly use the global version, so we are creating a local variable\n    var = \"local version from printLocalText fun\"\n    print \"var from printLocalText: \" + var\n\nprintGlobalText()\nprintLocalText()\n\"\"\"\nOutput Result:\nvar from printGlobalText: global from printGlobalText fun.\nvar from printLocalText: local version from printLocalText\n[Finished in 0.1s]\n\"\"\"\n \n    ", "date_posted": "2015-02-04 18:45:42Z", "upvote": "\r\n            29\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "27580376", "stack_answer_comment_id": "46534476", "comment_content": "'in every function you want to use' is subtly incorrect, should be closer to: 'in every function where you want to ", "user_id": "None"}]}, {"stack_answer_id": "28329600", "answer_content": "\r\n Try this: \n def x1():\n    global x\n    x += 1\n    print('x1: ', x)\n\ndef x2():\n    global x\n    x = x+1\n    print('x2: ', x)\n\nx = 5\nprint('x:  ', x)\nx1()\nx2()\n\n# Output:\n# x:   5\n# x1:  6\n# x2:  7\n \n    ", "date_posted": "2020-11-27 17:41:31Z", "upvote": "\r\n            28\r\n        ", "accepted": "No", "user": {"stack_user_id": "1147688", "name": "not2qubit", "reputation_score": "12.4k"}, "answer_comments": [{"stack_answer_id": "28329600", "stack_answer_comment_id": "114987502", "comment_content": "Congratulations! Finally someone who got the most important point of using ", "user_id": "None"}]}, {"stack_answer_id": "427818", "answer_content": "\r\n You're not actually storing the global in a local variable, just creating a local reference to the same object that your original global reference refers to. Remember that pretty much everything in Python is a name referring to an object, and nothing gets copied in usual operation. \n\n If you didn't have to explicitly specify when an identifier was to refer to a predefined global, then you'd presumably have to explicitly specify when an identifier is a new local variable instead (for example, with something like the 'var' command seen in JavaScript). Since local variables are more common than global variables in any serious and non-trivial system, Python's system makes more sense in most cases. \n\n You  could  have a language which attempted to guess, using a global variable if it existed or creating a local variable if it didn't. However, that would be very error-prone. For example, importing another module could inadvertently introduce a global variable by that name, changing the behaviour of your program. \n    ", "date_posted": "2011-05-30 21:09:51Z", "upvote": "\r\n            26\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "43285234", "answer_content": "\r\n In case you have a local variable with the same name, you might want to use the  globals()  function . \n\n globals()['your_global_var'] = 42\n \n    ", "date_posted": "2017-04-07 19:15:55Z", "upvote": "\r\n            21\r\n        ", "accepted": "No", "user": {"stack_user_id": "562769", "name": "Martin Thoma", "reputation_score": "111k"}, "answer_comments": []}, {"stack_answer_id": "33320055", "answer_content": "\r\n Following on and as an add on, use a file to contain all global variables all declared locally and then  import as : \n\n File  initval.py : \n\n Stocksin = 300\nPrices = []\n \n\n File  getstocks.py : \n\n import initval as iv\n\ndef getmystocks(): \n    iv.Stocksin = getstockcount()\n\n\ndef getmycharts():\n    for ic in range(iv.Stocksin):\n \n    ", "date_posted": "2019-05-21 10:59:46Z", "upvote": "\r\n            18\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "33320055", "stack_answer_comment_id": "75306337", "comment_content": "What is the advantage to move the global variables to another file? Is it just to group together the global variables in a tiny file? And why using the statement ", "user_id": "None"}, {"stack_answer_id": "33320055", "stack_answer_comment_id": "75306618", "comment_content": "Ah... I have finally understood the advantage: No need to use the keyword ", "user_id": "None"}]}, {"stack_answer_id": "34664752", "answer_content": "\r\n Writing to explicit elements of a global array does not apparently need the global declaration, though writing to it \"wholesale\" does have that requirement: \n\n import numpy as np\n\nhostValue = 3.14159\nhostArray = np.array([2., 3.])\nhostMatrix = np.array([[1.0, 0.0],[ 0.0, 1.0]])\n\ndef func1():\n    global hostValue    # mandatory, else local.\n    hostValue = 2.0\n\ndef func2():\n    global hostValue    # mandatory, else UnboundLocalError.\n    hostValue += 1.0\n\ndef func3():\n    global hostArray    # mandatory, else local.\n    hostArray = np.array([14., 15.])\n\ndef func4():            # no need for globals\n    hostArray[0] = 123.4\n\ndef func5():            # no need for globals\n    hostArray[1] += 1.0\n\ndef func6():            # no need for globals\n    hostMatrix[1][1] = 12.\n\ndef func7():            # no need for globals\n    hostMatrix[0][0] += 0.33\n\nfunc1()\nprint \"After func1(), hostValue = \", hostValue\nfunc2()\nprint \"After func2(), hostValue = \", hostValue\nfunc3()\nprint \"After func3(), hostArray = \", hostArray\nfunc4()\nprint \"After func4(), hostArray = \", hostArray\nfunc5()\nprint \"After func5(), hostArray = \", hostArray\nfunc6()\nprint \"After func6(), hostMatrix = \\n\", hostMatrix\nfunc7()\nprint \"After func7(), hostMatrix = \\n\", hostMatrix\n \n    ", "date_posted": "2016-01-08 22:35:22Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "5266381", "name": "Mike Lampton", "reputation_score": "181"}, "answer_comments": []}, {"stack_answer_id": "46058078", "answer_content": "\r\n I'm adding this as I haven't seen it in any of the other answers and it might be useful for someone struggling with something similar. The  globals()  function returns a mutable global symbol dictionary where you can \"magically\" make data available for the rest of your code. \nFor example: \n\n from pickle import load\ndef loaditem(name):\n    with open(r\"C:\\pickle\\file\\location\"+\"\\{}.dat\".format(name), \"rb\") as openfile:\n        globals()[name] = load(openfile)\n    return True\n \n\n and  \n\n from pickle import dump\ndef dumpfile(name):\n    with open(name+\".dat\", \"wb\") as outfile:\n        dump(globals()[name], outfile)\n    return True\n \n\n Will just let you dump/load variables out of and into the global namespace. Super convenient, no muss, no fuss. Pretty sure it's Python 3 only. \n    ", "date_posted": "2019-05-21 12:08:51Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "46058078", "stack_answer_comment_id": "98710279", "comment_content": " always returns globals available in the local context, so a mutation here may not reflect in another module.", "user_id": "None"}]}, {"stack_answer_id": "45769568", "answer_content": "\r\n Reference the class namespace where you want the change to show up.   \n\n In this example, runner is using  max  from the file config. I want my test to change the value of  max  when runner is using it. \n\n main/config.py \n\n max = 15000\n \n\n main/runner.py \n\n from main import config\ndef check_threads():\n    return max < thread_count \n \n\n tests/runner_test.py \n\n from main import runner                # <----- 1. add file\nfrom main.runner import check_threads\nclass RunnerTest(unittest):\n   def test_threads(self):\n       runner.max = 0                  # <----- 2. set global \n       check_threads()\n \n    ", "date_posted": "2017-08-19 08:48:27Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "1303587", "name": "llewellyn falco", "reputation_score": "2,181"}, "answer_comments": []}, {"stack_answer_id": "61992762", "answer_content": "\r\n Globals are fine - Except with Multiprocessing \n\n Globals in connection with multiprocessing on different platforms/envrionments \nas Windows/Mac OS on the one side and Linux on the other are troublesome. \n\n I will show you this with a simple example pointing out a problem which I run into some time ago.  \n\n If you want to understand, why things are different on Windows/MacOs and Linux you \nneed to know that, the default mechanism to start a new process on ... \n\n \n Windows/MacOs is 'spawn' \n Linux is 'fork' \n \n\n They are different in Memory allocation an initialisation ... (but I don't go into this\nhere).  \n\n Let's have a look at the problem/example ... \n\n import multiprocessing\n\ncounter = 0\n\ndef do(task_id):\n    global counter\n    counter +=1\n    print(f'task {task_id}: counter = {counter}')\n\nif __name__ == '__main__':\n\n    pool = multiprocessing.Pool(processes=4)\n    task_ids = list(range(4))\n    pool.map(do, task_ids)\n \n\n Windows \n\n If you run this on Windows (And I suppose on MacOS too), you get the following output ... \n\n task 0: counter = 1\ntask 1: counter = 2\ntask 2: counter = 3\ntask 3: counter = 4\n \n\n Linux \n\n If you run this on Linux, you get the following instead.  \n\n task 0: counter = 1\ntask 1: counter = 1\ntask 2: counter = 1\ntask 3: counter = 1\n \n    ", "date_posted": "2020-05-24 21:41:53Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "6229784", "name": "thomas", "reputation_score": "259"}, "answer_comments": []}, {"stack_answer_id": "63629668", "answer_content": "\r\n There are 2 ways to declare a variable as global: \n 1. assign variable inside functions and use global line \n def declare_a_global_variable():\n    global global_variable_1\n    global_variable_1 = 1\n\n# Note to use the function to global variables\ndeclare_a_global_variable() \n \n 2. assign variable outside functions: \n global_variable_2 = 2\n \n Now we can use these declared global variables in the other functions: \n def declare_a_global_variable():\n    global global_variable_1\n    global_variable_1 = 1\n\n# Note to use the function to global variables\ndeclare_a_global_variable() \nglobal_variable_2 = 2\n\ndef print_variables():\n    print(global_variable_1)\n    print(global_variable_2)\nprint_variables() # prints 1 & 2\n \n Note 1: \n If you want to change a global variable inside another function like  update_variables()  you should use global line in that function before assigning the variable: \n global_variable_1 = 1\nglobal_variable_2 = 2\n\ndef update_variables():\n    global global_variable_1\n    global_variable_1 = 11\n    global_variable_2 = 12 # will update just locally for this function\n\nupdate_variables()\nprint(global_variable_1) # prints 11\nprint(global_variable_2) # prints 2\n \n Note 2: \n There is a exception for note 1 for list and dictionary variables while not using global line inside a function: \n # declaring some global variables\nvariable = 'peter'\nlist_variable_1 = ['a','b']\nlist_variable_2 = ['c','d']\n\ndef update_global_variables():\n    \"\"\"without using global line\"\"\"\n    variable = 'PETER' # won't update in global scope\n    list_variable_1 = ['A','B'] # won't update in global scope\n    list_variable_2[0] = 'C' # updated in global scope surprisingly this way\n    list_variable_2[1] = 'D' # updated in global scope surprisingly this way\n\nupdate_global_variables()\n\nprint('variable is: %s'%variable) # prints peter\nprint('list_variable_1 is: %s'%list_variable_1) # prints ['a', 'b']\nprint('list_variable_2 is: %s'%list_variable_2) # prints ['C', 'D']\n \n    ", "date_posted": "2020-09-12 09:23:03Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "6756530", "name": "Mohsen Haddadi", "reputation_score": "1,198"}, "answer_comments": []}, {"stack_answer_id": "67339244", "answer_content": "\r\n Though this has been answered, I am giving solution again as I prefer single line\nThis is if you wish to create global variable within function \n def someFunc():\n    x=20\n    globals()['y']=50\nsomeFunc() # invoking function so that variable Y is created globally \nprint(y) # output 50\nprint(x) #NameError: name 'x' is not defined as x was defined locally within function\n \n    ", "date_posted": "2021-04-30 19:26:17Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "15132261", "name": "Pavn", "reputation_score": "123"}, "answer_comments": []}, {"stack_answer_id": "71663780", "answer_content": "\r\n global_var = 10  # will be considered as a global variable\n\n\ndef func_1():\n    global global_var  # access variable using variable keyword\n    global_var += 1\n\n\ndef func_2():\n    global global_var\n    global_var *= 2\n    print(f\"func_2: {global_var}\")\n\n\nfunc_1()\nfunc_2()\nprint(\"Global scope:\", global_var) # will print 22\n \n Explanation: \n global_var  is a global variable and all functions and classes can access that variable. \n The  func_1()  accessed that global variable using the keyword  global  which points to the variable which is written in the global scope. If I didn't write the global keyword the variable  global_var  inside  func_1  is considered a local variable that is only usable inside the function. Then inside  func_1 , I have incremented that global variable by 1. \n The same happened in  func_2() . \n After calling  func_1  and  func_2 , you'll see the  global_var  is changed \n    ", "date_posted": "2022-04-04 14:58:25Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "15531189", "name": "SHIVAM SINGH", "reputation_score": "65"}, "answer_comments": [{"stack_answer_id": "71663780", "stack_answer_comment_id": "126780096", "comment_content": " is a global variable and all functions and classes can access that variable.  The func_1() accessed that global variable using the keyword ", "user_id": "None"}]}, {"stack_answer_id": "71074895", "answer_content": "\r\n Like this code: \n myVar = 12\n\ndef myFunc():\n  myVar += 12\n \n Key: \n If you declare a variable outside the strings, it become global. \n If you declare a variable inside the strings, it become local. \n If you want to declare a global variable inside the strings, use the keyword  global  before the variable you want to declare: \n myVar = 124\ndef myFunc():\n  global myVar2\n  myVar2 = 100\nmyFunc()\nprint(myVar2)\n \n and then you have 100 in the document. \n    ", "date_posted": "2022-02-22 09:19:20Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "17754099", "name": "Oscar Nguyen", "reputation_score": "43"}, "answer_comments": []}, {"stack_answer_id": "71883300", "answer_content": "\r\n Initialized = 0  #Here This Initialized is global variable  \n\ndef Initialize():\n     print(\"Initialized!\")\n     Initialized = 1  #This is local variable and assigning 1 to local variable\nwhile Initialized == 0:  \n \n Here we are comparing global variable Initialized that 0, so while loop condition got true \n      Initialize()\n \n Function will get called.Loop will be infinite \n #if we do Initialized=1 then loop will terminate  \n\nelse:\n    print(\"Lets do something else now!\")\n \n    ", "date_posted": "2022-04-15 11:10:50Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "15512418", "name": "zeeshan12396", "reputation_score": "378"}, "answer_comments": []}], "user": {"stack_user_id": "46646", "name": "user46646", "reputation_score": "146k"}, "question_comments": [{"stack_question_id": "423379", "stack_question_comment_id": "129288933", "comment_content": "No matter where you mentioned 'global' before variable name, it can be used anywhere  like normal local variable, once the python read it as with 'global' keyword. But it is a very bad idea to unless the variable is common to the entire project. For example, project_name, database_url", "user_id": "None"}]},
{"stack_question_id": "20625582", "question_title": "How to deal with SettingWithCopyWarning in Pandas", "question_content": "\r\n                Background\nI just upgraded my Pandas from 0.11 to 0.13.0rc1. Now, the application is popping out many new warnings. One of them like this:\nE:\\FinReporter\\FM_EXT.py:449: SettingWithCopyWarning: A value ...\r\n", "question_url": "/questions/20625582/how-to-deal-with-settingwithcopywarning-in-pandas", "date_posted": "Dec 17, 2013 at 3:48", "upvote": "1", "view": "1", "tags": ["python", "pandas", "dataframe", "chained-assignment"], "answers_count": "2", "answers": [{"stack_answer_id": "20627316", "answer_content": "\r\n The  SettingWithCopyWarning  was created to flag potentially confusing \"chained\" assignments, such as the following, which does not always work as expected, particularly when the first selection returns a  copy .  [see  GH5390  and  GH5597  for background discussion.] \n df[df['A'] > 2]['B'] = new_val  # new_val not set in df\n \n The warning offers a suggestion to rewrite as follows: \n df.loc[df['A'] > 2, 'B'] = new_val\n \n However, this doesn't fit your usage, which is equivalent to: \n df = df[df['A'] > 2]\ndf['B'] = new_val\n \n While it's clear that you don't care about writes making it back to the original frame (since you are overwriting the reference to it), unfortunately this pattern cannot be differentiated from the first chained assignment example. Hence the (false positive) warning. The potential for false positives is addressed in the  docs on indexing , if you'd like to read further.  You can safely disable this new warning with the following assignment. \n import pandas as pd\npd.options.mode.chained_assignment = None  # default='warn'\n \n \n Other Resources \n \n pandas User Guide: Indexing and selecting data \n Python Data Science Handbook: Data Indexing and Selection \n Real Python: SettingWithCopyWarning in Pandas: Views vs Copies \n Dataquest: SettingwithCopyWarning: How to Fix This Warning in Pandas \n Towards Data Science: Explaining the SettingWithCopyWarning in pandas \n \n    ", "date_posted": "2022-07-28 19:28:08Z", "upvote": "\r\n            1416\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "7758804", "name": "Trenton McKinney", "reputation_score": "46.5k"}, "answer_comments": [{"stack_answer_id": "20627316", "stack_answer_comment_id": "119156609", "comment_content": "I was using a slice of a dataframe, doing modifications in that slice and was getting this error. I created this slice by doing a ", "user_id": "None"}, {"stack_answer_id": "20627316", "stack_answer_comment_id": "121147727", "comment_content": "How should I deal with ", "user_id": "None"}]}, {"stack_answer_id": "53954986", "answer_content": "\r\n \n How to deal with  SettingWithCopyWarning  in Pandas? \n \n This post is meant for readers who, \n \n Would like to understand what this warning means \n Would like to understand different ways of suppressing this warning \n Would like to understand how to improve their code and follow good practices to avoid this warning in the future. \n \n Setup \n np.random.seed(0)\ndf = pd.DataFrame(np.random.choice(10, (3, 5)), columns=list('ABCDE'))\ndf\n   A  B  C  D  E\n0  5  0  3  3  7\n1  9  3  5  2  4\n2  7  6  8  8  1\n \n \n What is the  SettingWithCopyWarning ? \n To know how to deal with this warning, it is important to understand what it means and why it is raised in the first place. \n When filtering DataFrames, it is possible slice/index a frame to return either a  view , or a  copy , depending on the internal layout and various implementation details. A \"view\" is, as the term suggests, a view into the original data, so modifying the view may modify the original object. On the other hand, a \"copy\" is a replication of data from the original, and modifying the copy has no effect on the original. \n As mentioned by other answers, the  SettingWithCopyWarning  was created to flag \"chained assignment\" operations. Consider  df  in the setup above. Suppose you would like to select all values in column \"B\" where values in column \"A\" is > 5. Pandas allows you to do this in different ways, some more correct than others. For example, \n df[df.A > 5]['B']\n \n1    3\n2    6\nName: B, dtype: int64\n \n And, \n df.loc[df.A > 5, 'B']\n\n1    3\n2    6\nName: B, dtype: int64\n \n These return the same result, so if you are only reading these values, it makes no difference. So, what is the issue? The problem with chained assignment, is that it is generally difficult to predict whether a view or a copy is returned,  so this largely becomes an issue when you are attempting to assign values back.  To build on the earlier example, consider how this code is executed by the interpreter: \n df.loc[df.A > 5, 'B'] = 4\n# becomes\ndf.__setitem__((df.A > 5, 'B'), 4)\n \n With a single  __setitem__  call to  df . OTOH, consider this code: \n df[df.A > 5]['B'] = 4\n# becomes\ndf.__getitem__(df.A > 5).__setitem__('B', 4)\n \n Now, depending on whether  __getitem__  returned a view or a copy, the  __setitem__  operation  may not work . \n In general, you should use  loc  for label-based assignment, and  iloc  for integer/positional based assignment, as the spec guarantees that they always operate on the original. Additionally, for setting a single cell, you should use  at  and  iat . \n More can be found in the  documentation . \n \n Note \nAll boolean indexing operations done with  loc  can also be done with  iloc . The only difference is that  iloc  expects either\nintegers/positions for index or a numpy array of boolean values, and\ninteger/position indexes for the columns. \n For example, \n df.loc[df.A > 5, 'B'] = 4\n \n Can be written nas \n df.iloc[(df.A > 5).values, 1] = 4\n \n And, \n df.loc[1, 'A'] = 100\n \n Can be written as \n df.iloc[1, 0] = 100\n \n And so on. \n \n \n Just tell me how to suppress the warning! \n Consider a simple operation on the \"A\" column of  df . Selecting \"A\" and dividing by 2 will raise the warning, but the operation will work. \n df2 = df[['A']]\ndf2['A'] /= 2\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/__main__.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\ndf2\n     A\n0  2.5\n1  4.5\n2  3.5\n \n There are a couple ways of directly silencing this warning: \n \n (recommended)  Use  loc  to slice subsets : \n  df2 = df.loc[:, ['A']]\n df2['A'] /= 2     # Does not raise \n \n \n Change  pd.options.mode.chained_assignment \nCan be set to  None ,  \"warn\" , or  \"raise\" .  \"warn\"  is the default.  None  will suppress the warning entirely, and  \"raise\"  will throw a  SettingWithCopyError , preventing the operation from going through. \n  pd.options.mode.chained_assignment = None\n df2['A'] /= 2\n \n \n Make a  deepcopy \n  df2 = df[['A']].copy(deep=True)\n df2['A'] /= 2\n \n \n \n @Peter Cotton  in the comments, came up with a nice way of non-intrusively changing the mode (modified from  this gist ) using a context manager, to set the mode only as long as it is required, and the reset it back to the original state when finished. \n \n class ChainedAssignent:\n    def __init__(self, chained=None):\n        acceptable = [None, 'warn', 'raise']\n        assert chained in acceptable, \"chained must be in \" + str(acceptable)\n        self.swcw = chained\n\n    def __enter__(self):\n        self.saved_swcw = pd.options.mode.chained_assignment\n        pd.options.mode.chained_assignment = self.swcw\n        return self\n\n    def __exit__(self, *args):\n        pd.options.mode.chained_assignment = self.saved_swcw\n \n \n The usage is as follows: \n # some code here\nwith ChainedAssignent():\n    df2['A'] /= 2\n# more code follows\n \n Or, to raise the exception \n with ChainedAssignent(chained='raise'):\n    df2['A'] /= 2\n\nSettingWithCopyError: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n \n \n The \"XY Problem\": What am I doing wrong? \n A lot of the time, users attempt to look for ways of suppressing this exception without fully understanding why it was raised in the first place. This is a good example of an  XY problem , where users attempt to solve a problem \"Y\" that is actually a symptom of a deeper rooted problem \"X\". Questions will be raised based on common problems that encounter this warning, and solutions will then be presented. \n \n Question 1 \nI have a DataFrame \n df\n       A  B  C  D  E\n    0  5  0  3  3  7\n    1  9  3  5  2  4\n    2  7  6  8  8  1\n \n I want to assign values in col \"A\" > 5 to 1000. My expected output is \n       A  B  C  D  E\n0     5  0  3  3  7\n1  1000  3  5  2  4\n2  1000  6  8  8  1\n \n \n Wrong way to do this: \n df.A[df.A > 5] = 1000         # works, because df.A returns a view\ndf[df.A > 5]['A'] = 1000      # does not work\ndf.loc[df.A > 5]['A'] = 1000   # does not work\n \n Right way using  loc : \n df.loc[df.A > 5, 'A'] = 1000\n \n \n \n Question 2 1 \nI am trying to set the value in cell (1, 'D') to 12345. My expected output is \n    A  B  C      D  E\n0  5  0  3      3  7\n1  9  3  5  12345  4\n2  7  6  8      8  1\n \n I have tried different ways of accessing this cell, such as\n df['D'][1] . What is the best way to do this? \n 1. This question isn't specifically related to the warning, but\nit is good to understand how to do this particular operation correctly\nso as to avoid situations where the warning could potentially arise in\nfuture. \n \n You can use any of the following methods to do this. \n df.loc[1, 'D'] = 12345\ndf.iloc[1, 3] = 12345\ndf.at[1, 'D'] = 12345\ndf.iat[1, 3] = 12345\n \n \n \n Question 3 \nI am trying to subset values based on some condition. I have a\nDataFrame \n    A  B  C  D  E\n1  9  3  5  2  4\n2  7  6  8  8  1\n \n I would like to assign values in \"D\" to 123 such that \"C\" == 5. I\ntried \n df2.loc[df2.C == 5, 'D'] = 123\n \n Which seems fine but I am  still  getting the\n SettingWithCopyWarning ! How do I fix this? \n \n This is actually probably because of code higher up in your pipeline. Did you create  df2  from something larger, like \n df2 = df[df.A > 5]\n \n ? In this case, boolean indexing will return a view, so  df2  will reference the original. What you'd need to do is assign  df2  to a  copy : \n df2 = df[df.A > 5].copy()\n# Or,\n# df2 = df.loc[df.A > 5, :]\n \n \n \n Question 4 \nI'm trying to drop column \"C\" in-place from \n \n \n    A  B  C  D  E\n1  9  3  5  2  4\n2  7  6  8  8  1\n \n But using \n df2.drop('C', axis=1, inplace=True)\n \n Throws  SettingWithCopyWarning . Why is this happening? \n \n This is because  df2  must have been created as a view from some other slicing operation, such as \n df2 = df[df.A > 5]\n \n The solution here is to either make a  copy()  of  df , or use  loc , as before. \n\n    ", "date_posted": "2021-11-07 08:54:25Z", "upvote": "\r\n            691\r\n        ", "accepted": "No", "user": {"stack_user_id": "155137", "name": "Martijn Courteaux", "reputation_score": "66k"}, "answer_comments": [{"stack_answer_id": "53954986", "stack_answer_comment_id": "97716054", "comment_content": "P.S.: Let me know if your situation is not covered under section 3's list of questions. I will amend my post.", "user_id": "None"}, {"stack_answer_id": "53954986", "stack_answer_comment_id": "113259726", "comment_content": "I think it would be helpful for Question 2 to link to a question addressing the differences between loc, iloc, at, and iat.  You are probably more aware of such a question than I am, but I'm happy to seek one if it would be helpful.", "user_id": "None"}, {"stack_answer_id": "53954986", "stack_answer_comment_id": "113259845", "comment_content": " address the case where you want to use loc and iloc at the same time, iloc for rows and loc for columns", "user_id": "None"}, {"stack_answer_id": "53954986", "stack_answer_comment_id": "114720974", "comment_content": "@cs95: Could you add  an XY description around the case where you are trying to create a new column based on simple math operations on an existing one. As in df['new_col'] = df['old_col']/2. Where 'new_col' does not yet exist. Thx", "user_id": "None"}, {"stack_answer_id": "53954986", "stack_answer_comment_id": "114723885", "comment_content": "@BryanP unless I'm mistaken that should more or less be covered under the \"Just tell me how to suppress the warning!\" section.", "user_id": "None"}]}, {"stack_answer_id": "20644369", "answer_content": "\r\n In general the point of the  SettingWithCopyWarning  is to show users (and especially new users) that they  may  be operating on a copy and not the original as they think. There  are  false positives (IOW if you know what you are doing it could be  ok ). One possibility is simply to turn off the (by default  warn ) warning as @Garrett suggest. \n\n Here is another option: \n\n In [1]: df = DataFrame(np.random.randn(5, 2), columns=list('AB'))\n\nIn [2]: dfa = df.ix[:, [1, 0]]\n\nIn [3]: dfa.is_copy\nOut[3]: True\n\nIn [4]: dfa['A'] /= 2\n/usr/local/bin/ipython:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_index,col_indexer] = value instead\n  #!/usr/local/bin/python\n \n\n You can set the  is_copy  flag to  False , which will effectively turn off the check,  for that object : \n\n In [5]: dfa.is_copy = False\n\nIn [6]: dfa['A'] /= 2\n \n\n If you explicitly copy then no further warning will happen: \n\n In [7]: dfa = df.ix[:, [1, 0]].copy()\n\nIn [8]: dfa['A'] /= 2\n \n\n The code the OP is showing above, while legitimate, and probably something I do as well, is technically a case for this warning, and not a false positive. Another way to  not  have the warning would be to do the selection operation via  reindex , e.g. \n\n quote_df = quote_df.reindex(columns=['STK', ...])\n \n\n Or,  \n\n quote_df = quote_df.reindex(['STK', ...], axis=1)  # v.0.21\n \n    ", "date_posted": "2018-11-09 19:23:22Z", "upvote": "\r\n            170\r\n        ", "accepted": "No", "user": {"stack_user_id": "1840471", "name": "Max Ghenis", "reputation_score": "13.3k"}, "answer_comments": [{"stack_answer_id": "20644369", "stack_answer_comment_id": "119840558", "comment_content": "I think it's an understatement to say that there are false positives. I don't think I've ever had this warning help me, and the number of times I've had it clog up my output is insane. It's also bad programming practice: if you start ignoring the warnings in your output because you know they are pure rubbish, you can start to miss real problems. It's also annoying to have to turn off the same warnings all the time.", "user_id": "None"}]}, {"stack_answer_id": "40214434", "answer_content": "\r\n Pandas dataframe copy warning \n When you go and do something like this: \n quote_df = quote_df.ix[:,[0,3,2,1,4,5,8,9,30,31]]\n \n pandas.ix   in this case  returns a new, stand alone dataframe. \n Any values you decide to change in this dataframe, will not change the original dataframe. \n This is what pandas tries to warn you about. \n \n Why  .ix  is a bad idea \n The  .ix  object tries to do more than one thing, and for anyone who has read anything about clean code, this is a strong smell. \n Given this dataframe: \n df = pd.DataFrame({\"a\": [1,2,3,4], \"b\": [1,1,2,2]})\n \n Two behaviors: \n dfcopy = df.ix[:,[\"a\"]]\ndfcopy.a.ix[0] = 2\n \n Behavior one:  dfcopy  is now a stand alone dataframe. Changing it will not change  df \n df.ix[0, \"a\"] = 3\n \n Behavior two: This changes the original dataframe. \n \n Use  .loc  instead \n The pandas developers recognized that the  .ix  object was quite smelly[speculatively] and thus created two new objects which helps in the accession and assignment of data. (The other being  .iloc ) \n .loc  is faster, because it does not try to create a copy of the data. \n .loc  is meant to modify your existing dataframe inplace, which is more memory efficient. \n .loc  is predictable, it has one behavior. \n \n The solution \n What you are doing in your code example is loading a big file with lots of columns, then modifying it to be smaller. \n The  pd.read_csv  function can help you out with a lot of this and also make the loading of the file a lot faster. \n So instead of doing this \n quote_df = pd.read_csv(StringIO(str_of_all), sep=',', names=list('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefg')) #dtype={'A': object, 'B': object, 'C': np.float64}\nquote_df.rename(columns={'A':'STK', 'B':'TOpen', 'C':'TPCLOSE', 'D':'TPrice', 'E':'THigh', 'F':'TLow', 'I':'TVol', 'J':'TAmt', 'e':'TDate', 'f':'TTime'}, inplace=True)\nquote_df = quote_df.ix[:,[0,3,2,1,4,5,8,9,30,31]]\n \n Do this \n columns = ['STK', 'TPrice', 'TPCLOSE', 'TOpen', 'THigh', 'TLow', 'TVol', 'TAmt', 'TDate', 'TTime']\ndf = pd.read_csv(StringIO(str_of_all), sep=',', usecols=[0,3,2,1,4,5,8,9,30,31])\ndf.columns = columns\n \n This will only read the columns you are interested in, and name them properly. No need for using the evil  .ix  object to do magical stuff. \n    ", "date_posted": "2020-06-20 09:12:55Z", "upvote": "\r\n            47\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}, {"stack_answer_id": "54914752", "answer_content": "\r\n Here I answer the question directly. How to deal with it? \n\n Make a  .copy(deep=False)  after you slice. See  pandas.DataFrame.copy . \n\n Wait, doesn't a slice return a copy? After all, this is what the warning message is attempting to say? Read the long answer: \n\n import pandas as pd\ndf = pd.DataFrame({'x':[1,2,3]})\n \n\n This gives a warning: \n\n df0 = df[df.x>2]\ndf0['foo'] = 'bar'\n \n\n This does not: \n\n df1 = df[df.x>2].copy(deep=False)\ndf1['foo'] = 'bar'\n \n\n Both  df0  and  df1  are  DataFrame  objects, but something about them is different that enables pandas to print the warning. Let's find out what it is. \n\n import inspect\nslice= df[df.x>2]\nslice_copy = df[df.x>2].copy(deep=False)\ninspect.getmembers(slice)\ninspect.getmembers(slice_copy)\n \n\n Using your diff tool of choice, you will see that beyond a couple of addresses, the only material difference is this: \n\n |          | slice   | slice_copy |\n| _is_copy | weakref | None       |\n \n\n The method that decides whether to warn is  DataFrame._check_setitem_copy  which checks  _is_copy . So here you go. Make a  copy  so that your DataFrame is not  _is_copy . \n\n The warning is suggesting to use  .loc , but if you use  .loc  on a frame that  _is_copy , you will still get the same warning. Misleading? Yes. Annoying? You bet. Helpful? Potentially, when chained assignment is used. But it cannot correctly detect chain assignment and prints the warning indiscriminately. \n    ", "date_posted": "2019-05-24 18:36:09Z", "upvote": "\r\n            47\r\n        ", "accepted": "No", "user": {"stack_user_id": "443854", "name": "user443854", "reputation_score": "6,574"}, "answer_comments": [{"stack_answer_id": "54914752", "stack_answer_comment_id": "119747857", "comment_content": "Good sleuthing.  FWIW I also found that ", "user_id": "None"}, {"stack_answer_id": "54914752", "stack_answer_comment_id": "124723865", "comment_content": "This answer surely deserves a separate badge for writing style.", "user_id": "None"}, {"stack_answer_id": "54914752", "stack_answer_comment_id": "125406269", "comment_content": "Hands-down the most concrete and direct answer to the question. Very well put.", "user_id": "None"}]}, {"stack_answer_id": "56507986", "answer_content": "\r\n This topic is really confusing with Pandas. Luckily, it has a relatively simple solution. \n The problem is that it is not always clear whether data filtering operations (e.g. loc) return a copy or a view of the DataFrame. Further use of such filtered DataFrame could therefore be confusing. \n The simple solution is (unless you need to work with very large sets of data): \n Whenever you need to update any values, always make sure that you explicitly copy the DataFrame before the assignment. \n df  # Some DataFrame\ndf = df.loc[:, 0:2]  # Some filtering (unsure whether a view or copy is returned)\ndf = df.copy()  # Ensuring a copy is made\ndf[df[\"Name\"] == \"John\"] = \"Johny\"  # Assignment can be done now (no warning)\n \n    ", "date_posted": "2020-12-09 17:57:58Z", "upvote": "\r\n            29\r\n        ", "accepted": "No", "user": {"stack_user_id": "832230", "name": "Asclepius", "reputation_score": "51.5k"}, "answer_comments": [{"stack_answer_id": "56507986", "stack_answer_comment_id": "115403288", "comment_content": "For large datasets you can make a shallow (deep=False) copy. Still it seems too much to suppress a warning.", "user_id": "None"}]}, {"stack_answer_id": "60885847", "answer_content": "\r\n I had been getting this issue with  .apply()  when assigning a new dataframe from a pre-existing dataframe on which i've used the  .query()  method. For instance: \n\n prop_df = df.query('column == \"value\"')\nprop_df['new_column'] = prop_df.apply(function, axis=1)\n \n\n Would return this error. The fix that seems to resolve the error in this case is by changing this to: \n\n prop_df = df.copy(deep=True)\nprop_df = prop_df.query('column == \"value\"')\nprop_df['new_column'] = prop_df.apply(function, axis=1)\n \n\n However, this is NOT efficient especially when using large dataframes, due to having to make a new copy. \n\n If you're using the  .apply()  method in generating a new column and its values, a fix that resolves the error and is more efficient is by adding  .reset_index(drop=True) : \n\n prop_df = df.query('column == \"value\"').reset_index(drop=True)\nprop_df['new_column'] = prop_df.apply(function, axis=1)\n \n    ", "date_posted": "2020-03-27 12:46:02Z", "upvote": "\r\n            18\r\n        ", "accepted": "No", "user": {"stack_user_id": "3604584", "name": "Zilbert97", "reputation_score": "442"}, "answer_comments": []}, {"stack_answer_id": "45361923", "answer_content": "\r\n To remove any doubt, my solution was to make a deep copy of the slice instead of a regular copy.\nThis may not be applicable depending on your context (Memory constraints / size of the slice, potential for performance degradation - especially if the copy occurs in a loop like it did for me, etc...) \n To be clear, here is the warning I received: \n /opt/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:54:\nSettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame\nSee the caveats in the documentation:\nhttp://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n \n Illustration \n I had doubts that the warning was thrown because of a column I was dropping on a copy of the slice. While not technically trying to set a value in the copy of the slice, that was still a modification of the copy of the slice.\nBelow are the (simplified) steps I have taken to confirm the suspicion, I hope it will help those of us who are trying to understand the warning. \n Example 1: dropping a column on the original affects the copy \n We knew that already but this is a healthy reminder. This is  NOT  what the warning is about. \n >> data1 = {'A': [111, 112, 113], 'B':[121, 122, 123]}\n>> df1 = pd.DataFrame(data1)\n>> df1\n\n    A   B\n0   111 121\n1   112 122\n2   113 123\n\n\n>> df2 = df1\n>> df2\n\nA   B\n0   111 121\n1   112 122\n2   113 123\n\n# Dropping a column on df1 affects df2\n>> df1.drop('A', axis=1, inplace=True)\n>> df2\n    B\n0   121\n1   122\n2   123\n \n It is possible to avoid changes made on df1 to affect df2. Note: you can avoid importing  copy.deepcopy  by doing  df.copy()  instead. \n >> data1 = {'A': [111, 112, 113], 'B':[121, 122, 123]}\n>> df1 = pd.DataFrame(data1)\n>> df1\n\nA   B\n0   111 121\n1   112 122\n2   113 123\n\n>> import copy\n>> df2 = copy.deepcopy(df1)\n>> df2\nA   B\n0   111 121\n1   112 122\n2   113 123\n\n# Dropping a column on df1 does not affect df2\n>> df1.drop('A', axis=1, inplace=True)\n>> df2\n    A   B\n0   111 121\n1   112 122\n2   113 123\n \n Example 2: dropping a column on the copy may affect the original \n This actually illustrates the warning. \n >> data1 = {'A': [111, 112, 113], 'B':[121, 122, 123]}\n>> df1 = pd.DataFrame(data1)\n>> df1\n\n    A   B\n0   111 121\n1   112 122\n2   113 123\n\n>> df2 = df1\n>> df2\n\n    A   B\n0   111 121\n1   112 122\n2   113 123\n\n# Dropping a column on df2 can affect df1\n# No slice involved here, but I believe the principle remains the same?\n# Let me know if not\n>> df2.drop('A', axis=1, inplace=True)\n>> df1\n\nB\n0   121\n1   122\n2   123\n \n It is possible to avoid changes made on df2 to affect df1 \n >> data1 = {'A': [111, 112, 113], 'B':[121, 122, 123]}\n>> df1 = pd.DataFrame(data1)\n>> df1\n\n    A   B\n0   111 121\n1   112 122\n2   113 123\n\n>> import copy\n>> df2 = copy.deepcopy(df1)\n>> df2\n\nA   B\n0   111 121\n1   112 122\n2   113 123\n\n>> df2.drop('A', axis=1, inplace=True)\n>> df1\n\nA   B\n0   111 121\n1   112 122\n2   113 123\n \n Cheers! \n    ", "date_posted": "2021-02-05 19:57:52Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "5009287", "name": "Raphvanns", "reputation_score": "1,536"}, "answer_comments": []}, {"stack_answer_id": "69595276", "answer_content": "\r\n For me worked: \n import pandas as pd\n# ...\npd.set_option('mode.chained_assignment', None)\n \n    ", "date_posted": "2021-10-16 11:43:25Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "13947931", "name": "mikolaj semeniuk", "reputation_score": "1,288"}, "answer_comments": []}, {"stack_answer_id": "49190903", "answer_content": "\r\n This should work: \n\n quote_df.loc[:,'TVol'] = quote_df['TVol']/TVOL_SCALE\n \n    ", "date_posted": "2018-03-09 09:48:49Z", "upvote": "\r\n            10\r\n        ", "accepted": "No", "user": {"stack_user_id": "1315131", "name": "jrouquie", "reputation_score": "4,255"}, "answer_comments": []}, {"stack_answer_id": "56183831", "answer_content": "\r\n Some may want to simply suppress the warning: \n\n class SupressSettingWithCopyWarning:\n    def __enter__(self):\n        pd.options.mode.chained_assignment = None\n\n    def __exit__(self, *args):\n        pd.options.mode.chained_assignment = 'warn'\n\nwith SupressSettingWithCopyWarning():\n    #code that produces warning\n \n    ", "date_posted": "2019-05-17 09:47:34Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "7027346", "name": "delica", "reputation_score": "1,557"}, "answer_comments": []}, {"stack_answer_id": "54664893", "answer_content": "\r\n Followup beginner question / remark \n\n Maybe a clarification for other beginners like me (I come from R which seems to work a bit differently under the hood). The following harmless-looking and functional code kept producing the SettingWithCopy warning, and I couldn't figure out why. I had both read and understood the issued with \"chained indexing\", but my code doesn't contain any: \n\n def plot(pdb, df, title, **kw):\n    df['target'] = (df['ogg'] + df['ugg']) / 2\n    # ...\n \n\n But then, later, much too late, I looked at where the plot() function is called: \n\n     df = data[data['anz_emw'] > 0]\n    pixbuf = plot(pdb, df, title)\n \n\n So \"df\" isn't a data frame but an object that somehow remembers that it was created by indexing a data frame (so is that a view?) which would make the line in plot() \n\n  df['target'] = ...\n \n\n equivalent to \n\n  data[data['anz_emw'] > 0]['target'] = ...\n \n\n which is a chained indexing. Did I get that right? \n\n Anyway,  \n\n def plot(pdb, df, title, **kw):\n    df.loc[:,'target'] = (df['ogg'] + df['ugg']) / 2\n \n\n fixed it. \n    ", "date_posted": "2019-02-13 07:39:54Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "9940188", "name": "musbur", "reputation_score": "499"}, "answer_comments": [{"stack_answer_id": "54664893", "stack_answer_comment_id": "117318843", "comment_content": "A tad late to the party, but the ", "user_id": "None"}, {"stack_answer_id": "54664893", "stack_answer_comment_id": "117864677", "comment_content": "This explanation was the only one that got through to me (maybe because I'm also coming from R). Thanks!", "user_id": "None"}]}, {"stack_answer_id": "60040464", "answer_content": "\r\n As this question is already fully explained and discussed in existing answers I will just provide a neat  pandas  approach to the context manager using  pandas.option_context  (links to  docs  and  example ) - there is absolutely no need to create a custom class with all the dunder methods and other bells and whistles. \n\n First the context manager code itself: \n\n from contextlib import contextmanager\n\n@contextmanager\ndef SuppressPandasWarning():\n    with pd.option_context(\"mode.chained_assignment\", None):\n        yield\n \n\n Then an example: \n\n import pandas as pd\nfrom string import ascii_letters\n\na = pd.DataFrame({\"A\": list(ascii_letters[0:4]), \"B\": range(0,4)})\n\nmask = a[\"A\"].isin([\"c\", \"d\"])\n# Even shallow copy below is enough to not raise the warning, but why is a mystery to me.\nb = a.loc[mask]  # .copy(deep=False)\n\n# Raises the `SettingWithCopyWarning`\nb[\"B\"] = b[\"B\"] * 2\n\n# Does not!\nwith SuppressPandasWarning():\n    b[\"B\"] = b[\"B\"] * 2\n \n\n Worth noticing is that both approches do not modify  a , which is a bit surprising to me, and even a shallow df copy with  .copy(deep=False)  would prevent this warning to be raised (as far as I understand shallow copy should at least modify  a  as well, but it doesn't.  pandas  magic.). \n    ", "date_posted": "2020-02-03 13:41:12Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "4272484", "name": "m-dz", "reputation_score": "2,282"}, "answer_comments": []}, {"stack_answer_id": "46732545", "answer_content": "\r\n You could avoid the whole problem like this, I believe: \n\n return (\n    pd.read_csv(StringIO(str_of_all), sep=',', names=list('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefg')) #dtype={'A': object, 'B': object, 'C': np.float64}\n    .rename(columns={'A':'STK', 'B':'TOpen', 'C':'TPCLOSE', 'D':'TPrice', 'E':'THigh', 'F':'TLow', 'I':'TVol', 'J':'TAmt', 'e':'TDate', 'f':'TTime'}, inplace=True)\n    .ix[:,[0,3,2,1,4,5,8,9,30,31]]\n    .assign(\n        TClose=lambda df: df['TPrice'],\n        RT=lambda df: 100 * (df['TPrice']/quote_df['TPCLOSE'] - 1),\n        TVol=lambda df: df['TVol']/TVOL_SCALE,\n        TAmt=lambda df: df['TAmt']/TAMT_SCALE,\n        STK_ID=lambda df: df['STK'].str.slice(13,19),\n        STK_Name=lambda df: df['STK'].str.slice(21,30)#.decode('gb2312'),\n        TDate=lambda df: df.TDate.map(lambda x: x[0:4]+x[5:7]+x[8:10]),\n    )\n)\n \n\n Using Assign. From the  documentation : Assign new columns to a DataFrame, returning a new object (a copy) with all the original columns in addition to the new ones.  \n\n See Tom Augspurger's article on method chaining in pandas:  https://tomaugspurger.github.io/method-chaining \n    ", "date_posted": "2018-01-16 21:27:38Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "6238102", "name": "Halee", "reputation_score": "473"}, "answer_comments": []}, {"stack_answer_id": "44731898", "answer_content": "\r\n If you have assigned the slice to a variable and want to set using the variable as in the following: \n\n df2 = df[df['A'] > 2]\ndf2['B'] = value\n \n\n And you do not want to use Jeffs solution because your condition computing  df2  is to long or for some other reason, then you can use the following: \n\n df.loc[df2.index.tolist(), 'B'] = value\n \n\n df2.index.tolist()  returns the indices from all entries in df2, which will then be used to set column B in the original dataframe. \n    ", "date_posted": "2017-06-24 01:30:48Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "2128832", "name": "Steohan", "reputation_score": "446"}, "answer_comments": [{"stack_answer_id": "44731898", "stack_answer_comment_id": "88721524", "comment_content": "this is 9 time more expensive then df[\"B\"] = value", "user_id": "None"}, {"stack_answer_id": "44731898", "stack_answer_comment_id": "91880924", "comment_content": "Can you explain this more deeply @ClaudiuCreanga?", "user_id": "None"}]}, {"stack_answer_id": "70545685", "answer_content": "\r\n this might apply to numpy only, which means you might need to import it,  but the data i used for my examples numpy was not essential with the calculations, but you can simply stop this settingwithcopy warning message, by using this 1 Line of Code below, \n np.warnings.filterwarnings('ignore')\n \n    ", "date_posted": "2021-12-31 21:12:04Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "5315363", "name": "Calculate", "reputation_score": "171"}, "answer_comments": [{"stack_answer_id": "70545685", "stack_answer_comment_id": "127376857", "comment_content": "This one is the best one! Thanks. The copy warning is really annoying!", "user_id": "None"}]}, {"stack_answer_id": "47507827", "answer_content": "\r\n For me this issue occured in a following >simplified< example. And I was also able to solve it (hopefully with a correct solution): \n\n old code with warning: \n\n def update_old_dataframe(old_dataframe, new_dataframe):\n    for new_index, new_row in new_dataframe.iterrorws():\n        old_dataframe.loc[new_index] = update_row(old_dataframe.loc[new_index], new_row)\n\ndef update_row(old_row, new_row):\n    for field in [list_of_columns]:\n        # line with warning because of chain indexing old_dataframe[new_index][field]\n        old_row[field] = new_row[field]  \n    return old_row\n \n\n This printed the warning for the line  old_row[field] = new_row[field] \n\n Since the rows in update_row method are actually type  Series , I replaced the line with: \n\n old_row.at[field] = new_row.at[field]\n \n\n i.e.  method  for accessing/lookups for a  Series . Eventhough both works just fine and the result is same, this way I don't have to disable the warnings (=keep them for other chain indexing issues somewhere else). \n\n I hope this may help someone. \n    ", "date_posted": "2017-11-27 09:39:57Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "7920758", "name": "Petr Szturc", "reputation_score": "784"}, "answer_comments": []}, {"stack_answer_id": "68362289", "answer_content": "\r\n I was facing the same warning, while I executed this  part of my code: \n     def scaler(self, numericals):\n        scaler = MinMaxScaler()\n        self.data.loc[:, numericals[0]] = scaler.fit_transform(self.data.loc[:, numericals[0]])\n        self.data.loc[:, numericals[1]] = scaler.fit_transform(self.data.loc[:, numericals[1]])\n \n which  scaler  is a MinMaxScaler and  numericals[0]   contains names of 3 of my numerical columns.\nthe  warning was removed as I changed the code to: \n     def scaler(self, numericals):\n        scaler = MinMaxScaler()\n        self.data.loc[:][numericals[0]] = scaler.fit_transform(self.data.loc[:][numericals[0]])\n        self.data.loc[:][numericals[1]] = scaler.fit_transform(self.data.loc[:][numericals[1]])\n \n So, Just change  [:, ~]  to  [:][~] \n    ", "date_posted": "2021-07-13 12:19:16Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "13046916", "name": "mossishahi", "reputation_score": "68"}, "answer_comments": []}, {"stack_answer_id": "71089974", "answer_content": "\r\n In my case, I would create a new column based on the index but I got this warning as you: \n df_temp[\"Quarter\"] = df_temp.index.quarter\n \n I use insert() instead of direct assignment and it works for me: \n df_temp.insert(loc=0, column='Quarter', value=df_temp.index.quarter)\n \n    ", "date_posted": "2022-02-12 07:54:18Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "16733101", "name": "Phoenix", "reputation_score": "2,121"}, "answer_comments": []}, {"stack_answer_id": "69558039", "answer_content": "\r\n Just create a copy of your dataframe(s) using  .copy()  method before the warning appears, to remove all of your warnings. This happens because we do not want to make changes to the original quote_df. In other words, we do not want to play with the reference of the object of the quote_df which we have created for quote_df. \n quote_df = quote_df.copy()\n \n    ", "date_posted": "2021-10-13 15:13:50Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "3874009", "name": "Vaibhav Hiwase", "reputation_score": "171"}, "answer_comments": [{"stack_answer_id": "69558039", "stack_answer_comment_id": "124723905", "comment_content": "This is needlessly a deep copy (default option is ", "user_id": "None"}]}], "user": {"stack_user_id": "1072888", "name": "bigbug", "reputation_score": "50.9k"}, "question_comments": [{"stack_question_id": "20625582", "stack_question_comment_id": "62589711", "comment_content": "Here's a context manager to temporarily set the warning level ", "user_id": "None"}, {"stack_question_id": "20625582", "stack_question_comment_id": "88200031", "comment_content": " official document explain in detail", "user_id": "None"}, {"stack_question_id": "20625582", "stack_question_comment_id": "95242599", "comment_content": "@leonprou ", "user_id": "None"}, {"stack_question_id": "20625582", "stack_question_comment_id": "112079428", "comment_content": "Using ", "user_id": "None"}, {"stack_question_id": "20625582", "stack_question_comment_id": "121588951", "comment_content": "Does this answer your question? ", "user_id": "None"}]},
{"stack_question_id": "48054321", "question_title": "Of the many findElement(s)/By functions in Selenium, when would you use one over the other?", "question_content": "\r\n                Selenium includes findElement functions, like so... \n\n.find_element_by_\n\nid\nlink_text\npartial_link_text\nname\nclass_name\ntag_name\ncss_selector\nxpath\r\nIt's apparent that some are limited by design due ...\r\n", "question_url": "/questions/48054321/of-the-many-findelements-by-functions-in-selenium-when-would-you-use-one-over", "date_posted": "Jan 2, 2018 at 0:20", "upvote": "0", "view": "1", "tags": ["python", "python-3.x", "selenium", "selenium-webdriver", "css-selectors"], "answers_count": "2", "answers": [{"stack_answer_id": "48067003", "answer_content": "\r\n In my experience  CSS  is the preferable selector because it can be concise, is well documented and web developers are likely to have more experience and exposure to it. \n\n id ,  name ,  tag_name  and  class_name  can all be easily reproduced with simple CSS so I would avoid explicitly using those. \n\n e.g.  \n\n id  ;  #my_id \n\n name ;  [name=\"my_name\"] \n\n tag_name ;  my_tag \n\n class_name ;  .my_class \n\n The use of  XPath  is often much maligned; labeled as slow and unstable.  However I disagree with this view point. \n\n When I interview people I cringe when they say they avoid Xpath because it is slow and brittle. The speed is no longer a concern, and xpath is only as brittle as the person who wrote it.  However, I prefer the syntax of CSS Selectors so that is why I would choose over XPath for the majority of use cases. \n\n There are 3 scenarios in which XPath is the better choice; \n\n \n Multiple CSS Selectors may be replaced with one XPath query (e.g find element then iterate through sub elements can be performed in one xpath) \n XPath can select based on Text where as CSS Selector cannot \n XPath allows you walk up the DOM Tree which can be really useful if you can only identify a control by its child \n \n\n I would always avoid selecting by text if possible, but if I had to, I would prefer to use XPath over the built in  Link Text  and  Partial Link Text  methods because the Xpath query woudl allow me to be more expressive and allow me to select more than just anchor tags. \n\n Finally, once gotcha when using XPath is that \"class\" is treated as a literal string rather than an array of class names as supported in CSS selectors; \n\n HTML: <div class=\"ab cd\">\n\nCSS matches: div.ab\nCSS matches: div.cd\nCSS matches: div.cd.ab\nCSS matches: div.ab.cd\n\nXPath matches: //div[@class=\"ab cd\"]\nXPath matches: //div[contains(@class, \"ab\")]\nXPath matches: //div[contains(@class, \"cd\")]\nXPath matches: //div[contains(@class, \"ab\") and contains(@class, \"cd\")]\n\nXPath DOES NOT match: //div[@class=\"cd\"]\nXPath DOES NOT match: //div[@class=\"ab\"]\nXPath DOES NOT match: //div[@class=\"cd ab\"]\n \n    ", "date_posted": "2018-01-04 14:30:37Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "1644596", "name": "Robbie Wareham", "reputation_score": "3,277"}, "answer_comments": [{"stack_answer_id": "48067003", "stack_answer_comment_id": "83188957", "comment_content": "Hmm, this was a very interesting read. I appreciate the info! When you say that xpath is only as brittle as the person who wrote it, how would I know if i'm using the correct path or not(assuming this is the weak point)?", "user_id": "6402048"}, {"stack_answer_id": "48067003", "stack_answer_comment_id": "83202051", "comment_content": "There is no \"correct path\" for xpath, but that is true for CSS Selectors too.  As an example take this page and your signature image.  The following XPATH would work;  //body/div[3]/div[1]/div[1]/div[1]/div[2]/div[1]/table/tbody/tr[1]/td[2]/div[1]/table[1]/tbody/tr/td[2]/div[1]/div[2]/a/div/img  It would find your image everytime BUT if there was a small change in the HTML layout, it could easily break.  I would call this a brittle XPATH.  It is important to appreciate that I could just as easily write this in CSS just as bad!", "user_id": "None"}, {"stack_answer_id": "48067003", "stack_answer_comment_id": "83202157", "comment_content": "A better xpath could be '//div[contains(@class, \"question\")]//a[@href=\"/users/6402048/matt-i\"]//img'.  This will more resilient to structural changes.  NB. In this case I would probably use CSS as it could be clearer; '.question a[href=\"/users/6402048/matt-i\"] >img'  However, to create the Xpath (or indeed CSS selctor) you need to understand the AUT and what your are trying to test", "user_id": "None"}, {"stack_answer_id": "48067003", "stack_answer_comment_id": "86132359", "comment_content": "@MattI Feel free to mark this as an answer if you think it addresses your question", "user_id": "None"}]}, {"stack_answer_id": "48056120", "answer_content": "\r\n This question have been asked and answered in numerous forums in different formats. Considering them all if we prioritize the locators the list would be as follows : \n \n id : Select element with the specified  id  attribute. \n name : Select first element with the specified  name  attribute. \n link_text : Select link (anchor tag) element which contains  text  matching the specified  LinkText . \n partial_link_text : Select link (anchor tag) element which contains  text  matching the specified  PartialLinkText . \n tag_name : Locate Element using a  Tag Name . \n class_name : Locate Element using a  ClassName . \n css_selector : Select the element using  CssSelectors . \n xpath : Locate an element using an  XPath  expression. \n \n So the question now is  Whats New ? \n The answer is  Selenium have evolved a lot recently .  WebDriver  is now a  W3C Recommendation Candidate . Things within  Selenium  are changing pretty fast. It's no more only about choosing the locator. We need to use a locator which will : \n \n Uniquely identify an element . \n The performance of the locator must be optimized. \n \n Keeping these two factors in mind, the best strategy would be to  Mock the DOM . The  W3C Recommendation Candidate  does mentions the list of the locators as per the below : \n \n So the verdict is clear and concise. \n    ", "date_posted": "2021-03-08 12:47:05Z", "upvote": "\r\n            4\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "7429447", "name": "undetected Selenium", "reputation_score": "160k"}, "answer_comments": [{"stack_answer_id": "48056120", "stack_answer_comment_id": "83088740", "comment_content": "Obviously you have not read my question correctly. I know what these functions do, but i'm wondering why one would choose one over the other. Would there be a certain instance where xpaths would be more beneficial to use than css_selector, and vice versa.", "user_id": "6402048"}, {"stack_answer_id": "48056120", "stack_answer_comment_id": "83088832", "comment_content": "Definitely you haven't read the full verbatim of my ", "user_id": "None"}, {"stack_answer_id": "48056120", "stack_answer_comment_id": "83089044", "comment_content": "I did read it, but that line doesn't specify anything. All you did was post what each tag does and some info that barely gets into what i'm looking for.   How about this. When you go to a web page and inspect the HTML doc, when would you want to use xpath over css_selector, or vice versa? Is one more stable than the other, in terms of clicking the elements that I so desire to click on?", "user_id": "6402048"}, {"stack_answer_id": "48056120", "stack_answer_comment_id": "83089358", "comment_content": "Stability depends on how effectively you write the automation code which I have detailed out in my Answer. To achieve the optimum performance I did provide you the sequential options starting with ", "user_id": "None"}]}], "user": {"stack_user_id": "6402048", "name": "Matt I", "reputation_score": "155"}, "question_comments": [{"stack_question_id": "48054321", "stack_question_comment_id": "83081056", "comment_content": "I use the function whichever gives me ", "user_id": "None"}, {"stack_question_id": "48054321", "stack_question_comment_id": "83081163", "comment_content": "This discussion might be relevant: ", "user_id": "None"}, {"stack_question_id": "48054321", "stack_question_comment_id": "83082781", "comment_content": "I pretty much only use xpaths if I need to find something by text, or if the only way to find the element I want is to find another element, traverse back up the dom tree to some shared element, and then back down to the element I want. In my experience css selectors end up being cleaner and easier to read. You'll find people arguing that xpaths are also slower, but in practice you'll probably not notice a difference.", "user_id": "None"}, {"stack_question_id": "48054321", "stack_question_comment_id": "83092905", "comment_content": "@Matt Yes, mostly they are unique. If I see id, I use findelementbyid; if that's missing, I use xpath/CSS selector. I do however have trust issues with findelementbyclass, as class names can be used in multiple places. I don't worry about performance in the beginning, will chose the easy path. If performance is bad, only then I think about optimization. Hope it helps!", "user_id": "None"}, {"stack_question_id": "48054321", "stack_question_comment_id": "83104090", "comment_content": "@MattI let's say you have a bunch of similar looking rows that all have some button in it you want to click. There is no way to directly uniquely get the button you want because all the rows have similar buttons with similar attributes. However, there is some other element in the row that is unique. So I could get that element, traverse back up the dom tree to get the row that contains it, and back down to get the button using xpath.", "user_id": "None"}]},
{"stack_question_id": "1680528", "question_title": "How to avoid having class data shared among instances?", "question_content": "\r\n                What I want is this behavior:\n\nclass a:\n    list = []\n\nx = a()\ny = a()\n\nx.list.append(1)\ny.list.append(2)\nx.list.append(3)\ny.list.append(4)\n\nprint(x.list) # prints [1, 3]\nprint(y.list) # prints [2, 4]\r...\r\n", "question_url": "/questions/1680528/how-to-avoid-having-class-data-shared-among-instances", "date_posted": "Nov 5, 2009 at 13:19", "upvote": "1", "view": "3", "tags": ["python", "class"], "answers_count": "7", "answers": [{"stack_answer_id": "1680555", "answer_content": "\r\n You want this: \n\n class a:\n    def __init__(self):\n        self.list = []\n \n\n Declaring the variables inside the class declaration makes them \"class\" members and not instance members. Declaring them inside the  __init__  method makes sure that a new instance of the members is created alongside every new instance of the object, which is the behavior you're looking for. \n    ", "date_posted": "2009-11-05 13:28:53Z", "upvote": "\r\n            175\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "573", "name": "abyx", "reputation_score": "66.6k"}, "answer_comments": [{"stack_answer_id": "1680555", "stack_answer_comment_id": "1554819", "comment_content": "An added clarification: if you were to reassign the list property in one of the instances, it would not affect the others. So if you did something like ", "user_id": "None"}, {"stack_answer_id": "1680555", "stack_answer_comment_id": "48776247", "comment_content": "But why does this happens only for list? When i declared an integer or string outside the ", "user_id": "None"}, {"stack_answer_id": "1680555", "stack_answer_comment_id": "57726690", "comment_content": "@AmalTs It looks like you don't understand how assignment in python works. See ", "user_id": "None"}, {"stack_answer_id": "1680555", "stack_answer_comment_id": "57727008", "comment_content": "@AmalTs Note: it's considered a bad practice to use class attributes as \"lazy\" default values for instance attributes. Even if the attributes are of an immutable type it's better to assign them inside ", "user_id": "None"}, {"stack_answer_id": "1680555", "stack_answer_comment_id": "119016248", "comment_content": "I \"wow\" more every day I program in Python.", "user_id": "None"}]}, {"stack_answer_id": "15590354", "answer_content": "\r\n The accepted answer works but a little more explanation does not hurt.  \n\n Class attributes do not become instance attributes when an instance is created. They become instance attributes when a value is assigned to them. \n\n In the original code no value is assigned to  list  attribute after instantiation; so it remains a class attribute. Defining list inside  __init__  works because  __init__  is called after instantiation. Alternatively, this code would also produce the desired output: \n\n >>> class a:\n    list = []\n\n>>> y = a()\n>>> x = a()\n>>> x.list = []\n>>> y.list = []\n>>> x.list.append(1)\n>>> y.list.append(2)\n>>> x.list.append(3)\n>>> y.list.append(4)\n>>> print(x.list)\n[1, 3]\n>>> print(y.list)\n[2, 4]\n \n\n However, the confusing scenario in the question will never happen to immutable objects such as numbers and strings, because their value cannot be changed without assignment. For example a code similar to the original with string attribute type works without any problem: \n\n >>> class a:\n    string = ''\n\n\n>>> x = a()\n>>> y = a()\n>>> x.string += 'x'\n>>> y.string += 'y'\n>>> x.string\n'x'\n>>> y.string\n'y'\n \n\n So to summarize:  class attributes become instance attributes if and only if a value is assigned to them after instantiation, being in the  __init__  method or not . This is a good thing because this way you can have static attributes if you never assign a value to an attribute after instantiation. \n    ", "date_posted": "2013-03-23 18:12:40Z", "upvote": "\r\n            27\r\n        ", "accepted": "No", "user": {"stack_user_id": "1988148", "name": "jurgenreza", "reputation_score": "5,606"}, "answer_comments": [{"stack_answer_id": "15590354", "stack_answer_comment_id": "123884694", "comment_content": "I know this is an old answer, but... disagree with ", "user_id": "None"}]}, {"stack_answer_id": "41683345", "answer_content": "\r\n Although the accepted anwer is spot on, I would like to add a bit description. \n\n Let's do a small exercise  \n\n first of all define a class as follows: \n\n class A:\n    temp = 'Skyharbor'\n\n    def __init__(self, x):\n        self.x = x\n\n    def change(self, y):\n        self.temp = y\n \n\n So what do we have here? \n\n \n We have a very simple class which has an attribute  temp  which is a string \n An  __init__  method which sets  self.x   \n A change method sets  self.temp \n \n\n Pretty straight forward so far yeah? Now let's start playing around with this class. Let's initialize  this class first: \n\n a = A('Tesseract')\n \n\n Now do the following: \n\n >>> print(a.temp)\nSkyharbor\n>>> print(A.temp)\nSkyharbor\n \n\n Well,  a.temp  worked as expected but how the hell did  A.temp  work? Well it worked because temp is a class attribute. Everything in python is an object. Here A is also an object of class  type . Thus the attribute temp is an attribute held by the  A  class and if you change the value of temp through  A  (and not through an instance of  a ), the changed value is going to be reflected in all the instance of  A  class.\nLet's go ahead and do that: \n\n >>> A.temp = 'Monuments'\n>>> print(A.temp)\nMonuments\n>>> print(a.temp)\nMonuments\n \n\n Interesting isn't it? And  note that  id(a.temp)  and  id(A.temp)  are still the same . \n\n Any Python object is automatically given a  __dict__  attribute, which contains its list of attributes. Let's investigate what this dictionary contains for our example objects: \n\n >>> print(A.__dict__)\n{\n    'change': <function change at 0x7f5e26fee6e0>,\n    '__module__': '__main__',\n    '__init__': <function __init__ at 0x7f5e26fee668>,\n    'temp': 'Monuments',\n    '__doc__': None\n}\n>>> print(a.__dict__)\n{x: 'Tesseract'}\n \n\n Note that  temp  attribute is listed among  A  class's attributes while  x  is listed for the instance. \n\n So how come that we get a defined value of  a.temp  if it is not even listed for the instance  a . Well that's the magic of  __getattribute__()  method. In Python the dotted syntax automatically invokes this method so when we write  a.temp , Python executes  a.__getattribute__('temp') . That method performs the attribute lookup action, i.e. finds the value of the attribute by looking in different places. \n\n The standard implementation of  __getattribute__()  searches first the internal dictionary ( dict ) of an object, then the type of the object itself. In this case  a.__getattribute__('temp')  executes first  a.__dict__['temp']  and then  a.__class__.__dict__['temp'] \n\n Okay now let's use our  change  method: \n\n >>> a.change('Intervals')\n>>> print(a.temp)\nIntervals\n>>> print(A.temp)\nMonuments\n \n\n Well now that we have used  self ,  print(a.temp)  gives us a different value from  print(A.temp) .  \n\n Now if we compare  id(a.temp)  and  id(A.temp) , they will be different. \n    ", "date_posted": "2019-02-15 11:34:35Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "1222951", "name": "Aran-Fey", "reputation_score": "36.4k"}, "answer_comments": []}, {"stack_answer_id": "1680545", "answer_content": "\r\n You declared \"list\" as a \"class level property\" and not \"instance level property\".  In order to have properties scoped at the instance level, you need to initialize them through referencing with the \"self\" parameter in the  __init__  method (or elsewhere depending on the situation). \n\n You don't strictly have to initialize the instance properties in the  __init__  method but it makes for easier understanding. \n    ", "date_posted": "2009-11-05 13:27:29Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "171461", "name": "jldupont", "reputation_score": "89.2k"}, "answer_comments": []}, {"stack_answer_id": "21492237", "answer_content": "\r\n So nearly every response here seems to miss a particular point.  Class variables  never  become instance variables as demonstrated by the code below.  By utilizing a metaclass to intercept variable assignment at the class level, we can see that when a.myattr is reassigned, the field assignment magic method on the class is not called.  This is because the assignment  creates a new instance variable .  This behavior has  absolutely nothing  to do with the class variable as demonstrated by the second class which has no class variables and yet still allows field assignment. \n\n class mymeta(type):\n    def __init__(cls, name, bases, d):\n        pass\n\n    def __setattr__(cls, attr, value):\n        print(\"setting \" + attr)\n        super(mymeta, cls).__setattr__(attr, value)\n\nclass myclass(object):\n    __metaclass__ = mymeta\n    myattr = []\n\na = myclass()\na.myattr = []           #NOTHING IS PRINTED\nmyclass.myattr = [5]    #change is printed here\nb = myclass()\nprint(b.myattr)         #pass through lookup on the base class\n\nclass expando(object):\n    pass\n\na = expando()\na.random = 5            #no class variable required\nprint(a.random)         #but it still works\n \n\n IN SHORT  Class variables have NOTHING to do with instance variables. \n\n More clearly  They just happen to be in the scope for lookups on instances. Class variables are in fact  instance variables  on the class object itself.  You can also have  metaclass variables  if you want as well because metaclasses themselves are objects too.  Everything is an object whether it is used to create other objects or not, so do not get bound up in the semantics of other languages usage of the word class.  In python, a class is really just an object that is used to determine how to create other objects and what their behaviors will be.  Metaclasses are classes that create classes, just to further illustrate this point.  \n    ", "date_posted": "2014-01-31 23:52:55Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "2735812", "name": "TheQabalist", "reputation_score": "51"}, "answer_comments": []}, {"stack_answer_id": "1680581", "answer_content": "\r\n Yes you must declare in the \"constructor\" if you want that the list becomes an object property and not a class property. \n    ", "date_posted": "2009-11-05 13:27:04Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "201847", "name": "osanchezmon", "reputation_score": "544"}, "answer_comments": []}, {"stack_answer_id": "51728891", "answer_content": "\r\n To protect your variable shared by other instance you need to create new instance variable each time you create an instance. When you are declaring a variable inside a class it's class variable and shared by all instance. If you want to make it for instance wise need to use the  init  method to reinitialize the variable as  refer to the instance   \n\n From  Python Objects and Class  by Programiz.com : \n\n \n   __init__()  function. This special function gets called whenever a new object of that class is instantiated. \n  \n   This type of function is also called constructors in Object Oriented\n  Programming (OOP). We normally use it to initialize all the variables. \n \n\n For example: \n\n class example:\n    list=[] #This is class variable shared by all instance\n    def __init__(self):\n        self.list = [] #This is instance variable referred to specific instance\n \n    ", "date_posted": "2018-08-24 16:24:57Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "100297", "name": "Martijn Pieters", "reputation_score": "979k"}, "answer_comments": []}], "user": {"stack_user_id": "150564", "name": "8steve8", "reputation_score": "2,173"}, "question_comments": [{"stack_question_id": "1680528", "stack_question_comment_id": "48173061", "comment_content": "Please, do not use ", "user_id": "None"}]},
{"stack_question_id": "36921951", "question_title": "Truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()", "question_content": "\r\n                I want to filter my dataframe with an or condition to keep rows with a particular column's values that are outside the range [-0.25, 0.25]. I tried:\ndf = df[(df['col'] < -0.25) or (df['col'] > 0....\r\n", "question_url": "/questions/36921951/truth-value-of-a-series-is-ambiguous-use-a-empty-a-bool-a-item-a-any-o", "date_posted": "Apr 28, 2016 at 17:46", "upvote": "7", "view": "1", "tags": ["python", "pandas", "dataframe", "boolean", "filtering"], "answers_count": "1", "answers": [{"stack_answer_id": "36922103", "answer_content": "\r\n The  or  and  and  python statements require  truth -values. For  pandas , these are considered ambiguous so you should use \"bitwise\"  |  (or) or  &  (and) operations: \n df = df[(df['col'] < -0.25) | (df['col'] > 0.25)]\n \n These are overloaded for these kinds of data structures to yield the element-wise  or  or  and . \n \n Just to add some more explanation to this statement: \n The exception is thrown when you want to get the  bool  of a  pandas.Series : \n >>> import pandas as pd\n>>> x = pd.Series([1])\n>>> bool(x)\nValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n \n What you hit was a place where the operator  implicitly  converted the operands to  bool  (you used  or  but it also happens for  and ,  if  and  while ): \n >>> x or x\nValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n>>> x and x\nValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n>>> if x:\n...     print('fun')\nValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n>>> while x:\n...     print('fun')\nValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n \n Besides these 4 statements there are several python functions that hide some  bool  calls (like  any ,  all ,  filter , ...) these are normally not problematic with  pandas.Series  but for completeness I wanted to mention these. \n \n In your case, the exception isn't really helpful, because it doesn't mention the  right alternatives . For  and  and  or , if you want element-wise comparisons, you can use: \n \n numpy.logical_or : \n   >>> import numpy as np\n  >>> np.logical_or(x, y)\n \n or simply the  |  operator: \n   >>> x | y\n \n \n numpy.logical_and : \n   >>> np.logical_and(x, y)\n \n or simply the  &  operator: \n   >>> x & y\n \n \n \n If you're using the operators, then be sure to set your parentheses correctly because of  operator precedence . \n There are  several logical numpy functions  which  should  work on  pandas.Series . \n \n The alternatives mentioned in the Exception are more suited if you encountered it when doing  if  or  while . I'll shortly explain each of these: \n \n If you want to check if your Series is  empty : \n   >>> x = pd.Series([])\n  >>> x.empty\n  True\n  >>> x = pd.Series([1])\n  >>> x.empty\n  False\n \n Python normally interprets the  len gth of containers (like  list ,  tuple , ...) as truth-value if it has no explicit boolean interpretation. So if you want the python-like check, you could do:  if x.size  or  if not x.empty  instead of  if x . \n \n If your  Series  contains  one and only one  boolean value: \n   >>> x = pd.Series([100])\n  >>> (x > 50).bool()\n  True\n  >>> (x < 50).bool()\n  False\n \n \n If you want to check the  first and only item  of your Series (like  .bool()  but works even for not boolean contents): \n   >>> x = pd.Series([100])\n  >>> x.item()\n  100\n \n \n If you want to check if  all  or  any  item is not-zero, not-empty or not-False: \n   >>> x = pd.Series([0, 1, 2])\n  >>> x.all()   # because one element is zero\n  False\n  >>> x.any()   # because one (or more) elements are non-zero\n  True\n \n \n \n    ", "date_posted": "2022-05-31 16:32:35Z", "upvote": "\r\n            981\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": []}, {"stack_answer_id": "57897625", "answer_content": "\r\n Well pandas use bitwise  &   |  and each condition should be wrapped in a  () \n For example following works \n data_query = data[(data['year'] >= 2005) & (data['year'] <= 2010)]\n \n But the same query without proper brackets does not \n data_query = data[(data['year'] >= 2005 & data['year'] <= 2010)]\n \n    ", "date_posted": "2020-10-14 15:37:22Z", "upvote": "\r\n            105\r\n        ", "accepted": "No", "user": {"stack_user_id": "7403431", "name": "Stefan", "reputation_score": "1,427"}, "answer_comments": [{"stack_answer_id": "57897625", "stack_answer_comment_id": "122452906", "comment_content": "Wonderful, the only answer mentioning the importance of wrapping conditions in parenthesis. The only problem with my syntax. But why is this mandatory?", "user_id": "None"}, {"stack_answer_id": "57897625", "stack_answer_comment_id": "123087979", "comment_content": "Yes, wrapping with parens was the key!", "user_id": "None"}]}, {"stack_answer_id": "36922486", "answer_content": "\r\n For boolean logic, use  &  and  | . \n np.random.seed(0)\ndf = pd.DataFrame(np.random.randn(5,3), columns=list('ABC'))\n\n>>> df\n          A         B         C\n0  1.764052  0.400157  0.978738\n1  2.240893  1.867558 -0.977278\n2  0.950088 -0.151357 -0.103219\n3  0.410599  0.144044  1.454274\n4  0.761038  0.121675  0.443863\n\n>>> df.loc[(df.C > 0.25) | (df.C < -0.25)]\n          A         B         C\n0  1.764052  0.400157  0.978738\n1  2.240893  1.867558 -0.977278\n3  0.410599  0.144044  1.454274\n4  0.761038  0.121675  0.443863\n \n To see what is happening, you get a column of booleans for each comparison, e.g. \n df.C > 0.25\n0     True\n1    False\n2    False\n3     True\n4     True\nName: C, dtype: bool\n \n When you have multiple criteria, you will get multiple columns returned.  This is why the join logic is ambiguous.  Using  and  or  or  treats each column separately, so you first need to reduce that column to a single boolean value.  For example, to see if any value or all values in each of the columns is True. \n # Any value in either column is True?\n(df.C > 0.25).any() or (df.C < -0.25).any()\nTrue\n\n# All values in either column is True?\n(df.C > 0.25).all() or (df.C < -0.25).all()\nFalse\n \n One convoluted way to achieve the same thing is to zip all of these columns together, and perform the appropriate logic. \n >>> df[[any([a, b]) for a, b in zip(df.C > 0.25, df.C < -0.25)]]\n          A         B         C\n0  1.764052  0.400157  0.978738\n1  2.240893  1.867558 -0.977278\n3  0.410599  0.144044  1.454274\n4  0.761038  0.121675  0.443863\n \n For more details, refer to  Boolean Indexing  in the docs. \n    ", "date_posted": "2020-08-27 20:44:10Z", "upvote": "\r\n            61\r\n        ", "accepted": "No", "user": {"stack_user_id": "2430549", "name": "HoldOffHunger", "reputation_score": "16.2k"}, "answer_comments": []}, {"stack_answer_id": "41736427", "answer_content": "\r\n Or, alternatively, you could use Operator module. More detailed information is here  Python docs \n\n import operator\nimport numpy as np\nimport pandas as pd\nnp.random.seed(0)\ndf = pd.DataFrame(np.random.randn(5,3), columns=list('ABC'))\ndf.loc[operator.or_(df.C > 0.25, df.C < -0.25)]\n\n          A         B         C\n0  1.764052  0.400157  0.978738\n1  2.240893  1.867558 -0.977278\n3  0.410599  0.144044  1.454274\n4  0.761038  0.121675  0.4438\n \n    ", "date_posted": "2017-01-19 07:48:25Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "2464237", "name": "C\u1ea3nh To\u00e0n Nguy\u1ec5n", "reputation_score": "440"}, "answer_comments": []}, {"stack_answer_id": "47073907", "answer_content": "\r\n This excellent answer  explains very well what is happening and provides a solution. I would like to add another solution that might be suitable in similar cases: using the  query  method: \n df = df.query(\"(col > 0.25) or (col < -0.25)\")\n \n See also  http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-query . \n (Some tests with a dataframe I'm currently working with suggest that this method is a bit slower than using the bitwise operators on series of booleans: 2 ms vs. 870 \u00b5s) \n A piece of warning : At least one situation where this is not straightforward is when column names happen to be python expressions. I had columns named  WT_38hph_IP_2 ,  WT_38hph_input_2  and  log2(WT_38hph_IP_2/WT_38hph_input_2)  and wanted to perform the following query:  \"(log2(WT_38hph_IP_2/WT_38hph_input_2) > 1) and (WT_38hph_IP_2 > 20)\" \n I obtained the following exception cascade: \n \n KeyError: 'log2' \n UndefinedVariableError: name 'log2' is not defined \n ValueError: \"log2\" is not a supported function \n \n I guess this happened because the query parser was trying to make something from the first two columns instead of identifying the expression with the name of the third column. \n A possible workaround is proposed  here . \n    ", "date_posted": "2022-03-30 05:01:29Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": []}, {"stack_answer_id": "71956180", "answer_content": "\r\n This is quite a common question for beginners when making multiple conditions in Pandas. Generally speaking, there are two possible conditions causing this error: \n Condition 1: Python Operator Precedence \n There is a paragraph of  Boolean indexing | Indexing and selecting data \u2014 pandas documentation  explains this \n \n Another common operation is the use of boolean vectors to filter the data. The operators are:  |  for  or ,  &  for  and , and  ~  for  not . These  must  be grouped by using  parentheses . \n By default Python will evaluate an expression such as  df['A'] > 2 & df['B'] < 3  as  df['A'] > (2 & df['B']) < 3 , while the desired evaluation order is  (df['A'] > 2) & (df['B'] < 3) . \n \n # Wrong\ndf['col'] < -0.25 | df['col'] > 0.25\n\n# Right\n(df['col'] < -0.25) | (df['col'] > 0.25)\n \n There are some possible ways to get rid off the parentheses, I will cover this later. \n \n Condition 2: Improper Operator/Statement \n As is explained in previous quotation, you need use  |  for  or ,  &  for  and , and  ~  for  not \n # Wrong\n(df['col'] < -0.25) or (df['col'] > 0.25)\n\n# Right\n(df['col'] < -0.25) | (df['col'] > 0.25)\n \n \n Another possible situation is that you are using a boolean Series in  if  statement. \n # Wrong\nif pd.Series([True, False]):\n    pass\n \n It's clear that Python  if  statement accepts boolean like expression rather than Pandas Series. You should use  pandas.Series.any  or methods listed in the error message to convert the Series to a value according to your need. \n For example: \n # Right\nif df['col'].eq(0).all():\n    # If you want all column values equal to zero\n    print('do something')\n\n# Right\nif df['col'].eq(0).any():\n    # If you want at least one column value equal to zero\n    print('do something')\n \n \n Let's talk about ways to escape the parentheses in the first situation. \n \n Use Pandas mathematical functions \n \n Pandas has defined a lot of mathematical functions including comparison as follows: \n \n pandas.Series.lt()  for  less than ; \n pandas.Series.gt()  for  greater than ; \n pandas.Series.le()  for  less and equal ; \n pandas.Series.ge()  for  greater and equal ; \n pandas.Series.ne()  for  not equal ; \n pandas.Series.eq()  for  equal ; \n \n As a result, you can use \n df = df[(df['col'] < -0.25) | (df['col'] > 0.25)]\n\n# is equal to\n\ndf = df[df['col'].lt(-0.25) | df['col'].gt(0.25)]\n \n \n Use  pandas.Series.between() \n \n If you want to select rows in between two values, you can use  pandas.Series.between \n \n df['col].between(left, right)  is equal to  \n (left <= df['col']) & (df['col'] <= right) ; \n df['col].between(left, right, inclusive='left)  is equal to  \n (left <= df['col']) & (df['col'] < right) ; \n df['col].between(left, right, inclusive='right')  is equal to  \n (left < df['col']) & (df['col'] <= right) ; \n df['col].between(left, right, inclusive='neither')  is equal to  \n (left < df['col']) & (df['col'] < right) ; \n \n df = df[(df['col'] > -0.25) & (df['col'] < 0.25)]\n\n# is equal to\n\ndf = df[df['col'].between(-0.25, 0.25, inclusive='neither')]\n \n \n Use  pandas.DataFrame.query() \n \n Document referenced before has a chapter  The  query()  Method  explains this well. \n pandas.DataFrame.query()  can help you select a DataFrame with a condition string. Within the query string, you can use both bitwise operators( &  and  | ) and their boolean cousins( and  and  or ). Moreover, you can omit the parentheses, but I don't recommend for readable reason. \n df = df[(df['col'] < -0.25) | (df['col'] > 0.25)]\n\n# is equal to\n\ndf = df.query('col < -0.25 or col > 0.25')\n \n \n Use  pandas.DataFrame.eval() \n \n pandas.DataFrame.eval()  evaluates a string describing operations on DataFrame columns. Thus, we can use this method to build our multiple condition. The syntax is same with  pandas.DataFrame.query() . \n df = df[(df['col'] < -0.25) | (df['col'] > 0.25)]\n\n# is equal to\n\ndf = df[df.eval('col < -0.25 or col > 0.25')]\n \n pandas.DataFrame.query()  and  pandas.DataFrame.eval()  can do more things than I describe here, you are recommended to read their documentation and have fun with them. \n    ", "date_posted": "2022-05-14 05:47:41Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "10315163", "name": "Ynjxsjmh", "reputation_score": "22.9k"}, "answer_comments": []}, {"stack_answer_id": "69256931", "answer_content": "\r\n If you have more than one value: \n df['col'].all()\n \n If its only a single value: \n df['col'].item()\n \n    ", "date_posted": "2022-03-30 05:01:04Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": []}, {"stack_answer_id": "68258741", "answer_content": "\r\n I was getting error in this command: \n if df != '':\n    pass\n \n But it worked when I changed it to this: \n if df is not '':\n    pass\n \n    ", "date_posted": "2022-04-17 02:42:29Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "6153082", "name": "Mehdi Rostami", "reputation_score": "119"}, "answer_comments": []}, {"stack_answer_id": "62929797", "answer_content": "\r\n You need to use bitwise operators  |  instead of  or  and  &  instead of  and  in pandas, you can't simply use the bool statements from python. \n \nFor much complex filtering create a  mask  and apply the mask on the dataframe. \nPut all your query in the mask and apply it. \nSuppose, \n mask = (df[\"col1\"]>=df[\"col2\"]) & (stock[\"col1\"]<=df[\"col2\"])\ndf_new = df[mask]\n \n    ", "date_posted": "2020-07-16 07:39:08Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "11534375", "name": "Hemanth Kollipara", "reputation_score": "692"}, "answer_comments": []}, {"stack_answer_id": "64504183", "answer_content": "\r\n I'll try to give the benchmark of the three most common way (also mentioned above): \n from timeit import repeat\n\nsetup = \"\"\"\nimport numpy as np;\nimport random;\nx = np.linspace(0,100);\nlb, ub = np.sort([random.random() * 100, random.random() * 100]).tolist()\n\"\"\"\nstmts = 'x[(x > lb) * (x <= ub)]', 'x[(x > lb) & (x <= ub)]', 'x[np.logical_and(x > lb, x <= ub)]'\n\nfor _ in range(3):\n    for stmt in stmts:\n        t = min(repeat(stmt, setup, number=100_000))\n        print('%.4f' % t, stmt)\n    print()\n \n result: \n 0.4808 x[(x > lb) * (x <= ub)]\n0.4726 x[(x > lb) & (x <= ub)]\n0.4904 x[np.logical_and(x > lb, x <= ub)]\n\n0.4725 x[(x > lb) * (x <= ub)]\n0.4806 x[(x > lb) & (x <= ub)]\n0.5002 x[np.logical_and(x > lb, x <= ub)]\n\n0.4781 x[(x > lb) * (x <= ub)]\n0.4336 x[(x > lb) & (x <= ub)]\n0.4974 x[np.logical_and(x > lb, x <= ub)]\n \n But,  *  is not supported in Panda Series, and NumPy Array is faster than pandas data frame (arround 1000 times slower, see number): \n from timeit import repeat\n\nsetup = \"\"\"\nimport numpy as np;\nimport random;\nimport pandas as pd;\nx = pd.DataFrame(np.linspace(0,100));\nlb, ub = np.sort([random.random() * 100, random.random() * 100]).tolist()\n\"\"\"\nstmts = 'x[(x > lb) & (x <= ub)]', 'x[np.logical_and(x > lb, x <= ub)]'\n\nfor _ in range(3):\n    for stmt in stmts:\n        t = min(repeat(stmt, setup, number=100))\n        print('%.4f' % t, stmt)\n    print()\n \n result: \n 0.1964 x[(x > lb) & (x <= ub)]\n0.1992 x[np.logical_and(x > lb, x <= ub)]\n\n0.2018 x[(x > lb) & (x <= ub)]\n0.1838 x[np.logical_and(x > lb, x <= ub)]\n\n0.1871 x[(x > lb) & (x <= ub)]\n0.1883 x[np.logical_and(x > lb, x <= ub)]\n \n Note: adding one line of code  x = x.to_numpy()  will need about 20 \u00b5s. \n For those who prefer  %timeit : \n import numpy as np\nimport random\nlb, ub = np.sort([random.random() * 100, random.random() * 100]).tolist()\nlb, ub\nx = pd.DataFrame(np.linspace(0,100))\n\ndef asterik(x):\n    x = x.to_numpy()\n    return x[(x > lb) * (x <= ub)]\n\ndef and_symbol(x):\n    x = x.to_numpy()\n    return x[(x > lb) & (x <= ub)]\n\ndef numpy_logical(x):\n    x = x.to_numpy()\n    return x[np.logical_and(x > lb, x <= ub)]\n\nfor i in range(3):\n    %timeit asterik(x)\n    %timeit and_symbol(x)\n    %timeit numpy_logical(x)\n    print('\\n')\n \n result: \n 23 \u00b5s \u00b1 3.62 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\n35.6 \u00b5s \u00b1 9.53 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n31.3 \u00b5s \u00b1 8.9 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n\n\n21.4 \u00b5s \u00b1 3.35 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\n21.9 \u00b5s \u00b1 1.02 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n21.7 \u00b5s \u00b1 500 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n\n\n25.1 \u00b5s \u00b1 3.71 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n36.8 \u00b5s \u00b1 18.3 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n28.2 \u00b5s \u00b1 5.97 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\n \n    ", "date_posted": "2020-10-23 16:49:37Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "11671779", "name": "Muhammad Yasirroni", "reputation_score": "779"}, "answer_comments": []}, {"stack_answer_id": "61719230", "answer_content": "\r\n I encountered the same error and got stalled with a pyspark dataframe for few days,  I was able to resolve it successfully by filling na values with 0  since I was comparing integer values from 2 fields. \n    ", "date_posted": "2020-05-10 21:54:06Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "7901426", "name": "iretex", "reputation_score": "43"}, "answer_comments": []}, {"stack_answer_id": "64277449", "answer_content": "\r\n One minor thing, which wasted my time. \n Put the conditions(if comparing using \" = \", \" != \") in parenthesis, failing to do so also raises this exception.\nThis will work \n df[(some condition) conditional operator (some conditions)]\n \n This will not \n df[some condition conditional-operator some condition]\n \n    ", "date_posted": "2020-10-09 09:37:01Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "8486505", "name": "satinder singh", "reputation_score": "160"}, "answer_comments": []}], "user": {"stack_user_id": "6267003", "name": "obabs", "reputation_score": "7,611"}, "question_comments": [{"stack_question_id": "36921951", "stack_question_comment_id": "61405699", "comment_content": "use ", "user_id": "None"}, {"stack_question_id": "36921951", "stack_question_comment_id": "94761896", "comment_content": "Here's a workaround: ", "user_id": "None"}, {"stack_question_id": "36921951", "stack_question_comment_id": "96891030", "comment_content": "Related: ", "user_id": "None"}, {"stack_question_id": "36921951", "stack_question_comment_id": "116738206", "comment_content": "I ran into the same error message using the standard ", "user_id": "None"}]},
{"stack_question_id": "1436703", "question_title": "What is the difference between __str__ and __repr__?", "question_content": "\r\n                What is the difference between __str__ and __repr__ in Python?\r\n", "question_url": "/questions/1436703/what-is-the-difference-between-str-and-repr", "date_posted": "Sep 17, 2009 at 4:27", "upvote": "3", "view": "8", "tags": ["python", "magic-methods", "repr"], "answers_count": "2", "answers": [{"stack_answer_id": "2626364", "answer_content": "\r\n Alex  summarized well but, surprisingly, was too succinct. \n First, let me reiterate the main points in  Alex\u2019s post : \n \n The default implementation is useless (it\u2019s hard to think of one which wouldn\u2019t be, but yeah) \n __repr__  goal is to be unambiguous \n __str__  goal is to be readable \n Container\u2019s  __str__  uses contained objects\u2019  __repr__ \n \n Default implementation is useless \n This is mostly a surprise because Python\u2019s defaults tend to be fairly useful. However, in this case, having a default for  __repr__  which would act like: \n return \"%s(%r)\" % (self.__class__, self.__dict__)\n \n would have been too dangerous (for example, too easy to get into infinite recursion if objects reference each other). So Python cops out. Note that there is one default which is true: if  __repr__  is defined, and  __str__  is not, the object will behave as though  __str__=__repr__ . \n This means, in simple terms: almost every object you implement should have a functional  __repr__  that\u2019s usable for understanding the object. Implementing  __str__  is optional: do that if you need a \u201cpretty print\u201d functionality (for example, used by a report generator). \n The goal of  __repr__  is to be unambiguous \n Let me come right out and say it \u2014 I do not believe in debuggers. I don\u2019t really know how to use any debugger, and have never used one seriously. Furthermore, I believe that the big fault in debuggers is their basic nature \u2014 most failures I debug happened a long long time ago, in a galaxy far far away. This means that I do believe, with religious fervor, in logging. Logging is the lifeblood of any decent fire-and-forget server system. Python makes it easy to log: with maybe some project specific wrappers, all you need is a \n log(INFO, \"I am in the weird function and a is\", a, \"and b is\", b, \"but I got a null C \u2014 using default\", default_c)\n \n But you have to do the last step \u2014 make sure every object you implement has a useful repr, so code like that can just work. This is why the \u201ceval\u201d thing comes up: if you have enough information so  eval(repr(c))==c , that means you know everything there is to know about  c . If that\u2019s easy enough, at least in a fuzzy way, do it. If not, make sure you have enough information about  c  anyway. I usually use an eval-like format:  \"MyClass(this=%r,that=%r)\" % (self.this,self.that) . It does not mean that you can actually construct MyClass, or that those are the right constructor arguments \u2014 but it is a useful form to express \u201cthis is everything you need to know about this instance\u201d. \n Note: I used  %r  above, not  %s . You always want to use  repr()  [or  %r  formatting character, equivalently] inside  __repr__  implementation, or you\u2019re defeating the goal of repr. You want to be able to differentiate  MyClass(3)  and  MyClass(\"3\") . \n The goal of  __str__  is to be readable \n Specifically, it is not intended to be unambiguous \u2014 notice that  str(3)==str(\"3\") . Likewise, if you implement an IP abstraction, having the str of it look like 192.168.1.1 is just fine. When implementing a date/time abstraction, the str can be \"2010/4/12 15:35:22\", etc. The goal is to represent it in a way that a user, not a programmer, would want to read it. Chop off useless digits, pretend to be some other class \u2014 as long is it supports readability, it is an improvement. \n Container\u2019s  __str__  uses contained objects\u2019  __repr__ \n This seems surprising, doesn\u2019t it? It is a little, but how readable would it be if it used their  __str__ ? \n [moshe is, 3, hello\nworld, this is a list, oh I don't know, containing just 4 elements]\n \n Not very. Specifically, the strings in a container would find it way too easy to disturb its string representation. In the face of ambiguity, remember, Python resists the temptation to guess. If you want the above behavior when you\u2019re printing a list, just \n print(\"[\" + \", \".join(l) + \"]\")\n \n (you can probably also figure out what to do about dictionaries. \n Summary \n Implement  __repr__  for any class you implement. This should be second nature. Implement  __str__  if you think it would be useful to have a string version which errs on the side of readability. \n    ", "date_posted": "2021-12-23 06:11:33Z", "upvote": "\r\n            3281\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "1192111", "name": "Francisco", "reputation_score": "10.3k"}, "answer_comments": [{"stack_answer_id": "2626364", "stack_answer_comment_id": "45597487", "comment_content": "Definitely disagree with your opinion that debugging isn't the way to go. For development use a debugger (and/or logging), for production use logging. With a debugger you have a view of everything that went wrong when the problem occurred. You can see the full picture. Unless you are logging EVERYTHING you can't get that. Plus if you are logging everything you're going have to wade through tons of data to get at what you want.", "user_id": "None"}, {"stack_answer_id": "2626364", "stack_answer_comment_id": "46649638", "comment_content": "Great answer (except the bit about not using debuggers). I'd just like to add a link to this ", "user_id": "None"}, {"stack_answer_id": "2626364", "stack_answer_comment_id": "100485156", "comment_content": "I heard that a variable ", "user_id": "None"}, {"stack_answer_id": "2626364", "stack_answer_comment_id": "101141471", "comment_content": "on debugger vs no debugger: don't get such entrenched opinions. In some applications debugging is not realistic, typically when real-time is involved, or when your code only executes remotely on a platform with little access or no console. In most other cases it will be much quicker to stop at an exception to investigate, or to set a breakpoint, because you don't have to go through thousands of lines of logging (which will clutter your disk and slow down the application). Finally, it's not always possible to log, for example on embedded devices, there debugger is your friend too.", "user_id": "None"}, {"stack_answer_id": "2626364", "stack_answer_comment_id": "105654853", "comment_content": "About debuggging vs logging, they are both useful. If a bug is reproducible, debugging is more simple. If the bug is randomic, logging is essential.", "user_id": "None"}]}, {"stack_answer_id": "1438297", "answer_content": "\r\n My rule of thumb:   __repr__  is for developers,  __str__  is for customers. \n    ", "date_posted": "2009-09-17 11:35:13Z", "upvote": "\r\n            730\r\n        ", "accepted": "No", "user": {"stack_user_id": "14343", "name": "Ned Batchelder", "reputation_score": "350k"}, "answer_comments": [{"stack_answer_id": "1438297", "stack_answer_comment_id": "98926405", "comment_content": "This is true because for obj = uuid.uuid1(), obj.__str__() is \"2d7fc7f0-7706-11e9-94ae-0242ac110002\" and obj.__repr__() is \"UUID('2d7fc7f0-7706-11e9-94ae-0242ac110002')\". Developers need (value + origin) whereas customers need a value and they don't care how they got it!", "user_id": "None"}, {"stack_answer_id": "1438297", "stack_answer_comment_id": "105488427", "comment_content": "Here ", "user_id": "None"}, {"stack_answer_id": "1438297", "stack_answer_comment_id": "124456934", "comment_content": "@NarenYellavula if you're exposing a UUID to a customer you're probably doing something wrong.", "user_id": "None"}, {"stack_answer_id": "1438297", "stack_answer_comment_id": "126975289", "comment_content": "@MarkRansom why is that?", "user_id": "None"}, {"stack_answer_id": "1438297", "stack_answer_comment_id": "126982587", "comment_content": "@AbdessabourMtk they're overly complex, and there's no protection against typing them wrong.  Maybe in certain contexts like as part of a QR code they would be OK.", "user_id": "None"}]}, {"stack_answer_id": "1436756", "answer_content": "\r\n Unless you specifically act to ensure otherwise, most classes don't have helpful results for either: \n >>> class Sic(object): pass\n... \n>>> print(str(Sic()))\n<__main__.Sic object at 0x8b7d0>\n>>> print(repr(Sic()))\n<__main__.Sic object at 0x8b7d0>\n>>> \n \n As you see -- no difference, and no info beyond the class and object's  id .  If you only override one of the two...: \n >>> class Sic(object): \n...   def __repr__(self): return 'foo'\n... \n>>> print(str(Sic()))\nfoo\n>>> print(repr(Sic()))\nfoo\n>>> class Sic(object):\n...   def __str__(self): return 'foo'\n... \n>>> print(str(Sic()))\nfoo\n>>> print(repr(Sic()))\n<__main__.Sic object at 0x2617f0>\n>>> \n \n as you see, if you override  __repr__ , that's ALSO used for  __str__ , but not vice versa. \n Other crucial tidbits to know:  __str__  on a built-on container uses the  __repr__ , NOT the  __str__ , for the items it contains. And, despite the words on the subject found in typical docs, hardly anybody bothers making the  __repr__  of objects be a string that  eval  may use to build an equal object (it's just too hard, AND not knowing how the relevant module was actually imported makes it actually flat out impossible). \n So, my advice: focus on making  __str__  reasonably human-readable, and  __repr__  as unambiguous as you possibly can, even if that interferes with the fuzzy unattainable goal of making  __repr__ 's returned value acceptable as input to  __eval__ ! \n    ", "date_posted": "2022-02-09 22:35:24Z", "upvote": "\r\n            484\r\n        ", "accepted": "No", "user": {"stack_user_id": "2311167", "name": "Adrian W", "reputation_score": "4,163"}, "answer_comments": [{"stack_answer_id": "1436756", "stack_answer_comment_id": "9992427", "comment_content": "In my unit tests I always check that ", "user_id": "None"}, {"stack_answer_id": "1436756", "stack_answer_comment_id": "40619938", "comment_content": "I always try to make sure that either ", "user_id": "None"}, {"stack_answer_id": "1436756", "stack_answer_comment_id": "83919034", "comment_content": "Why would not containers (lists, tuples) use  ", "user_id": "None"}, {"stack_answer_id": "1436756", "stack_answer_comment_id": "95167441", "comment_content": "Just ran into an annoying bug related to the fact that ", "user_id": "None"}, {"stack_answer_id": "1436756", "stack_answer_comment_id": "115164858", "comment_content": "@abarnert: for a custom ", "user_id": "None"}]}, {"stack_answer_id": "1436721", "answer_content": "\r\n __repr__ : representation of python object usually eval will convert it back to that object \n\n __str__ : is whatever you think is that object in text form \n\n e.g. \n\n >>> s=\"\"\"w'o\"w\"\"\"\n>>> repr(s)\n'\\'w\\\\\\'o\"w\\''\n>>> str(s)\n'w\\'o\"w'\n>>> eval(str(s))==s\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"<string>\", line 1\n    w'o\"w\n       ^\nSyntaxError: EOL while scanning single-quoted string\n>>> eval(repr(s))==s\nTrue\n \n    ", "date_posted": "2012-08-15 19:40:17Z", "upvote": "\r\n            203\r\n        ", "accepted": "No", "user": {"stack_user_id": "505154", "name": "Andrew Clark", "reputation_score": "194k"}, "answer_comments": [{"stack_answer_id": "1436721", "stack_answer_comment_id": "124693632", "comment_content": "__repr__() : used to create \"constructor-like expression\" in string, so that eval() can re-construct an object back from this string representation   __str__() : used to create string containing a printable representation of an object", "user_id": "None"}]}, {"stack_answer_id": "19597196", "answer_content": "\r\n \n   In short, the goal of  __repr__  is to be unambiguous and  __str__  is to be\n  readable. \n \n\n Here is a good example: \n\n >>> import datetime\n>>> today = datetime.datetime.now()\n>>> str(today)\n'2012-03-14 09:21:58.130922'\n>>> repr(today)\n'datetime.datetime(2012, 3, 14, 9, 21, 58, 130922)'\n \n\n Read this documentation for repr: \n\n \n   repr(object) \n  \n   Return a string containing a printable representation of an object. This is the same value yielded by conversions (reverse\n  quotes). It is sometimes useful to be able to access this operation as\n  an ordinary function. For many types, this function makes an attempt\n  to return a string that would yield an object with the same value when\n  passed to  eval() , otherwise the representation is a string enclosed in\n  angle brackets that contains the name of the type of the object\n  together with additional information often including the name and\n  address of the object. A class can control what this function returns\n  for its instances by defining a  __repr__()  method. \n \n\n Here is the documentation for str: \n\n \n   str(object='') \n  \n   Return a string containing a nicely printable\n  representation of an object. For strings, this returns the string\n  itself. The difference with  repr(object)  is that  str(object)  does not\n  always attempt to return a string that is acceptable to  eval() ; its\n  goal is to return a printable string. If no argument is given, returns\n  the empty string,  '' . \n \n    ", "date_posted": "2013-10-28 00:23:46Z", "upvote": "\r\n            196\r\n        ", "accepted": "No", "user": {"stack_user_id": "1442342", "name": "deadly", "reputation_score": "1,198"}, "answer_comments": [{"stack_answer_id": "19597196", "stack_answer_comment_id": "90779593", "comment_content": "What is the meaning of printable string here? Can you explain it please?", "user_id": "None"}, {"stack_answer_id": "19597196", "stack_answer_comment_id": "111199240", "comment_content": "building upon the above example  by \"bitoffdev\" and  @deadly we can see how ", "user_id": "None"}]}, {"stack_answer_id": "28132458", "answer_content": "\r\n \n What is the difference between  __str__  and  __repr__  in Python? \n \n __str__  (read as \"dunder (double-underscore) string\") and  __repr__  (read as \"dunder-repper\" (for \"representation\")) are both special methods that return strings based on the state of the object. \n __repr__  provides backup behavior if  __str__  is missing. \n So one should first write a  __repr__  that allows you to reinstantiate an equivalent object from the string it returns e.g. using  eval  or by typing it in character-for-character in a Python shell. \n At any time later, one can write a  __str__  for a user-readable string representation of the instance, when one believes it to be necessary. \n __str__ \n If you print an object, or pass it to  format ,  str.format , or  str , then if a  __str__  method is defined, that method will be called, otherwise,  __repr__  will be used. \n __repr__ \n The  __repr__  method is called by the builtin function  repr  and is what is echoed on your python shell when it evaluates an expression that returns an object. \n Since it provides a backup for  __str__ , if you can only write one, start with  __repr__ \n Here's the builtin help on  repr : \n repr(...)\n    repr(object) -> string\n    \n    Return the canonical string representation of the object.\n    For most object types, eval(repr(object)) == object.\n \n That is, for most objects, if you type in what is printed by  repr , you should be able to create an equivalent object.  But this is not the default implementation. \n Default Implementation of  __repr__ \n The default object  __repr__  is ( C Python source ) something like: \n def __repr__(self):\n    return '<{0}.{1} object at {2}>'.format(\n      type(self).__module__, type(self).__qualname__, hex(id(self)))\n \n That means by default you'll print the module the object is from, the class name, and the hexadecimal representation of its location in memory - for example: \n <__main__.Foo object at 0x7f80665abdd0>\n \n This information isn't very useful, but there's no way to derive how one might accurately create a canonical representation of any given instance, and it's better than nothing, at least telling us how we might uniquely identify it in memory. \n How can  __repr__  be useful? \n Let's look at how useful it can be, using the Python shell and  datetime  objects. First we need to import the  datetime  module: \n import datetime\n \n If we call  datetime.now  in the shell, we'll see everything we need to recreate an equivalent datetime object. This is created by the datetime  __repr__ : \n >>> datetime.datetime.now()\ndatetime.datetime(2015, 1, 24, 20, 5, 36, 491180)\n \n If we print a datetime object, we see a nice human readable (in fact, ISO) format. This is implemented by datetime's  __str__ : \n >>> print(datetime.datetime.now())\n2015-01-24 20:05:44.977951\n \n It is a simple matter to recreate the object we lost because we didn't assign it to a variable by copying and pasting from the  __repr__  output, and then printing it, and we get it in the same human readable output as the other object: \n >>> the_past = datetime.datetime(2015, 1, 24, 20, 5, 36, 491180)\n>>> print(the_past)\n2015-01-24 20:05:36.491180\n \n #How do I implement them? \n As you're developing, you'll want to be able to reproduce objects in the same state, if possible. This, for example, is how the datetime object defines  __repr__  ( Python source ). It is fairly complex, because of all of the attributes needed to reproduce such an object: \n def __repr__(self):\n    \"\"\"Convert to formal string, for repr().\"\"\"\n    L = [self._year, self._month, self._day,  # These are never zero\n         self._hour, self._minute, self._second, self._microsecond]\n    if L[-1] == 0:\n        del L[-1]\n    if L[-1] == 0:\n        del L[-1]\n    s = \"%s.%s(%s)\" % (self.__class__.__module__,\n                       self.__class__.__qualname__,\n                       \", \".join(map(str, L)))\n    if self._tzinfo is not None:\n        assert s[-1:] == \")\"\n        s = s[:-1] + \", tzinfo=%r\" % self._tzinfo + \")\"\n    if self._fold:\n        assert s[-1:] == \")\"\n        s = s[:-1] + \", fold=1)\"\n    return s\n \n If you want your object to have a more human readable representation, you can implement  __str__  next. Here's how the datetime object ( Python source ) implements  __str__ , which it easily does because it already has a function to display it in ISO format: \n def __str__(self):\n    \"Convert to string, for str().\"\n    return self.isoformat(sep=' ')\n \n Set  __repr__ = __str__ ? \n This is a critique of another answer here that suggests setting  __repr__ = __str__ . \n Setting  __repr__ = __str__  is silly -  __repr__  is a fallback for  __str__  and a  __repr__ , written for developers usage in debugging, should be written before you write a  __str__ . \n You need a  __str__  only when you need a textual representation of the object. \n Conclusion \n Define  __repr__  for objects you write so you and other developers have a reproducible example when using it as you develop. Define  __str__  when you need a human readable string representation of it. \n    ", "date_posted": "2022-03-31 17:05:03Z", "upvote": "\r\n            162\r\n        ", "accepted": "No", "user": {"stack_user_id": "2326961", "name": "Maggyero", "reputation_score": "4,880"}, "answer_comments": [{"stack_answer_id": "28132458", "stack_answer_comment_id": "93999470", "comment_content": "Shouldn't it be something along the lines of ", "user_id": "None"}, {"stack_answer_id": "28132458", "stack_answer_comment_id": "94014066", "comment_content": "@SolomonUcko yes in Python 3, that would seem to be the case - I've been hunting down the source code where this is implemented and I'll update my answer with that information when I get it together.", "user_id": "None"}, {"stack_answer_id": "28132458", "stack_answer_comment_id": "125520621", "comment_content": "This answer will be more helpful for beginners. Nice explanation!!", "user_id": "None"}, {"stack_answer_id": "28132458", "stack_answer_comment_id": "126709060", "comment_content": "I have changed ", "user_id": "None"}]}, {"stack_answer_id": "44099267", "answer_content": "\r\n On page 358 of the book  Python scripting for computational science  by Hans Petter Langtangen, it clearly states that  \n\n \n The  __repr__  aims at a complete string representation of the object; \n The  __str__  is to return a nice string for printing. \n \n\n So, I prefer to understand them as \n\n \n repr = reproduce \n str = string (representation) \n \n\n from the user's point of view\nalthough this is a misunderstanding I made when learning python. \n\n A small but good example is also given on the same page as follows: \n\n Example \n\n In [38]: str('s')\nOut[38]: 's'\n\nIn [39]: repr('s')\nOut[39]: \"'s'\"\n\nIn [40]: eval(str('s'))\nTraceback (most recent call last):\n\n  File \"<ipython-input-40-abd46c0c43e7>\", line 1, in <module>\n    eval(str('s'))\n\n  File \"<string>\", line 1, in <module>\n\nNameError: name 's' is not defined\n\n\nIn [41]: eval(repr('s'))\nOut[41]: 's'\n \n    ", "date_posted": "2019-06-19 07:47:15Z", "upvote": "\r\n            47\r\n        ", "accepted": "No", "user": {"stack_user_id": "10323798", "name": "NelsonGon", "reputation_score": "12.7k"}, "answer_comments": [{"stack_answer_id": "44099267", "stack_answer_comment_id": "94617094", "comment_content": "It is at pg. #351.", "user_id": "None"}, {"stack_answer_id": "44099267", "stack_answer_comment_id": "99893843", "comment_content": "It's kind of misleading to refer to ", "user_id": "None"}]}, {"stack_answer_id": "39382137", "answer_content": "\r\n Apart from all the answers given, I would like to add few points :- \n\n 1)  __repr__()  is invoked when you simply write object's name on interactive python console and press enter. \n\n 2)  __str__()  is invoked when you use object with print statement. \n\n 3) In case, if  __str__  is missing, then print and any function using  str()  invokes  __repr__()  of object. \n\n 4)  __str__()  of containers, when invoked will execute  __repr__()  method of its contained elements. \n\n 5)  str()  called within  __str__()  could potentially recurse without a base case, and error on maximum recursion depth. \n\n 6)  __repr__()  can call  repr()  which will attempt to avoid infinite recursion automatically, replacing an already represented object with  ... . \n    ", "date_posted": "2018-06-05 07:47:41Z", "upvote": "\r\n            46\r\n        ", "accepted": "No", "user": {"stack_user_id": "9542308", "name": "David Augusto Villa", "reputation_score": "63"}, "answer_comments": []}, {"stack_answer_id": "63464185", "answer_content": "\r\n (2020 entry) \n Q:  What's the difference between  __str__()  and  __repr__() ? \n TL;DR: \n \n LONG \n This question has been around a long time, and there are a variety of answers of which most are correct (not to mention from several Python community legends[!]). However when it comes down to the nitty-gritty, this question is analogous to asking the difference between the  str()  and  repr()  built-in functions. I'm going to describe the differences in my own words (which means I may be \"borrowing\" liberally from  Core Python Programming  so pls forgive me). \n Both   str()  and  repr()  have the same basic job: their goal is to return a string representation of a Python object. What  kind  of string representation is what differentiates them. \n \n str()  &  __str__()  return a  printable  string representation of\nan object... something human-readable/for human consumption \n repr()  &  __repr__()  return a string representation of an object that is a  valid Python expression , an object you can pass to  eval()  or type into the Python shell without getting an error. \n \n For example, let's assign a string to  x  and an  int  to  y , and simply showing human-readable string versions of each: \n >>> x, y = 'foo', 123\n>>> str(x), str(y)\n('foo', '123')\n \n Can we take  what is inside the quotes  in both cases and enter them verbatim into the Python interpreter? Let's give it a try: \n >>> 123\n123\n>>> foo\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'foo' is not defined\n \n Clearly you can for an  int  but not necessarily for a  str . Similarly, while I can pass  '123'  to  eval() , that doesn't work for  'foo' : \n >>> eval('123')\n123\n>>> eval('foo')\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"<string>\", line 1, in <module>\nNameError: name 'foo' is not defined\n \n So this tells you the Python shell just  eval() s what you give it. Got it? Now, let's  repr()  both expressions and see what we get. More specifically, take its output and dump  those  out in the interpreter (there's a point to this which we'll address afterwards): \n >>> repr(x), repr(y)\n(\"'foo'\", '123')\n>>> 123\n123\n>>> 'foo'\n'foo'\n \n Wow, they  both  work? That's because  'foo' , while a printable string representation of that string, it's  not  evaluatable, but  \"'foo'\"  is.  123  is a valid Python  int  called by either  str()  or  repr() . What happens when we call  eval()  with these? \n >>> eval('123')\n123\n>>> eval(\"'foo'\")\n'foo'\n \n It works because  123  and  'foo'  are valid Python objects. Another key takeaway is that while sometimes both return the same thing (the same string representation), that's not always the case. (And yes, yes, I can go create a variable  foo  where the  eval()  works, but that's not the point.) \n More factoids about both pairs \n \n Sometimes,  str()  and  repr()  are called  implicitly , meaning they're called on behalf of users: when users execute  print  (Py1/Py2) or call  print()  (Py3+), even if users don't call  str()  explicitly, such a call is made on their behalf before the object is displayed. \n In the Python shell (interactive interpreter), if you enter a variable at the  >>>  prompt and press RETURN, the interpreter displays the results of  repr()  implicitly called on that object. \n To connect  str()  and  repr()  to  __str__()  and  __repr__() , realize that calls to the built-in functions, i.e.,  str(x)  or  repr(y)  result in calling their object's corresponding special methods:  x.__str__()  or  y.__repr()__ \n By implementing  __str__()  and  __repr__()  for  your  Python classes, you overload the built-in functions ( str()  and  repr() ), allowing instances of your classes to be passed in to  str()  and  repr() . When such calls are made, they turn around and call the class'  __str__()  and  __repr__()  (per #3). \n \n    ", "date_posted": "2022-02-03 06:36:55Z", "upvote": "\r\n            36\r\n        ", "accepted": "No", "user": {"stack_user_id": "305689", "name": "wescpy", "reputation_score": "10.1k"}, "answer_comments": []}, {"stack_answer_id": "34734815", "answer_content": "\r\n To put it simply: \n\n __str__  is used in to show a string representation of your object  to be read easily  by others. \n\n __repr__  is used to show a string representation of  the  object. \n\n Let's say I want to create a  Fraction  class where the string representation of a fraction is '(1/2)' and the object (Fraction class) is to be represented as 'Fraction (1,2)' \n\n So we can create a simple Fraction class: \n\n class Fraction:\n    def __init__(self, num, den):\n        self.__num = num\n        self.__den = den\n\n    def __str__(self):\n        return '(' + str(self.__num) + '/' + str(self.__den) + ')'\n\n    def __repr__(self):\n        return 'Fraction (' + str(self.__num) + ',' + str(self.__den) + ')'\n\n\n\nf = Fraction(1,2)\nprint('I want to represent the Fraction STRING as ' + str(f)) # (1/2)\nprint('I want to represent the Fraction OBJECT as ', repr(f)) # Fraction (1,2)\n \n    ", "date_posted": "2016-07-28 04:08:32Z", "upvote": "\r\n            15\r\n        ", "accepted": "No", "user": {"stack_user_id": "222758", "name": "user222758", "reputation_score": "12.6k"}, "answer_comments": []}, {"stack_answer_id": "1436706", "answer_content": "\r\n From  an (An Unofficial) Python Reference Wiki (archive copy)  by effbot: \n\n __str__  \" computes the \"informal\" string representation of an object. This differs from  __repr__  in that it does not have to be a valid Python expression: a more convenient or concise representation may be used instead. \" \n    ", "date_posted": "2019-05-29 12:51:25Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "1436706", "stack_answer_comment_id": "80631615", "comment_content": " is by no means required to return a vaild Python expression.", "user_id": "None"}]}, {"stack_answer_id": "13395755", "answer_content": "\r\n In all honesty,  eval(repr(obj))  is never used. If you find yourself using it, you should stop, because  eval  is dangerous, and strings are a very inefficient way to serialize your objects (use  pickle  instead). \n Therefore, I would recommend setting  __repr__ = __str__ . The reason is that  str(list)  calls  repr  on the elements (I consider this to be one of the biggest design flaws of Python that was not addressed by Python 3). An actual  repr  will probably not be very helpful as the output of  print([your, objects]) . \n To qualify this, in my experience, the most useful use case of the  repr  function is to put a string inside another string (using string formatting). This way, you don't have to worry about escaping quotes or anything. But note that there is no  eval  happening here. \n    ", "date_posted": "2021-12-23 06:13:22Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "1192111", "name": "Francisco", "reputation_score": "10.3k"}, "answer_comments": [{"stack_answer_id": "13395755", "stack_answer_comment_id": "37141861", "comment_content": "I think this misses the point. The use of ", "user_id": "None"}, {"stack_answer_id": "13395755", "stack_answer_comment_id": "59127770", "comment_content": " is not inherently dangerous. Is not more dangerous than ", "user_id": "None"}]}, {"stack_answer_id": "40960730", "answer_content": "\r\n str  - Creates a new string object from the given object. \n\n repr  - Returns the canonical string representation of the object. \n\n The differences: \n\n str(): \n\n \n makes object readable \n generates output for end-user \n \n\n repr(): \n\n \n needs code that reproduces object \n generates output for developer \n \n    ", "date_posted": "2016-12-04 16:18:48Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "5401681", "name": "Taufiq Rahman", "reputation_score": "5,453"}, "answer_comments": []}, {"stack_answer_id": "44201752", "answer_content": "\r\n One aspect that is missing in other answers. It's true that in general the pattern is: \n\n \n Goal of  __str__ : human-readable \n Goal of  __repr__ : unambiguous, possibly machine-readable via  eval \n \n\n Unfortunately, this differentiation is flawed, because the Python REPL and also IPython use  __repr__  for printing objects in a REPL console (see related questions for  Python  and  IPython ). Thus, projects which are targeted for interactive console work (e.g., Numpy or Pandas) have started to ignore above rules and provide a human-readable  __repr__  implementation instead. \n    ", "date_posted": "2017-05-26 12:33:51Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "1804173", "name": "bluenote10", "reputation_score": "20.5k"}, "answer_comments": []}, {"stack_answer_id": "43207419", "answer_content": "\r\n From the book  Fluent Python : \n\n \n   A basic requirement for a Python object is to provide usable \n       string   representations of itself, one used for debugging and\n       logging, another for presentation to end users. That is why the \n       special methods  __repr__  and  __str__  exist in the data model. \n \n    ", "date_posted": "2019-05-29 12:57:22Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": []}, {"stack_answer_id": "68665826", "answer_content": "\r\n You can get some insight from this code: \n class Foo():\n    def __repr__(self):\n        return(\"repr\")\n    def __str__(self):\n        return(\"str\")\n\nfoo = Foo()\nfoo #repr\nprint(foo) #str\n \n    ", "date_posted": "2021-08-05 11:36:27Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "1291302", "name": "JonnyRobbie", "reputation_score": "487"}, "answer_comments": []}, {"stack_answer_id": "56481986", "answer_content": "\r\n __str__  can be invoked on an object by calling  str(obj)  and should return a human readable string.  \n\n __repr__  can be invoked on an object by calling  repr(obj)  and should return internal object (object fields/attributes) \n\n This example may help: \n\n class C1:pass\n\nclass C2:        \n    def __str__(self):\n        return str(f\"{self.__class__.__name__} class str \")\n\nclass C3:        \n    def __repr__(self):        \n         return str(f\"{self.__class__.__name__} class repr\")\n\nclass C4:        \n    def __str__(self):\n        return str(f\"{self.__class__.__name__} class str \")\n    def __repr__(self):        \n         return str(f\"{self.__class__.__name__} class repr\")\n\n\nci1 = C1()    \nci2 = C2()  \nci3 = C3()  \nci4 = C4()\n\nprint(ci1)       #<__main__.C1 object at 0x0000024C44A80C18>\nprint(str(ci1))  #<__main__.C1 object at 0x0000024C44A80C18>\nprint(repr(ci1)) #<__main__.C1 object at 0x0000024C44A80C18>\nprint(ci2)       #C2 class str\nprint(str(ci2))  #C2 class str\nprint(repr(ci2)) #<__main__.C2 object at 0x0000024C44AE12E8>\nprint(ci3)       #C3 class repr\nprint(str(ci3))  #C3 class repr\nprint(repr(ci3)) #C3 class repr\nprint(ci4)       #C4 class str \nprint(str(ci4))  #C4 class str \nprint(repr(ci4)) #C4 class repr\n \n    ", "date_posted": "2019-06-06 16:53:43Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "5884955", "name": "prosti", "reputation_score": "36.9k"}, "answer_comments": []}, {"stack_answer_id": "33421226", "answer_content": "\r\n Excellent answers already cover the difference between  __str__  and  __repr__ , which for me boils down to the former being readable even by an end user, and the latter being as useful as possible to developers. Given that, I find that the default implementation of  __repr__  often fails to achieve this goal because it  omits  information useful to developers. \n\n For this reason, if I have a simple enough  __str__ , I generally just try to get the best of both worlds with something like: \n\n def __repr__(self):\n    return '{0} ({1})'.format(object.__repr__(self), str(self))\n \n    ", "date_posted": "2018-04-25 19:35:20Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "answer_comments": []}, {"stack_answer_id": "31427937", "answer_content": "\r\n >>> print(decimal.Decimal(23) / decimal.Decimal(\"1.05\"))\n21.90476190476190476190476190\n>>> decimal.Decimal(23) / decimal.Decimal(\"1.05\")\nDecimal('21.90476190476190476190476190')\n \n\n When  print()  is called on the result of  decimal.Decimal(23) / decimal.Decimal(\"1.05\")  the raw number is printed; this output is in  string form  which can be achieved with  __str__() . If we simply enter the expression we get a  decimal.Decimal  output \u2014 this output is in  representational form  which can be achieved with  __repr__() . All Python objects have two output forms. String form is designed to be human-readable. The representational form is designed to produce output that if fed to a Python interpreter would (when possible) reproduce the represented object. \n    ", "date_posted": "2019-05-29 12:58:50Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": []}, {"stack_answer_id": "33727876", "answer_content": "\r\n \n   One important thing to keep in mind is that container's  __str__  uses contained objects'  __repr__ . \n \n\n >>> from datetime import datetime\n>>> from decimal import Decimal\n>>> print (Decimal('52'), datetime.now())\n(Decimal('52'), datetime.datetime(2015, 11, 16, 10, 51, 26, 185000))\n>>> str((Decimal('52'), datetime.now()))\n\"(Decimal('52'), datetime.datetime(2015, 11, 16, 10, 52, 22, 176000))\"\n \n\n Python favors unambiguity over readability , the  __str__  call of a  tuple  calls the contained objects'  __repr__ , the  \"formal\"  representation of an object. Although the formal representation is harder to read than an informal one, it is unambiguous and more robust against bugs. \n    ", "date_posted": "2015-11-16 03:02:21Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "3011380", "name": "zangw", "reputation_score": "38.2k"}, "answer_comments": [{"stack_answer_id": "33727876", "stack_answer_comment_id": "94618177", "comment_content": "It uses ", "user_id": "None"}]}, {"stack_answer_id": "49447574", "answer_content": "\r\n In a nutshell: \n\n class Demo:\n  def __repr__(self):\n    return 'repr'\n  def __str__(self):\n    return 'str'\n\ndemo = Demo()\nprint(demo) # use __str__, output 'str' to stdout\n\ns = str(demo) # __str__ is used, return 'str'\nr = repr(demo) # __repr__ is used, return 'repr'\n\nimport logging\nlogger = logging.getLogger(logging.INFO)\nlogger.info(demo) # use __str__, output 'str' to stdout\n\nfrom pprint import pprint, pformat\npprint(demo) # use __repr__, output 'repr' to stdout\nresult = pformat(demo) # use __repr__, result is string which value is 'str'\n \n    ", "date_posted": "2018-04-16 09:28:38Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "50065", "name": "BioGeek", "reputation_score": "21.1k"}, "answer_comments": []}, {"stack_answer_id": "47690304", "answer_content": "\r\n Understand  __str__  and  __repr__  intuitively and permanently distinguish them at all. \n\n __str__  return the string disguised body of a given object for readable of eyes \n __repr__  return the real flesh body of a given object (return itself) for unambiguity to identify. \n\n See it in an example \n\n In [30]: str(datetime.datetime.now())\nOut[30]: '2017-12-07 15:41:14.002752'\nDisguised in string form\n \n\n As to  __repr__ \n\n In [32]: datetime.datetime.now()\nOut[32]: datetime.datetime(2017, 12, 7, 15, 43, 27, 297769)\nPresence in real body which allows to be manipulated directly.\n \n\n We can do arithmetic operation on  __repr__  results conveniently. \n\n In [33]: datetime.datetime.now()\nOut[33]: datetime.datetime(2017, 12, 7, 15, 47, 9, 741521)\nIn [34]: datetime.datetime(2017, 12, 7, 15, 47, 9, 741521) - datetime.datetime(2\n    ...: 017, 12, 7, 15, 43, 27, 297769)\nOut[34]: datetime.timedelta(0, 222, 443752)\n \n\n if apply the operation on  __str__ \n\n In [35]: '2017-12-07 15:43:14.002752' - '2017-12-07 15:41:14.002752'\nTypeError: unsupported operand type(s) for -: 'str' and 'str'\n \n\n Returns nothing but error. \n\n Another example. \n\n In [36]: str('string_body')\nOut[36]: 'string_body' # in string form\n\nIn [37]: repr('real_body')\nOut[37]: \"'real_body'\" #its real body hide inside\n \n\n Hope this help you build concrete grounds to explore more answers. \n    ", "date_posted": "2018-01-02 10:36:32Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "7301792", "name": "AbstProcDo", "reputation_score": "18.1k"}, "answer_comments": []}, {"stack_answer_id": "55744921", "answer_content": "\r\n \n __str__  must return string object whereas  __repr__  can return any python expression. \n If  __str__  implementation is missing then  __repr__  function is used as fallback. There is no fallback if  __repr__  function implementation is missing. \n If  __repr__  function is returning String representation of the object, we can skip implementation of  __str__  function. \n \n\n Source:  https://www.journaldev.com/22460/python-str-repr-functions \n    ", "date_posted": "2019-04-18 11:20:28Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "811625", "name": "Sampath", "reputation_score": "1,059"}, "answer_comments": []}, {"stack_answer_id": "50229578", "answer_content": "\r\n __repr__  is used everywhere, except by  print  and  str  methods (when a  __str__ is defined !) \n    ", "date_posted": "2019-04-14 07:50:40Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "7127824", "name": "techkuz", "reputation_score": "3,158"}, "answer_comments": []}, {"stack_answer_id": "65164408", "answer_content": "\r\n Every object inherits  __repr__   from the base class that all objects created. \n class Person:\n     pass\n\np=Person()\n \n if you call  repr(p)  you will get this as default: \n  <__main__.Person object at 0x7fb2604f03a0>\n \n But if you call  str(p)  you will get the same output. it is because when  __str__  does not exist, Python calls  __repr__ \n Let's implement our own  __str__ \n class Person:\n    def __init__(self,name,age):\n        self.name=name\n        self.age=age\n    def __repr__(self):\n        print(\"__repr__ called\")\n        return f\"Person(name='{self.name}',age={self.age})\"\n\np=Person(\"ali\",20)\n \n print(p)  and  str(p) will return \n  __repr__ called\n     Person(name='ali',age=20)\n \n let's add  __str__() \n class Person:\n    def __init__(self, name, age):\n        self.name = name\n        self.age = age\n        \n    def __repr__(self):\n        print('__repr__ called')\n        return f\"Person(name='{self.name}, age=self.age')\"\n    \n    def __str__(self):\n        print('__str__ called')\n        return self.name\n\np=Person(\"ali\",20)\n \n if we call  print(p)  and str(p), it will call  __str__()  so it will return \n __str__ called\nali\n \n repr(p)  will return \n repr  called\n\"Person(name='ali, age=self.age')\" \n Let's omit  __repr__  and just implement  __str__ . \n class Person:\ndef __init__(self, name, age):\n    self.name = name\n    self.age = age\n\ndef __str__(self):\n    print('__str__ called')\n    return self.name\n\np=Person('ali',20)\n \n print(p)  will look for the  __str__  and will return: \n __str__ called\nali\n \n NOTE= if we had  __repr__  and  __str__  defined,  f'name is {p}'  would call  __str__ \n    ", "date_posted": "2020-12-06 03:31:59Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "10262805", "name": "Yilmaz", "reputation_score": "16.9k"}, "answer_comments": []}, {"stack_answer_id": "72027825", "answer_content": "\r\n \n Programmers with prior experience in languages with a  toString  method tend to implement  __str__  and not  __repr__ .\nIf you only implement one of these special methods in Python, choose  __repr__ . \n \n From  Fluent Python  book, by Ramalho, Luciano. \n    ", "date_posted": "2022-04-27 11:19:34Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "30038", "name": "Vlad Bezden", "reputation_score": "74.9k"}, "answer_comments": []}, {"stack_answer_id": "72238659", "answer_content": "\r\n Basically  __str__  or  str()  is used for creating output that is human-readable are must be for end-users.\nOn the other hand,  repr()  or  __repr__  mainly returns canonical string representation of objects which serve the purpose of debugging and development helps the programmers. \n    ", "date_posted": "2022-05-14 08:47:49Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "13829776", "name": "barii", "reputation_score": "275"}, "answer_comments": []}], "user": {"stack_user_id": "165495", "name": "Casebash", "reputation_score": "109k"}, "question_comments": []},
{"stack_question_id": "370357", "question_title": "UnboundLocalError on local variable when reassigned after first use", "question_content": "\r\n                The following code works as expected in both Python 2.5 and 3.0:\n\na, b, c = (1, 2, 3)\n\nprint(a, b, c)\n\ndef test():\n    print(a)\n    print(b)\n    print(c)    # (A)\n    #c+=1       # (B)\ntest()\r\nHowever,...\r\n", "question_url": "/questions/370357/unboundlocalerror-on-local-variable-when-reassigned-after-first-use", "date_posted": "Dec 16, 2008 at 3:06", "upvote": "2", "view": "8", "tags": ["python", "variables", "scope"], "answers_count": "1", "answers": [{"stack_answer_id": "370363", "answer_content": "\r\n Python treats variables in functions differently depending on whether you assign values to them from inside or outside the function.  If a variable is assigned within a function, it is treated by default as a local variable.  Therefore, when you uncomment the line, you are trying to reference the local variable  c  before any value has been assigned to it. \n If you want the variable  c  to refer to the global  c = 3  assigned before the function, put \n global c\n \n as the first line of the function. \n As for python 3, there is now \n nonlocal c\n \n that you can use to refer to the nearest enclosing function scope that has a  c  variable. \n    ", "date_posted": "2022-01-03 18:12:36Z", "upvote": "\r\n            275\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "4518341", "name": "wjandrea", "reputation_score": "24.1k"}, "answer_comments": [{"stack_answer_id": "370363", "stack_answer_comment_id": "199343", "comment_content": "Thanks. Quick question. Does this imply that Python decides the scope of each variable before running a program? Before running a function?", "user_id": "46521"}, {"stack_answer_id": "370363", "stack_answer_comment_id": "199347", "comment_content": "The variable scope decision is made by the compiler, which normally runs once when you first start the program. However it is worth keeping in mind that the compiler might also run later if you have \"eval\" or \"exec\" statements in your program.", "user_id": "None"}, {"stack_answer_id": "370363", "stack_answer_comment_id": "199358", "comment_content": "Okay thank you. I guess \"interpreted language\" doesn't imply quite as much as I had thought.", "user_id": "46521"}, {"stack_answer_id": "370363", "stack_answer_comment_id": "1634018", "comment_content": "Ah that 'nonlocal' keyword was exactly what I was looking for, it seemed Python was missing this. Presumably this 'cascades' through each enclosing scope that imports the variable using this keyword?", "user_id": "None"}, {"stack_answer_id": "370363", "stack_answer_comment_id": "8941039", "comment_content": "@brainfsck: it is easiest to understand if you make the distinction between \"looking up\" and \"assigning\" a variable. Lookup falls back to a higher scope if the name is not found in the current scope. Assignment is always done in the local scope (unless you use ", "user_id": "None"}]}, {"stack_answer_id": "370380", "answer_content": "\r\n Python is a little weird in that it keeps everything in a dictionary for the various scopes.  The original a,b,c are in the uppermost scope and so in that uppermost dictionary.  The function has its own dictionary.  When you reach the  print(a)  and  print(b)  statements, there's nothing by that name in the dictionary, so Python looks up the list and finds them in the global dictionary. \n\n Now we get to  c+=1 , which is, of course, equivalent to  c=c+1 .  When Python scans that line, it says \"aha, there's a variable named c, I'll put it into my local scope dictionary.\"  Then when it goes looking for a value for c for the c on the right hand side of the assignment, it finds its  local variable named c , which has no value yet, and so throws the error. \n\n The statement  global c  mentioned above simply tells the parser that it uses the  c  from the global scope and so doesn't need a new one. \n\n The reason it says there's an issue on the line it does is because it is effectively looking for the names before it tries to generate code, and so in some sense doesn't think it's really doing that line yet.  I'd argue that is a usability bug, but it's generally a good practice to just learn not to take a compiler's messages  too  seriously. \n\n If it's any comfort, I spent probably a day digging and experimenting with this same issue before I found something Guido had written about the dictionaries that Explained Everything. \n\n Update, see comments: \n\n It doesn't scan the code twice, but it does scan the code in two phases, lexing and parsing. \n\n Consider how the parse of this line of code works.  The lexer reads the source text and breaks it into lexemes, the \"smallest components\" of the grammar.  So when it hits the line \n\n c+=1\n \n\n it breaks it up into something like \n\n SYMBOL(c) OPERATOR(+=) DIGIT(1)\n \n\n The parser eventually wants to make this into a parse tree and execute it, but since it's an assignment, before it does, it looks for the name c in the local dictionary, doesn't see it, and inserts it in the dictionary, marking it as uninitialized. In a fully compiled language, it would just go into the symbol table and wait for the parse, but since it WON'T have the luxury of a second pass, the lexer does a little extra work to make life easier later on.   Only, then it sees the OPERATOR, sees that the rules say \"if you have an operator += the left hand side must have been initialized\" and says \"whoops!\" \n\n The point here is that it  hasn't really started the parse of the line yet .  This is all happening sort of preparatory to the actual parse, so the line counter hasn't advanced to the next line.  Thus when it signals the error, it still thinks its on the previous line. \n\n As I say, you could argue it's a usability bug, but its actually a fairly common thing.  Some compilers are more honest about it and say \"error on or around line XXX\", but this one doesn't. \n    ", "date_posted": "2016-12-10 07:09:58Z", "upvote": "\r\n            87\r\n        ", "accepted": "No", "user": {"stack_user_id": "15168", "name": "Jonathan Leffler", "reputation_score": "704k"}, "answer_comments": [{"stack_answer_id": "370380", "stack_answer_comment_id": "199333", "comment_content": "Okay thank you for your response; it cleared some things up for me about scopes in python. However, I still don't understand why the error is raised at line (A) rather than line (B). Does Python create its variable scope dictionary BEFORE running the program?", "user_id": "46521"}, {"stack_answer_id": "370380", "stack_answer_comment_id": "199744", "comment_content": "No, it's on the expression level.  I'll add to the answer, I don't think I can fit this in a comment.", "user_id": "None"}, {"stack_answer_id": "370380", "stack_answer_comment_id": "60085042", "comment_content": "Note on implementation details: In CPython, the local scope isn't usually handled as a ", "user_id": "None"}]}, {"stack_answer_id": "370830", "answer_content": "\r\n Taking a look at the disassembly may clarify what is happening: \n\n >>> def f():\n...    print a\n...    print b\n...    a = 1\n\n>>> import dis\n>>> dis.dis(f)\n\n  2           0 LOAD_FAST                0 (a)\n              3 PRINT_ITEM\n              4 PRINT_NEWLINE\n\n  3           5 LOAD_GLOBAL              0 (b)\n              8 PRINT_ITEM\n              9 PRINT_NEWLINE\n\n  4          10 LOAD_CONST               1 (1)\n             13 STORE_FAST               0 (a)\n             16 LOAD_CONST               0 (None)\n             19 RETURN_VALUE\n \n\n As you can see, the bytecode for accessing a is  LOAD_FAST , and for b,  LOAD_GLOBAL .  This is because the compiler has identified that a is assigned to within the function, and classified it as a local variable.  The access mechanism for locals is fundamentally different for globals - they are statically assigned an offset in the frame's variables table, meaning lookup is a quick index, rather than the more expensive dict lookup as for globals.  Because of this, Python is reading the  print a  line as \"get the value of local variable 'a' held in slot 0, and print it\", and when it detects that this variable is still uninitialised, raises an exception. \n    ", "date_posted": "2008-12-16 09:49:28Z", "upvote": "\r\n            51\r\n        ", "accepted": "No", "user": {"stack_user_id": "9493", "name": "Brian", "reputation_score": "114k"}, "answer_comments": []}, {"stack_answer_id": "370364", "answer_content": "\r\n Python has rather interesting behavior when you try traditional global variable semantics.  I don't remember the details, but you can read the value of a variable declared in 'global' scope just fine, but if you want to modify it, you have to use the  global  keyword.  Try changing  test()  to this: \n\n def test():\n    global c\n    print(a)\n    print(b)\n    print(c)    # (A)\n    c+=1        # (B)\n \n\n Also, the reason you are getting this error is because you can also declare a new variable inside that function with the same name as a 'global' one, and it would be completely separate.  The interpreter thinks you are trying to make a new variable in this scope called  c  and modify it all in one operation, which isn't allowed in Python because this new  c  wasn't initialized. \n    ", "date_posted": "2016-12-10 06:53:57Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "15168", "name": "Jonathan Leffler", "reputation_score": "704k"}, "answer_comments": [{"stack_answer_id": "370364", "stack_answer_comment_id": "199334", "comment_content": "Thanks for your response, but I don't think it explains why the error is thrown at line (A), where I'm merely trying to print a variable. The program never gets to line (B) where it is trying to modify an un-initialized variable.", "user_id": "46521"}, {"stack_answer_id": "370364", "stack_answer_comment_id": "199708", "comment_content": "Python will read, parse and turn the whole function into internal bytecode before it starts running the program, so the fact that the \"turn c to local variable\" happens textually after the printing of the value doesn't, as it were, matter.", "user_id": "None"}, {"stack_answer_id": "370364", "stack_answer_comment_id": "129046450", "comment_content": "Python lets you access global variables in a local scope for reading, but not for writing.  This answer has a nice work-around with explanation in comment below... +=1.", "user_id": "None"}]}, {"stack_answer_id": "24035261", "answer_content": "\r\n The best example that makes it clear is: \n\n bar = 42\ndef foo():\n    print bar\n    if False:\n        bar = 0\n \n\n when calling  foo()  , this also  raises   UnboundLocalError  although we will never reach to line  bar=0 , so logically local variable should never be created. \n\n The mystery lies in \" Python is an Interpreted Language \" and the declaration of the function  foo  is interpreted as a single statement (i.e. a compound statement), it just interprets it dumbly and creates local and global scopes. So  bar  is recognized in local scope before execution. \n\n For  more examples  like this Read this post:  http://blog.amir.rachum.com/blog/2013/07/09/python-common-newbie-mistakes-part-2/ \n\n This post provides a Complete Description and Analyses of the Python Scoping of variables: \n    ", "date_posted": "2014-06-04 10:39:21Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "1731648", "name": "Sahil kalra", "reputation_score": "7,578"}, "answer_comments": []}, {"stack_answer_id": "1745180", "answer_content": "\r\n Here are two links that may help \n\n 1:  docs.python.org/3.1/faq/programming.html?highlight=nonlocal#why-am-i-getting-an-unboundlocalerror-when-the-variable-has-a-value \n\n 2:  docs.python.org/3.1/faq/programming.html?highlight=nonlocal#how-do-i-write-a-function-with-output-parameters-call-by-reference \n\n link one describes the error UnboundLocalError.  Link two can help with with re-writing your test function.  Based on link two, the original problem could be rewritten as: \n\n >>> a, b, c = (1, 2, 3)\n>>> print (a, b, c)\n(1, 2, 3)\n>>> def test (a, b, c):\n...     print (a)\n...     print (b)\n...     print (c)\n...     c += 1\n...     return a, b, c\n...\n>>> a, b, c = test (a, b, c)\n1\n2\n3\n>>> print (a, b ,c)\n(1, 2, 4)\n \n    ", "date_posted": "2011-09-13 04:00:56Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "68210", "name": "Daniel X Moore", "reputation_score": "14.2k"}, "answer_comments": []}, {"stack_answer_id": "476123", "answer_content": "\r\n This is not a direct answer to your question, but it is closely related, as it's another gotcha caused by the relationship between augmented assignment and function scopes. \n\n In most cases, you tend to think of augmented assignment ( a += b ) as exactly equivalent to simple assignment ( a = a + b ). It is possible to get into some trouble with this though, in one corner case. Let me explain: \n\n The way Python's simple assignment works means that if  a  is passed into a function (like  func(a) ; note that Python is always pass-by-reference), then  a = a + b  will not modify the  a  that is passed in. Instead, it will just modify the local pointer to  a .  \n\n But if you use  a += b , then it is sometimes implemented as: \n\n a = a + b\n \n\n or sometimes (if the method exists) as: \n\n a.__iadd__(b)\n \n\n In the first case (as long as  a  is not declared global), there are no side-effects outside local scope, as the assignment to  a  is just a pointer update. \n\n In the second case,  a  will actually modify itself, so all references to  a  will point to the modified version. This is demonstrated by the following code: \n\n def copy_on_write(a):\n      a = a + a\ndef inplace_add(a):\n      a += a\na = [1]\ncopy_on_write(a)\nprint a # [1]\ninplace_add(a)\nprint a # [1, 1]\nb = 1\ncopy_on_write(b)\nprint b # [1]\ninplace_add(b)\nprint b # 1\n \n\n So the trick is to avoid augmented assignment on function arguments (I try to only use it for local/loop variables). Use simple assignment, and you will be safe from ambiguous behaviour.  \n    ", "date_posted": "2016-12-10 07:07:03Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "15168", "name": "Jonathan Leffler", "reputation_score": "704k"}, "answer_comments": []}, {"stack_answer_id": "370752", "answer_content": "\r\n The Python interpreter will read a function as a complete unit. I think of it as reading it in two passes, once to gather its closure (the local variables), then again to turn it into byte-code. \n\n As I'm sure you were already aware, any name used on the left of a '=' is implicitly a local variable. More than once I've been caught out by changing a variable access to a += and it's suddenly a different variable. \n\n I also wanted to point out it's not really anything to do with global scope specifically. You get the same behaviour with nested functions. \n    ", "date_posted": "2008-12-16 08:58:10Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "11828", "name": "James Hopkin", "reputation_score": "13.5k"}, "answer_comments": []}, {"stack_answer_id": "40409182", "answer_content": "\r\n c+=1  assigns  c , python assumes assigned variables are local, but in this case it hasn't been declared locally. \n\n Either use the  global  or  nonlocal  keywords.  \n\n nonlocal  works only in python 3, so if you're using python 2 and don't want to make your variable global, you can use a mutable object: \n\n my_variables = { # a mutable object\n    'c': 3\n}\n\ndef test():\n    my_variables['c'] +=1\n\ntest()\n \n    ", "date_posted": "2016-11-03 18:52:39Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "2392540", "name": "Colegram", "reputation_score": "106"}, "answer_comments": []}, {"stack_answer_id": "34153129", "answer_content": "\r\n The best way to reach class variable is directly accesing by class name \n\n class Employee:\n    counter=0\n\n    def __init__(self):\n        Employee.counter+=1\n \n    ", "date_posted": "2015-12-08 10:09:47Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "4104008", "name": "Harun ERGUL", "reputation_score": "5,446"}, "answer_comments": []}, {"stack_answer_id": "71914016", "answer_content": "\r\n You can also get this message if you define a variable with the same name as a method. \n For example: \n def teams():\n    ...\n\ndef some_other_method():\n    teams = teams()\n \n The solution, is to rename method  teams()  to something else like  get_teams() . \n Since it is only used locally, the Python message is rather misleading! \n You end up with something like this to get around it: \n def teams():\n    ...\n\ndef some_other_method():\n    teams = get_teams()\n \n    ", "date_posted": "2022-04-18 15:47:47Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "495157", "name": "JGFMK", "reputation_score": "7,889"}, "answer_comments": []}, {"stack_answer_id": "72633950", "answer_content": "\r\n This issue can also occur when the  del  keyword is utilized on the variable down the line, after initialization, typically in a loop or a conditional block. \n    ", "date_posted": "2022-06-15 15:21:05Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "221781", "name": "izilotti", "reputation_score": "4,659"}, "answer_comments": []}, {"stack_answer_id": "58002885", "answer_content": "\r\n The same problem bothers me. Using  nonlocal  and  global  can solve the problem. \nHowever, attention is needed for the usage of  nonlocal , it works for nested functions. However, at the module level, it does not work. See  examples  here. \n    ", "date_posted": "2020-12-06 21:16:23Z", "upvote": "\r\n            -1\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}], "user": {"stack_user_id": "46521", "name": "tba", "reputation_score": "5,881"}, "question_comments": [{"stack_question_id": "370357", "stack_question_comment_id": "110835190", "comment_content": "Does this answer your question? ", "user_id": "None"}, {"stack_question_id": "370357", "stack_question_comment_id": "123548687", "comment_content": "Same error but different cause: ", "user_id": "None"}]},
{"stack_question_id": "6260089", "question_title": "Strange result when removing item from a list while iterating over it", "question_content": "\r\n                I've got this piece of code:\nnumbers = list(range(1, 50))\n\nfor i in numbers:\n    if i < 20:\n        numbers.remove(i)\n\nprint(numbers)\n\nbut the result I'm getting is:\n[2, 4, 6, 8, 10, 12, 14, 16, 18,...\r\n", "question_url": "/questions/6260089/strange-result-when-removing-item-from-a-list-while-iterating-over-it", "date_posted": "Jun 7, 2011 at 2:29", "upvote": "7", "view": "1", "tags": ["python", "list", "loops"], "answers_count": "8", "answers": [{"stack_answer_id": "6260097", "answer_content": "\r\n You're modifying the list while you iterate over it. That means that the first time through the loop,  i == 1 , so 1 is removed from the list. Then the  for  loop goes to the second item in the list, which is not 2, but 3! Then that's removed from the list, and then the  for  loop goes on to the third item in the list, which is now 5. And so on. Perhaps it's easier to visualize like so, with a ^ pointing to the value of  i : \n\n [1, 2, 3, 4, 5, 6...]\n ^\n \n\n That's the state of the list initially; then 1 is removed and the loop goes to the second item in the list: \n\n [2, 3, 4, 5, 6...]\n    ^\n[2, 4, 5, 6...]\n       ^\n \n\n And so on.  \n\n There's no good way to alter a list's length while iterating over it. The best you can do is something like this: \n\n numbers = [n for n in numbers if n >= 20]\n \n\n or this, for in-place alteration (the thing in parens is a generator expression, which is implicitly converted into a tuple before slice-assignment): \n\n numbers[:] = (n for in in numbers if n >= 20)\n \n\n If you want to perform an operation on n before removing it, one trick you could try is this: \n\n for i, n in enumerate(numbers):\n    if n < 20 :\n        print(\"do something\")\n        numbers[i] = None\nnumbers = [n for n in numbers if n is not None]\n \n    ", "date_posted": "2020-05-28 12:59:52Z", "upvote": "\r\n            133\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "1398841", "name": "phoenix", "reputation_score": "6,278"}, "answer_comments": [{"stack_answer_id": "6260097", "stack_answer_comment_id": "125375319", "comment_content": "Related note on ", "user_id": "None"}, {"stack_answer_id": "6260097", "stack_answer_comment_id": "126368556", "comment_content": "This is a good answer, but with the final solution, \"if you want to perform an operation...\", is slightly unsatisfactory because 1) in fact there is no need to include that qualification: it is just a waste of effort to try and remove elements while iterating in a single operation, so this 2-stage solution applies in all cases, and 2) because there should be a warning that setting to ", "user_id": "None"}, {"stack_answer_id": "6260097", "stack_answer_comment_id": "126369014", "comment_content": "When I say that about the \"waste of effort\", I am referring to the \"general\" solution by the way, i.e. when random elements may need removing, rather than the \"specialist\" case of removing elements only at the start (or only at the end), which lends itself to something simple, like your list comprehension solution...", "user_id": "None"}]}, {"stack_answer_id": "8752528", "answer_content": "\r\n Begin at the list's end and go backwards: \n li = list(range(1, 15))\nprint(li)\n\nfor i in range(len(li) - 1, -1, -1):\n    if li[i] < 6:\n        del li[i]\n        \nprint(li)\n \n Result: \n [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14] \n[6, 7, 8, 9, 10, 11, 12, 13, 14]\n \n    ", "date_posted": "2022-04-07 11:47:31Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": [{"stack_answer_id": "8752528", "stack_answer_comment_id": "124218137", "comment_content": "How I wish I could +2 this answer!  Elegant, easy...not entirely obfuscated.", "user_id": "None"}, {"stack_answer_id": "8752528", "stack_answer_comment_id": "126368881", "comment_content": "This is a very specialised answer: it is not in fact clear whether we're meant to be looking for a general solution to the problem of how to remove elements while iterating, or how to do this exclusively when we just want to remove the first n elements of a list. The chosen answer provides the former, which is infinitely more helpful, but also the latter, in the shape of a one-line list comprehension solution.", "user_id": "None"}, {"stack_answer_id": "8752528", "stack_answer_comment_id": "126851697", "comment_content": "@mikerodent no it's not. It's pretty common when you want to modify a list while iterating over it that going backwards works", "user_id": "None"}, {"stack_answer_id": "8752528", "stack_answer_comment_id": "126853332", "comment_content": "@Boris you haven't understood my comment. The OP's question does not specify that we are removing contiguous elements (either from the start or end of the list).", "user_id": "None"}, {"stack_answer_id": "8752528", "stack_answer_comment_id": "126853360", "comment_content": "I still don't understand your comment then because it doesn't matter whether the list is shuffled or ordered, this code will still work.", "user_id": "None"}]}, {"stack_answer_id": "6260408", "answer_content": "\r\n @senderle's  answer is the way to go! \n Having said that to further illustrate even a bit more your problem, if you think about it, you will always want to remove the index 0 twenty times: \n [1,2,3,4,5............50]\n ^\n[2,3,4,5............50]\n ^\n[3,4,5............50]\n ^\n \n So you could actually go with something like this: \n aList = list(range(50))\ni = 0\nwhile i < 20:\n    aList.pop(0)\n    i += 1\n\nprint(aList) #[21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n \n I hope it helps. \n \n The ones below are  not  bad practices AFAIK. \n EDIT (Some more): \n lis = range(50)\nlis = lis[20:]\n \n Will do the job also. \n EDIT2 (I'm bored): \n functional = filter(lambda x: x> 20, range(50))\n \n    ", "date_posted": "2021-06-15 09:17:27Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "7496129", "name": "Sneha Valabailu", "reputation_score": "95"}, "answer_comments": []}, {"stack_answer_id": "64835673", "answer_content": "\r\n So I found a solution but it's really clumsy... \n First of all you make an index array, where you list all the index' you want to delete like in the following \n numbers = range(1, 50)\nindex_arr = []\n\nfor i in range(len(numbers):\n    if numbers[i] < 20:\n        index_arr.append(i)\n\n \n after that you want to delete all the entries from the numbers list with the index saved in the index_arr. The problem you will encounter is the same as before. Therefore you have to subtract 1 from every index in the index_arr after you just removed a number from the numbers arr, like in the following: \n numbers = range(1, 50)\nindex_arr = []\n\nfor i in range(len(numbers):\n    if numbers[i] < 20:\n        index_arr.append(i)\n\nfor del_index in index_list:\n    numbers.pop(del_index)\n\n    #the nasty part\n    for i in range(len(index_list)):\n        index_list[i] -= 1\n \n It will work, but I guess it's not the intended way to do it \n    ", "date_posted": "2020-11-14 15:44:33Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "13761698", "name": "Yassin Julian", "reputation_score": "39"}, "answer_comments": []}, {"stack_answer_id": "70269930", "answer_content": "\r\n Building on and simplying the answer by @eyquem ... \n The problem is that elements are being yanked out from under you as you iterate, skipping numbers as you progress to what  was  the next number. \n If you start from the end and go backwards, removing items on-the-go won't matter, because when it steps to the \"next\" item (actually the prior item), the deletion does not affect the first half of the list. \n Simply adding  reversed()  to your iterator solves the problem. A comment would be good form to preclude future developers from \"tidying up\" your code and breaking it mysteriously. \n for i in reversed(numbers): # `reversed` so removing doesn't foobar iteration\n  if i < 20:\n    numbers.remove(i)\n \n    ", "date_posted": "2021-12-08 04:24:02Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "4454732", "name": "David Hempy", "reputation_score": "4,434"}, "answer_comments": []}, {"stack_answer_id": "67652659", "answer_content": "\r\n As an additional information to @Senderle's answer, just for records,  I thought it's helpful to visualize the logic behind the scene when python sees  for  on a \" Sequence type \". \n Let's say we have : \n lst = [1, 2, 3, 4, 5]\n\nfor i in lst:\n    print(i ** 2)\n \n It is actually going to be : \n index = 0\nwhile True:\n    try:\n        i = lst.__getitem__(index)\n    except IndexError:\n        break\n    print(i ** 2)\n    index += 1\n \n That's what it is, there is a try-catch mechanism that  for  has when we use it on a Sequence types or Iterables(It's a little different though - calling  next()  and  StopIteration  Exception). \n *All I'm trying to say is, python will keep track of an independent variable here called  index , so no matter what happens to the list (removing or adding), python increments that variable and calls  __getitem__()  method with \"this variable\" and asks for item. \n    ", "date_posted": "2021-05-22 17:59:27Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "13944524", "name": "S.B", "reputation_score": "8,308"}, "answer_comments": []}, {"stack_answer_id": "67703510", "answer_content": "\r\n You could also use continue to  ignore the values less than 20 \n mylist = []\n\nfor i in range(51):\n    if i<20:\n        continue\n    else:\n        mylist.append(i)\nprint(mylist)\n \n    ", "date_posted": "2021-05-26 10:57:47Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "13734451", "name": "Moses", "reputation_score": "1,025"}, "answer_comments": []}, {"stack_answer_id": "71138926", "answer_content": "\r\n Since  Python 3.3  you may use the list  copy()  method as the iterator: \n numbers = list(range(1, 50))\n\nfor i in numbers.copy():\n    if i < 20:\n        numbers.remove(i)\nprint(numbers)\n\n[20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n \n    ", "date_posted": "2022-02-16 09:07:21Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "3474282", "name": "Cosmittus", "reputation_score": "622"}, "answer_comments": [{"stack_answer_id": "71138926", "stack_answer_comment_id": "126368658", "comment_content": "This looks like a neat suggestion to a classic problem, but I'm not sure that in practice it will prove better than the 2-stage solution suggested at the end of the chosen answer: firstly, what is the cost of the ", "user_id": "None"}]}], "user": {"stack_user_id": "415088", "name": "Finger twist", "reputation_score": "3,314"}, "question_comments": [{"stack_question_id": "6260089", "stack_question_comment_id": "129230071", "comment_content": "See also: ", "user_id": "None"}]},
{"stack_question_id": "38987", "question_title": "How do I merge two dictionaries in a single expression?", "question_content": "\r\n                I want to merge two dictionaries into a new dictionary.\nx = {'a': 1, 'b': 2}\ny = {'b': 3, 'c': 4}\nz = merge(x, y)\n\n>>> z\n{'a': 1, 'b': 3, 'c': 4}\n\nWhenever a key k is present in both ...\r\n", "question_url": "/questions/38987/how-do-i-merge-two-dictionaries-in-a-single-expression", "date_posted": "Sep 2, 2008 at 7:44", "upvote": "6", "view": "2", "tags": ["python", "dictionary", "merge"], "answers_count": "4", "answers": [{"stack_answer_id": "26853961", "answer_content": "\r\n How can I merge two Python dictionaries in a single expression? \n For dictionaries  x  and  y , their shallowly-merged dictionary  z  takes values from  y , replacing those from  x . \n \n In Python 3.9.0 or greater (released 17 October 2020,  PEP-584 ,  discussed here ): \n z = x | y\n \n \n In Python 3.5 or greater: \n z = {**x, **y}\n \n \n In Python 2, (or 3.4 or lower) write a function: \n def merge_two_dicts(x, y):\n    z = x.copy()   # start with keys and values of x\n    z.update(y)    # modifies z with keys and values of y\n    return z\n \n and now: \n z = merge_two_dicts(x, y)\n \n \n \n Explanation \n Say you have two dictionaries and you want to merge them into a new dictionary without altering the original dictionaries: \n x = {'a': 1, 'b': 2}\ny = {'b': 3, 'c': 4}\n \n The desired result is to get a new dictionary ( z ) with the values merged, and the second dictionary's values overwriting those from the first. \n >>> z\n{'a': 1, 'b': 3, 'c': 4}\n \n A new syntax for this, proposed in  PEP 448  and  available as of Python 3.5 , is \n z = {**x, **y}\n \n And it is indeed a single expression. \n Note that we can merge in with literal notation as well: \n z = {**x, 'foo': 1, 'bar': 2, **y}\n \n and now: \n >>> z\n{'a': 1, 'b': 3, 'foo': 1, 'bar': 2, 'c': 4}\n \n It is now showing as implemented in the  release schedule for 3.5, PEP 478 , and it has now made its way into the  What's New in Python 3.5  document. \n However, since many organizations are still on Python 2, you may wish to do this in a backward-compatible way. The classically Pythonic way, available in Python 2 and Python 3.0-3.4, is to do this as a two-step process: \n z = x.copy()\nz.update(y) # which returns None since it mutates z\n \n In both approaches,  y  will come second and its values will replace  x 's values, thus  b  will point to  3  in our final result. \n Not yet on Python 3.5, but want a  single expression \n If you are not yet on Python 3.5 or need to write backward-compatible code, and you want this in a  single expression , the most performant while the correct approach is to put it in a function: \n def merge_two_dicts(x, y):\n    \"\"\"Given two dictionaries, merge them into a new dict as a shallow copy.\"\"\"\n    z = x.copy()\n    z.update(y)\n    return z\n \n and then you have a single expression: \n z = merge_two_dicts(x, y)\n \n You can also make a function to merge an arbitrary number of dictionaries, from zero to a very large number: \n def merge_dicts(*dict_args):\n    \"\"\"\n    Given any number of dictionaries, shallow copy and merge into a new dict,\n    precedence goes to key-value pairs in latter dictionaries.\n    \"\"\"\n    result = {}\n    for dictionary in dict_args:\n        result.update(dictionary)\n    return result\n \n This function will work in Python 2 and 3 for all dictionaries. e.g. given dictionaries  a  to  g : \n z = merge_dicts(a, b, c, d, e, f, g) \n \n and key-value pairs in  g  will take precedence over dictionaries  a  to  f , and so on. \n Critiques of Other Answers \n Don't use what you see in the formerly accepted answer: \n z = dict(x.items() + y.items())\n \n In Python 2, you create two lists in memory for each dict, create a third list in memory with length equal to the length of the first two put together, and then discard all three lists to create the dict.  In Python 3, this will fail  because you're adding two  dict_items  objects together, not two lists - \n >>> c = dict(a.items() + b.items())\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: unsupported operand type(s) for +: 'dict_items' and 'dict_items'\n \n and you would have to explicitly create them as lists, e.g.  z = dict(list(x.items()) + list(y.items())) . This is a waste of resources and computation power. \n Similarly, taking the union of  items()  in Python 3 ( viewitems()  in Python 2.7) will also fail when values are unhashable objects (like lists, for example). Even if your values are hashable,  since sets are semantically unordered, the behavior is undefined in regards to precedence. So don't do this: \n >>> c = dict(a.items() | b.items())\n \n This example demonstrates what happens when values are unhashable: \n >>> x = {'a': []}\n>>> y = {'b': []}\n>>> dict(x.items() | y.items())\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: unhashable type: 'list'\n \n Here's an example where  y  should have precedence, but instead the value from  x  is retained due to the arbitrary order of sets: \n >>> x = {'a': 2}\n>>> y = {'a': 1}\n>>> dict(x.items() | y.items())\n{'a': 2}\n \n Another hack you should not use: \n z = dict(x, **y)\n \n This uses the  dict  constructor and is very fast and memory-efficient (even slightly more so than our two-step process) but unless you know precisely what is happening here (that is, the second dict is being passed as keyword arguments to the dict constructor), it's difficult to read, it's not the intended usage, and so it is not Pythonic. \n Here's an example of the usage being  remediated in django . \n Dictionaries are intended to take hashable keys (e.g.  frozenset s or tuples), but  this method fails in Python 3 when keys are not strings. \n >>> c = dict(a, **b)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: keyword arguments must be strings\n \n From the  mailing list , Guido van Rossum, the creator of the language, wrote: \n \n I am fine with\ndeclaring dict({}, **{1:3}) illegal, since after all it is abuse of\nthe ** mechanism. \n \n and \n \n Apparently dict(x, **y) is going around as \"cool hack\" for \"call\nx.update(y) and return x\". Personally, I find it more despicable than\ncool. \n \n It is my understanding (as well as the understanding of the  creator of the language ) that the intended usage for  dict(**y)  is for creating dictionaries for readability purposes, e.g.: \n dict(a=1, b=10, c=11)\n \n instead of \n {'a': 1, 'b': 10, 'c': 11}\n \n Response to comments \n \n Despite what Guido says,  dict(x, **y)  is in line with the dict specification, which btw. works for both Python 2 and 3. The fact that this only works for string keys is a direct consequence of how keyword parameters work and not a short-coming of dict. Nor is using the ** operator in this place an abuse of the mechanism, in fact, ** was designed precisely to pass dictionaries as keywords. \n \n Again, it doesn't work for 3 when keys are not strings. The implicit calling contract is that namespaces take ordinary dictionaries, while users must only pass keyword arguments that are strings. All other callables enforced it.  dict  broke this consistency in Python 2: \n >>> foo(**{('a', 'b'): None})\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: foo() keywords must be strings\n>>> dict(**{('a', 'b'): None})\n{('a', 'b'): None}\n \n This inconsistency was bad given other implementations of Python (PyPy, Jython, IronPython). Thus it was fixed in Python 3, as this usage could be a breaking change. \n I submit to you that it is malicious incompetence to intentionally write code that only works in one version of a language or that only works given certain arbitrary constraints. \n More comments: \n \n dict(x.items() + y.items())  is still the most readable solution for Python 2. Readability counts. \n \n My response:  merge_two_dicts(x, y)  actually seems much clearer to me, if we're actually concerned about readability. And it is not forward compatible, as Python 2 is increasingly deprecated. \n \n {**x, **y}  does not seem to handle nested dictionaries. the contents of nested keys are simply overwritten, not merged [...] I ended up being burnt by these answers that do not merge recursively and I was surprised no one mentioned it. In my interpretation of the word \"merging\" these answers describe \"updating one dict with another\", and not merging. \n \n Yes. I must refer you back to the question, which is asking for a  shallow  merge of  two  dictionaries, with the first's values being overwritten by the second's - in a single expression. \n Assuming two dictionaries of dictionaries, one might recursively merge them in a single function, but you should be careful not to modify the dictionaries from either source, and the surest way to avoid that is to make a copy when assigning values. As keys must be hashable and are usually therefore immutable, it is pointless to copy them: \n from copy import deepcopy\n\ndef dict_of_dicts_merge(x, y):\n    z = {}\n    overlapping_keys = x.keys() & y.keys()\n    for key in overlapping_keys:\n        z[key] = dict_of_dicts_merge(x[key], y[key])\n    for key in x.keys() - overlapping_keys:\n        z[key] = deepcopy(x[key])\n    for key in y.keys() - overlapping_keys:\n        z[key] = deepcopy(y[key])\n    return z\n \n Usage: \n >>> x = {'a':{1:{}}, 'b': {2:{}}}\n>>> y = {'b':{10:{}}, 'c': {11:{}}}\n>>> dict_of_dicts_merge(x, y)\n{'b': {2: {}, 10: {}}, 'a': {1: {}}, 'c': {11: {}}}\n \n Coming up with contingencies for other value types is far beyond the scope of this question, so I will point you at  my answer to the canonical question on a \"Dictionaries of dictionaries merge\" . \n Less Performant But Correct Ad-hocs \n These approaches are less performant, but they will provide correct behavior.\nThey will be  much less  performant than  copy  and  update  or the new unpacking because they iterate through each key-value pair at a higher level of abstraction, but they  do  respect the order of precedence (latter dictionaries have precedence) \n You can also chain the dictionaries manually inside a  dict comprehension : \n {k: v for d in dicts for k, v in d.items()} # iteritems in Python 2.7\n \n or in Python 2.6 (and perhaps as early as 2.4 when generator expressions were introduced): \n dict((k, v) for d in dicts for k, v in d.items()) # iteritems in Python 2\n \n itertools.chain  will chain the iterators over the key-value pairs in the correct order: \n from itertools import chain\nz = dict(chain(x.items(), y.items())) # iteritems in Python 2\n \n Performance Analysis \n I'm only going to do the performance analysis of the usages known to behave correctly. (Self-contained so you can copy and paste yourself.) \n from timeit import repeat\nfrom itertools import chain\n\nx = dict.fromkeys('abcdefg')\ny = dict.fromkeys('efghijk')\n\ndef merge_two_dicts(x, y):\n    z = x.copy()\n    z.update(y)\n    return z\n\nmin(repeat(lambda: {**x, **y}))\nmin(repeat(lambda: merge_two_dicts(x, y)))\nmin(repeat(lambda: {k: v for d in (x, y) for k, v in d.items()}))\nmin(repeat(lambda: dict(chain(x.items(), y.items()))))\nmin(repeat(lambda: dict(item for d in (x, y) for item in d.items())))\n \n In Python 3.8.1, NixOS: \n >>> min(repeat(lambda: {**x, **y}))\n1.0804965235292912\n>>> min(repeat(lambda: merge_two_dicts(x, y)))\n1.636518670246005\n>>> min(repeat(lambda: {k: v for d in (x, y) for k, v in d.items()}))\n3.1779992282390594\n>>> min(repeat(lambda: dict(chain(x.items(), y.items()))))\n2.740647904574871\n>>> min(repeat(lambda: dict(item for d in (x, y) for item in d.items())))\n4.266070580109954\n \n $ uname -a\nLinux nixos 4.19.113 #1-NixOS SMP Wed Mar 25 07:06:15 UTC 2020 x86_64 GNU/Linux\n \n Resources on Dictionaries \n \n My explanation of Python's  dictionary implementation , updated for 3.6. \n Answer on how to add new keys to a dictionary \n Mapping two lists into a dictionary \n The official Python docs on dictionaries \n The Dictionary Even Mightier  - talk by Brandon Rhodes at Pycon 2017 \n Modern Python Dictionaries, A Confluence of Great Ideas  - talk by Raymond Hettinger at Pycon 2017 \n \n    ", "date_posted": "2022-03-29 10:49:08Z", "upvote": "\r\n            8286\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": [{"stack_answer_id": "26853961", "stack_answer_comment_id": "98971751", "comment_content": "@MohammadAzim \"strings only\" only applies to keyword argument expansion in callables, not generalized unpacking syntax. To demonstrate that this works: ", "user_id": "None"}, {"stack_answer_id": "26853961", "stack_answer_comment_id": "106950304", "comment_content": "This may be changed when PEP-0584 is accepted. A new union operator will be implemented with the following syntax: ", "user_id": "None"}, {"stack_answer_id": "26853961", "stack_answer_comment_id": "106950627", "comment_content": "@cal97g yes, I addressed that in my answer about 10 days ago: ", "user_id": "None"}, {"stack_answer_id": "26853961", "stack_answer_comment_id": "107329096", "comment_content": "Hi, the top is a summary, yes.  Up to you.  The whole thing would be a great blog post.  Note Py 3.4 and below are EOL, 3.5 approaching EOL in 2020-09.", "user_id": "None"}, {"stack_answer_id": "26853961", "stack_answer_comment_id": "109402225", "comment_content": "I agree with the eagerness to leave the old way behind, but sometimes people have to work in environments where they only have the older technology available to them. People also have to update code, and seeing the old way next to the new way allows them to confidently replace the old code with equivalent new code. I am open to suggestions on reorganizing the material, but I think we need to keep the older information.", "user_id": "None"}]}, {"stack_answer_id": "38990", "answer_content": "\r\n In your case, what you can do is: \n z = dict(list(x.items()) + list(y.items()))\n \n This will, as you want it, put the final dict in  z , and make the value for key  b  be properly overridden by the second ( y ) dict's value: \n >>> x = {'a':1, 'b': 2}\n>>> y = {'b':10, 'c': 11}\n>>> z = dict(list(x.items()) + list(y.items()))\n>>> z\n{'a': 1, 'c': 11, 'b': 10}\n\n \n If you use Python 2, you can even remove the  list()  calls. To create z: \n >>> z = dict(x.items() + y.items())\n>>> z\n{'a': 1, 'c': 11, 'b': 10}\n \n If you use Python version 3.9.0a4 or greater, then you can directly use: \n x = {'a':1, 'b': 2}\ny = {'b':10, 'c': 11}\nz = x | y\nprint(z)\n \n {'a': 1, 'c': 11, 'b': 10}\n \n    ", "date_posted": "2020-10-30 21:08:09Z", "upvote": "\r\n            1766\r\n        ", "accepted": "No", "user": {"stack_user_id": "3815432", "name": "Nikita Vlasenko", "reputation_score": "3,634"}, "answer_comments": [{"stack_answer_id": "38990", "stack_answer_comment_id": "107286634", "comment_content": "Don't use this as it is very inefficient.  (See the timeit results below.)  It may have been necessary in the Py2 days if a wrapper function was not an option, but those days are now past.", "user_id": "None"}]}, {"stack_answer_id": "39437", "answer_content": "\r\n An alternative: \n\n z = x.copy()\nz.update(y)\n \n    ", "date_posted": "2008-09-02 13:00:46Z", "upvote": "\r\n            729\r\n        ", "accepted": "No", "user": {"stack_user_id": "188", "name": "Matthew Schinckel", "reputation_score": "34.1k"}, "answer_comments": [{"stack_answer_id": "39437", "stack_answer_comment_id": "22031787", "comment_content": "To clarify why this doesn't meet the critera provided by the question: it's not a single expression and it doesn't return z.", "user_id": "None"}, {"stack_answer_id": "39437", "stack_answer_comment_id": "80608499", "comment_content": "Put it this way: if you need to put two lines of comments explaining your one line of code to the people you hand your code off to...have you really done it in one line? :) I fully agree Python is not good for this: there should be a much easier way. While this answer is more pythonic, is it really all that explicit or clear? ", "user_id": "None"}, {"stack_answer_id": "39437", "stack_answer_comment_id": "106803501", "comment_content": "Well, if people insist on making it a oneliner, you can always do ", "user_id": "None"}, {"stack_answer_id": "39437", "stack_answer_comment_id": "128914525", "comment_content": "@AlexanderOh I am not sure whenever this is a joke or not; I see this as a perfectly (valid) answ!  (at least in terms of it works) but Of course;  yeah; the second comment sets a precedent!    either way; it is ", "user_id": "None"}, {"stack_answer_id": "39437", "stack_answer_comment_id": "128918894", "comment_content": "@WilliamMartens it wasn't a joke. But let's face it, if you optimize for single line expressions,you are optimizing for the wrong thing.", "user_id": "None"}]}, {"stack_answer_id": "39858", "answer_content": "\r\n Another, more concise, option: \n\n z = dict(x, **y)\n \n\n Note : this has become a popular answer, but it is important to point out that if  y  has any non-string keys, the fact that this works at all is an abuse of a CPython implementation detail, and it does not work in Python 3, or in PyPy, IronPython, or Jython. Also,  Guido is not a fan . So I can't recommend this technique for forward-compatible or cross-implementation portable code, which really means it should be avoided entirely. \n    ", "date_posted": "2016-01-21 06:43:24Z", "upvote": "\r\n            421\r\n        ", "accepted": "No", "user": {"stack_user_id": "3207", "name": "Carl Meyer", "reputation_score": "116k"}, "answer_comments": [{"stack_answer_id": "39858", "stack_answer_comment_id": "97993261", "comment_content": ", can't speak to Jython or Iron. Given this pattern is ", "user_id": "None"}, {"stack_answer_id": "39858", "stack_answer_comment_id": "98801135", "comment_content": "@amcgregor You missed the key phrase \"if y has any non-string keys.\" That's what doesn't work in Python3; the fact that it works in CPython 2 is an implementation detail that can't be relied on. IFF all your keys are guaranteed to be strings, this is a fully supported option.", "user_id": "3207"}]}, {"stack_answer_id": "49492", "answer_content": "\r\n This probably won't be a popular answer, but you almost certainly do not want to do this.  If you want a copy that's a merge, then use copy (or  deepcopy , depending on what you want) and then update.  The two lines of code are much more readable - more Pythonic - than the single line creation with .items() + .items().  Explicit is better than implicit. \n\n In addition, when you use .items() (pre Python 3.0), you're creating a new list that contains the items from the dict.  If your dictionaries are large, then that is quite a lot of overhead (two large lists that will be thrown away as soon as the merged dict is created).  update() can work more efficiently, because it can run through the second dict item-by-item. \n\n In terms of  time : \n\n >>> timeit.Timer(\"dict(x, **y)\", \"x = dict(zip(range(1000), range(1000)))\\ny=dict(zip(range(1000,2000), range(1000,2000)))\").timeit(100000)\n15.52571702003479\n>>> timeit.Timer(\"temp = x.copy()\\ntemp.update(y)\", \"x = dict(zip(range(1000), range(1000)))\\ny=dict(zip(range(1000,2000), range(1000,2000)))\").timeit(100000)\n15.694622993469238\n>>> timeit.Timer(\"dict(x.items() + y.items())\", \"x = dict(zip(range(1000), range(1000)))\\ny=dict(zip(range(1000,2000), range(1000,2000)))\").timeit(100000)\n41.484580039978027\n \n\n IMO the tiny slowdown between the first two is worth it for the readability.  In addition, keyword arguments for dictionary creation was only added in Python 2.3, whereas copy() and update() will work in older versions. \n    ", "date_posted": "2014-08-05 23:56:02Z", "upvote": "\r\n            252\r\n        ", "accepted": "No", "user": {"stack_user_id": "2213647", "name": "twasbrillig", "reputation_score": "15.3k"}, "answer_comments": []}, {"stack_answer_id": "228366", "answer_content": "\r\n In a follow-up answer, you asked about the relative performance of these two alternatives: \n\n z1 = dict(x.items() + y.items())\nz2 = dict(x, **y)\n \n\n On my machine, at least (a fairly ordinary x86_64 running Python 2.5.2), alternative  z2  is not only shorter and simpler but also significantly faster.  You can verify this for yourself using the  timeit  module that comes with Python. \n\n Example 1: identical dictionaries mapping 20 consecutive integers to themselves: \n\n % python -m timeit -s 'x=y=dict((i,i) for i in range(20))' 'z1=dict(x.items() + y.items())'\n100000 loops, best of 3: 5.67 usec per loop\n% python -m timeit -s 'x=y=dict((i,i) for i in range(20))' 'z2=dict(x, **y)' \n100000 loops, best of 3: 1.53 usec per loop\n \n\n z2  wins by a factor of 3.5 or so.  Different dictionaries seem to yield quite different results, but  z2  always seems to come out ahead.  (If you get inconsistent results for the  same  test, try passing in  -r  with a number larger than the default 3.) \n\n Example 2: non-overlapping dictionaries mapping 252 short strings to integers and vice versa: \n\n % python -m timeit -s 'from htmlentitydefs import codepoint2name as x, name2codepoint as y' 'z1=dict(x.items() + y.items())'\n1000 loops, best of 3: 260 usec per loop\n% python -m timeit -s 'from htmlentitydefs import codepoint2name as x, name2codepoint as y' 'z2=dict(x, **y)'               \n10000 loops, best of 3: 26.9 usec per loop\n \n\n z2  wins by about a factor of 10.  That's a pretty big win in my book! \n\n After comparing those two, I wondered if  z1 's poor performance could be attributed to the overhead of constructing the two item lists, which in turn led me to wonder if this variation might work better: \n\n from itertools import chain\nz3 = dict(chain(x.iteritems(), y.iteritems()))\n \n\n A few quick tests, e.g. \n\n % python -m timeit -s 'from itertools import chain; from htmlentitydefs import codepoint2name as x, name2codepoint as y' 'z3=dict(chain(x.iteritems(), y.iteritems()))'\n10000 loops, best of 3: 66 usec per loop\n \n\n lead me to conclude that  z3  is somewhat faster than  z1 , but not nearly as fast as  z2 .  Definitely not worth all the extra typing. \n\n This discussion is still missing something important, which is a performance comparison of these alternatives with the \"obvious\" way of merging two lists: using the  update  method.  To try to keep things on an equal footing with the expressions, none of which modify x or y, I'm going to make a copy of x instead of modifying it in-place, as follows: \n\n z0 = dict(x)\nz0.update(y)\n \n\n A typical result: \n\n % python -m timeit -s 'from htmlentitydefs import codepoint2name as x, name2codepoint as y' 'z0=dict(x); z0.update(y)'\n10000 loops, best of 3: 26.9 usec per loop\n \n\n In other words,  z0  and  z2  seem to have essentially identical performance.  Do you think this might be a coincidence?  I don't.... \n\n In fact, I'd go so far as to claim that it's impossible for pure Python code to do any better than this.  And if you can do significantly better in a C extension module, I imagine the Python folks might well be interested in incorporating your code (or a variation on your approach) into the Python core.  Python uses  dict  in lots of places; optimizing its operations is a big deal. \n\n You could also write this as \n\n z0 = x.copy()\nz0.update(y)\n \n\n as Tony does, but (not surprisingly) the difference in notation turns out not to have any measurable effect on performance.  Use whichever looks right to you.  Of course, he's absolutely correct to point out that the two-statement version is much easier to understand. \n    ", "date_posted": "2015-01-10 02:32:55Z", "upvote": "\r\n            187\r\n        ", "accepted": "No", "user": {"stack_user_id": "128421", "name": "the Tin Man", "reputation_score": "156k"}, "answer_comments": [{"stack_answer_id": "228366", "stack_answer_comment_id": "46375571", "comment_content": "This does not work in Python 3; ", "user_id": "None"}]}, {"stack_answer_id": "16259217", "answer_content": "\r\n In Python 3.0 and later , you can use  collections.ChainMap  which groups multiple dicts or other mappings together to create a single, updateable view: \n >>> from collections import ChainMap\n>>> x = {'a':1, 'b': 2}\n>>> y = {'b':10, 'c': 11}\n>>> z = dict(ChainMap({}, y, x))\n>>> for k, v in z.items():\n        print(k, '-->', v)\n    \na --> 1\nb --> 10\nc --> 11\n \n Update for Python 3.5 and later : You can use  PEP 448  extended dictionary packing and unpacking.  This is fast and easy: \n >>> x = {'a':1, 'b': 2}\n>>> y = {'b':10, 'c': 11}\n>>> {**x, **y}\n{'a': 1, 'b': 10, 'c': 11}\n \n Update for Python 3.9 and later :  You can use the  PEP 584  union operator: \n >>> x = {'a':1, 'b': 2}\n>>> y = {'b':10, 'c': 11}\n>>> x | y\n{'a': 1, 'b': 10, 'c': 11}\n \n    ", "date_posted": "2020-12-11 06:43:11Z", "upvote": "\r\n            184\r\n        ", "accepted": "No", "user": {"stack_user_id": "424499", "name": "Raymond Hettinger", "reputation_score": "205k"}, "answer_comments": [{"stack_answer_id": "16259217", "stack_answer_comment_id": "71597496", "comment_content": "But one should be cautious while using ChainMap there's a catch that if you have duplicate keys the values from first mapping get used and when you call a ", "user_id": "None"}, {"stack_answer_id": "16259217", "stack_answer_comment_id": "71644530", "comment_content": "@Prerit What else would you expect it to do?  That's the normal way chained namespaces work.  Consider how $PATH works in bash.  Deleting an executable on the path doesn't preclude another executable with the same name further upstream.", "user_id": "None"}, {"stack_answer_id": "16259217", "stack_answer_comment_id": "71663990", "comment_content": "@Raymond Hettinger I agree, just added a caution. Most people may not know about it. :D", "user_id": "None"}, {"stack_answer_id": "16259217", "stack_answer_comment_id": "100615370", "comment_content": "@Prerit You could cast to ", "user_id": "None"}, {"stack_answer_id": "16259217", "stack_answer_comment_id": "120954371", "comment_content": "Suggested Edit Queue is full, but someone put the modification from @wjandrea into the answer, which is wrong - it's no longer a ", "user_id": "None"}]}, {"stack_answer_id": "44512", "answer_content": "\r\n I wanted something similar, but with the ability to specify how the values on duplicate keys were merged, so I hacked this out (but did not heavily test it).  Obviously this is not a single expression, but it is a single function call. \n\n def merge(d1, d2, merge_fn=lambda x,y:y):\n    \"\"\"\n    Merges two dictionaries, non-destructively, combining \n    values on duplicate keys as defined by the optional merge\n    function.  The default behavior replaces the values in d1\n    with corresponding values in d2.  (There is no other generally\n    applicable merge strategy, but often you'll have homogeneous \n    types in your dicts, so specifying a merge technique can be \n    valuable.)\n\n    Examples:\n\n    >>> d1\n    {'a': 1, 'c': 3, 'b': 2}\n    >>> merge(d1, d1)\n    {'a': 1, 'c': 3, 'b': 2}\n    >>> merge(d1, d1, lambda x,y: x+y)\n    {'a': 2, 'c': 6, 'b': 4}\n\n    \"\"\"\n    result = dict(d1)\n    for k,v in d2.iteritems():\n        if k in result:\n            result[k] = merge_fn(result[k], v)\n        else:\n            result[k] = v\n    return result\n \n    ", "date_posted": "2014-09-13 19:56:21Z", "upvote": "\r\n            152\r\n        ", "accepted": "No", "user": {"stack_user_id": "2748838", "name": "Rainy", "reputation_score": "1,017"}, "answer_comments": [{"stack_answer_id": "44512", "stack_answer_comment_id": "117550353", "comment_content": "Handy solution when the default behaviour of the shorter and simpler solutions (replacement of values of common keys by the second dictionary) is not wished. For Python 3, iteritems() is not available anymore in dicts, and one can simply use items() instead.", "user_id": "None"}]}, {"stack_answer_id": "8310229", "answer_content": "\r\n Recursively/deep update a dict \n\n def deepupdate(original, update):\n    \"\"\"\n    Recursively update a dict.\n    Subdict's won't be overwritten but also updated.\n    \"\"\"\n    for key, value in original.iteritems(): \n        if key not in update:\n            update[key] = value\n        elif isinstance(value, dict):\n            deepupdate(value, update[key]) \n    return update \n\n Demonstration: \n\n pluto_original = {\n    'name': 'Pluto',\n    'details': {\n        'tail': True,\n        'color': 'orange'\n    }\n}\n\npluto_update = {\n    'name': 'Pluutoo',\n    'details': {\n        'color': 'blue'\n    }\n}\n\nprint deepupdate(pluto_original, pluto_update) \n\n Outputs: \n\n {\n    'name': 'Pluutoo',\n    'details': {\n        'color': 'blue',\n        'tail': True\n    }\n} \n\n Thanks rednaw for edits. \n    ", "date_posted": "2015-12-18 11:19:15Z", "upvote": "\r\n            121\r\n        ", "accepted": "No", "user": {"stack_user_id": "1392229", "name": "Dawid Gos\u0142awski", "reputation_score": "1,918"}, "answer_comments": [{"stack_answer_id": "8310229", "stack_answer_comment_id": "93325213", "comment_content": "This does not answer the question. The question clearly asks for a new dictionary, z, from original dictionaries, x and y, with values from y replacing those of x - not an updated dictionary. This answer modifies y in-place by adding values from x. Worse, it does not copy these values, so one could further modify the modified dictionary, y, and modifications could be reflected in dictionary x. @J\u00e9r\u00f4me I hope this code is not causing any bugs for your application - at least consider using deepcopy to copy the values.", "user_id": "None"}, {"stack_answer_id": "8310229", "stack_answer_comment_id": "93339886", "comment_content": "@AaronHall agreed this does not answer the question. But it answers my need. I understand those limitations, but that's not an issue in my case. Thinking of it, maybe the name is misleading, as it might evoke a deepcopy, which it does not provide. But it addresses deep nesting. Here's another implementation from the Martellibot: ", "user_id": "None"}]}, {"stack_answer_id": "28753078", "answer_content": "\r\n Python 3.5 (PEP 448) allows a nicer syntax option: \n\n x = {'a': 1, 'b': 1}\ny = {'a': 2, 'c': 2}\nfinal = {**x, **y} \nfinal\n# {'a': 2, 'b': 1, 'c': 2}\n \n\n Or even  \n\n final = {'a': 1, 'b': 1, **x, **y}\n \n\n In Python 3.9 you also use | and |= with the below example from PEP 584 \n\n d = {'spam': 1, 'eggs': 2, 'cheese': 3}\ne = {'cheese': 'cheddar', 'aardvark': 'Ethel'}\nd | e\n# {'spam': 1, 'eggs': 2, 'cheese': 'cheddar', 'aardvark': 'Ethel'}\n \n    ", "date_posted": "2020-05-03 21:16:55Z", "upvote": "\r\n            99\r\n        ", "accepted": "No", "user": {"stack_user_id": "852240", "name": "Bilal Syed Hussain", "reputation_score": "7,924"}, "answer_comments": [{"stack_answer_id": "28753078", "stack_answer_comment_id": "45972281", "comment_content": "In what way is this solution better than the ", "user_id": "None"}, {"stack_answer_id": "28753078", "stack_answer_comment_id": "45997426", "comment_content": "Guido dislikes ", "user_id": "3207"}]}, {"stack_answer_id": "3936548", "answer_content": "\r\n The best version I could think while not using copy would be: \n\n from itertools import chain\nx = {'a':1, 'b': 2}\ny = {'b':10, 'c': 11}\ndict(chain(x.iteritems(), y.iteritems()))\n \n\n It's faster than  dict(x.items() + y.items())  but not as fast as  n = copy(a); n.update(b) , at least on CPython. This version also works in Python 3 if you change  iteritems()  to  items() , which is automatically done by the 2to3 tool. \n\n Personally I like this version best because it describes fairly good what I want in a single  functional syntax. The only minor problem is that it doesn't make completely obvious that values from y takes precedence over values from x, but I don't believe it's difficult to figure that out. \n    ", "date_posted": "2010-10-14 18:55:15Z", "upvote": "\r\n            95\r\n        ", "accepted": "No", "user": {"stack_user_id": "72476", "name": "driax", "reputation_score": "2,448"}, "answer_comments": []}, {"stack_answer_id": "38989", "answer_content": "\r\n x = {'a':1, 'b': 2}\ny = {'b':10, 'c': 11}\nz = dict(x.items() + y.items())\nprint z\n \n\n For items with keys in both dictionaries ('b'), you can control which one ends up in the output by putting that one last. \n    ", "date_posted": "2008-09-02 07:49:27Z", "upvote": "\r\n            93\r\n        ", "accepted": "No", "user": {"stack_user_id": "893", "name": "Greg Hewgill", "reputation_score": "903k"}, "answer_comments": [{"stack_answer_id": "38989", "stack_answer_comment_id": "98388054", "comment_content": "In python 3 you would get TypeError: unsupported operand type(s) for +: 'dict_items' and 'dict_items' ... you should encapsulate each dict with list() like: dict(list(x.items()) + list(y.items()))", "user_id": "None"}, {"stack_answer_id": "38989", "stack_answer_comment_id": "124851979", "comment_content": "@justSaid ", "user_id": "None"}]}, {"stack_answer_id": "7770473", "answer_content": "\r\n While the question has already been answered several times,\nthis simple solution to the problem has not been listed yet. \n\n x = {'a':1, 'b': 2}\ny = {'b':10, 'c': 11}\nz4 = {}\nz4.update(x)\nz4.update(y)\n \n\n It is as fast as z0 and the evil z2 mentioned above, but easy to understand and change. \n    ", "date_posted": "2011-10-14 16:12:33Z", "upvote": "\r\n            72\r\n        ", "accepted": "No", "user": {"stack_user_id": "509648", "name": "phobie", "reputation_score": "2,464"}, "answer_comments": [{"stack_answer_id": "7770473", "stack_answer_comment_id": "9516513", "comment_content": "but it's three statements rather than one expression", "user_id": "None"}, {"stack_answer_id": "7770473", "stack_answer_comment_id": "9680836", "comment_content": "Yes! The mentioned one-expression-solutions are either slow or evil. Good code is readable and maintainable. So the problem is the question not the answer. We should ask for the best solution of a problem not for a one-line-solution.", "user_id": "None"}, {"stack_answer_id": "7770473", "stack_answer_comment_id": "21587977", "comment_content": "Lose the ", "user_id": "None"}, {"stack_answer_id": "7770473", "stack_answer_comment_id": "23506047", "comment_content": "Your suggestion would change this to Matthews answer. While his answer is fine, I think mine is more readable and better maintainable. The extra line would only be bad if it would cost execution time.", "user_id": "None"}, {"stack_answer_id": "7770473", "stack_answer_comment_id": "110323413", "comment_content": "I suggest you put this into a function", "user_id": "None"}]}, {"stack_answer_id": "11825563", "answer_content": "\r\n def dict_merge(a, b):\n  c = a.copy()\n  c.update(b)\n  return c\n\nnew = dict_merge(old, extras)\n \n\n Among such shady and dubious answers, this shining example is the one and only good way to merge dicts in Python, endorsed by dictator for life  Guido van Rossum  himself!  Someone else suggested half of this, but did not put it in a function. \n\n print dict_merge(\n      {'color':'red', 'model':'Mini'},\n      {'model':'Ferrari', 'owner':'Carl'})\n \n\n gives: \n\n {'color': 'red', 'owner': 'Carl', 'model': 'Ferrari'}\n \n    ", "date_posted": "2012-08-06 09:30:07Z", "upvote": "\r\n            65\r\n        ", "accepted": "No", "user": {"stack_user_id": "218294", "name": "Sam Watkins", "reputation_score": "7,441"}, "answer_comments": []}, {"stack_answer_id": "8247023", "answer_content": "\r\n If you think lambdas are evil then read no further.\nAs requested, you can write the fast and memory-efficient solution with one expression: \n\n x = {'a':1, 'b':2}\ny = {'b':10, 'c':11}\nz = (lambda a, b: (lambda a_copy: a_copy.update(b) or a_copy)(a.copy()))(x, y)\nprint z\n{'a': 1, 'c': 11, 'b': 10}\nprint x\n{'a': 1, 'b': 2}\n \n\n As suggested above, using two lines or writing a function is probably a better way to go. \n    ", "date_posted": "2011-11-23 18:20:48Z", "upvote": "\r\n            58\r\n        ", "accepted": "No", "user": {"stack_user_id": "364984", "name": "EMS", "reputation_score": "1,013"}, "answer_comments": []}, {"stack_answer_id": "34899183", "answer_content": "\r\n Be pythonic. Use a  comprehension : \n z={k: v for d in [x,y] for k, v in d.items()}\n\n>>> print z\n{'a': 1, 'c': 11, 'b': 10}\n \n    ", "date_posted": "2022-06-16 22:40:57Z", "upvote": "\r\n            58\r\n        ", "accepted": "No", "user": {"stack_user_id": "833208", "name": "Robino", "reputation_score": "4,083"}, "answer_comments": []}, {"stack_answer_id": "19279501", "answer_content": "\r\n In python3, the  items  method  no longer returns a list , but rather a  view , which acts like a set. In this case you'll need to take the set union since concatenating with  +  won't work: \n\n dict(x.items() | y.items())\n \n\n For python3-like behavior in version 2.7, the  viewitems  method should work in place of  items : \n\n dict(x.viewitems() | y.viewitems())\n \n\n I prefer this notation anyways since it seems more natural to think of it as a set union operation rather than concatenation (as the title shows). \n\n Edit: \n\n A couple more points for python 3. First, note that the  dict(x, **y)  trick won't work in python 3 unless the keys in  y  are strings. \n\n Also, Raymond Hettinger's Chainmap  answer  is pretty elegant, since it can take an arbitrary number of dicts as arguments, but  from the docs  it looks like it sequentially looks through a list of all the dicts for each lookup: \n\n \n   Lookups search the underlying mappings successively until a key is found. \n \n\n This can slow you down if you have a lot of lookups in your application: \n\n In [1]: from collections import ChainMap\nIn [2]: from string import ascii_uppercase as up, ascii_lowercase as lo; x = dict(zip(lo, up)); y = dict(zip(up, lo))\nIn [3]: chainmap_dict = ChainMap(y, x)\nIn [4]: union_dict = dict(x.items() | y.items())\nIn [5]: timeit for k in union_dict: union_dict[k]\n100000 loops, best of 3: 2.15 \u00b5s per loop\nIn [6]: timeit for k in chainmap_dict: chainmap_dict[k]\n10000 loops, best of 3: 27.1 \u00b5s per loop\n \n\n So about an order of magnitude slower for lookups. I'm a fan of Chainmap, but looks less practical where there may be many lookups. \n    ", "date_posted": "2017-05-23 12:34:53Z", "upvote": "\r\n            46\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}, {"stack_answer_id": "62820532", "answer_content": "\r\n I benchmarked the suggested with  perfplot  and found that the good old \n temp = x.copy()\ntemp.update(y)\n \n is the fastest solution together with the new (Python 3.9+) \n x | y\n \n \n \n Code to reproduce the plot: \n from collections import ChainMap\nfrom itertools import chain\nimport perfplot\n\n\ndef setup(n):\n    x = dict(zip(range(n), range(n)))\n    y = dict(zip(range(n, 2 * n), range(n, 2 * n)))\n    return x, y\n\n\ndef copy_update(data):\n    x, y = data\n    temp = x.copy()\n    temp.update(y)\n    return temp\n\n\ndef add_items(data):\n    x, y = data\n    return dict(list(x.items()) + list(y.items()))\n\n\ndef curly_star(data):\n    x, y = data\n    return {**x, **y}\n\n\ndef chain_map(data):\n    x, y = data\n    return dict(ChainMap({}, y, x))\n\n\ndef itertools_chain(data):\n    x, y = data\n    return dict(chain(x.items(), y.items()))\n\n\ndef python39_concat(data):\n    x, y = data\n    return x | y\n\n\nb = perfplot.bench(\n    setup=setup,\n    kernels=[\n        copy_update,\n        add_items,\n        curly_star,\n        chain_map,\n        itertools_chain,\n        python39_concat,\n    ],\n    labels=[\n        \"copy_update\",\n        \"dict(list(x.items()) + list(y.items()))\",\n        \"{**x, **y}\",\n        \"chain_map\",\n        \"itertools.chain\",\n        \"x | y\",\n    ],\n    n_range=[2 ** k for k in range(18)],\n    xlabel=\"len(x), len(y)\",\n    equality_check=None,\n)\nb.save(\"out.png\")\nb.show()\n \n    ", "date_posted": "2021-12-17 17:54:55Z", "upvote": "\r\n            39\r\n        ", "accepted": "No", "user": {"stack_user_id": "353337", "name": "Nico Schl\u00f6mer", "reputation_score": "48.1k"}, "answer_comments": [{"stack_answer_id": "62820532", "stack_answer_comment_id": "129098958", "comment_content": "Tried to reproduce the results, getting this error -> ", "user_id": "None"}]}, {"stack_answer_id": "12926103", "answer_content": "\r\n Two dictionaries \n\n def union2(dict1, dict2):\n    return dict(list(dict1.items()) + list(dict2.items()))\n \n\n n  dictionaries \n\n def union(*dicts):\n    return dict(itertools.chain.from_iterable(dct.items() for dct in dicts))\n \n\n sum  has bad performance. See  https://mathieularose.com/how-not-to-flatten-a-list-of-lists-in-python/ \n    ", "date_posted": "2016-10-02 18:16:17Z", "upvote": "\r\n            36\r\n        ", "accepted": "No", "user": {"stack_user_id": "122894", "name": "Mathieu Larose", "reputation_score": "1,210"}, "answer_comments": []}, {"stack_answer_id": "31812635", "answer_content": "\r\n Simple solution using itertools that preserves order (latter dicts have precedence) \n # py2\nfrom itertools import chain, imap\nmerge = lambda *args: dict(chain.from_iterable(imap(dict.iteritems, args)))\n\n# py3\nfrom itertools import chain\nmerge = lambda *args: dict(chain.from_iterable(map(dict.items, args)))\n \n And it's usage: \n >>> x = {'a':1, 'b': 2}\n>>> y = {'b':10, 'c': 11}\n>>> merge(x, y)\n{'a': 1, 'b': 10, 'c': 11}\n\n>>> z = {'c': 3, 'd': 4}\n>>> merge(x, y, z)\n{'a': 1, 'b': 10, 'c': 3, 'd': 4}\n \n    ", "date_posted": "2020-09-29 19:45:06Z", "upvote": "\r\n            33\r\n        ", "accepted": "No", "user": {"stack_user_id": "408556", "name": "reubano", "reputation_score": "4,774"}, "answer_comments": []}, {"stack_answer_id": "18114065", "answer_content": "\r\n Abuse leading to a one-expression solution for  Matthew's answer : \n\n >>> x = {'a':1, 'b': 2}\n>>> y = {'b':10, 'c': 11}\n>>> z = (lambda f=x.copy(): (f.update(y), f)[1])()\n>>> z\n{'a': 1, 'c': 11, 'b': 10}\n \n\n You said you wanted one expression, so I abused  lambda  to bind a name, and tuples to override lambda's one-expression limit. Feel free to cringe. \n\n You could also do this of course if you don't care about copying it: \n\n >>> x = {'a':1, 'b': 2}\n>>> y = {'b':10, 'c': 11}\n>>> z = (x.update(y), x)[1]\n>>> z\n{'a': 1, 'b': 10, 'c': 11}\n \n    ", "date_posted": "2017-05-23 12:34:53Z", "upvote": "\r\n            31\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}, {"stack_answer_id": "46356150", "answer_content": "\r\n If you don't mind mutating  x , \n x.update(y) or x\n \n Simple, readable, performant. You  know   update()  always returns  None , which is a false value. So the above expression will always evaluate to  x , after updating it. \n Most mutating methods in the standard library (like  .update() ) return  None  by convention, so this kind of pattern will work on those too. However, if you're using a dict subclass or some other method that doesn't follow this convention, then  or  may return its left operand, which may not be what you want. Instead, you can use a tuple display and index, which works regardless of what the first element evaluates to (although it's not quite as pretty): \n (x.update(y), x)[-1]\n \n If you don't have  x  in a variable yet, you can use  lambda  to make a local without using an assignment statement. This amounts to using  lambda  as a  let expression , which is a common technique in functional languages, but is maybe unpythonic. \n (lambda x: x.update(y) or x)({'a': 1, 'b': 2})\n \n Although it's not that different from the following use of the new walrus operator (Python 3.8+ only), \n (x := {'a': 1, 'b': 2}).update(y) or x\n \n especially if you use a default argument: \n (lambda x={'a': 1, 'b': 2}: x.update(y) or x)()\n \n If you do want a copy,  PEP 584  style  x | y  is the most Pythonic on 3.9+. If you must support older versions,  PEP 448  style  {**x, **y}  is easiest for 3.5+. But if that's not available in your (even older) Python version, the  let expression  pattern works here too. \n (lambda z=x.copy(): z.update(y) or z)()\n \n (That is, of course, nearly equivalent to  (z := x.copy()).update(y) or z , but if your Python version is new enough for that, then the PEP 448 style will be available.) \n    ", "date_posted": "2021-05-29 06:33:34Z", "upvote": "\r\n            24\r\n        ", "accepted": "No", "user": {"stack_user_id": "4381487", "name": "gilch", "reputation_score": "9,922"}, "answer_comments": []}, {"stack_answer_id": "62141222", "answer_content": "\r\n New  in Python 3.9:  Use the union operator ( | ) to merge  dict s similar to  set s: \n >>> d = {'a': 1, 'b': 2}\n>>> e = {'a': 9, 'c': 3}\n>>> d | e\n{'a': 9, 'b': 2, 'c': 3}\n \n For matching keys, the  right  dict  takes precedence . \n This also works for  |=  to modify a  dict  in-place: \n >>> e |= d    # e = e | d\n>>> e\n{'a': 1, 'c': 3, 'b': 2}\n \n    ", "date_posted": "2020-11-29 21:49:39Z", "upvote": "\r\n            21\r\n        ", "accepted": "No", "user": {"stack_user_id": "2111778", "name": "xjcl", "reputation_score": "10.1k"}, "answer_comments": [{"stack_answer_id": "62141222", "stack_answer_comment_id": "128455113", "comment_content": "What does this add that wasn't mentioned already months earlier? ", "user_id": "None"}]}, {"stack_answer_id": "17738920", "answer_content": "\r\n Drawing on ideas here and elsewhere I've comprehended a function: \n\n def merge(*dicts, **kv): \n      return { k:v for d in list(dicts) + [kv] for k,v in d.items() }\n \n\n Usage (tested in python 3): \n\n assert (merge({1:11,'a':'aaa'},{1:99, 'b':'bbb'},foo='bar')==\\\n    {1: 99, 'foo': 'bar', 'b': 'bbb', 'a': 'aaa'})\n\nassert (merge(foo='bar')=={'foo': 'bar'})\n\nassert (merge({1:11},{1:99},foo='bar',baz='quux')==\\\n    {1: 99, 'foo': 'bar', 'baz':'quux'})\n\nassert (merge({1:11},{1:99})=={1: 99})\n \n\n You could use a lambda instead. \n    ", "date_posted": "2013-07-19 05:49:19Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "375570", "name": "Bijou Trouvaille", "reputation_score": "8,016"}, "answer_comments": []}, {"stack_answer_id": "22122836", "answer_content": "\r\n It's so silly that  .update  returns nothing. \nI just use a simple helper function to solve the problem: \n\n def merge(dict1,*dicts):\n    for dict2 in dicts:\n        dict1.update(dict2)\n    return dict1\n \n\n Examples: \n\n merge(dict1,dict2)\nmerge(dict1,dict2,dict3)\nmerge(dict1,dict2,dict3,dict4)\nmerge({},dict1,dict2)  # this one returns a new copy\n \n    ", "date_posted": "2014-03-02 01:44:39Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "25700", "name": "GetFree", "reputation_score": "37.5k"}, "answer_comments": []}, {"stack_answer_id": "36263150", "answer_content": "\r\n (For Python2.7* only; there are simpler solutions for Python3*.) \n\n If you're not averse to importing a standard library module, you can do \n\n from functools import reduce\n\ndef merge_dicts(*dicts):\n    return reduce(lambda a, d: a.update(d) or a, dicts, {})\n \n\n (The  or a  bit in the  lambda  is necessary because  dict.update  always returns  None  on success.) \n    ", "date_posted": "2016-03-28 13:13:27Z", "upvote": "\r\n            18\r\n        ", "accepted": "No", "user": {"stack_user_id": "559827", "name": "kjo", "reputation_score": "31.2k"}, "answer_comments": []}, {"stack_answer_id": "20358548", "answer_content": "\r\n The problem I have with solutions listed to date is that, in the merged dictionary, the value for key \"b\" is 10 but, to my way of thinking, it should be 12.\nIn that light, I present the following: \n\n import timeit\n\nn=100000\nsu = \"\"\"\nx = {'a':1, 'b': 2}\ny = {'b':10, 'c': 11}\n\"\"\"\n\ndef timeMerge(f,su,niter):\n    print \"{:4f} sec for: {:30s}\".format(timeit.Timer(f,setup=su).timeit(n),f)\n\ntimeMerge(\"dict(x, **y)\",su,n)\ntimeMerge(\"x.update(y)\",su,n)\ntimeMerge(\"dict(x.items() + y.items())\",su,n)\ntimeMerge(\"for k in y.keys(): x[k] = k in x and x[k]+y[k] or y[k] \",su,n)\n\n#confirm for loop adds b entries together\nx = {'a':1, 'b': 2}\ny = {'b':10, 'c': 11}\nfor k in y.keys(): x[k] = k in x and x[k]+y[k] or y[k]\nprint \"confirm b elements are added:\",x\n \n\n Results: \n\n 0.049465 sec for: dict(x, **y)\n0.033729 sec for: x.update(y)                   \n0.150380 sec for: dict(x.items() + y.items())   \n0.083120 sec for: for k in y.keys(): x[k] = k in x and x[k]+y[k] or y[k]\n\nconfirm b elements are added: {'a': 1, 'c': 11, 'b': 12}\n \n    ", "date_posted": "2013-12-03 18:11:54Z", "upvote": "\r\n            17\r\n        ", "accepted": "No", "user": {"stack_user_id": "3062691", "name": "upandacross", "reputation_score": "417"}, "answer_comments": [{"stack_answer_id": "20358548", "stack_answer_comment_id": "71707374", "comment_content": "You might be interested in ", "user_id": "None"}]}, {"stack_answer_id": "54930992", "answer_content": "\r\n There will be a new option when Python 3.8 releases ( scheduled for 20 October, 2019 ), thanks to  PEP 572: Assignment Expressions . The new assignment expression operator  :=  allows you to assign the result of the  copy  and still use it to call  update , leaving the combined code a single expression, rather than two statements, changing: \n\n newdict = dict1.copy()\nnewdict.update(dict2)\n \n\n to: \n\n (newdict := dict1.copy()).update(dict2)\n \n\n while behaving identically in every way. If you must also return the resulting  dict  (you asked for an expression returning the  dict ; the above creates and assigns to  newdict , but doesn't return it, so you couldn't use it to pass an argument to a function as is, a la  myfunc((newdict := dict1.copy()).update(dict2)) ), then just add  or newdict  to the end (since  update  returns  None , which is falsy, it will then evaluate and return  newdict  as the result of the expression): \n\n (newdict := dict1.copy()).update(dict2) or newdict\n \n\n Important caveat:  In general, I'd discourage this approach in favor of: \n\n newdict = {**dict1, **dict2}\n \n\n The unpacking approach is clearer (to anyone who knows about generalized unpacking in the first place,  which you should ), doesn't require a name for the result at all (so it's much more concise when constructing a temporary that is immediately passed to a function or included in a  list / tuple  literal or the like), and is almost certainly faster as well, being (on CPython) roughly equivalent to: \n\n newdict = {}\nnewdict.update(dict1)\nnewdict.update(dict2)\n \n\n but done at the C layer, using the concrete  dict  API, so no dynamic method lookup/binding or function call dispatch overhead is involved (where  (newdict := dict1.copy()).update(dict2)  is unavoidably identical to the original two-liner in behavior, performing the work in discrete steps, with dynamic lookup/binding/invocation of methods. \n\n It's also more extensible, as merging three  dict s is obvious: \n\n  newdict = {**dict1, **dict2, **dict3}\n \n\n where using assignment expressions won't scale like that; the closest you could get would be: \n\n  (newdict := dict1.copy()).update(dict2), newdict.update(dict3)\n \n\n or without the temporary tuple of  None s, but with truthiness testing of each  None  result: \n\n  (newdict := dict1.copy()).update(dict2) or newdict.update(dict3)\n \n\n either of which is obviously much uglier, and includes further inefficiencies (either a wasted temporary  tuple  of  None s for comma separation, or pointless truthiness testing of each  update 's  None  return for  or  separation). \n\n The only real advantage to the assignment expression approach occurs if: \n\n \n You have generic code that needs handle both  set s and  dict s  (both of them support  copy  and  update , so the code works roughly as you'd expect it to) \n You expect to receive arbitrary dict-like objects , not just  dict  itself,  and must preserve the type and semantics of the left hand side  (rather than ending up with a plain  dict ). While  myspecialdict({**speciala, **specialb})  might work, it would involve an extra temporary  dict , and if  myspecialdict  has features plain  dict  can't preserve (e.g. regular  dict s now preserve order based on the first appearance of a key, and value based on the last appearance of a key; you might want one that preserves order based on the  last  appearance of a key so updating a value also moves it to the end), then the semantics would be wrong. Since the assignment expression version uses the named methods (which are presumably overloaded to behave appropriately), it never creates a  dict  at all (unless  dict1  was already a  dict ), preserving the original type (and original type's semantics), all while avoiding any temporaries. \n \n    ", "date_posted": "2019-02-28 17:49:22Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "364696", "name": "ShadowRanger", "reputation_score": "129k"}, "answer_comments": []}, {"stack_answer_id": "33999337", "answer_content": "\r\n from collections import Counter\ndict1 = {'a':1, 'b': 2}\ndict2 = {'b':10, 'c': 11}\nresult = dict(Counter(dict1) + Counter(dict2))\n \n\n This should solve your problem. \n    ", "date_posted": "2015-11-30 13:04:00Z", "upvote": "\r\n            15\r\n        ", "accepted": "No", "user": {"stack_user_id": "3145137", "name": "reetesh11", "reputation_score": "631"}, "answer_comments": [{"stack_answer_id": "33999337", "stack_answer_comment_id": "121401705", "comment_content": "I will recommend using the Counter's ", "user_id": "None"}]}, {"stack_answer_id": "31478567", "answer_content": "\r\n This can be done with a single dict comprehension: \n\n >>> x = {'a':1, 'b': 2}\n>>> y = {'b':10, 'c': 11}\n>>> { key: y[key] if key in y else x[key]\n      for key in set(x) + set(y)\n    }\n \n\n In my view the best answer for the 'single expression' part as no extra functions are needed, and it is short. \n    ", "date_posted": "2015-07-17 14:47:23Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "799163", "name": "RemcoGerlich", "reputation_score": "29.3k"}, "answer_comments": [{"stack_answer_id": "31478567", "stack_answer_comment_id": "71711009", "comment_content": "I suspect performance will not be very good though; creating a set out of each dict then only iterating through the keys means another lookup for the value each time (though relatively fast, still increases the order of the function for scaling)", "user_id": "None"}, {"stack_answer_id": "31478567", "stack_answer_comment_id": "82876896", "comment_content": "it all depends on the version of the python we are using. In 3.5 and above {**x,**y} gives the concatenated dictionary", "user_id": "None"}]}], "user": {"stack_user_id": "3207", "name": "Carl Meyer", "reputation_score": "116k"}, "question_comments": []},
{"stack_question_id": "306313", "question_title": "\"is\" operator behaves unexpectedly with integers", "question_content": "\r\n                Why does the following behave unexpectedly in Python?\n\n>>> a = 256\n>>> b = 256\n>>> a is b\nTrue           # This is an expected result\n>>> a = 257\n>>> b = ...\r\n", "question_url": "/questions/306313/is-operator-behaves-unexpectedly-with-integers", "date_posted": "Nov 20, 2008 at 18:21", "upvote": "5", "view": "9", "tags": ["python", "int", "operators", "identity", "python-internals"], "answers_count": "1", "answers": [{"stack_answer_id": "306353", "answer_content": "\r\n Take a look at this: \n\n >>> a = 256\n>>> b = 256\n>>> id(a)\n9987148\n>>> id(b)\n9987148\n>>> a = 257\n>>> b = 257\n>>> id(a)\n11662816\n>>> id(b)\n11662828\n \n\n Here's what I found in the Python 2 documentation,  \"Plain Integer Objects\"  (It's the same for  Python 3 ): \n\n \n   The current implementation keeps an\n  array of integer objects for all\n  integers between -5 and 256, when you\n  create an int in that range you\n  actually just get back a reference to\n  the existing object. So it should be\n  possible to change the value of 1. I\n  suspect the behaviour of Python in\n  this case is undefined. :-) \n \n    ", "date_posted": "2020-01-29 18:59:48Z", "upvote": "\r\n            438\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "68587", "name": "John Kugelman", "reputation_score": "335k"}, "answer_comments": [{"stack_answer_id": "306353", "stack_answer_comment_id": "78696988", "comment_content": "does anyone know how that range (-5, 256) was chosen? i wouldn't be too surprised if it were (0, 255) or even (-255, 255), but a range of 262 numbers starting at -5 seems surprisingly arbitrary.", "user_id": "None"}, {"stack_answer_id": "306353", "stack_answer_comment_id": "83937709", "comment_content": "@WoodrowBarlow: The -5 is just a heuristic to capture common negative placeholders, I think.  0..255 covers arrays of single byte values.  It\u2019s 256 that\u2019s mysterious, but I guess it\u2019s for (dis)assembling integers into/from bytes.", "user_id": "None"}, {"stack_answer_id": "306353", "stack_answer_comment_id": "89237748", "comment_content": "From what I understand the range was chosen by looking at the commonly used values across multiple projects (and multiple languages).", "user_id": "None"}, {"stack_answer_id": "306353", "stack_answer_comment_id": "89434930", "comment_content": "According to ", "user_id": "None"}, {"stack_answer_id": "306353", "stack_answer_comment_id": "122849028", "comment_content": "The note about changing the value of ", "user_id": "None"}]}, {"stack_answer_id": "28864111", "answer_content": "\r\n \n   Python's \u201cis\u201d operator behaves unexpectedly with integers? \n \n\n In summary - let me emphasize:  Do not use  is  to compare integers. \n\n This isn't behavior you should have any expectations about. \n\n Instead, use  ==  and  !=  to compare for equality and inequality, respectively. For example: \n\n >>> a = 1000\n>>> a == 1000       # Test integers like this,\nTrue\n>>> a != 5000       # or this!\nTrue\n>>> a is 1000       # Don't do this! - Don't use `is` to test integers!!\nFalse\n \n\n Explanation \n\n To know this, you need to know the following. \n\n First, what does  is  do? It is a comparison operator. From the  documentation : \n\n \n   The operators  is  and  is not  test for object identity:  x is y  is true\n  if and only if x and y are the same object.  x is not y  yields the\n  inverse truth value. \n \n\n And so the following are equivalent.  \n\n >>> a is b\n>>> id(a) == id(b)\n \n\n From the  documentation : \n\n \n   id \n  Return the \u201cidentity\u201d of an object. This is an integer (or long\n  integer) which is guaranteed to be unique and constant for this object\n  during its lifetime. Two objects with non-overlapping lifetimes may\n  have the same  id()  value. \n \n\n Note that the fact that the id of an object in CPython (the reference implementation of Python) is the location in memory is an implementation detail. Other implementations of Python (such as Jython or IronPython) could easily have a different implementation for  id . \n\n So what is the use-case for  is ?   PEP8 describes : \n\n \n   Comparisons to singletons like  None  should always be done with  is  or\n   is not , never the equality operators. \n \n\n The Question \n\n You ask, and state, the following question (with code): \n\n \n   Why does the following behave unexpectedly in Python? \n\n >>> a = 256\n>>> b = 256\n>>> a is b\nTrue           # This is an expected result\n \n \n\n It is  not  an expected result. Why is it expected? It only means that the integers valued at  256  referenced by both  a  and  b  are the same instance of integer. Integers are immutable in Python, thus they cannot change. This should have no impact on any code. It should not be expected. It is merely an implementation detail.  \n\n But perhaps we should be glad that there is not a new separate instance in memory every time we state a value equals 256.  \n\n \n >>> a = 257\n>>> b = 257\n>>> a is b\nFalse          # What happened here? Why is this False?\n \n \n\n Looks like we now have two separate instances of integers with the value of  257  in memory. Since integers are immutable, this wastes memory. Let's hope we're not wasting a lot of it. We're probably not. But this behavior is not guaranteed. \n\n \n >>> 257 is 257\nTrue           # Yet the literal numbers compare properly\n \n \n\n Well, this looks like your particular implementation of Python is trying to be smart and not creating redundantly valued integers in memory unless it has to. You seem to indicate you are using the referent implementation of Python, which is CPython. Good for CPython.  \n\n It might be even better if CPython could do this globally, if it could do so cheaply (as there would a cost in the lookup), perhaps another implementation might.  \n\n But as for impact on code, you should not care if an integer is a particular instance of an integer. You should only care what the value of that instance is, and you would use the normal comparison operators for that, i.e.  == . \n\n What  is  does \n\n is  checks that the  id  of two objects are the same. In CPython, the  id  is the location in memory, but it could be some other uniquely identifying number in another implementation. To restate this with code: \n\n >>> a is b\n \n\n is the same as \n\n >>> id(a) == id(b)\n \n\n Why would we want to use  is  then? \n\n This can be a very fast check relative to say, checking if two very long strings are equal in value. But since it applies to the uniqueness of the object, we thus have limited use-cases for it. In fact, we mostly want to use it to check for  None , which is a singleton (a sole instance existing in one place in memory). We might create other singletons if there is potential to conflate them, which we might check with  is , but these are relatively rare. Here's an example (will work in Python 2 and 3) e.g. \n\n SENTINEL_SINGLETON = object() # this will only be created one time.\n\ndef foo(keyword_argument=None):\n    if keyword_argument is None:\n        print('no argument given to foo')\n    bar()\n    bar(keyword_argument)\n    bar('baz')\n\ndef bar(keyword_argument=SENTINEL_SINGLETON):\n    # SENTINEL_SINGLETON tells us if we were not passed anything\n    # as None is a legitimate potential argument we could get.\n    if keyword_argument is SENTINEL_SINGLETON:\n        print('no argument given to bar')\n    else:\n        print('argument to bar: {0}'.format(keyword_argument))\n\nfoo()\n \n\n Which prints: \n\n no argument given to foo\nno argument given to bar\nargument to bar: None\nargument to bar: baz\n \n\n And so we see, with  is  and a sentinel, we are able to differentiate between when  bar  is called with no arguments and when it is called with  None . These are the primary use-cases for  is  - do  not  use it to test for equality of integers, strings, tuples, or other things like these. \n    ", "date_posted": "2017-09-09 20:02:03Z", "upvote": "\r\n            147\r\n        ", "accepted": "No", "user": {"stack_user_id": "541136", "name": "Russia Must Remove Putin", "reputation_score": "347k"}, "answer_comments": [{"stack_answer_id": "28864111", "stack_answer_comment_id": "98590248", "comment_content": "\"These are the primary use-cases for ", "user_id": "None"}, {"stack_answer_id": "28864111", "stack_answer_comment_id": "98590866", "comment_content": "@Alexey sounds like you need enums? ", "user_id": "None"}, {"stack_answer_id": "28864111", "stack_answer_comment_id": "98591512", "comment_content": "Maybe, thanks, didn't know of them. This could be an appropriate addition to you answer IMO.", "user_id": "None"}, {"stack_answer_id": "28864111", "stack_answer_comment_id": "98591718", "comment_content": "Maybe using a number of dumb objects like the sentinel in your answer would be a more lightweight solution...", "user_id": "None"}, {"stack_answer_id": "28864111", "stack_answer_comment_id": "125042249", "comment_content": "@MarkRansom Don't use ", "user_id": "None"}]}, {"stack_answer_id": "34964030", "answer_content": "\r\n\n I'm late but, you want some source with your answer?  I'll try and word this in an introductory manner so more folks can follow along. \n \n A good thing about CPython is that you can actually see the source for this. I'm going to use links for the  3.5  release, but finding the corresponding  2.x  ones is trivial. \n In CPython, the  C-API  function that handles creating a new  int  object is  PyLong_FromLong(long v) . The description for this function is: \n \n The current implementation keeps an array of integer objects for all integers between -5 and 256, when you create an int in that range you actually just get back a reference to the existing object . So it should be possible to change the value of 1. I suspect the behaviour of Python in this case is undefined. :-) \n \n (My italics) \n Don't know about you but I see this and think:  Let's find that array! \n If you haven't fiddled with the C code implementing CPython  you should ; everything is pretty organized and readable. For our case, we need to look in the  Objects  subdirectory  of the  main source code directory tree . \n PyLong_FromLong  deals with  long  objects so it shouldn't be hard to deduce that we need to peek inside  longobject.c . After looking inside you might think things are chaotic; they are, but fear not, the function we're looking for is chilling at  line 230  waiting for us to check it out. It's a smallish function so the main body (excluding declarations) is easily pasted here: \n PyObject *\nPyLong_FromLong(long ival)\n{\n    // omitting declarations\n\n    CHECK_SMALL_INT(ival);\n\n    if (ival < 0) {\n        /* negate: cant write this as abs_ival = -ival since that\n           invokes undefined behaviour when ival is LONG_MIN */\n        abs_ival = 0U-(unsigned long)ival;\n        sign = -1;\n    }\n    else {\n        abs_ival = (unsigned long)ival;\n    }\n\n    /* Fast path for single-digit ints */\n    if (!(abs_ival >> PyLong_SHIFT)) {\n        v = _PyLong_New(1);\n        if (v) {\n            Py_SIZE(v) = sign;\n            v->ob_digit[0] = Py_SAFE_DOWNCAST(\n                abs_ival, unsigned long, digit);\n        }\n        return (PyObject*)v; \n}\n \n Now, we're no C  master-code-haxxorz  but we're also not dumb, we can see that  CHECK_SMALL_INT(ival);  peeking at us all seductively; we can understand it has something to do with this.  Let's check it out: \n #define CHECK_SMALL_INT(ival) \\\n    do if (-NSMALLNEGINTS <= ival && ival < NSMALLPOSINTS) { \\\n        return get_small_int((sdigit)ival); \\\n    } while(0)\n \n So it's a macro that calls function  get_small_int  if the value  ival  satisfies the condition: \n if (-NSMALLNEGINTS <= ival && ival < NSMALLPOSINTS)\n \n So what are  NSMALLNEGINTS  and  NSMALLPOSINTS ? Macros!  Here they are : \n #ifndef NSMALLPOSINTS\n#define NSMALLPOSINTS           257\n#endif\n#ifndef NSMALLNEGINTS\n#define NSMALLNEGINTS           5\n#endif\n \n So our condition is  if (-5 <= ival && ival < 257)  call  get_small_int . \n Next let's look at  get_small_int  in all its glory  (well, we'll just look at its body because that's where the interesting things are): \n PyObject *v;\nassert(-NSMALLNEGINTS <= ival && ival < NSMALLPOSINTS);\nv = (PyObject *)&small_ints[ival + NSMALLNEGINTS];\nPy_INCREF(v);\n \n Okay, declare a  PyObject , assert that the previous condition holds and execute the assignment: \n v = (PyObject *)&small_ints[ival + NSMALLNEGINTS];\n \n small_ints  looks a lot like that array we've been searching for, and it is!  We could've just read the damn documentation and we would've know all along! : \n /* Small integers are preallocated in this array so that they\n   can be shared.\n   The integers that are preallocated are those in the range\n   -NSMALLNEGINTS (inclusive) to NSMALLPOSINTS (not inclusive).\n*/\nstatic PyLongObject small_ints[NSMALLNEGINTS + NSMALLPOSINTS];\n \n So yup, this is our guy. When you want to create a new  int  in the range  [NSMALLNEGINTS, NSMALLPOSINTS)  you'll just get back a reference to an already existing object that has been preallocated. \n Since the reference refers to the same object, issuing  id()  directly or checking for identity with  is  on it will return exactly the same thing. \n But, when are they allocated?? \n During initialization in  _PyLong_Init  Python will gladly enter in a for loop to do this for you: \n for (ival = -NSMALLNEGINTS; ival <  NSMALLPOSINTS; ival++, v++) {\n \n Check out the source to read the loop body! \n I hope my explanation has made you  C  things clearly now (pun obviously intented). \n \n But,  257 is 257 ? What's up? \n This is actually easier to explain,  and I have attempted to do so already ; it's due to the fact that Python will execute this interactive statement as a single block: \n >>> 257 is 257\n \n During complilation of this statement, CPython will see that you have two matching literals and will use the same  PyLongObject  representing  257 . You can see this if you do the compilation yourself and examine its contents: \n >>> codeObj = compile(\"257 is 257\", \"blah!\", \"exec\")\n>>> codeObj.co_consts\n(257, None)\n \n When CPython does the operation, it's now just going to load the exact same object: \n >>> import dis\n>>> dis.dis(codeObj)\n  1           0 LOAD_CONST               0 (257)   # dis\n              3 LOAD_CONST               0 (257)   # dis again\n              6 COMPARE_OP               8 (is)\n \n So  is  will return  True . \n    ", "date_posted": "2021-03-18 16:08:30Z", "upvote": "\r\n            71\r\n        ", "accepted": "No", "user": {"stack_user_id": "2326961", "name": "Maggyero", "reputation_score": "4,880"}, "answer_comments": []}, {"stack_answer_id": "306377", "answer_content": "\r\n It depends on whether you're looking to see if 2 things are equal, or the same object.  \n\n is  checks to see if they are the same object, not just equal. The small ints are probably pointing to the same memory location for space efficiency  \n\n In [29]: a = 3\nIn [30]: b = 3\nIn [31]: id(a)\nOut[31]: 500729144\nIn [32]: id(b)\nOut[32]: 500729144\n \n\n You should use  ==  to compare equality of arbitrary objects. You can specify the behavior with the  __eq__ , and  __ne__  attributes. \n    ", "date_posted": "2017-04-24 02:20:18Z", "upvote": "\r\n            61\r\n        ", "accepted": "No", "user": {"stack_user_id": "2470818", "name": "vallentin", "reputation_score": "21.7k"}, "answer_comments": []}, {"stack_answer_id": "306603", "answer_content": "\r\n As you can check in  source file  intobject.c , Python caches small integers for efficiency. Every time you create a reference to a small integer, you are referring the cached small integer, not a new object. 257 is not an small integer, so it is calculated as a different object. \n\n It is better to use  ==  for that purpose. \n    ", "date_posted": "2017-04-24 02:20:25Z", "upvote": "\r\n            38\r\n        ", "accepted": "No", "user": {"stack_user_id": "2470818", "name": "vallentin", "reputation_score": "21.7k"}, "answer_comments": []}, {"stack_answer_id": "306347", "answer_content": "\r\n I think your hypotheses is correct. Experiment with  id  (identity of object): \n\n In [1]: id(255)\nOut[1]: 146349024\n\nIn [2]: id(255)\nOut[2]: 146349024\n\nIn [3]: id(257)\nOut[3]: 146802752\n\nIn [4]: id(257)\nOut[4]: 148993740\n\nIn [5]: a=255\n\nIn [6]: b=255\n\nIn [7]: c=257\n\nIn [8]: d=257\n\nIn [9]: id(a), id(b), id(c), id(d)\nOut[9]: (146349024, 146349024, 146783024, 146804020)\n \n\n It appears that numbers  <= 255  are treated as literals and anything above is treated differently! \n    ", "date_posted": "2017-02-08 10:12:22Z", "upvote": "\r\n            21\r\n        ", "accepted": "No", "user": {"stack_user_id": "4952130", "name": "Dimitris Fasarakis Hilliard", "reputation_score": "139k"}, "answer_comments": [{"stack_answer_id": "306347", "stack_answer_comment_id": "89237899", "comment_content": "It is because objects representing values from -5 to +256 are created at Startup time - and so all use of those value use to prebuilt object. Almost all references to integers outside that range create a new internal object each time they are referenced. I think the use of the term literal is confusing - literal normally refers to any value that is typed in a piece of code - so all number in the source code are literals.", "user_id": "None"}]}, {"stack_answer_id": "49472348", "answer_content": "\r\n There's another issue that isn't pointed out in any of the existing answers. Python is allowed to merge any two immutable values, and pre-created small int values are not the only way this can happen. A Python implementation is never  guaranteed  to do this, but they all do it for more than just small ints. \n\n \n\n For one thing, there are some other pre-created values, such as the empty  tuple ,  str , and  bytes , and some short strings (in CPython 3.6, it's the 256 single-character Latin-1 strings). For example: \n\n >>> a = ()\n>>> b = ()\n>>> a is b\nTrue\n \n\n \n\n But also, even non-pre-created values can be identical. Consider these examples: \n\n >>> c = 257\n>>> d = 257\n>>> c is d\nFalse\n>>> e, f = 258, 258\n>>> e is f\nTrue\n \n\n And this isn't limited to  int  values: \n\n >>> g, h = 42.23e100, 42.23e100\n>>> g is h\nTrue\n \n\n Obviously, CPython doesn't come with a pre-created  float  value for  42.23e100 . So, what's going on here? \n\n The CPython compiler will merge constant values of some known-immutable types like  int ,  float ,  str ,  bytes ,  in the same compilation unit. For a module, the whole module is a compilation unit, but at the interactive interpreter, each statement is a separate compilation unit. Since  c  and  d  are defined in separate statements, their values aren't merged. Since  e  and  f  are defined in the same statement, their values are merged. \n\n \n\n You can see what's going on by disassembling the bytecode. Try defining a function that does  e, f = 128, 128  and then calling  dis.dis  on it, and you'll see that there's a single constant value  (128, 128) \n\n >>> def f(): i, j = 258, 258\n>>> dis.dis(f)\n  1           0 LOAD_CONST               2 ((128, 128))\n              2 UNPACK_SEQUENCE          2\n              4 STORE_FAST               0 (i)\n              6 STORE_FAST               1 (j)\n              8 LOAD_CONST               0 (None)\n             10 RETURN_VALUE\n>>> f.__code__.co_consts\n(None, 128, (128, 128))\n>>> id(f.__code__.co_consts[1], f.__code__.co_consts[2][0], f.__code__.co_consts[2][1])\n4305296480, 4305296480, 4305296480\n \n\n \n\n You may notice that the compiler has stored  128  as a constant even though it's not actually used by the bytecode, which gives you an idea of how little optimization CPython's compiler does. Which means that (non-empty) tuples actually don't end up merged: \n\n >>> k, l = (1, 2), (1, 2)\n>>> k is l\nFalse\n \n\n Put that in a function,  dis  it, and look at the  co_consts \u2014there's a  1  and a  2 , two  (1, 2)  tuples that share the same  1  and  2  but are not identical, and a  ((1, 2), (1, 2))  tuple that has the two distinct equal tuples. \n\n \n\n There's one more optimization that CPython does: string interning. Unlike compiler constant folding, this isn't restricted to source code literals: \n\n >>> m = 'abc'\n>>> n = 'abc'\n>>> m is n\nTrue\n \n\n On the other hand, it is limited to the  str  type, and to strings of  internal storage kind \"ascii compact\", \"compact\", or \"legacy ready\" , and in many cases only \"ascii compact\" will get interned. \n\n \n\n At any rate, the rules for what values must be, might be, or cannot be distinct vary from implementation to implementation, and between versions of the same implementation, and maybe even between runs of the same code on the same copy of the same implementation. \n\n It can be worth learning the rules for one specific Python for the fun of it. But it's not worth relying on them in your code. The only safe rule is: \n\n \n Do not write code that assumes two equal but separately-created immutable values are identical (don't use  x is y , use  x == y ) \n Do not write code that assumes two equal but separately-created immutable values are distinct (don't use  x is not y , use  x != y ) \n \n\n Or, in other words, only use  is  to test for the documented singletons (like  None ) or that are only created in one place in the code (like the  _sentinel = object()  idiom). \n    ", "date_posted": "2020-03-09 06:40:04Z", "upvote": "\r\n            15\r\n        ", "accepted": "No", "user": {"stack_user_id": "202229", "name": "smci", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "49472348", "stack_answer_comment_id": "107203132", "comment_content": "The less cryptic advice is simply: don't use ", "user_id": "None"}, {"stack_answer_id": "49472348", "stack_answer_comment_id": "110073088", "comment_content": "So looking at ", "user_id": "None"}]}, {"stack_answer_id": "307594", "answer_content": "\r\n For immutable value objects, like ints, strings or datetimes, object identity is not especially useful. It's better to think about equality. Identity is essentially an implementation detail for value objects - since they're immutable, there's no effective difference between having multiple refs to the same object or multiple objects. \n    ", "date_posted": "2008-11-21 01:58:53Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "38851", "name": "babbageclunk", "reputation_score": "8,275"}, "answer_comments": []}, {"stack_answer_id": "15522094", "answer_content": "\r\n is   is  the identity equality operator (functioning like  id(a) == id(b) ); it's just that two equal numbers aren't necessarily the same object. For performance reasons some small integers happen to be  memoized  so they will tend to be the same (this can be done since they are immutable). \n\n PHP's   ===  operator, on the other hand, is described as checking equality and type:  x == y and type(x) == type(y)  as per Paulo Freitas' comment. This will suffice for common numbers, but differ from  is  for classes that define  __eq__  in an absurd manner: \n\n class Unequal:\n    def __eq__(self, other):\n        return False\n \n\n PHP apparently allows the same thing for \"built-in\" classes (which I take to mean implemented at C level, not in PHP). A slightly less absurd use might be a timer object, which has a different value every time it's used as a number. Quite why you'd want to emulate Visual Basic's  Now  instead of showing that it is an evaluation with  time.time()  I don't know. \n\n Greg Hewgill (OP) made one clarifying comment \"My goal is to compare object identity, rather than equality of value. Except for numbers, where I want to treat object identity the same as equality of value.\" \n\n This would have yet another answer, as we have to categorize things as numbers or not, to select whether we compare with  ==  or  is .  CPython  defines the  number protocol , including PyNumber_Check, but this is not accessible from Python itself. \n\n We could try to use  isinstance  with all the number types we know of, but this would inevitably be incomplete. The types module contains a StringTypes list but no NumberTypes. Since Python 2.6, the built in number classes have a base class  numbers.Number , but it has the same problem: \n\n import numpy, numbers\nassert not issubclass(numpy.int16,numbers.Number)\nassert issubclass(int,numbers.Number)\n \n\n By the way,  NumPy  will produce separate instances of low numbers. \n\n I don't actually know an answer to this variant of the question. I suppose one could theoretically use ctypes to call  PyNumber_Check , but even that function  has been debated , and it's certainly not portable. We'll just have to be less particular about what we test for now. \n\n In the end, this issue stems from Python not originally having a type tree with predicates like  Scheme's   number? , or  Haskell's   type class   Num .  is  checks object identity, not value equality. PHP has a colorful history as well, where  ===  apparently behaves as  is  only on objects  in PHP5, but not PHP4 . Such are the growing pains of moving across languages (including versions of one). \n    ", "date_posted": "2015-11-12 11:52:54Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "379311", "name": "Yann Vernier", "reputation_score": "14.9k"}, "answer_comments": []}, {"stack_answer_id": "33130014", "answer_content": "\r\n It also happens with strings: \n\n >>> s = b = 'somestr'\n>>> s == b, s is b, id(s), id(b)\n(True, True, 4555519392, 4555519392)\n \n\n Now everything seems fine. \n\n >>> s = 'somestr'\n>>> b = 'somestr'\n>>> s == b, s is b, id(s), id(b)\n(True, True, 4555519392, 4555519392)\n \n\n That's expected too. \n\n >>> s1 = b1 = 'somestrdaasd ad ad asd as dasddsg,dlfg ,;dflg, dfg a'\n>>> s1 == b1, s1 is b1, id(s1), id(b1)\n(True, True, 4555308080, 4555308080)\n\n>>> s1 = 'somestrdaasd ad ad asd as dasddsg,dlfg ,;dflg, dfg a'\n>>> b1 = 'somestrdaasd ad ad asd as dasddsg,dlfg ,;dflg, dfg a'\n>>> s1 == b1, s1 is b1, id(s1), id(b1)\n(True, False, 4555308176, 4555308272)\n \n\n Now that's unexpected. \n    ", "date_posted": "2015-10-14 15:53:05Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "4842742", "name": "sobolevn", "reputation_score": "15.2k"}, "answer_comments": [{"stack_answer_id": "33130014", "stack_answer_comment_id": "56385375", "comment_content": "Happened upon this - agreed, that even weirder.  So I played with it, and it's weirder yet - related to the space.  For example, the string ", "user_id": "None"}, {"stack_answer_id": "33130014", "stack_answer_comment_id": "66570944", "comment_content": "That's because it looks like a symbol if there's no space in it. Names are automatically interned, so if there's anything named ", "user_id": "None"}]}, {"stack_answer_id": "57641343", "answer_content": "\r\n What\u2019s New In Python 3.8: Changes in Python behavior : \n\n \n   The compiler now produces a  SyntaxWarning  when identity checks ( is  and\n   is not ) are used with certain types of literals (e.g. strings, ints).\n  These can often work by accident in CPython, but are not guaranteed by\n  the language spec. The warning advises users to use equality tests ( == \n  and  != ) instead. \n \n    ", "date_posted": "2019-11-11 21:21:47Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "2420341", "name": "cclauss", "reputation_score": "505"}, "answer_comments": []}], "user": {"stack_user_id": "893", "name": "Greg Hewgill", "reputation_score": "903k"}, "question_comments": [{"stack_question_id": "306313", "stack_question_comment_id": "99214572", "comment_content": "Take a look ", "user_id": "None"}, {"stack_question_id": "306313", "stack_question_comment_id": "99499964", "comment_content": "This is a CPython-specific implementation detail and a undefined behavior, use with cautions", "user_id": "None"}, {"stack_question_id": "306313", "stack_question_comment_id": "122294396", "comment_content": "Does this answer your question? ", "user_id": "None"}]},
{"stack_question_id": "394809", "question_title": "Does Python have a ternary conditional operator?", "question_content": "\r\n                Is there a ternary conditional operator in Python?\r\n", "question_url": "/questions/394809/does-python-have-a-ternary-conditional-operator", "date_posted": null, "upvote": "7", "view": "2", "tags": ["python", "operators", "conditional-operator"], "answers_count": "3", "answers": [{"stack_answer_id": "394814", "answer_content": "\r\n Yes, it was  added  in version 2.5. The expression syntax is: \n a if condition else b\n \n First  condition  is evaluated, then exactly one of either  a  or  b  is evaluated and returned based on the  Boolean  value of  condition . If  condition  evaluates to  True , then  a  is evaluated and returned but  b  is ignored, or else when  b  is evaluated and returned but  a  is ignored. \n This allows short-circuiting because when  condition  is true only  a  is evaluated and  b  is not evaluated at all, but when  condition  is false only  b  is evaluated and  a  is not evaluated at all. \n For example: \n >>> 'true' if True else 'false'\n'true'\n>>> 'true' if False else 'false'\n'false'\n \n Note that conditionals are an  expression , not a  statement . This means you can't use assignment statements or  pass  or other  statements  within a conditional  expression : \n >>> pass if False else x = 3\n  File \"<stdin>\", line 1\n    pass if False else x = 3\n          ^\nSyntaxError: invalid syntax\n \n You can, however, use conditional expressions to assign a variable like so: \n x = a if True else b\n \n Think of the conditional expression as switching between two values. It is very useful when you're in a 'one value or another' situation, but it doesn't do much else. \n If you need to use statements, you have to use a normal  if   statement  instead of a conditional  expression . \n \n Keep in mind that it's frowned upon by some Pythonistas for several reasons: \n \n The order of the arguments is different from those of the classic  condition ? a : b  ternary operator from many other languages (such as  C ,  C++ ,  Go ,  Perl ,  Ruby ,  Java ,  JavaScript , etc.), which may lead to bugs when people unfamiliar with Python's \"surprising\" behaviour use it (they may reverse the argument order). \n Some find it \"unwieldy\", since it goes contrary to the normal flow of thought (thinking of the condition first and then the effects). \n Stylistic reasons. (Although the 'inline  if ' can be  really  useful, and make your script more concise, it really does complicate your code) \n \n If you're having trouble remembering the order, then remember that when read aloud, you (almost) say what you mean. For example,  x = 4 if b > 8 else 9  is read aloud as  x will be 4 if b is greater than 8 otherwise 9 . \n Official documentation: \n \n Conditional expressions \n Is there an equivalent of C\u2019s \u201d?:\u201d ternary operator? \n \n    ", "date_posted": "2022-06-03 22:21:26Z", "upvote": "\r\n            8586\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "394814", "name": "\r\n        22 revs, 18 users 18%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "394814", "stack_answer_comment_id": "57719599", "comment_content": "The order may seems strange for coders however ", "user_id": "None"}, {"stack_answer_id": "394814", "stack_answer_comment_id": "59317179", "comment_content": "Be careful with order of operations when using this. For example, the line ", "user_id": "None"}, {"stack_answer_id": "394814", "stack_answer_comment_id": "60867668", "comment_content": "The point was if you want to perform additional evaluations ", "user_id": "None"}, {"stack_answer_id": "394814", "stack_answer_comment_id": "78209851", "comment_content": "@MrGeek, I see what you mean, so you would basically be nesting the operations: ` \"foo\" if Bool else (\"bar\" if Bool else \"foobar\") `", "user_id": "None"}, {"stack_answer_id": "394814", "stack_answer_comment_id": "88793385", "comment_content": "Programmers need precise correct formulation even more than mathematician, because in mathematics there is always a resort to underlying concepts. A convincing argument  is the % operator, mimicking the way \"mod\" is used in math would have been a disaster.  So no, I don't accept your argument. It is like adhering to imperial units. Groetjes Albert", "user_id": "None"}]}, {"stack_answer_id": "470376", "answer_content": "\r\n You can index into a tuple: \n\n (falseValue, trueValue)[test]\n \n\n test  needs to return  True  or  False . \nIt might be safer to always implement it as: \n\n (falseValue, trueValue)[test == True]\n \n\n or you can use the built-in  bool()  to assure a  Boolean  value: \n\n (falseValue, trueValue)[bool(<expression>)]\n \n    ", "date_posted": "2015-10-17 07:35:10Z", "upvote": "\r\n            955\r\n        ", "accepted": "No", "user": {"stack_user_id": "470376", "name": "\r\n        Landon Kuhn\r\n        ", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "470376", "stack_answer_comment_id": "5445970", "comment_content": "Note that this one always evaluates everything, whereas the if/else construct only evaluates the winning expression.", "user_id": "None"}, {"stack_answer_id": "470376", "stack_answer_comment_id": "12212868", "comment_content": " ", "user_id": "None"}, {"stack_answer_id": "470376", "stack_answer_comment_id": "14113335", "comment_content": "It should be noted that what's within the ", "user_id": "None"}, {"stack_answer_id": "470376", "stack_answer_comment_id": "59136440", "comment_content": "I've done a similar trick -- only once or twice, but done it -- by indexing into a dictionary with ", "user_id": "None"}, {"stack_answer_id": "470376", "stack_answer_comment_id": "61540187", "comment_content": " ", "user_id": "None"}]}, {"stack_answer_id": "394887", "answer_content": "\r\n For versions prior to 2.5, there's the trick: \n [expression] and [on_true] or [on_false]\n \n It can give wrong results when  on_true  has a false Boolean value. 1 \n Although it does have the benefit of evaluating expressions left to right, which is clearer in my opinion. \n 1.  Is there an equivalent of C\u2019s \u201d?:\u201d ternary operator? \n    ", "date_posted": "2022-02-06 12:19:50Z", "upvote": "\r\n            420\r\n        ", "accepted": "No", "user": {"stack_user_id": "394887", "name": "\r\n        4 revs, 4 users 35%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "394887", "stack_answer_comment_id": "1466794", "comment_content": "The remedy is to use (test and [true_value] or [false_value])[0], which avoids this trap.", "user_id": "None"}, {"stack_answer_id": "394887", "stack_answer_comment_id": "31716349", "comment_content": "Ternary operator usually executes faster(sometimes by 10-25%).", "user_id": "None"}, {"stack_answer_id": "394887", "stack_answer_comment_id": "39130413", "comment_content": "@volcano Do you have source for me?", "user_id": "None"}, {"stack_answer_id": "394887", "stack_answer_comment_id": "85745604", "comment_content": "@OrangeTux ", "user_id": "None"}]}, {"stack_answer_id": "2919360", "answer_content": "\r\n   <expression 1>   if   <condition>   else   <expression 2>   \n\n a = 1\nb = 2\n\n1 if a > b else -1 \n# Output is -1\n\n1 if a > b else -1 if a < b else 0\n# Output is -1\n \n    ", "date_posted": "2019-05-15 15:03:41Z", "upvote": "\r\n            334\r\n        ", "accepted": "No", "user": {"stack_user_id": "2919360", "name": "\r\n        3 revs, 2 users 62%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "2919360", "stack_answer_comment_id": "4103349", "comment_content": "This one emphasizes the primary intent of the ternary operator: value selection. It also shows that more than one ternary can be chained together into a single expression.", "user_id": "None"}, {"stack_answer_id": "2919360", "stack_answer_comment_id": "42951997", "comment_content": "@Craig , I agree, but it's also helpful to know what will happen when there are no parentheses. In real code, I too would tend to insert explicit parens.", "user_id": "None"}, {"stack_answer_id": "2919360", "stack_answer_comment_id": "114095475", "comment_content": "Use: ", "user_id": "None"}]}, {"stack_answer_id": "394815", "answer_content": "\r\n From  the documentation : \n\n \n   Conditional expressions (sometimes called a \u201cternary operator\u201d) have the lowest priority of all Python operations. \n  \n   The expression  x if C else y  first evaluates the condition,  C  ( not x ); if  C  is true,  x  is evaluated and its value is returned; otherwise,  y  is evaluated and its value is returned. \n  \n   See  PEP 308  for more details about conditional expressions. \n \n\n New since version 2.5. \n    ", "date_posted": "2015-10-17 07:43:53Z", "upvote": "\r\n            195\r\n        ", "accepted": "No", "user": {"stack_user_id": "394815", "name": "\r\n        Michael Burr\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "30052371", "answer_content": "\r\n An operator for a conditional expression in Python was added in 2006 as part of  Python Enhancement Proposal 308 . Its form differ from common  ?:  operator and it's: \n\n <expression1> if <condition> else <expression2>\n \n\n which is equivalent to: \n\n if <condition>: <expression1> else: <expression2>\n \n\n Here is an example: \n\n result = x if a > b else y\n \n\n Another syntax which can be used (compatible with versions before 2.5): \n\n result = (lambda:y, lambda:x)[a > b]()\n \n\n where operands are  lazily evaluated . \n\n Another way is by indexing a tuple (which isn't consistent with the conditional operator of most other languages): \n\n result = (y, x)[a > b]\n \n\n or explicitly constructed dictionary: \n\n result = {True: x, False: y}[a > b]\n \n\n Another (less reliable), but simpler method is to use  and  and  or  operators: \n\n result = (a > b) and x or y\n \n\n however this won't work if  x  would be  False . \n\n A possible workaround is to make  x  and  y  lists or tuples as in the following: \n\n result = ((a > b) and [x] or [y])[0]\n \n\n or: \n\n result = ((a > b) and (x,) or (y,))[0]\n \n\n If you're working with dictionaries, instead of using a ternary conditional, you can take advantage of  get(key, default) , for example: \n\n shell = os.environ.get('SHELL', \"/bin/sh\")\n \n\n Source:  ?: in Python at Wikipedia \n    ", "date_posted": "2017-08-07 14:22:32Z", "upvote": "\r\n            159\r\n        ", "accepted": "No", "user": {"stack_user_id": "30052371", "name": "\r\n        2 revs, 2 users 98%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "30052371", "stack_answer_comment_id": "96013109", "comment_content": " is another possible variant (", "user_id": "None"}]}, {"stack_answer_id": "1855173", "answer_content": "\r\n Unfortunately, the \n (falseValue, trueValue)[test]\n \n solution doesn't have short-circuit behaviour; thus both  falseValue  and  trueValue  are evaluated regardless of the condition. This could be suboptimal or even buggy (i.e. both  trueValue  and  falseValue  could be methods and have side effects). \n One solution to this would be \n (lambda: falseValue, lambda: trueValue)[test]()\n \n (execution delayed until the winner is known ;)), but it introduces inconsistency between callable and non-callable objects. In addition, it doesn't solve the case when using properties. \n And so the story goes - choosing between three mentioned solutions is a trade-off between having the short-circuit feature, using at least Python 2.5 (IMHO, not a problem anymore) and not being prone to \" trueValue -evaluates-to-false\" errors. \n    ", "date_posted": "2022-02-06 12:22:50Z", "upvote": "\r\n            118\r\n        ", "accepted": "No", "user": {"stack_user_id": "1855173", "name": "\r\n        6 revs, 5 users 67%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "1855173", "stack_answer_comment_id": "92454573", "comment_content": "While the tuple of lambdas trick works, it takes roughly 3x as long as the ternary operator.  It's only likely to be a reasonable idea if it can replace a long chain of ", "user_id": "None"}]}, {"stack_answer_id": "39067220", "answer_content": "\r\n Ternary operator in different programming languages \n Here I just try to show some important differences in the  ternary operator  between a couple of programming languages. \n Ternary operator in  JavaScript \n var a = true ? 1 : 0;\n# 1\nvar b = false ? 1 : 0;\n# 0\n \n Ternary operator in  Ruby \n a = true ? 1 : 0\n# 1\nb = false ? 1 : 0\n# 0\n \n Ternary operator in  Scala \n val a = true ? 1 | 0\n# 1\nval b = false ? 1 | 0\n# 0\n \n Ternary operator in  R  programming \n a <- if (TRUE) 1 else 0\n# 1\nb <- if (FALSE) 1 else 0\n# 0\n \n Ternary operator in Python \n a = 1 if True else 0\n# 1\nb = 1 if False else 0\n# 0\n \n    ", "date_posted": "2022-02-06 12:47:23Z", "upvote": "\r\n            94\r\n        ", "accepted": "No", "user": {"stack_user_id": "39067220", "name": "\r\n        5 revs, 4 users 78%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "39067220", "stack_answer_comment_id": "71681244", "comment_content": "This ", "user_id": "None"}, {"stack_answer_id": "39067220", "stack_answer_comment_id": "83365814", "comment_content": "It may sound opinionated; but what it essentially says is that it the Python syntax is likely to be understood by a person who never saw a ternary operator, while very few people will understand the more usual syntax unless they have been told first what it means.", "user_id": "None"}, {"stack_answer_id": "39067220", "stack_answer_comment_id": "88793454", "comment_content": "Algol68:  a=.if. .true. .then. 1 .else. 0 .fi. This may be expressed also a=(.true.|1|0)  As usual Algol68 is an improvement over its successors.", "user_id": "None"}, {"stack_answer_id": "39067220", "stack_answer_comment_id": "114386996", "comment_content": "something simple as ", "user_id": "None"}, {"stack_answer_id": "39067220", "stack_answer_comment_id": "114654346", "comment_content": "@VarunGarg But of course you can say ", "user_id": "None"}]}, {"stack_answer_id": "10314837", "answer_content": "\r\n For Python 2.5 and newer there is a specific syntax: \n\n [on_true] if [cond] else [on_false]\n \n\n In older Pythons a ternary operator is not implemented but it's possible to simulate it. \n\n cond and on_true or on_false\n \n\n Though, there is a potential problem, which if  cond  evaluates to  True  and  on_true  evaluates to  False  then  on_false  is returned instead of  on_true . If you want this behavior the method is OK, otherwise use this: \n\n {True: on_true, False: on_false}[cond is True] # is True, not == True\n \n\n which can be wrapped by: \n\n def q(cond, on_true, on_false)\n    return {True: on_true, False: on_false}[cond is True]\n \n\n and used this way: \n\n q(cond, on_true, on_false)\n \n\n It is compatible with all Python versions. \n    ", "date_posted": "2012-04-25 12:02:06Z", "upvote": "\r\n            79\r\n        ", "accepted": "No", "user": {"stack_user_id": "10314837", "name": "\r\n        Paolo\r\n        ", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "10314837", "stack_answer_comment_id": "16979616", "comment_content": "The behaviour is not identical - ", "user_id": "None"}, {"stack_answer_id": "10314837", "stack_answer_comment_id": "29624617", "comment_content": "Why not ", "user_id": "None"}]}, {"stack_answer_id": "14321907", "answer_content": "\r\n You might often find \n cond and on_true or on_false\n \n but this leads to a problem when on_true == 0 \n >>> x = 0\n>>> print x == 0 and 0 or 1\n1\n>>> x = 1\n>>> print x == 0 and 0 or 1\n1\n \n Where you would expect this result for a normal ternary operator: \n >>> x = 0\n>>> print 0 if x == 0 else 1\n0\n>>> x = 1\n>>> print 0 if x == 0 else 1\n1\n \n    ", "date_posted": "2022-04-01 17:25:19Z", "upvote": "\r\n            56\r\n        ", "accepted": "No", "user": {"stack_user_id": "14321907", "name": "\r\n        3 revs, 3 users 64%", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "33765206", "answer_content": "\r\n \n Does Python have a ternary conditional operator? \n \n Yes. From the  grammar file : \n test: or_test ['if' or_test 'else' test] | lambdef\n \n The part of interest is: \n or_test ['if' or_test 'else' test]\n \n So, a ternary conditional operation is of the form: \n expression1 if expression2 else expression3\n \n expression3  will be lazily evaluated (that is, evaluated only if  expression2  is false in a boolean context). And because of the recursive definition, you can chain them indefinitely (though it may considered bad style.) \n expression1 if expression2 else expression3 if expression4 else expression5 # and so on\n \n A note on usage: \n Note that every  if  must be followed with an  else . People learning list comprehensions and generator expressions may find this to be a difficult lesson to learn - the following will not work, as Python expects a third expression for an else: \n [expression1 if expression2 for element in iterable]\n#                          ^-- need an else here\n \n which raises a  SyntaxError: invalid syntax .\nSo the above is either an incomplete piece of logic (perhaps the user expects a no-op in the false condition) or what may be intended is to use  expression2  as a filter - notes that the following is legal Python: \n [expression1 for element in iterable if expression2]\n \n expression2  works as a filter for the list comprehension, and is  not  a ternary conditional operator. \n Alternative syntax for a more narrow case: \n You may find it somewhat painful to write the following: \n expression1 if expression1 else expression2\n \n expression1  will have to be evaluated twice with the above usage. It can limit redundancy if it is simply a local variable. However, a common and performant Pythonic idiom for this use-case is to use  or 's shortcutting behavior: \n expression1 or expression2\n \n which is equivalent in semantics. Note that some style-guides may limit this usage on the grounds of clarity - it does pack a lot of meaning into very little syntax. \n    ", "date_posted": "2022-04-01 17:30:21Z", "upvote": "\r\n            50\r\n        ", "accepted": "No", "user": {"stack_user_id": "33765206", "name": "\r\n        3 revs, 2 users 76%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "33765206", "stack_answer_comment_id": "58658010", "comment_content": " being similar and with the same drawbacks/positives as ", "user_id": "None"}, {"stack_answer_id": "33765206", "stack_answer_comment_id": "62448054", "comment_content": "Thanks, @selurvedu - it can be confusing until you get it straight. I learned the hard way, so your way might not be as hard. ;) Using if without the else, at the end of a generator expression or list comprehension will filter the iterable. In the front, it's a ternary conditional operation, and requires the else. Cheers!!", "user_id": "None"}, {"stack_answer_id": "33765206", "stack_answer_comment_id": "95571762", "comment_content": "@AaronHall Although your use of metasyntactic ", "user_id": "None"}, {"stack_answer_id": "33765206", "stack_answer_comment_id": "95575895", "comment_content": "@tchrist thanks for the review - if you look at the revision history, this post currently has two revisions. Most of my other answers, especially the top ones, have been revisited again and again. This answer never gets my attention because the community wiki status gives me no credit for the content, and so I never see any votes on it. As I don't really have time for an edit on this right now, frog knows when it will come to my attention again in the future. I can see you've edited the top answer, so feel free to borrow/quote my material from this post in that one (and cite me if apropos!)", "user_id": "None"}]}, {"stack_answer_id": "58409100", "answer_content": "\r\n As already answered, yes, there is a ternary operator in Python: \n <expression 1> if <condition> else <expression 2>\n \n In many cases  <expression 1>  is also used as Boolean evaluated  <condition> . Then you can use  short-circuit evaluation . \n a = 0\nb = 1\n\n# Instead of this:\nx = a if a else b\n# Evaluates as 'a if bool(a) else b'\n\n# You could use short-circuit evaluation:\nx = a or b\n \n One big pro of short-circuit evaluation is the possibility of chaining more than two expressions: \n x = a or b or c or d or e\n \n When working with functions it is more different in detail: \n # Evaluating functions:\ndef foo(x):\n    print('foo executed')\n    return x\n\n\ndef bar(y):\n    print('bar executed')\n    return y\n\n\ndef blubb(z):\n    print('blubb executed')\n    return z\n\n\n# Ternary Operator expression 1 equals to False\nprint(foo(0) if foo(0) else bar(1))\n''' foo and bar are executed once\nfoo executed\nbar executed\n1\n'''\n\n# Ternary Operator expression 1 equals to True\nprint(foo(2) if foo(2) else bar(3))\n''' foo is executed twice!\nfoo executed\nfoo executed\n2\n'''\n\n# Short-circuit evaluation second equals to True\nprint(foo(0) or bar(1) or blubb(2))\n''' blubb is not executed\nfoo executed\nbar executed\n1\n'''\n\n# Short-circuit evaluation third equals to True\nprint(foo(0) or bar(0) or blubb(2))\n'''\nfoo executed\nbar executed\nblubb executed\n2\n'''\n\n# Short-circuit evaluation all equal to False\nprint(foo(0) or bar(0) or blubb(0))\n''' Result is 0 (from blubb(0)) because no value equals to True\nfoo executed\nbar executed\nblubb executed\n0\n'''\n \n PS: Of course, a short-circuit evaluation is not a ternary operator, but often the ternary is used in cases where the short circuit would be enough. It has a better readability and can be chained. \n    ", "date_posted": "2022-02-06 13:28:15Z", "upvote": "\r\n            33\r\n        ", "accepted": "No", "user": {"stack_user_id": "58409100", "name": "\r\n        4 revs, 2 users 89%", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "54609267", "answer_content": "\r\n One of the alternatives to Python's  conditional expression \n \"yes\" if boolean else \"no\"\n \n is the following: \n {True: \"yes\", False: \"no\"}[boolean]\n \n which has the following nice extension: \n {True: \"yes\", False: \"no\", None: \"maybe\"}[boolean_or_none]\n \n The shortest alternative remains \n (\"no\", \"yes\")[boolean]\n \n which works because  issubclass(bool, int) . \n Careful, though: the alternative to \n yes() if boolean else no()\n \n is  not \n (no(), yes())[boolean]  # bad: BOTH no() and yes() are called\n \n but \n (no, yes)[boolean]()\n \n This works fine as long as  no  and  yes  are to be called with exactly the same parameters. If they are not, like in \n yes(\"ok\") if boolean else no()  # (1)\n \n or in \n yes(\"ok\") if boolean else no(\"sorry\")  # (2)\n \n then a similar alternative either does not exist (1) or is hardly viable (2). (In rare cases, depending on the context, something like \n msg = (\"sorry\", \"ok\")[boolean]\n(no, yes)[boolean](msg)\n \n could make sense.) \n Thanks to Radek Roj\u00edk for his comment \n    ", "date_posted": "2022-06-01 12:19:26Z", "upvote": "\r\n            33\r\n        ", "accepted": "No", "user": {"stack_user_id": "54609267", "name": "\r\n        6 revs", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "54609267", "stack_answer_comment_id": "127061683", "comment_content": "Alternative: ", "user_id": "None"}]}, {"stack_answer_id": "20093702", "answer_content": "\r\n Simulating the Python ternary operator. \n For example \n a, b, x, y = 1, 2, 'a greather than b', 'b greater than a'\nresult = (lambda:y, lambda:x)[a > b]()\n \n Output: \n 'b greater than a'\n \n    ", "date_posted": "2022-02-06 12:25:06Z", "upvote": "\r\n            31\r\n        ", "accepted": "No", "user": {"stack_user_id": "20093702", "name": "\r\n        2 revs, 2 users 81%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "20093702", "stack_answer_comment_id": "31175220", "comment_content": "Why not simply ", "user_id": "None"}, {"stack_answer_id": "20093702", "stack_answer_comment_id": "32895313", "comment_content": "@GrijeshChauhan Because on \"compliated\" expressions, e. g. involving a function call etc., this would be executed in both cases. This might not be wanted.", "user_id": "None"}, {"stack_answer_id": "20093702", "stack_answer_comment_id": "115414421", "comment_content": "The use of ", "user_id": "None"}, {"stack_answer_id": "20093702", "stack_answer_comment_id": "116319126", "comment_content": "@GrijeshChauhan In short, this implements the so-called \u201c", "user_id": "None"}]}, {"stack_answer_id": "53653902", "answer_content": "\r\n a if condition else b\n \n\n Just memorize this pyramid if you have trouble remembering: \n\n      condition\n  if           else\na                   b \n \n    ", "date_posted": "2018-12-06 14:45:27Z", "upvote": "\r\n            29\r\n        ", "accepted": "No", "user": {"stack_user_id": "53653902", "name": "\r\n        shivtej\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "49653070", "answer_content": "\r\n The ternary conditional operator simply allows testing a condition in a single line replacing the multiline if-else making the code compact. \n Syntax: \n \n [on_true] if [expression] else [on_false] \n \n 1- Simple Method to use ternary operator: \n # Program to demonstrate conditional operator\na, b = 10, 20\n# Copy value of a in min if a < b else copy b\nmin = a if a < b else b\nprint(min)  # Output: 10\n \n 2- Direct Method of using tuples, Dictionary, and lambda: \n # Python program to demonstrate ternary operator\na, b = 10, 20\n# Use tuple for selecting an item\nprint( (b, a) [a < b] )\n# Use Dictionary for selecting an item\nprint({True: a, False: b} [a < b])\n# lambda is more efficient than above two methods\n# because in lambda  we are assure that\n# only one expression will be evaluated unlike in\n# tuple and Dictionary\nprint((lambda: b, lambda: a)[a < b]()) # in output you should see three 10\n \n 3- Ternary operator can be written as nested if-else: \n # Python program to demonstrate nested ternary operator\na, b = 10, 20\nprint (\"Both a and b are equal\" if a == b else \"a is greater than b\"\n        if a > b else \"b is greater than a\")\n \n Above approach can be written as: \n # Python program to demonstrate nested ternary operator\na, b = 10, 20\nif a != b:\n    if a > b:\n        print(\"a is greater than b\")\n    else:\n        print(\"b is greater than a\")\nelse:\n    print(\"Both a and b are equal\")\n# Output: b is greater than a\n \n    ", "date_posted": "2022-02-06 13:11:36Z", "upvote": "\r\n            28\r\n        ", "accepted": "No", "user": {"stack_user_id": "49653070", "name": "\r\n        3 revs, 2 users 86%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "49653070", "stack_answer_comment_id": "92454366", "comment_content": "Note that the ternary operator is smaller (in memory) and faster than the nested if.  Also, your nested ", "user_id": "None"}]}, {"stack_answer_id": "65422380", "answer_content": "\r\n Vinko Vrsalovic's answer  is good enough. There is only one more thing: \n \n Note that conditionals are an  expression , not a  statement . This means you can't use assignment statements or  pass  or other  statements  within a conditional  expression \n \n Walrus operator in Python 3.8 \n After the  walrus operator  was introduced in Python 3.8, something changed. \n (a := 3) if True else (b := 5)\n \n gives  a = 3  and  b is not defined , \n (a := 3) if False else (b := 5)\n \n gives  a is not defined  and  b = 5 , and \n c = (a := 3) if False else (b := 5)\n \n gives  c = 5 ,  a is not defined  and  b = 5 . \n Even if this may be ugly,  assignments  can be done  inside  conditional expressions after Python 3.8. Anyway, it is still better to use normal  if   statement  instead in this case. \n    ", "date_posted": "2022-02-06 13:36:09Z", "upvote": "\r\n            27\r\n        ", "accepted": "No", "user": {"stack_user_id": "65422380", "name": "\r\n        2 revs, 2 users 69%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "65422380", "stack_answer_comment_id": "121325576", "comment_content": "In the first example: ", "user_id": "None"}, {"stack_answer_id": "65422380", "stack_answer_comment_id": "121356996", "comment_content": "@AndrewAnderson No it's not redundant. You should compare both the first and the second examples. You can combine them and consider this: ", "user_id": "None"}, {"stack_answer_id": "65422380", "stack_answer_comment_id": "121376861", "comment_content": "Yes, that's correct :). I considered this only for ", "user_id": "None"}, {"stack_answer_id": "65422380", "stack_answer_comment_id": "121396760", "comment_content": "Because we don't really write down this code ", "user_id": "None"}]}, {"stack_answer_id": "37155553", "answer_content": "\r\n More a tip than an answer (I don't need to repeat the obvious for the hundredth time), but I sometimes use it as a one-liner shortcut in such constructs: \n if conditionX:\n    print('yes')\nelse:\n    print('nah')\n \n , becomes: \n print('yes') if conditionX else print('nah')\n \n Some (many :) may frown upon it as unpythonic (even, Ruby-ish :), but I personally find it more natural - i.e., how you'd express it normally, plus a bit more visually appealing in large blocks of code. \n    ", "date_posted": "2022-02-06 12:30:29Z", "upvote": "\r\n            26\r\n        ", "accepted": "No", "user": {"stack_user_id": "37155553", "name": "\r\n        3 revs, 3 users 76%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "37155553", "stack_answer_comment_id": "78515516", "comment_content": "I prefer ", "user_id": "None"}, {"stack_answer_id": "37155553", "stack_answer_comment_id": "80853618", "comment_content": "That is if you want to ", "user_id": "None"}, {"stack_answer_id": "37155553", "stack_answer_comment_id": "92749861", "comment_content": "To add to Frederick99's remark, another reason to avoid ", "user_id": "None"}, {"stack_answer_id": "37155553", "stack_answer_comment_id": "92753803", "comment_content": "The only reason it gives a syntax error is because in Python 2 print is a statement - ", "user_id": "None"}]}, {"stack_answer_id": "45779600", "answer_content": "\r\n You can do this: \n [condition] and [expression_1] or [expression_2];\n \n Example: \n print(number%2 and \"odd\" or \"even\")\n \n This would print \"odd\" if the number is odd or \"even\" if the number is even. \n \n The result:  If condition is true, exp_1 is executed, else exp_2 is executed. \n Note:  0, None, False, emptylist, and emptyString evaluates as False. \n And any data other than 0 evaluates to True. \n Here's how it works: \n If the condition [condition] becomes \"True\", then expression_1 will be evaluated, but not expression_2. \n If we \"and\" something with 0 (zero), the result will always to be false. So in the below statement, \n 0 and exp\n \n The expression  exp  won't be evaluated at all since \"and\" with 0 will always evaluate to zero and there is no need to evaluate the expression. This is how the compiler itself works, in all languages. \n In \n 1 or exp\n \n the expression  exp  won't be evaluated at all since \"or\" with 1 will always be 1. So it won't bother to evaluate the expression exp since the result will be 1 anyway (compiler optimization methods). \n But in case of \n True and exp1 or exp2\n \n The second expression exp2 won't be evaluated since  True and exp1  would be True when exp1 isn't false. \n Similarly in \n False and exp1 or exp2\n \n The expression  exp1  won't be evaluated since False is equivalent to writing 0 and doing \"and\" with 0 would be 0 itself, but after exp1 since \"or\" is used, it will evaluate the expression exp2 after \"or\". \n \n Note:-  This kind of branching using \"or\" and \"and\" can only be used when the expression_1 doesn't have a Truth value of False (or 0 or None or emptylist [ ] or emptystring ' '.) since if expression_1 becomes False, then the expression_2 will be evaluated because of the presence \"or\" between exp_1 and exp_2. \n In case you still want to make it work for all the cases regardless of what exp_1 and exp_2 truth values are, do this: \n [condition] and ([expression_1] or 1) or [expression_2];\n \n    ", "date_posted": "2022-02-06 12:43:54Z", "upvote": "\r\n            26\r\n        ", "accepted": "No", "user": {"stack_user_id": "45779600", "name": "\r\n        5 revs, 2 users 52%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "45779600", "stack_answer_comment_id": "80634562", "comment_content": "If you want to use that in the context of ", "user_id": "None"}]}, {"stack_answer_id": "53922638", "answer_content": "\r\n Many programming languages derived from  C  usually have the following syntax of the ternary conditional operator: \n <condition> ? <expression1> : <expression2>\n \n At first, the Python's  benevolent dictator for life  (I mean  Guido van Rossum , of course) rejected it (as non-Pythonic style), since it's quite hard to understand for people not used to C language. Also, the colon sign  :  already has many uses in Python. After  PEP 308  was approved, Python finally received its own shortcut conditional expression (what we use now): \n <expression1> if <condition> else <expression2>\n \n So, firstly it evaluates the condition. If it returns  True ,  expression1  will be evaluated to give the result, otherwise  expression2  will be evaluated. Due to  lazy evaluation  mechanics \u2013 only one expression will be executed. \n Here are some examples (conditions will be evaluated from left to right): \n pressure = 10\nprint('High' if pressure < 20 else 'Critical')\n\n# Result is 'High'\n \n Ternary operators can be chained in series: \n pressure = 5\nprint('Normal' if pressure < 10 else 'High' if pressure < 20 else 'Critical')\n\n# Result is 'Normal'\n \n The following one is the same as previous one: \n pressure = 5\n\nif pressure < 20:\n    if pressure < 10:\n        print('Normal')\n    else:\n        print('High')\nelse:\n    print('Critical')\n\n# Result is 'Normal'\n \n    ", "date_posted": "2022-02-06 12:57:48Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "53922638", "name": "\r\n        4 revs, 3 users 87%", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "52919467", "answer_content": "\r\n Yes , Python have a ternary operator, here is the syntax and an example code to demonstrate the same :) \n #[On true] if [expression] else[On false]\n# if the expression evaluates to true then it will pass On true otherwise On false\n\na = input(\"Enter the First Number \")\nb = input(\"Enter the Second Number \")\n\nprint(\"A is Bigger\") if a>b else print(\"B is Bigger\")\n \n    ", "date_posted": "2022-02-06 12:52:56Z", "upvote": "\r\n            15\r\n        ", "accepted": "No", "user": {"stack_user_id": "52919467", "name": "\r\n        3 revs, 2 users 51%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "52919467", "stack_answer_comment_id": "92748969", "comment_content": "I have added a one line statement example to check which number is big to elaborate it further", "user_id": "None"}, {"stack_answer_id": "52919467", "stack_answer_comment_id": "92749878", "comment_content": " is really not a good choice, as this will give a SyntaxError in Python2.", "user_id": "None"}, {"stack_answer_id": "52919467", "stack_answer_comment_id": "92749900", "comment_content": "@Thierry Lathuille here I used print() function not print statement, print function is for Python 3 while print statement is for Python 2", "user_id": "None"}, {"stack_answer_id": "52919467", "stack_answer_comment_id": "92749954", "comment_content": "The question has already been asked on SO, just try it with Python 2 and you will see by yourself. 'print('hello') is a perfectly valid syntax in Python 2.7, but the way it is parsed makes your code above throw a SyntaxError.", "user_id": "None"}]}, {"stack_answer_id": "61896436", "answer_content": "\r\n Other answers correctly talk about the Python ternary operator. I would like to complement by mentioning a scenario for which the ternary operator is often used, but for which there is a better idiom. This is the scenario of using a default value. \n Suppose we want to use  option_value  with a default value if it is not set: \n run_algorithm(option_value if option_value is not None else 10)\n \n or, if  option_value  is never set to a falsy value ( 0 ,  \"\" , etc.), simply \n run_algorithm(option_value if option_value else 10)\n \n However, in this case an ever better solution is simply to write \n run_algorithm(option_value or 10)\n \n    ", "date_posted": "2022-02-06 13:31:30Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "61896436", "name": "\r\n        3 revs, 2 users 83%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "61896436", "stack_answer_comment_id": "113960535", "comment_content": "A valuable complement, but I disagree: ", "user_id": "None"}, {"stack_answer_id": "61896436", "stack_answer_comment_id": "114022487", "comment_content": "@ruancomelli: Good point. I've modified the answer to reflect that correction.", "user_id": "None"}, {"stack_answer_id": "61896436", "stack_answer_comment_id": "114022542", "comment_content": "As for it looking weird, I wonder if it looked weird to you because you noticed the imprecision (that it was not really equivalent). To me it sounds natural because it reminds me saying in English: \"Use this or that (if the first option is unavailable)\". But of course that is subjective. It is useful to know it does not look natural to everybody.", "user_id": "None"}, {"stack_answer_id": "61896436", "stack_answer_comment_id": "114190254", "comment_content": "Much better! And thanks for the explanation regarding the \"or\"-idiom. It looks weird to me because I tend to think of ", "user_id": "None"}]}, {"stack_answer_id": "71819081", "answer_content": "\r\n The syntax for the ternary operator in Python is: \n [on_true] if [expression] else [on_false] \n Using that syntax, here is how we would rewrite the code above using Python\u2019s ternary operator: \n game_type = 'home'\nshirt = 'white' if game_type == 'home' else 'green'\n\n \n It's still pretty clear, but much shorter. Note that the expression could be any type of expression, including a function call, that returns a value that evaluates to True or False. \n    ", "date_posted": "2022-04-10 17:39:25Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "71819081", "name": "\r\n        George Imerlishvili\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "60630600", "answer_content": "\r\n Python has a ternary form for assignments; however there may be even a shorter form that people should be aware of. \n It's very common to need to assign to a variable one value or another depending on a condition. \n >>> li1 = None\n>>> li2 = [1, 2, 3]\n>>>\n>>> if li1:\n...     a = li1\n... else:\n...     a = li2\n...\n>>> a\n[1, 2, 3]\n \n ^ This is the long form for doing such assignments. \n Below is the ternary form. But this isn't the most succinct way - see the last example. \n >>> a = li1 if li1 else li2\n>>>\n>>> a\n[1, 2, 3]\n>>>\n \n With Python, you can simply use  or  for alternative assignments. \n >>> a = li1 or li2\n>>>\n>>> a\n[1, 2, 3]\n>>>\n \n The above works since  li1  is  None  and the interpreter treats that as False in logic expressions. The interpreter then moves on and evaluates the second expression, which is not  None  and it's not an empty list - so it gets assigned to  a . \n This also works with empty lists. For instance, if you want to assign  a  whichever list has items. \n >>> li1 = []\n>>> li2 = [1, 2, 3]\n>>>\n>>> a = li1 or li2\n>>>\n>>> a\n[1, 2, 3]\n>>>\n \n Knowing this, you can simply such assignments whenever you encounter them. This also works with strings and other iterables. You could assign  a  whichever string isn't empty. \n >>> s1 = ''\n>>> s2 = 'hello world'\n>>>\n>>> a = s1 or s2\n>>>\n>>> a\n'hello world'\n>>>\n \n I always liked the C ternary syntax, but Python takes it a step further! \n I understand that some may say this isn't a good stylistic choice, because it relies on mechanics that aren't immediately apparent to all developers. I personally disagree with that viewpoint. Python is a syntax-rich language with lots of idiomatic tricks that aren't immediately apparent to the dabbler. But the more you learn and understand the mechanics of the underlying system, the more you appreciate it. \n    ", "date_posted": "2022-02-06 13:26:23Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "60630600", "name": "\r\n        4 revs, 2 users 86%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "60630600", "stack_answer_comment_id": "125525088", "comment_content": "Something seems to be missing near ", "user_id": "None"}, {"stack_answer_id": "60630600", "stack_answer_comment_id": "125527651", "comment_content": "\"Simplify\" such assignments =) @PeterMortensen", "user_id": "None"}]}, {"stack_answer_id": "70523744", "answer_content": "\r\n Pythonic way of doing the things: \n \"true\" if var else \"false\"\n \n But there always exists a different way of doing a ternary condition too: \n \"true\" and var or \"false\"\n \n    ", "date_posted": "2022-02-06 13:55:46Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "70523744", "name": "\r\n        2 revs, 2 users 80%", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "71007804", "answer_content": "\r\n There are multiple ways. The simplest one is to use the condition inside the \"print\" method. \n You can use \n print(\"Twenty\" if number == 20 else \"Not twenty\")\n \n Which is equivalent to: \n if number == 20:\n    print(\"Twenty\")\nelse:\n    print(\"Not twenty\")\n \n In this way, more than two statements are also possible to print. For example: \n if number == 20:\n    print(\"Twenty\")\nelif number < 20:\n    print(\"Lesser\")\nelif 30 > number > 20:\n    print(\"Between\")\nelse:\n    print(\"Greater\")\n \n can be written as: \n print(\"Twenty\" if number == 20 else \"Lesser\" if number < 20 else \"Between\" if 30 > number > 20 else \"Greater\")\n \n    ", "date_posted": "2022-02-06 13:46:32Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "71007804", "name": "\r\n        Aldrin Saurov Sarker\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "70941294", "answer_content": "\r\n The  if else-if  version can be written as: \n sample_set=\"train\" if \"Train\" in full_path else (\"test\" if \"Test\" in full_path else \"validation\")\n \n    ", "date_posted": "2022-02-06 13:56:20Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "70941294", "name": "\r\n        2 revs, 2 users 67%", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "71150434", "answer_content": "\r\n Yes, it has, but it's different from C-syntax-like programming languages (which is  condition ? value_if_true : value_if_false \n In Python, it goes like this:  value_if_true if condition else value_if_false \n Example:  even_or_odd = \"even\" if x % 2 == 0 else \"odd\" \n    ", "date_posted": "2022-02-16 23:09:11Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "71150434", "name": "\r\n        Heroes Of Balkan\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "56099511", "answer_content": "\r\n A neat way to chain multiple operators: \n\n f = lambda x,y: 'greater' if x > y else 'less' if y > x else 'equal'\n\narray = [(0,0),(0,1),(1,0),(1,1)]\n\nfor a in array:\n  x, y = a[0], a[1]\n  print(f(x,y))\n\n# Output is:\n#   equal,\n#   less,\n#   greater,\n#   equal\n\n \n    ", "date_posted": "2019-05-12 13:03:48Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "56099511", "name": "\r\n        Yaakov Bressler\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "60876846", "answer_content": "\r\n I find the default Python syntax  val = a if cond else b  cumbersome, so sometimes I do this: \n iif = lambda (cond, a, b): a if cond else b\n# So I can then use it like:\nval = iif(cond, a, b)\n \n Of course, it has the downside of always evaluating both sides ( a  and  b ), but the syntax is way clearer to me. \n    ", "date_posted": "2022-02-06 13:30:33Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "60876846", "name": "\r\n        2 revs, 2 users 60%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "60876846", "stack_answer_comment_id": "108765520", "comment_content": "This seems to be twice the amount of work, more RAM usage and more obfuscated than the simpler ", "user_id": "None"}, {"stack_answer_id": "60876846", "stack_answer_comment_id": "116103460", "comment_content": "Also both ", "user_id": "None"}, {"stack_answer_id": "60876846", "stack_answer_comment_id": "126733397", "comment_content": "According to PEP8 assigning lambda to variable is a code smell. Lambda should be used only as inplace function.", "user_id": "None"}]}], "user": {"stack_user_id": null, "name": null, "reputation_score": 0}, "question_comments": [{"stack_question_id": "394809", "stack_question_comment_id": "19777451", "comment_content": "In the Python 3.0 official documentation referenced in a comment above, this is referred to as \"conditional_expressions\" and is very cryptically defined.  That documentation doesn't even include the term \"ternary\", so you would be hard-pressed to find it via Google unless you knew exactly what to look for.  The ", "user_id": "None"}, {"stack_question_id": "394809", "stack_question_comment_id": "43418120", "comment_content": "\"ternary\" (having three inputs) is a consequential property of this impelmentation, not a defining property of the concept. eg:  SQL has ", "user_id": "None"}, {"stack_question_id": "394809", "stack_question_comment_id": "43418299", "comment_content": "also ISO/IEC 9899 (the C programming language standard) section 6.5.15 calls it the \"the condtitional operator\"", "user_id": "None"}, {"stack_question_id": "394809", "stack_question_comment_id": "62912948", "comment_content": "Wikipedia covers this thoroughly in the article \"", "user_id": "None"}, {"stack_question_id": "394809", "stack_question_comment_id": "90671337", "comment_content": "In the years since nobar's comment the ", "user_id": "None"}]},
{"stack_question_id": "2709821", "question_title": "What is the `self` parameter in class methods?", "question_content": "\r\n                self refers to the specific object instance created from a class. But why must every method explicitly include self as a parameter?\nclass MyClass:\n    def func(self, name):\n        self.name = name\n\n...\r\n", "question_url": "/questions/2709821/what-is-the-self-parameter-in-class-methods", "date_posted": "Apr 25, 2010 at 20:22", "upvote": "1", "view": "9", "tags": ["python", "class", "oop", "self"], "answers_count": "2", "answers": [{"stack_answer_id": "2709832", "answer_content": "\r\n The reason you need to use  self.  is because Python does not use the  @  syntax to refer to instance attributes. Python decided to do methods in a way that makes the instance to which the method belongs be  passed  automatically, but not  received  automatically: the first parameter of methods is the instance the method is called on. That makes methods entirely the same as functions, and leaves the actual name to use up to you (although  self  is the convention, and people will generally frown at you when you use something else.)  self  is not special to the code, it's just another object. \n\n Python could have done something else to distinguish normal names from attributes -- special syntax like Ruby has, or requiring declarations like C++ and Java do, or perhaps something  yet more different -- but it didn't. Python's all for making things explicit, making it obvious what's what, and although it doesn't do it entirely everywhere, it does do it for instance attributes. That's why assigning to an instance attribute needs to know what instance to assign to, and that's why it needs  self. . \n    ", "date_posted": "2010-04-27 23:01:28Z", "upvote": "\r\n            765\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "17624", "name": "Thomas Wouters", "reputation_score": "126k"}, "answer_comments": [{"stack_answer_id": "2709832", "stack_answer_comment_id": "2734191", "comment_content": "@Georg: ", "user_id": "None"}, {"stack_answer_id": "2709832", "stack_answer_comment_id": "4604498", "comment_content": "@SilentGhost: Actually, the name of the first parameter is whatever you want it to be.  On class methods, the convention is to use ", "user_id": "None"}, {"stack_answer_id": "2709832", "stack_answer_comment_id": "19063966", "comment_content": "I find it interesting that the community didn't choose ", "user_id": "None"}, {"stack_answer_id": "2709832", "stack_answer_comment_id": "27940514", "comment_content": "@Julius The ", "user_id": "None"}, {"stack_answer_id": "2709832", "stack_answer_comment_id": "42210957", "comment_content": "@Julius The ", "user_id": "None"}]}, {"stack_answer_id": "21366809", "answer_content": "\r\n Let's say you have a class  ClassA  which contains a method  methodA  defined as: \n\n def methodA(self, arg1, arg2):\n    # do something\n \n\n and  ObjectA  is an instance of this class. \n\n Now when  ObjectA.methodA(arg1, arg2)  is called, python internally converts it for you as: \n\n ClassA.methodA(ObjectA, arg1, arg2)\n \n\n The  self  variable refers to the object itself. \n    ", "date_posted": "2019-11-16 18:56:13Z", "upvote": "\r\n            583\r\n        ", "accepted": "No", "user": {"stack_user_id": "997813", "name": "Arjun Sreedharan", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "21366809", "stack_answer_comment_id": "41174707", "comment_content": "I read all the other answers and sort of understood, I read this one and then it all made sense.", "user_id": "None"}, {"stack_answer_id": "21366809", "stack_answer_comment_id": "79661533", "comment_content": "Why not keep those guts inside, though, like Ruby does?", "user_id": "None"}, {"stack_answer_id": "21366809", "stack_answer_comment_id": "83963043", "comment_content": "But in __init__(self) method, it accepts self, then even without creating the object, how does it refer to itself?", "user_id": "None"}, {"stack_answer_id": "21366809", "stack_answer_comment_id": "120812764", "comment_content": "This doesn't answer the question though. The OP was asking about why ", "user_id": "None"}, {"stack_answer_id": "21366809", "stack_answer_comment_id": "129280090", "comment_content": "Why then a new function is generated for every instance of ", "user_id": "None"}]}, {"stack_answer_id": "2725996", "answer_content": "\r\n Let\u2019s take a simple vector class: \n\n class Vector:\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n \n\n We want to have a method which calculates the length. What would it look like if we wanted to define it inside the class? \n\n     def length(self):\n        return math.sqrt(self.x ** 2 + self.y ** 2)\n \n\n What should it look like when we were to define it as a global method/function? \n\n def length_global(vector):\n    return math.sqrt(vector.x ** 2 + vector.y ** 2)\n \n\n So the whole structure stays the same. How can me make use of this? If we assume for a moment that we hadn\u2019t written a  length  method for our  Vector  class, we could do this: \n\n Vector.length_new = length_global\nv = Vector(3, 4)\nprint(v.length_new()) # 5.0\n \n\n This works because the first parameter of  length_global , can be re-used as the  self  parameter in  length_new . This would not be possible without an explicit  self . \n\n \n\n Another way of understanding the need for the explicit  self  is to see where Python adds some syntactical sugar. When you keep in mind, that basically, a call like \n\n v_instance.length()\n \n\n is internally transformed to \n\n Vector.length(v_instance)\n \n\n it is easy to see where the  self  fits in. You don't actually write instance methods in Python; what you write is class methods which must take an instance as a first parameter. And therefore, you\u2019ll have to place the instance parameter somewhere explicitly. \n    ", "date_posted": "2017-08-15 06:40:38Z", "upvote": "\r\n            436\r\n        ", "accepted": "No", "user": {"stack_user_id": "1637126", "name": "empty", "reputation_score": "4,892"}, "answer_comments": [{"stack_answer_id": "2725996", "stack_answer_comment_id": "4604132", "comment_content": "Vector.length_new = length_global... I actually started to use syntax like this in my class declarations. Whenever I only want to inherit some of the methods from another class, I just explicitly copy the reference to the methods.", "user_id": "None"}, {"stack_answer_id": "2725996", "stack_answer_comment_id": "16540616", "comment_content": "would it be fair to say that python's \"instance method\" is simply a syntactic sugar of static global methods (as in Java or C++) with an instance object passed in to package multiple attributes?  --- well this is kind of half-true since in polymorphism, the more important purpose of \"this\" (as in java) or \"self\" is to give u the correct implementation of methods. Python does have this. so calling myobj.someMethod() is equal to TheClassOfMyObj.someMethod(myobj) in python. note that the \"TheClassOfMyObj\" is automatically figured out by python from \"self\", otherwise u'd have to find that out.", "user_id": "None"}, {"stack_answer_id": "2725996", "stack_answer_comment_id": "27469407", "comment_content": "Infact, not only are instance methods just class methods, but methods are just functions which are members of a class, as the ", "user_id": "None"}, {"stack_answer_id": "2725996", "stack_answer_comment_id": "34102116", "comment_content": "\"This works, because the first parameter of length_global, can be re-used as the self parameter in length_new. This would not be possible without an explicit self.\" - it would work just the same. it would be re-used for the implicit self... the second example is a circular reasoning - you have to explicitly place self there, because python needs the explicit self.", "user_id": "None"}, {"stack_answer_id": "2725996", "stack_answer_comment_id": "34123622", "comment_content": "@KarolyHorvath: Sure, it would also be possible to have a language with a model where internally defined methods do not need an explicit self but externally defined methods do. But I\u2019d say there is some consistency in requiring the explicit self in both cases, which makes it a legitimate reason to do it this way. Other languages may choose different approaches.", "user_id": "None"}]}, {"stack_answer_id": "31096552", "answer_content": "\r\n When objects are instantiated, the object itself is passed into the self parameter.  \n\n \n\n Because of this, the object\u2019s data is bound to the object. Below is an example of how you might like to visualize what each object\u2019s data might look. Notice how \u2018self\u2019 is replaced with the objects name. I'm not saying this example diagram below is wholly accurate but it hopefully with serve a purpose in visualizing the use of self.  \n\n \n\n The Object is passed into the self parameter so that the object can keep hold of its own data. \n\n Although this may not be wholly accurate, think of the process of instantiating an object like this: When an object is made it uses the class as a template for its own data and methods. Without passing it's own name into the self parameter, the attributes and methods in the class would remain as a general template and would not be referenced to (belong to) the object. So by passing the object's name into the self parameter it means that if 100 objects are instantiated from the one class, they can all keep track of their own data and methods. \n\n See the illustration below: \n\n \n    ", "date_posted": "2015-06-28 05:47:02Z", "upvote": "\r\n            246\r\n        ", "accepted": "No", "user": {"stack_user_id": "2686197", "name": "sw123456", "reputation_score": "3,171"}, "answer_comments": [{"stack_answer_id": "31096552", "stack_answer_comment_id": "51742866", "comment_content": "Hey there, when accessing Bob's attributes for example by \"bob.name()\", you actually accesing bob().self.name so to speak from the '", "user_id": "None"}, {"stack_answer_id": "31096552", "stack_answer_comment_id": "51743445", "comment_content": "When you write bob.name() in the above comment, you are implying that bob has a method called name() due to the fact that you added brackets after name. In this example however there is no such method. 'bob.name' (which has no parenthesis) is directly accessing the attribute called name from the init (constructor) method. When bob's speak method is called it is the method which accesses the name attribute and returns it in a print statement. Hope this helps.", "user_id": "None"}, {"stack_answer_id": "31096552", "stack_answer_comment_id": "51744484", "comment_content": "No, you get the value of self.name, which for the bob object is actually bob.name, because the object's name is passed into the self parameter when it is created (instantiated). Again, hope this helps. Feel free to upvote main post if it has.", "user_id": "None"}, {"stack_answer_id": "31096552", "stack_answer_comment_id": "51744680", "comment_content": "Name is assigned to self.name at instantiation. After an object is created, all variables that belong to the object are those prefixed with 'self.' Remember that self is replaced with the object's name when it is created from the class.", "user_id": "None"}, {"stack_answer_id": "31096552", "stack_answer_comment_id": "81189993", "comment_content": "This is how you explain stuff ! nice job :)", "user_id": "None"}]}, {"stack_answer_id": "2714920", "answer_content": "\r\n I like this example: \n\n class A: \n    foo = []\na, b = A(), A()\na.foo.append(5)\nb.foo\nans: [5]\n\nclass A: \n    def __init__(self): \n        self.foo = []\na, b = A(), A()\na.foo.append(5)\nb.foo\nans: []\n \n    ", "date_posted": "2010-04-26 16:02:48Z", "upvote": "\r\n            85\r\n        ", "accepted": "No", "user": {"stack_user_id": "237934", "name": "kame", "reputation_score": "19.4k"}, "answer_comments": [{"stack_answer_id": "2714920", "stack_answer_comment_id": "16540656", "comment_content": "so vars without self is simply static vars of the class, like in java", "user_id": "None"}, {"stack_answer_id": "2714920", "stack_answer_comment_id": "34582202", "comment_content": "teddy teddy, you aren't entirely correct. The behavior (static or non-static like) depends not only on ", "user_id": "None"}, {"stack_answer_id": "2714920", "stack_answer_comment_id": "39184200", "comment_content": "Actually, my question with this is why are you allowed to say ", "user_id": "None"}, {"stack_answer_id": "2714920", "stack_answer_comment_id": "41852298", "comment_content": "You can call static members from instances of the object in most languages. Why is that surprising?", "user_id": "None"}, {"stack_answer_id": "2714920", "stack_answer_comment_id": "77100679", "comment_content": "@RadonRosborough Because in the first example, ", "user_id": "None"}]}, {"stack_answer_id": "6433556", "answer_content": "\r\n I will demonstrate with code that  does not use classes : \n\n def state_init(state):\n    state['field'] = 'init'\n\ndef state_add(state, x):\n    state['field'] += x\n\ndef state_mult(state, x):\n    state['field'] *= x\n\ndef state_getField(state):\n    return state['field']\n\nmyself = {}\nstate_init(myself)\nstate_add(myself, 'added')\nstate_mult(myself, 2)\n\nprint( state_getField(myself) )\n#--> 'initaddedinitadded'\n \n\n Classes are just a way to avoid passing in this \"state\" thing all the time (and other nice things like initializing, class composition, the rarely-needed metaclasses, and supporting custom methods to override operators). \n\n Now let's demonstrate the above code using the built-in python class machinery, to show how it's basically the same thing. \n\n class State(object):\n    def __init__(self):\n        self.field = 'init'\n    def add(self, x):\n        self.field += x\n    def mult(self, x):\n        self.field *= x\n\ns = State()\ns.add('added')    # self is implicitly passed in\ns.mult(2)         # self is implicitly passed in\nprint( s.field )\n \n\n [migrated my answer from duplicate closed question] \n    ", "date_posted": "2011-06-22 00:27:23Z", "upvote": "\r\n            45\r\n        ", "accepted": "No", "user": {"stack_user_id": "711085", "name": "ninjagecko", "reputation_score": "84.7k"}, "answer_comments": [{"stack_answer_id": "6433556", "stack_answer_comment_id": "79661616", "comment_content": "I wish Python sugarcoated the handlers as well as Ruby does.", "user_id": "None"}]}, {"stack_answer_id": "2709847", "answer_content": "\r\n The following excerpts are from the  Python documentation about self : \n \n As in Modula-3, there are no shorthands [in Python] for referencing the object\u2019s members from its methods: the method function is declared with an explicit first argument representing the object, which is provided implicitly by the call. \n Often, the first argument of a method is called self. This is nothing more than a convention: the name self has absolutely no special meaning to Python. Note, however, that by not following the convention your code may be less readable to other Python programmers, and it is also conceivable that a class browser program might be written that relies upon such a convention. \n \n For more information, see the  Python documentation tutorial on classes . \n    ", "date_posted": "2020-06-20 09:12:55Z", "upvote": "\r\n            23\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}, {"stack_answer_id": "2709857", "answer_content": "\r\n As well as all the other reasons already stated, it allows for easier access to overridden methods; you can call  Class.some_method(inst) . \n\n An example of where it\u2019s useful: \n\n class C1(object):\n    def __init__(self):\n         print \"C1 init\"\n\nclass C2(C1):\n    def __init__(self): #overrides C1.__init__\n        print \"C2 init\"\n        C1.__init__(self) #but we still want C1 to init the class too\n \n\n\n\n >>> C2()\n\"C2 init\"\n\"C1 init\"\n \n    ", "date_posted": "2013-12-24 22:23:49Z", "upvote": "\r\n            22\r\n        ", "accepted": "No", "user": {"stack_user_id": "707111", "name": "Ry-", "reputation_score": "211k"}, "answer_comments": []}, {"stack_answer_id": "12201574", "answer_content": "\r\n Its use is similar to the use of  this  keyword in Java, i.e. to give a reference to the current object. \n    ", "date_posted": "2017-02-27 09:47:48Z", "upvote": "\r\n            18\r\n        ", "accepted": "No", "user": {"stack_user_id": "5387193", "name": "ChickenFeet", "reputation_score": "2,417"}, "answer_comments": [{"stack_answer_id": "12201574", "stack_answer_comment_id": "17780797", "comment_content": "class myClass:         def myFunc(this, name):             this.name = name", "user_id": "None"}]}, {"stack_answer_id": "30442095", "answer_content": "\r\n Python is not a language built for Object Oriented Programming unlike Java or C++.  \n\n When calling a static method in Python, one simply writes a method with regular arguments inside it.  \n\n class Animal():\n    def staticMethod():\n        print \"This is a static method\"\n \n\n However, an object method, which requires you to make a variable, which is an Animal, in this case, needs the self argument \n\n class Animal():\n    def objectMethod(self):\n        print \"This is an object method which needs an instance of a class\"\n \n\n The self method is also used to refer to a variable field within the class.  \n\n class Animal():\n    #animalName made in constructor\n    def Animal(self):\n        self.animalName = \"\";\n\n\n    def getAnimalName(self):\n        return self.animalName\n \n\n In this case, self is referring to the animalName variable of the entire class. REMEMBER: If you have a variable within a method, self will not work. That variable is simply existent only while that method is running. For defining fields (the variables of the entire class), you have to define them OUTSIDE the class methods.  \n\n If you don't understand a single word of what I am saying, then Google \"Object Oriented Programming.\" Once you understand this, you won't even need to ask that question :). \n    ", "date_posted": "2017-09-21 18:39:06Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "4871483", "name": "rassa45", "reputation_score": "3,406"}, "answer_comments": [{"stack_answer_id": "30442095", "stack_answer_comment_id": "51164282", "comment_content": "+1 because of the distinction between ", "user_id": "None"}, {"stack_answer_id": "30442095", "stack_answer_comment_id": "57247895", "comment_content": "What you are saying isn't 100% true. That's just a convention. You can still call the static method from an object created. You just won't be able to use any class members because you didn't declare a self. I can even call Animal.objectMethod(animalObj) to call the non static. Basically this means a static method is only a method that doesn't use member variables. There shouldn't be any need to declare self. It's a silly language requirement I think. Languages like Lua and C++ give you obj variables behind the scenes.", "user_id": "None"}, {"stack_answer_id": "30442095", "stack_answer_comment_id": "79661861", "comment_content": "You made a useless animalName string declaration and crashing animalName method.", "user_id": "None"}, {"stack_answer_id": "30442095", "stack_answer_comment_id": "79662136", "comment_content": "@ytpillai Irrelevant. Confusing and incorrect code should not be presented as an answer.", "user_id": "None"}, {"stack_answer_id": "30442095", "stack_answer_comment_id": "79662264", "comment_content": " to not clobber the string you're trying to return, and ", "user_id": "None"}]}, {"stack_answer_id": "48219699", "answer_content": "\r\n First of all, self is a conventional name, you could put anything else (being coherent) in its stead. \n\n It refers to the object itself, so when you are using it, you are declaring that .name and .age are properties of the Student objects (note, not of the Student class) you are going to create. \n\n class Student:\n    #called each time you create a new Student instance\n    def __init__(self,name,age): #special method to initialize\n        self.name=name\n        self.age=age\n\n    def __str__(self): #special method called for example when you use print\n        return \"Student %s is %s years old\" %(self.name,self.age)\n\n    def call(self, msg): #silly example for custom method\n        return (\"Hey, %s! \"+msg) %self.name\n\n#initializing two instances of the student class\nbob=Student(\"Bob\",20)\nalice=Student(\"Alice\",19)\n\n#using them\nprint bob.name\nprint bob.age\nprint alice #this one only works if you define the __str__ method\nprint alice.call(\"Come here!\") #notice you don't put a value for self\n\n#you can modify attributes, like when alice ages\nalice.age=20\nprint alice\n \n\n Code is here  \n    ", "date_posted": "2018-01-12 04:45:25Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "6464277", "name": "Akash Kandpal", "reputation_score": "2,684"}, "answer_comments": []}, {"stack_answer_id": "2709836", "answer_content": "\r\n self  is an object reference to the object itself, therefore, they are same.\nPython methods are not called in the context of the object itself.\n self  in Python may be used to deal with custom object models or something. \n    ", "date_posted": "2010-04-25 20:26:35Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "303939", "name": "Ming-Tang", "reputation_score": "17.1k"}, "answer_comments": []}, {"stack_answer_id": "18278904", "answer_content": "\r\n It\u2019s there to follow the Python zen \u201cexplicit is better than implicit\u201d. It\u2019s indeed a reference to your class object. In Java and PHP, for example, it's called  this . \n\n If  user_type_name  is a field on your model you access it by  self.user_type_name . \n    ", "date_posted": "2013-12-24 22:24:58Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "707111", "name": "Ry-", "reputation_score": "211k"}, "answer_comments": []}, {"stack_answer_id": "34750920", "answer_content": "\r\n I'm surprised nobody has brought up Lua. Lua also uses the 'self' variable however it can be omitted but still used. C++ does the same with 'this'. I don't see any reason to have to declare 'self' in each function but you should still be able to use it just like you can with lua and C++. For a language that prides itself on being brief it's odd that it requires you to declare the self variable. \n    ", "date_posted": "2016-01-12 18:10:32Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "441521", "name": "user441521", "reputation_score": "6,684"}, "answer_comments": []}, {"stack_answer_id": "51631485", "answer_content": "\r\n The use of the argument, conventionally called  self  isn't as hard to understand, as is why is it necessary? Or as to why explicitly mention it? That, I suppose, is a bigger question for most users who look up this question, or if it is not, they will certainly have the same question as they move forward learning python. I recommend them to read these couple of blogs: \n\n 1: Use of self explained \n\n Note that it is not a keyword. \n\n \n   The first argument of every class method, including init, is always a reference to the current instance of the class. By convention, this argument is always named self. In the init method, self refers to the newly created object; in other class methods, it refers to the instance whose method was called. For example the below code is the same as the above code. \n \n\n 2: Why do we have it this way and why can we not eliminate it as an argument, like Java, and have a keyword instead \n\n Another thing I would like to add is, an optional  self  argument allows me to declare static methods inside a class, by not writing  self . \n\n Code examples: \n\n class MyClass():\n    def staticMethod():\n        print \"This is a static method\"\n\n    def objectMethod(self):\n        print \"This is an object method which needs an instance of a class, and that is what self refers to\"\n \n\n PS :This works only in Python 3.x. \n\n In previous versions, you have to explicitly add  @staticmethod  decorator, otherwise  self  argument is obligatory.  \n    ", "date_posted": "2018-08-12 10:20:06Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "5758889", "name": "Bugs Buggy", "reputation_score": "1,494"}, "answer_comments": []}, {"stack_answer_id": "26943812", "answer_content": "\r\n Take a look at the following example, which clearly explains the purpose of  self \n\n class Restaurant(object):  \n    bankrupt = False\n\n    def open_branch(self):\n        if not self.bankrupt:\n           print(\"branch opened\")\n\n#create instance1\n>>> x = Restaurant()\n>>> x.bankrupt\nFalse\n\n#create instance2\n>>> y = Restaurant()\n>>> y.bankrupt = True   \n>>> y.bankrupt\nTrue\n\n>>> x.bankrupt\nFalse  \n \n\n self  is used/needed to distinguish between instances. \n\n Source:  self variable in python explained - Pythontips \n    ", "date_posted": "2020-05-19 22:05:41Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "2956066", "name": "kmario23", "reputation_score": "52.1k"}, "answer_comments": [{"stack_answer_id": "26943812", "stack_answer_comment_id": "57247643", "comment_content": "Yes, I think we know why self is used, but the question is why does the language make you explicitly declare it. Many other languages don't require this and a language which prides itself on being brief, you'd think they would just give you the variable behind the scenes to use like Lua or C++ (this) does.", "user_id": "None"}, {"stack_answer_id": "26943812", "stack_answer_comment_id": "86661379", "comment_content": "@kmario23 You're response was from here: ", "user_id": "None"}]}, {"stack_answer_id": "32243243", "answer_content": "\r\n Is because by the way python is designed the alternatives would hardly work. Python is designed to allow methods or functions to be defined in a context where both implicit  this  (a-la Java/C++) or explicit  @  (a-la ruby) wouldn't work. Let's have an example with the explicit approach with python conventions: \n\n def fubar(x):\n    self.x = x\n\nclass C:\n    frob = fubar\n \n\n Now the  fubar  function wouldn't work since it would assume that  self  is a global variable (and in  frob  as well). The alternative would be to execute method's with a replaced global scope (where  self  is the object). \n\n The implicit approach would be \n\n def fubar(x)\n    myX = x\n\nclass C:\n    frob = fubar\n \n\n This would mean that  myX  would be interpreted as a local variable in  fubar  (and in  frob  as well). The alternative here would be to execute methods with a replaced local scope which is retained between calls, but that would remove the posibility of method local variables. \n\n However the current situation works out well: \n\n  def fubar(self, x)\n     self.x = x\n\n class C:\n     frob = fubar\n \n\n here when called as a method  frob  will receive the object on which it's called via the  self  parameter, and  fubar  can still be called with an object as parameter and work the same (it  is  the same as  C.frob  I think). \n    ", "date_posted": "2015-08-27 07:31:02Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "4498329", "name": "skyking", "reputation_score": "13.3k"}, "answer_comments": []}, {"stack_answer_id": "21367245", "answer_content": "\r\n In the  __init__  method, self refers to the newly created object; in other class methods, it refers to the instance whose method was called. \n\n self, as a name, is  just a convention , call it as you want ! but when using it, for example to delete the object, you have to use the same name:  __del__(var) , where  var  was used in the  __init__(var,[...]) \n\n You should take a look at  cls  too, to have  the bigger picture . This  post  could be helpful. \n    ", "date_posted": "2017-05-23 12:18:30Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}, {"stack_answer_id": "58585068", "answer_content": "\r\n self is acting as like current object name or instance of class . \n\n # Self explanation.\n\n\n class classname(object):\n\n    def __init__(self,name):\n\n        self.name=name\n        # Self is acting as a replacement of object name.\n        #self.name=object1.name\n\n   def display(self):\n      print(\"Name of the person is :\",self.name)\n      print(\"object name:\",object1.name)\n\n\n object1=classname(\"Bucky\")\n object2=classname(\"ford\")\n\n object1.display()\n object2.display()\n\n###### Output \nName of the person is : Bucky\nobject name: Bucky\nName of the person is : ford\nobject name: Bucky\n \n    ", "date_posted": "2019-10-28 02:15:18Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "9724968", "name": "sameer_nubia", "reputation_score": "661"}, "answer_comments": []}, {"stack_answer_id": "63320527", "answer_content": "\r\n \"self\" keyword holds the reference of class and it is upto you if you want to use it or not but if you notice, whenever you create a new method in python, python automatically write self keyword for you. If you do some R&D, you will notice that if you create say two methods in a class and try to call one inside another, it does not recognize method unless you add self (reference of class). \n class testA:\ndef __init__(self):\n    print('ads')\ndef m1(self):\n    print('method 1')\n    self.m2()\ndef m2(self):\n    print('method 2')\n \n Below code throws unresolvable reference error. \n class testA:\ndef __init__(self):\n    print('ads')\ndef m1(self):\n    print('method 1')\n    m2()  #throws unresolvable reference error as class does not know if m2 exist in class scope\ndef m2(self):\n    print('method 2')\n \n Now let see below example \n class testA:\ndef __init__(self):\n    print('ads')\ndef m1(self):\n    print('method 1')\ndef m2():\n    print('method 2')\n \n Now when you create object of class testA, you can call method m1() using class object like this as method m1() has included self keyword \n obj = testA()\nobj.m1()\n \n But if you want to call method m2(), because is has no self reference so you can call m2() directly using class name like below \n testA.m2()\n \n But keep in practice to live with self keyword as there are other benefits too of it like creating global variable inside and so on. \n    ", "date_posted": "2020-08-09 08:33:08Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "4268680", "name": "Rahul Jha", "reputation_score": "726"}, "answer_comments": []}, {"stack_answer_id": "56279547", "answer_content": "\r\n self  is inevitable. \n\n There was just a  question  should  self  be implicit or explicit.\n Guido van Rossum  resolved this question saying  self  has to stay . \n\n So where the  self  live? \n\n If we would just stick to functional programming we would not need  self .\nOnce we enter the  Python OOP  we find  self  there. \n\n Here is the typical use case  class C  with the method  m1 \n\n class C:\n    def m1(self, arg):\n        print(self, ' inside')\n        pass\n\nci =C()\nprint(ci, ' outside')\nci.m1(None)\nprint(hex(id(ci))) # hex memory address\n \n\n \n\n This program will output: \n\n <__main__.C object at 0x000002B9D79C6CC0>  outside\n<__main__.C object at 0x000002B9D79C6CC0>  inside\n0x2b9d79c6cc0\n \n\n So  self  holds the memory address of the class instance.\n The purpose  of  self  would be to hold the reference for  instance methods  and for us to have  explicit  access to that reference.      \n\n \n\n Note there are three different types of class methods:  \n\n \n static methods (read: functions),  \n class methods,  \n instance methods (mentioned). \n \n    ", "date_posted": "2019-05-25 08:53:24Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "5884955", "name": "prosti", "reputation_score": "36.9k"}, "answer_comments": []}, {"stack_answer_id": "67015236", "answer_content": "\r\n The word 'self' refers to instance of a class \n class foo:\n      def __init__(self, num1, num2):\n             self.n1 = num1 #now in this it will make the perimeter num1 and num2 access across the whole class\n             self.n2 = num2\n      def add(self):\n             return self.n1 + self.n2 # if we had not written self then if would throw an error that n1 and n2 is not defined and we have to include self in the function's perimeter to access it's variables\n \n    ", "date_posted": "2021-04-09 04:52:32Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "15394199", "name": "PrabhavDevo", "reputation_score": "1,270"}, "answer_comments": []}, {"stack_answer_id": "2709828", "answer_content": "\r\n it's an explicit reference to the class instance object.  \n    ", "date_posted": "2010-04-25 20:24:57Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "12855", "name": "SilentGhost", "reputation_score": "291k"}, "answer_comments": [{"stack_answer_id": "2709828", "stack_answer_comment_id": "2734185", "comment_content": "I don't think this helps richzilla to understand the reason behind it.", "user_id": "None"}, {"stack_answer_id": "2709828", "stack_answer_comment_id": "80247629", "comment_content": "@SilentGhost: you have nailed it. I am impressed. if I understand it correctly: I do create an object as an instance of the defined class and the self parameter refers to that object? I understand self refers in implicit way to the class itself but it would be great if you explain your answer a bit more.", "user_id": "None"}]}, {"stack_answer_id": "60412005", "answer_content": "\r\n from the  docs ,  \n\n \n   the special thing about methods is that the instance object is passed as the first argument of the function. In our example, the call  x.f()  is exactly equivalent to  MyClass.f(x) . In general, calling a method with a list of n arguments is equivalent to calling the corresponding function with an argument list that is created by inserting the method\u2019s instance object before the first argument. \n \n\n preceding this the related snippet, \n\n class MyClass:\n    \"\"\"A simple example class\"\"\"\n    i = 12345\n\n    def f(self):\n        return 'hello world'\n \n\n x = MyClass()\n \n    ", "date_posted": "2020-02-26 10:39:14Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "6903290", "name": "laxman", "reputation_score": "1,342"}, "answer_comments": []}, {"stack_answer_id": "62536337", "answer_content": "\r\n I would say for Python at least, the self parameter can be thought of as a placeholder.\nTake a look at this: \n class Person:\n  def __init__(self, name, age):\n    self.name = name\n    self.age = age\n\np1 = Person(\"John\", 36)\n\nprint(p1.name)\nprint(p1.age)\n \n Self in this case and a lot of others was used as a method to say store the name value. However, after that, we use the p1 to assign it to the class we're using. Then when we print it we use the same p1 keyword. \n Hope this helps for Python! \n    ", "date_posted": "2020-06-23 13:50:57Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "13750055", "name": "Rishi", "reputation_score": "41"}, "answer_comments": []}, {"stack_answer_id": "65461903", "answer_content": "\r\n my little 2 cents \n In this class Person, we defined out  init  method with the self and interesting thing to notice here is the memory location of both the  self  and instance variable  p  is same  <__main__.Person object at 0x106a78fd0> \n class Person:\n\n    def __init__(self, name, age):\n        self.name = name \n        self.age = age \n\n    def say_hi(self):\n        print(\"the self is at:\", self)\n        print((f\"hey there, my name is {self.name} and I am {self.age} years old\"))\n\n    def say_bye(self):\n        print(\"the self is at:\", self)\n        print(f\"good to see you {self.name}\")\n\np = Person(\"john\", 78)\nprint(\"the p is at\",p)\np.say_hi()  \np.say_bye() \n \n so as explained in above, both self and instance variable are same object. \n    ", "date_posted": "2020-12-27 00:13:06Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "9476814", "name": "saran", "reputation_score": "326"}, "answer_comments": []}], "user": {"stack_user_id": "301032", "name": "richzilla", "reputation_score": "38.6k"}, "question_comments": [{"stack_question_id": "2709821", "stack_question_comment_id": "2734198", "comment_content": "You may find interesting this essay \"Why explicit self has to stay\" by Guido van Rossum: ", "user_id": "None"}, {"stack_question_id": "2709821", "stack_question_comment_id": "2734210", "comment_content": "See also \"Why must 'self' be used explicitly in method definitions and calls\": ", "user_id": "None"}, {"stack_question_id": "2709821", "stack_question_comment_id": "2752890", "comment_content": "\"Which i understand, quite easily\" ---  Quite subjective, don't you think? What makes ", "user_id": "None"}, {"stack_question_id": "2709821", "stack_question_comment_id": "2752966", "comment_content": "Although to play devils advocate its very easy to forget to add an additional argument to each method and have bizarre behavior when you forget which makes it hard for beginners. IMHO I rather be specific about unusual things like static methods then normal behavior like instance methods.", "user_id": "None"}, {"stack_question_id": "2709821", "stack_question_comment_id": "11116129", "comment_content": "That's the key difference between a function and a class method. A function is floating free, unencumbered. A class (instance) method has to be aware of it's parent (and parent properties) so you need to pass the method a reference to the parent class (as ", "user_id": "None"}]},
{"stack_question_id": "29640685", "question_title": "How do I detect collision in pygame?", "question_content": "\r\n                I have made a list of bullets and a list of sprites using the classes below. How do I detect if a bullet collides with a sprite and then delete that sprite and the bullet?\n\n#Define the sprite class\n...\r\n", "question_url": "/questions/29640685/how-do-i-detect-collision-in-pygame", "date_posted": "Apr 15, 2015 at 2:38", "upvote": "2", "view": "9", "tags": ["python", "pygame", "collision-detection", "pygame-surface", "pygame2"], "answers_count": "5", "answers": [{"stack_answer_id": "65064907", "answer_content": "\r\n In PyGame, collision detection is done using  pygame.Rect  objects. The  Rect  object offers various methods for detecting collisions between objects. Even the collision between a rectangular and circular object such as a paddle and a ball can be detected by a collision between two rectangular objects, the paddle and the bounding rectangle of the ball. \n Some examples: \n \n pygame.Rect.collidepoint : \n \n Test if a point is inside a rectangle \n \n  repl.it/@Rabbid76/PyGame-collidepoint \n \n import pygame\n\npygame.init()\nwindow = pygame.display.set_mode((250, 250))\nrect = pygame.Rect(*window.get_rect().center, 0, 0).inflate(100, 100)\n\nrun = True\nwhile run:\n    for event in pygame.event.get():\n        if event.type == pygame.QUIT:\n            run = False\n\n    point = pygame.mouse.get_pos()\n    collide = rect.collidepoint(point)\n    color = (255, 0, 0) if collide else (255, 255, 255)\n\n    window.fill(0)\n    pygame.draw.rect(window, color, rect)\n    pygame.display.flip()\n\npygame.quit()\nexit()\n \n \n pygame.Rect.colliderect \n \n Test if two rectangles overlap \n \n See also  How to detect collisions between two rectangular objects or images in pygame \n  repl.it/@Rabbid76/PyGame-colliderect \n \n import pygame\n\npygame.init()\nwindow = pygame.display.set_mode((250, 250))\nrect1 = pygame.Rect(*window.get_rect().center, 0, 0).inflate(75, 75)\nrect2 = pygame.Rect(0, 0, 75, 75)\n\nrun = True\nwhile run:\n    for event in pygame.event.get():\n        if event.type == pygame.QUIT:\n            run = False\n\n    rect2.center = pygame.mouse.get_pos()\n    collide = rect1.colliderect(rect2)\n    color = (255, 0, 0) if collide else (255, 255, 255)\n\n    window.fill(0)\n    pygame.draw.rect(window, color, rect1)\n    pygame.draw.rect(window, (0, 255, 0), rect2, 6, 1)\n    pygame.display.flip()\n\npygame.quit()\nexit()\n \n \n \n Furthermore,  pygame.Rect.collidelist  and  pygame.Rect.collidelistall  can be used for the collision test between a rectangle and a list of rectangles.  pygame.Rect.collidedict  and  pygame.Rect.collidedictall  can be used for the collision test between a rectangle and a dictionary of rectangles. \n The collision of  pygame.sprite.Sprite  and  pygame.sprite.Group  objects, can be detected by  pygame.sprite.spritecollide() ,  pygame.sprite.groupcollide()  or  pygame.sprite.spritecollideany() . When using these methods, the collision detection algorithm can be specified by the  collided  argument: \n \n The collided argument is a callback function used to calculate if two sprites are colliding. \n \n Possible  collided  callables are  collide_rect ,  collide_rect_ratio ,  collide_circle ,  collide_circle_ratio ,  collide_mask \n Some examples: \n \n pygame.sprite.spritecollide() \n  repl.it/@Rabbid76/PyGame-spritecollide \n \n import pygame\n\npygame.init()\nwindow = pygame.display.set_mode((250, 250))\n\nsprite1 = pygame.sprite.Sprite()\nsprite1.image = pygame.Surface((75, 75))\nsprite1.image.fill((255, 0, 0))\nsprite1.rect = pygame.Rect(*window.get_rect().center, 0, 0).inflate(75, 75)\nsprite2 = pygame.sprite.Sprite()\nsprite2.image = pygame.Surface((75, 75))\nsprite2.image.fill((0, 255, 0))\nsprite2.rect = pygame.Rect(*window.get_rect().center, 0, 0).inflate(75, 75)\n\nall_group = pygame.sprite.Group([sprite2, sprite1])\ntest_group = pygame.sprite.Group(sprite2)\n\nrun = True\nwhile run:\n    for event in pygame.event.get():\n        if event.type == pygame.QUIT:\n            run = False\n\n    sprite1.rect.center = pygame.mouse.get_pos()\n    collide = pygame.sprite.spritecollide(sprite1, test_group, False)\n\n    window.fill(0)\n    all_group.draw(window)\n    for s in collide:\n        pygame.draw.rect(window, (255, 255, 255), s.rect, 5, 1)\n    pygame.display.flip()\n\npygame.quit()\nexit()\n \n \n \n For a collision with masks, see  How can I make a collision mask?  or  Pygame mask collision \n See also  Collision and Intersection \n \n pygame.sprite.spritecollide()  /  collide_circle \n  repl.it/@Rabbid76/PyGame-spritecollidecollidecircle \n \n import pygame\n\npygame.init()\nwindow = pygame.display.set_mode((250, 250))\n\nsprite1 = pygame.sprite.Sprite()\nsprite1.image = pygame.Surface((80, 80), pygame.SRCALPHA)\npygame.draw.circle(sprite1.image, (255, 0, 0), (40, 40), 40)\nsprite1.rect = pygame.Rect(*window.get_rect().center, 0, 0).inflate(40, 40)\nsprite2 = pygame.sprite.Sprite()\nsprite2.image = pygame.Surface((80, 89), pygame.SRCALPHA)\npygame.draw.circle(sprite2.image, (0, 255, 0), (40, 40), 40)\nsprite2.rect = pygame.Rect(*window.get_rect().center, 0, 0).inflate(80, 80)\n\nall_group = pygame.sprite.Group([sprite2, sprite1])\ntest_group = pygame.sprite.Group(sprite2)\n\nrun = True\nwhile run:\n    for event in pygame.event.get():\n        if event.type == pygame.QUIT:\n            run = False\n\n    sprite1.rect.center = pygame.mouse.get_pos()\n    collide = pygame.sprite.spritecollide(sprite1, test_group, False, pygame.sprite.collide_circle)\n\n    window.fill(0)\n    all_group.draw(window)\n    for s in collide:\n        pygame.draw.circle(window, (255, 255, 255), s.rect.center, s.rect.width // 2, 5)\n    pygame.display.flip()\n\npygame.quit()\nexit()\n \n \n \n \n What does this all mean for your code? \n pygame.Surface.get_rect.get_rect()  returns a rectangle with the size of the  Surface  object, that always starts at (0, 0) since a  Surface  object has no position. The position of the rectangle can be specified by a keyword argument. For example, the centre of the rectangle can be specified with the keyword argument  center . These keyword arguments are applied to the attributes of the  pygame.Rect  before it is returned (see  pygame.Rect  for a list of the keyword arguments). \nSee * Why is my collision test always returning 'true' and why is the position of the rectangle of the image always wrong (0, 0)? \n You do not need the  x  and  y  attributes of  Sprite  and  Bullet  at all. Use the position of the  rect  attribute instead: \n #Define the sprite class\nclass Sprite:\n    def __init__(self, x, y, name):\n        self.image = pygame.image.load(name)\n        self.rect = self.image.get_rect(topleft = (x, y))\n\n    def render(self):\n        window.blit(self.image, self.rect)\n\n# Define the bullet class to create bullets          \nclass Bullet:\n    def __init__(self, x, y):\n        self.bullet = pygame.image.load(\"user_bullet.BMP\")\n        self.rect = self.bullet.get_rect(topleft = (x + 23, y))\n\n    def render(self):\n        window.blit(self.bullet, self.rect)\n \n Use  pygame.Rect.colliderect()  to detect collisions between instances of  Sprite  and  Bullet . \nSee  How to detect collisions between two rectangular objects or images in pygame : \n my_sprite = Sprite(sx, sy, name)\nmy_bullet = Bullet(by, by)\n \n while True:\n    # [...]\n\n    if my_sprite.rect.colliderect(my_bullet.rect):\n        printe(\"hit\")\n \n    ", "date_posted": "2022-06-20 05:17:50Z", "upvote": "\r\n            64\r\n        ", "accepted": "No", "user": {"stack_user_id": "19372340", "name": "Joshua Rose", "reputation_score": "11"}, "answer_comments": []}, {"stack_answer_id": "29641464", "answer_content": "\r\n From what I understand of pygame you just need to check if the two rectangles overlap using the  colliderect  method. One way to do it is to have a method in your  Bullet  class that checks for collisions: \n\n def is_collided_with(self, sprite):\n    return self.rect.colliderect(sprite.rect)\n \n\n Then you can call it like: \n\n sprite = Sprite(10, 10, 'my_sprite')\nbullet = Bullet(20, 10)\nif bullet.is_collided_with(sprite):\n    print('collision!')\n    bullet.kill()\n    sprite.kill()\n \n    ", "date_posted": "2020-01-03 21:48:42Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "1470749", "name": "101", "reputation_score": "8,012"}, "answer_comments": [{"stack_answer_id": "29641464", "stack_answer_comment_id": "47424513", "comment_content": "Note that if the speed of bullet relative to the target is more than target's width per tick, the bullet can just 'teleport' to the other side of the target without hitting. If this might be the case, you might need to check against a rectangle that represents the trajectory of the bullet from the previous frame to the current frame, not just the bullet itself.", "user_id": "None"}]}, {"stack_answer_id": "40338475", "answer_content": "\r\n There is a very simple method for what you are trying to do using built in methods. \n\n here is an example. \n\n import pygame\nimport sys\n\nclass Sprite(pygame.sprite.Sprite):\n    def __init__(self, pos):\n        pygame.sprite.Sprite.__init__(self)\n        self.image = pygame.Surface([20, 20])\n        self.image.fill((255, 0, 0))\n        self.rect = self.image.get_rect()\n\n        self.rect.center = pos\n\ndef main():\n    pygame.init()\n    clock = pygame.time.Clock()\n    fps = 50\n    bg = [255, 255, 255]\n    size =[200, 200]\n\n\n    screen = pygame.display.set_mode(size)\n\n    player = Sprite([40, 50])\n    player.move = [pygame.K_LEFT, pygame.K_RIGHT, pygame.K_UP, pygame.K_DOWN]\n    player.vx = 5\n    player.vy = 5\n\n\n    wall = Sprite([100, 60])\n\n    wall_group = pygame.sprite.Group()\n    wall_group.add(wall)\n\n    player_group = pygame.sprite.Group()\n    player_group.add(player)\n\n    # I added loop for a better exit from the game\n    loop = 1\n    while loop:\n        for event in pygame.event.get():\n            if event.type == pygame.QUIT:\n                loop = 0\n\n        key = pygame.key.get_pressed()\n\n        for i in range(2):\n            if key[player.move[i]]:\n                player.rect.x += player.vx * [-1, 1][i]\n\n        for i in range(2):\n            if key[player.move[2:4][i]]:\n                player.rect.y += player.vy * [-1, 1][i]\n\n        screen.fill(bg)\n\n        # first parameter takes a single sprite\n        # second parameter takes sprite groups\n        # third parameter is a do kill command if true\n        # all group objects colliding with the first parameter object will be\n        # destroyed. The first parameter could be bullets and the second one\n        # targets although the bullet is not destroyed but can be done with\n        # simple trick bellow\n        hit = pygame.sprite.spritecollide(player, wall_group, True)\n\n        if hit:\n            # if collision is detected call a function in your case destroy\n            # bullet\n            player.image.fill((255, 255, 255))\n\n        player_group.draw(screen)\n        wall_group.draw(screen)\n\n        pygame.display.update()\n        clock.tick(fps)\n\n    pygame.quit()\n    # sys.exit\n\n\nif __name__ == '__main__':\n    main()\n \n    ", "date_posted": "2019-11-01 17:53:22Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "6464947", "name": "PythonProgrammi", "reputation_score": "20.8k"}, "answer_comments": []}, {"stack_answer_id": "56195193", "answer_content": "\r\n Make a group for the bullets, and then add the bullets to the group. \n\n What I would do is this:\nIn the class for the player: \n\n def collideWithBullet(self):\n    if pygame.sprite.spritecollideany(self, 'groupName'):\n        print(\"CollideWithBullet!!\")\n        return True\n \n\n And in the main loop somewhere:   \n\n def run(self):\n    if self.player.collideWithBullet():\n         print(\"Game Over\")\n \n\n Hopefully that works for you!!! \n    ", "date_posted": "2019-05-18 01:15:02Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "11483179", "name": "jaden.joeyak", "reputation_score": "91"}, "answer_comments": []}, {"stack_answer_id": "72277288", "answer_content": "\r\n Inside the Sprite class, try adding a  self.mask  attribute with \n self.mask = pygame.mask.from_surface(self.image) \nand a  collide_mask  function inside of the Sprite class with this code: \n     def collide_mask(self, mask):\n        collided = False\n        mask_outline = mask.outline()\n        self.mask_outline = self.mask.outline()\n        for point in range(len(mask_outline)):\n            mask_outline[point] = list(mask_outline[point])\n            mask_outline[point][0] += bullet.x\n            mask_outline[point][1] += bullet.y\n        for point in range(len(self.mask_outline)):\n            self.mask_outline[point] = list(mask_outline[point])\n            self.mask_outline[point][0] += self.x\n            self.mask_outline[point][1] += self.y\n        for point in mask_outline:\n            for self_mask_point in self.mask_outline:\n                if point = self_mask_point:\n                    collided = True\n        return collided\n \n    ", "date_posted": "2022-05-19 00:54:05Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "5014656", "name": "Soumendra", "reputation_score": "1,347"}, "answer_comments": []}], "user": {"stack_user_id": "4744250", "name": "Mike Schmidt", "reputation_score": "843"}, "question_comments": [{"stack_question_id": "29640685", "stack_question_comment_id": "47451199", "comment_content": "I would notes that there is a Sprite Class in pygame - I am not sure redefining it in your code is a good idea. Besides are they really targets (for want of a better word), as a sprite is simply an object with a graphical representation on screen (and therefore your Bullet is a sprite too).", "user_id": "None"}]},
{"stack_question_id": "19960077", "question_title": "How to filter Pandas dataframe using 'in' and 'not in' like in SQL", "question_content": "\r\n                How can I achieve the equivalents of SQL's IN and NOT IN?\nI have a list with the required values.\nHere's the scenario:\ndf = pd.DataFrame({'country': ['US', 'UK', 'Germany', 'China']})\n...\r\n", "question_url": "/questions/19960077/how-to-filter-pandas-dataframe-using-in-and-not-in-like-in-sql", "date_posted": "Nov 13, 2013 at 17:11", "upvote": "7", "view": "9", "tags": ["python", "pandas", "dataframe", "sql-function"], "answers_count": "1", "answers": [{"stack_answer_id": "19960116", "answer_content": "\r\n You can use  pd.Series.isin . \n For \"IN\" use:  something.isin(somewhere) \n Or for \"NOT IN\":  ~something.isin(somewhere) \n As a worked example: \n import pandas as pd\n\n>>> df\n  country\n0        US\n1        UK\n2   Germany\n3     China\n>>> countries_to_keep\n['UK', 'China']\n>>> df.country.isin(countries_to_keep)\n0    False\n1     True\n2    False\n3     True\nName: country, dtype: bool\n>>> df[df.country.isin(countries_to_keep)]\n  country\n1        UK\n3     China\n>>> df[~df.country.isin(countries_to_keep)]\n  country\n0        US\n2   Germany\n \n    ", "date_posted": "2020-07-09 19:25:24Z", "upvote": "\r\n            1300\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "12814639", "name": "gpr", "reputation_score": "106"}, "answer_comments": [{"stack_answer_id": "19960116", "stack_answer_comment_id": "29714037", "comment_content": "If you're actually dealing with 1-dimensional arrays (like in you're example) then on you're first line use a Series instead of a DataFrame, like @DSM used: ", "user_id": "None"}, {"stack_answer_id": "19960116", "stack_answer_comment_id": "29747942", "comment_content": "@TomAugspurger: like usual, I'm probably missing something.  ", "user_id": "None"}, {"stack_answer_id": "19960116", "stack_answer_comment_id": "87855266", "comment_content": "This answer is confusing because you keep reusing the ", "user_id": "None"}, {"stack_answer_id": "19960116", "stack_answer_comment_id": "108599103", "comment_content": "@ifly6 : Agreed, I made the same mistake and realized it when I got a error : \"'DataFrame' object has no attribute 'countries'", "user_id": "None"}, {"stack_answer_id": "19960116", "stack_answer_comment_id": "118083299", "comment_content": "For people who are confused by the tilde (like me): ", "user_id": "None"}]}, {"stack_answer_id": "45190397", "answer_content": "\r\n Alternative solution that uses  .query()  method: \n In [5]: df.query(\"countries in @countries_to_keep\")\nOut[5]:\n  countries\n1        UK\n3     China\n\nIn [6]: df.query(\"countries not in @countries_to_keep\")\nOut[6]:\n  countries\n0        US\n2   Germany\n \n    ", "date_posted": "2021-09-07 06:46:56Z", "upvote": "\r\n            133\r\n        ", "accepted": "No", "user": {"stack_user_id": "5741205", "name": "MaxU - stop genocide of UA", "reputation_score": "195k"}, "answer_comments": [{"stack_answer_id": "45190397", "stack_answer_comment_id": "112681283", "comment_content": ".query is so much more readable. Especially for the \"not in\" scenario, vs a distant tilde. Thanks!", "user_id": "None"}, {"stack_answer_id": "45190397", "stack_answer_comment_id": "122096421", "comment_content": "What is @countries ? Another dataframe ? A list ?", "user_id": "None"}, {"stack_answer_id": "45190397", "stack_answer_comment_id": "122127585", "comment_content": "@FlorianCastelain countries are the column you want to check on, OP called this column", "user_id": "None"}, {"stack_answer_id": "45190397", "stack_answer_comment_id": "122129378", "comment_content": "@FlorianCastelain, somebody has renamed a variable in the original question: ", "user_id": "None"}, {"stack_answer_id": "45190397", "stack_answer_comment_id": "124255455", "comment_content": "The most readable solution indeed. I wonder if syntax exists to avoid creating ", "user_id": "None"}]}, {"stack_answer_id": "55554709", "answer_content": "\r\n \n   How to implement 'in' and 'not in' for a pandas DataFrame? \n \n\n Pandas offers two methods:  Series.isin  and  DataFrame.isin  for Series and DataFrames, respectively. \n\n \n\n Filter DataFrame Based on ONE Column (also applies to Series) \n\n The most common scenario is applying an  isin  condition on a specific column to filter rows in a DataFrame. \n\n df = pd.DataFrame({'countries': ['US', 'UK', 'Germany', np.nan, 'China']})\ndf\n  countries\n0        US\n1        UK\n2   Germany\n3     China\n\nc1 = ['UK', 'China']             # list\nc2 = {'Germany'}                 # set\nc3 = pd.Series(['China', 'US'])  # Series\nc4 = np.array(['US', 'UK'])      # array\n \n\n \n\n Series.isin  accepts various types as inputs. The following are all valid ways of getting what you want: \n\n df['countries'].isin(c1)\n\n0    False\n1     True\n2    False\n3    False\n4     True\nName: countries, dtype: bool\n\n# `in` operation\ndf[df['countries'].isin(c1)]\n\n  countries\n1        UK\n4     China\n\n# `not in` operation\ndf[~df['countries'].isin(c1)]\n\n  countries\n0        US\n2   Germany\n3       NaN\n \n\n \n\n # Filter with `set` (tuples work too)\ndf[df['countries'].isin(c2)]\n\n  countries\n2   Germany\n \n\n \n\n # Filter with another Series\ndf[df['countries'].isin(c3)]\n\n  countries\n0        US\n4     China\n \n\n \n\n # Filter with array\ndf[df['countries'].isin(c4)]\n\n  countries\n0        US\n1        UK\n \n\n \n\n Filter on MANY Columns \n\n Sometimes, you will want to apply an 'in' membership check with some search terms over multiple columns, \n\n df2 = pd.DataFrame({\n    'A': ['x', 'y', 'z', 'q'], 'B': ['w', 'a', np.nan, 'x'], 'C': np.arange(4)})\ndf2\n\n   A    B  C\n0  x    w  0\n1  y    a  1\n2  z  NaN  2\n3  q    x  3\n\nc1 = ['x', 'w', 'p']\n \n\n To apply the  isin  condition to both columns \"A\" and \"B\", use  DataFrame.isin : \n\n df2[['A', 'B']].isin(c1)\n\n      A      B\n0   True   True\n1  False  False\n2  False  False\n3  False   True\n \n\n From this,  to retain rows where at least one column is  True , we can use  any  along the first axis: \n\n df2[['A', 'B']].isin(c1).any(axis=1)\n\n0     True\n1    False\n2    False\n3     True\ndtype: bool\n\ndf2[df2[['A', 'B']].isin(c1).any(axis=1)]\n\n   A  B  C\n0  x  w  0\n3  q  x  3\n \n\n Note that if you want to search every column, you'd just omit the column selection step and do  \n\n df2.isin(c1).any(axis=1)\n \n\n Similarly,  to retain rows where ALL columns are  True , use  all  in the same manner as before. \n\n df2[df2[['A', 'B']].isin(c1).all(axis=1)]\n\n   A  B  C\n0  x  w  0\n \n\n \n\n Notable Mentions:  numpy.isin ,  query , list comprehensions (string data) \n\n In addition to the methods described above, you can also use the numpy equivalent:  numpy.isin . \n\n # `in` operation\ndf[np.isin(df['countries'], c1)]\n\n  countries\n1        UK\n4     China\n\n# `not in` operation\ndf[np.isin(df['countries'], c1, invert=True)]\n\n  countries\n0        US\n2   Germany\n3       NaN\n \n\n Why is it worth considering? NumPy functions are usually a bit faster than their pandas equivalents because of lower overhead. Since this is an elementwise operation that does not depend on index alignment, there are very few situations where this method is not an appropriate replacement for pandas'  isin . \n\n Pandas routines are usually iterative when working with strings, because string operations are hard to vectorise.  There is a lot of evidence to suggest that list comprehensions will be faster here. .\nWe resort to an  in  check now.  \n\n c1_set = set(c1) # Using `in` with `sets` is a constant time operation... \n                 # This doesn't matter for pandas because the implementation differs.\n# `in` operation\ndf[[x in c1_set for x in df['countries']]]\n\n  countries\n1        UK\n4     China\n\n# `not in` operation\ndf[[x not in c1_set for x in df['countries']]]\n\n  countries\n0        US\n2   Germany\n3       NaN\n \n\n It is a lot more unwieldy to specify, however, so don't use it unless you know what you're doing. \n\n Lastly, there's also  DataFrame.query  which has been covered in  this answer . numexpr FTW! \n    ", "date_posted": "2019-06-06 20:48:21Z", "upvote": "\r\n            82\r\n        ", "accepted": "No", "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "answer_comments": [{"stack_answer_id": "55554709", "stack_answer_comment_id": "103289706", "comment_content": "I like it, but what if I want to compare a column in df3 that isin df1 column?  What would that look like?", "user_id": "None"}]}, {"stack_answer_id": "19960136", "answer_content": "\r\n I've been usually doing generic filtering over rows like this: \n\n criterion = lambda row: row['countries'] not in countries\nnot_in = df[df.apply(criterion, axis=1)]\n \n    ", "date_posted": "2013-11-13 17:14:32Z", "upvote": "\r\n            18\r\n        ", "accepted": "No", "user": {"stack_user_id": "399317", "name": "Kos", "reputation_score": "68.5k"}, "answer_comments": [{"stack_answer_id": "19960136", "stack_answer_comment_id": "29710214", "comment_content": "FYI, this is much slower than @DSM soln which is vectorized", "user_id": "None"}, {"stack_answer_id": "19960136", "stack_answer_comment_id": "29730160", "comment_content": "@Jeff I'd expect that, but that's what I fall back to when I need to filter over something unavailable in pandas directly. (I was about to say \"like .startwith or regex matching, but just found out about Series.str that has all of that!)", "user_id": "None"}]}, {"stack_answer_id": "56407969", "answer_content": "\r\n Collating possible solutions from the answers: \n\n For IN:  df[df['A'].isin([3, 6])] \n\n For NOT IN: \n\n \n df[-df[\"A\"].isin([3, 6])] \n df[~df[\"A\"].isin([3, 6])] \n df[df[\"A\"].isin([3, 6]) == False] \n df[np.logical_not(df[\"A\"].isin([3, 6]))] \n \n    ", "date_posted": "2019-06-02 02:47:13Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "answer_comments": [{"stack_answer_id": "56407969", "stack_answer_comment_id": "99414948", "comment_content": "This mostly repeats information from other answers. Using ", "user_id": "None"}]}, {"stack_answer_id": "45070797", "answer_content": "\r\n I wanted to filter out dfbc rows that had a BUSINESS_ID that was also in the BUSINESS_ID of dfProfilesBusIds \n\n dfbc = dfbc[~dfbc['BUSINESS_ID'].isin(dfProfilesBusIds['BUSINESS_ID'])]\n \n    ", "date_posted": "2019-05-19 03:26:27Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "answer_comments": [{"stack_answer_id": "45070797", "stack_answer_comment_id": "77347669", "comment_content": "You can negate the isin (as done in the accepted answer)  rather than comparing to False", "user_id": "None"}]}, {"stack_answer_id": "69195120", "answer_content": "\r\n Why is no one talking about the performance of various filtering methods? In fact, this topic often pops up here (see the example). I did my own performance test for a large data set. It is very interesting and instructive. \n df = pd.DataFrame({'animals': np.random.choice(['cat', 'dog', 'mouse', 'birds'], size=10**7), \n                   'number': np.random.randint(0,100, size=(10**7,))})\n\ndf.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 10000000 entries, 0 to 9999999\nData columns (total 2 columns):\n #   Column   Dtype \n---  ------   ----- \n 0   animals  object\n 1   number   int64 \ndtypes: int64(1), object(1)\nmemory usage: 152.6+ MB\n \n %%timeit\n# .isin() by one column\nconditions = ['cat', 'dog']\ndf[df.animals.isin(conditions)]\n \n 367 ms \u00b1 2.34 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n \n %%timeit\n# .query() by one column\nconditions = ['cat', 'dog']\ndf.query('animals in @conditions')\n \n 395 ms \u00b1 3.9 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n \n %%timeit\n# .loc[]\ndf.loc[(df.animals=='cat')|(df.animals=='dog')]\n \n 987 ms \u00b1 5.17 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n \n %%timeit\ndf[df.apply(lambda x: x['animals'] in ['cat', 'dog'], axis=1)]\n \n 41.9 s \u00b1 490 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n \n %%timeit\nnew_df = df.set_index('animals')\nnew_df.loc[['cat', 'dog'], :]\n \n 3.64 s \u00b1 62.5 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n \n %%timeit\nnew_df = df.set_index('animals')\nnew_df[new_df.index.isin(['cat', 'dog'])]\n \n 469 ms \u00b1 8.98 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n \n %%timeit\ns = pd.Series(['cat', 'dog'], name='animals')\ndf.merge(s, on='animals', how='inner')\n \n 796 ms \u00b1 30.9 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n \n Thus, the  isin  method turned out to be the fastest and the method with  apply()  was the slowest, which is not surprising. \n    ", "date_posted": "2021-09-15 14:33:28Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "16591526", "name": "padu", "reputation_score": "294"}, "answer_comments": []}, {"stack_answer_id": "71227998", "answer_content": "\r\n You can also use  .isin()  inside  .query() : \n df.query('country.isin(@countries_to_keep).values')\n\n# Or alternatively:\ndf.query('country.isin([\"UK\", \"China\"]).values')\n \n To negate your query, use  ~ : \n df.query('~country.isin(@countries_to_keep).values')\n \n \n Update: \n Another way is to use comparison operators: \n df.query('country == @countries_to_keep')\n\n# Or alternatively:\ndf.query('country == [\"UK\", \"China\"]')\n \n And to negate the query, use  != : \n df.query('country != @countries_to_keep')\n \n    ", "date_posted": "2022-06-21 18:48:02Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "18145256", "name": "rachwa", "reputation_score": "770"}, "answer_comments": [{"stack_answer_id": "71227998", "stack_answer_comment_id": "126028674", "comment_content": "Good to know, although this is a bit less readable than ", "user_id": "2071807"}]}, {"stack_answer_id": "49650285", "answer_content": "\r\n df = pd.DataFrame({'countries':['US','UK','Germany','China']})\ncountries = ['UK','China']\n \n\n implement in :     \n\n df[df.countries.isin(countries)]\n \n\n implement not in  as in of rest countries: \n\n df[df.countries.isin([x for x in np.unique(df.countries) if x not in countries])]\n \n    ", "date_posted": "2018-04-04 11:51:01Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "8563649", "name": "Ioannis Nasios", "reputation_score": "7,996"}, "answer_comments": []}, {"stack_answer_id": "63918237", "answer_content": "\r\n A trick if you want to keep the order of the list: \n df = pd.DataFrame({'country': ['US', 'UK', 'Germany', 'China']})\ncountries_to_keep = ['Germany', 'US']\n\n\nind=[df.index[df['country']==i].tolist() for i in countries_to_keep]\nflat_ind=[item for sublist in ind for item in sublist]\n\ndf.reindex(flat_ind)\n\n   country\n2  Germany\n0       US\n \n    ", "date_posted": "2020-09-16 10:38:18Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "7183444", "name": "Billy Bonaros", "reputation_score": "1,539"}, "answer_comments": []}, {"stack_answer_id": "68108690", "answer_content": "\r\n My 2c worth:\nI needed a combination of in and ifelse statements for a dataframe, and this worked for me. \n sale_method = pd.DataFrame(model_data[\"Sale Method\"].str.upper())\nsale_method[\"sale_classification\"] = np.where(\n    sale_method[\"Sale Method\"].isin([\"PRIVATE\"]),\n    \"private\",\n    np.where(\n        sale_method[\"Sale Method\"].str.contains(\"AUCTION\"), \"auction\", \"other\"\n    ),\n)\n \n    ", "date_posted": "2021-06-24 09:17:55Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "2071807", "name": "LondonRob", "reputation_score": "65.3k"}, "answer_comments": []}], "user": {"stack_user_id": "2071807", "name": "LondonRob", "reputation_score": "65.3k"}, "question_comments": [{"stack_question_id": "19960077", "stack_question_comment_id": "89135565", "comment_content": "Related (performance / pandas internals): ", "user_id": "None"}, {"stack_question_id": "19960077", "stack_question_comment_id": "115748356", "comment_content": " is similar, but the negation ", "user_id": "None"}]},
{"stack_question_id": "19913659", "question_title": "Pandas conditional creation of a series/dataframe column", "question_content": "\r\n                How do I add a color column to the following dataframe so that color='green' if Set\u00a0==\u00a0'Z', and color='red' otherwise?\n    Type       Set\n1    A          Z\n2    B          Z           \n3    B          ...\r\n", "question_url": "/questions/19913659/pandas-conditional-creation-of-a-series-dataframe-column", "date_posted": "Nov 11, 2013 at 18:52", "upvote": "4", "view": "7", "tags": ["python", "pandas", "numpy", "dataframe"], "answers_count": "1", "answers": [{"stack_answer_id": "19913845", "answer_content": "\r\n If you only have two choices to select from: \n\n df['color'] = np.where(df['Set']=='Z', 'green', 'red')\n \n\n For example, \n\n import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({'Type':list('ABBC'), 'Set':list('ZZXY')})\ndf['color'] = np.where(df['Set']=='Z', 'green', 'red')\nprint(df)\n \n\n yields \n\n   Set Type  color\n0   Z    A  green\n1   Z    B  green\n2   X    B    red\n3   Y    C    red\n \n\n \n\n If you have more than two conditions then use  np.select . For example, if you want  color  to be  \n\n \n yellow  when  (df['Set'] == 'Z') & (df['Type'] == 'A') \n otherwise  blue  when  (df['Set'] == 'Z') & (df['Type'] == 'B')   \n otherwise  purple  when  (df['Type'] == 'B') \n otherwise  black , \n \n\n then use \n\n df = pd.DataFrame({'Type':list('ABBC'), 'Set':list('ZZXY')})\nconditions = [\n    (df['Set'] == 'Z') & (df['Type'] == 'A'),\n    (df['Set'] == 'Z') & (df['Type'] == 'B'),\n    (df['Type'] == 'B')]\nchoices = ['yellow', 'blue', 'purple']\ndf['color'] = np.select(conditions, choices, default='black')\nprint(df)\n \n\n which yields \n\n   Set Type   color\n0   Z    A  yellow\n1   Z    B    blue\n2   X    B  purple\n3   Y    C   black\n \n    ", "date_posted": "2020-01-09 21:47:51Z", "upvote": "\r\n            965\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "answer_comments": [{"stack_answer_id": "19913845", "stack_answer_comment_id": "118100469", "comment_content": "what is the reason for having to use numpy?", "user_id": "None"}, {"stack_answer_id": "19913845", "stack_answer_comment_id": "120730869", "comment_content": "It's the library ", "user_id": "None"}, {"stack_answer_id": "19913845", "stack_answer_comment_id": "125065370", "comment_content": "This code now (January 2022) returns ", "user_id": "None"}, {"stack_answer_id": "19913845", "stack_answer_comment_id": "128376343", "comment_content": "@Luis , for your case, it's not related to the np.select function, but rather caused by how you assign new Series / DataFrame values.  And the message is simply a warning. Please check this out: ", "user_id": "None"}]}, {"stack_answer_id": "31173785", "answer_content": "\r\n List comprehension is another way to create another column conditionally. If you are working with object dtypes in columns, like in your example, list comprehensions typically outperform most other methods. \n\n Example list comprehension: \n\n df['color'] = ['red' if x == 'Z' else 'green' for x in df['Set']]\n \n\n %timeit tests: \n\n import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({'Type':list('ABBC'), 'Set':list('ZZXY')})\n%timeit df['color'] = ['red' if x == 'Z' else 'green' for x in df['Set']]\n%timeit df['color'] = np.where(df['Set']=='Z', 'green', 'red')\n%timeit df['color'] = df.Set.map( lambda x: 'red' if x == 'Z' else 'green')\n\n1000 loops, best of 3: 239 \u00b5s per loop\n1000 loops, best of 3: 523 \u00b5s per loop\n1000 loops, best of 3: 263 \u00b5s per loop\n \n    ", "date_posted": "2017-08-16 16:49:28Z", "upvote": "\r\n            167\r\n        ", "accepted": "No", "user": {"stack_user_id": "4561314", "name": "stackoverflowuser2010", "reputation_score": "35.2k"}, "answer_comments": [{"stack_answer_id": "31173785", "stack_answer_comment_id": "74103959", "comment_content": "Note that, with much larger dataframes (think ", "user_id": "None"}, {"stack_answer_id": "31173785", "stack_answer_comment_id": "94824690", "comment_content": "Can the list comprehension method be used if the condition needs information from multiple columns? I am looking for something like this (this does not work): ", "user_id": "None"}, {"stack_answer_id": "31173785", "stack_answer_comment_id": "95178560", "comment_content": "Add iterrows to the dataframe, then you can access multiple columns via row:  ['red' if (row['Set'] == 'Z') & (row['Type'] == 'B') else 'green' for index, row in in df.iterrows()]", "user_id": "None"}, {"stack_answer_id": "31173785", "stack_answer_comment_id": "102364666", "comment_content": "Note this nice solution will not work if you need to take replacement values from another series in the data frame, such as ", "user_id": "None"}, {"stack_answer_id": "31173785", "stack_answer_comment_id": "106373265", "comment_content": "@cheekybastard Or don't, since ", "user_id": "None"}]}, {"stack_answer_id": "24074316", "answer_content": "\r\n Another way in which this could be achieved is  \n\n df['color'] = df.Set.map( lambda x: 'red' if x == 'Z' else 'green')\n \n    ", "date_posted": "2014-06-06 04:43:52Z", "upvote": "\r\n            28\r\n        ", "accepted": "No", "user": {"stack_user_id": "678613", "name": "acharuva", "reputation_score": "665"}, "answer_comments": []}, {"stack_answer_id": "42113965", "answer_content": "\r\n The following is slower than the approaches timed  here , but we can compute the extra column based on the contents of more than one column, and more than two values can be computed for the extra column. \n\n Simple example using just the \"Set\" column: \n\n def set_color(row):\n    if row[\"Set\"] == \"Z\":\n        return \"red\"\n    else:\n        return \"green\"\n\ndf = df.assign(color=df.apply(set_color, axis=1))\n\nprint(df)\n \n\n   Set Type  color\n0   Z    A    red\n1   Z    B    red\n2   X    B  green\n3   Y    C  green\n \n\n Example with more colours and more columns taken into account: \n\n def set_color(row):\n    if row[\"Set\"] == \"Z\":\n        return \"red\"\n    elif row[\"Type\"] == \"C\":\n        return \"blue\"\n    else:\n        return \"green\"\n\ndf = df.assign(color=df.apply(set_color, axis=1))\n\nprint(df)\n \n\n   Set Type  color\n0   Z    A    red\n1   Z    B    red\n2   X    B  green\n3   Y    C   blue\n \n\n Edit (21/06/2019): Using plydata \n\n It is also possible to use  plydata  to do this kind of things (this seems even slower than using  assign  and  apply , though). \n\n from plydata import define, if_else\n \n\n Simple  if_else : \n\n df = define(df, color=if_else('Set==\"Z\"', '\"red\"', '\"green\"'))\n\nprint(df)\n \n\n   Set Type  color\n0   Z    A    red\n1   Z    B    red\n2   X    B  green\n3   Y    C  green\n \n\n Nested  if_else : \n\n df = define(df, color=if_else(\n    'Set==\"Z\"',\n    '\"red\"',\n    if_else('Type==\"C\"', '\"green\"', '\"blue\"')))\n\nprint(df)                            \n \n\n   Set Type  color\n0   Z    A    red\n1   Z    B    red\n2   X    B   blue\n3   Y    C  green\n \n    ", "date_posted": "2019-06-21 15:23:50Z", "upvote": "\r\n            26\r\n        ", "accepted": "No", "user": {"stack_user_id": "1878788", "name": "bli", "reputation_score": "6,866"}, "answer_comments": [{"stack_answer_id": "42113965", "stack_answer_comment_id": "115250012", "comment_content": "How do we refer to other rows with this type of function? eg. ", "user_id": "None"}, {"stack_answer_id": "42113965", "stack_answer_comment_id": "115271309", "comment_content": "@ChrisDixon As far as I know, ", "user_id": "None"}]}, {"stack_answer_id": "42260631", "answer_content": "\r\n Here's yet another way to skin this cat, using a dictionary to map new values onto the keys in the list: \n\n def map_values(row, values_dict):\n    return values_dict[row]\n\nvalues_dict = {'A': 1, 'B': 2, 'C': 3, 'D': 4}\n\ndf = pd.DataFrame({'INDICATOR': ['A', 'B', 'C', 'D'], 'VALUE': [10, 9, 8, 7]})\n\ndf['NEW_VALUE'] = df['INDICATOR'].apply(map_values, args = (values_dict,))\n \n\n What's it look like: \n\n df\nOut[2]: \n  INDICATOR  VALUE  NEW_VALUE\n0         A     10          1\n1         B      9          2\n2         C      8          3\n3         D      7          4\n \n\n This approach can be very powerful when you have many  ifelse -type statements to make (i.e. many unique values to replace). \n\n And of course you could always do this: \n\n df['NEW_VALUE'] = df['INDICATOR'].map(values_dict)\n \n\n But that approach is more than three times as slow as the  apply  approach from above, on my machine. \n\n And you could also do this, using  dict.get : \n\n df['NEW_VALUE'] = [values_dict.get(v, None) for v in df['INDICATOR']]\n \n    ", "date_posted": "2017-05-16 20:59:07Z", "upvote": "\r\n            25\r\n        ", "accepted": "No", "user": {"stack_user_id": "5015569", "name": "blacksite", "reputation_score": "11.3k"}, "answer_comments": [{"stack_answer_id": "42260631", "stack_answer_comment_id": "88914688", "comment_content": "I like this answer because it shows how to do multiple replacements of values", "user_id": "None"}, {"stack_answer_id": "42260631", "stack_answer_comment_id": "106373391", "comment_content": " How did you benchmark these? From my quick measurements, the ", "user_id": "None"}, {"stack_answer_id": "42260631", "stack_answer_comment_id": "106373539", "comment_content": "Update: On 100,000,000 rows, 52 string values, ", "user_id": "None"}]}, {"stack_answer_id": "55029355", "answer_content": "\r\n You can simply use the powerful  .loc  method and use one condition or several depending on your need (tested with pandas=1.0.5). \n Code Summary: \n df=pd.DataFrame(dict(Type='A B B C'.split(), Set='Z Z X Y'.split()))\ndf['Color'] = \"red\"\ndf.loc[(df['Set']==\"Z\"), 'Color'] = \"green\"\n\n#practice!\ndf.loc[(df['Set']==\"Z\")&(df['Type']==\"B\")|(df['Type']==\"C\"), 'Color'] = \"purple\"\n\n \n Explanation: \n df=pd.DataFrame(dict(Type='A B B C'.split(), Set='Z Z X Y'.split()))\n\n# df so far: \n  Type Set  \n0    A   Z \n1    B   Z \n2    B   X \n3    C   Y\n \n add a 'color' column and set all values to \"red\" \n df['Color'] = \"red\"\n \n Apply your single condition: \n df.loc[(df['Set']==\"Z\"), 'Color'] = \"green\"\n\n\n# df: \n  Type Set  Color\n0    A   Z  green\n1    B   Z  green\n2    B   X    red\n3    C   Y    red\n \n or multiple conditions if you want: \n df.loc[(df['Set']==\"Z\")&(df['Type']==\"B\")|(df['Type']==\"C\"), 'Color'] = \"purple\"\n \n You can read on Pandas logical operators and conditional selection here:\n Logical operators for boolean indexing in Pandas \n    ", "date_posted": "2021-01-31 07:17:13Z", "upvote": "\r\n            23\r\n        ", "accepted": "No", "user": {"stack_user_id": "10951905", "name": "Hossein Kalbasi", "reputation_score": "1,393"}, "answer_comments": []}, {"stack_answer_id": "65760879", "answer_content": "\r\n You can use pandas methods  where  and  mask : \n df['color'] = 'green'\ndf['color'] = df['color'].where(df['Set']=='Z', other='red')\n# Replace values where the condition is False\n \n or \n df['color'] = 'red'\ndf['color'] = df['color'].mask(df['Set']=='Z', other='green')\n# Replace values where the condition is True\n \n Alternatively, you can use the method  transform  with a lambda function: \n df['color'] = df['Set'].transform(lambda x: 'green' if x == 'Z' else 'red')\n \n Output: \n   Type Set  color\n1    A   Z  green\n2    B   Z  green\n3    B   X    red\n4    C   Y    red\n \n Performance comparison from @chai: \n import pandas as pd\nimport numpy as np\ndf = pd.DataFrame({'Type':list('ABBC')*1000000, 'Set':list('ZZXY')*1000000})\n \n%timeit df['color1'] = 'red'; df['color1'].where(df['Set']=='Z','green')\n%timeit df['color2'] = ['red' if x == 'Z' else 'green' for x in df['Set']]\n%timeit df['color3'] = np.where(df['Set']=='Z', 'red', 'green')\n%timeit df['color4'] = df.Set.map(lambda x: 'red' if x == 'Z' else 'green')\n\n397 ms \u00b1 101 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n976 ms \u00b1 241 ms per loop\n673 ms \u00b1 139 ms per loop\n796 ms \u00b1 182 ms per loop\n \n    ", "date_posted": "2021-12-28 14:25:49Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "8973620", "name": "Mykola Zotko", "reputation_score": "12.6k"}, "answer_comments": [{"stack_answer_id": "65760879", "stack_answer_comment_id": "124631526", "comment_content": "It is also faster: import pandas as pd import numpy as np df = pd.DataFrame({'Type':list('ABBC')*1000000, 'Set':list('ZZXY')*1000000}) %timeit df['color1'] = 'red'; df['color1'].where(df['Set']=='Z','green') %timeit df['color2'] = ['red' if x == 'Z' else 'green' for x in df['Set']] %timeit df['color3'] = np.where(df['Set']=='Z', 'red', 'green') %timeit df['color4'] = df.Set.map( lambda x: 'red' if x == 'Z' else 'green') 397 ms \u00b1 101 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) 976 ms \u00b1 241 ms per loop  673 ms \u00b1 139 ms per loop  796 ms \u00b1 182 ms per loop", "user_id": "None"}, {"stack_answer_id": "65760879", "stack_answer_comment_id": "124637064", "comment_content": "@chai added your evaluation to my answer. Thank you!", "user_id": "None"}]}, {"stack_answer_id": "68221846", "answer_content": "\r\n if you have only  2 choices , use  np.where() \n df = pd.DataFrame({'A':range(3)})\ndf['B'] = np.where(df.A>2, 'yes', 'no')\n \n if you have over  2 choices , maybe  apply()  could work\ninput \n arr = pd.DataFrame({'A':list('abc'), 'B':range(3), 'C':range(3,6), 'D':range(6, 9)})\n \n and arr is \n     A   B   C   D\n0   a   0   3   6\n1   b   1   4   7\n2   c   2   5   8\n \n if you want the column E tobe  if arr.A =='a' then arr.B elif arr.A=='b' then arr.C elif arr.A == 'c' then arr.D else something_else \n arr['E'] = arr.apply(lambda x: x['B'] if x['A']=='a' else(x['C'] if x['A']=='b' else(x['D'] if x['A']=='c' else 1234)), axis=1)\n \n and finally the arr is \n     A   B   C   D   E\n0   a   0   3   6   0\n1   b   1   4   7   4\n2   c   2   5   8   8\n \n    ", "date_posted": "2021-07-02 08:17:27Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "4821909", "name": "xiaotong xu", "reputation_score": "131"}, "answer_comments": []}, {"stack_answer_id": "58325311", "answer_content": "\r\n One liner with  .apply()  method is following: \n\n df['color'] = df['Set'].apply(lambda set_: 'green' if set_=='Z' else 'red')\n \n\n After that,  df  data frame looks like this: \n\n >>> print(df)\n  Type Set  color\n0    A   Z  green\n1    B   Z  green\n2    B   X    red\n3    C   Y    red\n \n    ", "date_posted": "2019-10-10 14:30:03Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "7122272", "name": "Jaroslav Bezd\u011bk", "reputation_score": "5,139"}, "answer_comments": []}, {"stack_answer_id": "59238705", "answer_content": "\r\n If you're working with massive data, a memoized approach would be best: \n\n # First create a dictionary of manually stored values\ncolor_dict = {'Z':'red'}\n\n# Second, build a dictionary of \"other\" values\ncolor_dict_other = {x:'green' for x in df['Set'].unique() if x not in color_dict.keys()}\n\n# Next, merge the two\ncolor_dict.update(color_dict_other)\n\n# Finally, map it to your column\ndf['color'] = df['Set'].map(color_dict)\n \n\n This approach will be fastest when you have many repeated values.  My general rule of thumb is to memoize when:  data_size  >  10**4  &  n_distinct  <  data_size/4   \n\n E.x. Memoize in a case 10,000 rows with 2,500 or fewer distinct values. \n    ", "date_posted": "2019-12-08 18:42:01Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "10521959", "name": "Yaakov Bressler", "reputation_score": "7,312"}, "answer_comments": [{"stack_answer_id": "59238705", "stack_answer_comment_id": "106373684", "comment_content": "Alright, so with only 2 distinct values to map, 100,000,000 rows, it takes 6.67 seconds to run without \"memoization\", and 9.86 seconds with.", "user_id": "None"}, {"stack_answer_id": "59238705", "stack_answer_comment_id": "106373894", "comment_content": "100,000,000 rows, 52 distinct values, where 1 of those maps to the first output value, and the other 51 all correspond to the other: 7.99 seconds without memoization, 11.1 seconds with.", "user_id": "None"}, {"stack_answer_id": "59238705", "stack_answer_comment_id": "106374783", "comment_content": "Are your values in random order? Or are they back to back? High speed of pandas could be due to caching @AMC", "user_id": "None"}, {"stack_answer_id": "59238705", "stack_answer_comment_id": "106404740", "comment_content": " Values are random, selected using ", "user_id": "None"}]}, {"stack_answer_id": "69613519", "answer_content": "\r\n The  case_when  function from  pyjanitor  is a wrapper around  pd.Series.mask  and offers a chainable/convenient form for multiple conditions: \n For a single condition: \n df.case_when(\n    df.col1 == \"Z\",  # condition\n    \"green\",         # value if True\n    \"red\",           # value if False\n    column_name = \"color\"\n    )\n\n  Type Set  color\n1    A   Z  green\n2    B   Z  green\n3    B   X    red\n4    C   Y    red\n \n For multiple conditions: \n df.case_when(\n    df.Set.eq('Z') & df.Type.eq('A'), 'yellow', # condition, result\n    df.Set.eq('Z') & df.Type.eq('B'), 'blue',   # condition, result\n    df.Type.eq('B'), 'purple',                  # condition, result\n    'black',              # default if none of the conditions evaluate to True\n    column_name = 'color'  \n)\n  Type  Set   color\n1    A   Z  yellow\n2    B   Z    blue\n3    B   X  purple\n4    C   Y   black\n \n More examples can be found  here \n    ", "date_posted": "2021-10-18 09:11:47Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "7175713", "name": "sammywemmy", "reputation_score": "23.6k"}, "answer_comments": []}, {"stack_answer_id": "71358186", "answer_content": "\r\n A Less verbose approach using  np.select : \n a = np.array([['A','Z'],['B','Z'],['B','X'],['C','Y']])\ndf = pd.DataFrame(a,columns=['Type','Set'])\n\nconditions = [\n    df['Set'] == 'Z'\n]\n\noutputs = [\n    'Green'\n    ]\n             # conditions Z is Green, Red Otherwise.\nres = np.select(conditions, outputs, 'Red')\nres \narray(['Green', 'Green', 'Red', 'Red'], dtype='<U5')\ndf.insert(2, 'new_column',res)    \n\ndf\n    Type    Set new_column\n0   A   Z   Green\n1   B   Z   Green\n2   B   X   Red\n3   C   Y   Red\n\ndf.to_numpy()    \n    \narray([['A', 'Z', 'Green'],\n       ['B', 'Z', 'Green'],\n       ['B', 'X', 'Red'],\n       ['C', 'Y', 'Red']], dtype=object)\n\n%%timeit conditions = [df['Set'] == 'Z'] \noutputs = ['Green'] \nnp.select(conditions, outputs, 'Red')\n\n134 \u00b5s \u00b1 9.71 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\n\ndf2 = pd.DataFrame({'Type':list('ABBC')*1000000, 'Set':list('ZZXY')*1000000})\n%%timeit conditions = [df2['Set'] == 'Z'] \noutputs = ['Green'] \nnp.select(conditions, outputs, 'Red')\n\n188 ms \u00b1 26.5 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n \n    ", "date_posted": "2022-03-04 23:16:57Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "9550633", "name": "rubengavidia0x", "reputation_score": "361"}, "answer_comments": []}], "user": {"stack_user_id": "213216", "name": "user7289", "reputation_score": "30.1k"}, "question_comments": []},
{"stack_question_id": "1894269", "question_title": "How to convert string representation of list to a list", "question_content": "\r\n                I was wondering what the simplest way is to convert a string representation of a list like the following to a list:\nx = '[ \"A\",\"B\",\"C\" , \" D\"]'\n\nEven in cases ...\r\n", "question_url": "/questions/1894269/how-to-convert-string-representation-of-list-to-a-list", "date_posted": "Dec 12, 2009 at 18:19", "upvote": "7", "view": "5", "tags": ["python", "string"], "answers_count": "1", "answers": [{"stack_answer_id": "1894296", "answer_content": "\r\n >>> import ast\n>>> x = '[ \"A\",\"B\",\"C\" , \" D\"]'\n>>> x = ast.literal_eval(x)\n>>> x\n['A', 'B', 'C', ' D']\n>>> x = [n.strip() for n in x]\n>>> x\n['A', 'B', 'C', 'D']\n \n ast.literal_eval : \n \n With  ast.literal_eval  you can safely evaluate an expression node or a string containing a Python literal or container display. The string or node provided may only consist of the following Python literal structures: strings, bytes, numbers, tuples, lists, dicts, booleans, and  None . \n \n    ", "date_posted": "2020-10-30 08:58:25Z", "upvote": "\r\n            1075\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": [{"stack_answer_id": "1894296", "stack_answer_comment_id": "81694867", "comment_content": "Per comment below, this is dangerous as it simply runs whatever python is in the string.  So if someone puts a call to delete everything in there, it happily will.", "user_id": "None"}, {"stack_answer_id": "1894296", "stack_answer_comment_id": "85749309", "comment_content": "@PaulKenjora: You're thinking of ", "user_id": "None"}, {"stack_answer_id": "1894296", "stack_answer_comment_id": "86141783", "comment_content": " is ", "user_id": "None"}, {"stack_answer_id": "1894296", "stack_answer_comment_id": "110342556", "comment_content": "@sqp_125, then it's a regular list, and you don't need to parse anything?", "user_id": "None"}, {"stack_answer_id": "1894296", "stack_answer_comment_id": "124170297", "comment_content": "The documentation states (in 2021):  \"This can be used for safely evaluating strings containing Python values from untrusted sources without the need to parse the values oneself. It is not capable of evaluating arbitrarily complex expressions, for example involving operators or indexing.\"", "user_id": "None"}]}, {"stack_answer_id": "35461204", "answer_content": "\r\n The  json  module is a better solution whenever there is a  stringified  list of dictionaries. The  json.loads(your_data)  function can be used to convert it to a list. \n >>> import json\n>>> x = '[ \"A\",\"B\",\"C\" , \" D\"]'\n>>> json.loads(x)\n['A', 'B', 'C', ' D']\n \n Similarly \n >>> x = '[ \"A\",\"B\",\"C\" , {\"D\":\"E\"}]'\n>>> json.loads(x)\n['A', 'B', 'C', {'D': 'E'}]\n \n    ", "date_posted": "2020-10-30 09:02:00Z", "upvote": "\r\n            205\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": [{"stack_answer_id": "35461204", "stack_answer_comment_id": "81694901", "comment_content": "This works for ints but not for strings in my case because each string is single quoted not double quoted, sigh.", "user_id": "None"}, {"stack_answer_id": "35461204", "stack_answer_comment_id": "99897185", "comment_content": "As per @PaulKenjora's comment, it works for ", "user_id": "None"}, {"stack_answer_id": "35461204", "stack_answer_comment_id": "115322875", "comment_content": "In my case I had to replace single quotes with double quotes in initial string to ensure it works ", "user_id": "None"}, {"stack_answer_id": "35461204", "stack_answer_comment_id": "124307845", "comment_content": "If user should only enter list of numeric, I think this is the safest way to go to stop malicious intend user.", "user_id": "None"}, {"stack_answer_id": "35461204", "stack_answer_comment_id": "129474567", "comment_content": "The ", "user_id": "None"}]}, {"stack_answer_id": "1894293", "answer_content": "\r\n The  eval  is dangerous - you shouldn't execute user input. \n\n If you have 2.6 or newer, use ast instead of eval: \n\n >>> import ast\n>>> ast.literal_eval('[\"A\",\"B\" ,\"C\" ,\" D\"]')\n[\"A\", \"B\", \"C\", \" D\"]\n \n\n Once you have that,  strip  the strings. \n\n If you're on an older version of Python, you can get very close to what you want with a simple regular expression: \n\n >>> x='[  \"A\",  \" B\", \"C\",\"D \"]'\n>>> re.findall(r'\"\\s*([^\"]*?)\\s*\"', x)\n['A', 'B', 'C', 'D']\n \n\n This isn't as good as the ast solution, for example it doesn't correctly handle escaped quotes in strings. But it's simple, doesn't involve a dangerous eval, and might be good enough for your purpose if you're on an older Python without ast. \n    ", "date_posted": "2009-12-12 20:21:43Z", "upvote": "\r\n            107\r\n        ", "accepted": "No", "user": {"stack_user_id": "61974", "name": "Mark Byers", "reputation_score": "777k"}, "answer_comments": [{"stack_answer_id": "1894293", "stack_answer_comment_id": "77239301", "comment_content": "Could you please tell me what why did you say \u201cThe ", "user_id": "None"}, {"stack_answer_id": "1894293", "stack_answer_comment_id": "79669145", "comment_content": "@AaryanDewan if you use ", "user_id": "None"}]}, {"stack_answer_id": "1894283", "answer_content": "\r\n There is a quick solution: \n\n x = eval('[ \"A\",\"B\",\"C\" , \" D\"]')\n \n\n Unwanted whitespaces in the list elements may be removed in this way: \n\n x = [x.strip() for x in eval('[ \"A\",\"B\",\"C\" , \" D\"]')]\n \n    ", "date_posted": "2009-12-12 18:24:11Z", "upvote": "\r\n            28\r\n        ", "accepted": "No", "user": {"stack_user_id": "213682", "name": "Alexei Sholik", "reputation_score": "7,063"}, "answer_comments": [{"stack_answer_id": "1894283", "stack_answer_comment_id": "1795912", "comment_content": "this would still preserve the spaces inside the quotes", "user_id": "None"}, {"stack_answer_id": "1894283", "stack_answer_comment_id": "1795920", "comment_content": "This is an open invitation to arbitrary code execution, NEVER do this or anything like it unless you know with absolute certainty that the input will always be 100% trusted.", "user_id": "None"}, {"stack_answer_id": "1894283", "stack_answer_comment_id": "59555410", "comment_content": "I could use this suggestion because I knew my data was always gonna be in that format and was a data processing work.", "user_id": "None"}]}, {"stack_answer_id": "55931430", "answer_content": "\r\n Inspired from some of the answers above that work with base python packages I compared the performance of a few (using Python 3.7.3): \n\n Method 1: ast \n\n import ast\nlist(map(str.strip, ast.literal_eval(u'[ \"A\",\"B\",\"C\" , \" D\"]')))\n# ['A', 'B', 'C', 'D']\n\nimport timeit\ntimeit.timeit(stmt=\"list(map(str.strip, ast.literal_eval(u'[ \\\"A\\\",\\\"B\\\",\\\"C\\\" , \\\" D\\\"]')))\", setup='import ast', number=100000)\n# 1.292875313000195\n \n\n Method 2: json \n\n import json\nlist(map(str.strip, json.loads(u'[ \"A\",\"B\",\"C\" , \" D\"]')))\n# ['A', 'B', 'C', 'D']\n\nimport timeit\ntimeit.timeit(stmt=\"list(map(str.strip, json.loads(u'[ \\\"A\\\",\\\"B\\\",\\\"C\\\" , \\\" D\\\"]')))\", setup='import json', number=100000)\n# 0.27833264000014424\n \n\n Method 3: no import \n\n list(map(str.strip, u'[ \"A\",\"B\",\"C\" , \" D\"]'.strip('][').replace('\"', '').split(',')))\n# ['A', 'B', 'C', 'D']\n\nimport timeit\ntimeit.timeit(stmt=\"list(map(str.strip, u'[ \\\"A\\\",\\\"B\\\",\\\"C\\\" , \\\" D\\\"]'.strip('][').replace('\\\"', '').split(',')))\", number=100000)\n# 0.12935059100027502\n \n\n I was disappointed to see what I considered the method with the worst readability was the method with the best performance... there are tradeoffs to consider when going with the most readable option... for the type of workloads I use python for I usually value readability over a slightly more performant option, but as usual it depends. \n    ", "date_posted": "2019-05-01 03:54:25Z", "upvote": "\r\n            24\r\n        ", "accepted": "No", "user": {"stack_user_id": "4277990", "name": "kinzleb", "reputation_score": "955"}, "answer_comments": [{"stack_answer_id": "55931430", "stack_answer_comment_id": "114797691", "comment_content": "is there any particular reason for there being a ", "user_id": "None"}, {"stack_answer_id": "55931430", "stack_answer_comment_id": "129474506", "comment_content": "The manual method is simply not as powerful, and does less work, so it's not surprising that it's faster. It will not handle escape sequences in the strings, or a different quote type. (The JSON method demands double-quotes, but does process escape sequences.) It also will only process a flat list of strings; the other approaches can handle complex nested data structures.", "user_id": "None"}]}, {"stack_answer_id": "1894292", "answer_content": "\r\n import ast\nl = ast.literal_eval('[ \"A\",\"B\",\"C\" , \" D\"]')\nl = [i.strip() for i in l]\n \n    ", "date_posted": "2009-12-12 18:29:02Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "403939", "name": "tosh", "reputation_score": "5,554"}, "answer_comments": []}, {"stack_answer_id": "52058605", "answer_content": "\r\n If it's only a one dimensional list, this can be done without importing anything: \n\n >>> x = u'[ \"A\",\"B\",\"C\" , \" D\"]'\n>>> ls = x.strip('[]').replace('\"', '').replace(' ', '').split(',')\n>>> ls\n['A', 'B', 'C', 'D']\n \n    ", "date_posted": "2020-03-19 15:58:33Z", "upvote": "\r\n            15\r\n        ", "accepted": "No", "user": {"stack_user_id": "9835872", "name": "ruohola", "reputation_score": "19.8k"}, "answer_comments": [{"stack_answer_id": "52058605", "stack_answer_comment_id": "92199807", "comment_content": "Cautionary note: this could potentially be dangerous if any of the strings inside list has a comma in between.", "user_id": "None"}, {"stack_answer_id": "52058605", "stack_answer_comment_id": "107501629", "comment_content": "This will not work if your string list is a list of lists", "user_id": "None"}]}, {"stack_answer_id": "70891720", "answer_content": "\r\n This u can do, \n ** \n x = '[ \"A\",\"B\",\"C\" , \" D\"]'\nprint(list(eval(x)))\n \n **\nbest one is the accepted answer \n Though this is not a safe way, the best answer is the accepted one.\nwasn't aware of the eval danger when answer was posted. \n    ", "date_posted": "2022-03-02 07:45:56Z", "upvote": "\r\n            10\r\n        ", "accepted": "No", "user": {"stack_user_id": "11863894", "name": "Tomato Master", "reputation_score": "416"}, "answer_comments": [{"stack_answer_id": "70891720", "stack_answer_comment_id": "125495153", "comment_content": "eval is not recommended in several places on this thread as it will simple run as code whatever is entered, presenting a security risk. it is also a duplicate answer.", "user_id": "None"}]}, {"stack_answer_id": "1894876", "answer_content": "\r\n Assuming that all your inputs are lists and that the double quotes in the input actually don't matter, this can be done with a simple regexp replace.  It is a bit perl-y but works like a charm.  Note also that the output is now a list of unicode strings, you didn't specify that you needed that, but it seems to make sense given unicode input. \n\n import re\nx = u'[ \"A\",\"B\",\"C\" , \" D\"]'\njunkers = re.compile('[[\" \\]]')\nresult = junkers.sub('', x).split(',')\nprint result\n--->  [u'A', u'B', u'C', u'D']\n \n\n The junkers variable contains a compiled regexp (for speed) of all characters we don't want, using ] as a character required some backslash trickery.\nThe re.sub replaces all these characters with nothing, and we split the resulting string at the commas.    \n\n Note that this also removes spaces from inside entries u'[\"oh no\"]' ---> [u'ohno'].  If this is not what you wanted, the regexp needs to be souped up a bit.   \n    ", "date_posted": "2009-12-12 22:18:37Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "230446", "name": "dirkjot", "reputation_score": "3,089"}, "answer_comments": []}, {"stack_answer_id": "68293376", "answer_content": "\r\n No need to import anything and no need evaluate. You can do this in one line for most basic use cases, including the one given in original question. \n One liner \n l_x = [i.strip() for i in x[1:-1].replace('\"',\"\").split(',')]\n \n Explanation \n x = '[ \"A\",\"B\",\"C\" , \" D\"]'\n# str indexing to eliminate the brackets\n# replace as split will otherwise retain the quotes in returned list\n# split to conv to list\nl_x = x[1:-1].replace('\"',\"\").split(',')\n \n Outputs : \n for i in range(0, len(l_x)):\n    print(l_x[i])\n# vvvv output vvvvv\n'''\n A\nB\nC \n  D\n'''\nprint(type(l_x)) # out: class 'list'\nprint(len(l_x)) # out: 4\n \n You can parse and clean up this list as needed using list comprehension. \n l_x = [i.strip() for i in l_x] # list comprehension to clean up\nfor i in range(0, len(l_x)):\n    print(l_x[i])\n# vvvvv output vvvvv\n'''\nA\nB\nC\nD\n'''\n \n Nested lists \n If you have nested lists, it does get a bit more annoying. Without using regex (which would simplify the replace), and assuming you want to return a flattened list (and the  zen of python says flat is better than nested ): \n x = '[ \"A\",\"B\",\"C\" , \" D\", [\"E\",\"F\",\"G\"]]'\nl_x = x[1:-1].split(',')\nl_x = [i\n    .replace(']', '')\n    .replace('[', '')\n    .replace('\"', '')\n    .strip() for i in l_x\n]\n# returns ['A', 'B', 'C', 'D', 'E', 'F', 'G']\n \n If you need to retain the nested list it gets a bit uglier, but can still be done just with re and list comprehension: \n import re\nx = '[ \"A\",\"B\",\"C\" , \" D\", \"[\"E\",\"F\",\"G\"]\",\"Z\", \"Y\", \"[\"H\",\"I\",\"J\"]\", \"K\", \"L\"]'\n# clean it up so regex is simpler\nx = x.replace('\"', '').replace(' ', '') \n# look ahead for the bracketed text that signifies nested list\nl_x = re.split(r',(?=\\[[A-Za-z0-9\\',]+\\])|(?<=\\]),', x[1:-1])\nprint(l_x)\n# flatten and split the non nested list items\nl_x0 = [item for items in l_x for item in items.split(',') if not '[' in items]\n# convert the nested lists to lists\nl_x1 = [\n    i[1:-1].split(',') for i in l_x if '[' in i \n]\n# add the two lists \nl_x = l_x0 + l_x1\n \n This last solution will work on any list stored as a string, nested or not. \n    ", "date_posted": "2021-07-07 22:07:51Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "12642339", "name": "born_naked", "reputation_score": "634"}, "answer_comments": [{"stack_answer_id": "68293376", "stack_answer_comment_id": "128067504", "comment_content": "Notice the method doesn't play well with empty lists. You take ", "user_id": "None"}]}, {"stack_answer_id": "1894785", "answer_content": "\r\n If you know that your lists only contain quoted strings, this pyparsing example will give you your list of stripped strings (even preserving the original Unicode-ness). \n >>> from pyparsing import *\n>>> x =u'[ \"A\",\"B\",\"C\" , \" D\"]'\n>>> LBR,RBR = map(Suppress,\"[]\")\n>>> qs = quotedString.setParseAction(removeQuotes, lambda t: t[0].strip())\n>>> qsList = LBR + delimitedList(qs) + RBR\n>>> print qsList.parseString(x).asList()\n[u'A', u'B', u'C', u'D']\n \n If your lists can have more datatypes, or even contain lists within lists, then you will need a more complete grammar - like  this one  in the pyparsing examples directory, which will handle tuples, lists, ints, floats, and quoted strings. \n    ", "date_posted": "2022-05-28 14:28:20Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "165216", "name": "PaulMcG", "reputation_score": "60.3k"}, "answer_comments": []}, {"stack_answer_id": "62050605", "answer_content": "\r\n You may run into such problem while dealing with scraped data stored as Pandas DataFrame. \n\n This solution works like charm if the  list of values is present as text .  \n\n def textToList(hashtags):\n    return hashtags.strip('[]').replace('\\'', '').replace(' ', '').split(',')\n\nhashtags = \"[ 'A','B','C' , ' D']\"\nhashtags = textToList(hashtags)\n\nOutput: ['A', 'B', 'C', 'D']\n \n\n \n   No external library required. \n \n    ", "date_posted": "2020-05-27 18:44:33Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "3888829", "name": "dobydx", "reputation_score": "57"}, "answer_comments": []}, {"stack_answer_id": "50063947", "answer_content": "\r\n To further complete @Ryan 's answer using json, one very convenient function to convert unicode is the one posted here:  https://stackoverflow.com/a/13105359/7599285 \n\n ex with double or single quotes: \n\n >print byteify(json.loads(u'[ \"A\",\"B\",\"C\" , \" D\"]')\n>print byteify(json.loads(u\"[ 'A','B','C' , ' D']\".replace('\\'','\"')))\n['A', 'B', 'C', ' D']\n['A', 'B', 'C', ' D']\n \n    ", "date_posted": "2018-04-27 13:56:02Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "7599285", "name": "CptHwK", "reputation_score": "105"}, "answer_comments": [{"stack_answer_id": "50063947", "stack_answer_comment_id": "129474559", "comment_content": "The only new information here is a further processing step that is ", "user_id": "None"}]}, {"stack_answer_id": "66908306", "answer_content": "\r\n This usually happens when you load list stored as string to CSV \n If you have your list stored in CSV in form like OP asked: \n x = '[ \"A\",\"B\",\"C\" , \" D\"]'\n \n Here is how you can load it back to list: \n import csv\nwith open('YourCSVFile.csv') as csv_file:\n    reader = csv.reader(csv_file, delimiter=',')\n    rows = list(reader)\n\nlistItems = rows[0]\n \n listItems  is now list \n    ", "date_posted": "2021-04-02 14:58:20Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "2119941", "name": "Hrvoje", "reputation_score": "11.1k"}, "answer_comments": [{"stack_answer_id": "66908306", "stack_answer_comment_id": "118291288", "comment_content": "Not sure how this is related to the question... ", "user_id": "None"}, {"stack_answer_id": "66908306", "stack_answer_comment_id": "118292398", "comment_content": "@Tomerikoo string representation of list is exactly the same only it's in the file.", "user_id": "None"}, {"stack_answer_id": "66908306", "stack_answer_comment_id": "118292450", "comment_content": "No. A string representation of a list is ", "user_id": "None"}, {"stack_answer_id": "66908306", "stack_answer_comment_id": "118292698", "comment_content": "@Tomerikoo how about you store list in file and than use any method here to restore it.", "user_id": "None"}, {"stack_answer_id": "66908306", "stack_answer_comment_id": "118292778", "comment_content": "Ok, let's say the csv has literally ", "user_id": "None"}]}, {"stack_answer_id": "50640336", "answer_content": "\r\n I would like to provide a more intuitive patterning solution with regex. \nThe below function takes as input a stringified list containing arbitrary strings.  \n\n Stepwise explanation: \nYou remove all whitespacing,bracketing and value_separators (provided they are not part of the values you want to extract, else make the regex more complex). Then you split the cleaned string on single or double quotes and take the non-empty values (or odd indexed values, whatever the preference).  \n\n def parse_strlist(sl):\nimport re\nclean = re.sub(\"[\\[\\],\\s]\",\"\",sl)\nsplitted = re.split(\"[\\'\\\"]\",clean)\nvalues_only = [s for s in splitted if s != '']\nreturn values_only\n \n\n testsample : \"['21',\"foo\" '6', '0', \" A\"]\" \n    ", "date_posted": "2018-06-01 09:32:00Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "7141994", "name": "Jordy Van Landeghem", "reputation_score": "19"}, "answer_comments": []}, {"stack_answer_id": "54101165", "answer_content": "\r\n you can save yourself the .strip() fcn by just slicing off the first and last characters from the string representation of the list (see third line below) \n\n >>> mylist=[1,2,3,4,5,'baloney','alfalfa']\n>>> strlist=str(mylist)\n['1', ' 2', ' 3', ' 4', ' 5', \" 'baloney'\", \" 'alfalfa'\"]\n>>> mylistfromstring=(strlist[1:-1].split(', '))\n>>> mylistfromstring[3]\n'4'\n>>> for entry in mylistfromstring:\n...     print(entry)\n...     type(entry)\n... \n1\n<class 'str'>\n2\n<class 'str'>\n3\n<class 'str'>\n4\n<class 'str'>\n5\n<class 'str'>\n'baloney'\n<class 'str'>\n'alfalfa'\n<class 'str'>\n \n    ", "date_posted": "2019-01-08 23:24:24Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "6470375", "name": "JCMontalbano", "reputation_score": "69"}, "answer_comments": []}, {"stack_answer_id": "57186365", "answer_content": "\r\n and with pure python - not importing any libraries \n\n [x for x in  x.split('[')[1].split(']')[0].split('\"')[1:-1] if x not in[',',' , ',', ']]\n \n    ", "date_posted": "2019-07-26 08:40:47Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "8563649", "name": "Ioannis Nasios", "reputation_score": "7,996"}, "answer_comments": []}, {"stack_answer_id": "69755095", "answer_content": "\r\n This solution is simpler than some I read above but requires to match all features of the list \n x = '[ \"A\",\"B\",\"C\" , \" D\"]'\n[i.strip() for i in x.split('\"') if len(i.strip().strip(',').strip(']').strip('['))>0]\n \n \n \n ['A', 'B', 'C', 'D'] \n \n \n    ", "date_posted": "2021-10-28 13:35:18Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "11955928", "name": "CassAndr", "reputation_score": "13"}, "answer_comments": []}, {"stack_answer_id": "51705980", "answer_content": "\r\n So, following all the answers I decided to time the most common methods: \n\n from time import time\nimport re\nimport json\n\n\nmy_str = str(list(range(19)))\nprint(my_str)\n\nreps = 100000\n\nstart = time()\nfor i in range(0, reps):\n    re.findall(\"\\w+\", my_str)\nprint(\"Regex method:\\t\", (time() - start) / reps)\n\nstart = time()\nfor i in range(0, reps):\n    json.loads(my_str)\nprint(\"json method:\\t\", (time() - start) / reps)\n\nstart = time()\nfor i in range(0, reps):\n    ast.literal_eval(my_str)\nprint(\"ast method:\\t\\t\", (time() - start) / reps)\n\nstart = time()\nfor i in range(0, reps):\n    [n.strip() for n in my_str]\nprint(\"strip method:\\t\", (time() - start) / reps)\n\n\n\n    regex method:    6.391477584838867e-07\n    json method:     2.535374164581299e-06\n    ast method:      2.4425282478332518e-05\n    strip method:    4.983267784118653e-06\n \n\n So in the end regex wins! \n    ", "date_posted": "2018-08-06 11:12:47Z", "upvote": "\r\n            -1\r\n        ", "accepted": "No", "user": {"stack_user_id": "9224152", "name": "passs", "reputation_score": "43"}, "answer_comments": []}], "user": {"stack_user_id": "65424", "name": "harijay", "reputation_score": "10.4k"}, "question_comments": []},
{"stack_question_id": "16424091", "question_title": "Why does Tkinter image not show up if created in a function?", "question_content": "\r\n                This code works:\n\nimport tkinter\n\nroot = tkinter.Tk()\ncanvas = tkinter.Canvas(root)\ncanvas.grid(row = 0, column = 0)\nphoto = tkinter.PhotoImage(file = './test.gif')\ncanvas.create_image(0, 0, image=...\r\n", "question_url": "/questions/16424091/why-does-tkinter-image-not-show-up-if-created-in-a-function", "date_posted": "May 7, 2013 at 16:30", "upvote": "7", "view": "8", "tags": ["python", "image", "tkinter", "tkinter-canvas"], "answers_count": "4", "answers": [{"stack_answer_id": "16424553", "answer_content": "\r\n The variable  photo  is a local variable which gets garbage collected after the class is instantiated. Save a reference to the photo, for example: \n self.photo = tkinter.PhotoImage(...)\n \n If you do a Google search on \"tkinter image doesn't display\", the first result is this: \n Why do my Tkinter images not appear?  (The FAQ answer is currently  not  outdated) \n    ", "date_posted": "2021-03-15 16:50:04Z", "upvote": "\r\n            106\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "355230", "name": "martineau", "reputation_score": "115k"}, "answer_comments": [{"stack_answer_id": "16424553", "stack_answer_comment_id": "115733354", "comment_content": "Wow. Do they consider this a bug in tkinter? They should.", "user_id": "None"}, {"stack_answer_id": "16424553", "stack_answer_comment_id": "117806780", "comment_content": "@TamasHegedus: I agree it's bug, but apparently not one that anyone has ever bothered to fix after (currently) nearly two decades. Have lost count how many times I see a question regarding to it still pops up.", "user_id": "None"}, {"stack_answer_id": "16424553", "stack_answer_comment_id": "129582113", "comment_content": "@Enderman: a reference needs to be kept by something, somewhere.", "user_id": "None"}, {"stack_answer_id": "16424553", "stack_answer_comment_id": "129587214", "comment_content": "@Enderman: no, because it's referencing itself. An object needs an external reference to it or the garbage collector might destroy it.", "user_id": "None"}, {"stack_answer_id": "16424553", "stack_answer_comment_id": "129588131", "comment_content": "@Enderman: no. You need to save a reference to the instance of the class.", "user_id": "None"}]}, {"stack_answer_id": "63599265", "answer_content": "\r\n from tkinter import *\nfrom PIL import ImageTk, Image\n\nroot = Tk()\n\ndef open_img():\n    global img\n    path = r\"C:\\.....\\\\\"\n    img = ImageTk.PhotoImage(Image.open(path))\n    panel = Label(root, image=img)\n    panel.pack(side=\"bottom\", fill=\"both\")\nbut1 = Button(root, text=\"click to get the image\", command=open_img)\nbut1.pack()\nroot.mainloop() \n \n \n Just add global to the img definition and it will work \n \n    ", "date_posted": "2020-08-26 13:57:15Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "9769923", "name": "TIRTH SHAH", "reputation_score": "79"}, "answer_comments": [{"stack_answer_id": "63599265", "stack_answer_comment_id": "124847517", "comment_content": "This answer is fine for a program that just uses functions, but if, as in the OP's case, you use a class, than ", "user_id": "None"}]}, {"stack_answer_id": "71502573", "answer_content": "\r\n The problem is Python automatically deletes the references to the variable by a process known as  Garbage Collection . The solution is to save the reference or to create a new reference. \n The following are the ways: \n \n Using  self  to increase the reference count and to save the reference. \n \n import tkinter\n\nclass Test:\n    def __init__(self, master):\n        canvas = tkinter.Canvas(master)\n        canvas.grid(row = 0, column = 0)\n        self.photo = tkinter.PhotoImage(file = './test.gif') # Changes here\n        canvas.create_image(0, 0, image=self.photo) # Changes here\n\nroot = tkinter.Tk()\ntest = Test(root)\nroot.mainloop()\n \n \n Saving it to a list to increase the reference count and to save the reference. \n \n import tkinter\nl=[]\nclass Test:\n\n    def __init__(self, master):\n        canvas = tkinter.Canvas(master)\n        canvas.grid(row = 0, column = 0)\n        photo = tkinter.PhotoImage(file = './test.gif')\n        l.append(photo)\n        canvas.create_image(0, 0, image=photo)\n\nroot = tkinter.Tk()\ntest = Test(root)\nroot.mainloop()\n \n While using method 2, you can either make a global list as i did or use list inside the class. Both would work. \n Some useful links: \n \n About Garbage Collection 1 \n About Garbage Collection 2 ( More useful ) \n \n    ", "date_posted": "2022-03-16 19:03:59Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "16187613", "name": "Faraaz Kurawle", "reputation_score": "945"}, "answer_comments": []}, {"stack_answer_id": "54936405", "answer_content": "\r\n Just add  global photo  as the first line inside the function. \n    ", "date_posted": "2019-03-01 00:45:49Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "6451750", "name": "Gabriel", "reputation_score": "37"}, "answer_comments": [{"stack_answer_id": "54936405", "stack_answer_comment_id": "99917567", "comment_content": "And then you create a 2nd ", "user_id": "None"}, {"stack_answer_id": "54936405", "stack_answer_comment_id": "123329075", "comment_content": "There is definitely no no need to use ", "user_id": "None"}]}], "user": {"stack_user_id": "1554934", "name": "thomas.winckell", "reputation_score": "1,107"}, "question_comments": [{"stack_question_id": "16424091", "stack_question_comment_id": "116648223", "comment_content": " is down. The gist of it is that the image is passed by reference. If the reference is to a local variable, the memory referenced gets reused and the reference becomes stale. The variable storing the image should be in the same scope (has to have the same lifetime) as the Tk gui object it appears on.", "user_id": "None"}, {"stack_question_id": "16424091", "stack_question_comment_id": "122756541", "comment_content": "@maszoka: ", "user_id": "None"}, {"stack_question_id": "16424091", "stack_question_comment_id": "125991644", "comment_content": "Also note that the same problem can appear anywhere temporary ", "user_id": "None"}]},
{"stack_question_id": "49775502", "question_title": "WebDriverWait not working as expected", "question_content": "\r\n                I am working with selenium to scrape some data.\n\nThere is button on the page that I am clicking say \"custom_cols\". This button opens up a window for me where I can select my columns. \n\nThis new window ...\r\n", "question_url": "/questions/49775502/webdriverwait-not-working-as-expected", "date_posted": "Apr 11, 2018 at 12:43", "upvote": "1", "view": "1", "tags": ["python", "selenium", "web-scraping", "webdriverwait", "expected-condition"], "answers_count": "1", "answers": [{"stack_answer_id": "49775808", "answer_content": "\r\n Once you wait for the element and moving forward as you are trying to invoke  click()  method instead of using  presence_of_element_located()  method you need to use  element_to_be_clickable()  as follows : \n\n try:\n    myElem = WebDriverWait(self.browser, delay).until(EC.element_to_be_clickable((By.XPATH , xpath)))\n \n\n \n\n Update \n\n As per your counter question in the comments here are the details of the three methods : \n\n presence_of_element_located \n\n presence_of_element_located(locator)  is defined as follows : \n\n class selenium.webdriver.support.expected_conditions.presence_of_element_located(locator)\n\nParameter : locator - used to find the element returns the WebElement once it is located\n\nDescription : An expectation for checking that an element is present on the DOM of a page. This does not necessarily mean that the element is visible or interactable (i.e. clickable). \n \n\n visibility_of_element_located \n\n visibility_of_element_located(locator)  is defined as follows : \n\n class selenium.webdriver.support.expected_conditions.visibility_of_element_located(locator)\n\nParameter : locator -  used to find the element returns the WebElement once it is located and visible\n\nDescription : An expectation for checking that an element is present on the DOM of a page and visible. Visibility means that the element is not only displayed but also has a height and width that is greater than 0.\n \n\n element_to_be_clickable \n\n element_to_be_clickable(locator)  is defined as follows : \n\n class selenium.webdriver.support.expected_conditions.element_to_be_clickable(locator)\n\nParameter : locator - used to find the element returns the WebElement once it is visible, enabled and interactable (i.e. clickable).\n\nDescription : An Expectation for checking an element is visible, enabled and interactable such that you can click it. \n \n    ", "date_posted": "2018-10-02 11:32:14Z", "upvote": "\r\n            12\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "7429447", "name": "undetected Selenium", "reputation_score": "160k"}, "answer_comments": [{"stack_answer_id": "49775808", "stack_answer_comment_id": "86567318", "comment_content": "Can you please explain why it works but other function not.", "user_id": "6770735"}, {"stack_answer_id": "49775808", "stack_answer_comment_id": "123680315", "comment_content": " definitely helped, but I still had situations where ", "user_id": "None"}]}], "user": {"stack_user_id": "6770735", "name": "Rao Sahab", "reputation_score": "971"}, "question_comments": [{"stack_question_id": "49775502", "stack_question_comment_id": "123680419", "comment_content": "Just a comment that the 2nd argument for ", "user_id": "None"}]},
{"stack_question_id": "16476924", "question_title": "How to iterate over rows in a DataFrame in Pandas", "question_content": "\r\n                I have a pandas dataframe, df:\n   c1   c2\n0  10  100\n1  11  110\n2  12  120\n\nHow do I iterate over the rows of this dataframe? For every row, I want to be able to access its elements (values in cells) ...\r\n", "question_url": "/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas", "date_posted": "May 10, 2013 at 7:04", "upvote": "3", "view": "5", "tags": ["python", "pandas", "dataframe"], "answers_count": "3", "answers": [{"stack_answer_id": "16476974", "answer_content": "\r\n DataFrame.iterrows  is a generator which yields both the index and row (as a Series): \n import pandas as pd\n\ndf = pd.DataFrame({'c1': [10, 11, 12], 'c2': [100, 110, 120]})\ndf = df.reset_index()  # make sure indexes pair with number of rows\n\nfor index, row in df.iterrows():\n    print(row['c1'], row['c2'])\n \n\n 10 100\n11 110\n12 120\n \n    ", "date_posted": "2022-06-06 03:16:21Z", "upvote": "\r\n            4654\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": [{"stack_answer_id": "16476974", "stack_answer_comment_id": "69252004", "comment_content": "Note: \"Because iterrows returns a Series for each row, it ", "user_id": "None"}, {"stack_answer_id": "16476974", "stack_answer_comment_id": "79079467", "comment_content": "@viddik13 that's a great note thanks. Because of that I ran into a case where numerical values like ", "user_id": "None"}, {"stack_answer_id": "16476974", "stack_answer_comment_id": "79152689", "comment_content": "@AzizAlto use ", "user_id": "None"}, {"stack_answer_id": "16476974", "stack_answer_comment_id": "82152649", "comment_content": "Do not use iterrows. Itertuples is faster and preserves data type. ", "user_id": "None"}, {"stack_answer_id": "16476974", "stack_answer_comment_id": "99276519", "comment_content": "From ", "user_id": "None"}]}, {"stack_answer_id": "55557758", "answer_content": "\r\n \n How to iterate over rows in a DataFrame in Pandas? \n \n Answer: DON'T * ! \n Iteration in Pandas is an anti-pattern and is something you should only do when you have exhausted every other option. You should not use any function with \" iter \" in its name for more than a few thousand rows or you will have to get used to a  lot  of waiting. \n Do you want to print a DataFrame? Use  DataFrame.to_string() . \n Do you want to compute something? In that case, search for methods in this order (list modified from  here ): \n \n Vectorization \n Cython  routines \n List Comprehensions (vanilla  for  loop) \n DataFrame.apply() : i) \u00a0Reductions that can be performed in Cython, ii) Iteration in Python space \n DataFrame.itertuples()  and  iteritems() \n DataFrame.iterrows() \n \n iterrows  and  itertuples  (both receiving many votes in answers to this question) should be used in very rare circumstances, such as generating row objects/nametuples for sequential processing, which is really the only thing these functions are useful for. \n Appeal to Authority \n The documentation page  on iteration has a huge red warning box that says: \n \n Iterating through pandas objects is generally slow. In many cases, iterating manually over the rows is not needed [...]. \n \n * It's actually a little more complicated than \"don't\".  df.iterrows()  is the correct answer to this question, but \"vectorize your ops\" is the better one. I will concede that there are circumstances where iteration cannot be avoided (for example, some operations where the result depends on the value computed for the previous row). However, it takes some familiarity with the library to know when. If you're not sure whether you need an iterative solution, you probably don't. PS: To know more about my rationale for writing this answer, skip to the very bottom. \n \n Faster than Looping:  Vectorization ,  Cython \n A good number of basic operations and computations are \"vectorised\" by pandas (either through NumPy, or through Cythonized functions). This includes arithmetic, comparisons, (most) reductions, reshaping (such as pivoting), joins, and groupby operations. Look through the documentation on  Essential Basic Functionality  to find a suitable vectorised method for your problem. \n If none exists, feel free to write your own using custom  Cython extensions . \n \n Next Best Thing:  List Comprehensions * \n List comprehensions should be your next port of call if 1) there is no vectorized solution available, 2) performance is important, but not important enough to go through the hassle of cythonizing your code, and 3) you're trying to perform elementwise transformation on your code. There is a  good amount of evidence  to suggest that list comprehensions are sufficiently fast (and even sometimes faster) for many common Pandas tasks. \n The formula is simple, \n # Iterating over one column - `f` is some function that processes your data\nresult = [f(x) for x in df['col']]\n# Iterating over two columns, use `zip`\nresult = [f(x, y) for x, y in zip(df['col1'], df['col2'])]\n# Iterating over multiple columns - same data type\nresult = [f(row[0], ..., row[n]) for row in df[['col1', ...,'coln']].to_numpy()]\n# Iterating over multiple columns - differing data type\nresult = [f(row[0], ..., row[n]) for row in zip(df['col1'], ..., df['coln'])]\n \n If you can encapsulate your business logic into a function, you can use a list comprehension that calls it. You can make arbitrarily complex things work through the simplicity and speed of raw Python code. \n Caveats \n List comprehensions assume that your data is easy to work with - what that means is your data types are consistent and you don't have NaNs, but this cannot always be guaranteed. \n \n The first one is more obvious, but when dealing with NaNs, prefer in-built pandas methods if they exist (because they have much better corner-case handling logic), or ensure your business logic includes appropriate NaN handling logic. \n When dealing with mixed data types you should iterate over  zip(df['A'], df['B'], ...)  instead of  df[['A', 'B']].to_numpy()  as the latter implicitly upcasts data to the most common type. As an example if A is numeric and B is string,  to_numpy()  will cast the entire array to string, which may not be what you want. Fortunately  zip ping your columns together is the most straightforward workaround to this. \n \n *Your mileage may vary for the reasons outlined in the  Caveats  section above. \n \n An Obvious Example \n Let's demonstrate the difference with a simple example of adding two pandas columns  A + B . This is a vectorizable operaton, so it will be easy to contrast the performance of the methods discussed above. \n \n Benchmarking code, for your reference . The line at the bottom measures a function written in numpandas, a style of Pandas that mixes heavily with NumPy to squeeze out maximum performance. Writing numpandas code should be avoided unless you know what you're doing. Stick to the API where you can (i.e., prefer  vec  over  vec_numpy ). \n I should mention, however, that it isn't always this cut and dry. Sometimes the answer to \"what is the best method for an operation\" is \"it depends on your data\". My advice is to test out different approaches on your data before settling on one. \n \n My Personal Opinion  * \n Most of the analyses performed on the various alternatives to the iter family has been through the lens of performance. However, in most situations you will typically be working on a reasonably sized dataset (nothing beyond a few thousand or 100K rows) and performance will come second to simplicity/readability of the solution. \n Here is my personal preference when selecting a method to use for a problem. \n For the novice: \n \n Vectorization  (when possible) ;  apply() ; List Comprehensions;  itertuples() / iteritems() ;  iterrows() ; Cython \n \n For the more experienced: \n \n Vectorization  (when possible) ;  apply() ; List Comprehensions; Cython;  itertuples() / iteritems() ;  iterrows() \n \n Vectorization prevails as the most idiomatic method for any problem that can be vectorized. Always seek to vectorize! When in doubt, consult the docs, or look on Stack Overflow for an existing question on your particular task. \n I do tend to go on about how bad  apply  is in a lot of my posts, but I do concede it is easier for a beginner to wrap their head around what it's doing. Additionally, there are quite a few use cases for  apply  has explained in  this post of mine . \n Cython ranks lower down on the list because it takes more time and effort to pull off correctly. You will usually never need to write code with pandas that demands this level of performance that even a list comprehension cannot satisfy. \n * As with any personal opinion, please take with heaps of salt! \n \n Further Reading \n \n 10 Minutes to pandas , and  Essential Basic Functionality  - Useful links that introduce you to Pandas and its library of vectorized*/cythonized functions. \n \n Enhancing Performance  - A primer from the documentation on enhancing standard Pandas operations \n \n Are for-loops in pandas really bad? When should I care?  - a detailed writeup by me on list comprehensions and their suitability for various operations (mainly ones involving non-numeric data) \n \n When should I (not) want to use pandas apply() in my code?  -  apply  is slow (but not as slow as the  iter*  family. There are, however, situations where one can (or should) consider  apply  as a serious alternative, especially in some  GroupBy  operations). \n \n \n * Pandas string methods are \"vectorized\" in the sense that they are specified on the series but operate on each element. The underlying mechanisms are still iterative, because string operations are inherently hard to vectorize. \n \n Why I Wrote this Answer \n A common trend I notice from new users is to ask questions of the form \"How can I iterate over my df to do X?\". Showing code that calls  iterrows()  while doing something inside a  for  loop. Here is why. A new user to the library who has not been introduced to the concept of vectorization will likely envision the code that solves their problem as iterating over their data to do something. Not knowing how to iterate over a DataFrame, the first thing they do is Google it and end up here, at this question. They then see the accepted answer telling them how to, and they close their eyes and run this code without ever first questioning if iteration is the right thing to do. \n The aim of this answer is to help new users understand that iteration is not necessarily the solution to every problem, and that better, faster and more idiomatic solutions could exist, and that it is worth investing time in exploring them. I'm not trying to start a war of iteration vs. vectorization, but I want new users to be informed when developing solutions to their problems with this library. \n    ", "date_posted": "2022-03-19 15:58:59Z", "upvote": "\r\n            1969\r\n        ", "accepted": "No", "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "answer_comments": [{"stack_answer_id": "55557758", "stack_answer_comment_id": "99356021", "comment_content": "Note that there are important caveats with ", "user_id": "None"}, {"stack_answer_id": "55557758", "stack_answer_comment_id": "99360660", "comment_content": "This is the only answer that focuses on the idiomatic techniques one should use with pandas, making it the best answer for this question. Learning to get the ", "user_id": "None"}, {"stack_answer_id": "55557758", "stack_answer_comment_id": "100017200", "comment_content": "I think you are being unfair to the for loop, though, seeing as they are only a bit slower than list comprehension in my tests. The trick is to loop over ", "user_id": "None"}, {"stack_answer_id": "55557758", "stack_answer_comment_id": "105699071", "comment_content": "Under List Comprehensions, the \"iterating over multiple columns\" example needs a caveat: ", "user_id": "None"}, {"stack_answer_id": "55557758", "stack_answer_comment_id": "111575230", "comment_content": "@Dean I get this response quite often and it honestly confuses me. It's all about forming good habits. \"My data is small and performance doesn't matter so my use of this antipattern can be excused\" ..? When performance actually does matter one day, you'll thank yourself for having prepared the right tools in advance.", "user_id": "None"}]}, {"stack_answer_id": "41022840", "answer_content": "\r\n First consider if you really need to  iterate  over rows in a DataFrame. See  this answer  for alternatives. \n If you still need to iterate over rows, you can use methods below. Note some   important caveats  which are not mentioned in any of the other answers. \n \n DataFrame.iterrows() \n   for index, row in df.iterrows():\n      print(row[\"c1\"], row[\"c2\"])\n \n \n DataFrame.itertuples() \n   for row in df.itertuples(index=True, name='Pandas'):\n      print(row.c1, row.c2)\n \n \n \n itertuples()  is supposed to be faster than  iterrows() \n But be aware, according to the docs (pandas 0.24.2 at the moment): \n \n iterrows:  dtype  might not match from row to row \n \n \n Because iterrows returns a Series for each row, it  does not preserve  dtypes across the rows (dtypes are preserved across columns for DataFrames). To preserve dtypes while iterating over the rows, it is better to use itertuples() which returns namedtuples of the values and which is generally much faster than iterrows() \n \n \n iterrows: Do not modify rows \n \n \n You should  never modify  something you are iterating over. This is not guaranteed to work in all cases. Depending on the data types, the iterator returns a copy and not a view, and writing to it will have no effect. \n \n Use  DataFrame.apply()  instead: \n     new_df = df.apply(lambda x: x * 2, axis = 1)\n \n \n itertuples: \n \n \n The column names will be renamed to positional names if they are invalid Python identifiers, repeated, or start with an underscore. With a large number of columns (>255), regular tuples are returned. \n \n See  pandas docs on iteration  for more details. \n    ", "date_posted": "2022-04-30 18:45:58Z", "upvote": "\r\n            534\r\n        ", "accepted": "No", "user": {"stack_user_id": "7156008", "name": "George", "reputation_score": "2,904"}, "answer_comments": [{"stack_answer_id": "41022840", "stack_answer_comment_id": "83917009", "comment_content": "Just a small question from someone reading this thread so long after its completion: how df.apply() compares to itertuples in terms of efficiency?", "user_id": "None"}, {"stack_answer_id": "41022840", "stack_answer_comment_id": "89180584", "comment_content": "Note: you can also say something like ", "user_id": "None"}, {"stack_answer_id": "41022840", "stack_answer_comment_id": "90586609", "comment_content": "Instead of ", "user_id": "None"}, {"stack_answer_id": "41022840", "stack_answer_comment_id": "90954217", "comment_content": "I am about 90% sure that if you use ", "user_id": "None"}, {"stack_answer_id": "41022840", "stack_answer_comment_id": "99357008", "comment_content": "I have stumbled upon this question because, although I knew there's split-apply-combine, I still ", "user_id": "None"}]}, {"stack_answer_id": "10739432", "answer_content": "\r\n You should use  df.iterrows() . Though iterating row-by-row is not especially efficient since  Series  objects have to be created. \n    ", "date_posted": "2019-12-11 18:42:58Z", "upvote": "\r\n            238\r\n        ", "accepted": "No", "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "answer_comments": [{"stack_answer_id": "10739432", "stack_answer_comment_id": "17255818", "comment_content": "Is this faster than converting the DataFrame to a numpy array (via .values) and operating on the array directly? I have the same problem, but ended up converting to a numpy array and then using cython.", "user_id": "None"}, {"stack_answer_id": "10739432", "stack_answer_comment_id": "24785470", "comment_content": "@vgoklani If iterating row-by-row is inefficient and you have a non-object numpy array then almost surely using the raw numpy array will be faster, especially for arrays with many rows. you should avoid iterating over rows unless you absolutely have to", "user_id": "None"}, {"stack_answer_id": "10739432", "stack_answer_comment_id": "56363619", "comment_content": "I have done a bit of testing on the time consumption for df.iterrows(), df.itertuples(), and zip(df['a'], df['b']) and posted the result in the answer of another question: ", "user_id": "None"}]}, {"stack_answer_id": "32680162", "answer_content": "\r\n While  iterrows()  is a good option, sometimes  itertuples()  can be much faster: \n\n df = pd.DataFrame({'a': randn(1000), 'b': randn(1000),'N': randint(100, 1000, (1000)), 'x': 'x'})\n\n%timeit [row.a * 2 for idx, row in df.iterrows()]\n# => 10 loops, best of 3: 50.3 ms per loop\n\n%timeit [row[1] * 2 for row in df.itertuples()]\n# => 1000 loops, best of 3: 541 \u00b5s per loop\n \n    ", "date_posted": "2016-06-01 09:00:01Z", "upvote": "\r\n            178\r\n        ", "accepted": "No", "user": {"stack_user_id": "1054939", "name": "e9t", "reputation_score": "14.5k"}, "answer_comments": [{"stack_answer_id": "32680162", "stack_answer_comment_id": "53208434", "comment_content": "Much of the time difference in your two examples seems like it is due to the fact that you appear to be using label-based indexing for the .iterrows() command and integer-based indexing for the .itertuples() command.", "user_id": "None"}, {"stack_answer_id": "32680162", "stack_answer_comment_id": "54234206", "comment_content": "For a finance data based dataframe(timestamp, and 4x float), itertuples is 19,57 times faster then iterrows on my machine. Only ", "user_id": "None"}, {"stack_answer_id": "32680162", "stack_answer_comment_id": "70363504", "comment_content": "Can you explain why it's faster?", "user_id": "None"}, {"stack_answer_id": "32680162", "stack_answer_comment_id": "71581133", "comment_content": "@AbeMiessler ", "user_id": "None"}, {"stack_answer_id": "32680162", "stack_answer_comment_id": "81199073", "comment_content": "Note that the order of the columns is actually indeterminate, because ", "user_id": "None"}]}, {"stack_answer_id": "39370553", "answer_content": "\r\n You can use the  df.iloc  function as follows: \n for i in range(0, len(df)):\n    print(df.iloc[i]['c1'], df.iloc[i]['c2'])\n \n    ", "date_posted": "2022-01-08 22:42:21Z", "upvote": "\r\n            129\r\n        ", "accepted": "No", "user": {"stack_user_id": "6160119", "name": "Tonechas", "reputation_score": "12.9k"}, "answer_comments": [{"stack_answer_id": "39370553", "stack_answer_comment_id": "80130437", "comment_content": "I know that one should avoid this in favor of iterrows or itertuples, but it would be interesting to know why. Any thoughts?", "user_id": "None"}, {"stack_answer_id": "39370553", "stack_answer_comment_id": "83643245", "comment_content": "This is the only valid technique I know of if you want to preserve the data types, and also refer to columns by name.  ", "user_id": "None"}, {"stack_answer_id": "39370553", "stack_answer_comment_id": "91754942", "comment_content": "Spent hours trying to wade through the idiosyncrasies of pandas data structures to do something simple AND expressive.  This results in readable code.", "user_id": "None"}, {"stack_answer_id": "39370553", "stack_answer_comment_id": "94421406", "comment_content": "While ", "user_id": "None"}, {"stack_answer_id": "39370553", "stack_answer_comment_id": "94897279", "comment_content": "On large Datafrmes this seems better as ", "user_id": "None"}]}, {"stack_answer_id": "30566899", "answer_content": "\r\n You can also use  df.apply()  to iterate over rows and access multiple columns for a function. \n\n docs: DataFrame.apply() \n\n def valuation_formula(x, y):\n    return x * y * 0.5\n\ndf['price'] = df.apply(lambda row: valuation_formula(row['x'], row['y']), axis=1)\n \n    ", "date_posted": "2015-06-01 06:24:44Z", "upvote": "\r\n            120\r\n        ", "accepted": "No", "user": {"stack_user_id": "1803298", "name": "cheekybastard", "reputation_score": "5,355"}, "answer_comments": [{"stack_answer_id": "30566899", "stack_answer_comment_id": "50344574", "comment_content": "Is the df['price'] refers to a column name in the data frame? I am trying to create a dictionary with unique values from several columns in a csv file. I used your logic to create a dictionary with unique keys and values and got an error stating ", "user_id": "None"}, {"stack_answer_id": "30566899", "stack_answer_comment_id": "50344609", "comment_content": "  df['Workclass'] = df.apply(lambda row: dic_update(row), axis=1) ", "user_id": "None"}, {"stack_answer_id": "30566899", "stack_answer_comment_id": "82085632", "comment_content": "Having the axis default to 0 is the worst", "user_id": "None"}, {"stack_answer_id": "30566899", "stack_answer_comment_id": "86313667", "comment_content": "Notice that ", "user_id": "None"}, {"stack_answer_id": "30566899", "stack_answer_comment_id": "111570055", "comment_content": "this is the appropriate answer for pandas", "user_id": "None"}]}, {"stack_answer_id": "59413206", "answer_content": "\r\n How to iterate efficiently \n\n If you really have to iterate a Pandas dataframe, you will probably want to  avoid using iterrows() . There are different methods and the usual  iterrows()  is far from being the best.  itertuples() can be 100 times faster. \n\n In short: \n\n \n As a general rule, use  df.itertuples(name=None) . In particular, when you have a fixed number columns and less than 255 columns.  See point (3) \n Otherwise, use  df.itertuples()  except if your columns have special characters such as spaces or '-'.  See point (2) \n It is possible to use  itertuples()  even if your dataframe has strange columns by using the last example.  See point (4) \n Only use  iterrows()  if you cannot the previous solutions.  See point (1) \n \n\n Different methods to iterate over rows in a Pandas dataframe: \n\n Generate a random dataframe with a million rows and 4 columns: \n\n     df = pd.DataFrame(np.random.randint(0, 100, size=(1000000, 4)), columns=list('ABCD'))\n    print(df)\n \n\n 1) The usual  iterrows()  is convenient, but damn slow: \n\n start_time = time.clock()\nresult = 0\nfor _, row in df.iterrows():\n    result += max(row['B'], row['C'])\n\ntotal_elapsed_time = round(time.clock() - start_time, 2)\nprint(\"1. Iterrows done in {} seconds, result = {}\".format(total_elapsed_time, result))\n \n\n 2) The default  itertuples()  is already much faster, but it doesn't work with column names such as  My Col-Name is very Strange  (you should avoid this method if your columns are repeated or if a column name cannot be simply converted to a Python variable name).: \n\n start_time = time.clock()\nresult = 0\nfor row in df.itertuples(index=False):\n    result += max(row.B, row.C)\n\ntotal_elapsed_time = round(time.clock() - start_time, 2)\nprint(\"2. Named Itertuples done in {} seconds, result = {}\".format(total_elapsed_time, result))\n \n\n 3) The default  itertuples()  using name=None is even faster but not really convenient as you have to define a variable per column. \n\n start_time = time.clock()\nresult = 0\nfor(_, col1, col2, col3, col4) in df.itertuples(name=None):\n    result += max(col2, col3)\n\ntotal_elapsed_time = round(time.clock() - start_time, 2)\nprint(\"3. Itertuples done in {} seconds, result = {}\".format(total_elapsed_time, result))\n \n\n 4) Finally, the named  itertuples()  is slower than the previous point, but you do not have to define a variable per column and it works with column names such as  My Col-Name is very Strange . \n\n start_time = time.clock()\nresult = 0\nfor row in df.itertuples(index=False):\n    result += max(row[df.columns.get_loc('B')], row[df.columns.get_loc('C')])\n\ntotal_elapsed_time = round(time.clock() - start_time, 2)\nprint(\"4. Polyvalent Itertuples working even with special characters in the column name done in {} seconds, result = {}\".format(total_elapsed_time, result))\n \n\n Output: \n\n          A   B   C   D\n0       41  63  42  23\n1       54   9  24  65\n2       15  34  10   9\n3       39  94  82  97\n4        4  88  79  54\n...     ..  ..  ..  ..\n999995  48  27   4  25\n999996  16  51  34  28\n999997   1  39  61  14\n999998  66  51  27  70\n999999  51  53  47  99\n\n[1000000 rows x 4 columns]\n\n1. Iterrows done in 104.96 seconds, result = 66151519\n2. Named Itertuples done in 1.26 seconds, result = 66151519\n3. Itertuples done in 0.94 seconds, result = 66151519\n4. Polyvalent Itertuples working even with special characters in the column name done in 2.94 seconds, result = 66151519\n \n\n This article is a very interesting comparison between iterrows and itertuples \n    ", "date_posted": "2020-06-11 13:43:59Z", "upvote": "\r\n            61\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "59413206", "stack_answer_comment_id": "124783543", "comment_content": "So WHY are these inefficient methods available in Pandas in the first place - if it's \"common knowledge\" that iterrows and itertuples should not be used - then why are they there, or rather, why are those methods not updated and made more efficient in the background by the maintainers of Pandas?", "user_id": "None"}, {"stack_answer_id": "59413206", "stack_answer_comment_id": "124794962", "comment_content": "@Monty, it's not always possible to vectorize all operations.", "user_id": "None"}]}, {"stack_answer_id": "48297889", "answer_content": "\r\n I was looking for  How to iterate on rows   and   columns  and ended here so: \n\n for i, row in df.iterrows():\n    for j, column in row.iteritems():\n        print(column)\n \n    ", "date_posted": "2020-06-11 13:37:53Z", "upvote": "\r\n            48\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "48297889", "stack_answer_comment_id": "111393447", "comment_content": "When possible, you should avoid using iterrows(). I explain why in the answer ", "user_id": "None"}]}, {"stack_answer_id": "47149876", "answer_content": "\r\n You can write your own iterator that implements  namedtuple \n\n from collections import namedtuple\n\ndef myiter(d, cols=None):\n    if cols is None:\n        v = d.values.tolist()\n        cols = d.columns.values.tolist()\n    else:\n        j = [d.columns.get_loc(c) for c in cols]\n        v = d.values[:, j].tolist()\n\n    n = namedtuple('MyTuple', cols)\n\n    for line in iter(v):\n        yield n(*line)\n \n\n This is directly comparable to  pd.DataFrame.itertuples .  I'm aiming at performing the same task with more efficiency. \n\n \n\n For the given dataframe with my function: \n\n list(myiter(df))\n\n[MyTuple(c1=10, c2=100), MyTuple(c1=11, c2=110), MyTuple(c1=12, c2=120)]\n \n\n Or with  pd.DataFrame.itertuples : \n\n list(df.itertuples(index=False))\n\n[Pandas(c1=10, c2=100), Pandas(c1=11, c2=110), Pandas(c1=12, c2=120)]\n \n\n \n\n A comprehensive test \nWe test making all columns available and subsetting the columns.   \n\n def iterfullA(d):\n    return list(myiter(d))\n\ndef iterfullB(d):\n    return list(d.itertuples(index=False))\n\ndef itersubA(d):\n    return list(myiter(d, ['col3', 'col4', 'col5', 'col6', 'col7']))\n\ndef itersubB(d):\n    return list(d[['col3', 'col4', 'col5', 'col6', 'col7']].itertuples(index=False))\n\nres = pd.DataFrame(\n    index=[10, 30, 100, 300, 1000, 3000, 10000, 30000],\n    columns='iterfullA iterfullB itersubA itersubB'.split(),\n    dtype=float\n)\n\nfor i in res.index:\n    d = pd.DataFrame(np.random.randint(10, size=(i, 10))).add_prefix('col')\n    for j in res.columns:\n        stmt = '{}(d)'.format(j)\n        setp = 'from __main__ import d, {}'.format(j)\n        res.at[i, j] = timeit(stmt, setp, number=100)\n\nres.groupby(res.columns.str[4:-1], axis=1).plot(loglog=True);\n \n\n \n\n \n    ", "date_posted": "2017-11-07 04:29:57Z", "upvote": "\r\n            24\r\n        ", "accepted": "No", "user": {"stack_user_id": "2336654", "name": "piRSquared", "reputation_score": "270k"}, "answer_comments": [{"stack_answer_id": "47149876", "stack_answer_comment_id": "82152350", "comment_content": "For people who don't want to read the code: blue line is ", "user_id": "None"}]}, {"stack_answer_id": "42741552", "answer_content": "\r\n To loop all rows in a  dataframe  you can use: \n\n for x in range(len(date_example.index)):\n    print date_example['Date'].iloc[x]\n \n    ", "date_posted": "2017-04-04 20:46:53Z", "upvote": "\r\n            21\r\n        ", "accepted": "No", "user": {"stack_user_id": "797495", "name": "Pedro Lobito", "reputation_score": "87.6k"}, "answer_comments": [{"stack_answer_id": "42741552", "stack_answer_comment_id": "98185901", "comment_content": "This is chained indexing. I do not recommend doing this.", "user_id": "None"}, {"stack_answer_id": "42741552", "stack_answer_comment_id": "98187282", "comment_content": "@cs95 What would you recommend instead?", "user_id": "None"}, {"stack_answer_id": "42741552", "stack_answer_comment_id": "98187416", "comment_content": "If you want to make this work, call df.columns.get_loc to get the integer index position of the date column (outside the loop), then use a single iloc indexing call inside.", "user_id": "None"}]}, {"stack_answer_id": "47073107", "answer_content": "\r\n  for ind in df.index:\n     print df['c1'][ind], df['c2'][ind]\n \n    ", "date_posted": "2019-05-07 06:37:44Z", "upvote": "\r\n            21\r\n        ", "accepted": "No", "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "answer_comments": [{"stack_answer_id": "47073107", "stack_answer_comment_id": "91463214", "comment_content": "how is the performance of this option when used on a large dataframe (millions of rows for example)?", "user_id": "None"}, {"stack_answer_id": "47073107", "stack_answer_comment_id": "92887253", "comment_content": "Honestly, I don\u2019t know exactly, I think that in comparison with the best answer, the elapsed time will be about the same, because both cases use \"for\"-construction.  But the memory may be different in some cases.", "user_id": "None"}, {"stack_answer_id": "47073107", "stack_answer_comment_id": "98185895", "comment_content": "This is chained indexing. Do not use this!", "user_id": "None"}]}, {"stack_answer_id": "70096237", "answer_content": "\r\n We have multiple options to do the same, lots of folks have shared their answers. \n I found below two methods easy and efficient to do : \n \n DataFrame.iterrows() \n DataFrame.itertuples() \n \n Example: \n  import pandas as pd\n inp = [{'c1':10, 'c2':100}, {'c1':11,'c2':110}, {'c1':12,'c2':120}]\n df = pd.DataFrame(inp)\n print (df)\n\n #With iterrows method \n\n for index, row in df.iterrows():\n     print(row[\"c1\"], row[\"c2\"])\n\n #With itertuples method\n\n for row in df.itertuples(index=True, name='Pandas'):\n     print(row.c1, row.c2)\n \n Note: itertuples() is supposed to be faster than iterrows() \n    ", "date_posted": "2022-01-06 09:46:42Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "9076666", "name": "Sachin", "reputation_score": "862"}, "answer_comments": [{"stack_answer_id": "70096237", "stack_answer_comment_id": "124086617", "comment_content": "This actually answers the question. +1", "user_id": "None"}]}, {"stack_answer_id": "60836700", "answer_content": "\r\n Update : cs95 has updated  his answer  to include plain numpy vectorization. You can simply refer to his answer. \n \n cs95 shows  that Pandas vectorization far outperforms other Pandas methods for computing stuff with dataframes. \n I wanted to add that if you first convert the dataframe to a NumPy array and then use vectorization, it's even faster than Pandas dataframe vectorization, (and that includes the time to turn it back into a dataframe series). \n If you add the following functions to cs95's benchmark code, this becomes pretty evident: \n def np_vectorization(df):\n    np_arr = df.to_numpy()\n    return pd.Series(np_arr[:,0] + np_arr[:,1], index=df.index)\n\ndef just_np_vectorization(df):\n    np_arr = df.to_numpy()\n    return np_arr[:,0] + np_arr[:,1]\n \n \n    ", "date_posted": "2021-08-27 05:47:45Z", "upvote": "\r\n            15\r\n        ", "accepted": "No", "user": {"stack_user_id": "10801098", "name": "bug_spray", "reputation_score": "1,335"}, "answer_comments": [{"stack_answer_id": "60836700", "stack_answer_comment_id": "121890161", "comment_content": "how do did you plot this?", "user_id": "None"}, {"stack_answer_id": "60836700", "stack_answer_comment_id": "121960481", "comment_content": " ", "user_id": "None"}]}, {"stack_answer_id": "51069586", "answer_content": "\r\n Sometimes a useful pattern is: \n\n # Borrowing @KutalmisB df example\ndf = pd.DataFrame({'col1': [1, 2], 'col2': [0.1, 0.2]}, index=['a', 'b'])\n# The to_dict call results in a list of dicts\n# where each row_dict is a dictionary with k:v pairs of columns:value for that row\nfor row_dict in df.to_dict(orient='records'):\n    print(row_dict)\n \n\n Which results in: \n\n {'col1':1.0, 'col2':0.1}\n{'col1':2.0, 'col2':0.2}\n \n    ", "date_posted": "2019-04-13 23:06:06Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "answer_comments": []}, {"stack_answer_id": "62136475", "answer_content": "\r\n In short \n \n Use vectorization if possible \n If an operation can't be vectorized - use list comprehensions \n If you need a single object representing the entire row - use itertuples \n If the above is too slow - try  swifter.apply \n If it's still too slow - try a  Cython  routine \n \n Benchmark \n \n    ", "date_posted": "2021-04-21 16:42:24Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "58436037", "answer_content": "\r\n There is a way to iterate throw rows while getting a DataFrame in return, and not a Series. I don't see anyone mentioning that you can pass index as a list for the row to be returned as a DataFrame: \n\n for i in range(len(df)):\n    row = df.iloc[[i]]\n \n\n Note the usage of double brackets. This returns a DataFrame with a single row. \n    ", "date_posted": "2019-10-17 15:26:30Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "1871385", "name": "Zeitgeist", "reputation_score": "1,242"}, "answer_comments": [{"stack_answer_id": "58436037", "stack_answer_comment_id": "104526424", "comment_content": "This was very helpful for getting the nth largest row in a data frame after sorting. Thanks!", "user_id": "None"}]}, {"stack_answer_id": "49984074", "answer_content": "\r\n To loop all rows in a  dataframe  and  use  values of each row  conveniently ,  namedtuples  can be converted to  ndarray s. For example: \n\n df = pd.DataFrame({'col1': [1, 2], 'col2': [0.1, 0.2]}, index=['a', 'b'])\n \n\n Iterating over the rows: \n\n for row in df.itertuples(index=False, name='Pandas'):\n    print np.asarray(row)\n \n\n results in: \n\n [ 1.   0.1]\n[ 2.   0.2]\n \n\n Please note that if  index=True ,  the index is added as the first element of the tuple , which may be undesirable for some applications. \n    ", "date_posted": "2018-04-24 08:48:05Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "3393574", "name": "Herpes Free Engineer", "reputation_score": "2,125"}, "answer_comments": []}, {"stack_answer_id": "54896256", "answer_content": "\r\n For both viewing and modifying values, I would use  iterrows() . In a for loop and by using tuple unpacking (see the example:  i, row ), I use the  row  for only viewing the value and use  i  with the  loc  method when I want to modify values. As stated in previous answers, here you should not modify something you are iterating over. \n\n for i, row in df.iterrows():\n    df_column_A = df.loc[i, 'A']\n    if df_column_A == 'Old_Value':\n        df_column_A = 'New_value'  \n \n\n Here the  row  in the loop is a copy of that row, and not a view of it. Therefore, you should NOT write something like  row['A'] = 'New_Value' , it will not modify the DataFrame. However, you can use  i  and  loc  and specify the DataFrame to do the work. \n    ", "date_posted": "2020-02-28 17:51:44Z", "upvote": "\r\n            10\r\n        ", "accepted": "No", "user": {"stack_user_id": "10951905", "name": "Hossein Kalbasi", "reputation_score": "1,393"}, "answer_comments": []}, {"stack_answer_id": "54264778", "answer_content": "\r\n There are so many ways to iterate over the rows in Pandas dataframe. One very simple and intuitive way is: \n\n df = pd.DataFrame({'A':[1, 2, 3], 'B':[4, 5, 6], 'C':[7, 8, 9]})\nprint(df)\nfor i in range(df.shape[0]):\n    # For printing the second column\n    print(df.iloc[i, 1])\n\n    # For printing more than one columns\n    print(df.iloc[i, [0, 2]])\n \n    ", "date_posted": "2020-06-11 13:38:59Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "64653674", "answer_content": "\r\n The easiest way, use the  apply  function \n def print_row(row):\n   print row['c1'], row['c2']\n\ndf.apply(lambda row: print_row(row), axis=1)\n \n    ", "date_posted": "2020-11-02 21:35:10Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "12566550", "name": "Fran\u00e7ois B.", "reputation_score": "1,014"}, "answer_comments": []}, {"stack_answer_id": "65396738", "answer_content": "\r\n As many answers here correctly and clearly point out, you should not generally attempt to loop in Pandas, but rather should write vectorized code.  But the question remains if you should  ever  write loops in Pandas, and if so the best way to loop in those situations. \n I believe there is at least one general situation where loops are appropriate: when you need to calculate some function that depends on values in  other  rows in a somewhat complex manner.  In this case, the looping code is often simpler, more readable, and less error prone than vectorized code.   The looping code might even be faster, too. \n I will attempt to show this with an example.  Suppose you want to take a cumulative sum of a column, but reset it whenever some other column equals zero: \n import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame( { 'x':[1,2,3,4,5,6], 'y':[1,1,1,0,1,1]  } )\n\n#   x  y  desired_result\n#0  1  1               1\n#1  2  1               3\n#2  3  1               6\n#3  4  0               4\n#4  5  1               9\n#5  6  1              15\n \n This is a good example where you could certainly write one line of Pandas to achieve this, although it's not especially readable, especially if you aren't fairly experienced with Pandas already: \n df.groupby( (df.y==0).cumsum() )['x'].cumsum()\n \n That's going to be fast enough for most situations, although you could also write faster code by avoiding the  groupby , but it will likely be even less readable. \n Alternatively, what if we write this as a loop?  You could do something like the following with NumPy: \n import numba as nb\n\n@nb.jit(nopython=True)  # Optional\ndef custom_sum(x,y):\n    x_sum = x.copy()\n    for i in range(1,len(df)):\n        if y[i] > 0: x_sum[i] = x_sum[i-1] + x[i]\n    return x_sum\n\ndf['desired_result'] = custom_sum( df.x.to_numpy(), df.y.to_numpy() )\n \n Admittedly, there's a bit of overhead there required to convert DataFrame columns to NumPy arrays, but the core piece of code is just one line of code that you could read even if you didn't know anything about Pandas or NumPy: \n if y[i] > 0: x_sum[i] = x_sum[i-1] + x[i]\n \n And this code is actually  faster  than the vectorized code.  In some quick tests with 100,000 rows, the above is about 10x faster than the  groupby  approach.  Note that one key to the speed there is numba, which is optional.  Without the \"@nb.jit\" line, the looping code is actually about 10x slower than the  groupby  approach. \n Clearly this example is simple enough that you would likely prefer the one line of pandas to writing a loop with its associated overhead.  However, there are more complex versions of this problem for which the readability or speed of the NumPy/numba loop approach likely makes sense. \n    ", "date_posted": "2021-07-23 18:29:01Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "3877338", "name": "JohnE", "reputation_score": "27.1k"}, "answer_comments": []}, {"stack_answer_id": "68233908", "answer_content": "\r\n df.iterrows()  returns  tuple(a, b)  where  a  is the  index  and  b  is the  row . \n    ", "date_posted": "2022-03-31 07:36:53Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "9534390", "name": "pythonic833", "reputation_score": "2,904"}, "answer_comments": []}, {"stack_answer_id": "47598852", "answer_content": "\r\n You can also do NumPy indexing for even greater speed ups. It's not really iterating but works much better than iteration for certain applications. \n\n subset = row['c1'][0:5]\nall = row['c1'][:]\n \n\n You may also want to cast it to an array. These indexes/selections are supposed to act like NumPy arrays already, but I ran into issues and needed to cast \n\n np.asarray(all)\nimgs[:] = cv2.resize(imgs[:], (224,224) ) # Resize every image in an hdf5 file\n \n    ", "date_posted": "2020-06-11 13:37:16Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "71234113", "answer_content": "\r\n Disclaimer:  Although here are so many answers which recommend  not  using an iterative (loop) approach (and I mostly agree), I would still see it as a reasonable approach for the following situation: \n Extend dataframe with data from API \n Let's say you have a large dataframe which contains incomplete user data. Now you have to extend this data with additional columns, for example the user's  age  and  gender . \n Both values have to be fetched from a backend API. I'm assuming the API doesn't provide a \"batch\" endpoint (which would accept multiple user IDs at once). Otherwise, you should rather call the API only once. \n The costs (waiting time) for the network request surpass the iteration of the dataframe by far. We're talking about network roundtrip times of hundreds of milliseconds compared to the negligibly small gains in using alternative approaches to iterations. \n 1 expensive network request for each row \n So in this case, I would absolutely prefer using an iterative approach. Although the network request is expensive, it is guaranteed being triggered only once for each row in the dataframe. Here is an example using  DataFrame.iterrows : \n Example \n for index, row in users_df.iterrows():\n  user_id = row['user_id']\n  # trigger expensive network request once for each row\n  response_dict = backend_api.get(f'/api/user-data/{user_id}')\n  # extend dataframe with multiple data from response\n  users_df.at[index, 'age'] = response_dict.get('age')\n  users_df.at[index, 'gender'] = response_dict.get('gender')\n \n    ", "date_posted": "2022-04-08 16:02:59Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "2472398", "name": "gru", "reputation_score": "1,480"}, "answer_comments": []}, {"stack_answer_id": "55202153", "answer_content": "\r\n This example uses iloc to isolate each digit in the data frame.  \n\n import pandas as pd\n\n a = [1, 2, 3, 4]\n b = [5, 6, 7, 8]\n\n mjr = pd.DataFrame({'a':a, 'b':b})\n\n size = mjr.shape\n\n for i in range(size[0]):\n     for j in range(size[1]):\n         print(mjr.iloc[i, j])\n \n    ", "date_posted": "2019-03-16 22:33:02Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "8042986", "name": "mjr2000", "reputation_score": "90"}, "answer_comments": []}, {"stack_answer_id": "59264161", "answer_content": "\r\n Some libraries (e.g. a Java interop library that I use) require values to be passed in a row at a time, for example, if streaming data. To replicate the streaming nature, I 'stream' my dataframe values one by one, I wrote the below, which comes in handy from time to time. \n\n class DataFrameReader:\n  def __init__(self, df):\n    self._df = df\n    self._row = None\n    self._columns = df.columns.tolist()\n    self.reset()\n    self.row_index = 0\n\n  def __getattr__(self, key):\n    return self.__getitem__(key)\n\n  def read(self) -> bool:\n    self._row = next(self._iterator, None)\n    self.row_index += 1\n    return self._row is not None\n\n  def columns(self):\n    return self._columns\n\n  def reset(self) -> None:\n    self._iterator = self._df.itertuples()\n\n  def get_index(self):\n    return self._row[0]\n\n  def index(self):\n    return self._row[0]\n\n  def to_dict(self, columns: List[str] = None):\n    return self.row(columns=columns)\n\n  def tolist(self, cols) -> List[object]:\n    return [self.__getitem__(c) for c in cols]\n\n  def row(self, columns: List[str] = None) -> Dict[str, object]:\n    cols = set(self._columns if columns is None else columns)\n    return {c : self.__getitem__(c) for c in self._columns if c in cols}\n\n  def __getitem__(self, key) -> object:\n    # the df index of the row is at index 0\n    try:\n        if type(key) is list:\n            ix = [self._columns.index(key) + 1 for k in key]\n        else:\n            ix = self._columns.index(key) + 1\n        return self._row[ix]\n    except BaseException as e:\n        return None\n\n  def __next__(self) -> 'DataFrameReader':\n    if self.read():\n        return self\n    else:\n        raise StopIteration\n\n  def __iter__(self) -> 'DataFrameReader':\n    return self\n \n\n Which can be used: \n\n for row in DataFrameReader(df):\n  print(row.my_column_name)\n  print(row.to_dict())\n  print(row['my_column_name'])\n  print(row.tolist())\n \n\n And preserves the values/ name mapping for the rows being iterated. Obviously, is a lot slower than using apply and Cython as indicated above, but is necessary in some circumstances. \n    ", "date_posted": "2019-12-10 09:36:45Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "6690508", "name": "morganics", "reputation_score": "1,111"}, "answer_comments": []}, {"stack_answer_id": "64177887", "answer_content": "\r\n Along with the great answers in this post I am going to propose  Divide and Conquer  approach, I am not writing this answer to abolish the other great answers but to fulfill them with another approach which was working efficiently for me. It has two steps of  splitting  and  merging  the pandas dataframe: \n PROS of Divide and Conquer: \n \n You don't need to use vectorization or any other methods to cast the type of your dataframe into another type \n You don't need to Cythonize your code which normally takes extra time from you \n Both  iterrows()  and  itertuples()  in my case were having the same performance over entire dataframe \n Depends on your choice of slicing  index , you will be able to exponentially quicken the iteration. The higher  index , the quicker your iteration process. \n \n CONS of Divide and Conquer: \n \n You shouldn't have dependency over the iteration process to the same dataframe and different  slice . Meaning if you want to read or write from other  slice , it maybe difficult to do that. \n \n ===================    Divide and Conquer Approach    ================= \n Step 1: Splitting/Slicing \n In this step, we are going to divide the iteration over the entire dataframe. Think that you are going to read a csv file into pandas df then iterate over it. In may case I have 5,000,000 records and I am going to split it into 100,000 records. \n NOTE:  I need to reiterate as other runtime analysis explained in the other solutions in this page, \"number of records\" has exponential proportion of \"runtime\" on search on the df. Based on the benchmark on my data here are the results: \n Number of records | Iteration per second\n========================================\n100,000           | 500 it/s\n500,000           | 200 it/s\n1,000,000         | 50 it/s\n5,000,000         | 20 it/s\n \n Step 2: Merging \n This is going to be an easy step, just merge all the written csv files into one dataframe and write it into a bigger csv file. \n Here is the sample code: \n # Step 1 (Splitting/Slicing)\nimport pandas as pd\ndf_all = pd.read_csv('C:/KtV.csv')\ndf_index = 100000\ndf_len = len(df)\nfor i in range(df_len // df_index + 1):\n    lower_bound = i * df_index \n    higher_bound = min(lower_bound + df_index, df_len)\n    # splitting/slicing df (make sure to copy() otherwise it will be a view\n    df = df_all[lower_bound:higher_bound].copy()\n    '''\n    write your iteration over the sliced df here\n    using iterrows() or intertuples() or ...\n    '''\n    # writing into csv files\n    df.to_csv('C:/KtV_prep_'+str(i)+'.csv')\n\n\n\n# Step 2 (Merging)\nfilename='C:/KtV_prep_'\ndf = (pd.read_csv(f) for f in [filename+str(i)+'.csv' for i in range(ktv_len // ktv_index + 1)])\ndf_prep_all = pd.concat(df)\ndf_prep_all.to_csv('C:/KtV_prep_all.csv')\n \n Reference: \n Efficient way of iteration over datafreame \n Concatenate csv files into one Pandas Dataframe \n    ", "date_posted": "2020-10-31 13:57:20Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "6117017", "name": "Timbus Calin", "reputation_score": "12.2k"}, "answer_comments": []}, {"stack_answer_id": "67701850", "answer_content": "\r\n As  the accepted answer  states, the fastest way to apply a function over rows is to use a  vectorized function , the so-called NumPy  ufuncs  (universal functions). \n But what should you do when the function you want to apply isn't already implemented in NumPy? \n Well, using the  vectorize  decorator from  numba , you can easily create ufuncs directly in Python like this: \n from numba import vectorize, float64\n\n@vectorize([float64(float64)])\ndef f(x):\n    #x is your line, do something with it, and return a float\n \n The documentation for this function is here:  Creating NumPy universal functions \n    ", "date_posted": "2022-01-05 20:48:26Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "68562557", "answer_content": "\r\n Probably the most elegant solution (but certainly not the most efficient): \n for row in df.values:\n    c2 = row[1]\n    print(row)\n    # ...\n\nfor c1, c2 in df.values:\n    # ...\n \n Note that: \n \n the  documentation  explicitly recommends to use  .to_numpy()  instead \n the produced NumPy array will have a dtype that fits all columns, in the worst case  object \n there are  good reasons  not to use a loop in the first place \n \n Still, I think this option should be included here, as a straight-forward solution to a (one should think) trivial problem. \n    ", "date_posted": "2021-08-02 10:04:04Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "4248897", "name": "Ernesto Els\u00e4\u00dfer", "reputation_score": "694"}, "answer_comments": []}], "user": {"stack_user_id": "245549", "name": "Roman", "reputation_score": "115k"}, "question_comments": [{"stack_question_id": "16476924", "stack_question_comment_id": "82610234", "comment_content": "The df.iteritems() iterates over columns and not rows. Thus, to make it iterate over rows, you have to transpose (the \"T\"), which means you change rows and columns into each other (reflect over diagonal). As a result, you effectively iterate the original dataframe over its rows when you use df.T.iteritems()", "user_id": "None"}, {"stack_question_id": "16476924", "stack_question_comment_id": "103162518", "comment_content": "In contrast to what cs95 says, there are perfectly fine reasons to want to iterate over a dataframe, so new users should not feel discouraged. One example is if you want to execute some code using the values of each row as input. Also, if your dataframe is reasonably small (e.g. less than 1000 items), performance is not really an issue.", "user_id": "None"}, {"stack_question_id": "16476924", "stack_question_comment_id": "104047003", "comment_content": "@cs95 It seems to me that dataframes are the go-to table format in Python. So whenever you want to read in a csv, or you have a list of dicts whose values you want to manipulate, or you want to perform simple join, groupby or window operations, you use a dataframe, even if your data is comparitively small.", "user_id": "None"}, {"stack_question_id": "16476924", "stack_question_comment_id": "104053145", "comment_content": "@cs95 No, but this was in response to \"using a DataFrame at all\". My point is that this is why one may have one's data in a dataframe. If you then want to e.g. run a script for each line of your data, you have to iterate over that dataframe.", "user_id": "None"}, {"stack_question_id": "16476924", "stack_question_comment_id": "104107821", "comment_content": "I second @oulenz. As far as I can tell ", "user_id": "None"}]},
{"stack_question_id": "2158395", "question_title": "Flatten an irregular list of lists", "question_content": "\r\n                Yes, I know this subject has been covered before (here, here, here, here), but as far as I know, all solutions, except for one, fail on a list like this:\n\nL = [[[1, 2, 3], [4, 5]], 6]\r\nWhere the ...\r\n", "question_url": "/questions/2158395/flatten-an-irregular-list-of-lists", "date_posted": "Jan 28, 2010 at 22:15", "upvote": "5", "view": "1", "tags": ["python", "list", "optimization", "nested-lists", "flatten"], "answers_count": "5", "answers": [{"stack_answer_id": "2158532", "answer_content": "\r\n Using generator functions can make your example easier to read and improve performance. \n Python 2 \n Using the  Iterable  ABC  added in 2.6: \n from collections import Iterable\n\ndef flatten(xs):\n    for x in xs:\n        if isinstance(x, Iterable) and not isinstance(x, basestring):\n            for item in flatten(x):\n                yield item\n        else:\n            yield x\n \n Python 3 \n In Python 3,  basestring  is no more, but the tuple  (str, bytes)  gives the same effect. Also, the  yield from  operator returns an item from a generator one at a time. \n from collections.abc import Iterable\n\ndef flatten(xs):\n    for x in xs:\n        if isinstance(x, Iterable) and not isinstance(x, (str, bytes)):\n            yield from flatten(x)\n        else:\n            yield x\n \n    ", "date_posted": "2022-05-22 20:17:07Z", "upvote": "\r\n            448\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": [{"stack_answer_id": "2158532", "stack_answer_comment_id": "14265381", "comment_content": "Of all the suggestions on this page, this is the only one that flattened this list ", "user_id": "None"}, {"stack_answer_id": "2158532", "stack_answer_comment_id": "49961116", "comment_content": "This also flattens dictionaries. Maybe you want to use ", "user_id": "None"}, {"stack_answer_id": "2158532", "stack_answer_comment_id": "52038449", "comment_content": "This doesn't work with things that aren't lists initially, e.g. ", "user_id": "None"}, {"stack_answer_id": "2158532", "stack_answer_comment_id": "92094122", "comment_content": "For Python 3.7, using ", "user_id": "None"}, {"stack_answer_id": "2158532", "stack_answer_comment_id": "96939998", "comment_content": "Indeed, recursion is ", "user_id": "None"}]}, {"stack_answer_id": "2158522", "answer_content": "\r\n My solution: \n\n import collections\n\n\ndef flatten(x):\n    if isinstance(x, collections.Iterable):\n        return [a for i in x for a in flatten(i)]\n    else:\n        return [x]\n \n\n A little more concise, but pretty much the same. \n    ", "date_posted": "2019-05-23 12:18:40Z", "upvote": "\r\n            62\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "2158522", "stack_answer_comment_id": "25410021", "comment_content": "You can do this without importing anything if you just ", "user_id": "None"}, {"stack_answer_id": "2158522", "stack_answer_comment_id": "43136613", "comment_content": "Worth to note that this solution works only if all the items are of type ", "user_id": "None"}, {"stack_answer_id": "2158522", "stack_answer_comment_id": "77581475", "comment_content": "Could make it more concise, ", "user_id": "None"}, {"stack_answer_id": "2158522", "stack_answer_comment_id": "93943979", "comment_content": "this doesn't work on strings because strings are iterable too. Replace the condition with ", "user_id": "None"}, {"stack_answer_id": "2158522", "stack_answer_comment_id": "110395399", "comment_content": "replace ", "user_id": "None"}]}, {"stack_answer_id": "14491059", "answer_content": "\r\n Generator using recursion and duck typing (updated for Python 3): \n\n def flatten(L):\n    for item in L:\n        try:\n            yield from flatten(item)\n        except TypeError:\n            yield item\n\nlist(flatten([[[1, 2, 3], [4, 5]], 6]))\n>>>[1, 2, 3, 4, 5, 6]\n \n    ", "date_posted": "2015-09-08 15:01:25Z", "upvote": "\r\n            46\r\n        ", "accepted": "No", "user": {"stack_user_id": "1355221", "name": "dansalmo", "reputation_score": "11.1k"}, "answer_comments": [{"stack_answer_id": "14491059", "stack_answer_comment_id": "52784011", "comment_content": "Thanks, that works nice for Python 3.  For 2.x the previous is needed:  ", "user_id": "None"}, {"stack_answer_id": "14491059", "stack_answer_comment_id": "85707692", "comment_content": "list(flatten([['X'], 'Y'])) fails on 2.X variant", "user_id": "None"}, {"stack_answer_id": "14491059", "stack_answer_comment_id": "85750061", "comment_content": "@user1019129 see my comment above yours", "user_id": "None"}, {"stack_answer_id": "14491059", "stack_answer_comment_id": "85788346", "comment_content": "yes it fails with the cycle.. i think because a string is also an \"array\"-of-chars", "user_id": "None"}]}, {"stack_answer_id": "5409395", "answer_content": "\r\n Here is my functional version of recursive flatten which handles both tuples and lists, and lets you throw in any mix of positional arguments. Returns a generator which produces the entire sequence in order, arg by arg: \n\n flatten = lambda *n: (e for a in n\n    for e in (flatten(*a) if isinstance(a, (tuple, list)) else (a,)))\n \n\n Usage: \n\n l1 = ['a', ['b', ('c', 'd')]]\nl2 = [0, 1, (2, 3), [[4, 5, (6, 7, (8,), [9]), 10]], (11,)]\nprint list(flatten(l1, -2, -1, l2))\n['a', 'b', 'c', 'd', -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n \n    ", "date_posted": "2011-03-23 17:42:24Z", "upvote": "\r\n            39\r\n        ", "accepted": "No", "user": {"stack_user_id": "538718", "name": "samplebias", "reputation_score": "36k"}, "answer_comments": [{"stack_answer_id": "5409395", "stack_answer_comment_id": "29945046", "comment_content": "great solution, however would be much helpful if you added some comment to describe what ", "user_id": "None"}, {"stack_answer_id": "5409395", "stack_answer_comment_id": "31445589", "comment_content": "@WolfgangKuehne: Try ", "user_id": "None"}, {"stack_answer_id": "5409395", "stack_answer_comment_id": "51406248", "comment_content": "This is significantly faster than ", "user_id": "None"}, {"stack_answer_id": "5409395", "stack_answer_comment_id": "111812784", "comment_content": "This is the only solution I have come across, in a moderate google search, on any website that actually works for lists nested deeper than one level.", "user_id": "None"}, {"stack_answer_id": "5409395", "stack_answer_comment_id": "114103535", "comment_content": "This is a work of art. So few characters, and still nearly impossible to understand. 10/10 best Python code golf I've seen yet \ud83c\udfcc\ufe0f\u200d\u2642\ufe0f\ud83c\udfcc\ufe0f\u200d\u2640\ufe0f\u26f3\ufe0f.  Having something this short almost makes up for the fact that Python doesn't have a built-in flatten function.", "user_id": "None"}]}, {"stack_answer_id": "2159079", "answer_content": "\r\n Generator version of @unutbu's non-recursive solution, as requested by @Andrew in a comment: \n\n def genflat(l, ltypes=collections.Sequence):\n    l = list(l)\n    i = 0\n    while i < len(l):\n        while isinstance(l[i], ltypes):\n            if not l[i]:\n                l.pop(i)\n                i -= 1\n                break\n            else:\n                l[i:i + 1] = l[i]\n        yield l[i]\n        i += 1\n \n\n Slightly simplified version of this generator: \n\n def genflat(l, ltypes=collections.Sequence):\n    l = list(l)\n    while l:\n        while l and isinstance(l[0], ltypes):\n            l[0:1] = l[0]\n        if l: yield l.pop(0)\n \n    ", "date_posted": "2010-01-29 00:27:22Z", "upvote": "\r\n            36\r\n        ", "accepted": "No", "user": {"stack_user_id": "95810", "name": "Alex Martelli", "reputation_score": "820k"}, "answer_comments": [{"stack_answer_id": "2159079", "stack_answer_comment_id": "2104766", "comment_content": "it's a pre-order traversal of the tree formed by the nested lists.  only the leaves are returned.  Note that this implementation will consume the original data structure, for better or worse.  Could be fun to write one that both preserves the original tree, but also doesn't have to copy the list entries.", "user_id": "None"}, {"stack_answer_id": "2159079", "stack_answer_comment_id": "4686862", "comment_content": "I think you need to test for strings -- eg add \"and not isinstance(l[0], basestring)\" as in Cristian's solution. Otherwise you get an infinite loop around l[0:1] = l[0]", "user_id": "None"}, {"stack_answer_id": "2159079", "stack_answer_comment_id": "17780727", "comment_content": "This is a good example of making a generator, but as c-urchin mentions, the algorithm itself fails when the sequence contains strings.", "user_id": "None"}]}, {"stack_answer_id": "2158562", "answer_content": "\r\n This version of  flatten  avoids python's recursion limit (and thus works with arbitrarily deep, nested iterables). It is a generator which can handle strings and arbitrary iterables (even infinite ones). \n\n import itertools as IT\nimport collections\n\ndef flatten(iterable, ltypes=collections.Iterable):\n    remainder = iter(iterable)\n    while True:\n        first = next(remainder)\n        if isinstance(first, ltypes) and not isinstance(first, (str, bytes)):\n            remainder = IT.chain(first, remainder)\n        else:\n            yield first\n \n\n Here are some examples demonstrating its use: \n\n print(list(IT.islice(flatten(IT.repeat(1)),10)))\n# [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n\nprint(list(IT.islice(flatten(IT.chain(IT.repeat(2,3),\n                                       {10,20,30},\n                                       'foo bar'.split(),\n                                       IT.repeat(1),)),10)))\n# [2, 2, 2, 10, 20, 30, 'foo', 'bar', 1, 1]\n\nprint(list(flatten([[1,2,[3,4]]])))\n# [1, 2, 3, 4]\n\nseq = ([[chr(i),chr(i-32)] for i in range(ord('a'), ord('z')+1)] + list(range(0,9)))\nprint(list(flatten(seq)))\n# ['a', 'A', 'b', 'B', 'c', 'C', 'd', 'D', 'e', 'E', 'f', 'F', 'g', 'G', 'h', 'H',\n# 'i', 'I', 'j', 'J', 'k', 'K', 'l', 'L', 'm', 'M', 'n', 'N', 'o', 'O', 'p', 'P',\n# 'q', 'Q', 'r', 'R', 's', 'S', 't', 'T', 'u', 'U', 'v', 'V', 'w', 'W', 'x', 'X',\n# 'y', 'Y', 'z', 'Z', 0, 1, 2, 3, 4, 5, 6, 7, 8]\n \n\n Although  flatten  can handle infinite generators, it can not handle infinite nesting: \n\n def infinitely_nested():\n    while True:\n        yield IT.chain(infinitely_nested(), IT.repeat(1))\n\nprint(list(IT.islice(flatten(infinitely_nested()), 10)))\n# hangs\n \n    ", "date_posted": "2019-05-23 12:53:56Z", "upvote": "\r\n            33\r\n        ", "accepted": "No", "user": {"stack_user_id": "190597", "name": "unutbu", "reputation_score": "791k"}, "answer_comments": [{"stack_answer_id": "2158562", "stack_answer_comment_id": "27754234", "comment_content": "any consensus on whether to use ABC Iterable or ABC Sequence?", "user_id": "None"}, {"stack_answer_id": "2158562", "stack_answer_comment_id": "27754354", "comment_content": ", ", "user_id": "None"}, {"stack_answer_id": "2158562", "stack_answer_comment_id": "27804882", "comment_content": "@wim: One problem with using ", "user_id": "None"}, {"stack_answer_id": "2158562", "stack_answer_comment_id": "99165386", "comment_content": "This doesn't seem to work for the 3rd and the 4th examples. It throws ", "user_id": "None"}, {"stack_answer_id": "2158562", "stack_answer_comment_id": "106796892", "comment_content": "@Georgy this could be fixed with encapsulating the body of flatten in a ", "user_id": "None"}]}, {"stack_answer_id": "4590652", "answer_content": "\r\n def flatten(xs):\n    res = []\n    def loop(ys):\n        for i in ys:\n            if isinstance(i, list):\n                loop(i)\n            else:\n                res.append(i)\n    loop(xs)\n    return res\n \n    ", "date_posted": "2012-08-21 14:39:45Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "348785", "name": "kev", "reputation_score": "148k"}, "answer_comments": [{"stack_answer_id": "4590652", "stack_answer_comment_id": "121983372", "comment_content": "This looks very elegant and simple. Why it does not have more upvotes? Are there any problems with this solution?", "user_id": "None"}, {"stack_answer_id": "4590652", "stack_answer_comment_id": "129064569", "comment_content": "This is a brilliant solution!", "user_id": "None"}]}, {"stack_answer_id": "4694575", "answer_content": "\r\n Here's another answer that is even more interesting... \n import re\n\ndef Flatten(TheList):\n    a = str(TheList)\n    b,_Anon = re.subn(r'[\\[,\\]]', ' ', a)\n    c = b.split()\n    d = [int(x) for x in c]\n\n    return(d)\n \n Basically, it converts the nested list to a string, uses a regex to strip out the nested syntax, and then converts the result back to a (flattened) list. \n    ", "date_posted": "2021-01-20 14:15:09Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "392301", "name": "clay", "reputation_score": "1,677"}, "answer_comments": [{"stack_answer_id": "4694575", "stack_answer_comment_id": "40277369", "comment_content": "If you try to generalize this to something other than int values, it'll be fun with, e.g., ", "user_id": "None"}, {"stack_answer_id": "4694575", "stack_answer_comment_id": "40293216", "comment_content": "The original prompt was about flattening a list of integers. If you just change the list comprehension to d=[x for x in c] it should work fine for your sample.", "user_id": "None"}, {"stack_answer_id": "4694575", "stack_answer_comment_id": "40305748", "comment_content": "First, ", "user_id": "None"}, {"stack_answer_id": "4694575", "stack_answer_comment_id": "40313909", "comment_content": "Ha! The way your comment got formatted on my computer, I didn't even realize that was supposed to be Apple II as it appeared on the old computers. In any case, my answer to both your questions is that this exercise--for me--is merely an experiment to find a creative solution to flattening a list. I'm not sure I would generalize it to flattening every list out there.", "user_id": "None"}, {"stack_answer_id": "4694575", "stack_answer_comment_id": "95431251", "comment_content": "You just need to ", "user_id": "None"}]}, {"stack_answer_id": "17868434", "answer_content": "\r\n It was fun trying to create a function that could flatten irregular list in Python, but of course that is what Python is for (to make programming fun). The following generator works fairly well with some caveats: \n\n def flatten(iterable):\n    try:\n        for item in iterable:\n            yield from flatten(item)\n    except TypeError:\n        yield iterable\n \n\n It will flatten datatypes that you might want left alone (like  bytearray ,  bytes , and  str  objects). Also, the code relies on the fact that requesting an iterator from a non-iterable raises a  TypeError . \n\n >>> L = [[[1, 2, 3], [4, 5]], 6]\n>>> def flatten(iterable):\n    try:\n        for item in iterable:\n            yield from flatten(item)\n    except TypeError:\n        yield iterable\n\n\n>>> list(flatten(L))\n[1, 2, 3, 4, 5, 6]\n>>>\n \n\n \n\n Edit: \n\n I disagree with the previous implementation. The problem is that you should not be able to flatten something that is not an iterable. It is confusing and gives the wrong impression of the argument. \n\n >>> list(flatten(123))\n[123]\n>>>\n \n\n The following generator is almost the same as the first but does not have the problem of trying to flatten a non-iterable object. It fails as one would expect when an inappropriate argument is given to it. \n\n def flatten(iterable):\n    for item in iterable:\n        try:\n            yield from flatten(item)\n        except TypeError:\n            yield item\n \n\n Testing the generator works fine with the list that was provided. However, the new code will raise a  TypeError  when a non-iterable object is given to it. Example are shown below of the new behavior. \n\n >>> L = [[[1, 2, 3], [4, 5]], 6]\n>>> list(flatten(L))\n[1, 2, 3, 4, 5, 6]\n>>> list(flatten(123))\nTraceback (most recent call last):\n  File \"<pyshell#32>\", line 1, in <module>\n    list(flatten(123))\n  File \"<pyshell#27>\", line 2, in flatten\n    for item in iterable:\nTypeError: 'int' object is not iterable\n>>>\n \n    ", "date_posted": "2014-08-28 13:51:28Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "216356", "name": "Noctis Skytower", "reputation_score": "20.6k"}, "answer_comments": []}, {"stack_answer_id": "45390129", "answer_content": "\r\n You could use  deepflatten  from the 3rd party package  iteration_utilities : \n\n >>> from iteration_utilities import deepflatten\n>>> L = [[[1, 2, 3], [4, 5]], 6]\n>>> list(deepflatten(L))\n[1, 2, 3, 4, 5, 6]\n\n>>> list(deepflatten(L, types=list))  # only flatten \"inner\" lists\n[1, 2, 3, 4, 5, 6]\n \n\n It's an iterator so you need to iterate it (for example by wrapping it with  list  or using it in a loop). Internally it uses an iterative approach instead of an recursive approach and it's written as C extension so it can be faster than pure python approaches: \n\n >>> %timeit list(deepflatten(L))\n12.6 \u00b5s \u00b1 298 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n>>> %timeit list(deepflatten(L, types=list))\n8.7 \u00b5s \u00b1 139 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n\n>>> %timeit list(flatten(L))   # Cristian - Python 3.x approach from https://stackoverflow.com/a/2158532/5393381\n86.4 \u00b5s \u00b1 4.42 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\n\n>>> %timeit list(flatten(L))   # Josh Lee - https://stackoverflow.com/a/2158522/5393381\n107 \u00b5s \u00b1 2.99 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\n\n>>> %timeit list(genflat(L, list))  # Alex Martelli - https://stackoverflow.com/a/2159079/5393381\n23.1 \u00b5s \u00b1 710 ns per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\n \n\n \n\n I'm the author of the  iteration_utilities  library. \n    ", "date_posted": "2017-07-29 14:01:42Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "5393381", "name": "MSeifert", "reputation_score": "136k"}, "answer_comments": []}, {"stack_answer_id": "20495215", "answer_content": "\r\n Here's a simple function that flattens lists of arbitrary depth. No recursion, to avoid stack overflow. \n\n from copy import deepcopy\n\ndef flatten_list(nested_list):\n    \"\"\"Flatten an arbitrarily nested list, without recursion (to avoid\n    stack overflows). Returns a new list, the original list is unchanged.\n\n    >> list(flatten_list([1, 2, 3, [4], [], [[[[[[[[[5]]]]]]]]]]))\n    [1, 2, 3, 4, 5]\n    >> list(flatten_list([[1, 2], 3]))\n    [1, 2, 3]\n\n    \"\"\"\n    nested_list = deepcopy(nested_list)\n\n    while nested_list:\n        sublist = nested_list.pop(0)\n\n        if isinstance(sublist, list):\n            nested_list = sublist + nested_list\n        else:\n            yield sublist\n \n    ", "date_posted": "2013-12-10 14:55:11Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "509706", "name": "Wilfred Hughes", "reputation_score": "28.2k"}, "answer_comments": [{"stack_answer_id": "20495215", "stack_answer_comment_id": "95431976", "comment_content": "Yes! Very similar to my code at ", "user_id": "None"}, {"stack_answer_id": "20495215", "stack_answer_comment_id": "127199352", "comment_content": "This could be made much more efficient by using ", "user_id": "None"}]}, {"stack_answer_id": "64517529", "answer_content": "\r\n Pandas has a function that does this. It returns an iterator as you mentioned. \n In [1]: import pandas\nIn [2]: pandas.core.common.flatten([[[1, 2, 3], [4, 5]], 6])\nOut[2]: <generator object flatten at 0x7f12ade66200>\nIn [3]: list(pandas.core.common.flatten([[[1, 2, 3], [4, 5]], 6]))\nOut[3]: [1, 2, 3, 4, 5, 6]\n \n    ", "date_posted": "2020-10-24 20:03:15Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "116", "name": "Mark Harrison", "reputation_score": "287k"}, "answer_comments": [{"stack_answer_id": "64517529", "stack_answer_comment_id": "116168058", "comment_content": "Great stuff! For people (like me) who are using pandas anyway, this is a beautifully simple way", "user_id": "None"}]}, {"stack_answer_id": "5226060", "answer_content": "\r\n Although an elegant and very pythonic answer has been selected I would present my solution just for the review: \n\n def flat(l):\n    ret = []\n    for i in l:\n        if isinstance(i, list) or isinstance(i, tuple):\n            ret.extend(flat(i))\n        else:\n            ret.append(i)\n    return ret\n \n\n Please tell how good or bad this code is? \n    ", "date_posted": "2011-03-07 22:32:07Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "69746", "name": "Xolve", "reputation_score": "21.3k"}, "answer_comments": [{"stack_answer_id": "5226060", "stack_answer_comment_id": "25450076", "comment_content": "Use ", "user_id": "None"}, {"stack_answer_id": "5226060", "stack_answer_comment_id": "35343653", "comment_content": " will get you the same container type back as was passed in, also. :)", "user_id": "None"}, {"stack_answer_id": "5226060", "stack_answer_comment_id": "35429281", "comment_content": "@dash-tom-bang Can you please explain what it means in a bit detail.", "user_id": "None"}, {"stack_answer_id": "5226060", "stack_answer_comment_id": "37392303", "comment_content": "If you pass in a list, you probably want a list back. If you pass in a tuple, you probably want a tuple back. If you pass in a mishmash of the two, you'll get whatever the outer enclosing thing was.", "user_id": "None"}]}, {"stack_answer_id": "4676482", "answer_content": "\r\n I prefer simple answers.  No generators.  No recursion or recursion limits.  Just iteration: \n\n def flatten(TheList):\n    listIsNested = True\n\n    while listIsNested:                 #outer loop\n        keepChecking = False\n        Temp = []\n\n        for element in TheList:         #inner loop\n            if isinstance(element,list):\n                Temp.extend(element)\n                keepChecking = True\n            else:\n                Temp.append(element)\n\n        listIsNested = keepChecking     #determine if outer loop exits\n        TheList = Temp[:]\n\n    return TheList\n \n\n This works with two lists: an inner for loop and an outer while loop.   \n\n The inner for loop iterates through the list.  If it finds a list element, it (1) uses list.extend() to flatten that part one level of nesting and (2) switches keepChecking to True.  keepchecking is used to control the outer while loop.  If the outer loop gets set to true, it triggers the inner loop for another pass.   \n\n Those passes keep happening until no more nested lists are found.  When a pass finally occurs where none are found, keepChecking never gets tripped to true, which means listIsNested stays false and the outer while loop exits.   \n\n The flattened list is then returned. \n\n Test-run    \n\n flatten([1,2,3,4,[100,200,300,[1000,2000,3000]]])\n \n\n [1, 2, 3, 4, 100, 200, 300, 1000, 2000, 3000] \n    ", "date_posted": "2011-01-13 04:16:53Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "392301", "name": "clay", "reputation_score": "1,677"}, "answer_comments": [{"stack_answer_id": "4676482", "stack_answer_comment_id": "5159157", "comment_content": "I like simple too.  In this case though, you iterate over the list as many times as there are nestings or levels.  Could get expensive.", "user_id": "215679"}, {"stack_answer_id": "4676482", "stack_answer_comment_id": "5176210", "comment_content": "@telliott99: You're right if your lists are really big and/or nested to great depths.  However, if that isn't the case, then the simpler solution works just as well, and without the deep magic of some of the other answers.  There is a place for multi-stage recursive generator comprehensions, but I'm not convinced that should be where you look first.  (I guess you know where I fall in the \"Worse is Better\" debate.)", "user_id": "None"}, {"stack_answer_id": "4676482", "stack_answer_comment_id": "5176316", "comment_content": "@telliott99: Or to put that another way, you won't have to \"try to Grok\" my solution.  If performance isn't a bottleneck, what matters most to you as a programmer?", "user_id": "None"}, {"stack_answer_id": "4676482", "stack_answer_comment_id": "35343606", "comment_content": "Simpler solutions have less logic. Recursion is a pretty fundamental programming construct that anyone who considers themselves a programmer should be completely comfortable with. Generators are very much the Python Way and (along with comprehensions) are something that any professional Python programmer should grok instantly.", "user_id": "None"}, {"stack_answer_id": "4676482", "stack_answer_comment_id": "35348551", "comment_content": "I agree about recursion. When I wrote my answer, python still broke recursion at 1000 cycles. Have they changed this? As for being a professional python programmer, I'm not. Moreover, I imagine many people programming in python do not do so full time.", "user_id": "None"}]}, {"stack_answer_id": "51649649", "answer_content": "\r\n When trying to answer such a question you really need to give the limitations of the code you propose as a solution. If it was only about performances I wouldn't mind too much, but most of the codes proposed as solution (including the accepted answer) fail to flatten any list that has a depth greater than 1000. \n\n When I say  most of the codes  I mean all codes that use any form of recursion (or call a standard library function that is recursive). All these codes fail because for every of the recursive call made, the (call) stack grow by one unit, and the (default) python call stack has a size of 1000.  \n\n If you're not too familiar with the call stack, then maybe the following will help (otherwise you can just scroll to the  Implementation ). \n\n Call stack size and recursive programming (dungeon analogy) \n\n Finding the treasure and exit \n\n Imagine you enter a huge  dungeon with numbered rooms , looking for a treasure. You don't know the place but you have some  indications  on how to find the treasure. Each indication is a riddle (difficulty varies, but you can't predict how hard they will be). You decide to think a little bit about a strategy to save time, you make two observations:  \n\n \n It's hard (long) to find the treasure as you'll have to solve (potentially hard) riddles to get there.  \n Once the treasure found, returning to the entrance may be easy, you just have to use the same path in the other direction (though this needs a bit of memory to recall your path).  \n \n\n When entering the dungeon, you notice a small  notebook  here. You decide to use it to write down every room you exit after solving a riddle (when entering a new room), this way you'll be able to return back to the entrance. That's a genius idea, you  won't even spend a cent  implementing your strategy. \n\n You enter the dungeon, solving with great success the first 1001 riddles, but here comes something you hadn't planed, you have no space left in the notebook you borrowed. You decide to  abandon  your quest as you prefer not having the treasure than being lost forever inside the dungeon (that looks smart indeed). \n\n Executing a recursive program \n\n Basically, it's the exact same thing as finding the treasure. The dungeon is the  computer's memory , your goal now is not to find a treasure but to  compute some function  (find  f(x)  for a given  x ). The indications simply are sub-routines that will help you solving  f(x) . Your strategy is the same as the  call stack  strategy, the notebook is the stack, the rooms are the functions' return addresses:  \n\n x = [\"over here\", \"am\", \"I\"]\ny = sorted(x) # You're about to enter a room named `sorted`, note down the current room address here so you can return back: 0x4004f4 (that room address looks weird)\n# Seems like you went back from your quest using the return address 0x4004f4\n# Let's see what you've collected \nprint(' '.join(y))\n \n\n The problem you encountered in the dungeon will be the same here, the call stack has a finite size (here 1000) and therefore, if you enter too many functions without returning back then you'll fill the call stack and have an error that look like  \"Dear adventurer, I'm very sorry but your notebook is full\" :  RecursionError: maximum recursion depth exceeded . Note that you don't need recursion to fill the call stack, but it's very unlikely that a non-recursive program call 1000 functions without ever returning. It's important to also understand that once you returned from a function, the call stack is freed from the address used (hence the name \"stack\", return address are pushed in before entering a function and pulled out when returning). In the special case of a simple recursion (a function  f  that call itself once -- over and over --) you will enter  f  over and over until the computation is finished (until the treasure is found) and return from  f  until you go back to the place where you called  f  in the first place. The call stack will never be freed from anything until the end where it will be freed from all return addresses one after the other.  \n\n How to avoid this issue? \n\n That's actually pretty simple: \"don't use recursion if you don't know how deep it can go\". That's not always true as in some cases,  Tail Call recursion can be Optimized (TCO) . But in python, this is not the case, and even \"well written\" recursive function will  not  optimize stack use. There is an interesting post from Guido about this question:  Tail Recursion Elimination . \n\n There is a technique that you can use to make any recursive function iterative, this technique we could call  bring your own notebook . For example, in our particular case we simply are exploring a list, entering a room is equivalent to entering a sublist, the question you should ask yourself is  how can I get back from a list to its parent list?  The answer is not that complex, repeat the following until the  stack  is empty: \n\n \n push the current list  address  and  index  in a  stack  when entering a new sublist (note that a list address+index is also an address, therefore we just use the exact same technique used by the call stack); \n every time an item is found,  yield  it (or add them in a list); \n once a list is fully explored, go back to the parent list using the  stack   return  address  (and  index ) . \n \n\n Also note that this is equivalent to a DFS in a tree where some nodes are sublists  A = [1, 2]  and some are simple items:  0, 1, 2, 3, 4  (for  L = [0, [1,2], 3, 4] ). The tree looks like this: \n\n                     L\n                    |\n           -------------------\n           |     |     |     |\n           0   --A--   3     4\n               |   |\n               1   2\n \n\n The DFS traversal pre-order is: L, 0, A, 1, 2, 3, 4. Remember, in order to implement an iterative DFS you also \"need\" a stack. The implementation I proposed before result in having the following states (for the  stack  and the  flat_list ):  \n\n init.:  stack=[(L, 0)]\n**0**:  stack=[(L, 0)],         flat_list=[0]\n**A**:  stack=[(L, 1), (A, 0)], flat_list=[0]\n**1**:  stack=[(L, 1), (A, 0)], flat_list=[0, 1]\n**2**:  stack=[(L, 1), (A, 1)], flat_list=[0, 1, 2]\n**3**:  stack=[(L, 2)],         flat_list=[0, 1, 2, 3]\n**3**:  stack=[(L, 3)],         flat_list=[0, 1, 2, 3, 4]\nreturn: stack=[],               flat_list=[0, 1, 2, 3, 4]\n \n\n In this example, the stack maximum size is 2, because the input list (and therefore the tree) have depth 2. \n\n Implementation \n\n For the implementation, in python you can simplify a little bit by using iterators instead of simple lists. References to the (sub)iterators will be used to store  sublists return addresses  (instead of having both the list address and the index). This is not a big difference but I feel this is more readable (and also a bit faster): \n\n def flatten(iterable):\n    return list(items_from(iterable))\n\ndef items_from(iterable):\n    cursor_stack = [iter(iterable)]\n    while cursor_stack:\n        sub_iterable = cursor_stack[-1]\n        try:\n            item = next(sub_iterable)\n        except StopIteration:   # post-order\n            cursor_stack.pop()\n            continue\n        if is_list_like(item):  # pre-order\n            cursor_stack.append(iter(item))\n        elif item is not None:\n            yield item          # in-order\n\ndef is_list_like(item):\n    return isinstance(item, list)\n \n\n Also, notice that in  is_list_like  I have  isinstance(item, list) , which could be changed to handle more input types, here I just wanted to have the simplest version where (iterable) is just a list. But you could also do that: \n\n def is_list_like(item):\n    try:\n        iter(item)\n        return not isinstance(item, str)  # strings are not lists (hmm...) \n    except TypeError:\n        return False\n \n\n This considers strings as \"simple items\" and therefore  flatten_iter([[\"test\", \"a\"], \"b])  will return  [\"test\", \"a\", \"b\"]  and not  [\"t\", \"e\", \"s\", \"t\", \"a\", \"b\"] . Remark that in that case,  iter(item)  is called twice on each item, let's pretend it's an exercise for the reader to make this cleaner.  \n\n Testing and remarks on other implementations \n\n In the end, remember that you can't print a infinitely nested list  L  using  print(L)  because internally it will use recursive calls to  __repr__  ( RecursionError: maximum recursion depth exceeded while getting the repr of an object ). For the same reason, solutions to  flatten  involving  str  will fail with the same error message.  \n\n If you need to test your solution, you can use this function to generate a simple nested list: \n\n def build_deep_list(depth):\n    \"\"\"Returns a list of the form $l_{depth} = [depth-1, l_{depth-1}]$\n    with $depth > 1$ and $l_0 = [0]$.\n    \"\"\"\n    sub_list = [0]\n    for d in range(1, depth):\n        sub_list = [d, sub_list]\n    return sub_list\n \n\n Which gives:  build_deep_list(5)  >>>  [4, [3, [2, [1, [0]]]]] . \n    ", "date_posted": "2018-08-02 10:30:05Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "1720199", "name": "cglacet", "reputation_score": "7,038"}, "answer_comments": []}, {"stack_answer_id": "36500762", "answer_content": "\r\n I didn't go through all the already available answers here, but here is a one liner I came up with, borrowing from lisp's way of first and rest list processing \n def flatten(l): return flatten(l[0]) + (flatten(l[1:]) if len(l) > 1 else []) if type(l) is list else [l]\n \n here is one simple and one not-so-simple case - \n >>> flatten([1,[2,3],4])\n[1, 2, 3, 4]\n\n>>> flatten([1, [2, 3], 4, [5, [6, {'name': 'some_name', 'age':30}, 7]], [8, 9, [10, [11, [12, [13, {'some', 'set'}, 14, [15, 'some_string'], 16], 17, 18], 19], 20], 21, 22, [23, 24], 25], 26, 27, 28, 29, 30])\n[1, 2, 3, 4, 5, 6, {'age': 30, 'name': 'some_name'}, 7, 8, 9, 10, 11, 12, 13, set(['set', 'some']), 14, 15, 'some_string', 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n>>> \n \n    ", "date_posted": "2021-06-16 03:10:18Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "3098229", "name": "Shreyas", "reputation_score": "1,204"}, "answer_comments": [{"stack_answer_id": "36500762", "stack_answer_comment_id": "83335636", "comment_content": "It's not a one liner.  No matter how much you attempt to fit it into one, the ", "user_id": "None"}, {"stack_answer_id": "36500762", "stack_answer_comment_id": "84252901", "comment_content": "I've de-one-line-ified the code, and did some further refactoring. (edit is pending peer review as I write this) This particular method seemed very readable to me, though the original code did need some refactoring.", "user_id": "None"}, {"stack_answer_id": "36500762", "stack_answer_comment_id": "120182087", "comment_content": "Please do not edit the answer. If you feel the need to \"refactor\", feel free to post as your own answer. There is a reason why the code is presented the way it is. It is to emphasise that the approach came from lisp. You can plain ignore the \"one-liner\" part of it - it was not intended as some kind of boasting. It was, again, to indicate that the thought behind it is still \"one-liner\": that of first and rest list processing.", "user_id": "None"}]}, {"stack_answer_id": "18466318", "answer_content": "\r\n Here's the  compiler.ast.flatten  implementation in 2.7.5: \n\n def flatten(seq):\n    l = []\n    for elt in seq:\n        t = type(elt)\n        if t is tuple or t is list:\n            for elt2 in flatten(elt):\n                l.append(elt2)\n        else:\n            l.append(elt)\n    return l\n \n\n There are better, faster methods (If you've reached here, you have seen them already) \n\n Also note: \n\n \n   Deprecated since version 2.6: The compiler package has been removed in Python 3. \n \n    ", "date_posted": "2013-08-27 13:05:57Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "1931274", "name": "pradyunsg", "reputation_score": "16.9k"}, "answer_comments": []}, {"stack_answer_id": "23918614", "answer_content": "\r\n totally hacky but I think it would work (depending on your data_type) \n\n flat_list = ast.literal_eval(\"[%s]\"%re.sub(\"[\\[\\]]\",\"\",str(the_list)))\n \n    ", "date_posted": "2014-05-28 17:54:20Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "541038", "name": "Joran Beasley", "reputation_score": "104k"}, "answer_comments": []}, {"stack_answer_id": "33705609", "answer_content": "\r\n I'm surprised no one has thought of this. Damn recursion I don't get the recursive answers that the advanced people here made. anyway here is my attempt on this. caveat is it's very specific to the OP's use case \n\n import re\n\nL = [[[1, 2, 3], [4, 5]], 6]\nflattened_list = re.sub(\"[\\[\\]]\", \"\", str(L)).replace(\" \", \"\").split(\",\")\nnew_list = list(map(int, flattened_list))\nprint(new_list)\n \n\n output: \n\n [1, 2, 3, 4, 5, 6]\n \n    ", "date_posted": "2015-11-14 06:28:45Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "5166790", "name": "Zion", "reputation_score": "1,480"}, "answer_comments": [{"stack_answer_id": "33705609", "stack_answer_comment_id": "113752265", "comment_content": "this only works for types (like int) which are convertible to string and back. something with the complexity of regular expressions is also not needed to tackle such a simple problem. If you want a simple solution, pradyunsg's is best.", "user_id": "None"}]}, {"stack_answer_id": "55305409", "answer_content": "\r\n Just use a  funcy  library:\n pip install funcy \n\n import funcy\n\n\nfuncy.flatten([[[[1, 1], 1], 2], 3]) # returns generator\nfuncy.lflatten([[[[1, 1], 1], 2], 3]) # returns list\n \n    ", "date_posted": "2019-05-23 13:32:02Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "55305409", "stack_answer_comment_id": "99167172", "comment_content": "FYI: it uses recursive solution: ", "user_id": "None"}]}, {"stack_answer_id": "36412443", "answer_content": "\r\n I am a dumb guy so I'll give a \"dumb\" solution. All that recursion hurts my brain. \n\n flattened_list = []\nnested_list = [[[1, 2, 3], [4, 5]], 6]\n\ndef flatten(nested_list, container):\n    for item in nested_list:\n        if isintance(item, list):\n            flatten(item, container)\n        else:\n            container.append(item)\n\n>>> flatten(nested_list, flattened_list)\n>>> flattened_list\n[1, 2, 3, 4, 5, 6]\n \n\n I get that it's using a side effect but well that's to the best of my comprehension of recursion can go \n    ", "date_posted": "2019-09-04 11:12:13Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "1879728", "name": "vlz", "reputation_score": "836"}, "answer_comments": []}, {"stack_answer_id": "7037726", "answer_content": "\r\n I don't see anything like this posted around here and just got here from a closed question on the same subject, but why not just do something like this(if you know the type of the list you want to split): \n\n >>> a = [1, 2, 3, 5, 10, [1, 25, 11, [1, 0]]]    \n>>> g = str(a).replace('[', '').replace(']', '')    \n>>> b = [int(x) for x in g.split(',') if x.strip()]\n \n\n You would need to know the type of the elements but I think this can be generalised and in terms of speed I think it would be faster. \n    ", "date_posted": "2013-07-25 17:36:51Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "977038", "name": "Abhijit", "reputation_score": "59.7k"}, "answer_comments": [{"stack_answer_id": "7037726", "stack_answer_comment_id": "14305819", "comment_content": "This is clever (and probably fast)... but it's not very pythonic.", "user_id": "None"}, {"stack_answer_id": "7037726", "stack_answer_comment_id": "16146250", "comment_content": "\"why not just do something like this\"  you say? Because it is very easy to break! Very bad idea. One example, what if your items are strings, not ints? Then if a string contains a '[' you are doomed. And what if your items have no good (or very long) string representation?", "user_id": "None"}, {"stack_answer_id": "7037726", "stack_answer_comment_id": "55183752", "comment_content": "@gb. Well what if this was what the op needed? and the example was clearly a list of ", "user_id": "None"}, {"stack_answer_id": "7037726", "stack_answer_comment_id": "55235168", "comment_content": "Well sorry, \"what ifs\" apply, careful considerations of all \"what ifs\" is the blood and guts of programming.", "user_id": "None"}]}, {"stack_answer_id": "25353058", "answer_content": "\r\n Here is another py2 approach, Im not sure if its the fastest or the most elegant nor safest ... \n\n from collections import Iterable\nfrom itertools import imap, repeat, chain\n\n\ndef flat(seqs, ignore=(int, long, float, basestring)):\n    return repeat(seqs, 1) if any(imap(isinstance, repeat(seqs), ignore)) or not isinstance(seqs, Iterable) else chain.from_iterable(imap(flat, seqs))\n \n\n It can ignore any specific (or derived) type you would like, it returns an iterator, so you can convert it to any specific container such as list, tuple, dict or simply consume it in order to reduce memory footprint, for better or worse it can handle initial non-iterable objects such as int ... \n\n Note most of the heavy lifting is done in C, since as far as I know thats how itertools are implemented, so while it is recursive, AFAIK it isn't bounded by python recursion depth since the function calls are happening in C, though this doesn't mean you are bounded by memory, specially in OS X where its stack size has a hard limit as of today (OS X Mavericks) ... \n\n there is a slightly faster approach, but less portable method, only use it if you can assume that the base elements of the input can be explicitly determined otherwise, you'll get an infinite recursion, and OS X with its limited stack size, will throw a segmentation fault fairly quickly ... \n\n def flat(seqs, ignore={int, long, float, str, unicode}):\n    return repeat(seqs, 1) if type(seqs) in ignore or not isinstance(seqs, Iterable) else chain.from_iterable(imap(flat, seqs))\n \n\n here we are using sets to check for the type so it takes O(1) vs O(number of types) to check whether or not an element should be ignored, though of course any value with derived type of the stated ignored types will fail, this is why its using  str ,  unicode  so use it with caution ... \n\n tests: \n\n import random\n\ndef test_flat(test_size=2000):\n    def increase_depth(value, depth=1):\n        for func in xrange(depth):\n            value = repeat(value, 1)\n        return value\n\n    def random_sub_chaining(nested_values):\n        for values in nested_values:\n            yield chain((values,), chain.from_iterable(imap(next, repeat(nested_values, random.randint(1, 10)))))\n\n    expected_values = zip(xrange(test_size), imap(str, xrange(test_size)))\n    nested_values = random_sub_chaining((increase_depth(value, depth) for depth, value in enumerate(expected_values)))\n    assert not any(imap(cmp, chain.from_iterable(expected_values), flat(chain(((),), nested_values, ((),)))))\n\n>>> test_flat()\n>>> list(flat([[[1, 2, 3], [4, 5]], 6]))\n[1, 2, 3, 4, 5, 6]\n>>>  \n\n$ uname -a\nDarwin Samys-MacBook-Pro.local 13.3.0 Darwin Kernel Version 13.3.0: Tue Jun  3 21:27:35 PDT 2014; root:xnu-2422.110.17~1/RELEASE_X86_64 x86_64\n$ python --version\nPython 2.7.5\n \n    ", "date_posted": "2014-08-18 16:14:38Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "1445740", "name": "Samy Vilar", "reputation_score": "10.2k"}, "answer_comments": []}, {"stack_answer_id": "27340134", "answer_content": "\r\n Without using any library: \n\n def flat(l):\n    def _flat(l, r):    \n        if type(l) is not list:\n            r.append(l)\n        else:\n            for i in l:\n                r = r + flat(i)\n        return r\n    return _flat(l, [])\n\n\n\n# example\ntest = [[1], [[2]], [3], [['a','b','c'] , [['z','x','y']], ['d','f','g']], 4]    \nprint flat(test) # prints [1, 2, 3, 'a', 'b', 'c', 'z', 'x', 'y', 'd', 'f', 'g', 4]\n \n    ", "date_posted": "2014-12-07 17:58:00Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "1057429", "name": "Nir Alfasi", "reputation_score": "52.1k"}, "answer_comments": []}, {"stack_answer_id": "28756609", "answer_content": "\r\n Using  itertools.chain : \n\n import itertools\nfrom collections import Iterable\n\ndef list_flatten(lst):\n    flat_lst = []\n    for item in itertools.chain(lst):\n        if isinstance(item, Iterable):\n            item = list_flatten(item)\n            flat_lst.extend(item)\n        else:\n            flat_lst.append(item)\n    return flat_lst\n \n\n Or without chaining: \n\n def flatten(q, final):\n    if not q:\n        return\n    if isinstance(q, list):\n        if not isinstance(q[0], list):\n            final.append(q[0])\n        else:\n            flatten(q[0], final)\n        flatten(q[1:], final)\n    else:\n        final.append(q)\n \n    ", "date_posted": "2015-05-09 22:04:16Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "4596008", "name": "Saksham Varma", "reputation_score": "2,072"}, "answer_comments": []}, {"stack_answer_id": "26130883", "answer_content": "\r\n I used recursive to solve  nested list with any depth \n\n def combine_nlist(nlist,init=0,combiner=lambda x,y: x+y):\n    '''\n    apply function: combiner to a nested list element by element(treated as flatten list)\n    '''\n    current_value=init\n    for each_item in nlist:\n        if isinstance(each_item,list):\n            current_value =combine_nlist(each_item,current_value,combiner)\n        else:\n            current_value = combiner(current_value,each_item)\n    return current_value\n \n\n So after i define function combine_nlist, it is easy to use this function do flatting. Or you can combine it into one function. I like my solution because it can be applied to any nested list. \n\n def flatten_nlist(nlist):\n    return combine_nlist(nlist,[],lambda x,y:x+[y])\n \n\n result \n\n In [379]: flatten_nlist([1,2,3,[4,5],[6],[[[7],8],9],10])\nOut[379]: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n \n    ", "date_posted": "2015-08-09 11:13:41Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "2169114", "name": "Alex Lisovoy", "reputation_score": "5,357"}, "answer_comments": [{"stack_answer_id": "26130883", "stack_answer_comment_id": "90241387", "comment_content": "\"nested list with any depth\" not true. Just try you'll see:  ", "user_id": "None"}, {"stack_answer_id": "26130883", "stack_answer_comment_id": "90247735", "comment_content": "hmmm I are you trying to flaten list with more than 1000 layers?", "user_id": "None"}, {"stack_answer_id": "26130883", "stack_answer_comment_id": "90257853", "comment_content": "Of course, that's the whole point of the discussion about recursive vs. iterative solutions. If you know in advance that the number of layers is < than 1000 then the most simple solution will work. When you say \"any depth\" this includes list with depth > 1000.", "user_id": "None"}]}, {"stack_answer_id": "34298369", "answer_content": "\r\n The easiest way is to use the  morph  library using  pip install morph . \n\n The code is: \n\n import morph\n\nlist = [[[1, 2, 3], [4, 5]], 6]\nflattened_list = morph.flatten(list)  # returns [1, 2, 3, 4, 5, 6]\n \n    ", "date_posted": "2015-12-15 20:03:50Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "2532070", "name": "YPCrumble", "reputation_score": "24.4k"}, "answer_comments": []}, {"stack_answer_id": "39835505", "answer_content": "\r\n I am aware that there are already many awesome answers but i wanted to add an answer that uses the functional programming method of solving the question. In this answer i make use of double recursion : \n\n def flatten_list(seq):\n    if not seq:\n        return []\n    elif isinstance(seq[0],list):\n        return (flatten_list(seq[0])+flatten_list(seq[1:]))\n    else:\n        return [seq[0]]+flatten_list(seq[1:])\n\nprint(flatten_list([1,2,[3,[4],5],[6,7]]))\n \n\n output: \n\n [1, 2, 3, 4, 5, 6, 7]\n \n    ", "date_posted": "2016-10-03 15:46:27Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "6797779", "name": "Leo wahyd", "reputation_score": "197"}, "answer_comments": []}, {"stack_answer_id": "43948658", "answer_content": "\r\n I'm not sure if this is necessarily quicker or more effective, but this is what I do: \n\n def flatten(lst):\n    return eval('[' + str(lst).replace('[', '').replace(']', '') + ']')\n\nL = [[[1, 2, 3], [4, 5]], 6]\nprint(flatten(L))\n \n\n The  flatten  function here turns the list into a string, takes out  all  of the square brackets, attaches square brackets back onto the ends, and turns it back into a list.  \n\n Although, if you knew you would have square brackets in your list in strings, like  [[1, 2], \"[3, 4] and [5]\"] , you would have to do something else. \n    ", "date_posted": "2017-05-13 02:32:08Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "3571147", "name": "diligar", "reputation_score": "393"}, "answer_comments": [{"stack_answer_id": "43948658", "stack_answer_comment_id": "90257931", "comment_content": "This has no advantage over the simple solution as this fails to process deep lists, ie \"RecursionError: maximum recursion depth exceeded while getting the repr of an object\".", "user_id": "None"}]}, {"stack_answer_id": "53523266", "answer_content": "\r\n This is a simple implement of flatten on python2 \n\n flatten=lambda l: reduce(lambda x,y:x+y,map(flatten,l),[]) if isinstance(l,list) else [l]\n\ntest=[[1,2,3,[3,4,5],[6,7,[8,9,[10,[11,[12,13,14]]]]]],]\nprint flatten(test)\n\n#output [1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n \n    ", "date_posted": "2018-11-28 15:48:09Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "5918696", "name": "Statham", "reputation_score": "3,818"}, "answer_comments": []}], "user": {"stack_user_id": "215679", "name": "telliott99", "reputation_score": "7,374"}, "question_comments": [{"stack_question_id": "2158395", "stack_question_comment_id": "34197359", "comment_content": "The fact that there are this many answers and so much action on this question really suggests that this should be a built-in function somewhere, right?  It's especially too bad the compiler.ast was removed from Python 3.0", "user_id": "None"}, {"stack_question_id": "2158395", "stack_question_comment_id": "47164204", "comment_content": "I would say that what Python really needs is unbroken recursion rather than another builtin.", "user_id": "None"}, {"stack_question_id": "2158395", "stack_question_comment_id": "99158509", "comment_content": "@Mittenchops: totally disagree, the fact that people working with obviously bad APIs/overly complicated data structures (just a note: ", "user_id": "None"}, {"stack_question_id": "2158395", "stack_question_comment_id": "107119718", "comment_content": "If you can afford adding a package to your project - I suppose the ", "user_id": "None"}, {"stack_question_id": "2158395", "stack_question_comment_id": "116850410", "comment_content": "@viddik13: please consider making that an answer for this question, as well.  It would absolutely get my upvote.  (I agree with Mittenchops.)  The fact that it's not a ", "user_id": "None"}]},
{"stack_question_id": "1832940", "question_title": "Why is using 'eval' a bad practice?", "question_content": "\r\n                I use the following class to easily store data of my songs.\nclass Song:\n    \"\"\"The class to store the details of each song\"\"\"\n    attsToStore=('Name', 'Artist', 'Album', '...\r\n", "question_url": "/questions/1832940/why-is-using-eval-a-bad-practice", "date_posted": "Dec 2, 2009 at 13:34", "upvote": "1", "view": "6", "tags": ["python", "eval"], "answers_count": "8", "answers": [{"stack_answer_id": "1832957", "answer_content": "\r\n Yes, using  eval  is a bad practice. Just to name a few reasons: \n \n There is almost always a better way to do it \n Very dangerous and insecure \n Makes debugging difficult \n Slow \n \n In your case you can use  setattr  instead: \n class Song:\n    \"\"\"The class to store the details of each song\"\"\"\n    attsToStore=('Name', 'Artist', 'Album', 'Genre', 'Location')\n    def __init__(self):\n        for att in self.attsToStore:\n            setattr(self, att.lower(), None)\n    def setDetail(self, key, val):\n        if key in self.attsToStore:\n            setattr(self, key.lower(), val)\n \n There are some cases where you have to use  eval  or  exec . But they are rare. Using  eval  in your case is a bad practice for sure. I'm emphasizing on bad practice because  eval  and  exec  are frequently used in the wrong place. \n Replying to the comments: \n It looks like some disagree that  eval  is 'very dangerous and insecure' in the OP case. That might be true for this specific case but not in general. The question was general and the reasons I listed are true for the general case as well. \n    ", "date_posted": "2021-02-18 10:22:36Z", "upvote": "\r\n            229\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "1832957", "stack_answer_comment_id": "1725807", "comment_content": "-1: \"Very dangerous and insecure\" is false.  The other three are outstandingly clear.  Please reorder them so that 2 and 4 are the first two.  It's only insecure if you are surrounded by evil sociopaths who are looking for ways to subvert your application.", "user_id": "None"}, {"stack_answer_id": "1832957", "stack_answer_comment_id": "1726183", "comment_content": "@S.Lott, Insecurity is a very important reason to avoid eval/exec in general. Many applications like websites should take extra care. Take the OP example in a website that expects users to enter the song name. It is bound to be exploited sooner or later. Even an innocent input like: Let's have fun. will cause a syntax error and expose the vulnerability.", "user_id": "None"}, {"stack_answer_id": "1832957", "stack_answer_comment_id": "1726811", "comment_content": "@Nadia Alramli: User input and ", "user_id": "None"}, {"stack_answer_id": "1832957", "stack_answer_comment_id": "3268287", "comment_content": "@jeffjose: Actually, ", "user_id": "None"}, {"stack_answer_id": "1832957", "stack_answer_comment_id": "8538640", "comment_content": "I'm not sure why Nadia's assertion is so contentious. It seems simple to me: eval is a vector for code injection, and is dangerous in a way that most other Python functions are not. That doesn't mean you shouldn't use it at all, but I think you should use it judiciously.", "user_id": "None"}]}, {"stack_answer_id": "1834754", "answer_content": "\r\n Using  eval  is weak, not a clearly  bad  practice. \n\n \n It violates the \"Fundamental Principle of Software\".  Your source is not the sum total of what's executable.  In addition to your source, there are the arguments to  eval , which must be clearly understood.  For this reason, it's the tool of last resort. \n It's usually a sign of thoughtless design.  There's rarely a good reason for dynamic source code, built on-the-fly.  Almost anything can be done with delegation and other OO design techniques. \n It leads to relatively slow on-the-fly compilation of small pieces of code.  An overhead which can be avoided by using better design patterns. \n \n\n As a footnote, in the hands of deranged sociopaths, it may not work out well.  However, when confronted with deranged sociopathic users or administrators, it's best to not give them interpreted Python in the first place.  In the hands of the truly evil, Python can a liability;  eval  doesn't increase the risk at all.   \n    ", "date_posted": "2009-12-02 18:08:39Z", "upvote": "\r\n            47\r\n        ", "accepted": "No", "user": {"stack_user_id": "10661", "name": "S.Lott", "reputation_score": "375k"}, "answer_comments": [{"stack_answer_id": "1834754", "stack_answer_comment_id": "8543247", "comment_content": "@Owen S. The point is this.  Folks will tell you that ", "user_id": "None"}, {"stack_answer_id": "1834754", "stack_answer_comment_id": "10920770", "comment_content": "Well, I can tell you exactly why I would say eval is a security vulnerability, and it has to do with the trustworthiness of the string it's given as input. If that string comes, in whole or in part, from the outside world, there's a possibility of a scripting attack on your program if you're not careful. But that's thge derangement of an outside attacker, not of the user or administrator.", "user_id": "None"}, {"stack_answer_id": "1834754", "stack_answer_comment_id": "10921231", "comment_content": "@OwenS.: \"If that string comes, in whole or in part, from the outside world\"  Often false.  This isn't a \"careful\" thing.  It's black and white.  If the text comes from a user, it can ", "user_id": "None"}, {"stack_answer_id": "1834754", "stack_answer_comment_id": "10925199", "comment_content": "@OwenS.: There's no possible escaping for a string of untrusted Python code that would make it trustable.  I agree with most of what you're saying except for the \"careful\" part.  It's a very crisp distinction. Code from the outside world is untrustable.  AFAIK, no amount of escaping or filtering can clean it up.  If you have some kind of escaping function that would make code acceptable, please share.  I didn't think such a thing was possible.  For example ", "user_id": "None"}, {"stack_answer_id": "1834754", "stack_answer_comment_id": "10952344", "comment_content": "@OwenS.: \"intended as a string, not arbitrary code\".  That's unrelated.  That's just a string value, which you would never pass through ", "user_id": "None"}]}, {"stack_answer_id": "37081082", "answer_content": "\r\n Yes, it is: \n\n Hack using Python: \n\n >>> eval(input())\n\"__import__('os').listdir('.')\"\n...........\n...........   #dir listing\n...........\n \n\n The below code will list all tasks running on a Windows machine. \n\n >>> eval(input())\n\"__import__('subprocess').Popen(['tasklist'],stdout=__import__('subprocess').PIPE).communicate()[0]\"\n \n\n In Linux: \n\n >>> eval(input())\n\"__import__('subprocess').Popen(['ps', 'aux'],stdout=__import__('subprocess').PIPE).communicate()[0]\"\n \n    ", "date_posted": "2016-11-21 08:17:22Z", "upvote": "\r\n            26\r\n        ", "accepted": "No", "user": {"stack_user_id": "2294755", "name": "Hackaholic", "reputation_score": "17.9k"}, "answer_comments": [{"stack_answer_id": "37081082", "stack_answer_comment_id": "127060561", "comment_content": "Why is that bad/dangerous? Can't I just execute the same Python code anyway without ", "user_id": "None"}, {"stack_answer_id": "37081082", "stack_answer_comment_id": "127949948", "comment_content": "It is dangerous because it allows for text ", "user_id": "None"}]}, {"stack_answer_id": "1832968", "answer_content": "\r\n In this case, yes. Instead of \n\n exec 'self.Foo=val'\n \n\n you should use the  builtin  function  setattr : \n\n setattr(self, 'Foo', val)\n \n    ", "date_posted": "2009-12-02 13:38:31Z", "upvote": "\r\n            23\r\n        ", "accepted": "No", "user": {"stack_user_id": "19750", "name": "Josh Lee", "reputation_score": "163k"}, "answer_comments": []}, {"stack_answer_id": "40831661", "answer_content": "\r\n Other users pointed out how your code can be changed as to not depend on  eval ; I'll offer a legitimate use-case for using  eval , one that is found even in CPython:  testing . \n\n Here's one example I found in  test_unary.py  where a test on whether  (+|-|~)b'a'  raises a  TypeError : \n\n def test_bad_types(self):\n    for op in '+', '-', '~':\n        self.assertRaises(TypeError, eval, op + \"b'a'\")\n        self.assertRaises(TypeError, eval, op + \"'a'\")\n \n\n The usage is clearly not bad practice here;  you define the input  and merely observe behavior.  eval  is handy for testing. \n\n Take a look at this search  for  eval , performed on the CPython git repository; testing with eval is heavily used. \n    ", "date_posted": "2016-11-27 17:20:00Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "4952130", "name": "Dimitris Fasarakis Hilliard", "reputation_score": "139k"}, "answer_comments": []}, {"stack_answer_id": "1834815", "answer_content": "\r\n It's worth noting that for the specific problem in question, there are several alternatives to using  eval : \n\n The simplest, as noted, is using  setattr : \n\n def __init__(self):\n    for name in attsToStore:\n        setattr(self, name, None)\n \n\n A less obvious approach is updating the object's  __dict__  object directly.  If all you want to do is initialize the attributes to  None , then this is less straightforward than the above.  But consider this: \n\n def __init__(self, **kwargs):\n    for name in self.attsToStore:\n       self.__dict__[name] = kwargs.get(name, None)\n \n\n This allows you to pass keyword arguments to the constructor, e.g.: \n\n s = Song(name='History', artist='The Verve')\n \n\n It also allows you to make your use of  locals()  more explicit, e.g.: \n\n s = Song(**locals())\n \n\n ...and, if you really want to assign  None  to the attributes whose names are found in  locals() : \n\n s = Song(**dict([(k, None) for k in locals().keys()]))\n \n\n Another approach to providing an object with default values for a list of attributes is to define the class's  __getattr__  method: \n\n def __getattr__(self, name):\n    if name in self.attsToStore:\n        return None\n    raise NameError, name\n \n\n This method gets called when the named attribute isn't found in the normal way.  This approach somewhat less straightforward than simply setting the attributes in the constructor or updating the  __dict__ , but it has the merit of not actually creating the attribute unless it exists, which can pretty substantially reduce the class's memory usage. \n\n The point of all this:  There are lots of reasons, in general, to avoid  eval  - the security problem of executing code that you don't control, the practical problem of code you can't debug, etc.  But an even more important reason is that generally, you don't need to use it.  Python exposes so much of its internal mechanisms to the programmer that you rarely really need to write code that writes code. \n    ", "date_posted": "2009-12-02 18:19:56Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "19403", "name": "Robert Rossney", "reputation_score": "92.3k"}, "answer_comments": [{"stack_answer_id": "1834815", "stack_answer_comment_id": "1727231", "comment_content": "Another way that's arguably more (or less) Pythonic: Instead of using the object's ", "user_id": "None"}, {"stack_answer_id": "1834815", "stack_answer_comment_id": "88177930", "comment_content": "\"A less obvious approach is updating the object's ", "user_id": "None"}]}, {"stack_answer_id": "50581256", "answer_content": "\r\n When  eval()  is used to process user-provided input, you enable the user to  Drop-to-REPL  providing something like this: \n\n \"__import__('code').InteractiveConsole(locals=globals()).interact()\"\n \n\n You may get away with it, but normally you don't want vectors for  arbitrary code execution  in your applications. \n    ", "date_posted": "2018-06-01 10:22:13Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "1025391", "name": "moooeeeep", "reputation_score": "30.1k"}, "answer_comments": []}, {"stack_answer_id": "53040664", "answer_content": "\r\n In addition to @Nadia Alramli answer, since I am new to Python and was eager to check how using  eval  will affect the  timings , I tried a small program and below were the observations:  \n\n #Difference while using print() with eval() and w/o eval() to print an int = 0.528969s per 100000 evals()\n\nfrom datetime import datetime\ndef strOfNos():\n    s = []\n    for x in range(100000):\n        s.append(str(x))\n    return s\n\nstrOfNos()\nprint(datetime.now())\nfor x in strOfNos():\n    print(x) #print(eval(x))\nprint(datetime.now())\n\n#when using eval(int)\n#2018-10-29 12:36:08.206022\n#2018-10-29 12:36:10.407911\n#diff = 2.201889 s\n\n#when using int only\n#2018-10-29 12:37:50.022753\n#2018-10-29 12:37:51.090045\n#diff = 1.67292\n \n    ", "date_posted": "2018-10-29 07:46:40Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "2227834", "name": "Unheilig", "reputation_score": "16k"}, "answer_comments": []}], "user": {"stack_user_id": "32001", "name": "Nikwin", "reputation_score": "6,376"}, "question_comments": [{"stack_question_id": "1832940", "stack_question_comment_id": "1725429", "comment_content": "how did you learn about ", "user_id": "None"}, {"stack_question_id": "1832940", "stack_question_comment_id": "1726037", "comment_content": "I believe it was from an article comparing python and lisp than I learned about eval.", "user_id": "32001"}, {"stack_question_id": "1832940", "stack_question_comment_id": "127949976", "comment_content": "This should have been considered as two separate questions in the first place - explaining the risk of ", "user_id": "None"}, {"stack_question_id": "1832940", "stack_question_comment_id": "127949979", "comment_content": "See also: ", "user_id": "None"}]},
{"stack_question_id": "1663807", "question_title": "How do I iterate through two lists in parallel?", "question_content": "\r\n                I have two iterables, and I want to go over them in pairs:\nfoo = [1, 2, 3]\nbar = [4, 5, 6]\n\nfor (f, b) in iterate_together(foo, bar):\n    print(\"f: \", f, \"; b: \", b)\n\nThat should ...\r\n", "question_url": "/questions/1663807/how-do-i-iterate-through-two-lists-in-parallel", "date_posted": "Nov 2, 2009 at 21:26", "upvote": "1", "view": "1", "tags": ["python", "list", "for-loop", "iterator"], "answers_count": "7", "answers": [{"stack_answer_id": "1663826", "answer_content": "\r\n Python 3 \n\n for f, b in zip(foo, bar):\n    print(f, b)\n \n\n zip  stops when the shorter of  foo  or  bar  stops. \n\n In  Python 3 ,  zip \nreturns an iterator of tuples, like  itertools.izip  in Python2.  To get a list\nof tuples, use  list(zip(foo, bar)) . And to zip until both iterators are\nexhausted, you would use\n itertools.zip_longest . \n\n Python 2 \n\n In  Python 2 ,  zip \nreturns a list of tuples. This is fine when  foo  and  bar  are not massive. If they are both massive then forming  zip(foo,bar)  is an unnecessarily massive\ntemporary variable, and should be replaced by  itertools.izip  or\n itertools.izip_longest , which returns an iterator instead of a list. \n\n import itertools\nfor f,b in itertools.izip(foo,bar):\n    print(f,b)\nfor f,b in itertools.izip_longest(foo,bar):\n    print(f,b)\n \n\n izip  stops when either  foo  or  bar  is exhausted.\n izip_longest  stops when both  foo  and  bar  are exhausted.\nWhen the shorter iterator(s) are exhausted,  izip_longest  yields a tuple with  None  in the position corresponding to that iterator. You can also set a different  fillvalue  besides  None  if you wish. See here for the  full story . \n\n \n\n Note also that  zip  and its  zip -like brethen can accept an arbitrary number of iterables as arguments. For example, \n\n for num, cheese, color in zip([1,2,3], ['manchego', 'stilton', 'brie'], \n                              ['red', 'blue', 'green']):\n    print('{} {} {}'.format(num, color, cheese))\n \n\n prints \n\n 1 red manchego\n2 blue stilton\n3 green brie\n \n    ", "date_posted": "2019-06-09 20:46:42Z", "upvote": "\r\n            1801\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "5476399", "name": "blkpingu", "reputation_score": "1,414"}, "answer_comments": [{"stack_answer_id": "1663826", "stack_answer_comment_id": "59645080", "comment_content": "@unutbu Why would I prefer OP's method over the ", "user_id": "None"}, {"stack_answer_id": "1663826", "stack_answer_comment_id": "63101672", "comment_content": "You might want to mention Python 3 first, as it's probably more future-proof. Moreover, it*s worth pointing out that in Python 3, zip() has exactly that advantage that only itertools.izip() had in Python 2 and thus it is usually the way to go.", "user_id": "None"}, {"stack_answer_id": "1663826", "stack_answer_comment_id": "64037068", "comment_content": "May I ask you to update your answer to explicitly state that ", "user_id": "None"}, {"stack_answer_id": "1663826", "stack_answer_comment_id": "85279619", "comment_content": "what if additionally I want the index ", "user_id": "None"}, {"stack_answer_id": "1663826", "stack_answer_comment_id": "85281906", "comment_content": "@CharlieParker: Yes you can, but then you would use ", "user_id": "None"}]}, {"stack_answer_id": "1663818", "answer_content": "\r\n You want the  zip  function. \n\n for (f,b) in zip(foo, bar):\n    print \"f: \", f ,\"; b: \", b\n \n    ", "date_posted": "2009-11-02 21:27:53Z", "upvote": "\r\n            84\r\n        ", "accepted": "No", "user": {"stack_user_id": "111878", "name": "Karl Guertin", "reputation_score": "4,236"}, "answer_comments": [{"stack_answer_id": "1663818", "stack_answer_comment_id": "1536594", "comment_content": "Before Python 3.0 you'd want to use ", "user_id": "None"}]}, {"stack_answer_id": "43570380", "answer_content": "\r\n You should use ' zip ' function. Here is an example how your own zip function can look like \n\n def custom_zip(seq1, seq2):\n    it1 = iter(seq1)\n    it2 = iter(seq2)\n    while True:\n        yield next(it1), next(it2)\n \n    ", "date_posted": "2017-04-23 11:09:20Z", "upvote": "\r\n            21\r\n        ", "accepted": "No", "user": {"stack_user_id": "30038", "name": "Vlad Bezden", "reputation_score": "74.9k"}, "answer_comments": [{"stack_answer_id": "43570380", "stack_answer_comment_id": "88442487", "comment_content": "Doesn't this have exactly the same result as ", "user_id": "None"}, {"stack_answer_id": "43570380", "stack_answer_comment_id": "88457150", "comment_content": "@NiklasMertsch yes it has exactly the same result. I just provided example how zip function looks like", "user_id": "None"}, {"stack_answer_id": "43570380", "stack_answer_comment_id": "116837923", "comment_content": "This is a pretty limited reinvention of ", "user_id": "None"}]}, {"stack_answer_id": "62479781", "answer_content": "\r\n Building on the answer by  @unutbu , I have compared the iteration performance of two identical lists when using Python 3.6's  zip()  functions, Python's  enumerate()  function, using a manual counter (see  count()  function), using an index-list, and during a special scenario where the elements of one of the two lists (either  foo  or  bar ) may be used to index the other list. Their performances for printing and creating a new list, respectively, were investigated using the  timeit()  function where the number of repetitions used was 1000 times. One of the Python scripts that I had created to perform these investigations is given below. The sizes of the  foo  and  bar  lists had ranged from 10 to 1,000,000 elements. \n Results: \n \n For printing purposes:  The performances of all the considered approaches were observed to be approximately similar to the  zip()  function, after factoring an accuracy tolerance of +/-5%. An exception occurred when the list size was smaller than 100 elements. In such a scenario, the index-list method was slightly slower than the  zip()  function while the  enumerate()  function was ~9% faster. The other methods yielded similar performance to the  zip()  function. \n \n \n For creating lists:  Two types of list creation approaches were explored: using the (a)  list.append()  method and (b)  list comprehension . After factoring an accuracy tolerance of +/-5%, for both of these approaches, the  zip()  function was found to perform faster than the  enumerate()  function, than using a list-index, than using a manual counter. The performance gain by the  zip()  function in these comparisons can be 5% to 60% faster. Interestingly, using the element of  foo  to index  bar  can yield equivalent or faster performances (5% to 20%) than the  zip()  function. \n \n \n \n Making sense of these results: \n A programmer has to determine the amount of compute-time per operation that is meaningful or that is of significance. \n For example, for printing purposes, if this time criterion is 1 second, i.e. 10**0 sec, then looking at the y-axis of the graph that is on the left at 1 sec and projecting it horizontally until it reaches the monomials curves, we see that lists sizes that are more than 144 elements will incur significant compute cost and significance to the programmer. That is, any performance gained by the approaches mentioned in this investigation for smaller list sizes will be insignificant to the programmer. The programmer will conclude that the performance of the  zip()  function to iterate print statements is similar to the other approaches. \n Conclusion \n Notable performance can be gained from using the  zip()  function to iterate through two lists in parallel during  list  creation. When iterating through two lists in parallel to print out the elements of the two lists, the  zip()  function will yield similar performance as the  enumerate()  function, as to using a manual counter variable, as to using an index-list, and as to during the special scenario where the elements of one of the two lists (either  foo  or  bar ) may be used to index the other list. \n The Python\u00a03.6 script that was used to investigate list creation. \n import timeit\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\ndef test_zip( foo, bar ):\n    store = []\n    for f, b in zip(foo, bar):\n        #print(f, b)\n        store.append( (f, b) )\n\ndef test_enumerate( foo, bar ):\n    store = []\n    for n, f in enumerate( foo ):\n        #print(f, bar[n])\n        store.append( (f, bar[n]) )\n\ndef test_count( foo, bar ):\n    store = []\n    count = 0\n    for f in foo:\n        #print(f, bar[count])\n        store.append( (f, bar[count]) )\n        count += 1\n\ndef test_indices( foo, bar, indices ):\n    store = []\n    for i in indices:\n        #print(foo[i], bar[i])\n        store.append( (foo[i], bar[i]) )\n\ndef test_existing_list_indices( foo, bar ):\n    store = []\n    for f in foo:\n        #print(f, bar[f])\n        store.append( (f, bar[f]) )\n\n\nlist_sizes = [ 10, 100, 1000, 10000, 100000, 1000000 ]\ntz = []\nte = []\ntc = []\nti = []\ntii= []\n\ntcz = []\ntce = []\ntci = []\ntcii= []\n\nfor a in list_sizes:\n    foo = [ i for i in range(a) ]\n    bar = [ i for i in range(a) ]\n    indices = [ i for i in range(a) ]\n    reps = 1000\n\n    tz.append( timeit.timeit( 'test_zip( foo, bar )',\n                              'from __main__ import test_zip, foo, bar',\n                              number=reps\n                              )\n               )\n    te.append( timeit.timeit( 'test_enumerate( foo, bar )',\n                              'from __main__ import test_enumerate, foo, bar',\n                              number=reps\n                              )\n               )\n    tc.append( timeit.timeit( 'test_count( foo, bar )',\n                              'from __main__ import test_count, foo, bar',\n                              number=reps\n                              )\n               )\n    ti.append( timeit.timeit( 'test_indices( foo, bar, indices )',\n                              'from __main__ import test_indices, foo, bar, indices',\n                              number=reps\n                              )\n               )\n    tii.append( timeit.timeit( 'test_existing_list_indices( foo, bar )',\n                               'from __main__ import test_existing_list_indices, foo, bar',\n                               number=reps\n                               )\n                )\n\n    tcz.append( timeit.timeit( '[(f, b) for f, b in zip(foo, bar)]',\n                               'from __main__ import foo, bar',\n                               number=reps\n                               )\n                )\n    tce.append( timeit.timeit( '[(f, bar[n]) for n, f in enumerate( foo )]',\n                               'from __main__ import foo, bar',\n                               number=reps\n                               )\n                )\n    tci.append( timeit.timeit( '[(foo[i], bar[i]) for i in indices ]',\n                               'from __main__ import foo, bar, indices',\n                               number=reps\n                               )\n                )\n    tcii.append( timeit.timeit( '[(f, bar[f]) for f in foo ]',\n                                'from __main__ import foo, bar',\n                                number=reps\n                                )\n                 )\n\nprint( f'te  = {te}' )\nprint( f'ti  = {ti}' )\nprint( f'tii = {tii}' )\nprint( f'tc  = {tc}' )\nprint( f'tz  = {tz}' )\n\nprint( f'tce  = {te}' )\nprint( f'tci  = {ti}' )\nprint( f'tcii = {tii}' )\nprint( f'tcz  = {tz}' )\n\nfig, ax = plt.subplots( 2, 2 )\nax[0,0].plot( list_sizes, te, label='enumerate()', marker='.' )\nax[0,0].plot( list_sizes, ti, label='index-list', marker='.' )\nax[0,0].plot( list_sizes, tii, label='element of foo', marker='.' )\nax[0,0].plot( list_sizes, tc, label='count()', marker='.' )\nax[0,0].plot( list_sizes, tz, label='zip()', marker='.')\nax[0,0].set_xscale('log')\nax[0,0].set_yscale('log')\nax[0,0].set_xlabel('List Size')\nax[0,0].set_ylabel('Time (s)')\nax[0,0].legend()\nax[0,0].grid( b=True, which='major', axis='both')\nax[0,0].grid( b=True, which='minor', axis='both')\n\nax[0,1].plot( list_sizes, np.array(te)/np.array(tz), label='enumerate()', marker='.' )\nax[0,1].plot( list_sizes, np.array(ti)/np.array(tz), label='index-list', marker='.' )\nax[0,1].plot( list_sizes, np.array(tii)/np.array(tz), label='element of foo', marker='.' )\nax[0,1].plot( list_sizes, np.array(tc)/np.array(tz), label='count()', marker='.' )\nax[0,1].set_xscale('log')\nax[0,1].set_xlabel('List Size')\nax[0,1].set_ylabel('Performances ( vs zip() function )')\nax[0,1].legend()\nax[0,1].grid( b=True, which='major', axis='both')\nax[0,1].grid( b=True, which='minor', axis='both')\n\nax[1,0].plot( list_sizes, tce, label='list comprehension using enumerate()',  marker='.')\nax[1,0].plot( list_sizes, tci, label='list comprehension using index-list()',  marker='.')\nax[1,0].plot( list_sizes, tcii, label='list comprehension using element of foo',  marker='.')\nax[1,0].plot( list_sizes, tcz, label='list comprehension using zip()',  marker='.')\nax[1,0].set_xscale('log')\nax[1,0].set_yscale('log')\nax[1,0].set_xlabel('List Size')\nax[1,0].set_ylabel('Time (s)')\nax[1,0].legend()\nax[1,0].grid( b=True, which='major', axis='both')\nax[1,0].grid( b=True, which='minor', axis='both')\n\nax[1,1].plot( list_sizes, np.array(tce)/np.array(tcz), label='enumerate()', marker='.' )\nax[1,1].plot( list_sizes, np.array(tci)/np.array(tcz), label='index-list', marker='.' )\nax[1,1].plot( list_sizes, np.array(tcii)/np.array(tcz), label='element of foo', marker='.' )\nax[1,1].set_xscale('log')\nax[1,1].set_xlabel('List Size')\nax[1,1].set_ylabel('Performances ( vs zip() function )')\nax[1,1].legend()\nax[1,1].grid( b=True, which='major', axis='both')\nax[1,1].grid( b=True, which='minor', axis='both')\n\nplt.show()\n \n    ", "date_posted": "2022-05-20 12:16:57Z", "upvote": "\r\n            15\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "62479781", "stack_answer_comment_id": "110540746", "comment_content": "Almost all the time is taken by printing in your ", "user_id": "None"}, {"stack_answer_id": "62479781", "stack_answer_comment_id": "110548548", "comment_content": "@user2357112supportsMonica Agree. For printing, the iteration performance is determined by the slow system I/O operations, hence is insensitive to the performance of the ", "user_id": "None"}]}, {"stack_answer_id": "60842028", "answer_content": "\r\n You can bundle the nth elements into a tuple or list using comprehension, then pass them out with a generator function. \n\n def iterate_multi(*lists):\n    for i in range(min(map(len,lists))):\n        yield tuple(l[i] for l in lists)\n\nfor l1, l2, l3 in iterate_multi([1,2,3],[4,5,6],[7,8,9]):\n    print(str(l1)+\",\"+str(l2)+\",\"+str(l3))\n \n    ", "date_posted": "2020-03-25 02:07:46Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "11547701", "name": "Don F", "reputation_score": "111"}, "answer_comments": []}, {"stack_answer_id": "57718165", "answer_content": "\r\n Here's how to do it with a  list comprehension : \n a = (1, 2, 3)\nb = (4, 5, 6)\n[print('f:', i, '; b', j) for i, j in zip(a, b)]\n \n It prints: \n f: 1 ; b 4\nf: 2 ; b 5\nf: 3 ; b 6\n \n    ", "date_posted": "2022-05-20 12:35:08Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "57718165", "stack_answer_comment_id": "101953804", "comment_content": " ", "user_id": "None"}]}, {"stack_answer_id": "68533514", "answer_content": "\r\n We can just use an index to iterate... \n foo = ['a', 'b', 'c']\nbar = [10, 20, 30]\nfor indx, itm in enumerate(foo):\n    print (foo[indx], bar[indx])\n \n    ", "date_posted": "2022-05-20 12:15:44Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "68533514", "stack_answer_comment_id": "125562360", "comment_content": "Why use ", "user_id": "None"}]}], "user": {"stack_user_id": "1084", "name": "Nathan Fellman", "reputation_score": "118k"}, "question_comments": []},
{"stack_question_id": "17778372", "question_title": "Why does my recursive function return None?", "question_content": "\r\n                I have this function that calls itself:\n\ndef get_input():\n    my_var = input('Enter \"a\" or \"b\": ')\n\n    if my_var != \"a\" and my_var != \"b\":\n        print('You didn\\'t type \"a\" or \"b\". Try again.')\n    ...\r\n", "question_url": "/questions/17778372/why-does-my-recursive-function-return-none", "date_posted": "Jul 22, 2013 at 0:29", "upvote": "9", "view": "1", "tags": ["python", "function", "recursion", "return"], "answers_count": "4", "answers": [{"stack_answer_id": "17778390", "answer_content": "\r\n It is returning  None  because when you recursively call it: \n if my_var != \"a\" and my_var != \"b\":\n    print('You didn\\'t type \"a\" or \"b\". Try again.')\n    get_input()\n \n ..you don't return the value. \n So while the recursion does happen, the return value gets discarded, and then you fall off the end of the function.  Falling off the end of the function means that python implicitly returns  None , just like this: \n >>> def f(x):\n...     pass\n>>> print(f(20))\nNone\n \n So, instead of just  calling   get_input()  in your  if  statement, you need to  return  it: \n if my_var != \"a\" and my_var != \"b\":\n    print('You didn\\'t type \"a\" or \"b\". Try again.')\n    return get_input()\n \n    ", "date_posted": "2020-07-04 15:08:23Z", "upvote": "\r\n            129\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "2581969", "name": "roippi", "reputation_score": "24.9k"}, "answer_comments": [{"stack_answer_id": "17778390", "stack_answer_comment_id": "25931174", "comment_content": "Shouldn't it run through the if statement again if it is called recursively? I don't understand why it wouldn't return a value.", "user_id": "2605186"}, {"stack_answer_id": "17778390", "stack_answer_comment_id": "25931214", "comment_content": "Nope.  See my edit.  The recursion happens, and then you discard what the recursion returns.", "user_id": "None"}, {"stack_answer_id": "17778390", "stack_answer_comment_id": "25931366", "comment_content": "You lost me with that ", "user_id": "None"}, {"stack_answer_id": "17778390", "stack_answer_comment_id": "61202878", "comment_content": "Use return for recursive function in order to put its value into the stack , so that when function will do recursion values from the stack are taken one by one. If you don't use return , the stack will collect only \"None\"  values.", "user_id": "None"}, {"stack_answer_id": "17778390", "stack_answer_comment_id": "99673988", "comment_content": "you, sir, are a genius! That was not intuitive to me.", "user_id": "None"}]}, {"stack_answer_id": "17778402", "answer_content": "\r\n To return a value other than None, you need to use a return statement. \n\n In your case, the if block only executes a return when executing one branch. Either move the return outside of the if/else block, or have returns in both options. \n    ", "date_posted": "2013-07-22 00:32:48Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "2605206", "name": "Simon", "reputation_score": "121"}, "answer_comments": [{"stack_answer_id": "17778402", "stack_answer_comment_id": "25931232", "comment_content": "I've tried moving it out of the block, but to no avail.  Instead of returning the correct value, it returns the first incorrect value.  Also, I don't want a return statement for the if part of the if/else statement because I want the function to only return a correct value.", "user_id": "2605186"}]}, {"stack_answer_id": "37287846", "answer_content": "\r\n def get_input():\n    my_var = input('Enter \"a\" or \"b\": ')\n\n    if my_var != \"a\" and my_var != \"b\":\n        print('You didn\\'t type \"a\" or \"b\". Try again.')\n        return get_input()\n    else:\n        return my_var\n\nprint('got input:', get_input())\n \n    ", "date_posted": "2019-03-23 11:02:31Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "1222951", "name": "Aran-Fey", "reputation_score": "36.4k"}, "answer_comments": []}, {"stack_answer_id": "62835013", "answer_content": "\r\n i think this code more clearly \n def get_input():\n    my_var = str(input('Enter \"a\" or \"b\": '))\n    if my_var == \"a\" or my_var == \"b\":\n        print('got input:', my_var)\n        return my_var\n    else:\n        print('You didn\\'t type \"a\" or \"b\". Try again.')\n        return get_input()\nget_input()\n \n    ", "date_posted": "2020-07-13 18:32:56Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "13905960", "name": "O\u011fuzhan \u00c7etinkaya", "reputation_score": "1"}, "answer_comments": [{"stack_answer_id": "62835013", "stack_answer_comment_id": "117104452", "comment_content": "@SergeyShubin how you think this code differs from the one by user6348168. I feel both are the same.", "user_id": "None"}, {"stack_answer_id": "62835013", "stack_answer_comment_id": "117109344", "comment_content": "@jiten the code was changed after my comment so it is no longer relevant. I think I should delete it", "user_id": "None"}]}], "user": {"stack_user_id": "2605186", "name": "Cate", "reputation_score": "1,067"}, "question_comments": [{"stack_question_id": "17778372", "stack_question_comment_id": "25931124", "comment_content": "You need to do ", "user_id": "None"}, {"stack_question_id": "17778372", "stack_question_comment_id": "62101851", "comment_content": "Just a tip: The idiomatic way of that ", "user_id": "None"}, {"stack_question_id": "17778372", "stack_question_comment_id": "118974420", "comment_content": "@gonz not necessarily. Now you're hitting the heap allocating a tuple just to do a simple comparison. Could be painful in a critical path and it's not much more readable, really.", "user_id": "None"}, {"stack_question_id": "17778372", "stack_question_comment_id": "129519448", "comment_content": "This is a simple example of recursion for demonstration purposes; but in case you actually need to do this task, a ", "user_id": "None"}]},
{"stack_question_id": "231767", "question_title": "What does the \"yield\" keyword do?", "question_content": "\r\n                What is the use of the yield keyword in Python? What does it do?\nFor example, I'm trying to understand this code1:\ndef _get_child_candidates(self, distance, min_dist, max_dist):\n    if self._leftchild ...\r\n", "question_url": "/questions/231767/what-does-the-yield-keyword-do", "date_posted": "Oct 23, 2008 at 22:21", "upvote": "1", "view": "3", "tags": ["python", "iterator", "generator"], "answers_count": "4", "answers": [{"stack_answer_id": "231855", "answer_content": "\r\n To understand what  yield  does, you must understand what  generators  are. And before you can understand generators, you must understand  iterables . \n Iterables \n When you create a list, you can read its items one by one. Reading its items one by one is called iteration: \n >>> mylist = [1, 2, 3]\n>>> for i in mylist:\n...    print(i)\n1\n2\n3\n \n mylist  is an  iterable . When you use a list comprehension, you create a list, and so an iterable: \n >>> mylist = [x*x for x in range(3)]\n>>> for i in mylist:\n...    print(i)\n0\n1\n4\n \n Everything you can use \" for... in... \" on is an iterable;  lists ,  strings , files... \n These iterables are handy because you can read them as much as you wish, but you store all the values in memory and this is not always what you want when you have a lot of values. \n Generators \n Generators are iterators, a kind of iterable  you can only iterate over once . Generators do not store all the values in memory,  they generate the values on the fly : \n >>> mygenerator = (x*x for x in range(3))\n>>> for i in mygenerator:\n...    print(i)\n0\n1\n4\n \n It is just the same except you used  ()  instead of  [] . BUT, you  cannot  perform  for i in mygenerator  a second time since generators can only be used once: they calculate 0, then forget about it and calculate 1, and end calculating 4, one by one. \n Yield \n yield  is a keyword that is used like  return , except the function will return a generator. \n >>> def create_generator():\n...    mylist = range(3)\n...    for i in mylist:\n...        yield i*i\n...\n>>> mygenerator = create_generator() # create a generator\n>>> print(mygenerator) # mygenerator is an object!\n<generator object create_generator at 0xb7555c34>\n>>> for i in mygenerator:\n...     print(i)\n0\n1\n4\n \n Here it's a useless example, but it's handy when you know your function will return a huge set of values that you will only need to read once. \n To master  yield , you must understand that  when you call the function, the code you have written in the function body does not run.  The function only returns the generator object, this is a bit tricky. \n Then, your code will continue from where it left off each time  for  uses the generator. \n Now the hard part: \n The first time the  for  calls the generator object created from your function, it will run the code in your function from the beginning until it hits  yield , then it'll return the first value of the loop. Then, each subsequent call will run another iteration of the loop you have written in the function and return the next value. This will continue until the generator is considered empty, which happens when the function runs without hitting  yield . That can be because the loop has come to an end, or because you no longer satisfy an  \"if/else\" . \n \n Your code explained \n Generator: \n # Here you create the method of the node object that will return the generator\ndef _get_child_candidates(self, distance, min_dist, max_dist):\n\n    # Here is the code that will be called each time you use the generator object:\n\n    # If there is still a child of the node object on its left\n    # AND if the distance is ok, return the next child\n    if self._leftchild and distance - max_dist < self._median:\n        yield self._leftchild\n\n    # If there is still a child of the node object on its right\n    # AND if the distance is ok, return the next child\n    if self._rightchild and distance + max_dist >= self._median:\n        yield self._rightchild\n\n    # If the function arrives here, the generator will be considered empty\n    # there is no more than two values: the left and the right children\n \n Caller: \n # Create an empty list and a list with the current object reference\nresult, candidates = list(), [self]\n\n# Loop on candidates (they contain only one element at the beginning)\nwhile candidates:\n\n    # Get the last candidate and remove it from the list\n    node = candidates.pop()\n\n    # Get the distance between obj and the candidate\n    distance = node._get_dist(obj)\n\n    # If distance is ok, then you can fill the result\n    if distance <= max_dist and distance >= min_dist:\n        result.extend(node._values)\n\n    # Add the children of the candidate in the candidate's list\n    # so the loop will keep running until it will have looked\n    # at all the children of the children of the children, etc. of the candidate\n    candidates.extend(node._get_child_candidates(distance, min_dist, max_dist))\n\nreturn result\n \n This code contains several smart parts: \n \n The loop iterates on a list, but the list expands while the loop is being iterated. It's a concise way to go through all these nested data even if it's a bit dangerous since you can end up with an infinite loop. In this case,  candidates.extend(node._get_child_candidates(distance, min_dist, max_dist))  exhaust all the values of the generator, but  while  keeps creating new generator objects which will produce different values from the previous ones since it's not applied on the same node. \n \n The  extend()  method is a list object method that expects an iterable and adds its values to the list. \n \n \n Usually we pass a list to it: \n >>> a = [1, 2]\n>>> b = [3, 4]\n>>> a.extend(b)\n>>> print(a)\n[1, 2, 3, 4]\n \n But in your code, it gets a generator, which is good because: \n \n You don't need to read the values twice. \n You may have a lot of children and you don't want them all stored in memory. \n \n And it works because Python does not care if the argument of a method is a list or not. Python expects iterables so it will work with strings, lists, tuples, and generators! This is called duck typing and is one of the reasons why Python is so cool. But this is another story, for another question... \n You can stop here, or read a little bit to see an advanced use of a generator: \n Controlling a generator exhaustion \n >>> class Bank(): # Let's create a bank, building ATMs\n...    crisis = False\n...    def create_atm(self):\n...        while not self.crisis:\n...            yield \"$100\"\n>>> hsbc = Bank() # When everything's ok the ATM gives you as much as you want\n>>> corner_street_atm = hsbc.create_atm()\n>>> print(corner_street_atm.next())\n$100\n>>> print(corner_street_atm.next())\n$100\n>>> print([corner_street_atm.next() for cash in range(5)])\n['$100', '$100', '$100', '$100', '$100']\n>>> hsbc.crisis = True # Crisis is coming, no more money!\n>>> print(corner_street_atm.next())\n<type 'exceptions.StopIteration'>\n>>> wall_street_atm = hsbc.create_atm() # It's even true for new ATMs\n>>> print(wall_street_atm.next())\n<type 'exceptions.StopIteration'>\n>>> hsbc.crisis = False # The trouble is, even post-crisis the ATM remains empty\n>>> print(corner_street_atm.next())\n<type 'exceptions.StopIteration'>\n>>> brand_new_atm = hsbc.create_atm() # Build a new one to get back in business\n>>> for cash in brand_new_atm:\n...    print cash\n$100\n$100\n$100\n$100\n$100\n$100\n$100\n$100\n$100\n...\n \n Note:  For Python 3, use print(corner_street_atm.__next__())  or  print(next(corner_street_atm)) \n It can be useful for various things like controlling access to a resource. \n Itertools, your best friend \n The itertools module contains special functions to manipulate iterables. Ever wish to duplicate a generator?\nChain two generators? Group values in a nested list with a one-liner?  Map / Zip  without creating another list? \n Then just  import itertools . \n An example? Let's see the possible orders of arrival for a four-horse race: \n >>> horses = [1, 2, 3, 4]\n>>> races = itertools.permutations(horses)\n>>> print(races)\n<itertools.permutations object at 0xb754f1dc>\n>>> print(list(itertools.permutations(horses)))\n[(1, 2, 3, 4),\n (1, 2, 4, 3),\n (1, 3, 2, 4),\n (1, 3, 4, 2),\n (1, 4, 2, 3),\n (1, 4, 3, 2),\n (2, 1, 3, 4),\n (2, 1, 4, 3),\n (2, 3, 1, 4),\n (2, 3, 4, 1),\n (2, 4, 1, 3),\n (2, 4, 3, 1),\n (3, 1, 2, 4),\n (3, 1, 4, 2),\n (3, 2, 1, 4),\n (3, 2, 4, 1),\n (3, 4, 1, 2),\n (3, 4, 2, 1),\n (4, 1, 2, 3),\n (4, 1, 3, 2),\n (4, 2, 1, 3),\n (4, 2, 3, 1),\n (4, 3, 1, 2),\n (4, 3, 2, 1)]\n \n Understanding the inner mechanisms of iteration \n Iteration is a process implying iterables (implementing the  __iter__()  method) and iterators (implementing the  __next__()  method).\nIterables are any objects you can get an iterator from. Iterators are objects that let you iterate on iterables. \n There is more about it in this article about  how  for  loops work . \n    ", "date_posted": "2021-03-07 12:59:37Z", "upvote": "\r\n            17179\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "4298200", "name": "Neuron", "reputation_score": "4,509"}, "answer_comments": [{"stack_answer_id": "231855", "stack_answer_comment_id": "75308701", "comment_content": " is not as magical this answer suggests. When you call a function that contains a ", "user_id": "None"}, {"stack_answer_id": "231855", "stack_answer_comment_id": "84633217", "comment_content": "\"These iterables are handy... but you store all the values in memory and this is not always what you want\", is either wrong or confusing. An iterable returns an iterator upon calling the iter() on the iterable, and an iterator doesn't always have to store its values in memory, depending on the implementation of the ", "user_id": "None"}, {"stack_answer_id": "231855", "stack_answer_comment_id": "109059326", "comment_content": "It would be nice to add to this ", "user_id": "None"}, {"stack_answer_id": "231855", "stack_answer_comment_id": "110055463", "comment_content": "@MatthiasFripp \"This continues until the function runs off the end\" -- or it encounters a ", "user_id": "None"}, {"stack_answer_id": "231855", "stack_answer_comment_id": "115124375", "comment_content": "The yield statement suspends function\u2019s execution and sends a value back to the caller, but retains enough state to enable function to resume where it is left off. When resumed, the function continues execution immediately after the last yield run. This allows its code to produce a series of values over time, rather than computing them at once and sending them back like a list.", "user_id": "None"}]}, {"stack_answer_id": "237028", "answer_content": "\r\n Shortcut to understanding  yield \n\n When you see a function with  yield  statements, apply this easy trick to understand what will happen: \n\n \n Insert a line  result = []  at the start of the function. \n Replace each  yield expr  with  result.append(expr) . \n Insert a line  return result  at the bottom of the function. \n Yay - no more  yield  statements! Read and figure out code. \n Compare function to the original definition. \n \n\n This trick may give you an idea of the logic behind the function, but what actually happens with  yield  is significantly different than what happens in the list based approach. In many cases, the yield approach will be a lot more memory efficient and faster too. In other cases, this trick will get you stuck in an infinite loop, even though the original function works just fine. Read on to learn more... \n\n Don't confuse your Iterables, Iterators, and Generators \n\n First, the  iterator protocol  - when you write \n\n for x in mylist:\n    ...loop body...\n \n\n Python performs the following two steps: \n\n \n Gets an iterator for  mylist : \n\n Call  iter(mylist)  -> this returns an object with a  next()  method (or  __next__()  in Python 3). \n\n [This is the step most people forget to tell you about] \n Uses the iterator to loop over items: \n\n Keep calling the  next()  method on the iterator returned from step 1. The return value from  next()  is assigned to  x  and the loop body is executed. If an exception  StopIteration  is raised from within  next() , it means there are no more values in the iterator and the loop is exited. \n \n\n The truth is Python performs the above two steps anytime it wants to  loop over  the contents of an object - so it could be a for loop, but it could also be code like  otherlist.extend(mylist)  (where  otherlist  is a Python list). \n\n Here  mylist  is an  iterable  because it implements the iterator protocol. In a user-defined class, you can implement the  __iter__()  method to make instances of your class iterable. This method should return an  iterator . An iterator is an object with a  next()  method. It is possible to implement both  __iter__()  and  next()  on the same class, and have  __iter__()  return  self . This will work for simple cases, but not when you want two iterators looping over the same object at the same time. \n\n So that's the iterator protocol, many objects implement this protocol: \n\n \n Built-in lists, dictionaries, tuples, sets, files. \n User-defined classes that implement  __iter__() . \n Generators. \n \n\n Note that a  for  loop doesn't know what kind of object it's dealing with - it just follows the iterator protocol, and is happy to get item after item as it calls  next() . Built-in lists return their items one by one, dictionaries return the  keys  one by one, files return the  lines  one by one, etc. And generators return... well that's where  yield  comes in: \n\n def f123():\n    yield 1\n    yield 2\n    yield 3\n\nfor item in f123():\n    print item\n \n\n Instead of  yield  statements, if you had three  return  statements in  f123()  only the first would get executed, and the function would exit. But  f123()  is no ordinary function. When  f123()  is called, it  does not  return any of the values in the yield statements! It returns a generator object. Also, the function does not really exit - it goes into a suspended state. When the  for  loop tries to loop over the generator object, the function resumes from its suspended state at the very next line after the  yield  it previously returned from, executes the next line of code, in this case, a  yield  statement, and returns that as the next item. This happens until the function exits, at which point the generator raises  StopIteration , and the loop exits.  \n\n So the generator object is sort of like an adapter - at one end it exhibits the iterator protocol, by exposing  __iter__()  and  next()  methods to keep the  for  loop happy. At the other end, however, it runs the function just enough to get the next value out of it, and puts it back in suspended mode. \n\n Why Use Generators? \n\n Usually, you can write code that doesn't use generators but implements the same logic. One option is to use the temporary list 'trick' I mentioned before. That will not work in all cases, for e.g. if you have infinite loops, or it may make inefficient use of memory when you have a really long list. The other approach is to implement a new iterable class SomethingIter that keeps the state in instance members and performs the next logical step in it's  next()  (or  __next__()  in Python 3) method. Depending on the logic, the code inside the  next()  method may end up looking very complex and be prone to bugs. Here generators provide a clean and easy solution. \n    ", "date_posted": "2020-05-13 12:29:46Z", "upvote": "\r\n            2388\r\n        ", "accepted": "No", "user": {"stack_user_id": "13184566", "name": "nzz", "reputation_score": "5"}, "answer_comments": [{"stack_answer_id": "237028", "stack_answer_comment_id": "76206780", "comment_content": " Doesn't this completely ignore the fact that you can ", "user_id": "None"}, {"stack_answer_id": "237028", "stack_answer_comment_id": "79407236", "comment_content": "\"it could be a for loop, but it could also be code like ", "user_id": "None"}, {"stack_answer_id": "237028", "stack_answer_comment_id": "82933650", "comment_content": "@pedro You have misunderstood that sentence. It means that python performs the two mentioned steps on ", "user_id": "None"}]}, {"stack_answer_id": "231801", "answer_content": "\r\n Think of it this way: \n\n An iterator is just a fancy sounding term for an object that has a  next()  method.  So a yield-ed function ends up being something like this: \n\n Original version: \n\n def some_function():\n    for i in xrange(4):\n        yield i\n\nfor i in some_function():\n    print i\n \n\n This is basically what the Python interpreter does with the above code: \n\n class it:\n    def __init__(self):\n        # Start at -1 so that we get 0 when we add 1 below.\n        self.count = -1\n\n    # The __iter__ method will be called once by the 'for' loop.\n    # The rest of the magic happens on the object returned by this method.\n    # In this case it is the object itself.\n    def __iter__(self):\n        return self\n\n    # The next method will be called repeatedly by the 'for' loop\n    # until it raises StopIteration.\n    def next(self):\n        self.count += 1\n        if self.count < 4:\n            return self.count\n        else:\n            # A StopIteration exception is raised\n            # to signal that the iterator is done.\n            # This is caught implicitly by the 'for' loop.\n            raise StopIteration\n\ndef some_func():\n    return it()\n\nfor i in some_func():\n    print i\n \n\n For more insight as to what's happening behind the scenes, the  for  loop can be rewritten to this: \n\n iterator = some_func()\ntry:\n    while 1:\n        print iterator.next()\nexcept StopIteration:\n    pass\n \n\n Does that make more sense or just confuse you more?  :) \n\n I should note that this  is  an oversimplification for illustrative purposes. :) \n    ", "date_posted": "2019-05-07 13:28:35Z", "upvote": "\r\n            708\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "231801", "stack_answer_comment_id": "100409", "comment_content": " could be defined instead of ", "user_id": "None"}, {"stack_answer_id": "231801", "stack_answer_comment_id": "74681581", "comment_content": "I tried this example in Python 3.6 and if I create ", "user_id": "None"}, {"stack_answer_id": "231801", "stack_answer_comment_id": "109209205", "comment_content": "Where does the ", "user_id": "None"}, {"stack_answer_id": "231801", "stack_answer_comment_id": "113829987", "comment_content": "Unfortunately this answer is not true at all. This is not what python interpreter does with generators. It is not creating a class starting from the generator function and implement ", "user_id": "None"}]}, {"stack_answer_id": "6400990", "answer_content": "\r\n\n The  yield  keyword is reduced to two simple facts: \n \n If the compiler detects the  yield  keyword  anywhere  inside a function, that function no longer returns via the  return  statement.  Instead , it  immediately  returns a  lazy \"pending list\" object  called a generator \n A generator is iterable. What is an  iterable ? It's anything like a  list  or  set  or  range  or dict-view, with a  built-in protocol for visiting each element in a certain order . \n \n In a nutshell: Most commonly,  a generator is a lazy, incrementally-pending list , and  yield  statements allow you to use function notation to program the list values  the generator should incrementally spit out.  Furthermore, advanced usage lets you use generators as coroutines (see below). \n generator = myYieldingFunction(...)  # basically a list (but lazy)\nx = list(generator)  # evaluate every element into a list\n\n   generator\n       v\n[x[0], ..., ???]\n\n         generator\n             v\n[x[0], x[1], ..., ???]\n\n               generator\n                   v\n[x[0], x[1], x[2], ..., ???]\n\n                       StopIteration exception\n[x[0], x[1], x[2]]     done\n \n Basically, whenever the  yield  statement is encountered, the function pauses and saves its state, then emits \"the next return value in the 'list'\" according to the python iterator protocol (to some syntactic construct like a for-loop that repeatedly calls  next()  and catches a  StopIteration  exception, etc.). You might have encountered generators with  generator expressions ; generator functions are more powerful because you can pass arguments back into the paused generator function, using them to implement coroutines. More on that later. \n \n Basic Example ('list') \n Let's define a function  makeRange  that's just like Python's  range . Calling  makeRange(n)  RETURNS A GENERATOR: \n def makeRange(n):\n    # return 0,1,2,...,n-1\n    i = 0\n    while i < n:\n        yield i\n        i += 1\n\n>>> makeRange(5)\n<generator object makeRange at 0x19e4aa0>\n \n To force the generator to immediately return its pending values, you can pass it into  list()  (just like you could any iterable): \n >>> list(makeRange(5))\n[0, 1, 2, 3, 4]\n \n \n Comparing example to \"just returning a list\" \n The above example can be thought of as merely creating a list which you append to and return: \n # return a list                  #  # return a generator\ndef makeRange(n):                #  def makeRange(n):\n    \"\"\"return [0,1,2,...,n-1]\"\"\" #      \"\"\"return 0,1,2,...,n-1\"\"\"\n    TO_RETURN = []               # \n    i = 0                        #      i = 0\n    while i < n:                 #      while i < n:\n        TO_RETURN += [i]         #          yield i\n        i += 1                   #          i += 1\n    return TO_RETURN             # \n\n>>> makeRange(5)\n[0, 1, 2, 3, 4]\n \n There is one major difference, though; see the last section. \n \n How you might use generators \n An iterable is the last part of a list comprehension, and all generators are iterable, so they're often used like so: \n #                  < ITERABLE >\n>>> [x+10 for x in makeRange(5)]\n[10, 11, 12, 13, 14]\n \n To get a better feel for generators, you can play around with the  itertools  module (be sure to use  chain.from_iterable  rather than  chain  when warranted). For example, you might even use generators to implement infinitely-long lazy lists like  itertools.count() . You could implement your own  def enumerate(iterable): zip(count(), iterable) , or alternatively do so with the  yield  keyword in a while-loop. \n Please note: generators can actually be used for many more things, such as  implementing coroutines  or non-deterministic programming or other elegant things. However, the \"lazy lists\" viewpoint I present here is the most common use you will find. \n \n Behind the scenes \n This is how the \"Python iteration protocol\" works. That is, what is going on when you do  list(makeRange(5)) . This is what I describe earlier as a \"lazy, incremental list\". \n >>> x=iter(range(5))\n>>> next(x)  # calls x.__next__(); x.next() is deprecated\n0\n>>> next(x)\n1\n>>> next(x)\n2\n>>> next(x)\n3\n>>> next(x)\n4\n>>> next(x)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nStopIteration\n \n The built-in function  next()  just calls the objects  .__next__()  function, which is a part of the \"iteration protocol\" and is found on all iterators. You can manually use the  next()  function (and other parts of the iteration protocol) to implement fancy things, usually at the expense of readability, so try to avoid doing that... \n \n Coroutines \n Coroutine  example: \n def interactiveProcedure():\n    userResponse = yield makeQuestionWebpage()\n    print('user response:', userResponse)\n    yield 'success'\n\ncoroutine = interactiveProcedure()\nwebFormData = next(coroutine)  # same as .send(None)\nuserResponse = serveWebForm(webFormData)\n\n# ...at some point later on web form submit...\n\nsuccessStatus = coroutine.send(userResponse)\n \n A coroutine (generators which generally accept input via the  yield  keyword e.g.  nextInput = yield nextOutput , as a form of two-way communication) is basically a computation which is allowed to pause itself and request input (e.g. to what it should do next). When the coroutine pauses itself (when the running coroutine's eventually hits a  yield  keyword), the computation is paused and control is inverted (yielded) back to the 'calling' function (the frame which requested the  next  value of the computation). The paused generator/coroutine remains paused until another invoking function (possibly a different function/context) requests the next value to unpause it (usually passing input data to direct the paused logic interior to the coroutine's code). \n You can think of python coroutines as lazy incrementally-pending lists, where the next element doesn't just depend on the previous computation, but also on input you may opt to inject during the generation process. \n \n Minutiae \n Normally, most people would not care about the following distinctions and probably want to stop reading here. \n In Python-speak, an  iterable  is any object which \"understands the concept of a for-loop\" like a list  [1,2,3] , and an  iterator  is a specific instance of the requested for-loop like  [1,2,3].__iter__() . A  generator  is exactly the same as any iterator, except for the way it was written (with function syntax). \n When you request an iterator from a list, it creates a new iterator. However, when you request an iterator from an iterator (which you would rarely do), it just gives you a copy of itself. \n Thus, in the unlikely event that you are failing to do something like this... \n > x = myRange(5)\n> list(x)\n[0, 1, 2, 3, 4]\n> list(x)\n[]\n \n ... then remember that a generator is an  iterator ; that is, it is one-time-use. If you want to reuse it, you should call  myRange(...)  again. If you need to use the result twice, convert the result to a list and store it in a variable  x = list(myRange(5)) . Those who absolutely need to clone a generator (for example, who are doing terrifyingly hackish metaprogramming) can use  itertools.tee  ( still works in Python 3 ) if absolutely necessary, since the  copyable iterator Python PEP standards proposal  has been deferred. \n    ", "date_posted": "2022-08-18 13:50:45Z", "upvote": "\r\n            593\r\n        ", "accepted": "No", "user": {"stack_user_id": "711085", "name": "ninjagecko", "reputation_score": "84.7k"}, "answer_comments": []}, {"stack_answer_id": "31042491", "answer_content": "\r\n \n What does the  yield  keyword do in Python? \n \n Answer Outline/Summary \n \n A function with  yield , when called,  returns a  Generator . \n Generators are iterators because they implement the  iterator protocol , so you can iterate over them. \n A generator can also be  sent information , making it conceptually a  coroutine . \n In Python 3, you can  delegate  from one generator to another in both directions with  yield from . \n (Appendix critiques a couple of answers, including the top one, and discusses the use of  return  in a generator.) \n \n Generators: \n yield  is only legal inside of a function definition, and  the inclusion of  yield  in a function definition makes it return a generator. \n The idea for generators comes from other languages (see footnote 1) with varying implementations. In Python's Generators, the execution of the code is  frozen  at the point of the yield. When the generator is called (methods are discussed below) execution resumes and then freezes at the next yield. \n yield  provides an\neasy way of  implementing the iterator protocol , defined by the following two methods:\n __iter__  and  next  (Python 2) or  __next__  (Python 3).  Both of those methods\nmake an object an iterator that you could type-check with the  Iterator  Abstract Base\nClass from the  collections  module. \n >>> def func():\n...     yield 'I am'\n...     yield 'a generator!'\n... \n>>> type(func)                 # A function with yield is still a function\n<type 'function'>\n>>> gen = func()\n>>> type(gen)                  # but it returns a generator\n<type 'generator'>\n>>> hasattr(gen, '__iter__')   # that's an iterable\nTrue\n>>> hasattr(gen, 'next')       # and with .next (.__next__ in Python 3)\nTrue                           # implements the iterator protocol.\n \n The generator type is a sub-type of iterator: \n >>> import collections, types\n>>> issubclass(types.GeneratorType, collections.Iterator)\nTrue\n \n And if necessary, we can type-check like this: \n >>> isinstance(gen, types.GeneratorType)\nTrue\n>>> isinstance(gen, collections.Iterator)\nTrue\n \n A feature of an  Iterator   is that once exhausted , you can't reuse or reset it: \n >>> list(gen)\n['I am', 'a generator!']\n>>> list(gen)\n[]\n \n You'll have to make another if you want to use its functionality again (see footnote 2): \n >>> list(func())\n['I am', 'a generator!']\n \n One can yield data programmatically, for example: \n def func(an_iterable):\n    for item in an_iterable:\n        yield item\n \n The above simple generator is also equivalent to the below - as of Python 3.3 (and not available in Python 2), you can use  yield from : \n def func(an_iterable):\n    yield from an_iterable\n \n However,  yield from  also allows for delegation to subgenerators,\nwhich will be explained in the following section on cooperative delegation with sub-coroutines. \n Coroutines: \n yield  forms an expression that allows data to be sent into the generator (see footnote 3) \n Here is an example, take note of the  received  variable, which will point to the data that is sent to the generator: \n def bank_account(deposited, interest_rate):\n    while True:\n        calculated_interest = interest_rate * deposited \n        received = yield calculated_interest\n        if received:\n            deposited += received\n\n\n>>> my_account = bank_account(1000, .05)\n \n First, we must queue up the generator with the builtin function,  next . It will\ncall the appropriate  next  or  __next__  method, depending on the version of\nPython you are using: \n >>> first_year_interest = next(my_account)\n>>> first_year_interest\n50.0\n \n And now we can send data into the generator. ( Sending  None  is\nthe same as calling  next .) : \n >>> next_year_interest = my_account.send(first_year_interest + 1000)\n>>> next_year_interest\n102.5\n \n Cooperative Delegation to Sub-Coroutine with  yield from \n Now, recall that  yield from  is available in Python 3. This allows us to delegate coroutines to a subcoroutine: \n \ndef money_manager(expected_rate):\n    # must receive deposited value from .send():\n    under_management = yield                   # yield None to start.\n    while True:\n        try:\n            additional_investment = yield expected_rate * under_management \n            if additional_investment:\n                under_management += additional_investment\n        except GeneratorExit:\n            '''TODO: write function to send unclaimed funds to state'''\n            raise\n        finally:\n            '''TODO: write function to mail tax info to client'''\n        \n\ndef investment_account(deposited, manager):\n    '''very simple model of an investment account that delegates to a manager'''\n    # must queue up manager:\n    next(manager)      # <- same as manager.send(None)\n    # This is where we send the initial deposit to the manager:\n    manager.send(deposited)\n    try:\n        yield from manager\n    except GeneratorExit:\n        return manager.close()  # delegate?\n \n And now we can delegate functionality to a sub-generator and it can be used\nby a generator just as above: \n my_manager = money_manager(.06)\nmy_account = investment_account(1000, my_manager)\nfirst_year_return = next(my_account) # -> 60.0\n \n Now simulate adding another 1,000 to the account plus the return on the account (60.0): \n next_year_return = my_account.send(first_year_return + 1000)\nnext_year_return # 123.6\n \n You can read more about the precise semantics of  yield from  in  PEP 380. \n Other Methods: close and throw \n The  close  method raises  GeneratorExit  at the point the function\nexecution was frozen. This will also be called by  __del__  so you\ncan put any cleanup code where you handle the  GeneratorExit : \n my_account.close()\n \n You can also throw an exception which can be handled in the generator\nor propagated back to the user: \n import sys\ntry:\n    raise ValueError\nexcept:\n    my_manager.throw(*sys.exc_info())\n \n Raises: \n Traceback (most recent call last):\n  File \"<stdin>\", line 4, in <module>\n  File \"<stdin>\", line 6, in money_manager\n  File \"<stdin>\", line 2, in <module>\nValueError\n \n Conclusion \n I believe I have covered all aspects of the following question: \n \n What does the  yield  keyword do in Python? \n \n It turns out that  yield  does a lot. I'm sure I could add even more\nthorough examples to this. If you want more or have some constructive criticism, let me know by commenting\nbelow. \n \n Appendix: \n Critique of the Top/Accepted Answer** \n \n It is confused on what makes an  iterable , just using a list as an example. See my references above, but in summary: an iterable has an  __iter__  method returning an  iterator . An  iterator  provides a  .next  (Python 2 or  .__next__  (Python 3) method, which is implicitly called by  for  loops until it raises  StopIteration , and once it does, it will continue to do so. \n It then uses a generator expression to describe what a generator is. Since a generator is simply a convenient way to create an  iterator , it only confuses the matter, and we still have not yet gotten to the  yield  part. \n In  Controlling a generator exhaustion  he calls the  .next  method, when instead he should use the builtin function,  next . It would be an appropriate layer of indirection, because his code does not work in Python 3. \n Itertools? This was not relevant to what  yield  does at all. \n No discussion of the methods that  yield  provides along with the new functionality  yield from  in Python 3.  The top/accepted answer is a very incomplete answer. \n \n Critique of answer suggesting  yield  in a generator expression or comprehension. \n The grammar currently allows any expression in a list comprehension. \n expr_stmt: testlist_star_expr (annassign | augassign (yield_expr|testlist) |\n                     ('=' (yield_expr|testlist_star_expr))*)\n...\nyield_expr: 'yield' [yield_arg]\nyield_arg: 'from' test | testlist\n \n Since yield is an expression, it has been touted by some as interesting to use it in comprehensions or generator expression - in spite of citing no particularly good use-case. \n The CPython core developers are  discussing deprecating its allowance .\nHere's a relevant post from the mailing list: \n \n On 30 January 2017 at 19:05, Brett Cannon  wrote: \n \n On Sun, 29 Jan 2017 at 16:39 Craig Rodrigues  wrote: \n \n I'm OK with either approach.  Leaving things the way they are in Python 3\nis no good, IMHO. \n \n My vote is it be a SyntaxError since you're not getting what you expect from\nthe syntax. \n \n I'd agree that's a sensible place for us to end up, as any code\nrelying on the current behaviour is really too clever to be\nmaintainable. \n In terms of getting there, we'll likely want: \n \n SyntaxWarning or DeprecationWarning in 3.7 \n Py3k warning in 2.7.x \n SyntaxError in 3.8 \n \n Cheers, Nick. \n --  Nick Coghlan   |   ncoghlan at gmail.com   |   Brisbane, Australia \n \n Further, there is an  outstanding issue (10544)  which seems to be pointing in the direction of this  never  being a good idea (PyPy, a Python implementation written in Python, is already raising syntax warnings.) \n Bottom line, until the developers of CPython tell us otherwise:  Don't put  yield  in a generator expression or comprehension. \n The  return  statement in a generator \n In  Python 2 : \n \n In a generator function, the  return  statement is not allowed to include an  expression_list . In that context, a bare  return  indicates that the generator is done and will cause  StopIteration  to be raised. \n \n An  expression_list  is basically any number of expressions separated by commas - essentially, in Python 2, you can stop the generator with  return , but you can't return a value. \n In  Python 3 : \n \n In a generator function, the  return  statement indicates that the generator is done and will cause  StopIteration  to be raised. The returned value (if any) is used as an argument to construct  StopIteration  and becomes the  StopIteration.value  attribute. \n \n Footnotes \n \n The languages CLU, Sather, and Icon were referenced in the proposal\nto introduce the concept of generators to Python. The general idea is\nthat a function can maintain internal state and yield intermediate\ndata points on demand by the user. This promised to be  superior in performance\nto other approaches, including Python threading , which isn't even available on some systems. \n \n  This means, for example, that  range  objects aren't  Iterator s, even though they are iterable, because they can be reused. Like lists, their  __iter__  methods return iterator objects. \n \n  \n \n \n yield  was originally introduced as a statement, meaning that it\ncould only appear at the beginning of a line in a code block.\nNow  yield  creates a yield expression.\n https://docs.python.org/2/reference/simple_stmts.html#grammar-token-yield_stmt \nThis change was  proposed  to allow a user to send data into the generator just as\none might receive it. To send data, one must be able to assign it to something, and\nfor that, a statement just won't work. \n    ", "date_posted": "2021-01-24 04:44:45Z", "upvote": "\r\n            519\r\n        ", "accepted": "No", "user": {"stack_user_id": "541136", "name": "Russia Must Remove Putin", "reputation_score": "347k"}, "answer_comments": []}, {"stack_answer_id": "231778", "answer_content": "\r\n yield  is just like  return  - it returns whatever you tell it to (as a generator). The difference is that the next time you call the generator, execution starts from the last call to the  yield  statement. Unlike return,  the stack frame is not cleaned up when a yield occurs, however control is transferred back to the caller, so its state will resume the next time the function is called. \n\n In the case of your code, the function  get_child_candidates  is acting like an iterator so that when you extend your list, it adds one element at a time to the new list. \n\n list.extend  calls an iterator until it's exhausted. In the case of the code sample you posted, it would be much clearer to just return a tuple and append that to the list. \n    ", "date_posted": "2019-01-24 09:39:59Z", "upvote": "\r\n            425\r\n        ", "accepted": "No", "user": {"stack_user_id": "3551483", "name": "Fang", "reputation_score": "2,011"}, "answer_comments": [{"stack_answer_id": "231778", "stack_answer_comment_id": "99470", "comment_content": "This is close, but not correct.  Every time you call a function with a yield statement in it, it returns a brand new generator object.  It's only when you call that generator's .next() method that execution resumes after the last yield.", "user_id": "None"}]}, {"stack_answer_id": "232853", "answer_content": "\r\n There's one extra thing to mention: a function that yields doesn't actually have to terminate. I've written code like this: \n\n def fib():\n    last, cur = 0, 1\n    while True: \n        yield cur\n        last, cur = cur, last + cur\n \n\n Then I can use it in other code like this: \n\n for f in fib():\n    if some_condition: break\n    coolfuncs(f);\n \n\n It really helps simplify some problems, and makes some things easier to work with.  \n    ", "date_posted": "2013-04-21 15:42:14Z", "upvote": "\r\n            300\r\n        ", "accepted": "No", "user": {"stack_user_id": "15055", "name": "Claudiu", "reputation_score": "218k"}, "answer_comments": []}, {"stack_answer_id": "14404292", "answer_content": "\r\n For those who prefer a minimal working example, meditate on this interactive Python session: \n\n >>> def f():\n...   yield 1\n...   yield 2\n...   yield 3\n... \n>>> g = f()\n>>> for i in g:\n...   print(i)\n... \n1\n2\n3\n>>> for i in g:\n...   print(i)\n... \n>>> # Note that this time nothing was printed\n \n    ", "date_posted": "2020-02-02 22:09:19Z", "upvote": "\r\n            292\r\n        ", "accepted": "No", "user": {"stack_user_id": "2236185", "name": "Oren", "reputation_score": "3,867"}, "answer_comments": []}, {"stack_answer_id": "36220775", "answer_content": "\r\n TL;DR \n\n Instead of this: \n\n def square_list(n):\n    the_list = []                         # Replace\n    for x in range(n):\n        y = x * x\n        the_list.append(y)                # these\n    return the_list                       # lines\n \n\n do this: \n\n def square_yield(n):\n    for x in range(n):\n        y = x * x\n        yield y                           # with this one.\n \n\n Whenever you find yourself building a list from scratch,  yield  each piece instead.  \n\n This was my first \"aha\" moment with yield. \n\n \n\n yield  is a  sugary  way to say  \n\n \n   build a series of stuff \n \n\n Same behavior: \n\n >>> for square in square_list(4):\n...     print(square)\n...\n0\n1\n4\n9\n>>> for square in square_yield(4):\n...     print(square)\n...\n0\n1\n4\n9\n \n\n Different behavior: \n\n Yield is  single-pass : you can only iterate through once. When a function has a yield in it we call it a  generator function . And an  iterator  is what it returns. Those terms are revealing. We lose the convenience of a container, but gain the power of a series that's computed as needed, and arbitrarily long. \n\n Yield is  lazy , it puts off computation. A function with a yield in it  doesn't actually execute at all when you call it.  It returns an  iterator object  that remembers where it left off. Each time you call  next()  on the iterator (this happens in a for-loop) execution inches forward to the next yield.  return  raises StopIteration and ends the series (this is the natural end of a for-loop). \n\n Yield is  versatile . Data doesn't have to be stored all together, it can be made available one at a time. It can be infinite. \n\n >>> def squares_all_of_them():\n...     x = 0\n...     while True:\n...         yield x * x\n...         x += 1\n...\n>>> squares = squares_all_of_them()\n>>> for _ in range(4):\n...     print(next(squares))\n...\n0\n1\n4\n9\n \n\n \n\n If you need  multiple passes  and the series isn't too long, just call  list()  on it: \n\n >>> list(square_yield(4))\n[0, 1, 4, 9]\n \n\n \n\n Brilliant choice of the word  yield  because  both meanings  apply: \n\n \n   yield  \u2014 produce or provide (as in agriculture) \n \n\n ...provide the next data in the series. \n\n \n   yield  \u2014 give way or relinquish (as in political power) \n \n\n ...relinquish CPU execution until the iterator advances. \n    ", "date_posted": "2019-01-04 15:30:21Z", "upvote": "\r\n            272\r\n        ", "accepted": "No", "user": {"stack_user_id": "673991", "name": "Bob Stein", "reputation_score": "14.8k"}, "answer_comments": []}, {"stack_answer_id": "14352675", "answer_content": "\r\n Yield gives you a generator.  \n\n def get_odd_numbers(i):\n    return range(1, i, 2)\ndef yield_odd_numbers(i):\n    for x in range(1, i, 2):\n       yield x\nfoo = get_odd_numbers(10)\nbar = yield_odd_numbers(10)\nfoo\n[1, 3, 5, 7, 9]\nbar\n<generator object yield_odd_numbers at 0x1029c6f50>\nbar.next()\n1\nbar.next()\n3\nbar.next()\n5\n \n\n As you can see, in the first case  foo  holds the entire list in memory at once. It's not a big deal for a list with 5 elements, but what if you want a list of 5 million? Not only is this a huge memory eater, it also costs a lot of time to build at the time that the function is called. \n\n In the second case,  bar  just gives you a generator. A generator is an iterable--which means you can use it in a  for  loop, etc, but each value can only be accessed once. All the values are also not stored in memory at the same time; the generator object \"remembers\" where it was in the looping the last time you called it--this way, if you're using an iterable to (say) count to 50 billion, you don't have to count to 50 billion all at once and store the 50 billion numbers to count through. \n\n Again, this is a pretty contrived example, you probably would use itertools if you really wanted to count to 50 billion. :) \n\n This is the most simple use case of generators. As you said, it can be used to write efficient permutations, using yield to push things up through the call stack instead of using some sort of stack variable. Generators can also be used for specialized tree traversal, and all manner of other things. \n    ", "date_posted": "2019-03-13 06:04:08Z", "upvote": "\r\n            234\r\n        ", "accepted": "No", "user": {"stack_user_id": "4502035", "name": "Andreas", "reputation_score": "2,375"}, "answer_comments": [{"stack_answer_id": "14352675", "stack_answer_comment_id": "97303895", "comment_content": "Just a note - in Python 3, ", "user_id": "None"}]}, {"stack_answer_id": "231788", "answer_content": "\r\n It's returning a generator. I'm not particularly familiar with Python, but I believe it's the same kind of thing as  C#'s iterator blocks  if you're familiar with those. \n\n The key idea is that the compiler/interpreter/whatever does some trickery so that as far as the caller is concerned, they can keep calling next() and it will keep returning values -  as if the generator method was paused . Now obviously you can't really \"pause\" a method, so the compiler builds a state machine for you to remember where you currently are and what the local variables etc look like. This is much easier than writing an iterator yourself. \n    ", "date_posted": "2018-10-31 08:42:59Z", "upvote": "\r\n            230\r\n        ", "accepted": "No", "user": {"stack_user_id": "22656", "name": "Jon Skeet", "reputation_score": "1.4m"}, "answer_comments": []}, {"stack_answer_id": "15814755", "answer_content": "\r\n There is one type of answer that I don't feel has been given yet, among the many great answers that describe how to use generators. Here is the programming language theory answer: \n\n The  yield  statement in Python returns a generator. A generator in Python is a function that returns  continuations  (and specifically a type of coroutine, but continuations represent the more general mechanism to understand what is going on). \n\n Continuations in programming languages theory are a much more fundamental kind of computation, but they are not often used, because they are extremely hard to reason about and also very difficult to implement. But the idea of what a continuation is, is straightforward: it is the state of a computation that has not yet finished. In this state, the current values of variables, the operations that have yet to be performed, and so on, are saved. Then at some point later in the program the continuation can be invoked, such that the program's variables are reset to that state and the operations that were saved are carried out. \n\n Continuations, in this more general form, can be implemented in two ways. In the  call/cc  way, the program's stack is literally saved and then when the continuation is invoked, the stack is restored. \n\n In continuation passing style (CPS), continuations are just normal functions (only in languages where functions are first class) which the programmer explicitly manages and passes around to subroutines. In this style, program state is represented by closures (and the variables that happen to be encoded in them) rather than variables that reside somewhere on the stack. Functions that manage control flow accept continuation as arguments (in some variations of CPS, functions may accept multiple continuations) and manipulate control flow by invoking them by simply calling them and returning afterwards. A very simple example of continuation passing style is as follows: \n\n def save_file(filename):\n  def write_file_continuation():\n    write_stuff_to_file(filename)\n\n  check_if_file_exists_and_user_wants_to_overwrite(write_file_continuation)\n \n\n In this (very simplistic) example, the programmer saves the operation of actually writing the file into a continuation (which can potentially be a very complex operation with many details to write out), and then passes that continuation (i.e, as a first-class closure) to another operator which does some more processing, and then calls it if necessary. (I use this design pattern a lot in actual GUI programming, either because it saves me lines of code or, more importantly, to manage control flow after GUI events trigger.) \n\n The rest of this post will, without loss of generality, conceptualize continuations as CPS, because it is a hell of a lot easier to understand and read. \n\n \n\n Now let's talk about generators in Python. Generators are a specific subtype of continuation. Whereas  continuations are able in general to save the state of a  computation  (i.e., the program's call stack),  generators are only able to save the state of iteration over an  iterator . Although, this definition is slightly misleading for certain use cases of generators. For instance: \n\n def f():\n  while True:\n    yield 4\n \n\n This is clearly a reasonable iterable whose behavior is well defined -- each time the generator iterates over it, it returns 4 (and does so forever). But it isn't probably the prototypical type of iterable that comes to mind when thinking of iterators (i.e.,  for x in collection: do_something(x) ). This example illustrates the power of generators: if anything is an iterator, a generator can save the state of its iteration. \n\n To reiterate: Continuations can save the state of a program's stack and generators can save the state of iteration. This means that continuations are more a lot powerful than generators, but also that generators are a lot, lot easier. They are easier for the language designer to implement, and they are easier for the programmer to use (if you have some time to burn, try to read and understand  this page about continuations and call/cc ). \n\n But you could easily implement (and conceptualize) generators as a simple, specific case of continuation passing style: \n\n Whenever  yield  is called, it tells the function to return a continuation.  When the function is called again, it starts from wherever it left off. So, in pseudo-pseudocode (i.e., not pseudocode, but not code) the generator's  next  method is basically as follows: \n\n class Generator():\n  def __init__(self,iterable,generatorfun):\n    self.next_continuation = lambda:generatorfun(iterable)\n\n  def next(self):\n    value, next_continuation = self.next_continuation()\n    self.next_continuation = next_continuation\n    return value\n \n\n where the  yield  keyword is actually syntactic sugar for the real generator function, basically something like: \n\n def generatorfun(iterable):\n  if len(iterable) == 0:\n    raise StopIteration\n  else:\n    return (iterable[0], lambda:generatorfun(iterable[1:]))\n \n\n Remember that this is just pseudocode and the actual implementation of generators in Python is more complex. But as an exercise to understand what is going on, try to use continuation passing style to implement generator objects without use of the  yield  keyword. \n    ", "date_posted": "2018-05-20 10:25:32Z", "upvote": "\r\n            205\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "232111", "answer_content": "\r\n Here is an example in plain language. I will provide a correspondence between high-level human concepts to low-level Python concepts. \n I want to operate on a sequence of numbers, but I don't want to bother my self with the creation of that sequence, I want only to focus on the operation I want to do. So, I do the following: \n \n I call you and tell you that I want a sequence of numbers which are calculated in a specific way, and I let you know what the algorithm is.  \n This step corresponds to  def ining the generator function, i.e. the function containing a  yield . \n Sometime later, I tell you, \"OK, get ready to tell me the sequence of numbers\".  \n This step corresponds to calling the generator function which returns a generator object.  Note that you don't tell me any numbers yet; you just grab your paper and pencil. \n I ask you, \"tell me the next number\", and you tell me the first number; after that, you wait for me to ask you for the next number. It's your job to remember where you were, what numbers you have already said, and what is the next number. I don't care about the details.  \n This step corresponds to calling  next(generator)  on the generator object. \n(In Python 2,  .next  was a method of the generator object; in Python 3, it is named  .__next__ , but the proper way to call it is using the builtin  next()  function just like  len()  and  .__len__ ) \n \u2026 repeat previous step, until\u2026 \n eventually, you might come to an end. You don't tell me a number; you just shout, \"hold your horses! I'm done! No more numbers!\"  \n This step corresponds to the generator object ending its job, and raising a  StopIteration  exception. \nThe generator function does not need to raise the exception. It's raised automatically when the function ends or issues a  return . \n \n This is what a generator does (a function that contains a  yield ); it starts executing on the first  next() , pauses whenever it does a  yield , and when asked for the  next()  value it continues from the point it was last. It fits perfectly by design with the iterator protocol of Python, which describes how to sequentially request values. \n The most famous user of the iterator protocol is the  for  command in Python. So, whenever you do a: \n for item in sequence:\n \n it doesn't matter if  sequence  is a list, a string, a dictionary or a generator  object  like described above; the result is the same: you read items off a sequence one by one. \n Note that  def ining a function which contains a  yield  keyword is not the only way to create a generator; it's just the easiest way to create one. \n For more accurate information, read about  iterator types , the  yield statement  and  generators  in the Python documentation. \n    ", "date_posted": "2022-01-17 10:21:02Z", "upvote": "\r\n            203\r\n        ", "accepted": "No", "user": {"stack_user_id": "6899", "name": "tzot", "reputation_score": "88.7k"}, "answer_comments": []}, {"stack_answer_id": "21541902", "answer_content": "\r\n While a lot of answers show why you'd use a  yield  to create a generator, there are more uses for  yield .  It's quite easy to make a coroutine, which enables the passing of information between two blocks of code.  I won't repeat any of the fine examples that have already been given about using  yield  to create a generator. \n\n To help understand what a  yield  does in the following code, you can use your finger to trace the cycle through any code that has a  yield .  Every time your finger hits the  yield , you have to wait for a  next  or a  send  to be entered.  When a  next  is called, you trace through the code until you hit the  yield \u2026 the code on the right of the  yield  is evaluated and returned to the caller\u2026 then you wait.  When  next  is called again, you perform another loop through the code.  However, you'll note that in a coroutine,  yield  can also be used with a  send \u2026 which will send a value from the caller  into  the yielding function. If a  send  is given, then  yield  receives the value sent, and spits it out the left hand side\u2026 then the trace through the code progresses until you hit the  yield  again (returning the value at the end, as if  next  was called). \n\n For example: \n\n >>> def coroutine():\n...     i = -1\n...     while True:\n...         i += 1\n...         val = (yield i)\n...         print(\"Received %s\" % val)\n...\n>>> sequence = coroutine()\n>>> sequence.next()\n0\n>>> sequence.next()\nReceived None\n1\n>>> sequence.send('hello')\nReceived hello\n2\n>>> sequence.close()\n \n    ", "date_posted": "2014-02-04 02:27:35Z", "upvote": "\r\n            162\r\n        ", "accepted": "No", "user": {"stack_user_id": "2379433", "name": "Mike McKerns", "reputation_score": "31.4k"}, "answer_comments": [{"stack_answer_id": "21541902", "stack_answer_comment_id": "55942433", "comment_content": "Cute! A ", "user_id": "None"}]}, {"stack_answer_id": "24944096", "answer_content": "\r\n There is another  yield  use and meaning (since Python 3.3): \n yield from <expr>\n \n From  PEP 380 -- Syntax for Delegating to a Subgenerator : \n \n A syntax is proposed for a generator to delegate part of its operations to another generator. This allows a section of code containing 'yield' to be factored out and placed in another generator. Additionally, the subgenerator is allowed to return with a value, and the value is made available to the delegating generator. \n The new syntax also opens up some opportunities for optimisation when one generator re-yields values produced by another. \n \n Moreover  this  will introduce (since Python 3.5): \n async def new_coroutine(data):\n   ...\n   await blocking_action()\n \n to avoid coroutines being confused with a regular generator (today  yield  is used in both). \n    ", "date_posted": "2020-06-20 09:12:55Z", "upvote": "\r\n            158\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}, {"stack_answer_id": "47285378", "answer_content": "\r\n All great answers, however a bit difficult for newbies. \n\n I assume you have learned the  return  statement. \n\n As an analogy,  return  and  yield  are twins.  return  means 'return and stop' whereas 'yield` means 'return, but continue' \n\n \n   \n   Try to get a num_list with  return . \n   \n \n\n def num_list(n):\n    for i in range(n):\n        return i\n \n\n Run it: \n\n In [5]: num_list(3)\nOut[5]: 0\n \n\n See, you get only a single number rather than a list of them.  return  never allows you prevail happily, just implements once and quit. \n\n \n   \n   There comes  yield \n   \n \n\n Replace  return  with  yield : \n\n In [10]: def num_list(n):\n    ...:     for i in range(n):\n    ...:         yield i\n    ...:\n\nIn [11]: num_list(3)\nOut[11]: <generator object num_list at 0x10327c990>\n\nIn [12]: list(num_list(3))\nOut[12]: [0, 1, 2]\n \n\n Now, you win to get all the numbers. \n\n Comparing to  return  which runs once and stops,  yield  runs times you planed.\nYou can interpret  return  as  return one of them , and  yield  as  return all of them . This is called  iterable . \n\n \n   \n   One more step we can rewrite  yield  statement with  return \n   \n \n\n In [15]: def num_list(n):\n    ...:     result = []\n    ...:     for i in range(n):\n    ...:         result.append(i)\n    ...:     return result\n\nIn [16]: num_list(3)\nOut[16]: [0, 1, 2]\n \n\n It's the core about  yield . \n\n The difference between a list  return  outputs and the object  yield  output is: \n\n You will always get [0, 1, 2] from a list object but only could retrieve them from 'the object  yield  output' once. So, it has a new name  generator  object as displayed in  Out[11]: <generator object num_list at 0x10327c990> . \n\n In conclusion, as a metaphor to grok it: \n\n \n return  and  yield  are twins \n list  and  generator  are twins \n \n    ", "date_posted": "2018-05-28 09:06:22Z", "upvote": "\r\n            146\r\n        ", "accepted": "No", "user": {"stack_user_id": "7301792", "name": "AbstProcDo", "reputation_score": "18.1k"}, "answer_comments": [{"stack_answer_id": "47285378", "stack_answer_comment_id": "90923314", "comment_content": "This is understandable, but one major difference is that you can have multiple yields in a function/method. The analogy totally breaks down at that point. Yield remembers its place in a function, so the next time you call next(), your function continues on to the next ", "user_id": "None"}]}, {"stack_answer_id": "18365578", "answer_content": "\r\n From a programming viewpoint, the iterators are implemented as  thunks . \n To implement iterators, generators, and thread pools for concurrent execution, etc. as thunks, one uses  messages sent to a closure object , which has a dispatcher, and the  dispatcher answers to \"messages\" . \n \" next \"  is a message sent to a closure, created by the \" iter \" call. \n There are lots of ways to implement this computation. I used mutation, but it is possible to do this kind of computation without mutation, by returning the current value and the next yielder (making it  referential transparent ).  Racket uses a sequence of transformations of the initial program in some intermediary languages, one of such rewriting making the yield operator to be transformed in some language with simpler operators. \n Here is a demonstration of how yield could be rewritten, which uses the structure of R6RS, but the semantics is identical to Python's. It's the same model of computation, and only a change in syntax is required to rewrite it using yield of Python. \n \n Welcome to Racket v6.5.0.3.\n\n-> (define gen\n     (lambda (l)\n       (define yield\n         (lambda ()\n           (if (null? l)\n               'END\n               (let ((v (car l)))\n                 (set! l (cdr l))\n                 v))))\n       (lambda(m)\n         (case m\n           ('yield (yield))\n           ('init  (lambda (data)\n                     (set! l data)\n                     'OK))))))\n-> (define stream (gen '(1 2 3)))\n-> (stream 'yield)\n1\n-> (stream 'yield)\n2\n-> (stream 'yield)\n3\n-> (stream 'yield)\n'END\n-> ((stream 'init) '(a b))\n'OK\n-> (stream 'yield)\n'a\n-> (stream 'yield)\n'b\n-> (stream 'yield)\n'END\n-> (stream 'yield)\n'END\n->\n \n \n    ", "date_posted": "2020-07-02 07:36:31Z", "upvote": "\r\n            133\r\n        ", "accepted": "No", "user": {"stack_user_id": "1419272", "name": "alinsoar", "reputation_score": "14.8k"}, "answer_comments": []}, {"stack_answer_id": "12716515", "answer_content": "\r\n Here are some Python examples of how to actually implement generators as if Python did not provide syntactic sugar for them: \n\n As a Python generator: \n\n from itertools import islice\n\ndef fib_gen():\n    a, b = 1, 1\n    while True:\n        yield a\n        a, b = b, a + b\n\nassert [1, 1, 2, 3, 5] == list(islice(fib_gen(), 5))\n \n\n Using lexical closures instead of generators \n\n def ftake(fnext, last):\n    return [fnext() for _ in xrange(last)]\n\ndef fib_gen2():\n    #funky scope due to python2.x workaround\n    #for python 3.x use nonlocal\n    def _():\n        _.a, _.b = _.b, _.a + _.b\n        return _.a\n    _.a, _.b = 0, 1\n    return _\n\nassert [1,1,2,3,5] == ftake(fib_gen2(), 5)\n \n\n Using object closures instead of generators  (because  ClosuresAndObjectsAreEquivalent ) \n\n class fib_gen3:\n    def __init__(self):\n        self.a, self.b = 1, 1\n\n    def __call__(self):\n        r = self.a\n        self.a, self.b = self.b, self.a + self.b\n        return r\n\nassert [1,1,2,3,5] == ftake(fib_gen3(), 5)\n \n    ", "date_posted": "2017-10-24 10:46:05Z", "upvote": "\r\n            126\r\n        ", "accepted": "No", "user": {"stack_user_id": "20003", "name": "Dustin Getz", "reputation_score": "20.7k"}, "answer_comments": []}, {"stack_answer_id": "14554322", "answer_content": "\r\n I was going to post \"read page 19 of Beazley's 'Python: Essential Reference' for a quick description of generators\", but so many others have posted good descriptions already. \n\n Also, note that  yield  can be used in coroutines as the dual of their use in generator functions.  Although it isn't the same use as your code snippet,  (yield)  can be used as an expression in a function.  When a caller sends a value to the method using the  send()  method, then the coroutine will execute until the next  (yield)  statement is encountered. \n\n Generators and coroutines are a cool way to set up data-flow type applications.  I thought it would be worthwhile knowing about the other use of the  yield  statement in functions. \n    ", "date_posted": "2013-01-28 01:37:10Z", "upvote": "\r\n            115\r\n        ", "accepted": "No", "user": {"stack_user_id": "479213", "name": "johnzachary", "reputation_score": "2,385"}, "answer_comments": []}, {"stack_answer_id": "20704301", "answer_content": "\r\n Here is a simple example: \n\n def isPrimeNumber(n):\n    print \"isPrimeNumber({}) call\".format(n)\n    if n==1:\n        return False\n    for x in range(2,n):\n        if n % x == 0:\n            return False\n    return True\n\ndef primes (n=1):\n    while(True):\n        print \"loop step ---------------- {}\".format(n)\n        if isPrimeNumber(n): yield n\n        n += 1\n\nfor n in primes():\n    if n> 10:break\n    print \"wiriting result {}\".format(n)\n \n\n Output: \n\n loop step ---------------- 1\nisPrimeNumber(1) call\nloop step ---------------- 2\nisPrimeNumber(2) call\nloop step ---------------- 3\nisPrimeNumber(3) call\nwiriting result 3\nloop step ---------------- 4\nisPrimeNumber(4) call\nloop step ---------------- 5\nisPrimeNumber(5) call\nwiriting result 5\nloop step ---------------- 6\nisPrimeNumber(6) call\nloop step ---------------- 7\nisPrimeNumber(7) call\nwiriting result 7\nloop step ---------------- 8\nisPrimeNumber(8) call\nloop step ---------------- 9\nisPrimeNumber(9) call\nloop step ---------------- 10\nisPrimeNumber(10) call\nloop step ---------------- 11\nisPrimeNumber(11) call\n \n\n I am not a Python developer, but it looks to me  yield  holds the position of program flow and the next loop start from \"yield\" position. It seems like it is waiting at that position, and just before that, returning a value outside, and next time continues to work. \n\n It seems to be an interesting and nice ability :D \n    ", "date_posted": "2018-05-20 10:31:01Z", "upvote": "\r\n            100\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "20704301", "stack_answer_comment_id": "89241413", "comment_content": "You are correct. But what is the effect on flow which is to see the behaviour of \"yield\" ? I can change the algorithm in the name of mathmatics. Will it help to get different assessment of \"yield\" ?", "user_id": "None"}]}, {"stack_answer_id": "17113322", "answer_content": "\r\n Here is a mental image of what  yield  does. \n\n I like to think of a thread as having a stack (even when it's not implemented that way). \n\n When a normal function is called, it puts its local variables on the stack, does some computation, then clears the stack and returns. The values of its local variables are never seen again. \n\n With a  yield  function, when its code begins to run (i.e. after the function is called, returning a generator object, whose  next()  method is then invoked), it similarly puts its local variables onto the stack and computes for a while. But then, when it hits the  yield  statement, before clearing its part of the stack and returning, it takes a snapshot of its local variables and stores them in the generator object. It also writes down the place where it's currently up to in its code (i.e. the particular  yield  statement). \n\n So it's a kind of a frozen function that the generator is hanging onto. \n\n When  next()  is called subsequently, it retrieves the function's belongings onto the stack and re-animates it. The function continues to compute from where it left off, oblivious to the fact that it had just spent an eternity in cold storage. \n\n Compare the following examples: \n\n def normalFunction():\n    return\n    if False:\n        pass\n\ndef yielderFunction():\n    return\n    if False:\n        yield 12\n \n\n When we call the second function, it behaves very differently to the first. The  yield  statement might be unreachable, but if it's present anywhere, it changes the nature of what we're dealing with. \n\n >>> yielderFunction()\n<generator object yielderFunction at 0x07742D28>\n \n\n Calling  yielderFunction()  doesn't run its code, but makes a generator out of the code. (Maybe it's a good idea to name such things with the  yielder  prefix for readability.) \n\n >>> gen = yielderFunction()\n>>> dir(gen)\n['__class__',\n ...\n '__iter__',    #Returns gen itself, to make it work uniformly with containers\n ...            #when given to a for loop. (Containers return an iterator instead.)\n 'close',\n 'gi_code',\n 'gi_frame',\n 'gi_running',\n 'next',        #The method that runs the function's body.\n 'send',\n 'throw']\n \n\n The  gi_code  and  gi_frame  fields are where the frozen state is stored. Exploring them with  dir(..) , we can confirm that our mental model above is credible. \n    ", "date_posted": "2017-03-01 13:36:58Z", "upvote": "\r\n            85\r\n        ", "accepted": "No", "user": {"stack_user_id": "1143274", "name": "Evgeni Sergeev", "reputation_score": "21.3k"}, "answer_comments": []}, {"stack_answer_id": "55314423", "answer_content": "\r\n \n Imagine that you have created a remarkable machine that is capable of generating thousands and thousands of lightbulbs per day. The machine generates these lightbulbs in boxes with a unique serial number. You don't have enough space to store all of these lightbulbs at the same time, so you would like to adjust it to generate lightbulbs on-demand. \n Python generators don't differ much from this concept. Imagine that you have a function called  barcode_generator  that generates unique serial numbers for the boxes. Obviously, you can have a huge number of such barcodes returned by the function, subject to the hardware (RAM) limitations. A wiser, and space efficient, option is to generate those serial numbers on-demand. \n Machine's code: \n def barcode_generator():\n    serial_number = 10000  # Initial barcode\n    while True:\n        yield serial_number\n        serial_number += 1\n\n\nbarcode = barcode_generator()\nwhile True:\n    number_of_lightbulbs_to_generate = int(input(\"How many lightbulbs to generate? \"))\n    barcodes = [next(barcode) for _ in range(number_of_lightbulbs_to_generate)]\n    print(barcodes)\n\n    # function_to_create_the_next_batch_of_lightbulbs(barcodes)\n\n    produce_more = input(\"Produce more? [Y/n]: \")\n    if produce_more == \"n\":\n        break\n \n Note the  next(barcode)  bit. \n As you can see, we have a self-contained \u201cfunction\u201d to generate the next unique serial number each time. This function returns a  generator ! As you can see, we are not calling the function each time we need a new serial number, but instead we are using  next()  given the generator to obtain the next serial number. \n Lazy Iterators \n To be more precise, this generator is a  lazy iterator ! An iterator is an object that helps us traverse a sequence of objects. It's called  lazy  because it does not load all the items of the sequence in memory until they are needed. The use of  next  in the previous example is the  explicit  way to obtain the next item from the iterator. The  implicit  way is using for loops: \n for barcode in barcode_generator():\n    print(barcode)\n \n This will print barcodes infinitely, yet you will not run out of memory. \n In other words, a generator  looks like  a function but  behaves like  an iterator. \n Real-world application? \n Finally, real-world applications? They are usually useful when you work with big sequences. Imagine reading a  huge  file from disk with billions of records. Reading the entire file in memory, before you can work with its content, will probably be infeasible (i.e., you will run out of memory). \n    ", "date_posted": "2021-10-21 18:54:29Z", "upvote": "\r\n            81\r\n        ", "accepted": "No", "user": {"stack_user_id": "4946896", "name": "Rafael", "reputation_score": "6,652"}, "answer_comments": []}, {"stack_answer_id": "41426583", "answer_content": "\r\n An easy example to understand what it is:  yield \n\n def f123():\n    for _ in range(4):\n        yield 1\n        yield 2\n\n\nfor i in f123():\n    print (i)\n \n\n The output is:  \n\n 1 2 1 2 1 2 1 2\n \n    ", "date_posted": "2020-02-02 18:21:38Z", "upvote": "\r\n            78\r\n        ", "accepted": "No", "user": {"stack_user_id": "8928024", "name": "ZF007", "reputation_score": "3,601"}, "answer_comments": [{"stack_answer_id": "41426583", "stack_answer_comment_id": "106237799", "comment_content": "are you sure about that output?  wouldnt that only be printed on a single line if you ran that print statement using ", "user_id": "None"}, {"stack_answer_id": "41426583", "stack_answer_comment_id": "106255539", "comment_content": "@user9074332, You're right, but it is written on one line to facilitate understanding", "user_id": "None"}]}, {"stack_answer_id": "31692481", "answer_content": "\r\n Like every answer suggests,  yield  is used for creating a sequence generator. It's used for generating some sequence dynamically. For example, while reading a file line by line on a network, you can use the  yield  function as follows: \n\n def getNextLines():\n   while con.isOpen():\n       yield con.read()\n \n\n You can use it in your code as follows: \n\n for line in getNextLines():\n    doSomeThing(line)\n \n\n Execution Control Transfer gotcha \n\n The execution control will be transferred from getNextLines() to the  for  loop when yield is executed. Thus, every time getNextLines() is invoked, execution begins from the point where it was paused last time. \n\n Thus in short, a function with the following code \n\n def simpleYield():\n    yield \"first time\"\n    yield \"second time\"\n    yield \"third time\"\n    yield \"Now some useful value {}\".format(12)\n\nfor i in simpleYield():\n    print i\n \n\n will print \n\n \"first time\"\n\"second time\"\n\"third time\"\n\"Now some useful value 12\"\n \n    ", "date_posted": "2018-05-20 10:42:59Z", "upvote": "\r\n            74\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "36214653", "answer_content": "\r\n (My below answer only speaks from the perspective of using Python generator, not the  underlying implementation of generator mechanism , which involves some tricks of stack and heap manipulation.) \n\n When  yield  is used instead of a  return  in a python function, that function is turned into something special called  generator function . That function will return an object of  generator  type.  The  yield  keyword is a flag to notify the python compiler to treat such function specially.  Normal functions will terminate once some value is returned from it. But with the help of the compiler, the generator function  can be thought of  as resumable. That is, the execution context will be restored and the execution will continue from last run. Until you explicitly call return, which will raise a  StopIteration  exception (which is also part of the iterator protocol), or reach the end of the function. I found a lot of references about  generator  but this  one  from the  functional programming perspective  is the most digestable. \n\n (Now I want to talk about the rationale behind  generator , and the  iterator  based on my own understanding. I hope this can help you grasp the  essential motivation  of iterator and generator. Such concept shows up in other languages as well such as C#.) \n\n As I understand, when we want to process a bunch of data, we usually first store the data somewhere and then process it one by one. But this  naive  approach is problematic. If the data volume is huge, it's expensive to store them as a whole beforehand.  So instead of storing the  data  itself directly, why not store some kind of  metadata  indirectly, i.e.  the logic how the data is computed .  \n\n There are 2 approaches to wrap such metadata. \n\n \n The OO approach, we wrap the metadata  as a class . This is the so-called  iterator  who implements the iterator protocol (i.e. the  __next__() , and  __iter__()  methods). This is also the commonly seen  iterator design pattern . \n The functional approach, we wrap the metadata  as a function . This is\nthe so-called  generator function . But under the hood, the returned  generator object  still  IS-A  iterator because it also implements the iterator protocol. \n \n\n Either way, an iterator is created, i.e. some object that can give you the data you want. The OO approach may be a bit complex. Anyway, which one to use is up to you. \n    ", "date_posted": "2018-11-23 01:38:59Z", "upvote": "\r\n            72\r\n        ", "accepted": "No", "user": {"stack_user_id": "264052", "name": "smwikipedia", "reputation_score": "58.4k"}, "answer_comments": []}, {"stack_answer_id": "40022748", "answer_content": "\r\n In summary, the  yield  statement transforms your function into a factory that produces a special object called a  generator  which wraps around the body of your original function. When the  generator  is iterated, it executes your function  until it reaches the next  yield  then suspends execution and evaluates to the value passed to  yield . It repeats this process on each iteration until the path of execution exits the function. For instance, \n\n def simple_generator():\n    yield 'one'\n    yield 'two'\n    yield 'three'\n\nfor i in simple_generator():\n    print i\n \n\n simply outputs \n\n one\ntwo\nthree\n \n\n The power comes from using the generator with a loop that calculates a sequence, the generator executes the loop stopping each time to 'yield' the next result of the calculation, in this way it calculates a list on the fly, the benefit being the memory saved for especially large calculations \n\n Say you wanted to create a your own  range  function that produces an iterable range of numbers, you could do it like so, \n\n def myRangeNaive(i):\n    n = 0\n    range = []\n    while n < i:\n        range.append(n)\n        n = n + 1\n    return range\n \n\n and use it like this; \n\n for i in myRangeNaive(10):\n    print i\n \n\n But this is inefficient because \n\n \n You create an array that you only use once (this wastes memory) \n This code actually loops over that array twice! :( \n \n\n Luckily Guido and his team were generous enough to develop generators so we could just do this; \n\n def myRangeSmart(i):\n    n = 0\n    while n < i:\n       yield n\n       n = n + 1\n    return\n\nfor i in myRangeSmart(10):\n    print i\n \n\n Now upon each iteration a function on the generator called  next()  executes the function until it either reaches a 'yield' statement in which it stops and  'yields' the value or reaches the end of the function. In this case on the first call,  next()  executes up to the yield statement and yield 'n', on the next call it will execute the  increment statement, jump back to the 'while', evaluate it, and if true, it will stop and yield 'n' again, it will continue that way until the while condition returns false and the generator jumps to the end of the function. \n    ", "date_posted": "2018-05-20 11:04:36Z", "upvote": "\r\n            71\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "32331953", "answer_content": "\r\n Yield is an object \n\n A  return  in a function will return a single value. \n\n If you want  a function to return a huge set of values , use  yield . \n\n More importantly,  yield  is a  barrier . \n\n \n   like barrier in the CUDA language, it will not transfer control until it gets\n  completed. \n \n\n That is, it will run the code in your function from the beginning until it hits  yield . Then, it\u2019ll return the first value of the loop. \n\n Then, every other call will run the loop you have written in the function one more time, returning the next value until there isn't any value to return. \n    ", "date_posted": "2018-05-20 10:45:50Z", "upvote": "\r\n            67\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "39425637", "answer_content": "\r\n Many people use  return  rather than  yield , but in some cases  yield  can be more efficient and easier to work with. \n\n Here is an example which  yield  is definitely best for: \n\n \n   return  (in function) \n \n\n import random\n\ndef return_dates():\n    dates = [] # With 'return' you need to create a list then return it\n    for i in range(5):\n        date = random.choice([\"1st\", \"2nd\", \"3rd\", \"4th\", \"5th\", \"6th\", \"7th\", \"8th\", \"9th\", \"10th\"])\n        dates.append(date)\n    return dates\n \n\n \n   yield  (in function) \n \n\n def yield_dates():\n    for i in range(5):\n        date = random.choice([\"1st\", \"2nd\", \"3rd\", \"4th\", \"5th\", \"6th\", \"7th\", \"8th\", \"9th\", \"10th\"])\n        yield date # 'yield' makes a generator automatically which works\n                   # in a similar way. This is much more efficient.\n \n\n \n   Calling functions \n \n\n dates_list = return_dates()\nprint(dates_list)\nfor i in dates_list:\n    print(i)\n\ndates_generator = yield_dates()\nprint(dates_generator)\nfor i in dates_generator:\n    print(i)\n \n\n Both functions do the same thing, but  yield  uses three lines instead of five and has one less variable to worry about. \n\n \n   \n     This is the result from the code: \n   \n \n\n \n\n As you can see both functions do the same thing. The only difference is  return_dates()  gives a list and  yield_dates()  gives a generator. \n\n A real life example would be something like reading a file line by line or if you just want to make a generator. \n    ", "date_posted": "2018-05-20 11:02:52Z", "upvote": "\r\n            65\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "33788856", "answer_content": "\r\n The  yield  keyword simply collects returning results. Think of  yield  like  return += \n    ", "date_posted": "2016-04-23 03:16:19Z", "upvote": "\r\n            55\r\n        ", "accepted": "No", "user": {"stack_user_id": "4907496", "name": "Phillip", "reputation_score": "2,165"}, "answer_comments": []}, {"stack_answer_id": "30341713", "answer_content": "\r\n yield  is like a return element for a function. The difference is, that the  yield  element turns a function into a generator. A generator behaves just like a function until something is 'yielded'. The generator stops until it is next called, and continues from exactly the same point as it started. You can get a sequence of all the 'yielded' values in one, by calling  list(generator()) . \n    ", "date_posted": "2015-05-20 06:19:32Z", "upvote": "\r\n            52\r\n        ", "accepted": "No", "user": {"stack_user_id": "4884103", "name": "Will Dereham", "reputation_score": "976"}, "answer_comments": []}], "user": {"stack_user_id": "18300", "name": "Alex. S.", "reputation_score": "138k"}, "question_comments": [{"stack_question_id": "231767", "stack_question_comment_id": "129480481", "comment_content": "The Yield keyword in Python is similar to a return statement used for returning values or objects in Python. However, there is a slight difference. The yield statement returns a generator object to the one who calls the function which contains yield, instead of simply returning a value.", "user_id": "None"}]},
{"stack_question_id": "613183", "question_title": "How do I sort a dictionary by value?", "question_content": "\r\n                I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.\n\nI can sort on the keys, but how ...\r\n", "question_url": "/questions/613183/how-do-i-sort-a-dictionary-by-value", "date_posted": "Mar 5, 2009 at 0:49", "upvote": "3", "view": "4", "tags": ["python", "sorting", "dictionary"], "answers_count": "3", "answers": [{"stack_answer_id": "613218", "answer_content": "\r\n Python 3.7+ or CPython 3.6 \n Dicts preserve insertion order in Python 3.7+. Same in CPython 3.6, but  it's an implementation detail . \n >>> x = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}\n>>> {k: v for k, v in sorted(x.items(), key=lambda item: item[1])}\n{0: 0, 2: 1, 1: 2, 4: 3, 3: 4}\n \n or \n >>> dict(sorted(x.items(), key=lambda item: item[1]))\n{0: 0, 2: 1, 1: 2, 4: 3, 3: 4}\n \n Older Python \n It is not possible to sort a dictionary, only to get a representation of a dictionary that is sorted. Dictionaries are inherently orderless, but other types, such as lists and tuples, are not. So you need an ordered data type to represent sorted values, which will be a list\u2014probably a list of tuples. \n For instance, \n import operator\nx = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}\nsorted_x = sorted(x.items(), key=operator.itemgetter(1))\n \n sorted_x  will be a list of tuples sorted by the second element in each tuple.  dict(sorted_x) == x . \n And for those wishing to sort on keys instead of values: \n import operator\nx = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}\nsorted_x = sorted(x.items(), key=operator.itemgetter(0))\n \n In Python3 since  unpacking is not allowed  we can use \n x = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}\nsorted_x = sorted(x.items(), key=lambda kv: kv[1])\n \n If you want the output as a dict, you can use  collections.OrderedDict : \n import collections\n\nsorted_dict = collections.OrderedDict(sorted_x)\n \n    ", "date_posted": "2020-11-22 19:29:02Z", "upvote": "\r\n            6504\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "4518341", "name": "wjandrea", "reputation_score": "24.1k"}, "answer_comments": [{"stack_answer_id": "613218", "stack_answer_comment_id": "459741", "comment_content": "for timings on various dictionary sorting by value schemes:  ", "user_id": "None"}, {"stack_answer_id": "613218", "stack_answer_comment_id": "2787661", "comment_content": " will give you a descending ordering (by the second tuple element)", "user_id": "None"}, {"stack_answer_id": "613218", "stack_answer_comment_id": "3270439", "comment_content": "saidimu: Since we're already using ", "user_id": "None"}, {"stack_answer_id": "613218", "stack_answer_comment_id": "5594141", "comment_content": "In python3 I used a lambda: ", "user_id": "None"}, {"stack_answer_id": "613218", "stack_answer_comment_id": "123505096", "comment_content": "Where can I read more about the usage of ", "user_id": "None"}]}, {"stack_answer_id": "3177911", "answer_content": "\r\n As simple as:  sorted(dict1, key=dict1.get) \n\n Well, it is actually possible to do a \"sort by dictionary values\". Recently I had to do that in a Code Golf (Stack Overflow question  Code golf: Word frequency chart ). Abridged, the problem was of the kind: given a text, count how often each word is encountered and display a list of the top words, sorted by decreasing frequency.  \n\n If you construct a dictionary with the words as keys and the number of occurrences of each word as value, simplified here as: \n\n from collections import defaultdict\nd = defaultdict(int)\nfor w in text.split():\n    d[w] += 1\n \n\n then you can get a list of the words, ordered by frequency of use with  sorted(d, key=d.get)  - the sort iterates over the dictionary keys, using the number of word occurrences as a sort key .  \n\n for w in sorted(d, key=d.get, reverse=True):\n    print(w, d[w])\n \n\n I am writing this detailed explanation to illustrate what people often mean by \"I can easily sort a dictionary by key, but how do I sort by value\" - and I think the original post was trying to address such an issue. And the solution is to do sort of list of the keys, based on the values, as shown above. \n    ", "date_posted": "2020-03-10 14:42:24Z", "upvote": "\r\n            1548\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": [{"stack_answer_id": "3177911", "stack_answer_comment_id": "10448097", "comment_content": "This is also good but ", "user_id": "None"}, {"stack_answer_id": "3177911", "stack_answer_comment_id": "39602912", "comment_content": "@bli ", "user_id": "None"}, {"stack_answer_id": "3177911", "stack_answer_comment_id": "76481868", "comment_content": "i have come from the future to tell you of ", "user_id": "None"}]}, {"stack_answer_id": "2258273", "answer_content": "\r\n You could use: \n\n sorted(d.items(), key=lambda x: x[1])\n \n\n This will sort the dictionary by the values of each entry within the dictionary from smallest to largest. \n\n To sort it in descending order just add  reverse=True : \n\n sorted(d.items(), key=lambda x: x[1], reverse=True)\n \n\n Input: \n\n d = {'one':1,'three':3,'five':5,'two':2,'four':4}\na = sorted(d.items(), key=lambda x: x[1])    \nprint(a)\n \n\n Output: \n\n [('one', 1), ('two', 2), ('three', 3), ('four', 4), ('five', 5)]\n \n    ", "date_posted": "2020-01-10 09:43:23Z", "upvote": "\r\n            1098\r\n        ", "accepted": "No", "user": {"stack_user_id": "4815313", "name": "Suresh2692", "reputation_score": "3,633"}, "answer_comments": [{"stack_answer_id": "2258273", "stack_answer_comment_id": "21031477", "comment_content": "From what I've seen (", "user_id": "None"}, {"stack_answer_id": "2258273", "stack_answer_comment_id": "47252672", "comment_content": "I'd prefer ", "user_id": "None"}, {"stack_answer_id": "2258273", "stack_answer_comment_id": "55249296", "comment_content": "@Keyo shouldn't that be it returns an ordered list of keys (sorted by values) not ", "user_id": "None"}, {"stack_answer_id": "2258273", "stack_answer_comment_id": "58175437", "comment_content": "@Claudiu I like that ", "user_id": "None"}, {"stack_answer_id": "2258273", "stack_answer_comment_id": "97286619", "comment_content": "If you wrap this in an ", "user_id": "None"}]}, {"stack_answer_id": "613228", "answer_content": "\r\n Dicts can't be sorted, but you can build a sorted list from them. \n\n A sorted list of dict values: \n\n sorted(d.values())\n \n\n A list of (key, value) pairs, sorted by value: \n\n from operator import itemgetter\nsorted(d.items(), key=itemgetter(1))\n \n    ", "date_posted": "2014-09-16 17:26:10Z", "upvote": "\r\n            261\r\n        ", "accepted": "No", "user": {"stack_user_id": "13169", "name": "Roberto Bonvallet", "reputation_score": "30.2k"}, "answer_comments": [{"stack_answer_id": "613228", "stack_answer_comment_id": "14505868", "comment_content": "What order are keys with the same value placed in? I sorted the list by keys first, then by values, but the order of the keys with the same value does not remain.", "user_id": "None"}, {"stack_answer_id": "613228", "stack_answer_comment_id": "108645446", "comment_content": "Dicts can now be sorted, starting with CPython 3.6 and all other Python implementations starting with 3.7", "user_id": "None"}, {"stack_answer_id": "613228", "stack_answer_comment_id": "126263725", "comment_content": "True at the time, but now python dictionaries preserve the order in which items were inserted already by default. And therefore they can be sorted.", "user_id": "None"}]}, {"stack_answer_id": "3177025", "answer_content": "\r\n In recent Python 2.7, we have the new  OrderedDict  type, which remembers the order in which the items were added. \n\n >>> d = {\"third\": 3, \"first\": 1, \"fourth\": 4, \"second\": 2}\n\n>>> for k, v in d.items():\n...     print \"%s: %s\" % (k, v)\n...\nsecond: 2\nfourth: 4\nthird: 3\nfirst: 1\n\n>>> d\n{'second': 2, 'fourth': 4, 'third': 3, 'first': 1}\n \n\n To make a new ordered dictionary from the original, sorting by the values: \n\n >>> from collections import OrderedDict\n>>> d_sorted_by_value = OrderedDict(sorted(d.items(), key=lambda x: x[1]))\n \n\n The OrderedDict behaves like a normal dict: \n\n >>> for k, v in d_sorted_by_value.items():\n...     print \"%s: %s\" % (k, v)\n...\nfirst: 1\nsecond: 2\nthird: 3\nfourth: 4\n\n>>> d_sorted_by_value\nOrderedDict([('first': 1), ('second': 2), ('third': 3), ('fourth': 4)])\n \n    ", "date_posted": "2014-04-03 16:59:39Z", "upvote": "\r\n            180\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "3177025", "stack_answer_comment_id": "3271246", "comment_content": "This is not what the question is about - it is not about maintaining order of keys but about \"sorting by value\"", "user_id": "None"}, {"stack_answer_id": "3177025", "stack_answer_comment_id": "3272707", "comment_content": "@Nas Banov: it is NOT sorting by the key. it is sorting in the order, we create the items. in our case, we sort by the value. unfortunately, the 3-item dict was unfortunately chosen so the order was the same, when sorted voth by value and key, so i expanded the sample dict.", "user_id": "None"}, {"stack_answer_id": "3177025", "stack_answer_comment_id": "29524413", "comment_content": " Can you explain what the ", "user_id": "None"}, {"stack_answer_id": "3177025", "stack_answer_comment_id": "86527438", "comment_content": "@Boern ", "user_id": "None"}, {"stack_answer_id": "3177025", "stack_answer_comment_id": "102011442", "comment_content": "Note: As of 3.6 (as a CPython/PyPy implementation detail) and as of 3.7 (as a Python language guarantee), plain ", "user_id": "None"}]}, {"stack_answer_id": "34103440", "answer_content": "\r\n UPDATE: 5 DECEMBER 2015 using Python 3.5 \n\n Whilst I found the accepted answer useful, I was also surprised that it hasn't been updated to reference  OrderedDict  from the standard library  collections  module as a viable, modern alternative - designed to solve exactly this type of problem. \n\n from operator import itemgetter\nfrom collections import OrderedDict\n\nx = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}\nsorted_x = OrderedDict(sorted(x.items(), key=itemgetter(1)))\n# OrderedDict([(0, 0), (2, 1), (1, 2), (4, 3), (3, 4)])\n \n\n The official  OrderedDict  documentation offers a very similar example too, but using a lambda for the sort function: \n\n # regular unsorted dictionary\nd = {'banana': 3, 'apple':4, 'pear': 1, 'orange': 2}\n\n# dictionary sorted by value\nOrderedDict(sorted(d.items(), key=lambda t: t[1]))\n# OrderedDict([('pear', 1), ('orange', 2), ('banana', 3), ('apple', 4)])\n \n    ", "date_posted": "2015-12-15 05:54:53Z", "upvote": "\r\n            120\r\n        ", "accepted": "No", "user": {"stack_user_id": "1882064", "name": "arcseldon", "reputation_score": "33.3k"}, "answer_comments": [{"stack_answer_id": "34103440", "stack_answer_comment_id": "126263884", "comment_content": "can you explain what itemgetter does in this example? otherwise this seems just as cryptic as using a lamba", "user_id": "None"}]}, {"stack_answer_id": "613230", "answer_content": "\r\n Pretty much the same as  Hank Gay's answer : \n\n sorted([(value,key) for (key,value) in mydict.items()])\n \n\n Or optimized slightly as suggested by John Fouhy: \n\n sorted((value,key) for (key,value) in mydict.items())\n \n    ", "date_posted": "2019-03-12 05:18:46Z", "upvote": "\r\n            110\r\n        ", "accepted": "No", "user": {"stack_user_id": "11044033", "name": "Justin Batch", "reputation_score": "17"}, "answer_comments": [{"stack_answer_id": "613230", "stack_answer_comment_id": "426122", "comment_content": "..and as with Hank Gay's answer, you don't need the square brackets.  sorted() will happily take any iterable, such as a generator expression.", "user_id": "None"}, {"stack_answer_id": "613230", "stack_answer_comment_id": "2787653", "comment_content": "You may still need to swap the (value,key) tuple elements to end up with the (key, value). Another list comprehension is then needed.  ", "user_id": "None"}, {"stack_answer_id": "613230", "stack_answer_comment_id": "82368076", "comment_content": "no, it's better to leave square brackets, because ", "user_id": "None"}, {"stack_answer_id": "613230", "stack_answer_comment_id": "128345565", "comment_content": "I'm confused, this returns an array of tuples not a dict. IMO you are missing the dict comprehension part:  ", "user_id": "None"}]}, {"stack_answer_id": "39424969", "answer_content": "\r\n As of  Python 3.6  the built-in dict will be ordered \n\n Good news, so the OP's original use case of mapping pairs retrieved from a database with unique string ids as keys and numeric values as values into a built-in Python v3.6+ dict, should now respect the insert order. \n\n If say the resulting two column table expressions from a database query like: \n\n SELECT a_key, a_value FROM a_table ORDER BY a_value;\n \n\n would be stored in two Python tuples, k_seq and v_seq (aligned by numerical index and with the same length of course), then: \n\n k_seq = ('foo', 'bar', 'baz')\nv_seq = (0, 1, 42)\nordered_map = dict(zip(k_seq, v_seq))\n \n\n Allow to output later as: \n\n for k, v in ordered_map.items():\n    print(k, v)\n \n\n yielding in this case (for the new Python 3.6+ built-in dict!): \n\n foo 0\nbar 1\nbaz 42\n \n\n in the same ordering per value of v. \n\n Where in the Python 3.5 install on my machine it currently yields: \n\n bar 1\nfoo 0\nbaz 42\n \n\n Details: \n\n As proposed in 2012 by Raymond Hettinger (cf. mail on python-dev with subject  \"More compact dictionaries with faster iteration\" ) and now (in 2016) announced in a mail by Victor Stinner to python-dev with subject  \"Python 3.6 dict becomes compact and gets a private version; and keywords become ordered\"  due to the fix/implementation of issue 27350  \"Compact and ordered dict\"  in Python 3.6 we will now be able, to use a built-in dict to maintain insert order!! \n\n Hopefully this will lead to a thin layer OrderedDict implementation as a first step. As @JimFasarakis-Hilliard indicated, some see use cases for the OrderedDict type also in the future. I think the Python community at large will carefully inspect, if this will stand the test of time, and what the next steps will be. \n\n Time to rethink our coding habits to not miss the possibilities opened by stable ordering of: \n\n \n Keyword arguments and \n (intermediate) dict storage \n \n\n The first because it eases dispatch in the implementation of functions and methods in some cases. \n\n The second as it encourages to more easily use  dict s as intermediate storage in processing pipelines. \n\n Raymond Hettinger kindly provided documentation explaining \" The Tech Behind Python 3.6 Dictionaries \" - from his San Francisco Python Meetup Group presentation 2016-DEC-08. \n\n And maybe quite some Stack Overflow high decorated question and answer pages will receive variants of this information and many high quality answers will require a per version update too. \n\n Caveat Emptor (but also see below update 2017-12-15): \n\n As @ajcr rightfully notes: \"The order-preserving aspect of this new implementation is considered an implementation detail and should not be relied upon.\" (from the  whatsnew36 ) not nit picking,  but  the citation was cut a bit pessimistic ;-). It continues as \" (this may change in the future, but it is desired to have this new dict implementation in the language for a few releases before changing the language spec to mandate order-preserving semantics for all current and future Python implementations; this also helps preserve backwards-compatibility with older versions of the language where random iteration order is still in effect, e.g. Python 3.5).\" \n\n So as in some human languages (e.g. German), usage shapes the language, and the will now has been declared ... in  whatsnew36 . \n\n Update 2017-12-15: \n\n In a  mail to the python-dev list , Guido van Rossum declared: \n\n \n   Make it so. \"Dict keeps insertion order\" is the ruling. Thanks!  \n \n\n So, the version 3.6 CPython side-effect of dict insertion ordering is now becoming part of the language spec (and not anymore only an implementation detail). That mail thread also surfaced some distinguishing design goals for  collections.OrderedDict  as reminded by Raymond Hettinger during discussion. \n    ", "date_posted": "2017-12-16 15:47:55Z", "upvote": "\r\n            85\r\n        ", "accepted": "No", "user": {"stack_user_id": "378826", "name": "Dilettant", "reputation_score": "3,169"}, "answer_comments": [{"stack_answer_id": "39424969", "stack_answer_comment_id": "66183881", "comment_content": "@ajcr thanks for the caveat, very appreciated -  as smileys and maybe's were weaved into my response,these should indicated, the change is massive but of course, only available for CPython (reference implementation) and PyPy. For something completely different ... I rarely talk to non-implementation details when coding man-machine instructions. If it would only have been Jython ;-) ... I might not have had the courage to write it.", "user_id": "None"}, {"stack_answer_id": "39424969", "stack_answer_comment_id": "69358529", "comment_content": " definitely won't be dropped; instead, it will become a thin wrapper around the current dict implementation (so you might add that it will become more compact, too). Adding that snippet with the ", "user_id": "None"}, {"stack_answer_id": "39424969", "stack_answer_comment_id": "85153020", "comment_content": "In a response to this answer, and structured dicts, I posted ", "user_id": "None"}]}, {"stack_answer_id": "7237524", "answer_content": "\r\n It can often be very handy to use  namedtuple . For example, you have a dictionary of 'name' as keys and 'score' as values and you want to sort on 'score': \n\n import collections\nPlayer = collections.namedtuple('Player', 'score name')\nd = {'John':5, 'Alex':10, 'Richard': 7}\n \n\n sorting with lowest score first: \n\n worst = sorted(Player(v,k) for (k,v) in d.items())\n \n\n sorting with highest score first: \n\n best = sorted([Player(v,k) for (k,v) in d.items()], reverse=True)\n \n\n Now you can get the name and score of, let's say the second-best player (index=1) very Pythonically like this: \n\n player = best[1]\nplayer.name\n    'Richard'\nplayer.score\n    7\n \n    ", "date_posted": "2017-04-24 02:11:59Z", "upvote": "\r\n            83\r\n        ", "accepted": "No", "user": {"stack_user_id": "2470818", "name": "vallentin", "reputation_score": "21.7k"}, "answer_comments": [{"stack_answer_id": "7237524", "stack_answer_comment_id": "71369022", "comment_content": "How could I convert it back to a dictionary?", "user_id": "None"}, {"stack_answer_id": "7237524", "stack_answer_comment_id": "71976890", "comment_content": "as_list=[Player(v,k) for (k,v) in d.items()]       as_dict=dict((p.name,p.score) for p in as_list)", "user_id": "None"}]}, {"stack_answer_id": "4215710", "answer_content": "\r\n I had the same problem, and I solved it like this: \n\n WantedOutput = sorted(MyDict, key=lambda x : MyDict[x]) \n \n\n (People who answer \"It is not possible to sort a dict\" did not read the question! In fact, \"I can sort on the keys, but how can I sort based on the values?\" clearly means that he wants a list of the keys sorted according to the value of their values.) \n\n Please notice that the order is not well defined (keys with the same value will be in an arbitrary order in the output list). \n    ", "date_posted": "2017-11-28 13:44:24Z", "upvote": "\r\n            52\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "4215710", "stack_answer_comment_id": "66528932", "comment_content": "Note that you're both iterating the dictionary and fetching values by their key, so performance wise this is not an optimal solution.", "user_id": "None"}, {"stack_answer_id": "4215710", "stack_answer_comment_id": "95143642", "comment_content": "@Dejell: as the contributor says, he interprets the question as \"can I get the list of keys sorted according to the values\". We don't need the values in the result, we have them in the dictionary.", "user_id": "None"}]}, {"stack_answer_id": "11230132", "answer_content": "\r\n If values are numeric you may also use  Counter  from  collections . \n\n from collections import Counter\n\nx = {'hello': 1, 'python': 5, 'world': 3}\nc = Counter(x)\nprint(c.most_common())\n\n>> [('python', 5), ('world', 3), ('hello', 1)]    \n \n    ", "date_posted": "2019-05-17 13:48:42Z", "upvote": "\r\n            50\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "11230132", "stack_answer_comment_id": "31210677", "comment_content": "what about if you dictionary is >>> x={'hello':1,'python':5, 'world':300}", "user_id": "None"}, {"stack_answer_id": "11230132", "stack_answer_comment_id": "31211363", "comment_content": "@yopy ", "user_id": "None"}]}, {"stack_answer_id": "18375444", "answer_content": "\r\n In Python 2.7, simply do: \n\n from collections import OrderedDict\n# regular unsorted dictionary\nd = {'banana': 3, 'apple':4, 'pear': 1, 'orange': 2}\n\n# dictionary sorted by key\nOrderedDict(sorted(d.items(), key=lambda t: t[0]))\nOrderedDict([('apple', 4), ('banana', 3), ('orange', 2), ('pear', 1)])\n\n# dictionary sorted by value\nOrderedDict(sorted(d.items(), key=lambda t: t[1]))\nOrderedDict([('pear', 1), ('orange', 2), ('banana', 3), ('apple', 4)])\n \n\n copy-paste from :  http://docs.python.org/dev/library/collections.html#ordereddict-examples-and-recipes \n\n Enjoy ;-) \n    ", "date_posted": "2013-08-22 08:38:48Z", "upvote": "\r\n            41\r\n        ", "accepted": "No", "user": {"stack_user_id": "1415325", "name": "sweetdream", "reputation_score": "1,171"}, "answer_comments": []}, {"stack_answer_id": "5227519", "answer_content": "\r\n This is the code: \n\n import operator\norigin_list = [\n    {\"name\": \"foo\", \"rank\": 0, \"rofl\": 20000},\n    {\"name\": \"Silly\", \"rank\": 15, \"rofl\": 1000},\n    {\"name\": \"Baa\", \"rank\": 300, \"rofl\": 20},\n    {\"name\": \"Zoo\", \"rank\": 10, \"rofl\": 200},\n    {\"name\": \"Penguin\", \"rank\": -1, \"rofl\": 10000}\n]\nprint \">> Original >>\"\nfor foo in origin_list:\n    print foo\n\nprint \"\\n>> Rofl sort >>\"\nfor foo in sorted(origin_list, key=operator.itemgetter(\"rofl\")):\n    print foo\n\nprint \"\\n>> Rank sort >>\"\nfor foo in sorted(origin_list, key=operator.itemgetter(\"rank\")):\n    print foo\n \n\n Here are the results: \n\n Original \n\n {'name': 'foo', 'rank': 0, 'rofl': 20000}\n{'name': 'Silly', 'rank': 15, 'rofl': 1000}\n{'name': 'Baa', 'rank': 300, 'rofl': 20}\n{'name': 'Zoo', 'rank': 10, 'rofl': 200}\n{'name': 'Penguin', 'rank': -1, 'rofl': 10000}\n \n\n Rofl \n\n {'name': 'Baa', 'rank': 300, 'rofl': 20}\n{'name': 'Zoo', 'rank': 10, 'rofl': 200}\n{'name': 'Silly', 'rank': 15, 'rofl': 1000}\n{'name': 'Penguin', 'rank': -1, 'rofl': 10000}\n{'name': 'foo', 'rank': 0, 'rofl': 20000}\n \n\n Rank   \n\n {'name': 'Penguin', 'rank': -1, 'rofl': 10000}\n{'name': 'foo', 'rank': 0, 'rofl': 20000}\n{'name': 'Zoo', 'rank': 10, 'rofl': 200}\n{'name': 'Silly', 'rank': 15, 'rofl': 1000}\n{'name': 'Baa', 'rank': 300, 'rofl': 20}\n \n    ", "date_posted": "2016-03-02 07:42:26Z", "upvote": "\r\n            31\r\n        ", "accepted": "No", "user": {"stack_user_id": "1091386", "name": "icedwater", "reputation_score": "4,542"}, "answer_comments": []}, {"stack_answer_id": "22903797", "answer_content": "\r\n Try the following approach. Let us define a dictionary called mydict with the following data: \n\n mydict = {'carl':40,\n          'alan':2,\n          'bob':1,\n          'danny':3}\n \n\n If one wanted to sort the dictionary by keys, one could do something like: \n\n for key in sorted(mydict.iterkeys()):\n    print \"%s: %s\" % (key, mydict[key])\n \n\n This should return the following output: \n\n alan: 2\nbob: 1\ncarl: 40\ndanny: 3\n \n\n On the other hand, if one wanted to sort a dictionary by value (as is asked in the question), one could do the following: \n\n for key, value in sorted(mydict.iteritems(), key=lambda (k,v): (v,k)):\n    print \"%s: %s\" % (key, value)\n \n\n The result of this command (sorting the dictionary by value) should return the following: \n\n bob: 1\nalan: 2\ndanny: 3\ncarl: 40\n \n    ", "date_posted": "2018-05-23 23:11:19Z", "upvote": "\r\n            31\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "22903797", "stack_answer_comment_id": "76931274", "comment_content": "Awesome! ", "user_id": "None"}, {"stack_answer_id": "22903797", "stack_answer_comment_id": "119924329", "comment_content": "this doesn't work in later versions of python that dont support tuple unpacking and where dicts no longer have iteritems()", "user_id": "None"}]}, {"stack_answer_id": "52345214", "answer_content": "\r\n Starting from Python 3.6,  dict  objects are now ordered by insertion order. It's officially in the specs of Python 3.7. \n\n >>> words = {\"python\": 2, \"blah\": 4, \"alice\": 3}\n>>> dict(sorted(words.items(), key=lambda x: x[1]))\n{'python': 2, 'alice': 3, 'blah': 4}\n \n\n Before that, you had to use  OrderedDict . \n\n Python 3.7 documentation  says: \n\n \n   Changed in version 3.7: Dictionary order is guaranteed to be insertion\n  order. This behavior was implementation detail of CPython from 3.6.  \n \n    ", "date_posted": "2018-10-24 14:19:05Z", "upvote": "\r\n            30\r\n        ", "accepted": "No", "user": {"stack_user_id": "1787973", "name": "Maxime Ch\u00e9ramy", "reputation_score": "16.6k"}, "answer_comments": [{"stack_answer_id": "52345214", "stack_answer_comment_id": "93639658", "comment_content": "works great! ", "user_id": "None"}]}, {"stack_answer_id": "613326", "answer_content": "\r\n You can create an \"inverted index\", also \n\n from collections import defaultdict\ninverse= defaultdict( list )\nfor k, v in originalDict.items():\n    inverse[v].append( k )\n \n\n Now your inverse has the values; each value has a list of applicable keys. \n\n for k in sorted(inverse):\n    print k, inverse[k]\n \n    ", "date_posted": "2009-03-05 01:52:18Z", "upvote": "\r\n            27\r\n        ", "accepted": "No", "user": {"stack_user_id": "10661", "name": "S.Lott", "reputation_score": "375k"}, "answer_comments": []}, {"stack_answer_id": "15310681", "answer_content": "\r\n You can use the  collections.Counter . Note, this will work for both numeric and non-numeric values. \n\n >>> x = {1: 2, 3: 4, 4:3, 2:1, 0:0}\n>>> from collections import Counter\n>>> #To sort in reverse order\n>>> Counter(x).most_common()\n[(3, 4), (4, 3), (1, 2), (2, 1), (0, 0)]\n>>> #To sort in ascending order\n>>> Counter(x).most_common()[::-1]\n[(0, 0), (2, 1), (1, 2), (4, 3), (3, 4)]\n>>> #To get a dictionary sorted by values\n>>> from collections import OrderedDict\n>>> OrderedDict(Counter(x).most_common()[::-1])\nOrderedDict([(0, 0), (2, 1), (1, 2), (4, 3), (3, 4)])\n \n    ", "date_posted": "2014-04-03 17:04:58Z", "upvote": "\r\n            25\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "15310681", "stack_answer_comment_id": "34847147", "comment_content": "How is this different from ", "user_id": "None"}]}, {"stack_answer_id": "26049456", "answer_content": "\r\n You can use a  skip dict  which is a dictionary that's permanently sorted by value. \n\n >>> data = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}\n>>> SkipDict(data)\n{0: 0.0, 2: 1.0, 1: 2.0, 4: 3.0, 3: 4.0}\n \n\n If you use  keys() ,  values()  or  items()  then you'll iterate in sorted order by value. \n\n It's implemented using the  skip list  datastructure. \n    ", "date_posted": "2014-09-25 22:56:55Z", "upvote": "\r\n            20\r\n        ", "accepted": "No", "user": {"stack_user_id": "647151", "name": "malthe", "reputation_score": "975"}, "answer_comments": [{"stack_answer_id": "26049456", "stack_answer_comment_id": "106284747", "comment_content": "can we change the order of sort, right now, it is asending, but I want decsending.", "user_id": "None"}, {"stack_answer_id": "26049456", "stack_answer_comment_id": "106286713", "comment_content": "afaik you would have to negate your values in order to reverse the ordering", "user_id": "None"}]}, {"stack_answer_id": "44187197", "answer_content": "\r\n You can also use custom function that can be passed to key. \n\n def dict_val(x):\n    return x[1]\nx = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}\nsorted_x = sorted(x.items(), key=dict_val)\n \n    ", "date_posted": "2019-05-17 14:55:22Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "44187197", "stack_answer_comment_id": "116323245", "comment_content": "This is the only answer that worked so far in python 2.7", "user_id": "None"}]}, {"stack_answer_id": "22150003", "answer_content": "\r\n The collections solution mentioned in another answer is absolutely superb, because you retain a connection between the key and value which in the case of dictionaries is extremely important. \n I don't agree with the number one choice presented in another answer, because it throws away the keys. \n I used the solution mentioned above (code shown below) and retained access to both keys and values and in my case the ordering was on the values, but the importance was the ordering of the keys after ordering the values. \n from collections import Counter\n\nx = {'hello':1, 'python':5, 'world':3}\nc=Counter(x)\nprint( c.most_common() )\n\n\n>> [('python', 5), ('world', 3), ('hello', 1)]\n \n    ", "date_posted": "2021-10-07 10:56:15Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "2211268", "name": "Eamonn Kenny", "reputation_score": "1,681"}, "answer_comments": []}, {"stack_answer_id": "31741215", "answer_content": "\r\n Of course, remember, you need to use  OrderedDict  because regular Python dictionaries don't keep the original order.  \n\n from collections import OrderedDict\na = OrderedDict(sorted(originalDict.items(), key=lambda x: x[1]))\n \n\n \n\n If you do not have Python 2.7 or higher, the best you can do is iterate over the values in a generator function. (There is an  OrderedDict  for 2.4 and 2.6   here , but  \n\n a) I don't know about how well it works  \n\n and  \n\n b) You have to download and install it of course. If you do not have administrative access, then I'm afraid the option's out.) \n\n \n\n def gen(originalDict):\n    for x, y in sorted(zip(originalDict.keys(), originalDict.values()), key=lambda z: z[1]):\n        yield (x, y)\n    #Yields as a tuple with (key, value). You can iterate with conditional clauses to get what you want. \n\nfor bleh, meh in gen(myDict):\n    if bleh == \"foo\":\n        print(myDict[bleh])\n \n\n \n\n You can also print out every value \n\n for bleh, meh in gen(myDict):\n    print(bleh, meh)\n \n\n Please remember to remove the parentheses after print if not using Python 3.0 or above \n    ", "date_posted": "2019-05-17 16:17:06Z", "upvote": "\r\n            17\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "31741215", "stack_answer_comment_id": "94560075", "comment_content": " \u2014 as of Python 3.7, they do.", "user_id": "None"}]}, {"stack_answer_id": "4068769", "answer_content": "\r\n from django.utils.datastructures import SortedDict\n\ndef sortedDictByKey(self,data):\n    \"\"\"Sorted dictionary order by key\"\"\"\n    sortedDict = SortedDict()\n    if data:\n        if isinstance(data, dict):\n            sortedKey = sorted(data.keys())\n            for k in sortedKey:\n                sortedDict[k] = data[k]\n    return sortedDict\n \n    ", "date_posted": "2010-11-01 12:16:41Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "615617", "name": "Argun", "reputation_score": "417"}, "answer_comments": [{"stack_answer_id": "4068769", "stack_answer_comment_id": "8703854", "comment_content": "question was: sort by value, not by keys... I like seeing a function. You can import collections and of course use sorted(data.values())", "user_id": "None"}]}, {"stack_answer_id": "30949456", "answer_content": "\r\n Here is a solution using zip on  d.values()  and  d.keys() .  A few lines down this link (on Dictionary view objects) is: \n\n \n   This allows the creation of (value, key) pairs using zip(): pairs = zip(d.values(), d.keys()). \n \n\n So we can do the following: \n\n d = {'key1': 874.7, 'key2': 5, 'key3': 8.1}\n\nd_sorted = sorted(zip(d.values(), d.keys()))\n\nprint d_sorted \n# prints: [(5, 'key2'), (8.1, 'key3'), (874.7, 'key1')]\n \n    ", "date_posted": "2015-06-20 01:44:58Z", "upvote": "\r\n            15\r\n        ", "accepted": "No", "user": {"stack_user_id": "4663466", "name": "Scott", "reputation_score": "5,681"}, "answer_comments": []}, {"stack_answer_id": "49073645", "answer_content": "\r\n As pointed out by Dilettant , Python 3.6 will now  keep the order ! I thought I'd share a function I wrote that eases the sorting of an iterable (tuple, list, dict). In the latter case, you can sort either on keys or values, and it can take numeric comparison into account.  Only for >= 3.6! \n When you try using sorted on an iterable that holds e.g. strings as well as ints, sorted() will fail. Of course you can force string comparison with str(). However, in some cases you want to do  actual  numeric comparison where  12  is smaller than  20  (which is not the case in string comparison). So I came up with the following. When you want explicit numeric comparison you can use the flag  num_as_num  which will try to do explicit numeric sorting by trying to convert all values to floats. If that succeeds, it will do numeric sorting, otherwise it'll resort to string comparison. \n Comments for improvement welcome. \n def sort_iterable(iterable, sort_on=None, reverse=False, num_as_num=False):\n    def _sort(i):\n      # sort by 0 = keys, 1 values, None for lists and tuples\n      try:\n        if num_as_num:\n          if i is None:\n            _sorted = sorted(iterable, key=lambda v: float(v), reverse=reverse)\n          else:\n            _sorted = dict(sorted(iterable.items(), key=lambda v: float(v[i]), reverse=reverse))\n        else:\n          raise TypeError\n      except (TypeError, ValueError):\n        if i is None:\n          _sorted = sorted(iterable, key=lambda v: str(v), reverse=reverse)\n        else:\n          _sorted = dict(sorted(iterable.items(), key=lambda v: str(v[i]), reverse=reverse))\n      \n      return _sorted\n      \n    if isinstance(iterable, list):\n      sorted_list = _sort(None)\n      return sorted_list\n    elif isinstance(iterable, tuple):\n      sorted_list = tuple(_sort(None))\n      return sorted_list\n    elif isinstance(iterable, dict):\n      if sort_on == 'keys':\n        sorted_dict = _sort(0)\n        return sorted_dict\n      elif sort_on == 'values':\n        sorted_dict = _sort(1)\n        return sorted_dict\n      elif sort_on is not None:\n        raise ValueError(f\"Unexpected value {sort_on} for sort_on. When sorting a dict, use key or values\")\n    else:\n      raise TypeError(f\"Unexpected type {type(iterable)} for iterable. Expected a list, tuple, or dict\")\n \n    ", "date_posted": "2021-02-19 09:00:54Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "1150683", "name": "Bram Vanroy", "reputation_score": "25.5k"}, "answer_comments": []}, {"stack_answer_id": "50554874", "answer_content": "\r\n Just learned relevant skill from  Python for Everybody . \n\n You may use a temporary list to help you to sort the dictionary: \n\n #Assume dictionary to be:\nd = {'apple': 500.1, 'banana': 1500.2, 'orange': 1.0, 'pineapple': 789.0}\n\n# create a temporary list\ntmp = []\n\n# iterate through the dictionary and append each tuple into the temporary list \nfor key, value in d.items():\n    tmptuple = (value, key)\n    tmp.append(tmptuple)\n\n# sort the list in ascending order\ntmp = sorted(tmp)\n\nprint (tmp)\n \n\n If you want to sort the list in descending order, simply change the original sorting line to: \n\n tmp = sorted(tmp, reverse=True)\n \n\n Using list comprehension, the one liner would be: \n\n #Assuming the dictionary looks like\nd = {'apple': 500.1, 'banana': 1500.2, 'orange': 1.0, 'pineapple': 789.0}\n#One liner for sorting in ascending order\nprint (sorted([(v, k) for k, v in d.items()]))\n#One liner for sorting in descending order\nprint (sorted([(v, k) for k, v in d.items()], reverse=True))\n \n\n Sample Output: \n\n #Asending order\n[(1.0, 'orange'), (500.1, 'apple'), (789.0, 'pineapple'), (1500.2, 'banana')]\n#Descending order\n[(1500.2, 'banana'), (789.0, 'pineapple'), (500.1, 'apple'), (1.0, 'orange')]\n \n    ", "date_posted": "2018-05-27 17:59:56Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "5015739", "name": "mcgag", "reputation_score": "195"}, "answer_comments": [{"stack_answer_id": "50554874", "stack_answer_comment_id": "108965274", "comment_content": "If you want to print it in the initial format you should do:print ([(k,v) for v,k in sorted([(v,k) for k,v in d.items()])]) . The output is: [('orange', 1.0), ('apple', 500.1), ('pineapple', 789.0), ('banana', 1500.2)]. With [(k,v) for v,k in sorted([(v,k) for k,v in d.items()], reverse = True)]  the output is: [('banana', 1500.2), ('pineapple', 789.0), ('apple', 500.1), ('orange', 1.0)]", "user_id": "None"}]}, {"stack_answer_id": "7817348", "answer_content": "\r\n Use  ValueSortedDict  from  dicts : \n\n from dicts.sorteddict import ValueSortedDict\nd = {1: 2, 3: 4, 4:3, 2:1, 0:0}\nsorted_dict = ValueSortedDict(d)\nprint sorted_dict.items() \n\n[(0, 0), (2, 1), (1, 2), (4, 3), (3, 4)]\n \n    ", "date_posted": "2011-10-19 06:25:41Z", "upvote": "\r\n            10\r\n        ", "accepted": "No", "user": {"stack_user_id": "700820", "name": "ponty", "reputation_score": "594"}, "answer_comments": []}, {"stack_answer_id": "7947321", "answer_content": "\r\n Iterate through a dict and sort it by its values in descending order: \n\n $ python --version\nPython 3.2.2\n\n$ cat sort_dict_by_val_desc.py \ndictionary = dict(siis = 1, sana = 2, joka = 3, tuli = 4, aina = 5)\nfor word in sorted(dictionary, key=dictionary.get, reverse=True):\n  print(word, dictionary[word])\n\n$ python sort_dict_by_val_desc.py \naina 5\ntuli 4\njoka 3\nsana 2\nsiis 1\n \n    ", "date_posted": "2011-10-30 19:42:06Z", "upvote": "\r\n            10\r\n        ", "accepted": "No", "user": {"stack_user_id": "1021036", "name": "juhoh", "reputation_score": "109"}, "answer_comments": []}, {"stack_answer_id": "8992838", "answer_content": "\r\n If your values are integers, and you use Python 2.7 or newer, you can use  collections.Counter  instead of  dict . The  most_common  method will give you all items, sorted by the value. \n    ", "date_posted": "2012-01-24 19:50:43Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "99057", "name": "Petr Viktorin", "reputation_score": "63.3k"}, "answer_comments": []}, {"stack_answer_id": "8148132", "answer_content": "\r\n This works in 3.1.x: \n\n import operator\nslovar_sorted=sorted(slovar.items(), key=operator.itemgetter(1), reverse=True)\nprint(slovar_sorted)\n \n    ", "date_posted": "2012-11-06 19:27:31Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "442945", "name": "Nathaniel Ford", "reputation_score": "19.3k"}, "answer_comments": []}, {"stack_answer_id": "15587800", "answer_content": "\r\n For the sake of completeness, I am posting a solution using  heapq . Note, this method will work for both numeric and non-numeric values \n\n >>> x = {1: 2, 3: 4, 4:3, 2:1, 0:0}\n>>> x_items = x.items()\n>>> heapq.heapify(x_items)\n>>> #To sort in reverse order\n>>> heapq.nlargest(len(x_items),x_items, operator.itemgetter(1))\n[(3, 4), (4, 3), (1, 2), (2, 1), (0, 0)]\n>>> #To sort in ascending order\n>>> heapq.nsmallest(len(x_items),x_items, operator.itemgetter(1))\n[(0, 0), (2, 1), (1, 2), (4, 3), (3, 4)]\n \n    ", "date_posted": "2013-03-23 14:19:53Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "977038", "name": "Abhijit", "reputation_score": "59.7k"}, "answer_comments": []}], "user": {"stack_user_id": "2786", "name": "Gern Blanston", "reputation_score": "42.2k"}, "question_comments": [{"stack_question_id": "613183", "stack_question_comment_id": "3270272", "comment_content": "The dictionary data structure does not have inherent order. You can iterate through it but there's nothing to guarantee that the iteration will follow any particular order. This is by design, so your best bet is probaly using anohter data structure for representation.", "user_id": "None"}, {"stack_question_id": "613183", "stack_question_comment_id": "20901347", "comment_content": "\"sorted()\" can operate on dictionaries (and returns a list of sorted keys), so I think he's aware of this. Without knowing his program, it's absurd to tell someone they're using the wrong data structure. If fast lookups are what you need 90% of the time, then a dict is probably what you want.", "user_id": "None"}, {"stack_question_id": "613183", "stack_question_comment_id": "59347975", "comment_content": "All three outputs (keys, values, both) for sorting dictionaries are covered here in a clear and concise style: ", "user_id": "None"}, {"stack_question_id": "613183", "stack_question_comment_id": "79215136", "comment_content": "@Daishiman The base class might not be ordered but ", "user_id": "None"}, {"stack_question_id": "613183", "stack_question_comment_id": "94813348", "comment_content": "In Python 3.6+ dictionaries preserve insertion order. This is, of course, not the same as possibility of sorting them by value, but on the other hand it is no longer valid to say that \"dictionary data structure does not have inherent order\".", "user_id": "None"}]},
{"stack_question_id": "1101750", "question_title": "Tkinter: AttributeError: NoneType object has no attribute <attribute name>", "question_content": "\r\n                I've created this simple GUI:\n\nfrom tkinter import *\n\nroot = Tk()\n\ndef grabText(event):\n    print(entryBox.get())    \n\nentryBox = Entry(root, width=60).grid(row=2, column=1, sticky=W)\n\ngrabBtn = ...\r\n", "question_url": "/questions/1101750/tkinter-attributeerror-nonetype-object-has-no-attribute-attribute-name", "date_posted": "Jul 9, 2009 at 3:48", "upvote": "7", "view": "1", "tags": ["python", "user-interface", "tkinter"], "answers_count": "4", "answers": [{"stack_answer_id": "1101765", "answer_content": "\r\n The  grid ,  pack  and  place  functions of the  Entry  object and of all other widgets returns  None . In python when you do  a().b() , the result of the expression is whatever  b()  returns, therefore  Entry(...).grid(...)  will return  None .  \n\n You should split that on to two lines like this: \n\n entryBox = Entry(root, width=60)\nentryBox.grid(row=2, column=1, sticky=W)\n \n\n That way you get your  Entry  reference stored in  entryBox  and it's laid out like you expect. This has a bonus side effect of making your layout easier to understand and maintain if you collect all of your  grid  and/or  pack  statements in blocks. \n    ", "date_posted": "2018-03-16 16:17:18Z", "upvote": "\r\n            135\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "7475225", "name": "Mike - SMT", "reputation_score": "15.7k"}, "answer_comments": [{"stack_answer_id": "1101765", "stack_answer_comment_id": "126379872", "comment_content": "So single line coding is not just syntactical, it also has semantic ramifications which is very unexpected.", "user_id": "None"}, {"stack_answer_id": "1101765", "stack_answer_comment_id": "129540652", "comment_content": "@user7420124, not really. The difference is what you assign to ", "user_id": "None"}]}, {"stack_answer_id": "1102053", "answer_content": "\r\n Change this line: \n\n entryBox=Entry(root,width=60).grid(row=2, column=1,sticky=W)\n \n\n into these two lines: \n\n entryBox=Entry(root,width=60)\nentryBox.grid(row=2, column=1,sticky=W)\n \n\n Just as you already correctly do for  grabBtn ! \n    ", "date_posted": "2019-03-25 17:26:36Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "1222951", "name": "Aran-Fey", "reputation_score": "36.4k"}, "answer_comments": []}, {"stack_answer_id": "68782288", "answer_content": "\r\n Alternative solution for  Python3.8+  versions that allows to put all of this in one line using the  walrus operator : \n (entryBox := Entry(root, width=60)).grid(row=2, column=1, sticky=W)\n \n Now  entryBox  will refer to the  Entry  widget and also get packed. \n For characters per line management I can suggest something like this: \n (var := Button(\n    text='fine', command=some_func, width=20, height=15, activebackground='grey'\n)).grid(row=0, column=0, columnspan=0, rowspan=0, sticky='news')\n \n But at that point might as well just do this \"normally\" (as suggested by other answers) \n Sources: \n \n PEP 572 -- Assignment Expressions \n IMO great video explanation about  walrus operator \n \n    ", "date_posted": "2022-05-26 07:54:17Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "14531062", "name": "Matiiss", "reputation_score": "5,516"}, "answer_comments": []}, {"stack_answer_id": "62545078", "answer_content": "\r\n For  entryBox.get()  to access  get()  method you need  Entry  object but  Entry(root, width=60).grid(row=2, column=1, sticky=W)  returns None. \n entryBox = Entry(root, width=60)  creates a new Entry Object. \n Moreover, you won't need\n entryBox = entryBox.grid(row=2, column=1, sticky=W)  as it will rewrite  entryBox  with None \n \n Just replace  entryBox = entryBox.grid(row=2, column=1, sticky=W) \nwith \n entryBox = Entry(root, width=60)\nentryBox.grid(row=2, column=1, sticky=W)\n \n    ", "date_posted": "2020-06-23 23:04:14Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "13751567", "name": "7u5h4r", "reputation_score": "439"}, "answer_comments": [{"stack_answer_id": "62545078", "stack_answer_comment_id": "119945662", "comment_content": "Isn't this just a duplicate of the accepted answer, but 11 years later?", "user_id": "None"}]}], "user": {"stack_user_id": "68920", "name": "Arnkrishn", "reputation_score": "29.1k"}, "question_comments": []},
{"stack_question_id": "89228", "question_title": "How do I execute a program or call a system command?", "question_content": "\r\n                How do I call an external command within Python as if I'd typed it in a shell or command prompt?\r\n", "question_url": "/questions/89228/how-do-i-execute-a-program-or-call-a-system-command", "date_posted": "Sep 18, 2008 at 1:35", "upvote": "5", "view": "4", "tags": ["python", "shell", "terminal", "subprocess", "command"], "answers_count": "6", "answers": [{"stack_answer_id": "89243", "answer_content": "\r\n Use the  subprocess  module in the standard library: \n import subprocess\nsubprocess.run([\"ls\", \"-l\"])\n \n The advantage of  subprocess.run  over  os.system  is that it is more flexible (you can get the  stdout ,  stderr , the  \"real\" status code , better  error handling , etc...). \n Even  the documentation for  os.system  recommends using  subprocess  instead: \n \n The  subprocess  module provides more powerful facilities for spawning new processes and retrieving their results; using that module is preferable to using this function. See the  Replacing Older Functions with the subprocess Module  section in the  subprocess  documentation for some helpful recipes. \n \n On Python 3.4 and earlier, use  subprocess.call  instead of  .run : \n subprocess.call([\"ls\", \"-l\"])\n \n    ", "date_posted": "2021-06-09 18:44:34Z", "upvote": "\r\n            5488\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": [{"stack_answer_id": "89243", "stack_answer_comment_id": "52559086", "comment_content": "Is there a way to use variable substitution? IE I tried to do ", "user_id": "None"}, {"stack_answer_id": "89243", "stack_answer_comment_id": "52598063", "comment_content": "@KevinWheeler You'll have to use ", "user_id": "None"}, {"stack_answer_id": "89243", "stack_answer_comment_id": "55091938", "comment_content": "@KevinWheeler You should NOT use ", "user_id": "None"}, {"stack_answer_id": "89243", "stack_answer_comment_id": "123644441", "comment_content": "what if I want to pipe things e.g. ", "user_id": "None"}, {"stack_answer_id": "89243", "stack_answer_comment_id": "127649670", "comment_content": "Many arguments version looks like that:  ", "user_id": "None"}]}, {"stack_answer_id": "92395", "answer_content": "\r\n Summary of ways to call external programs, including their advantages and disadvantages: \n \n os.system  passes the command and arguments to your system's shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example: \n os.system(\"some_command < input_file | another_command > output_file\")  \n \n However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, et cetera. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs. \n \n os.popen  will do the same thing as  os.system  except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don't need to worry about escaping anything. Example: \n print(os.popen(\"ls -l\").read())\n \n \n subprocess.Popen . This is intended as a replacement for  os.popen , but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you'd say: \n print subprocess.Popen(\"echo Hello World\", shell=True, stdout=subprocess.PIPE).stdout.read()\n \n instead of \n print os.popen(\"echo Hello World\").read()\n \n but it is nice to have all of the options there in one unified class instead of 4 different popen functions. See  the documentation . \n \n subprocess.call . This is basically just like the  Popen  class and takes all of the same arguments, but it simply waits until the command completes and gives you the return code. For example: \n return_code = subprocess.call(\"echo Hello World\", shell=True)\n \n \n subprocess.run . Python 3.5+ only. Similar to the above but even more flexible and returns a  CompletedProcess  object when the command finishes executing. \n \n os.fork ,  os.exec ,  os.spawn  are similar to their C language counterparts, but I don't recommend using them directly. \n \n \n The  subprocess  module should probably be what you use. \n Finally, please be aware that for all methods where you pass the final command to be executed by the shell as a string and you are responsible for escaping it.  There are serious security implications  if any part of the string that you pass can not be fully trusted. For example, if a user is entering some/any part of the string. If you are unsure, only use these methods with constants. To give you a hint of the implications consider this code: \n print subprocess.Popen(\"echo %s \" % user_input, stdout=PIPE).stdout.read()\n \n and imagine that the user enters something \" my mama didnt love me && rm -rf / \" which could erase the whole filesystem. \n    ", "date_posted": "2021-10-18 03:05:37Z", "upvote": "\r\n            3351\r\n        ", "accepted": "No", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": [{"stack_answer_id": "92395", "stack_answer_comment_id": "49018699", "comment_content": "Nice answer/explanation.  How is this answer justifying Python's motto as described in this article ?  ", "user_id": "None"}, {"stack_answer_id": "92395", "stack_answer_comment_id": "53820265", "comment_content": "If using Python 3.5+, use ", "user_id": "None"}, {"stack_answer_id": "92395", "stack_answer_comment_id": "62619897", "comment_content": "What one typically needs to know is what is done with the child process's STDOUT and STDERR, because if they are ignored, under some (quite common) conditions, eventually the child process will issue a system call to write to STDOUT (STDERR too?) that would exceed the output buffer provided for the process by the OS, and the OS will cause it to block until some process reads from that buffer. So, with the currently recommended ways, ", "user_id": "None"}, {"stack_answer_id": "92395", "stack_answer_comment_id": "80783837", "comment_content": "which of the commands you recommended block my script? i.e. if I want to run multiple commands in a ", "user_id": "None"}, {"stack_answer_id": "92395", "stack_answer_comment_id": "94039654", "comment_content": "This is arguably the wrong way around. Most people only need ", "user_id": "None"}]}, {"stack_answer_id": "95246", "answer_content": "\r\n Typical implementation: \n import subprocess\n\np = subprocess.Popen('ls', shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\nfor line in p.stdout.readlines():\n    print line,\nretval = p.wait()\n \n You are free to do what you want with the  stdout  data in the pipe.  In fact, you can simply omit those parameters ( stdout=  and  stderr= ) and it'll behave like  os.system() . \n    ", "date_posted": "2021-07-25 23:37:57Z", "upvote": "\r\n            420\r\n        ", "accepted": "No", "user": {"stack_user_id": "11082165", "name": "Brian", "reputation_score": "4,787"}, "answer_comments": [{"stack_answer_id": "95246", "stack_answer_comment_id": "18336103", "comment_content": " reads ", "user_id": "None"}, {"stack_answer_id": "95246", "stack_answer_comment_id": "18358478", "comment_content": "Could you elaborate on what you mean by \"if there is no buffering issues\"?  If the process blocks definitely, the subprocess call also blocks.  The same could happen with my original example as well. What else could happen with respect to buffering?", "user_id": "None"}, {"stack_answer_id": "95246", "stack_answer_comment_id": "18358805", "comment_content": "the child process may use block-buffering in non-interactive mode instead of line-buffering so ", "user_id": "None"}, {"stack_answer_id": "95246", "stack_answer_comment_id": "18358836", "comment_content": "the buffering issue only matters if you want output in real time and doesn't apply to your code that doesn't print anything until ", "user_id": "None"}, {"stack_answer_id": "95246", "stack_answer_comment_id": "94039263", "comment_content": "This answer was fine for its time, but we should no longer recommend ", "user_id": "None"}]}, {"stack_answer_id": "2251026", "answer_content": "\r\n Some hints on detaching the child process from the calling one (starting the child process in background). \n\n Suppose you want to start a long task from a CGI script. That is, the child process should live longer than the CGI script execution process. \n\n The classical example from the subprocess module documentation is: \n\n import subprocess\nimport sys\n\n# Some code here\n\npid = subprocess.Popen([sys.executable, \"longtask.py\"]) # Call subprocess\n\n# Some more code here\n \n\n The idea here is that you do not want to wait in the line 'call subprocess' until the longtask.py is finished. But it is not clear what happens after the line 'some more code here' from the example. \n\n My target platform was FreeBSD, but the development was on Windows, so I faced the problem on Windows first. \n\n On Windows (Windows\u00a0XP), the parent process will not finish until the longtask.py has finished its work. It is not what you want in a CGI script. The problem is not specific to Python; in the PHP community the problems are the same. \n\n The solution is to pass DETACHED_PROCESS  Process Creation Flag  to the underlying CreateProcess function in Windows API.\nIf you happen to have installed pywin32, you can import the flag from the win32process module, otherwise you should define it yourself: \n\n DETACHED_PROCESS = 0x00000008\n\npid = subprocess.Popen([sys.executable, \"longtask.py\"],\n                       creationflags=DETACHED_PROCESS).pid\n \n\n /*  UPD 2015.10.27  @eryksun in a comment below notes, that the semantically correct flag is CREATE_NEW_CONSOLE (0x00000010) */ \n\n On FreeBSD we have another problem: when the parent process is finished, it finishes the child processes as well. And that is not what you want in a CGI script either. Some experiments showed that the problem seemed to be in sharing sys.stdout. And the working solution was the following: \n\n pid = subprocess.Popen([sys.executable, \"longtask.py\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, stdin=subprocess.PIPE)\n \n\n I have not checked the code on other platforms and do not know the reasons of the behaviour on FreeBSD. If anyone knows, please share your ideas. Googling on starting background processes in Python does not shed any light yet. \n    ", "date_posted": "2019-11-29 21:46:11Z", "upvote": "\r\n            268\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "2251026", "stack_answer_comment_id": "18336228", "comment_content": "you might also need CREATE_NEW_PROCESS_GROUP flag. See ", "user_id": "None"}, {"stack_answer_id": "2251026", "stack_answer_comment_id": "41807947", "comment_content": "I'm seeing ", "user_id": "None"}, {"stack_answer_id": "2251026", "stack_answer_comment_id": "41828669", "comment_content": "@ubershmekel, I am not sure what you mean and don't have a windows installation. If I recall correctly, without the flags you can not close the ", "user_id": "None"}, {"stack_answer_id": "2251026", "stack_answer_comment_id": "54511646", "comment_content": "The following is incorrect: \"[o]n windows (win xp), the parent process will not finish until the longtask.py has finished its work\". The parent will exit normally, but the console window (conhost.exe instance) only closes when the last attached process exits, and the child may have inherited the parent's console. Setting ", "user_id": "None"}, {"stack_answer_id": "2251026", "stack_answer_comment_id": "54543759", "comment_content": "I didn't mean that executing as a detached process is incorrect. That said, you may need to set the standard handles to files, pipes, or ", "user_id": "None"}]}, {"stack_answer_id": "89237", "answer_content": "\r\n import os\nos.system(\"your command\")\n \n\n Note that this is dangerous, since the command isn't cleaned. I leave it up to you to google for the relevant documentation on the 'os' and 'sys' modules. There are a bunch of functions (exec* and spawn*) that will do similar things. \n    ", "date_posted": "2018-06-03 17:10:00Z", "upvote": "\r\n            202\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "89237", "stack_answer_comment_id": "88457934", "comment_content": "No idea what I meant nearly a decade ago (check the date!), but if I had to guess, it would be that there's no validation done.", "user_id": "None"}, {"stack_answer_id": "89237", "stack_answer_comment_id": "94038788", "comment_content": "This should now point to ", "user_id": "None"}]}, {"stack_answer_id": "89255", "answer_content": "\r\n I'd recommend using the  subprocess  module instead of os.system because it does shell escaping for you and is therefore much safer. \n\n subprocess.call(['ping', 'localhost'])\n \n    ", "date_posted": "2020-02-24 01:01:46Z", "upvote": "\r\n            170\r\n        ", "accepted": "No", "user": {"stack_user_id": "10908375", "name": "Nicolas Gervais", "reputation_score": "30k"}, "answer_comments": [{"stack_answer_id": "89255", "stack_answer_comment_id": "91805349", "comment_content": "If you want to ", "user_id": "None"}, {"stack_answer_id": "89255", "stack_answer_comment_id": "94078666", "comment_content": "This is incorrect: \"", "user_id": "None"}]}, {"stack_answer_id": "89238", "answer_content": "\r\n import os\ncmd = 'ls -al'\nos.system(cmd)\n \n\n If you want to return the results of the command, you can use  os.popen . However, this is deprecated since version 2.6 in favor of the  subprocess module , which other answers have covered well. \n    ", "date_posted": "2016-01-26 16:53:05Z", "upvote": "\r\n            165\r\n        ", "accepted": "No", "user": {"stack_user_id": "1146608", "name": "Patrick M", "reputation_score": "10.2k"}, "answer_comments": [{"stack_answer_id": "89238", "stack_answer_comment_id": "39233700", "comment_content": "popen ", "user_id": "None"}, {"stack_answer_id": "89238", "stack_answer_comment_id": "81287939", "comment_content": "You can also save your result with the os.system call, since it works like the UNIX shell itself, like for example os.system('ls -l > test2.txt')", "user_id": "None"}]}, {"stack_answer_id": "40319875", "answer_content": "\r\n There are lots of different libraries which allow you to call external commands with Python. For each library I've given a description and shown an example of calling an external command. The command I used as the example is  ls -l  (list all files). If you want to find out more about any of the libraries I've listed and linked the documentation for each of them. \n Sources \n \n subprocess:  https://docs.python.org/3.5/library/subprocess.html \n shlex:  https://docs.python.org/3/library/shlex.html \n os:  https://docs.python.org/3.5/library/os.html \n sh:  https://amoffat.github.io/sh/ \n plumbum:  https://plumbum.readthedocs.io/en/latest/ \n pexpect:  https://pexpect.readthedocs.io/en/stable/ \n fabric:  http://www.fabfile.org/ \n envoy:  https://github.com/kennethreitz/envoy \n commands:  https://docs.python.org/2/library/commands.html \n \n These are all the libraries \n Hopefully this will help you make a decision on which library to use :) \n subprocess \n Subprocess allows you to call external commands and connect them to their input/output/error pipes (stdin, stdout, and stderr). Subprocess is the default choice for running commands, but sometimes other modules are better. \n subprocess.run([\"ls\", \"-l\"]) # Run command\nsubprocess.run([\"ls\", \"-l\"], stdout=subprocess.PIPE) # This will run the command and return any output\nsubprocess.run(shlex.split(\"ls -l\")) # You can also use the shlex library to split the command\n \n os \n os is used for \"operating system dependent functionality\". It can also be used to call external commands with  os.system  and  os.popen  (Note: There is also a subprocess.popen). os will always run the shell and is a simple alternative for people who don't need to, or don't know how to use  subprocess.run . \n os.system(\"ls -l\") # Run command\nos.popen(\"ls -l\").read() # This will run the command and return any output\n \n sh \n sh is a subprocess interface which lets you call programs as if they were functions. This is useful if you want to run a command multiple times. \n sh.ls(\"-l\") # Run command normally\nls_cmd = sh.Command(\"ls\") # Save command as a variable\nls_cmd() # Run command as if it were a function\n \n plumbum \n plumbum is a library for \"script-like\" Python programs. You can call programs like functions as in  sh . Plumbum is useful if you want to run a pipeline without the shell. \n ls_cmd = plumbum.local(\"ls -l\") # Get command\nls_cmd() # Run command\n \n pexpect \n pexpect lets you spawn child applications, control them and find patterns in their output. This is a better alternative to subprocess for commands that expect a tty on Unix. \n pexpect.run(\"ls -l\") # Run command as normal\nchild = pexpect.spawn('scp foo user@example.com:.') # Spawns child application\nchild.expect('Password:') # When this is the output\nchild.sendline('mypassword')\n \n fabric \n fabric is a Python 2.5 and 2.7 library. It allows you to execute local and remote shell commands. Fabric is simple alternative for running commands in a secure shell (SSH) \n fabric.operations.local('ls -l') # Run command as normal\nfabric.operations.local('ls -l', capture = True) # Run command and receive output\n \n envoy \n envoy is known as \"subprocess for humans\". It is used as a convenience wrapper around the  subprocess  module. \n r = envoy.run(\"ls -l\") # Run command\nr.std_out # Get output\n \n commands \n commands  contains wrapper functions for  os.popen , but it has been removed from Python 3 since  subprocess  is a better alternative. \n    ", "date_posted": "2021-04-07 17:36:52Z", "upvote": "\r\n            127\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "15954964", "answer_content": "\r\n With the standard library \n\n Use the  subprocess module  (Python 3): \n\n import subprocess\nsubprocess.run(['ls', '-l'])\n \n\n It is the recommended standard way. However, more complicated tasks (pipes, output, input, etc.) can be tedious to construct and write. \n\n Note on Python version: If you are still using Python 2,  subprocess.call  works in a similar way. \n\n ProTip:  shlex.split  can help you to parse the command for  run ,  call , and other  subprocess  functions in case you don't want (or you can't!) provide them in form of lists: \n\n import shlex\nimport subprocess\nsubprocess.run(shlex.split('ls -l'))\n \n\n With external dependencies \n\n If you do not mind external dependencies, use  plumbum : \n\n from plumbum.cmd import ifconfig\nprint(ifconfig['wlan0']())\n \n\n It is the best  subprocess  wrapper. It's cross-platform, i.e. it works on both Windows and Unix-like systems. Install by  pip install plumbum . \n\n Another popular library is  sh : \n\n from sh import ifconfig\nprint(ifconfig('wlan0'))\n \n\n However,  sh  dropped Windows support, so it's not as awesome as it used to be. Install by  pip install sh . \n    ", "date_posted": "2019-11-29 21:54:25Z", "upvote": "\r\n            86\r\n        ", "accepted": "No", "user": {"stack_user_id": "15954964", "name": "\r\n        6 revs, 2 users 79%", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "9676642", "answer_content": "\r\n I always use  fabric  for this things like: \n\n from fabric.operations import local\nresult = local('ls', capture=True)\nprint \"Content:/n%s\" % (result, )\n \n\n But this seem to be a good tool:  sh  (Python subprocess interface) . \n\n Look at an example: \n\n from sh import vgdisplay\nprint vgdisplay()\nprint vgdisplay('-v')\nprint vgdisplay(v=True)\n \n    ", "date_posted": "2019-11-29 21:47:58Z", "upvote": "\r\n            83\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "3879406", "answer_content": "\r\n Check the \"pexpect\" Python library, too. \n\n It allows for interactive controlling of external programs/commands, even ssh, ftp, telnet, etc. You can just type something like: \n\n child = pexpect.spawn('ftp 192.168.0.24')\n\nchild.expect('(?i)name .*: ')\n\nchild.sendline('anonymous')\n\nchild.expect('(?i)password')\n \n    ", "date_posted": "2017-05-28 23:02:27Z", "upvote": "\r\n            81\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "5824565", "answer_content": "\r\n If you need the output from the command you are calling,\nthen you can use  subprocess.check_output  (Python 2.7+). \n\n >>> subprocess.check_output([\"ls\", \"-l\", \"/dev/null\"])\n'crw-rw-rw- 1 root root 1, 3 Oct 18  2007 /dev/null\\n'\n \n\n Also note the  shell  parameter. \n\n \n   If shell is  True , the specified command will be executed through the shell. This can be useful if you are using Python primarily for the enhanced control flow it offers over most system shells and still want convenient access to other shell features such as shell pipes, filename wildcards, environment variable expansion, and expansion of ~ to a user\u2019s home directory. However, note that Python itself offers implementations of many shell-like features (in particular,  glob ,  fnmatch ,  os.walk() ,  os.path.expandvars() ,  os.path.expanduser() , and  shutil ). \n \n    ", "date_posted": "2018-06-03 20:18:34Z", "upvote": "\r\n            79\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "5824565", "stack_answer_comment_id": "84050970", "comment_content": "Note that ", "user_id": "None"}, {"stack_answer_id": "5824565", "stack_answer_comment_id": "120034000", "comment_content": "Like the answer vaguely mentions, and many other answers on this page explain in more detail, you can pass a list, or with ", "user_id": "None"}]}, {"stack_answer_id": "13402722", "answer_content": "\r\n Update: \n\n subprocess.run  is the recommended approach  as of Python 3.5  if your code does not need to maintain compatibility with earlier Python versions. It's more consistent and offers similar ease-of-use as Envoy. (Piping isn't as straightforward though. See  this question for how .) \n\n Here's some examples from  the documentation . \n\n Run a process: \n\n >>> subprocess.run([\"ls\", \"-l\"])  # Doesn't capture output\nCompletedProcess(args=['ls', '-l'], returncode=0)\n \n\n Raise on failed run: \n\n >>> subprocess.run(\"exit 1\", shell=True, check=True)\nTraceback (most recent call last):\n  ...\nsubprocess.CalledProcessError: Command 'exit 1' returned non-zero exit status 1\n \n\n Capture output: \n\n >>> subprocess.run([\"ls\", \"-l\", \"/dev/null\"], stdout=subprocess.PIPE)\nCompletedProcess(args=['ls', '-l', '/dev/null'], returncode=0,\nstdout=b'crw-rw-rw- 1 root root 1, 3 Jan 23 16:23 /dev/null\\n')\n \n\n Original answer: \n\n I recommend trying  Envoy . It's a wrapper for subprocess, which in turn  aims to replace  the older modules and functions. Envoy is subprocess for humans. \n\n Example usage from  the README : \n\n >>> r = envoy.run('git config', data='data to pipe in', timeout=2)\n\n>>> r.status_code\n129\n>>> r.std_out\n'usage: git config [options]'\n>>> r.std_err\n''\n \n\n Pipe stuff around too: \n\n >>> r = envoy.run('uptime | pbcopy')\n\n>>> r.command\n'pbcopy'\n>>> r.status_code\n0\n\n>>> r.history\n[<Response 'uptime'>]\n \n    ", "date_posted": "2019-11-29 21:52:33Z", "upvote": "\r\n            66\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "13106558", "answer_content": "\r\n This is how I run my commands. This code has everything you need pretty much \n\n from subprocess import Popen, PIPE\ncmd = \"ls -l ~/\"\np = Popen(cmd , shell=True, stdout=PIPE, stderr=PIPE)\nout, err = p.communicate()\nprint \"Return code: \", p.returncode\nprint out.rstrip(), err.rstrip()\n \n    ", "date_posted": "2012-10-28 05:44:05Z", "upvote": "\r\n            64\r\n        ", "accepted": "No", "user": {"stack_user_id": "1755213", "name": "Usman Khan", "reputation_score": "681"}, "answer_comments": [{"stack_answer_id": "13106558", "stack_answer_comment_id": "34789609", "comment_content": "I think it's acceptable for hard-coded commands, if it increases readability.", "user_id": "None"}]}, {"stack_answer_id": "46815111", "answer_content": "\r\n \n How to execute a program or call a system command from Python \n \n Simple, use  subprocess.run , which returns a  CompletedProcess  object: \n >>> from subprocess import run\n>>> from shlex import split\n>>> completed_process = run(split('python --version'))\nPython 3.8.8\n>>> completed_process\nCompletedProcess(args=['python', '--version'], returncode=0)\n \n ( run  wants a list of lexically parsed shell arguments - this is what you'd type in a shell, separated by spaces, but not where the spaces are quoted, so use a specialized function,  split , to split up what you would literally type into your shell) \n Why? \n As of Python 3.5, the documentation recommends  subprocess.run : \n \n The recommended approach to invoking subprocesses is to use the run() function for all use cases it can handle. For more advanced use cases, the underlying Popen interface can be used directly. \n \n Here's an example of the simplest possible usage - and it does exactly as asked: \n >>> from subprocess import run\n>>> from shlex import split\n>>> completed_process = run(split('python --version'))\nPython 3.8.8\n>>> completed_process\nCompletedProcess(args=['python', '--version'], returncode=0)\n \n run  waits for the command to successfully finish, then returns a  CompletedProcess  object. It may instead raise  TimeoutExpired  (if you give it a  timeout=  argument) or  CalledProcessError  (if it fails and you pass  check=True ). \n As you might infer from the above example, stdout and stderr both get piped to your own stdout and stderr by default. \n We can inspect the returned object and see the command that was given and the returncode: \n >>> completed_process.args\n['python', '--version']\n>>> completed_process.returncode\n0\n \n Capturing output \n If you want to capture the output, you can pass  subprocess.PIPE  to the appropriate  stderr  or  stdout : \n >>> from subprocess import PIPE\n>>> completed_process = run(shlex.split('python --version'), stdout=PIPE, stderr=PIPE)\n>>> completed_process.stdout\nb'Python 3.8.8\\n'\n>>> completed_process.stderr\nb''\n \n And those respective attributes return bytes. \n Pass a command list \n One might easily move from manually providing a command string (like the question suggests) to providing a string built programmatically.  Don't build strings programmatically.  This is a potential security issue. It's better to assume you don't trust the input. \n >>> import textwrap\n>>> args = ['python', textwrap.__file__]\n>>> cp = run(args, stdout=subprocess.PIPE)\n>>> cp.stdout\nb'Hello there.\\n  This is indented.\\n'\n \n Note, only  args  should be passed positionally. \n Full Signature \n Here's the actual signature in the source and as shown by  help(run) : \n \n def run(*popenargs, input=None, timeout=None, check=False, **kwargs):\n \n \n The  popenargs  and  kwargs  are given to the  Popen  constructor.  input  can be a string of bytes (or unicode, if specify encoding or  universal_newlines=True ) that will be piped to the subprocess's stdin. \n The documentation describes  timeout=  and  check=True  better than I could: \n \n The timeout argument is passed to Popen.communicate(). If the timeout\nexpires, the child process will be killed and waited for. The\nTimeoutExpired exception will be re-raised after the child process has\nterminated. \n If check is true, and the process exits with a non-zero exit code, a\nCalledProcessError exception will be raised. Attributes of that\nexception hold the arguments, the exit code, and stdout and stderr if\nthey were captured. \n \n and this example for  check=True  is better than one I could come up with: \n \n >>> subprocess.run(\"exit 1\", shell=True, check=True)\nTraceback (most recent call last):\n  ...\nsubprocess.CalledProcessError: Command 'exit 1' returned non-zero exit status 1\n \n \n Expanded Signature \n Here's an expanded signature, as given in the documentation: \n \n subprocess.run(args, *, stdin=None, input=None, stdout=None, stderr=None, \nshell=False, cwd=None, timeout=None, check=False, encoding=None, \nerrors=None)\n \n \n Note that this indicates that only the args list should be passed positionally. So pass the remaining arguments as keyword arguments. \n Popen \n When use  Popen  instead? I would struggle to find use-case based on the arguments alone. Direct usage of  Popen  would, however, give you access to its methods, including  poll , 'send_signal', 'terminate', and 'wait'. \n Here's the  Popen  signature as given in  the source . I think this is the most precise encapsulation of the information (as opposed to  help(Popen) ): \n \ndef __init__(self, args, bufsize=-1, executable=None,\n             stdin=None, stdout=None, stderr=None,\n             preexec_fn=None, close_fds=True,\n             shell=False, cwd=None, env=None, universal_newlines=None,\n             startupinfo=None, creationflags=0,\n             restore_signals=True, start_new_session=False,\n             pass_fds=(), *, user=None, group=None, extra_groups=None,\n             encoding=None, errors=None, text=None, umask=-1, pipesize=-1):\n\n \n But more informative is  the  Popen  documentation : \n \n subprocess.Popen(args, bufsize=-1, executable=None, stdin=None, stdout=None, \nstderr=None, preexec_fn=None, close_fds=True, shell=False, cwd=None,\nenv=None, universal_newlines=None, startupinfo=None, creationflags=0, \nrestore_signals=True, start_new_session=False, pass_fds=(), *, group=None, \nextra_groups=None, user=None, umask=-1, encoding=None, errors=None, \ntext=None)\n \n Execute a child program in a new process. On POSIX, the class uses\nos.execvp()-like behavior to execute the child program. On Windows,\nthe class uses the Windows CreateProcess() function. The arguments to\nPopen are as follows. \n \n Understanding the remaining documentation on  Popen  will be left as an exercise for the reader. \n    ", "date_posted": "2021-06-10 13:30:04Z", "upvote": "\r\n            54\r\n        ", "accepted": "No", "user": {"stack_user_id": "541136", "name": "Russia Must Remove Putin", "reputation_score": "347k"}, "answer_comments": [{"stack_answer_id": "46815111", "stack_answer_comment_id": "92598860", "comment_content": "A simple example of two-way communication between a primary process and a subprocess can be found here: ", "user_id": "None"}]}, {"stack_answer_id": "89262", "answer_content": "\r\n Use  subprocess . \n\n ...or for a very simple command: \n\n import os\nos.system('cat testfile')\n \n    ", "date_posted": "2019-11-29 21:39:08Z", "upvote": "\r\n            53\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "89304", "answer_content": "\r\n os.system  is OK, but kind of dated.  It's also not very secure.  Instead, try  subprocess .   subprocess  does not call sh directly and is therefore more secure than  os.system . \n\n Get more information  here . \n    ", "date_posted": "2016-12-10 13:25:05Z", "upvote": "\r\n            42\r\n        ", "accepted": "No", "user": {"stack_user_id": "4952130", "name": "Dimitris Fasarakis Hilliard", "reputation_score": "139k"}, "answer_comments": [{"stack_answer_id": "89304", "stack_answer_comment_id": "94039191", "comment_content": "While I agree with the overall recommendation, ", "user_id": "None"}]}, {"stack_answer_id": "64341833", "answer_content": "\r\n As of  Python 3.7.0 released on June 27th 2018 ( https://docs.python.org/3/whatsnew/3.7.html ) , you can achieve your desired result in the most powerful while equally simple way. This answer intends to show you the essential summary of various options in a short manner. For in-depth answers, please see the other ones. \n \n TL;DR in 2021 \n The big advantage of  os.system(...)  was its simplicity.  subprocess  is better and still easy to use, especially as of  Python 3.5 . \n import subprocess\nsubprocess.run(\"ls -a\", shell=True)\n \n Note:  This is the exact answer to your question - running a command \n \n like in a shell \n \n \n Preferred Way \n If possible, remove the shell overhead and run the command directly (requires a list). \n import subprocess\nsubprocess.run([\"help\"])\nsubprocess.run([\"ls\", \"-a\"])\n \n Pass program arguments in a list.  Don't include  \\\" -escaping for arguments containing spaces. \n \n Advanced Use Cases \n Checking The Output \n The following code speaks for itself: \n import subprocess\nresult = subprocess.run([\"ls\", \"-a\"], capture_output=True, text=True)\nif \"stackoverflow-logo.png\" in result.stdout:\n    print(\"You're a fan!\")\nelse:\n    print(\"You're not a fan?\")\n \n result.stdout  is all normal program output  excluding errors . Read  result.stderr  to get them. \n capture_output=True  - turns capturing on. Otherwise  result.stderr  and  result.stdout  would be  None . Available from  Python 3.7 . \n text=True  - a convenience argument added in  Python 3.7  which converts the received binary data to Python strings you can easily work with. \n Checking the returncode \n Do \n if result.returncode == 127: print(\"The program failed for some weird reason\")\nelif result.returncode == 0: print(\"The program succeeded\")\nelse: print(\"The program failed unexpectedly\")\n \n If you just want to check if the program succeeded (returncode == 0) and otherwise throw an Exception, there is a more convenient function: \n result.check_returncode()\n \n But it's Python, so there's an even more convenient argument  check  which does the same thing automatically for you: \n result = subprocess.run(..., check=True)\n \n stderr should be inside stdout \n You might want to have all program output inside stdout, even errors. To accomplish this, run \n result = subprocess.run(..., stderr=subprocess.STDOUT)\n \n result.stderr  will then be  None  and  result.stdout  will contain everything. \n Using shell=False with an argument string \n shell=False  expects a  list  of arguments. You might however, split an argument string on your own using shlex. \n import subprocess\nimport shlex\nsubprocess.run(shlex.split(\"ls -a\"))\n \n That's it. \n Common Problems \n Chances are high you just started using Python when you come across this question. Let's look at some common problems. \n \n FileNotFoundError: [Errno 2] No such file or directory: 'ls -a': 'ls -a' \n \n You're running a subprocess without  shell=True  . Either use a list ( [\"ls\", \"-a\"] ) or set  shell=True . \n \n TypeError: [...] NoneType [...] \n \n Check that you've set  capture_output=True . \n \n TypeError: a bytes-like object is required, not [...] \n \n You always receive byte results from your program. If you want to work with it like a normal string, set  text=True . \n \n subprocess.CalledProcessError: Command '[...]' returned non-zero exit status 1. \n \n Your command didn't run successfully. You could disable returncode checking or check your actual program's validity. \n \n TypeError:  init () got an unexpected keyword argument [...] \n \n You're likely using a version of Python older than 3.7.0; update it to the most recent one available. Otherwise there are other answers in this Stack Overflow post showing you older alternative solutions. \n    ", "date_posted": "2021-04-07 17:55:45Z", "upvote": "\r\n            42\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "64341833", "stack_answer_comment_id": "118105684", "comment_content": "\"The big advantage of os.system(...) was its simplicity. subprocess is better\" - how subprocess is better? I am happily using os.system, not sure how switching to subprocess and remembering extra ", "user_id": "None"}, {"stack_answer_id": "64341833", "stack_answer_comment_id": "118133731", "comment_content": "You're right in that ", "user_id": "None"}, {"stack_answer_id": "64341833", "stack_answer_comment_id": "118133786", "comment_content": "The problem with ", "user_id": "None"}, {"stack_answer_id": "64341833", "stack_answer_comment_id": "118133803", "comment_content": "Summing up, ", "user_id": "None"}]}, {"stack_answer_id": "26305089", "answer_content": "\r\n There is also  Plumbum \n\n >>> from plumbum import local\n>>> ls = local[\"ls\"]\n>>> ls\nLocalCommand(<LocalPath /bin/ls>)\n>>> ls()\nu'build.py\\ndist\\ndocs\\nLICENSE\\nplumbum\\nREADME.rst\\nsetup.py\\ntests\\ntodo.txt\\n'\n>>> notepad = local[\"c:\\\\windows\\\\notepad.exe\"]\n>>> notepad()                                   # Notepad window pops up\nu''                                             # Notepad window is closed by user, command returns\n \n    ", "date_posted": "2014-10-10 17:41:13Z", "upvote": "\r\n            39\r\n        ", "accepted": "No", "user": {"stack_user_id": "394370", "name": "stuckintheshuck", "reputation_score": "2,401"}, "answer_comments": [{"stack_answer_id": "26305089", "stack_answer_comment_id": "118415297", "comment_content": "An explanation would be in order.", "user_id": "None"}]}, {"stack_answer_id": "31114625", "answer_content": "\r\n Use: \n\n import os\n\ncmd = 'ls -al'\n\nos.system(cmd)\n \n\n os - This module provides a portable way of using operating system-dependent functionality. \n\n For the more  os  functions,  here  is the documentation. \n    ", "date_posted": "2017-05-28 23:05:23Z", "upvote": "\r\n            32\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "31114625", "stack_answer_comment_id": "56118340", "comment_content": "it's also deprecated.  use subprocess", "user_id": "None"}]}, {"stack_answer_id": "50101887", "answer_content": "\r\n It can be this simple: \n\n import os\ncmd = \"your command\"\nos.system(cmd)\n \n    ", "date_posted": "2018-06-08 12:06:53Z", "upvote": "\r\n            32\r\n        ", "accepted": "No", "user": {"stack_user_id": "6634322", "name": "Samadi Salahedine", "reputation_score": "517"}, "answer_comments": [{"stack_answer_id": "50101887", "stack_answer_comment_id": "94038650", "comment_content": "This fails to point out the drawbacks, which are explained in much more detail in ", "user_id": "None"}]}, {"stack_answer_id": "2030768", "answer_content": "\r\n There is another difference here which is not mentioned previously. \n\n subprocess.Popen  executes the <command> as a subprocess. In my case, I need to execute file <a> which needs to communicate with another program, <b>.  \n\n I tried subprocess, and execution was successful. However <b> could not communicate with <a>.\nEverything is normal when I run both from the terminal. \n\n One more: \n(NOTE: kwrite behaves different from other applications. If you try the below with Firefox, the results will not be the same.) \n\n If you try  os.system(\"kwrite\") , program flow freezes until the user closes kwrite. To overcome that I tried instead  os.system(konsole -e kwrite) . This time program continued to flow, but kwrite became the subprocess of the console. \n\n Anyone runs the kwrite not being a subprocess (i.e. in the system monitor it must appear at the leftmost edge of the tree). \n    ", "date_posted": "2018-06-03 20:14:32Z", "upvote": "\r\n            26\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "2030768", "stack_answer_comment_id": "88350869", "comment_content": "What do you mean by ", "user_id": "None"}, {"stack_answer_id": "2030768", "stack_answer_comment_id": "120034031", "comment_content": "It is baffling indeed that ", "user_id": "None"}]}, {"stack_answer_id": "10988365", "answer_content": "\r\n os.system  does not allow you to store results, so if you want to store results in some list or something, a  subprocess.call  works. \n    ", "date_posted": "2019-11-29 21:48:26Z", "upvote": "\r\n            26\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "4728086", "answer_content": "\r\n subprocess.check_call  is convenient if you don't want to test return values. It throws an exception on any error. \n    ", "date_posted": "2011-01-18 19:21:44Z", "upvote": "\r\n            25\r\n        ", "accepted": "No", "user": {"stack_user_id": "263998", "name": "cdunn2001", "reputation_score": "16.9k"}, "answer_comments": []}, {"stack_answer_id": "23391049", "answer_content": "\r\n I tend to use  subprocess  together with  shlex  (to handle escaping of quoted strings): \n\n >>> import subprocess, shlex\n>>> command = 'ls -l \"/your/path/with spaces/\"'\n>>> call_params = shlex.split(command)\n>>> print call_params\n[\"ls\", \"-l\", \"/your/path/with spaces/\"]\n>>> subprocess.call(call_params)\n \n    ", "date_posted": "2014-04-30 14:37:04Z", "upvote": "\r\n            25\r\n        ", "accepted": "No", "user": {"stack_user_id": "117268", "name": "Emil Stenstr\u00f6m", "reputation_score": "12.3k"}, "answer_comments": []}, {"stack_answer_id": "23416345", "answer_content": "\r\n I wrote a library for this,  shell.py . \n It's basically a wrapper for popen and shlex for now. It also supports piping commands, so you can chain commands easier in Python. So you can do things like: \n ex('echo hello shell.py') | \"awk '{print $2}'\"\n \n    ", "date_posted": "2021-04-07 17:28:21Z", "upvote": "\r\n            21\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "37877635", "answer_content": "\r\n In Windows you can just import the  subprocess  module and run external commands by calling  subprocess.Popen() ,  subprocess.Popen().communicate()  and  subprocess.Popen().wait()  as below: \n\n # Python script to run a command line\nimport subprocess\n\ndef execute(cmd):\n    \"\"\"\n        Purpose  : To execute a command and return exit status\n        Argument : cmd - command to execute\n        Return   : exit_code\n    \"\"\"\n    process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    (result, error) = process.communicate()\n\n    rc = process.wait()\n\n    if rc != 0:\n        print \"Error: failed to execute command:\", cmd\n        print error\n    return result\n# def\n\ncommand = \"tasklist | grep python\"\nprint \"This process detail: \\n\", execute(command)\n \n\n Output: \n\n This process detail:\npython.exe                     604 RDP-Tcp#0                  4      5,660 K\n \n    ", "date_posted": "2017-05-28 23:08:28Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "40824514", "answer_content": "\r\n Under Linux, in case you would like to call an external command that will execute independently (will keep running after the Python script terminates), you can use a simple queue as  task spooler  or the  at  command. \n An example with task spooler: \n import os\nos.system('ts <your-command>')\n \n Notes about task spooler ( ts ): \n \n You could set the number of concurrent processes to be run (\"slots\") with: \n ts -S <number-of-slots> \n \n Installing  ts  doesn't requires admin privileges. You can download and compile it from source with a simple  make , add it to your path and you're done. \n \n \n    ", "date_posted": "2021-04-07 17:39:42Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "40824514", "stack_answer_comment_id": "94039329", "comment_content": " is not standard on any distro I know of, though the pointer to ", "user_id": "None"}]}, {"stack_answer_id": "52339862", "answer_content": "\r\n Invoke  is a Python (2.7 and 3.4+) task execution tool and library. It provides a clean, high-level API for running shell commands: \n >>> from invoke import run\n>>> cmd = \"pip install -r requirements.txt\"\n>>> result = run(cmd, hide=True, warn=True)\n>>> print(result.ok)\nTrue\n>>> print(result.stdout.splitlines()[-1])\nSuccessfully installed invocations-0.13.0 pep8-1.5.7 spec-1.3.1\n \n    ", "date_posted": "2021-04-07 17:43:26Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "52339862", "stack_answer_comment_id": "96968474", "comment_content": "This is a great library.  I was trying to explain it to a coworker the other day adn described it like this: ", "user_id": "None"}]}, {"stack_answer_id": "11507283", "answer_content": "\r\n You can use Popen, and then you can check the procedure's status: \n\n from subprocess import Popen\n\nproc = Popen(['ls', '-l'])\nif proc.poll() is None:\n    proc.kill()\n \n\n Check out  subprocess.Popen . \n    ", "date_posted": "2017-05-28 23:01:49Z", "upvote": "\r\n            18\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}], "user": {"stack_user_id": "17085", "name": "freshWoWer", "reputation_score": "59.4k"}, "question_comments": []},
{"stack_question_id": "17071871", "question_title": "How do I select rows from a DataFrame based on column values?", "question_content": "\r\n                How can I select rows from a DataFrame based on values in some column in Pandas?\nIn SQL, I would use:\nSELECT *\nFROM table\nWHERE column_name = some_value\r\n", "question_url": "/questions/17071871/how-do-i-select-rows-from-a-dataframe-based-on-column-values", "date_posted": "Jun 12, 2013 at 17:42", "upvote": "3", "view": "5", "tags": ["python", "pandas", "dataframe"], "answers_count": "1", "answers": [{"stack_answer_id": "17071908", "answer_content": "\r\n To select rows whose column value equals a scalar,  some_value , use  == : \n\n df.loc[df['column_name'] == some_value]\n \n\n To select rows whose column value is in an iterable,  some_values , use  isin : \n\n df.loc[df['column_name'].isin(some_values)]\n \n\n Combine multiple conditions with  & :  \n\n df.loc[(df['column_name'] >= A) & (df['column_name'] <= B)]\n \n\n Note the parentheses. Due to Python's  operator precedence rules ,  &  binds more tightly than  <=  and  >= . Thus, the parentheses in the last example are necessary. Without the parentheses  \n\n df['column_name'] >= A & df['column_name'] <= B\n \n\n is parsed as  \n\n df['column_name'] >= (A & df['column_name']) <= B\n \n\n which results in a  Truth value of a Series is ambiguous error . \n\n \n\n To select rows whose column value  does not equal   some_value , use  != : \n\n df.loc[df['column_name'] != some_value]\n \n\n isin  returns a boolean Series, so to select rows whose value is  not  in  some_values , negate the boolean Series using  ~ : \n\n df.loc[~df['column_name'].isin(some_values)]\n \n\n \n\n For example, \n\n import pandas as pd\nimport numpy as np\ndf = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),\n                   'B': 'one one two three two two one three'.split(),\n                   'C': np.arange(8), 'D': np.arange(8) * 2})\nprint(df)\n#      A      B  C   D\n# 0  foo    one  0   0\n# 1  bar    one  1   2\n# 2  foo    two  2   4\n# 3  bar  three  3   6\n# 4  foo    two  4   8\n# 5  bar    two  5  10\n# 6  foo    one  6  12\n# 7  foo  three  7  14\n\nprint(df.loc[df['A'] == 'foo'])\n \n\n yields \n\n      A      B  C   D\n0  foo    one  0   0\n2  foo    two  2   4\n4  foo    two  4   8\n6  foo    one  6  12\n7  foo  three  7  14\n \n\n \n\n If you have multiple values you want to include, put them in a\nlist (or more generally, any iterable) and use  isin : \n\n print(df.loc[df['B'].isin(['one','three'])])\n \n\n yields \n\n      A      B  C   D\n0  foo    one  0   0\n1  bar    one  1   2\n3  bar  three  3   6\n6  foo    one  6  12\n7  foo  three  7  14\n \n\n \n\n Note, however, that if you wish to do this many times, it is more efficient to\nmake an index first, and then use  df.loc : \n\n df = df.set_index(['B'])\nprint(df.loc['one'])\n \n\n yields \n\n        A  C   D\nB              \none  foo  0   0\none  bar  1   2\none  foo  6  12\n \n\n or, to include multiple values from the index use  df.index.isin : \n\n df.loc[df.index.isin(['one','two'])]\n \n\n yields \n\n        A  C   D\nB              \none  foo  0   0\none  bar  1   2\ntwo  foo  2   4\ntwo  foo  4   8\ntwo  bar  5  10\none  foo  6  12\n \n    ", "date_posted": "2019-01-18 02:47:47Z", "upvote": "\r\n            5828\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "190597", "name": "unutbu", "reputation_score": "791k"}, "answer_comments": [{"stack_answer_id": "17071908", "stack_answer_comment_id": "24690158", "comment_content": "In fact, df[df['colume_name']==some_value] also works. But my first attempt, df.where(df['colume_name']==some_value) does not work... not sure why...", "user_id": "458429"}, {"stack_answer_id": "17071908", "stack_answer_comment_id": "24690368", "comment_content": "When you use ", "user_id": "None"}, {"stack_answer_id": "17071908", "stack_answer_comment_id": "36767217", "comment_content": "Those links could be very useful to many of you: ", "user_id": "None"}, {"stack_answer_id": "17071908", "stack_answer_comment_id": "51447442", "comment_content": "FYI: If you want to select a row based upon two (or more) labels (either requiring both or either), see ", "user_id": "None"}, {"stack_answer_id": "17071908", "stack_answer_comment_id": "88911433", "comment_content": "Since ", "user_id": "None"}]}, {"stack_answer_id": "46165056", "answer_content": "\r\n There are several ways to select rows from a Pandas dataframe: \n \n Boolean indexing ( df[df['col'] == value ] ) \n Positional indexing ( df.iloc[...] ) \n Label indexing ( df.xs(...) ) \n df.query(...)  API \n \n Below I show you examples of each, with advice when to use certain techniques. Assume our criterion is column  'A'  ==  'foo' \n (Note on performance: For each base type, we can keep things simple by using the Pandas API or we can venture outside the API, usually into NumPy, and speed things up.) \n \n Setup \n The first thing we'll need is to identify a condition that will act as our criterion for selecting rows. We'll start with the OP's case  column_name == some_value , and include some other common use cases. \n Borrowing from @unutbu: \n import pandas as pd, numpy as np\n\ndf = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),\n                   'B': 'one one two three two two one three'.split(),\n                   'C': np.arange(8), 'D': np.arange(8) * 2})\n \n \n 1. Boolean indexing \n ... Boolean indexing requires finding the true value of each row's  'A'  column being equal to  'foo' , then using those truth values to identify which rows to keep.  Typically, we'd name this series, an array of truth values,  mask .  We'll do so here as well. \n mask = df['A'] == 'foo'\n \n We can then use this mask to slice or index the data frame \n df[mask]\n\n     A      B  C   D\n0  foo    one  0   0\n2  foo    two  2   4\n4  foo    two  4   8\n6  foo    one  6  12\n7  foo  three  7  14\n \n This is one of the simplest ways to accomplish this task and if performance or intuitiveness isn't an issue, this should be your chosen method.  However, if performance is a concern, then you might want to consider an alternative way of creating the  mask . \n \n 2. Positional indexing \n Positional indexing ( df.iloc[...] ) has its use cases, but this isn't one of them.  In order to identify where to slice, we first need to perform the same boolean analysis we did above.  This leaves us performing one extra step to accomplish the same task. \n mask = df['A'] == 'foo'\npos = np.flatnonzero(mask)\ndf.iloc[pos]\n\n     A      B  C   D\n0  foo    one  0   0\n2  foo    two  2   4\n4  foo    two  4   8\n6  foo    one  6  12\n7  foo  three  7  14\n \n 3. Label indexing \n Label  indexing can be very handy, but in this case, we are again doing more work for no benefit \n df.set_index('A', append=True, drop=False).xs('foo', level=1)\n\n     A      B  C   D\n0  foo    one  0   0\n2  foo    two  2   4\n4  foo    two  4   8\n6  foo    one  6  12\n7  foo  three  7  14\n \n 4.  df.query()  API \n pd.DataFrame.query  is a very elegant/intuitive way to perform this task, but is often slower.  However , if you pay attention to the timings below, for large data, the query is very efficient. More so than the standard approach and of similar magnitude as my best suggestion. \n df.query('A == \"foo\"')\n\n     A      B  C   D\n0  foo    one  0   0\n2  foo    two  2   4\n4  foo    two  4   8\n6  foo    one  6  12\n7  foo  three  7  14\n \n \n My preference is to use the  Boolean   mask \n Actual improvements can be made by modifying how we create our  Boolean   mask . \n mask  alternative 1 \n Use the underlying NumPy array and forgo the overhead of creating another  pd.Series \n mask = df['A'].values == 'foo'\n \n I'll show more complete time tests at the end, but just take a look at the performance gains we get using the sample data frame.  First, we look at the difference in creating the  mask \n %timeit mask = df['A'].values == 'foo'\n%timeit mask = df['A'] == 'foo'\n\n5.84 \u00b5s \u00b1 195 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n166 \u00b5s \u00b1 4.45 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\n \n Evaluating the  mask  with the NumPy array is ~ 30 times faster.  This is partly due to NumPy evaluation often being faster. It is also partly due to the lack of overhead necessary to build an index and a corresponding  pd.Series  object. \n Next, we'll look at the timing for slicing with one  mask  versus the other. \n mask = df['A'].values == 'foo'\n%timeit df[mask]\nmask = df['A'] == 'foo'\n%timeit df[mask]\n\n219 \u00b5s \u00b1 12.3 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each)\n239 \u00b5s \u00b1 7.03 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each)\n \n The performance gains aren't as pronounced.  We'll see if this holds up over more robust testing. \n \n mask  alternative 2 \nWe could have reconstructed the data frame as well.  There is a big caveat when reconstructing a dataframe\u2014you must take care of the  dtypes  when doing so! \n Instead of  df[mask]  we will do this \n pd.DataFrame(df.values[mask], df.index[mask], df.columns).astype(df.dtypes)\n \n If the data frame is of mixed type, which our example is, then when we get  df.values  the resulting array is of  dtype   object  and consequently, all columns of the new data frame will be of  dtype   object .  Thus requiring the  astype(df.dtypes)  and killing any potential performance gains. \n %timeit df[m]\n%timeit pd.DataFrame(df.values[mask], df.index[mask], df.columns).astype(df.dtypes)\n\n216 \u00b5s \u00b1 10.4 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each)\n1.43 ms \u00b1 39.6 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each)\n \n However, if the data frame is not of mixed type, this is a very useful way to do it. \n Given \n np.random.seed([3,1415])\nd1 = pd.DataFrame(np.random.randint(10, size=(10, 5)), columns=list('ABCDE'))\n\nd1\n\n   A  B  C  D  E\n0  0  2  7  3  8\n1  7  0  6  8  6\n2  0  2  0  4  9\n3  7  3  2  4  3\n4  3  6  7  7  4\n5  5  3  7  5  9\n6  8  7  6  4  7\n7  6  2  6  6  5\n8  2  8  7  5  8\n9  4  7  6  1  5\n \n \n %%timeit\nmask = d1['A'].values == 7\nd1[mask]\n\n179 \u00b5s \u00b1 8.73 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\n \n Versus \n %%timeit\nmask = d1['A'].values == 7\npd.DataFrame(d1.values[mask], d1.index[mask], d1.columns)\n\n87 \u00b5s \u00b1 5.12 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\n \n We cut the time in half. \n \n mask  alternative 3 \n @unutbu also shows us how to use  pd.Series.isin  to account for each element of  df['A']  being in a set of values.  This evaluates to the same thing if our set of values is a set of one value, namely  'foo' .  But it also generalizes to include larger sets of values if needed.  Turns out, this is still pretty fast even though it is a more general solution.  The only real loss is in intuitiveness for those not familiar with the concept. \n mask = df['A'].isin(['foo'])\ndf[mask]\n\n     A      B  C   D\n0  foo    one  0   0\n2  foo    two  2   4\n4  foo    two  4   8\n6  foo    one  6  12\n7  foo  three  7  14\n \n However, as before, we can utilize NumPy to improve performance while sacrificing virtually nothing. We'll use  np.in1d \n mask = np.in1d(df['A'].values, ['foo'])\ndf[mask]\n\n     A      B  C   D\n0  foo    one  0   0\n2  foo    two  2   4\n4  foo    two  4   8\n6  foo    one  6  12\n7  foo  three  7  14\n \n \n Timing \n I'll include other concepts mentioned in other posts as well for reference. \n Code Below \n Each  column  in this table represents a different length data frame over which we test each function. Each column shows relative time taken, with the fastest function given a base index of  1.0 . \n res.div(res.min())\n\n                         10        30        100       300       1000      3000      10000     30000\nmask_standard         2.156872  1.850663  2.034149  2.166312  2.164541  3.090372  2.981326  3.131151\nmask_standard_loc     1.879035  1.782366  1.988823  2.338112  2.361391  3.036131  2.998112  2.990103\nmask_with_values      1.010166  1.000000  1.005113  1.026363  1.028698  1.293741  1.007824  1.016919\nmask_with_values_loc  1.196843  1.300228  1.000000  1.000000  1.038989  1.219233  1.037020  1.000000\nquery                 4.997304  4.765554  5.934096  4.500559  2.997924  2.397013  1.680447  1.398190\nxs_label              4.124597  4.272363  5.596152  4.295331  4.676591  5.710680  6.032809  8.950255\nmask_with_isin        1.674055  1.679935  1.847972  1.724183  1.345111  1.405231  1.253554  1.264760\nmask_with_in1d        1.000000  1.083807  1.220493  1.101929  1.000000  1.000000  1.000000  1.144175\n \n You'll notice that the fastest times seem to be shared between  mask_with_values  and  mask_with_in1d . \n res.T.plot(loglog=True)\n \n \n Functions \n def mask_standard(df):\n    mask = df['A'] == 'foo'\n    return df[mask]\n\ndef mask_standard_loc(df):\n    mask = df['A'] == 'foo'\n    return df.loc[mask]\n\ndef mask_with_values(df):\n    mask = df['A'].values == 'foo'\n    return df[mask]\n\ndef mask_with_values_loc(df):\n    mask = df['A'].values == 'foo'\n    return df.loc[mask]\n\ndef query(df):\n    return df.query('A == \"foo\"')\n\ndef xs_label(df):\n    return df.set_index('A', append=True, drop=False).xs('foo', level=-1)\n\ndef mask_with_isin(df):\n    mask = df['A'].isin(['foo'])\n    return df[mask]\n\ndef mask_with_in1d(df):\n    mask = np.in1d(df['A'].values, ['foo'])\n    return df[mask]\n \n \n Testing \n res = pd.DataFrame(\n    index=[\n        'mask_standard', 'mask_standard_loc', 'mask_with_values', 'mask_with_values_loc',\n        'query', 'xs_label', 'mask_with_isin', 'mask_with_in1d'\n    ],\n    columns=[10, 30, 100, 300, 1000, 3000, 10000, 30000],\n    dtype=float\n)\n\nfor j in res.columns:\n    d = pd.concat([df] * j, ignore_index=True)\n    for i in res.index:a\n        stmt = '{}(d)'.format(i)\n        setp = 'from __main__ import d, {}'.format(i)\n        res.at[i, j] = timeit(stmt, setp, number=50)\n \n \n Special Timing \n Looking at the special case when we have a single non-object  dtype  for the entire data frame. \n Code Below \n spec.div(spec.min())\n\n                     10        30        100       300       1000      3000      10000     30000\nmask_with_values  1.009030  1.000000  1.194276  1.000000  1.236892  1.095343  1.000000  1.000000\nmask_with_in1d    1.104638  1.094524  1.156930  1.072094  1.000000  1.000000  1.040043  1.027100\nreconstruct       1.000000  1.142838  1.000000  1.355440  1.650270  2.222181  2.294913  3.406735\n \n Turns out, reconstruction isn't worth it past a few hundred rows. \n spec.T.plot(loglog=True)\n \n \n Functions \n np.random.seed([3,1415])\nd1 = pd.DataFrame(np.random.randint(10, size=(10, 5)), columns=list('ABCDE'))\n\ndef mask_with_values(df):\n    mask = df['A'].values == 'foo'\n    return df[mask]\n\ndef mask_with_in1d(df):\n    mask = np.in1d(df['A'].values, ['foo'])\n    return df[mask]\n\ndef reconstruct(df):\n    v = df.values\n    mask = np.in1d(df['A'].values, ['foo'])\n    return pd.DataFrame(v[mask], df.index[mask], df.columns)\n\nspec = pd.DataFrame(\n    index=['mask_with_values', 'mask_with_in1d', 'reconstruct'],\n    columns=[10, 30, 100, 300, 1000, 3000, 10000, 30000],\n    dtype=float\n)\n \n Testing \n for j in spec.columns:\n    d = pd.concat([df] * j, ignore_index=True)\n    for i in spec.index:\n        stmt = '{}(d)'.format(i)\n        setp = 'from __main__ import d, {}'.format(i)\n        spec.at[i, j] = timeit(stmt, setp, number=50)\n \n    ", "date_posted": "2021-02-04 16:52:19Z", "upvote": "\r\n            695\r\n        ", "accepted": "No", "user": {"stack_user_id": "7758804", "name": "Trenton McKinney", "reputation_score": "46.5k"}, "answer_comments": [{"stack_answer_id": "46165056", "stack_answer_comment_id": "128817483", "comment_content": "use ", "user_id": "None"}]}, {"stack_answer_id": "31296878", "answer_content": "\r\n tl;dr \n The Pandas equivalent to \n select * from table where column_name = some_value\n \n is \n table[table.column_name == some_value]\n \n Multiple conditions: \n table[(table.column_name == some_value) | (table.column_name2 == some_value2)]\n \n or \n table.query('column_name == some_value | column_name2 == some_value2')\n \n Code example \n import pandas as pd\n\n# Create data set\nd = {'foo':[100, 111, 222],\n     'bar':[333, 444, 555]}\ndf = pd.DataFrame(d)\n\n# Full dataframe:\ndf\n\n# Shows:\n#    bar   foo\n# 0  333   100\n# 1  444   111\n# 2  555   222\n\n# Output only the row(s) in df where foo is 222:\ndf[df.foo == 222]\n\n# Shows:\n#    bar  foo\n# 2  555  222\n \n In the above code it is the line  df[df.foo == 222]  that gives the rows based on the column value,  222  in this case. \n Multiple conditions are also possible: \n df[(df.foo == 222) | (df.bar == 444)]\n#    bar  foo\n# 1  444  111\n# 2  555  222\n \n But at that point I would recommend using the  query  function, since it's less verbose and yields the same result: \n df.query('foo == 222 | bar == 444')\n \n    ", "date_posted": "2020-10-05 18:26:21Z", "upvote": "\r\n            333\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "31296878", "stack_answer_comment_id": "86989737", "comment_content": " is the only answer here that is compatible with method chaining.  It seems like it's the pandas analog to ", "user_id": "None"}, {"stack_answer_id": "31296878", "stack_answer_comment_id": "121454506", "comment_content": "Thank you. I tried multiple ways to get a record. The only way worked was using query function.", "user_id": "None"}]}, {"stack_answer_id": "35282530", "answer_content": "\r\n I find the syntax of the previous answers to be redundant and difficult to remember. Pandas introduced the  query()  method in v0.13 and I much prefer it. For your question, you could do  df.query('col == val') \n\n Reproduced from  http://pandas.pydata.org/pandas-docs/version/0.17.0/indexing.html#indexing-query \n\n In [167]: n = 10\n\nIn [168]: df = pd.DataFrame(np.random.rand(n, 3), columns=list('abc'))\n\nIn [169]: df\nOut[169]: \n          a         b         c\n0  0.687704  0.582314  0.281645\n1  0.250846  0.610021  0.420121\n2  0.624328  0.401816  0.932146\n3  0.011763  0.022921  0.244186\n4  0.590198  0.325680  0.890392\n5  0.598892  0.296424  0.007312\n6  0.634625  0.803069  0.123872\n7  0.924168  0.325076  0.303746\n8  0.116822  0.364564  0.454607\n9  0.986142  0.751953  0.561512\n\n# pure python\nIn [170]: df[(df.a < df.b) & (df.b < df.c)]\nOut[170]: \n          a         b         c\n3  0.011763  0.022921  0.244186\n8  0.116822  0.364564  0.454607\n\n# query\nIn [171]: df.query('(a < b) & (b < c)')\nOut[171]: \n          a         b         c\n3  0.011763  0.022921  0.244186\n8  0.116822  0.364564  0.454607\n \n\n You can also access variables in the environment by prepending an  @ . \n\n exclude = ('red', 'orange')\ndf.query('color not in @exclude')\n \n    ", "date_posted": "2016-02-09 01:36:49Z", "upvote": "\r\n            83\r\n        ", "accepted": "No", "user": {"stack_user_id": "3533440", "name": "fredcallaway", "reputation_score": "1,302"}, "answer_comments": []}, {"stack_answer_id": "57338153", "answer_content": "\r\n More flexibility using  .query  with pandas >= 0.25.0: \n Since pandas >= 0.25.0 we can use the  query  method to filter dataframes with pandas methods and even column names which have spaces. Normally the spaces in column names would give an error, but now we can solve that using a backtick (`) - see  GitHub : \n # Example dataframe\ndf = pd.DataFrame({'Sender email':['ex@example.com', \"reply@shop.com\", \"buy@shop.com\"]})\n\n     Sender email\n0  ex@example.com\n1  reply@shop.com\n2    buy@shop.com\n \n Using  .query  with method  str.endswith : \n df.query('`Sender email`.str.endswith(\"@shop.com\")')\n \n Output \n      Sender email\n1  reply@shop.com\n2    buy@shop.com\n \n \n Also we can use local variables by prefixing it with an  @  in our query: \n domain = 'shop.com'\ndf.query('`Sender email`.str.endswith(@domain)')\n \n Output \n      Sender email\n1  reply@shop.com\n2    buy@shop.com\n \n    ", "date_posted": "2022-03-28 11:50:03Z", "upvote": "\r\n            63\r\n        ", "accepted": "No", "user": {"stack_user_id": "9081267", "name": "Erfan", "reputation_score": "37.8k"}, "answer_comments": [{"stack_answer_id": "57338153", "stack_answer_comment_id": "121549942", "comment_content": "Upvoted because the .str cast isn't obvious.", "user_id": "None"}, {"stack_answer_id": "57338153", "stack_answer_comment_id": "126621522", "comment_content": "would be great to know how this performs in terms of efficiency... I can think some reasons it might be more efficient, also some it shouldn't be... I guess it may also have to do with the internal implementation and the number of elements being selected?", "user_id": "None"}]}, {"stack_answer_id": "47693145", "answer_content": "\r\n For selecting only specific columns out of multiple columns for a given value in Pandas: \n select col_name1, col_name2 from table where column_name = some_value.\n \n Options  loc : \n df.loc[df['column_name'] == some_value, [col_name1, col_name2]]\n \n or  query : \n df.query('column_name == some_value')[[col_name1, col_name2]]\n \n    ", "date_posted": "2021-09-05 08:26:39Z", "upvote": "\r\n            36\r\n        ", "accepted": "No", "user": {"stack_user_id": "15497888", "name": "Henry Ecker", "reputation_score": "32.4k"}, "answer_comments": []}, {"stack_answer_id": "65578196", "answer_content": "\r\n In newer versions of Pandas, inspired by the documentation ( Viewing data ): \n df[df[\"colume_name\"] == some_value] #Scalar, True/False..\n\ndf[df[\"colume_name\"] == \"some_value\"] #String\n \n Combine multiple conditions by putting the clause in parentheses,  () , and combining them with  &  and  |  (and/or). Like this: \n df[(df[\"colume_name\"] == \"some_value1\") & (pd[pd[\"colume_name\"] == \"some_value2\"])]\n \n Other filters \n pandas.notna(df[\"colume_name\"]) == True # Not NaN\ndf['colume_name'].str.contains(\"text\") # Search for \"text\"\ndf['colume_name'].str.lower().str.contains(\"text\") # Search for \"text\", after converting  to lowercase\n \n    ", "date_posted": "2021-02-08 15:58:43Z", "upvote": "\r\n            31\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "65578196", "stack_answer_comment_id": "122147955", "comment_content": "Thanks. What if I want to select rows where the length of content of a certain column is >10 ? For example, I want: len(df[\"column_name\"] > 10, is there a straight way of doing this or I must loop over to create a new DataFrame?", "user_id": "None"}]}, {"stack_answer_id": "44931669", "answer_content": "\r\n Faster results can be achieved using  numpy.where .  \n\n For example, with  unubtu's setup  - \n\n In [76]: df.iloc[np.where(df.A.values=='foo')]\nOut[76]: \n     A      B  C   D\n0  foo    one  0   0\n2  foo    two  2   4\n4  foo    two  4   8\n6  foo    one  6  12\n7  foo  three  7  14\n \n\n Timing comparisons: \n\n In [68]: %timeit df.iloc[np.where(df.A.values=='foo')]  # fastest\n1000 loops, best of 3: 380 \u00b5s per loop\n\nIn [69]: %timeit df.loc[df['A'] == 'foo']\n1000 loops, best of 3: 745 \u00b5s per loop\n\nIn [71]: %timeit df.loc[df['A'].isin(['foo'])]\n1000 loops, best of 3: 562 \u00b5s per loop\n\nIn [72]: %timeit df[df.A=='foo']\n1000 loops, best of 3: 796 \u00b5s per loop\n\nIn [74]: %timeit df.query('(A==\"foo\")')  # slowest\n1000 loops, best of 3: 1.71 ms per loop\n \n    ", "date_posted": "2017-10-03 16:17:21Z", "upvote": "\r\n            30\r\n        ", "accepted": "No", "user": {"stack_user_id": "243392", "name": "Brian Burns", "reputation_score": "18.5k"}, "answer_comments": []}, {"stack_answer_id": "17086321", "answer_content": "\r\n Here is a simple example   \n\n from pandas import DataFrame\n\n# Create data set\nd = {'Revenue':[100,111,222], \n     'Cost':[333,444,555]}\ndf = DataFrame(d)\n\n\n# mask = Return True when the value in column \"Revenue\" is equal to 111\nmask = df['Revenue'] == 111\n\nprint mask\n\n# Result:\n# 0    False\n# 1     True\n# 2    False\n# Name: Revenue, dtype: bool\n\n\n# Select * FROM df WHERE Revenue = 111\ndf[mask]\n\n# Result:\n#    Cost    Revenue\n# 1  444     111\n \n    ", "date_posted": "2013-06-13 11:49:00Z", "upvote": "\r\n            28\r\n        ", "accepted": "No", "user": {"stack_user_id": "1821873", "name": "DataByDavid", "reputation_score": "1,009"}, "answer_comments": []}, {"stack_answer_id": "40676816", "answer_content": "\r\n To append to this famous question (though a bit too late): You can also do  df.groupby('column_name').get_group('column_desired_value').reset_index()  to make a new data frame with specified column having a particular value. E.g. \n\n import pandas as pd\ndf = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),\n                   'B': 'one one two three two two one three'.split()})\nprint(\"Original dataframe:\")\nprint(df)\n\nb_is_two_dataframe = pd.DataFrame(df.groupby('B').get_group('two').reset_index()).drop('index', axis = 1) \n#NOTE: the final drop is to remove the extra index column returned by groupby object\nprint('Sub dataframe where B is two:')\nprint(b_is_two_dataframe)\n \n\n Run this gives: \n\n Original dataframe:\n     A      B\n0  foo    one\n1  bar    one\n2  foo    two\n3  bar  three\n4  foo    two\n5  bar    two\n6  foo    one\n7  foo  three\nSub dataframe where B is two:\n     A    B\n0  foo  two\n1  foo  two\n2  bar  two\n \n    ", "date_posted": "2016-11-18 12:10:42Z", "upvote": "\r\n            18\r\n        ", "accepted": "No", "user": {"stack_user_id": "3713927", "name": "TuanDT", "reputation_score": "1,625"}, "answer_comments": []}, {"stack_answer_id": "53674430", "answer_content": "\r\n You can also use .apply: \n\n df.apply(lambda row: row[df['B'].isin(['one','three'])])\n \n\n It actually works row-wise (i.e., applies the function to each row). \n\n The output is  \n\n    A      B  C   D\n0  foo    one  0   0\n1  bar    one  1   2\n3  bar  three  3   6\n6  foo    one  6  12\n7  foo  three  7  14\n \n\n The results is the same as using as mentioned by @unutbu \n\n df[[df['B'].isin(['one','three'])]]\n \n    ", "date_posted": "2018-12-07 17:38:58Z", "upvote": "\r\n            10\r\n        ", "accepted": "No", "user": {"stack_user_id": "4979951", "name": "Vahidn", "reputation_score": "315"}, "answer_comments": []}, {"stack_answer_id": "70120429", "answer_content": "\r\n If you want to make query to your dataframe repeatedly and speed is important to you, the best thing is to convert your dataframe to dictionary and then by doing this you can make query thousands of times faster. \n my_df = df.set_index(column_name)\nmy_dict = my_df.to_dict('index')\n \n After make my_dict dictionary you can go through: \n if some_value in my_dict.keys():\n   my_result = my_dict[some_value]\n \n If you have duplicated values in column_name you can't make a dictionary. but you can use: \n my_result = my_df.loc[some_value]\n \n    ", "date_posted": "2021-11-27 17:09:23Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "13302", "name": "marc_s", "reputation_score": "711k"}, "answer_comments": []}, {"stack_answer_id": "71952267", "answer_content": "\r\n SQL statements on DataFrames to select rows using DuckDB \n With  duckdb  we can query pandas DataFrames with SQL statements, in a  highly performant way . \n Since the question is  How do I select rows from a DataFrame based on column values? , and the example in the question is a SQL query, this answer looks logical in this topic. \n Example : \n In [1]: import duckdb\n\nIn [2]: import pandas as pd\n\nIn [3]: con = duckdb.connect()\n\nIn [4]: df = pd.DataFrame({\"A\": range(11), \"B\": range(11, 22)})\n\nIn [5]: df\nOut[5]:\n     A   B\n0    0  11\n1    1  12\n2    2  13\n3    3  14\n4    4  15\n5    5  16\n6    6  17\n7    7  18\n8    8  19\n9    9  20\n10  10  21\n\nIn [6]: results = con.execute(\"SELECT * FROM df where A > 2\").df()\n\nIn [7]: results\nOut[7]:\n    A   B\n0   3  14\n1   4  15\n2   5  16\n3   6  17\n4   7  18\n5   8  19\n6   9  20\n7  10  21\n \n    ", "date_posted": "2022-04-23 20:00:48Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "9081267", "name": "Erfan", "reputation_score": "37.8k"}, "answer_comments": []}, {"stack_answer_id": "71149332", "answer_content": "\r\n Great answers. Only, when the  size of the dataframe approaches million rows , many of the methods tend to take ages when using  df[df['col']==val] . I wanted to have all possible values of \"another_column\" that correspond to specific values in \"some_column\" (in this case in a dictionary). This worked and fast. \n s=datetime.datetime.now()\n\nmy_dict={}\n\nfor i, my_key in enumerate(df['some_column'].values): \n    if i%100==0:\n        print(i)  # to see the progress\n    if my_key not in my_dict.keys():\n        my_dict[my_key]={}\n        my_dict[my_key]['values']=[df.iloc[i]['another_column']]\n    else:\n        my_dict[my_key]['values'].append(df.iloc[i]['another_column'])\n        \ne=datetime.datetime.now()\n\nprint('operation took '+str(e-s)+' seconds')```\n\n \n    ", "date_posted": "2022-02-16 21:13:21Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "5716832", "name": "L. Astola", "reputation_score": "27"}, "answer_comments": []}, {"stack_answer_id": "73213567", "answer_content": "\r\n You can use  loc  (square brackets) with a function: \n # Series\ns = pd.Series([1, 2, 3, 4]) \ns.loc[lambda x: x > 1]\n# s[lambda x: x > 1]\n \n Output: \n 1    2\n2    3\n3    4\ndtype: int64\n \n or \n # DataFrame\ndf = pd.DataFrame({'A': [1, 2, 3], 'B': [10, 20, 30]})\ndf.loc[lambda x: x['A'] > 1]\n# df[lambda x: x['A'] > 1]\n \n Output: \n    A   B\n1  2  20\n2  3  30\n \n The advantage of this method is that you can chain selection with previous operations. For example: \n df.mul(2).loc[lambda x: x['A'] > 3, 'B']\n# (df * 2).loc[lambda x: x['A'] > 3, 'B']\n \n vs \n df_temp = df * 2\ndf_temp.loc[df_temp['A'] > 3, 'B']\n \n Output: \n 1    40\n2    60\nName: B, dtype: int64\n \n    ", "date_posted": "2022-08-02 20:59:55Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "8973620", "name": "Mykola Zotko", "reputation_score": "12.6k"}, "answer_comments": []}], "user": {"stack_user_id": "458429", "name": "szli", "reputation_score": "33.9k"}, "question_comments": [{"stack_question_id": "17071871", "stack_question_comment_id": "89524024", "comment_content": "Check here: ", "user_id": "None"}, {"stack_question_id": "17071871", "stack_question_comment_id": "94934916", "comment_content": "This is a  Comparison with SQL:  ", "user_id": "None"}, {"stack_question_id": "17071871", "stack_question_comment_id": "118735273", "comment_content": "you can also use DFsql, to run in memory SQL on pandas dataframes ", "user_id": "None"}, {"stack_question_id": "17071871", "stack_question_comment_id": "121502921", "comment_content": "Was led here looking for matching based on a list multiple-column values. This post is just about values in one column. Suggest editing title to read \"values in a column\" to avoid false search results.", "user_id": "None"}, {"stack_question_id": "17071871", "stack_question_comment_id": "129324183", "comment_content": "This question is about ", "user_id": "None"}]},
{"stack_question_id": "5767228", "question_title": "Why is my Button's command executed immediately when I create the Button, and not when I click it?", "question_content": "\r\n                My code is:\nfrom Tkinter import *\n\nadmin = Tk()\ndef button(an):\n    print(an)\n    print('het')\n\nb = Button(admin, text='as', command=button('hey'))\nb.pack()\nmainloop()\n\nThe button doesn't work, it ...\r\n", "question_url": "/questions/5767228/why-is-my-buttons-command-executed-immediately-when-i-create-the-button-and-no", "date_posted": "Apr 23, 2011 at 21:59", "upvote": "9", "view": "3", "tags": ["python", "tkinter", "callback"], "answers_count": "5", "answers": [{"stack_answer_id": "5771787", "answer_content": "\r\n Consider this code: \n b = Button(admin, text='as', command=button('hey'))\n \n It does exactly the same as this: \n result = button('hey')\nb = button(admin, text='as', command=result)\n \n Likewise, if you create a binding like this: \n listbox.bind(\"<<ListboxSelect>>\", some_function())\n \n ... it's the same as this: \n result = some_function()\nlistbox.bind(\"<<ListboxSelect>>\", result)\n \n The  command  option takes a reference to a function, which is a fancy way of saying you need to pass it the name of the function.  To pass a reference you must use the name only, without using parenthesis or arguments. For example: \n b = Button(... command = button)\n \n If you want to pass a parameter such as \"hey\" you must use a little extra code: \n \n You can create an intermediate function that can be called without your argument and which then calls your  button  function, \n You can use  lambda  to create what is referred to as an  anonymous function . In every way it's a function except it doesn't have a name. When you call the  lambda  command it returns a  reference  to the created function, which means it can be used for the value of the  command  option to the button. \n You can use  functools.partial \n \n For me,  lambda  is the simplest since it doesn't require any additional imports like  functools.partial  does, though some people think that  functools.partial  is easier to understand. \n To create a lambda function that calls your  button  function with an argument you would do something like this: \n lambda: button('hey')\n \n You end up with a function that is functionally equivalent to: \n def some_name():\n    return button('hey')\n \n As I said earlier,  lambda  returns a reference to this nameless function. Since a reference is what the  command  option expects you can use  lambda  directly in the creation of the button: \n b = Button(... command = lambda: button('hey'))\n \n There's a question on this site that has a lot of interesting comments about lambda, in general. See the question  Why Python lambdas are useful? . That same discussion has  an answer that shows how to use lambdas in a loop  when you need to pass in a variable to the callback. \n Finally, see the  zone.effbot.org  article titled  Tkinter Callbacks  for a nice tutorial. The coverage of  lambda  is pretty lean, but the information there might still be useful. \n    ", "date_posted": "2021-12-19 09:07:31Z", "upvote": "\r\n            118\r\n        ", "accepted": "No", "user": {"stack_user_id": "355230", "name": "martineau", "reputation_score": "115k"}, "answer_comments": []}, {"stack_answer_id": "5767256", "answer_content": "\r\n You need to create a function without parameters that you can use as the command: \n b = Button(admin, text='as', command=lambda: button('hey'))\n \n See the \"Passing Argument to Callbacks\" section of  this document . \n    ", "date_posted": "2021-12-19 09:29:33Z", "upvote": "\r\n            15\r\n        ", "accepted": "No", "user": {"stack_user_id": "355230", "name": "martineau", "reputation_score": "115k"}, "answer_comments": []}, {"stack_answer_id": "47980499", "answer_content": "\r\n Example GUI: \n Let's say I have the GUI: \n import tkinter as tk\n\nroot = tk.Tk()\n\nbtn = tk.Button(root, text=\"Press\")\nbtn.pack()\n\nroot.mainloop()\n \n What Happens When a Button Is Pressed \n See that when  btn  is pressed it calls  its own  function which is very similar to  button_press_handle  in the following example: \n def button_press_handle(callback=None):\n    if callback:\n        callback() # Where exactly the method assigned to btn['command'] is being callled\n \n with: \n button_press_handle(btn['command'])\n \n You can simply think that  command  option should be set as, the reference to the method we want to be called, similar to  callback  in  button_press_handle . \n \n Calling a Method (a  Callback ) When the Button is Pressed \n Without  arguments \n So if I wanted to  print  something when the button is pressed I would need to set: \n btn['command'] = print # default to print is new line\n \n Pay close attention to the  lack  of  ()  with the  print  method which is omitted in the meaning that:  \"This is the method's name which I want you to call when pressed  but  don't call it just this very instant.\"  However, I didn't pass any arguments for the  print  so it printed whatever it prints when called without arguments. \n With  Argument(s) \n Now If I wanted to also pass arguments to  the method I want to be called  when the button is pressed I could make use of the anonymous functions, which can be created with  lambda  statement, in this case for  print  built-in method, like the following: \n btn['command'] = lambda arg1=\"Hello\", arg2=\" \", arg3=\"World!\" : print(arg1 + arg2 + arg3)\n \n \n Calling  Multiple  Methods when the Button Is Pressed \n Without  Arguments \n You can also achieve that using  lambda  statement but it is considered bad practice and thus I won't include it here. The good practice is to define a separate method,  multiple_methods , that calls the methods wanted and then set it as the callback to the button press: \n def multiple_methods():\n    print(\"Vicariously\") # the first inner callback\n    print(\"I\") # another inner callback\n \n With  Argument(s) \n In order to pass argument(s) to method that calls other methods, again make use of  lambda  statement, but first: \n def multiple_methods(*args, **kwargs):\n    print(args[0]) # the first inner callback\n    print(kwargs['opt1']) # another inner callback\n \n and then set: \n btn['command'] = lambda arg=\"live\", kw=\"as the\" : a_new_method(arg, opt1=kw)\n \n \n Returning Object(s) From the Callback \n Also further note that  callback  can't really  return  because it's only called inside  button_press_handle  with  callback()  as opposed to  return callback() . It does  return  but  not  anywhere outside that function. Thus you should rather  modify  object(s) that are accessible in the current scope. \n \n Complete Example with  global  Object Modification(s) \n Below example will call a method that changes  btn 's text each time the button is pressed: \n import tkinter as tk\n\ni = 0\ndef text_mod():\n    global i, btn           # btn can be omitted but not sure if should be\n    txt = (\"Vicariously\", \"I\", \"live\", \"as\", \"the\", \"whole\", \"world\", \"dies\")\n    btn['text'] = txt[i]    # the global object that is modified\n    i = (i + 1) % len(txt)  # another global object that gets modified\n\nroot = tk.Tk()\n\nbtn = tk.Button(root, text=\"My Button\")\nbtn['command'] = text_mod\n\nbtn.pack(fill='both', expand=True)\n\nroot.mainloop()\n \n \n Mirror \n    ", "date_posted": "2021-12-19 09:34:41Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "355230", "name": "martineau", "reputation_score": "115k"}, "answer_comments": []}, {"stack_answer_id": "53093323", "answer_content": "\r\n The engine evaluates the result of the function when it is assigning the value at the line \"... command = ...\" \n\n The \"command\" expects a function to be returned, that's why using a lambda can do the job because it is creating an anomymous function that is returned to the \"command\" during evaluation. \nYou can also code your own function, it will do the job also. \n\n this is an example with lambda and without lambda: \n\n #!/usr/bin/python\n# coding=utf-8\n\nfrom Tkinter import *\n# Creation de la fen\u00eatre principale (main window)\nMafenetre = Tk()\nres1 = StringVar()\nres2 = StringVar()\n\ndef isValidInput(obj):\n    if hasattr(obj, 'get') and callable(getattr(obj, 'get')):\n        return TRUE\n    return FALSE\n\n\n# stupid action 2 (return 12 on purpose to show potential mistake)\ndef action1(*arguments):\n    print \"action1 running\"\n    for arg in arguments:\n        if isValidInput(arg):\n            print \"input value: \", arg.get()\n            res1.set(arg.get())\n        else:\n            print \"other value:\", arg\n    print \"\\n\"\n    return 12\n\n\n# stupid action 2\ndef action2(*arguments):\n    print \"action2 running\"\n    a = arguments[0]\n    b = arguments[1]\n    if isValidInput(a) and isValidInput(b):\n        c = a.get() + b.get()\n        res2.set(c)\n        print c\n    print \"\\n\"\n\n\n# a stupid workflow manager ordered by name\ndef start_tasks(*arguments, **keywords):\n    keys = sorted(keywords.keys())\n    for kw in keys:\n        print kw, \"plugged \"\n        keywords[kw](*arguments)\n\n\n# valid callback wrapper with lambda\ndef action1_callback(my_input):\n    return lambda args=[my_input]: action1(*args)\n\n\n# valid callback wrapper without lambda\ndef action1_callback_nolambda(*args, **kw):\n    def anon():\n        action1(*args)\n    return anon\n\n\n# first input string\ninput1 = StringVar()\ninput1.set(\"delete me...\")\nf1 = Entry(Mafenetre, textvariable=input1, bg='bisque', fg='maroon')\nf1.focus_set()\nf1.pack(fill=\"both\", expand=\"yes\", padx=\"5\", pady=5)\n\n# failed callback because the action1 function is evaluated, it will return 12. \n# in this case the button won't work at all, because the assignement expect a function \n# in order to have the button command to execute something\nba1 = Button(Mafenetre)\nba1['text'] = \"show input 1 (ko)\"\nba1['command'] = action1(input1)\nba1.pack(fill=\"both\", expand=\"yes\", padx=\"5\", pady=5)\n\n# working button using a wrapper\nba3 = Button(Mafenetre)\nba3['text'] = \"show input 1 (ok)\"\n# without a lambda it is also working if the assignment is a function\n#ba1['command'] = action1_callback_nolambda(input1)\nba3['command'] = action1_callback(input1)\nba3.pack(fill=\"both\", expand=\"yes\", padx=\"5\", pady=5)\n\n# display result label\nLabel1 = Label(Mafenetre, text=\"Action 1 result:\")\nLabel1.pack(fill=\"both\", expand=\"yes\", padx=\"5\", pady=5)\n# display result value\nresl1 = Label(Mafenetre, textvariable=res1)\nresl1.pack(fill=\"both\", expand=\"yes\", padx=\"5\", pady=5)\n\n\n# second input string\ninput2 = StringVar()\nf2 = Entry(Mafenetre, textvariable=input2, bg='bisque', fg='maroon')\nf2.focus_set()\nf2.pack(fill=\"both\", expand=\"yes\", padx=\"5\", pady=5)\n\n# third test without wrapper, but making sure that several arguments are well handled by a lambda function\nba2 = Button(Mafenetre)\nba2['text'] = \"execute action 2\"\nba2['command'] = lambda args=[input1, input2], action=action2: start_tasks(*args, do=action)\nba2.pack(fill=\"both\", expand=\"yes\", padx=\"5\", pady=5)\n\n# display result label\nLabel2 = Label(Mafenetre, text=\"Action 2 result:\")\nLabel2.pack(fill=\"both\", expand=\"yes\", padx=\"5\", pady=5)\n# display result value\nresl2 = Label(Mafenetre, textvariable=res2)\nresl2.pack(fill=\"both\", expand=\"yes\", padx=\"5\", pady=5)\n\nMafenetre.mainloop()\n \n    ", "date_posted": "2018-10-31 23:34:56Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "2703058", "name": "C.Vergnaud", "reputation_score": "827"}, "answer_comments": []}, {"stack_answer_id": "63638418", "answer_content": "\r\n I think the best way to solve this problem is to use a lambda function. \n from tkinter import *\nadmin= Tk()\ndef button(an):\n    print(an)\n    print(\"het\")\nb = Button(admin, text=\"as\", command=lambda: button(\"hey\"))\nb.pack()\nmainloop()\n \n If you don't want to use the command keyword, you can use the .bind() method instead: \n from tkinter import *\nadmin= Tk()\ndef button(an):\n    print(an)\n    print(\"het\")\nb = Button(admin, text=\"as\")\nb.pack()\nb.bind(\"<Button-1>\", lambda bb: button(\"hey\"))\nmainloop()\n \n Using a mother function (no parameter) which owns the child function (at least 1 parameter) you want to call is stupid. \n Just to share with you, this is one of my program: \n import tkinter\nwindow = tkinter.Tk()\n\ndef plus_them(field_1, field_2, field_3):\n    field_3.delete(0, 'end')\n    num1 = 0\n    num2 = 0\n    try:\n        num1 = int(field_1.get())\n        num2 = int(field_2.get())\n    except:\n        print(\"Exception occurs\")\n    else:\n        print(\"Continue\")\n    result = num1 + num2\n    field_3.insert(tkinter.END, str(result))\n    return result\ndef minus_them(field_1, field_2, field_3):\n    field_3.delete(0, 'end')\n    num1 = 0\n    num2 = 0\n    try:\n        num1 = int(field_1.get())\n        num2 = int(field_2.get())\n    except:\n        print(\"Exception occurs\")\n    else:\n        print(\"Continue\")\n    result = num1 - num2\n    field_3.insert(tkinter.END, str(result))\n    return result\n\n#Input Panel:\nlabel_1 = tkinter.Label(window, text=\"First Number:\")\nlabel_1.grid(row=0, column=0)\nlabel_2 = tkinter.Label(window, text=\"Second Number:\")\nlabel_2.grid(row=1, column=0)\nentry_1 = tkinter.Entry(window)\nentry_1.grid(row=0, column=1)\nentry_2 = tkinter.Entry(window)\nentry_2.grid(row=1, column=1)\n\n#Button Panel:\nbutton_1 = tkinter.Button(window, text=\"Plus\")\nbutton_1.grid(row=2, column=0)\nbutton_2 = tkinter.Button(window, text=\"Minus\")\nbutton_2.grid(row=2, column=1)\n\n#Answer Panel:\nlabel_3 = tkinter.Label(window, text=\"The Answer:\")\nlabel_3.grid(row=3, column=0)\nentry_3 = tkinter.Entry(window)\nentry_3.grid(row=3, column=1)\n\n#Event Handling:\nbutton_1.bind(\"<Button-1>\", lambda p: plus_them(entry_1, entry_2, entry_3))\nbutton_2.bind(\"<Button-1>\", lambda m: minus_them(entry_1, entry_2, entry_3))\n\n#Window Stuff:\nwindow.title(\"Plus and Minus Calculator\")\nwindow.mainloop()\n \n That's it. \n    ", "date_posted": "2020-08-28 17:26:39Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "13804724", "name": "Deer Lawson", "reputation_score": "41"}, "answer_comments": []}], "user": {"stack_user_id": "721481", "name": "salk", "reputation_score": "991"}, "question_comments": [{"stack_question_id": "5767228", "stack_question_comment_id": "92941778", "comment_content": "@Mike-SMT That's exactly why. I want to reward people for posting good answers to common questions - especially if the questions are easy. Many people post half-baked, unmotivated answers to easy questions. I want people to realize that you don't have to be a programming expert to write outstanding answers.", "user_id": "None"}, {"stack_question_id": "5767228", "stack_question_comment_id": "129618316", "comment_content": "I already mistakenly dupe-hammered and re-opened this. But now I think it is instead a duplicate of ", "user_id": "None"}]},
{"stack_question_id": "291978", "question_title": "Short description of the scoping rules?", "question_content": "\r\n                What exactly are the Python scoping rules?\n\nIf I have some code:\n\ncode1\nclass Foo:\n   code2\n   def spam.....\n      code3\n      for code4..:\n       code5\n       x()\r\nWhere is x found?  Some possible ...\r\n", "question_url": "/questions/291978/short-description-of-the-scoping-rules", "date_posted": "Nov 15, 2008 at 1:48", "upvote": "5", "view": "2", "tags": ["python", "scope", "dynamic-languages"], "answers_count": "9", "answers": [{"stack_answer_id": "292502", "answer_content": "\r\n Actually, a concise rule for Python Scope resolution, from  Learning Python, 3rd. Ed. . (These rules are specific to variable names, not attributes. If you reference it without a period, these rules apply.) \n\n LEGB Rule \n\n \n L ocal \u2014 Names assigned in any way within a function ( def  or  lambda ), and not declared global in that function \n E nclosing-function \u2014 Names assigned in the local scope of any and all statically enclosing functions ( def  or  lambda ), from inner to outer \n G lobal (module) \u2014 Names assigned at the top-level of a module file, or by executing a  global  statement in a  def  within the file \n B uilt-in (Python) \u2014 Names preassigned in the built-in names module:  open ,  range ,  SyntaxError , etc \n \n\n So, in the case of \n\n code1\nclass Foo:\n    code2\n    def spam():\n        code3\n        for code4:\n            code5\n            x()\n \n\n The  for  loop does not have its own namespace. In LEGB order, the scopes would be  \n\n \n L: Local in  def spam  (in  code3 ,  code4 , and  code5 ) \n E: Any enclosing functions (if the whole example were in another  def ) \n G: Were there any  x  declared globally in the module (in  code1 )? \n B: Any builtin  x  in Python. \n \n\n x  will never be found in  code2  (even in cases where you might expect it would, see  Antti's answer  or  here ). \n    ", "date_posted": "2019-08-25 15:53:35Z", "upvote": "\r\n            442\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "355230", "name": "martineau", "reputation_score": "115k"}, "answer_comments": [{"stack_answer_id": "292502", "stack_answer_comment_id": "14735255", "comment_content": "As a caveat to Global access - reading a global variable can happen without explicit declaration, but writing to it without declaring global(var_name) will instead create a new local instance.", "user_id": "None"}, {"stack_answer_id": "292502", "stack_answer_comment_id": "19372083", "comment_content": "Actually @Peter, ", "user_id": "None"}, {"stack_answer_id": "292502", "stack_answer_comment_id": "20763841", "comment_content": "If so, then why isn't foo's \"y\" variable visible to \"bar\" below:  ", "user_id": "None"}, {"stack_answer_id": "292502", "stack_answer_comment_id": "26476658", "comment_content": "@Jonathan: Because each ", "user_id": "None"}, {"stack_answer_id": "292502", "stack_answer_comment_id": "96658115", "comment_content": "@Ctrl-C Not really; there is nothing special about class attributes in terms of scope. They are shared in the sense that ", "user_id": "None"}]}, {"stack_answer_id": "293097", "answer_content": "\r\n Essentially, the only thing in Python that introduces a new scope is a function definition.  Classes are a bit of a special case in that anything defined directly in the body is placed in the class's namespace, but they are not directly accessible from within the methods (or nested classes) they contain. \n\n In your example there are only 3 scopes where x will be searched in: \n\n \n spam's scope - containing everything defined in code3 and code5 (as well as code4, your loop variable) \n The global scope - containing everything defined in code1, as well as Foo (and whatever changes after it) \n The builtins namespace.  A bit of a special case - this contains the various Python builtin functions and types such as len() and str(). Generally this shouldn't be modified by any user code, so expect it to contain the standard functions and nothing else. \n \n\n More scopes only appear when you introduce a nested function (or lambda) into the picture.\nThese will behave pretty much as you'd expect however.  The nested function can access everything in the local scope, as well as anything in the enclosing function's scope. eg. \n\n def foo():\n    x=4\n    def bar():\n        print x  # Accesses x from foo's scope\n    bar()  # Prints 4\n    x=5\n    bar()  # Prints 5\n \n\n Restrictions: \n\n Variables in scopes other than the local function's variables can be accessed, but can't be rebound to new parameters without further syntax.  Instead, assignment will create a new  local  variable instead of affecting the variable in the parent scope.  For example: \n\n global_var1 = []\nglobal_var2 = 1\n\ndef func():\n    # This is OK: It's just accessing, not rebinding\n    global_var1.append(4) \n\n    # This won't affect global_var2. Instead it creates a new variable\n    global_var2 = 2 \n\n    local1 = 4\n    def embedded_func():\n        # Again, this doen't affect func's local1 variable.  It creates a \n        # new local variable also called local1 instead.\n        local1 = 5\n        print local1\n\n    embedded_func() # Prints 5\n    print local1    # Prints 4\n \n\n In order to actually modify the bindings of global variables from within a function scope, you need to specify that the variable is global with the global keyword.  Eg: \n\n global_var = 4\ndef change_global():\n    global global_var\n    global_var = global_var + 1\n \n\n Currently there is no way to do the same for variables in enclosing  function  scopes, but Python 3 introduces a new keyword, \" nonlocal \" which will act in a similar way to global, but for nested function scopes. \n    ", "date_posted": "2008-11-15 21:51:09Z", "upvote": "\r\n            158\r\n        ", "accepted": "No", "user": {"stack_user_id": "9493", "name": "Brian", "reputation_score": "114k"}, "answer_comments": []}, {"stack_answer_id": "23471004", "answer_content": "\r\n There was no thorough answer concerning Python3 time, so I made an answer here. Most of what is described here is detailed in the  4.2.2 Resolution of names  of the Python 3 documentation. \n\n As provided in other answers, there are 4 basic scopes, the LEGB, for Local, Enclosing, Global and Builtin. In addition to those, there is a special scope, the  class body , which does not comprise an enclosing scope for methods defined within the class; any assignments within the class body make the variable from there on be bound in the class body. \n\n Especially,  no  block statement, besides  def  and  class , create a variable scope. In Python 2 a list comprehension does not create a variable scope, however in Python 3 the loop variable within list comprehensions is created in a new scope. \n\n To demonstrate the peculiarities of the class body \n\n x = 0\nclass X(object):\n    y = x\n    x = x + 1 # x is now a variable\n    z = x\n\n    def method(self):\n        print(self.x) # -> 1\n        print(x)      # -> 0, the global x\n        print(y)      # -> NameError: global name 'y' is not defined\n\ninst = X()\nprint(inst.x, inst.y, inst.z, x) # -> (1, 0, 1, 0)\n \n\n Thus unlike in function body, you can reassign the variable to the same name in class body, to get a class variable with the same name; further lookups on this name resolve\nto the class variable instead. \n\n \n\n One of the greater surprises to many newcomers to Python is that a  for  loop does not create a variable scope. In Python 2 the list comprehensions do not create a scope either (while generators and dict comprehensions do!) Instead they leak the value in the function or the global scope: \n\n >>> [ i for i in range(5) ]\n>>> i\n4\n \n\n The comprehensions can be used as a cunning (or awful if you will) way to make modifiable variables within lambda expressions in Python 2 - a lambda expression does create a variable scope, like the  def  statement would, but within lambda no statements are allowed. Assignment being a statement in Python means that no variable assignments in lambda are allowed, but a list comprehension is an expression... \n\n This behaviour has been fixed in Python 3 - no comprehension expressions or generators leak variables. \n\n \n\n The global really means the module scope; the main python module is the  __main__ ; all imported modules are accessible through the  sys.modules  variable; to get access to  __main__  one can use  sys.modules['__main__'] , or  import __main__ ; it is perfectly acceptable to access and assign attributes there; they will show up as variables in the global scope of the main module. \n\n \n\n If a name is ever assigned to in the current scope (except in the class scope), it will be considered belonging to that scope, otherwise it will be considered to belonging to any enclosing scope that assigns to the variable (it might not be assigned yet, or not at all), or finally the global scope. If the variable is considered local, but it is not set yet, or has been deleted, reading the variable value will result in  UnboundLocalError , which is a subclass of  NameError . \n\n x = 5\ndef foobar():\n    print(x)  # causes UnboundLocalError!\n    x += 1    # because assignment here makes x a local variable within the function\n\n# call the function\nfoobar()\n \n\n The scope can declare that it explicitly wants to modify the global (module scope) variable, with the global keyword: \n\n x = 5\ndef foobar():\n    global x\n    print(x)\n    x += 1\n\nfoobar() # -> 5\nprint(x) # -> 6\n \n\n This also is possible even if it was shadowed in enclosing scope: \n\n x = 5\ny = 13\ndef make_closure():\n    x = 42\n    y = 911\n    def func():\n        global x # sees the global value\n        print(x, y)\n        x += 1\n\n    return func\n\nfunc = make_closure()\nfunc()      # -> 5 911\nprint(x, y) # -> 6 13\n \n\n In python 2 there is no easy way to modify the value in the enclosing scope; usually this is simulated by having a mutable value, such as a list with length of 1: \n\n def make_closure():\n    value = [0]\n    def get_next_value():\n        value[0] += 1\n        return value[0]\n\n    return get_next_value\n\nget_next = make_closure()\nprint(get_next()) # -> 1\nprint(get_next()) # -> 2\n \n\n However in python 3, the  nonlocal  comes to rescue: \n\n def make_closure():\n    value = 0\n    def get_next_value():\n        nonlocal value\n        value += 1\n        return value\n    return get_next_value\n\nget_next = make_closure() # identical behavior to the previous example.\n \n\n The  nonlocal  documentation  says that \n\n \n   Names listed in a nonlocal statement, unlike those listed in a global statement, must refer to pre-existing bindings in an enclosing scope (the scope in which a new binding should be created cannot be determined unambiguously). \n \n\n i.e.  nonlocal  always refers to the innermost outer non-global scope where the name has been bound (i.e. assigned to, including used as the  for  target variable, in the  with  clause, or as a function parameter). \n\n \n\n Any variable that is not deemed to be local to the current scope, or any enclosing scope, is a global variable. A global name is looked up in the module global dictionary; if not found, the global is then looked up from the builtins module; the name of the module was changed from python 2 to python 3; in python 2 it was  __builtin__  and in python 3 it is now called  builtins . If you assign to an attribute of builtins module, it will be visible thereafter to any module as a readable global variable, unless that module shadows them with its own global variable with the same name. \n\n \n\n Reading the builtin module can also be useful; suppose that you want the python 3 style print function in some parts of file, but other parts of file still use the  print  statement. In Python 2.6-2.7 you can get hold of the Python 3  print  function with: \n\n import __builtin__\n\nprint3 = __builtin__.__dict__['print']\n \n\n The  from __future__ import print_function  actually does not import the  print  function anywhere in Python 2 - instead it just disables the parsing rules for  print  statement in the current module, handling  print  like any other variable identifier, and thus allowing the  print  the function be looked up in the builtins. \n    ", "date_posted": "2019-12-04 10:15:38Z", "upvote": "\r\n            114\r\n        ", "accepted": "No", "user": {"stack_user_id": "918959", "name": "Antti Haapala -- \u0421\u043b\u0430\u0432\u0430 \u0423\u043a\u0440\u0430\u0457\u043d\u0456", "reputation_score": "125k"}, "answer_comments": [{"stack_answer_id": "23471004", "stack_answer_comment_id": "118356809", "comment_content": "Glad to finally see an answer that mentions the special ", "user_id": "None"}]}, {"stack_answer_id": "34094235", "answer_content": "\r\n A slightly more complete example of scope: \n\n from __future__ import print_function  # for python 2 support\n\nx = 100\nprint(\"1. Global x:\", x)\nclass Test(object):\n    y = x\n    print(\"2. Enclosed y:\", y)\n    x = x + 1\n    print(\"3. Enclosed x:\", x)\n\n    def method(self):\n        print(\"4. Enclosed self.x\", self.x)\n        print(\"5. Global x\", x)\n        try:\n            print(y)\n        except NameError as e:\n            print(\"6.\", e)\n\n    def method_local_ref(self):\n        try:\n            print(x)\n        except UnboundLocalError as e:\n            print(\"7.\", e)\n        x = 200 # causing 7 because has same name\n        print(\"8. Local x\", x)\n\ninst = Test()\ninst.method()\ninst.method_local_ref()\n \n\n output: \n\n 1. Global x: 100\n2. Enclosed y: 100\n3. Enclosed x: 101\n4. Enclosed self.x 101\n5. Global x 100\n6. global name 'y' is not defined\n7. local variable 'x' referenced before assignment\n8. Local x 200\n \n    ", "date_posted": "2017-11-20 04:04:39Z", "upvote": "\r\n            26\r\n        ", "accepted": "No", "user": {"stack_user_id": "355230", "name": "martineau", "reputation_score": "115k"}, "answer_comments": [{"stack_answer_id": "34094235", "stack_answer_comment_id": "66143541", "comment_content": "This is great answer. However, I think that the differences between ", "user_id": "None"}, {"stack_answer_id": "34094235", "stack_answer_comment_id": "78761696", "comment_content": "@brianray: What about z?", "user_id": "None"}, {"stack_answer_id": "34094235", "stack_answer_comment_id": "81546225", "comment_content": "@kiril I added a note about that", "user_id": "None"}, {"stack_answer_id": "34094235", "stack_answer_comment_id": "81546228", "comment_content": "@MalikA.Rumi I removed z as it wasn't interesting", "user_id": "None"}, {"stack_answer_id": "34094235", "stack_answer_comment_id": "92307270", "comment_content": "Surprisingly, this is the ", "user_id": "None"}]}, {"stack_answer_id": "292907", "answer_content": "\r\n The scoping rules for Python 2.x have been outlined already in other answers. The only thing I would add is that in Python 3.0, there is also the concept of a non-local scope (indicated by the 'nonlocal' keyword). This allows you to access outer scopes directly, and opens up the ability to do some neat tricks, including lexical closures (without ugly hacks involving mutable objects). \n\n EDIT: Here's the  PEP  with more information on this. \n    ", "date_posted": "2008-11-15 18:52:49Z", "upvote": "\r\n            23\r\n        ", "accepted": "No", "user": {"stack_user_id": "18866", "name": "Jeremy Cantrell", "reputation_score": "25.1k"}, "answer_comments": []}, {"stack_answer_id": "292002", "answer_content": "\r\n Python resolves your variables with -- generally -- three namespaces available.   \n\n \n   At any time during execution, there\n  are at least three nested scopes whose\n  namespaces are directly accessible:\n  the innermost scope, which is searched\n  first, contains the local names; the\n  namespaces of any enclosing functions,\n  which are searched starting with the\n  nearest enclosing scope; the middle\n  scope, searched next, contains the\n  current module's global names; and the\n  outermost scope (searched last) is the\n  namespace containing built-in names. \n \n\n There are two functions:  globals  and  locals  which show you the contents two of these namespaces. \n\n Namespaces are created by packages, modules, classes, object construction and functions.  There aren't any other flavors of namespaces.   \n\n In this case, the call to a function named  x  has to be resolved in the local name space or the global namespace. \n\n Local in this case, is the body of the method function  Foo.spam . \n\n Global is -- well -- global.  \n\n The rule is to search the nested local spaces created by method functions (and nested function definitions), then search global.  That's it. \n\n There are no other scopes.  The  for  statement (and other compound statements like  if  and  try ) don't create new nested scopes.  Only definitions (packages, modules, functions, classes and object instances.) \n\n Inside a class definition, the names are part of the class namespace.   code2 , for instance, must be qualified by the class name.  Generally  Foo.code2 .  However,  self.code2  will also work because Python objects look at the containing class as a fall-back. \n\n An object (an instance of a class) has instance variables.  These names are in the object's namespace.  They must be qualified by the object.  ( variable.instance .)   \n\n From within a class method, you have locals and globals.  You say  self.variable  to pick the instance as the namespace.  You'll note that  self  is an argument to every class member function, making it part of the local namespace. \n\n See  Python Scope Rules ,  Python Scope ,  Variable Scope . \n    ", "date_posted": "2017-05-23 12:10:44Z", "upvote": "\r\n            15\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": [{"stack_answer_id": "292002", "stack_answer_comment_id": "140935", "comment_content": "This is out of date. Since 2.1 (7 years ago) there are more than two scopes, as nested functions introduce new scopes, so a function within a function will have access to its local scope, the enclosing functions scope, and global scope (also builtins).", "user_id": "None"}, {"stack_answer_id": "292002", "stack_answer_comment_id": "141122", "comment_content": "I'm sorry, this is no longer the case. ", "user_id": "None"}]}, {"stack_answer_id": "292498", "answer_content": "\r\n \n   Where is x found? \n \n\n x is not found as you haven't defined it. :-) It could be found in code1 (global) or code3 (local) if you put it there. \n\n code2 (class members) aren't visible to code inside methods of the same class\u2009\u2014\u2009you would usually access them using self. code4/code5 (loops) live in the same scope as code3, so if you wrote to x in there you would be changing the x instance defined in code3, not making a new x. \n\n Python is statically scoped, so if you pass \u2018spam\u2019 to another function spam will still have access to globals in the module it came from (defined in code1), and any other containing scopes (see below). code2 members would again be accessed through self. \n\n lambda is no different to def. If you have a lambda used inside a function, it's the same as defining a nested function. In Python 2.2 onwards, nested scopes are available. In this case you can bind x at any level of function nesting and Python will pick up the innermost instance: \n\n x= 0\ndef fun1():\n    x= 1\n    def fun2():\n        x= 2\n        def fun3():\n            return x\n        return fun3()\n    return fun2()\nprint fun1(), x\n\n2 0\n \n\n fun3 sees the instance x from the nearest containing scope, which is the function scope associated with fun2. But the other x instances, defined in fun1 and globally, are not affected. \n\n Before nested_scopes\u2009\u2014\u2009in Python pre-2.1, and in 2.1 unless you specifically ask for the feature using a from-future-import\u2009\u2014\u2009fun1 and fun2's scopes are not visible to fun3, so S.Lott's answer holds and you would get the global x: \n\n 0 0\n \n    ", "date_posted": "2008-11-15 12:44:59Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "18936", "name": "bobince", "reputation_score": "517k"}, "answer_comments": []}, {"stack_answer_id": "62379080", "answer_content": "\r\n The  Python name resolution  only knows the following kinds of scope: \n \n builtins scope which provides the  Builtin Functions , such as  print ,  int , or  zip , \n module  global scope which is always the top-level of the current module, \n three user-defined scopes that can be nested into each other, namely\n \n function  closure scope, from any enclosing  def  block,  lambda  expression or comprehension. \n function  local scope, inside a  def  block,  lambda  expression or comprehension, \n class  scope, inside a  class  block. \n \n \n \n Notably, other constructs such as  if ,  for , or  with  statements do not have their own scope. \n The scoping TLDR : The  lookup  of a name begins at the scope in which the name is used, then any enclosing scopes (excluding class scopes), to the module globals, and finally the builtins \u2013 the first match in this search order is used.\nThe  assignment  to a scope is by default to the current scope \u2013 the special forms  nonlocal  and  global  must be used to  assign  to a name from an outer scope. \n Finally, comprehensions and generator expressions as well as  :=  asignment expressions have one special rule when combined. \n \n Nested Scopes and Name Resolution \n These different scopes build a hierarchy, with builtins then global always forming the base, and closures, locals and class scope being nested as  lexically  defined. That is, only the nesting in the source code matters, not for example the call stack. \n print(\"builtins are available without definition\")\n\nsome_global = \"1\"  # global variables are at module scope\n\ndef outer_function():\n    some_closure = \"3.1\"  # locals and closure are defined the same, at function scope\n    some_local = \"3.2\"    # a variable becomes a closure if a nested scope uses it\n\n    class InnerClass:\n         some_classvar = \"3.3\"   # class variables exist *only* at class scope\n\n         def nested_function(self):\n             some_local = \"3.2\"   # locals can replace outer names\n             print(some_closure)  # closures are always readable\n    return InnerClass\n \n Even though  class  creates a scope and may have nested classes, functions and comprehensions, the names of the  class  scope are not visible to enclosed scopes. This creates the following hierarchy: \n \u250e builtins           [print, ...]\n\u2517\u2501\u2531 globals            [some_global]\n  \u2517\u2501\u2531 outer_function     [some_local, some_closure]\n    \u2523\u2501\u257e InnerClass         [some_classvar]\n    \u2517\u2501\u257e inner_function     [some_local]\n \n Name resolution always starts at the  current scope  in which a name is accessed, then goes up the hierarchy until a match is found. For example, looking up  some_local  inside  outer_function  and  inner_function  starts at the respective function - and immediately finds the  some_local  defined in  outer_function  and  inner_function , respectively. When a name is not local, it is fetched from the nearest enclosing scope that defines it \u2013 looking up  some_closure  and  print  inside  inner_function  searches until  outer_function  and builtins, respectively. \n \n Scope Declarations and Name Binding \n By default, a name belongs to any scope in which it is bound to a value. Binding the same name again in an inner scope creates a new variable with the same name - for example,  some_local  exists separately in both  outer_function  and  inner_function . As far as scoping is concerned, binding includes any statement that sets the value of a name \u2013 assignment statements, but also the iteration variable of a  for  loop, or the name of a  with  context manager. Notably,  del  also counts as name binding. \n When a name must refer to an outer variable  and  be bound in an inner scope, the name must be declared as not local. Separate declarations exists for the different kinds of enclosing scopes:  nonlocal  always refers to the nearest closure, and  global  always refers to a global name. Notably,  nonlocal  never refers to a global name and  global  ignores all closures of the same name. There is no declaration to refer to the builtin scope. \n \nsome_global = \"1\"\n\ndef outer_function():\n    some_closure = \"3.2\"\n    some_global = \"this is ignored by a nested global declaration\"\n    \n    def inner_function():\n        global some_global     # declare variable from global scope\n        nonlocal some_closure  # declare variable from enclosing scope\n        message = \" bound by an inner scope\"\n        some_global = some_global + message\n        some_closure = some_closure + message\n    return inner_function\n \n Of note is that function local and  nonlocal  are resolved at compile time. A  nonlocal  name  must  exist in some outer scope. In contrast, a  global  name can be defined dynamically and may be added or removed from the global scope at any time. \n \n Comprehensions and Assignment Expressions \n The scoping rules of list, set and dict comprehensions and generator expressions are  almost  the same as for functions. Likewise, the scoping rules for assignment expressions are  almost  the same as for regular name binding. \n The scope of comprehensions and generator expressions is of the same kind as function scope. All names bound in the scope, namely the iteration variables, are locals or closures to the comprehensions/generator and nested scopes. All names, including iterables, are resolved using name resolution as applicable inside functions. \n some_global = \"global\"\n\ndef outer_function():\n    some_closure = \"closure\"\n    return [            # new function-like scope started by comprehension\n        comp_local      # names resolved using regular name resolution\n        for comp_local  # iteration targets are local\n        in \"iterable\"\n        if comp_local in some_global and comp_local in some_global\n    ]\n \n An  :=  assignment expression works on the nearest function, class or global scope. Notably, if the target of an assignment expression has been declared  nonlocal  or  global  in the nearest scope, the assignment expression honors this like a regular assignment. \n print(some_global := \"global\")\n\ndef outer_function():\n    print(some_closure := \"closure\")\n \n However, an assignment expression inside a comprehension/generator works on the nearest  enclosing scope  of the comprehension/generator, not the scope of the comprehension/generator itself. When several comprehensions/generators are nested, the nearest function or global scope is used. Since the comprehension/generator scope can read closures and global variables, the assignment variable is readable in the comprehension as well. Assigning from a comprehension to a class scope is not valid. \n print(some_global := \"global\")\n\ndef outer_function():\n    print(some_closure := \"closure\")\n    steps = [\n        # v write to variable in containing scope\n        (some_closure := some_closure + comp_local)\n        #                 ^ read from variable in containing scope\n        for comp_local in some_global\n    ]\n    return some_closure, steps\n \n While the iteration variable is local to the comprehension in which it is bound, the target of the assignment expression does not create a local variable and is read from the outer scope: \n \u250e builtins           [print, ...]\n\u2517\u2501\u2531 globals            [some_global]\n  \u2517\u2501\u2531 outer_function     [some_closure]\n    \u2517\u2501\u257e <listcomp>         [comp_local]\n \n    ", "date_posted": "2020-07-07 08:28:34Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "5349916", "name": "MisterMiyagi", "reputation_score": "38.6k"}, "answer_comments": [{"stack_answer_id": "62379080", "stack_answer_comment_id": "126027050", "comment_content": "I think your answer is incomplete.  The ", "user_id": "None"}, {"stack_answer_id": "62379080", "stack_answer_comment_id": "126027529", "comment_content": "@JohnHenckel That is not a new scope. ", "user_id": "None"}, {"stack_answer_id": "62379080", "stack_answer_comment_id": "126027831", "comment_content": "OMG this is strange. Thank you for explaining that to me.", "user_id": "None"}]}, {"stack_answer_id": "56103969", "answer_content": "\r\n In Python,  \n\n \n   any variable that is assigned a value is local to the block in which\n  the assignment appears. \n \n\n If a variable can't be found in the current scope, please refer to the LEGB order. \n    ", "date_posted": "2019-05-12 22:27:43Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "9687097", "name": "GraceMeng", "reputation_score": "839"}, "answer_comments": []}], "user": {"stack_user_id": "1320510", "name": "Charles Merriam", "reputation_score": "18.9k"}, "question_comments": [{"stack_question_id": "291978", "stack_question_comment_id": "98969816", "comment_content": "The scoping rules are described fairly tersely \u2014 but also completely \u2014 in the Python documentation: ", "user_id": "None"}]},
{"stack_question_id": "419163", "question_title": "What does if __name__ == \"__main__\": do?", "question_content": "\r\n                What does this do, and why should one include the if statement?\nif __name__ == \"__main__\":\n    print(\"Hello, World!\")\r\n", "question_url": "/questions/419163/what-does-if-name-main-do", "date_posted": "Jan 7, 2009 at 4:11", "upvote": "7", "view": "4", "tags": ["python", "namespaces", "program-entry-point", "python-module", "idioms"], "answers_count": "4", "answers": [{"stack_answer_id": "419185", "answer_content": "\r\n Short Answer \n It's boilerplate code that protects users from accidentally invoking the script when they didn't intend to. Here are some common problems when the guard is omitted from a script: \n \n If you import the guardless script in another script (e.g.  import my_script_without_a_name_eq_main_guard ), then the latter script will trigger the former to run  at import time  and  using the second script's command line arguments . This is almost always a mistake. \n \n If you have a custom class in the guardless script and save it to a pickle file, then unpickling it in another script will trigger an import of the guardless script, with the same problems outlined in the previous bullet. \n \n \n Long Answer \n To better understand why and how this matters, we need to take a step back to understand how Python initializes scripts and how this interacts with its module import mechanism. \n Whenever the Python interpreter reads a source file, it does two things: \n \n it sets a few special variables like  __name__ , and then \n \n it executes all of the code found in the file. \n \n \n Let's see how this works and how it relates to your question about the  __name__  checks we always see in Python scripts. \n Code Sample \n Let's use a slightly different code sample to explore how imports and scripts work.  Suppose the following is in a file called  foo.py . \n # Suppose this is foo.py.\n\nprint(\"before import\")\nimport math\n\nprint(\"before function_a\")\ndef function_a():\n    print(\"Function A\")\n\nprint(\"before function_b\")\ndef function_b():\n    print(\"Function B {}\".format(math.sqrt(100)))\n\nprint(\"before __name__ guard\")\nif __name__ == '__main__':\n    function_a()\n    function_b()\nprint(\"after __name__ guard\")\n \n Special Variables \n When the Python interpreter reads a source file, it first defines a few special variables. In this case, we care about the  __name__  variable. \n When Your Module Is the Main Program \n If you are running your module (the source file) as the main program, e.g. \n python foo.py\n \n the interpreter will assign the hard-coded string  \"__main__\"  to the  __name__  variable, i.e. \n # It's as if the interpreter inserts this at the top\n# of your module when run as the main program.\n__name__ = \"__main__\" \n \n When Your Module Is Imported By Another \n On the other hand, suppose some other module is the main program and it imports your module. This means there's a statement like this in the main program, or in some other module the main program imports: \n # Suppose this is in some other main program.\nimport foo\n \n The interpreter will search for your  foo.py  file (along with searching for a few other variants), and prior to executing that module, it will assign the name  \"foo\"  from the import statement to the  __name__  variable, i.e. \n # It's as if the interpreter inserts this at the top\n# of your module when it's imported from another module.\n__name__ = \"foo\"\n \n Executing the Module's Code \n After the special variables are set up, the interpreter executes all the code in the module, one statement at a time. You may want to open another window on the side with the code sample so you can follow along with this explanation. \n Always \n \n It prints the string  \"before import\"  (without quotes). \n \n It loads the  math  module and assigns it to a variable called  math . This is equivalent to replacing  import math  with the following (note that  __import__  is a low-level function in Python that takes a string and triggers the actual import): \n \n \n # Find and load a module given its string name, \"math\",\n# then assign it to a local variable called math.\nmath = __import__(\"math\")\n \n \n It prints the string  \"before function_a\" . \n \n It executes the  def  block, creating a function object, then assigning that function object to a variable called  function_a . \n \n It prints the string  \"before function_b\" . \n \n It executes the second  def  block, creating another function object, then assigning it to a variable called  function_b . \n \n It prints the string  \"before __name__ guard\" . \n \n \n Only When Your Module Is the Main Program \n \n If your module is the main program, then it will see that  __name__  was indeed set to  \"__main__\"  and it calls the two functions, printing the strings  \"Function A\"  and  \"Function B 10.0\" . \n \n Only When Your Module Is Imported by Another \n \n ( instead ) If your module is not the main program but was imported by another one, then  __name__  will be  \"foo\" , not  \"__main__\" , and it'll skip the body of the  if  statement. \n \n Always \n \n It will print the string  \"after __name__ guard\"  in both situations. \n \n Summary \n In summary, here's what'd be printed in the two cases: \n # What gets printed if foo is the main program\nbefore import\nbefore function_a\nbefore function_b\nbefore __name__ guard\nFunction A\nFunction B 10.0\nafter __name__ guard\n \n # What gets printed if foo is imported as a regular module\nbefore import\nbefore function_a\nbefore function_b\nbefore __name__ guard\nafter __name__ guard\n \n Why Does It Work This Way? \n You might naturally wonder why anybody would want this.  Well, sometimes you want to write a  .py  file that can be both used by other programs and/or modules as a module, and can also be run as the main program itself.  Examples: \n \n Your module is a library, but you want to have a script mode where it runs some unit tests or a demo. \n \n Your module is only used as a main program, but it has some unit tests, and the testing framework works by importing  .py  files like your script and running special test functions. You don't want it to try running the script just because it's importing the module. \n \n Your module is mostly used as a main program, but it also provides a programmer-friendly API for advanced users. \n \n \n Beyond those examples, it's elegant that running a script in Python is just setting up a few magic variables and importing the script. \"Running\" the script is a side effect of importing the script's module. \n Food for Thought \n \n Question: Can I have multiple  __name__  checking blocks?  Answer: it's strange to do so, but the language won't stop you. \n \n Suppose the following is in  foo2.py .  What happens if you say  python foo2.py  on the command-line? Why? \n \n \n # Suppose this is foo2.py.\nimport os, sys; sys.path.insert(0, os.path.dirname(__file__)) # needed for some interpreters\n\ndef function_a():\n    print(\"a1\")\n    from foo2 import function_b\n    print(\"a2\")\n    function_b()\n    print(\"a3\")\n\ndef function_b():\n    print(\"b\")\n\nprint(\"t1\")\nif __name__ == \"__main__\":\n    print(\"m1\")\n    function_a()\n    print(\"m2\")\nprint(\"t2\")\n      \n \n \n Now, figure out what will happen if you remove the  __name__  check in  foo3.py : \n \n # Suppose this is foo3.py.\nimport os, sys; sys.path.insert(0, os.path.dirname(__file__)) # needed for some interpreters\n\ndef function_a():\n    print(\"a1\")\n    from foo3 import function_b\n    print(\"a2\")\n    function_b()\n    print(\"a3\")\n\ndef function_b():\n    print(\"b\")\n\nprint(\"t1\")\nprint(\"m1\")\nfunction_a()\nprint(\"m2\")\nprint(\"t2\")\n \n \n What will this do when used as a script?  When imported as a module? \n \n # Suppose this is in foo4.py\n__name__ = \"__main__\"\n\ndef bar():\n    print(\"bar\")\n    \nprint(\"before __name__ guard\")\nif __name__ == \"__main__\":\n    bar()\nprint(\"after __name__ guard\")\n \n    ", "date_posted": "2022-05-19 12:26:02Z", "upvote": "\r\n            8365\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "4298200", "name": "Neuron", "reputation_score": "4,509"}, "answer_comments": [{"stack_answer_id": "419185", "stack_answer_comment_id": "96284627", "comment_content": "Out of curiosity: What hapens if I run ", "user_id": "None"}, {"stack_answer_id": "419185", "stack_answer_comment_id": "96321241", "comment_content": "@hajef You're correct about how things would work with ", "user_id": "None"}, {"stack_answer_id": "419185", "stack_answer_comment_id": "96476792", "comment_content": "i have a doubt in foo2.py example in the food for thought section.what does from foo2.py import functionB do? In my view it just imports foo2.py from functionB", "user_id": "None"}, {"stack_answer_id": "419185", "stack_answer_comment_id": "102365381", "comment_content": "One of the modules that may import your code is ", "user_id": "None"}, {"stack_answer_id": "419185", "stack_answer_comment_id": "106231301", "comment_content": "Extremely minor point, but I believe python actually determines the ", "user_id": "None"}]}, {"stack_answer_id": "419189", "answer_content": "\r\n When your script is run by passing it as a command to the Python interpreter, \n\n python myscript.py\n \n\n all of the code that is at indentation level 0 gets executed.  Functions and classes that are defined are, well, defined, but none of their code gets run.  Unlike other languages, there's no  main()  function that gets run automatically - the  main()  function is implicitly all the code at the top level. \n\n In this case, the top-level code is an  if  block.   __name__  is a built-in variable which evaluates to the name of the current module.  However, if a module is being run directly (as in  myscript.py  above), then  __name__  instead is set to the string  \"__main__\" .  Thus, you can test whether your script is being run directly or being imported by something else by testing \n\n if __name__ == \"__main__\":\n    ...\n \n\n If your script is being imported into another module, its various function and class definitions will be imported and its top-level code will be executed, but the code in the then-body of the  if  clause above won't get run as the condition is not met. As a basic example, consider the following two scripts: \n\n # file one.py\ndef func():\n    print(\"func() in one.py\")\n\nprint(\"top-level in one.py\")\n\nif __name__ == \"__main__\":\n    print(\"one.py is being run directly\")\nelse:\n    print(\"one.py is being imported into another module\")\n \n\n\n\n # file two.py\nimport one\n\nprint(\"top-level in two.py\")\none.func()\n\nif __name__ == \"__main__\":\n    print(\"two.py is being run directly\")\nelse:\n    print(\"two.py is being imported into another module\")\n \n\n Now, if you invoke the interpreter as \n\n python one.py\n \n\n The output will be \n\n top-level in one.py\none.py is being run directly\n \n\n If you run  two.py  instead: \n\n python two.py\n \n\n You get \n\n top-level in one.py\none.py is being imported into another module\ntop-level in two.py\nfunc() in one.py\ntwo.py is being run directly\n \n\n Thus, when module  one  gets loaded, its  __name__  equals  \"one\"  instead of  \"__main__\" . \n    ", "date_posted": "2018-01-31 13:28:16Z", "upvote": "\r\n            2094\r\n        ", "accepted": "No", "user": {"stack_user_id": "6160119", "name": "Tonechas", "reputation_score": "12.9k"}, "answer_comments": [{"stack_answer_id": "419189", "stack_answer_comment_id": "117154652", "comment_content": "So, ", "user_id": "None"}, {"stack_answer_id": "419189", "stack_answer_comment_id": "127677317", "comment_content": "@Adam Rosenfield  ", "user_id": "None"}]}, {"stack_answer_id": "419986", "answer_content": "\r\n Create the following two files: \n # a.py\n\nimport b\n \n # b.py\n\nprint(\"__name__ equals \" + __name__)\n\nif __name__ == '__main__':\n    print(\"if-statement was executed\")\n \n Now run each file individually. \n \n Running  python a.py : \n $ python a.py\n__name__ equals b\n \n When  a.py  is executed, it imports the module  b . This causes all the code inside  b  to run. Python sets  globals()['__name__']  in the  b  module to the module's name,  b . \n   \n Running  python b.py : \n $ python b.py\n__name__ equals __main__\nif-statement was executed\n \n When only the file  b.py  is executed, Python sets  globals()['__name__']  in this file to  \"__main__\" . Therefore, the  if  statement evaluates to  True  this time. \n    ", "date_posted": "2022-05-31 01:44:10Z", "upvote": "\r\n            837\r\n        ", "accepted": "No", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": []}, {"stack_answer_id": "20158605", "answer_content": "\r\n \n   What does the  if __name__ == \"__main__\":  do? \n \n\n To outline the basics: \n\n \n The global variable,  __name__ , in the module that is the entry point to your program, is  '__main__' . Otherwise, it's the name you import the module by. \n So, code under the  if  block will only run if the module is the entry point to your program. \n It allows the code in the module to be importable by other modules, without executing the code block beneath on import. \n \n\n \n\n Why do we need this? \n\n Developing and Testing Your Code \n\n Say you're writing a Python script designed to be used as a module: \n\n def do_important():\n    \"\"\"This function does something very important\"\"\"\n \n\n You  could  test the module by adding this call of the function to the bottom: \n\n do_important()\n \n\n and running it (on a command prompt) with something like: \n\n ~$ python important.py\n \n\n The Problem \n\n However, if you want to import the module to another script: \n\n import important\n \n\n On import, the  do_important  function would be called, so you'd probably comment out your function call,  do_important() , at the bottom.  \n\n # do_important() # I must remember to uncomment to execute this!\n \n\n And then you'll have to remember whether or not you've commented out your test function call. And this extra complexity would mean you're likely to forget, making your development process more troublesome. \n\n A Better Way \n\n The  __name__  variable points to the namespace wherever the Python interpreter happens to be at the moment.  \n\n Inside an imported module, it's the name of that module.  \n\n But inside the primary module (or an interactive Python session, i.e. the interpreter's Read, Eval, Print Loop, or REPL) you are running everything from its  \"__main__\" . \n\n So if you check before executing: \n\n if __name__ == \"__main__\":\n    do_important()\n \n\n With the above, your code will only execute when you're running it as the primary module (or intentionally call it from another script).  \n\n An Even Better Way \n\n There's a Pythonic way to improve on this, though.  \n\n What if we want to run this business process from outside the module? \n\n If we put the code we want to exercise as we develop and test in a function like this and then do our check for  '__main__'  immediately after: \n\n def main():\n    \"\"\"business logic for when running this module as the primary one!\"\"\"\n    setup()\n    foo = do_important()\n    bar = do_even_more_important(foo)\n    for baz in bar:\n        do_super_important(baz)\n    teardown()\n\n# Here's our payoff idiom!\nif __name__ == '__main__':\n    main()\n \n\n We now have a final function for the end of our module that will run if we run the module as the primary module.  \n\n It will allow the module and its functions and classes to be imported into other scripts without running the  main  function, and will also allow the module (and its functions and classes) to be called when running from a different  '__main__'  module, i.e. \n\n import important\nimportant.main()\n \n\n This idiom can also be found in the Python documentation in an explanation of the  __main__  module.  That text states: \n\n \n   This module represents the (otherwise anonymous) scope in which the\n  interpreter\u2019s main program executes \u2014 commands read either from\n  standard input, from a script file, or from an interactive prompt. It\n  is this environment in which the idiomatic \u201cconditional script\u201d stanza\n  causes a script to run: \n\n if __name__ == '__main__':\n    main()\n \n \n    ", "date_posted": "2018-03-27 02:27:47Z", "upvote": "\r\n            588\r\n        ", "accepted": "No", "user": {"stack_user_id": "541136", "name": "Russia Must Remove Putin", "reputation_score": "347k"}, "answer_comments": [{"stack_answer_id": "20158605", "stack_answer_comment_id": "127678263", "comment_content": "Sorry, I can't there be any difference between the method mentioned in the section named ", "user_id": "None"}, {"stack_answer_id": "20158605", "stack_answer_comment_id": "129276841", "comment_content": "@John I don't think there's a difference. He used ", "user_id": "None"}]}, {"stack_answer_id": "419174", "answer_content": "\r\n if __name__ == \"__main__\"  is the part that runs when the script is run from (say) the command line using a command like  python myscript.py . \n    ", "date_posted": "2015-07-10 15:49:13Z", "upvote": "\r\n            163\r\n        ", "accepted": "No", "user": {"stack_user_id": "1709587", "name": "Mark Amery", "reputation_score": "130k"}, "answer_comments": [{"stack_answer_id": "419174", "stack_answer_comment_id": "101682583", "comment_content": "Why does a file ", "user_id": "None"}, {"stack_answer_id": "419174", "stack_answer_comment_id": "115789570", "comment_content": "When you run ", "user_id": "None"}]}, {"stack_answer_id": "26369628", "answer_content": "\r\n \n What does  if __name__ == \"__main__\":  do? \n \n __name__  is a global variable (in Python, global actually means on the  module level ) that exists in all namespaces. It is typically the module's name (as a  str  type). \n As the only special case, however, in whatever Python process you run, as in mycode.py: \n python mycode.py\n \n the otherwise anonymous global namespace is assigned the value of  '__main__'  to its  __name__ . \n Thus, including  the final lines \n if __name__ == '__main__':\n    main()\n \n \n at the end of your mycode.py script, \n when it is the primary, entry-point module that is run by a Python process, \n \n will cause your script's uniquely defined  main  function to run. \n Another benefit of using this construct: you can also import your code as a module in another script and then run the main function if and when your program decides: \n import mycode\n# ... any amount of other code\nmycode.main()\n \n    ", "date_posted": "2022-05-31 01:52:40Z", "upvote": "\r\n            102\r\n        ", "accepted": "No", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": []}, {"stack_answer_id": "39761460", "answer_content": "\r\n There are lots of different takes here on the mechanics of the code in question, the \"How\", but for me none of it made sense until I understood the \"Why\". This should be especially helpful for new programmers. \n\n Take file \"ab.py\": \n\n def a():\n    print('A function in ab file');\na()\n \n\n And a second file \"xy.py\": \n\n import ab\ndef main():\n    print('main function: this is where the action is')\ndef x():\n    print ('peripheral task: might be useful in other projects')\nx()\nif __name__ == \"__main__\":\n    main()\n \n\n \n   What is this code actually doing? \n \n\n When you execute  xy.py , you  import ab . The import statement runs the module immediately on import, so  ab 's operations get executed before the remainder of  xy 's. Once finished with  ab , it continues with  xy . \n\n The interpreter keeps track of which scripts are running with  __name__ . When you run a script - no matter what you've named it - the interpreter calls it  \"__main__\" , making it the master or 'home' script that gets returned to after running an external script. \n\n Any other script that's called from this  \"__main__\"  script is assigned its filename as its  __name__  (e.g.,  __name__ == \"ab.py\" ). Hence, the line  if __name__ == \"__main__\":  is the interpreter's test to determine if it's interpreting/parsing the 'home' script that was initially executed, or if it's temporarily peeking into another (external) script. This gives the programmer flexibility to have the script behave differently if it's executed directly vs. called externally. \n\n Let's step through the above code to understand what's happening, focusing first on the unindented lines and the order they appear in the scripts. Remember that function - or  def  - blocks don't do anything by themselves until they're called. What the interpreter might say if mumbled to itself: \n\n \n Open xy.py as the 'home' file; call it  \"__main__\"  in the  __name__  variable. \n Import and open file with the  __name__ == \"ab.py\" . \n Oh, a function. I'll remember that. \n Ok, function  a() ; I just learned that. Printing ' A function in ab file '. \n End of file; back to  \"__main__\" ! \n Oh, a function. I'll remember that. \n Another one. \n Function  x() ; ok, printing ' peripheral task: might be useful in other projects '. \n What's this? An  if  statement. Well, the condition has been met (the variable  __name__  has been set to  \"__main__\" ), so I'll enter the  main()  function and print ' main function: this is where the action is '. \n \n\n The bottom two lines mean: \"If this is the  \"__main__\"  or 'home' script, execute the function called  main() \". That's why you'll see a  def main():  block up top, which contains the main flow of the script's functionality. \n\n \n   Why implement this? \n \n\n Remember what I said earlier about import statements? When you import a module it doesn't just 'recognize' it and wait for further instructions - it actually runs all the executable operations contained within the script. So, putting the meat of your script into the  main()  function effectively quarantines it, putting it in isolation so that it won't immediately run when imported by another script. \n\n Again, there will be exceptions, but common practice is that  main()  doesn't usually get called externally. So you may be wondering one more thing: if we're not calling  main() , why are we calling the script at all? It's because many people structure their scripts with standalone functions that are built to be run independent of the rest of the code in the file. They're then later called somewhere else in the body of the script. Which brings me to this: \n\n \n   But the code works without it \n \n\n Yes, that's right. These separate functions  can  be called from an in-line script that's not contained inside a  main()  function. If you're accustomed (as I am, in my early learning stages of programming) to building in-line scripts that do exactly what you need, and you'll try to figure it out again if you ever need that operation again ... well, you're not used to this kind of internal structure to your code, because it's more complicated to build and it's not as intuitive to read. \n\n But that's a script that probably can't have its functions called externally, because if it did it would immediately start calculating and assigning variables. And chances are if you're trying to re-use a function, your new script is related closely enough to the old one that there will be conflicting variables. \n\n In splitting out independent functions, you gain the ability to re-use your previous work by calling them into another script. For example, \"example.py\" might import \"xy.py\" and call  x() , making use of the 'x' function from \"xy.py\". (Maybe it's capitalizing the third word of a given text string; creating a NumPy array from a list of numbers and squaring them; or detrending a 3D surface. The possibilities are limitless.) \n\n (As an aside,  this question  contains an answer by @kindall that finally helped me to understand - the why, not the how. Unfortunately it's been marked as a duplicate of  this one , which I think is a mistake.) \n    ", "date_posted": "2018-05-23 22:29:32Z", "upvote": "\r\n            90\r\n        ", "accepted": "No", "user": {"stack_user_id": "6833793", "name": "joechoj", "reputation_score": "1,259"}, "answer_comments": []}, {"stack_answer_id": "60017299", "answer_content": "\r\n The code under  if __name__ == '__main__':  will  only  be executed if the module is invoked as a script. \n As an example, consider the following module  my_test_module.py : \n # my_test_module.py\n\nprint('This is going to be printed out, no matter what')\n\nif __name__ == '__main__':\n    print('This is going to be printed out, only if user invokes the module as a script')\n \n \n First possibility: Import  my_test_module.py  in another module \n # main.py\n\nimport my_test_module\n\nif __name__ == '__main__':\n    print('Hello from main.py')\n \n Now if you invoke  main.py : \n python main.py\n\n>> 'This is going to be printed out, no matter what'\n>> 'Hello from main.py'\n \n Note that only the top-level  print()  statement in  my_test_module  is executed. \n \n Second possibility: Invoke  my_test_module.py  as a script \n Now if you run  my_test_module.py  as a Python script, both  print()  statements will be executed: \n python my_test_module.py\n\n>>> 'This is going to be printed out, no matter what'\n>>> 'This is going to be printed out, only if user invokes the module as a script'\n \n \n For a more comprehensive explanation, you can read  What does  if __name__ == '__main__'  do in Python . \n    ", "date_posted": "2022-05-13 14:31:40Z", "upvote": "\r\n            74\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "15789709", "answer_content": "\r\n When there are certain statements in our module ( M.py ) we want to be executed when it'll be running as main (not imported), we can place those statements (test-cases, print statements) under this  if  block. \n\n As by default (when module running as main, not imported) the  __name__  variable is set to  \"__main__\" , and when it'll be imported the  __name__  variable will get a different value, most probably the name of the module ( 'M' ).\nThis is helpful in running different variants of a modules together, and separating their specific input & output statements and also if there are any test-cases. \n\n In short , use this ' if __name__ == \"main\"  ' block to prevent (certain) code from being run when the module is imported. \n    ", "date_posted": "2018-05-23 22:07:29Z", "upvote": "\r\n            67\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "15789709", "stack_answer_comment_id": "122272582", "comment_content": "+1  Sometimes, it's good to just get a short one-liner like mentioned in this answer: \"In short, use this 'if ", "user_id": "None"}]}, {"stack_answer_id": "40057173", "answer_content": "\r\n Put simply,  __name__  is a variable defined for each script that defines whether the script is being run as the main module or it is being run as an imported module. \n\n So if we have two scripts; \n\n #script1.py\nprint \"Script 1's name: {}\".format(__name__)\n \n\n and \n\n #script2.py\nimport script1\nprint \"Script 2's name: {}\".format(__name__)\n \n\n The output from executing script1 is \n\n Script 1's name: __main__\n \n\n And the output from executing script2 is: \n\n Script1's name is script1\nScript 2's name: __main__\n \n\n As you can see,  __name__  tells us which code is the 'main' module.\nThis is great, because you can just write code and not have to worry about structural issues like in C/C++, where, if a file does not implement a 'main' function then it cannot be compiled as an executable and if it does, it cannot then be used as a library. \n\n Say you write a Python script that does something great and you implement a boatload of functions that are useful for other purposes. If I want to use them I can just import your script and use them without executing your program (given that your code only executes within the   if __name__ == \"__main__\":  context). Whereas in C/C++ you would have to portion out those pieces into a separate module that then includes the file. Picture the situation below; \n\n \n\n The arrows are import links. For three modules each trying to include the previous modules code there are six files (nine, counting the implementation files) and five links. This makes it difficult to include other code into a C project unless it is compiled specifically as a library. Now picture it for Python: \n\n \n\n You write a module, and if someone wants to use your code they just import it and the  __name__  variable can help to separate the executable portion of the program from the library part. \n    ", "date_posted": "2018-05-23 22:28:19Z", "upvote": "\r\n            62\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "40057173", "stack_answer_comment_id": "83396232", "comment_content": "The C/C++ illustration is wrong: 3 times the same unit name (", "user_id": "None"}]}, {"stack_answer_id": "28051929", "answer_content": "\r\n Let's look at the answer in a more abstract way: \n\n Suppose we have this code in  x.py : \n\n ...\n<Block A>\nif __name__ == '__main__':\n    <Block B>\n...\n \n\n Blocks A and B are run when we are running  x.py . \n\n But just block A (and not B) is run when we are running another module,  y.py  for example, in which  x.py  is imported and the code is run from there (like when a function in  x.py  is called from  y.py ). \n    ", "date_posted": "2020-05-27 10:50:24Z", "upvote": "\r\n            55\r\n        ", "accepted": "No", "user": {"stack_user_id": "2115079", "name": "kubuntu", "reputation_score": "2,525"}, "answer_comments": []}, {"stack_answer_id": "51011507", "answer_content": "\r\n To be short, you need to know several points: \n \n import a  action actually runs all that can be run in  a.py , meaning each line in  a.py \n \n Because of point 1, you may not want everything to be run in  a.py  when importing it \n \n To solve the problem in point 2, Python allows you to use a condition check \n \n __name__  is an implicit variable in all  .py  modules: \n \n \n \n when  a.py  is  import ed, the value of  __name__  of  a.py  module is set to its file name \" a \" \n when  a.py  is run directly using \" python a.py \", the value of  __name__  is set to a string  __main__ \n \n \n Based on the mechanism how Python sets the variable  __name__  for each module, do you know how to achieve point 3? The answer is fairly easy, right? Use an  if  condition:  if __name__ == \"__main__\": // do A \n \n \n then  python a.py  will run the part  // do A \n and  import a  will skip the part  // do A \n \n \n You can even put if  __name__ == \"a\"  depending on your functional need, but rarely do \n \n The important thing that Python is special at is point 4! The rest is just basic logic. \n I've been reading so much throughout the answers on this page. I would say, if you know the thing, for sure you will understand those answers, otherwise, you are still confused. \n    ", "date_posted": "2022-01-13 22:32:49Z", "upvote": "\r\n            54\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "51011507", "stack_answer_comment_id": "97383066", "comment_content": "Yes, point 1 is vital to understand. From that, the need for this mechanism become clear.", "user_id": "None"}]}, {"stack_answer_id": "20517795", "answer_content": "\r\n When you run Python interactively the local  __name__  variable is assigned a value of  __main__ . Likewise, when you execute a Python module from the command line, rather than importing it into another module, its  __name__  attribute is assigned a value of  __main__ , rather than the actual name of the module. In this way, modules can look at their own  __name__  value to determine for themselves how they are being used, whether as support for another program or as the main application executed from the command line. Thus, the following idiom is quite common in Python modules: \n\n if __name__ == '__main__':\n    # Do something appropriate here, like calling a\n    # main() function defined elsewhere in this module.\n    main()\nelse:\n    # Do nothing. This module has been imported by another\n    # module that wants to make use of the functions,\n    # classes and other useful bits it has defined.\n \n    ", "date_posted": "2013-12-11 11:23:53Z", "upvote": "\r\n            44\r\n        ", "accepted": "No", "user": {"stack_user_id": "1803858", "name": "Zain", "reputation_score": "1,186"}, "answer_comments": []}, {"stack_answer_id": "45824951", "answer_content": "\r\n Consider: \n if __name__ == \"__main__\":\n    main()\n \n It checks if the  __name__  attribute of the Python script is  \"__main__\" . In other words, if the program itself is executed, the attribute will be  __main__ , so the program will be executed (in this case the  main()  function). \n However, if your Python script is used by a module, any code outside of the  if  statement will be executed, so  if __name__ == \"__main__\"  is used just to check if the program is used as a module or not, and therefore decides whether to run the code. \n    ", "date_posted": "2022-05-20 08:24:03Z", "upvote": "\r\n            42\r\n        ", "accepted": "No", "user": {"stack_user_id": "874188", "name": "tripleee", "reputation_score": "162k"}, "answer_comments": []}, {"stack_answer_id": "49637838", "answer_content": "\r\n Before explaining anything about  if __name__ == '__main__'  it is important to understand what  __name__  is and what it does. \n What is  __name__ ? \n __name__  is a  DunderAlias  - can be thought of as a global variable (accessible from modules) and works in a similar way to  global . \n It is a string (global as mentioned above) as indicated by  type(__name__)  (yielding  <class 'str'> ), and is an inbuilt standard for both  Python 3  and  Python 2  versions. \n Where \n It can not only be used in scripts but can also be found in both the interpreter and modules/packages. \n Interpreter: \n >>> print(__name__)\n__main__\n>>>\n \n Script: \n test_file.py : \n print(__name__)\n \n Resulting in  __main__ \n Module or package: \n somefile.py: \n def somefunction():\n    print(__name__)\n \n test_file.py: \n import somefile\nsomefile.somefunction()\n \n Resulting in  somefile \n Notice that when used in a package or module,  __name__  takes the name of the file.  The path of the actual module or package path is not given, but has its own DunderAlias  __file__ , that allows for this. \n You should see that, where  __name__ , where it is the main file (or program) will  always  return  __main__ , and if it is a module/package, or anything that is running off some other Python script, will return the name of the file where it has originated from. \n Practice \n Being a variable means that it's value  can  be overwritten (\"can\" does not mean \"should\"), overwriting the value of  __name__  will result in a lack of readability.  So do not do it, for any reason.  If you need a variable define a new variable. \n It is always assumed that the value of  __name__  to be  __main__  or the name of the file.  Once again changing this default value will cause more confusion that it will do good, causing problems further down the line. \n Example: \n >>> __name__ = 'Horrify' # Change default from __main__\n>>> if __name__ == 'Horrify': print(__name__)\n...\n>>> else: print('Not Horrify')\n...\nHorrify\n>>>\n \n It is considered good practice in general to include the  if __name__ == '__main__'  in scripts. \n Now to answer  if __name__ == '__main__' : \n Now we know the behaviour of  __name__  things become clearer: \n An  if  is a flow control statement that contains the block of code will execute if the value given is true. We have seen that  __name__  can take either\n __main__  or the file name it has been imported from. \n This means that if  __name__  is equal to  __main__  then the file must be the main file and must actually be running (or it is the interpreter), not a module or package imported into the script. \n If indeed  __name__  does take the value of  __main__  then whatever is in that block of code will execute. \n This tells us that if the file running is the main file (or you are running from the interpreter directly) then that condition must execute.  If it is a package then it should not, and the value will not be  __main__ . \n Modules \n __name__  can also be used in modules to define the name of a module \n Variants \n It is also possible to do other, less common but useful things with  __name__ , some I will show here: \n Executing only if the file is a module or package \n if __name__ != '__main__':\n    # Do some useful things \n \n Running one condition if the file is the main one and another if it is not \n if __name__ == '__main__':\n    # Execute something\nelse:\n    # Do some useful things\n \n You can also use it to provide runnable help functions/utilities on packages and modules without the elaborate use of libraries. \n It also allows modules to be run from the command line as main scripts, which can be also very useful. \n    ", "date_posted": "2022-03-26 13:31:36Z", "upvote": "\r\n            40\r\n        ", "accepted": "No", "user": {"stack_user_id": "874188", "name": "tripleee", "reputation_score": "162k"}, "answer_comments": []}, {"stack_answer_id": "40881975", "answer_content": "\r\n I think it's best to break the answer in depth and in simple words: \n\n __name__ : Every module in Python has a special attribute called  __name__ .\nIt is a built-in variable that returns the name of the module. \n\n __main__ : Like other programming languages, Python too has an execution entry point, i.e., main.  '__main__'   is the name of the scope in which top-level code executes . Basically you have two ways of using a Python module: Run it directly as a script, or import it. When a module is run as a script, its  __name__  is set to  __main__ . \n\n Thus, the value of the  __name__  attribute is set to  __main__  when the module is run as the main program. Otherwise the value of  __name__   is set to contain the name of the module. \n    ", "date_posted": "2018-05-23 22:30:36Z", "upvote": "\r\n            35\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "14502904", "answer_content": "\r\n It is a special for when a Python file is called from the command line. This is typically used to call a \"main()\" function or execute other appropriate startup code, like commandline arguments handling for instance. \n It could be written in several ways. Another is: \n def some_function_for_instance_main():\n    dosomething()\n\n\n__name__ == '__main__' and some_function_for_instance_main()\n \n I am not saying you should use this in production code, but it serves to illustrate that there is nothing \"magical\" about  if __name__ == '__main__' . \n It just a convention for invoking a main function in Python files. \n    ", "date_posted": "2021-06-15 15:46:05Z", "upvote": "\r\n            35\r\n        ", "accepted": "No", "user": {"stack_user_id": "193892", "name": "Prof. Falken", "reputation_score": "23.5k"}, "answer_comments": [{"stack_answer_id": "14502904", "stack_answer_comment_id": "31163627", "comment_content": "I would consider this bad form as you're 1) relying on side effects and 2) abusing ", "user_id": "None"}, {"stack_answer_id": "14502904", "stack_answer_comment_id": "50673315", "comment_content": "Leaving aside the question of whether exploiting the short-circuit behaviour of boolean operators as a flow control mechanism is bad style or not, the bigger problem is that this ", "user_id": "None"}, {"stack_answer_id": "14502904", "stack_answer_comment_id": "120744784", "comment_content": "@jpmc26 Anyone with a background in Perl or Javascript is totally comfortable with this idiom, using ", "user_id": "None"}, {"stack_answer_id": "14502904", "stack_answer_comment_id": "120747922", "comment_content": "@JohnHenckel This is not Perl or JavaScript. This is not a Python idiom. It is considered bad form to use a function with side effects in the middle of a Boolean statement in Python. Particularly in this case, there is absolutely no benefit to using ", "user_id": "None"}, {"stack_answer_id": "14502904", "stack_answer_comment_id": "120989730", "comment_content": "@jpmc26 I'm trying to find an authoritative source that agrees with you. Is this mentioned somewhere?  For example in PEP8 does it say that we should avoid using ", "user_id": "None"}]}, {"stack_answer_id": "33916552", "answer_content": "\r\n There are a number of variables that the system (Python interpreter) provides for source files (modules).  You can get their values anytime you want, so, let us focus on the  __name__  variable/attribute: \n\n When Python loads a source code file, it executes all of the code found in it. (Note that it doesn't call all of the methods and functions defined in the file, but it does define them.) \n\n Before the interpreter executes the source code file though, it defines a few special variables for that file;  __name__  is one of those special variables that Python automatically defines for each source code file. \n\n If Python is loading this source code file as the main program (i.e. the file you run), then it sets the special  __name__  variable for this file to have a value  \"__main__\" . \n\n If this is being imported from another module,  __name__  will be set to that module's name. \n\n So, in your example in part: \n\n if __name__ == \"__main__\":\n   lock = thread.allocate_lock()\n   thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))\n   thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))\n \n\n means that the code block: \n\n lock = thread.allocate_lock()\nthread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))\nthread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))\n \n\n will be executed only when you run the module directly; the code block will not execute if another module is calling/importing it because the value of  __name__  will not equal to \" main \" in that particular instance. \n\n Hope this helps out. \n    ", "date_posted": "2016-07-20 09:30:24Z", "upvote": "\r\n            27\r\n        ", "accepted": "No", "user": {"stack_user_id": "5417963", "name": "codewizard", "reputation_score": "356"}, "answer_comments": [{"stack_answer_id": "33916552", "stack_answer_comment_id": "124905627", "comment_content": "Hi, you are one of  the few that addressed the question referring to the multithreaded aspect. May I ask you this, what happens if I have code outside of \"main\" and not encapsulated inside a function? Will this code get executed again and again by every new thread started from main?", "user_id": "None"}]}, {"stack_answer_id": "36820845", "answer_content": "\r\n if __name__ == \"__main__\":  is basically the top-level script environment, and it specifies the interpreter that ('I have the highest priority to be executed first'). \n\n '__main__'  is the name of the scope in which top-level code executes. A module\u2019s  __name__  is set equal to  '__main__'  when read from standard input, a script, or from an interactive prompt. \n\n if __name__ == \"__main__\":\n    # Execute only if run as a script\n    main()\n \n    ", "date_posted": "2018-05-23 22:14:07Z", "upvote": "\r\n            25\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "37965772", "answer_content": "\r\n Consider: \n\n print __name__\n \n\n The output for the above is  __main__ . \n\n if __name__ == \"__main__\":\n  print \"direct method\"\n \n\n The above statement is true and prints  \"direct method\" . Suppose if they imported this class in another class it doesn't print  \"direct method\"  because, while importing, it will set  __name__ equal to \"first model name\" . \n    ", "date_posted": "2019-02-06 23:16:06Z", "upvote": "\r\n            24\r\n        ", "accepted": "No", "user": {"stack_user_id": "4217744", "name": "simhumileco", "reputation_score": "28.1k"}, "answer_comments": []}, {"stack_answer_id": "42773985", "answer_content": "\r\n \n   You can make the file usable as a  script  as well as an  importable module . \n \n\n fibo.py (a module named  fibo ) \n\n # Other modules can IMPORT this MODULE to use the function fib\ndef fib(n):    # write Fibonacci series up to n\n    a, b = 0, 1\n    while b < n:\n        print(b, end=' ')\n        a, b = b, a+b\n    print()\n\n# This allows the file to be used as a SCRIPT\nif __name__ == \"__main__\":\n    import sys\n    fib(int(sys.argv[1]))\n \n\n Reference:  https://docs.python.org/3.5/tutorial/modules.html \n    ", "date_posted": "2017-03-13 21:44:26Z", "upvote": "\r\n            20\r\n        ", "accepted": "No", "user": {"stack_user_id": "3927314", "name": "kgf3JfUtW", "reputation_score": "12k"}, "answer_comments": []}, {"stack_answer_id": "46371154", "answer_content": "\r\n The reason for \n\n if __name__ == \"__main__\":\n    main()\n \n\n is primarily to avoid the  import lock  problems that would arise from  having code directly imported . You want  main()  to run if your file was directly invoked (that's the  __name__ == \"__main__\"  case), but if your code was imported then the importer has to enter your code from the true main module to avoid import lock problems. \n\n A side-effect is that you automatically sign on to a methodology that supports multiple entry points. You can run your program using  main()  as the entry point,  but you don't have to . While  setup.py  expects  main() , other tools use alternate entry points. For example, to run your file as a  gunicorn  process, you define an  app()  function instead of a  main() . Just as with  setup.py ,  gunicorn  imports your code so you don't want it do do anything while it's being imported (because of the import lock issue). \n    ", "date_posted": "2018-04-18 21:05:59Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "5896591", "name": "personal_cloud", "reputation_score": "3,584"}, "answer_comments": []}, {"stack_answer_id": "56558865", "answer_content": "\r\n Every module in Python has an attribute called  __name__ . The value of  __name__   attribute is   __main__  when the module is run directly, like  python my_module.py . Otherwise (like when you say  import my_module ) the value of  __name__   is the name of the module. \n Small example to explain in short. \n Script  test.py \n apple = 42\n\ndef hello_world():\n    print(\"I am inside hello_world\")\n\nif __name__ == \"__main__\":\n    print(\"Value of __name__ is: \", __name__)\n    print(\"Going to call hello_world\")\n    hello_world()\n \n We can execute this directly as \n python test.py\n \n Output \n Value of __name__ is: __main__\nGoing to call hello_world\nI am inside hello_world\n \n Now suppose we call the above script from another script: \n Script  external_calling.py \n import test\n\nprint(test.apple)\ntest.hello_world()\n\nprint(test.__name__)\n \n When you execute this, \n python external_calling.py\n \n Output \n 42\nI am inside hello_world\ntest\n \n So, the above is self-explanatory that when you call  test  from another script, if loop  __name__  in  test.py  will not execute. \n    ", "date_posted": "2022-01-13 22:45:08Z", "upvote": "\r\n            18\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "69778466", "answer_content": "\r\n If you are a beginner, probably the only answer you need right now is that  this code is unnecessary  for a simple script. It is only useful if you want to be able to  import  your script (or  unpickle  etc; see the other answers here for some other non-beginner scenarios). \n In slightly different words, the  if __name__  guard is a mechanism for hiding code from other code. If you don't have a specific reason to hide something, don't: If you don't need to hide some code from  import , don't put it behind this guard, and if you do, hide as little as possible. \n In slightly more detail, let's say you have a simple script  fib.py  (adapted from  this answer ): \n # XXX FIXME: useless (see below)\nif __name__ == \"__main__\":\n    n = int(input('Write a number: '))\n    a, b = 0, 1\n    while b < n:\n        a, b = b, a+b\n    print('Fibonacci number %i: %i' % (n, b))\n \n Now, if you simply run  python fib.py  it works fine. But  __name__  will always be  \"__main__\"  in this scenario, so the condition is actually unnecessary. The script could be simplified to just \n n = int(input('Write a number: '))\na, b = 0, 1\nwhile b < n:\n    a, b = b, a+b\nprint('Fibonacci number %i: %i' % (n, b))\n \n Now, you can't  import fib  with the new version, but if you didn't plan to do that in the first place, this version is actually better, because it's simpler and clearer. \n If you  do  want to be able to  import fib , the first version is useless, too, because the useful code is in a section which will not run when you  import  this file (in which case  __name__  will not be  \"__main__\" ). The proper design in that case would be to refactor the code so that the useful parts are in a function you can run when you want to after you have  import ed it. \n def main():\n    n = int(input('Write a number: '))\n    a, b = 0, 1\n    while b < n:\n        a, b = b, a+b\n    print('Fibonacci number %i: %i' % (n, b))\n\nif __name__ == \"__main__\":\n    main()\n \n Now, if you  import fib , the call to  main()  will not be executed; but when you run  python fib.py , it will. \n Actually, a better design still would be to isolate the reusable part (the actual calculation) from the user-visible input/output: \n def fibn(n: int) -> int:\n    a, b = 0, 1\n    while b < n:\n        a, b = b, a+b\n    return b\n\ndef main() -> None:\n    n = int(input('Write a number: '))\n    print('Fibonacci number %i: %i' % (n, fibn(n)))\n\nif __name__ == \"__main__\":\n    main()\n \n Now, you can  from fib import fibn  and call the  fibn()  function from the code which performs this  import . \n (I called the function  fibn()  just to make it clearer what is what in this example. In real life, you might call it  fib()  and do  from fib import fib .) \n Similarly, you could  import  and call the  main  function if you wanted to reuse it. \n Returning to the code in the question, I would similarly move the code from the  if  into a function as well, so that callers can invoke that function if they want to. \n def main():\n    lock = thread.allocate_lock()\n    thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))\n    thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))\n\nif __name__ == \"__main__\":\n    main()\n \n This changes the scope of the  lock  variable; if the surrounding code needs access to it, you will need to make it  global  (or, perhaps, better, refactor  main  to  return lock , and have the caller capture the value in a local variable of its own). \n (Unlike in languages like C, the name  main  has no specific meaning to Python; but it's a common convention to use it as the name of the thing which will be run. You still have to actually explicitly call it, like  main() , unlike in C.) \n    ", "date_posted": "2022-05-20 07:37:58Z", "upvote": "\r\n            17\r\n        ", "accepted": "No", "user": {"stack_user_id": "874188", "name": "tripleee", "reputation_score": "162k"}, "answer_comments": [{"stack_answer_id": "69778466", "stack_answer_comment_id": "123342064", "comment_content": "I kept the example code simple to avoid distractions; in real life, you need to cope with ", "user_id": "None"}, {"stack_answer_id": "69778466", "stack_answer_comment_id": "123342070", "comment_content": "The ", "user_id": "None"}, {"stack_answer_id": "69778466", "stack_answer_comment_id": "123342326", "comment_content": "The convention for the ordering of Fibonacci numbers is not entirely set in stone. The usual convention is that the first number is 0, but mathematically this is conventionally ", "user_id": "None"}]}, {"stack_answer_id": "52685565", "answer_content": "\r\n This answer is for Java programmers learning Python.\nEvery Java file typically contains one public class. You can use that class in two ways:  \n\n \n Call the class from other files. You just have to import it in the calling program. \n Run the class stand alone, for testing purposes.  \n \n\n For the latter case, the class should contain a public static void main() method. In Python this purpose is served by the globally defined label  '__main__' . \n    ", "date_posted": "2018-10-18 03:09:32Z", "upvote": "\r\n            15\r\n        ", "accepted": "No", "user": {"stack_user_id": "6622587", "name": "eyllanesc", "reputation_score": "224k"}, "answer_comments": []}, {"stack_answer_id": "64488013", "answer_content": "\r\n In simple words: \n The code you see under  if __name__ == \"__main__\":  will only get called upon when your Python file is executed as  python example1.py \n However, if you wish to import your Python file  example1.py  as a module to work with another Python file, say  example2.py , the code under  if __name__ == \"__main__\":  will not run or take any effect. \n    ", "date_posted": "2022-07-21 13:58:56Z", "upvote": "\r\n            15\r\n        ", "accepted": "No", "user": {"stack_user_id": "874188", "name": "tripleee", "reputation_score": "162k"}, "answer_comments": []}, {"stack_answer_id": "50927616", "answer_content": "\r\n If this .py file are imported by other .py files, the code under the  if  statement will not be executed. \n If this .py are run by  python this_py.py  under shell, or double clicked in Windows. the code under the  if  statement will be executed. \n It is usually written for testing. \n    ", "date_posted": "2022-05-20 08:22:30Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "874188", "name": "tripleee", "reputation_score": "162k"}, "answer_comments": []}, {"stack_answer_id": "57276038", "answer_content": "\r\n If the Python interpreter is running a particular module then the  __name__  global variable will have the value  \"__main__\" : \n   def a():\n      print(\"a\")\n\n  def b():\n      print(\"b\")\n\n  if __name__ == \"__main__\":\n\n          print (\"you can see me\")\n          a()\n  else:\n\n          print (\"You can't see me\")\n          b()\n \n When you run this script, it prints  you can see me . \n a \n If you import this file, say A to file B, and execute the file B then  if __name__ == \"__main__\"  in file A becomes false, so it prints   You can't see me . \n b \n    ", "date_posted": "2022-01-13 22:40:32Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "49653760", "answer_content": "\r\n We see if  __name__ == '__main__':  quite often. \n It checks if a module is being imported or not. \n In other words, the code within the  if  block will be executed only when the code runs directly. Here  directly  means  not imported . \n Let's see what it does using a simple code that prints the name of the module: \n # test.py\ndef test():\n   print('test module name=%s' %(__name__))\n\nif __name__ == '__main__':\n   print('call test()')\n   test()\n \n If we run the code directly via  python test.py , the module name is  __main__ : \n call test()\ntest module name=__main__\n \n    ", "date_posted": "2022-05-20 08:23:11Z", "upvote": "\r\n            10\r\n        ", "accepted": "No", "user": {"stack_user_id": "874188", "name": "tripleee", "reputation_score": "162k"}, "answer_comments": []}, {"stack_answer_id": "61458664", "answer_content": "\r\n Every module in Python has a special attribute called  __name__ . The value of the  __name__   attribute is set to  '__main__'  when the module is executed as the main program (e.g., running  python foo.py ). \n Otherwise, the value of  __name__  is set to the name of the module that it was called from. \n    ", "date_posted": "2022-03-26 13:22:00Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "874188", "name": "tripleee", "reputation_score": "162k"}, "answer_comments": [{"stack_answer_id": "61458664", "stack_answer_comment_id": "125030782", "comment_content": "Re ", "user_id": "None"}]}], "user": {"stack_user_id": "51518", "name": "Devoted", "reputation_score": "99.1k"}, "question_comments": [{"stack_question_id": "419163", "stack_question_comment_id": "118285977", "comment_content": "Just for the record - what is \"", "user_id": "None"}, {"stack_question_id": "419163", "stack_question_comment_id": "128699165", "comment_content": "For duplicate closers: if you are trying to tell someone to use this idiom to avoid problems with code running when a module is imported, don't use this - use ", "user_id": "None"}]},
{"stack_question_id": "36901", "question_title": "What does ** (double star/asterisk) and * (star/asterisk) do for parameters?", "question_content": "\r\n                What do *args and **kwargs mean?\ndef foo(x, y, *args):\ndef bar(x, y, **kwargs):\r\n", "question_url": "/questions/36901/what-does-double-star-asterisk-and-star-asterisk-do-for-parameters", "date_posted": "Aug 31, 2008 at 15:04", "upvote": "3", "view": "1", "tags": ["python", "syntax", "parameter-passing", "variadic-functions", "argument-unpacking"], "answers_count": "2", "answers": [{"stack_answer_id": "36908", "answer_content": "\r\n The  *args  and  **kwargs  is a common idiom to allow arbitrary number of arguments to functions as described in the section  more on defining functions  in the Python documentation. \n The  *args  will give you all function parameters  as a tuple : \n def foo(*args):\n    for a in args:\n        print(a)        \n\nfoo(1)\n# 1\n\nfoo(1,2,3)\n# 1\n# 2\n# 3\n \n The  **kwargs  will give you all\n keyword arguments  except for those corresponding to a formal parameter as a dictionary. \n def bar(**kwargs):\n    for a in kwargs:\n        print(a, kwargs[a])  \n\nbar(name='one', age=27)\n# name one\n# age 27\n \n Both idioms can be mixed with normal arguments to allow a set of fixed and some variable arguments: \n def foo(kind, *args, **kwargs):\n   pass\n \n It is also possible to use this the other way around: \n def foo(a, b, c):\n    print(a, b, c)\n\nobj = {'b':10, 'c':'lee'}\n\nfoo(100,**obj)\n# 100 10 lee\n \n Another usage of the  *l  idiom is to  unpack argument lists  when calling a function. \n def foo(bar, lee):\n    print(bar, lee)\n\nl = [1,2]\n\nfoo(*l)\n# 1 2\n \n In Python 3 it is possible to use  *l  on the left side of an assignment ( Extended Iterable Unpacking ), though it gives a list instead of a tuple in this context: \n first, *rest = [1,2,3,4]\nfirst, *l, last = [1,2,3,4]\n \n Also Python 3 adds new semantic (refer  PEP 3102 ): \n def func(arg1, arg2, arg3, *, kwarg1, kwarg2):\n    pass\n \n For example the following works in python 3 but not python 2: \n >>> x = [1, 2]\n>>> [*x]\n[1, 2]\n>>> [*x, 3, 4]\n[1, 2, 3, 4]\n\n>>> x = {1:1, 2:2}\n>>> x\n{1: 1, 2: 2}\n>>> {**x, 3:3, 4:4}\n{1: 1, 2: 2, 3: 3, 4: 4}\n \n Such function accepts only 3 positional arguments, and everything after  *  can only be passed as keyword arguments. \n Note: \n \n A Python  dict , semantically used for keyword argument passing, are arbitrarily ordered. However, in Python 3.6, keyword arguments are guaranteed to remember insertion order. \n \"The order of elements in  **kwargs  now corresponds to the order in which keyword arguments were passed to the function.\" -  What\u2019s New In Python 3.6 \n In fact, all dicts in CPython 3.6 will remember insertion order as an implementation detail, this becomes standard in Python 3.7. \n \n    ", "date_posted": "2022-05-12 20:32:27Z", "upvote": "\r\n            2959\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "497719", "name": "voxobscuro", "reputation_score": "2,042"}, "answer_comments": []}, {"stack_answer_id": "36926", "answer_content": "\r\n It's also worth noting that you can use  *  and  **  when calling functions as well. This is a shortcut that allows you to pass multiple arguments to a function directly using either a list/tuple or a dictionary. For example, if you have the following function: \n\n def foo(x,y,z):\n    print(\"x=\" + str(x))\n    print(\"y=\" + str(y))\n    print(\"z=\" + str(z))\n \n\n You can do things like: \n\n >>> mylist = [1,2,3]\n>>> foo(*mylist)\nx=1\ny=2\nz=3\n\n>>> mydict = {'x':1,'y':2,'z':3}\n>>> foo(**mydict)\nx=1\ny=2\nz=3\n\n>>> mytuple = (1, 2, 3)\n>>> foo(*mytuple)\nx=1\ny=2\nz=3\n \n\n Note: The keys in  mydict  have to be named exactly like the parameters of function  foo . Otherwise it will throw a  TypeError : \n\n >>> mydict = {'x':1,'y':2,'z':3,'badnews':9}\n>>> foo(**mydict)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: foo() got an unexpected keyword argument 'badnews'\n \n    ", "date_posted": "2018-03-07 01:53:17Z", "upvote": "\r\n            774\r\n        ", "accepted": "No", "user": {"stack_user_id": "2601671", "name": "Trenton", "reputation_score": "11.3k"}, "answer_comments": []}, {"stack_answer_id": "36911", "answer_content": "\r\n The single * means that there can be any number of extra positional arguments.  foo()  can be invoked like  foo(1,2,3,4,5) . In the body of foo() param2 is a sequence containing 2-5. \n\n The double ** means there can be any number of extra named parameters.  bar()  can be invoked like  bar(1, a=2, b=3) . In the body of bar() param2 is a dictionary containing {'a':2, 'b':3 } \n\n With the following code: \n\n def foo(param1, *param2):\n    print(param1)\n    print(param2)\n\ndef bar(param1, **param2):\n    print(param1)\n    print(param2)\n\nfoo(1,2,3,4,5)\nbar(1,a=2,b=3)\n \n\n the output is \n\n 1\n(2, 3, 4, 5)\n1\n{'a': 2, 'b': 3}\n \n    ", "date_posted": "2018-12-01 05:59:46Z", "upvote": "\r\n            209\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}, {"stack_answer_id": "26365795", "answer_content": "\r\n \n What does  **  (double star) and  *  (star) do for parameters? \n \n They allow for  functions to be defined to accept  and for  users to pass  any number of arguments, positional ( * ) and keyword ( ** ). \n Defining Functions \n *args  allows for any number of optional positional arguments (parameters), which will be assigned to a tuple named  args . \n **kwargs  allows for any number of optional keyword arguments (parameters), which will be in a dict named  kwargs . \n You can (and should) choose any appropriate name, but if the intention is for the arguments to be of non-specific semantics,  args  and  kwargs  are standard names. \n Expansion, Passing any number of arguments \n You can also use  *args  and  **kwargs  to pass in parameters from lists (or any iterable) and dicts (or any mapping), respectively. \n The function recieving the parameters does not have to know that they are being expanded. \n For example, Python 2's xrange does not explicitly expect  *args , but since it takes 3 integers as arguments: \n >>> x = xrange(3) # create our *args - an iterable of 3 integers\n>>> xrange(*x)    # expand here\nxrange(0, 2, 2)\n \n As another example, we can use dict expansion in  str.format : \n >>> foo = 'FOO'\n>>> bar = 'BAR'\n>>> 'this is foo, {foo} and bar, {bar}'.format(**locals())\n'this is foo, FOO and bar, BAR'\n \n New in Python 3: Defining functions with keyword only arguments \n You can have  keyword only arguments  after the  *args  - for example, here,  kwarg2  must be given as a keyword argument - not positionally: \n def foo(arg, kwarg=None, *args, kwarg2=None, **kwargs): \n    return arg, kwarg, args, kwarg2, kwargs\n \n Usage: \n >>> foo(1,2,3,4,5,kwarg2='kwarg2', bar='bar', baz='baz')\n(1, 2, (3, 4, 5), 'kwarg2', {'bar': 'bar', 'baz': 'baz'})\n \n Also,  *  can be used by itself  to indicate that keyword only arguments follow, without allowing for unlimited positional arguments. \n def foo(arg, kwarg=None, *, kwarg2=None, **kwargs): \n    return arg, kwarg, kwarg2, kwargs\n \n Here,  kwarg2  again must be an explicitly named, keyword argument: \n >>> foo(1,2,kwarg2='kwarg2', foo='foo', bar='bar')\n(1, 2, 'kwarg2', {'foo': 'foo', 'bar': 'bar'})\n \n And we can no longer accept unlimited positional arguments because we don't have  *args* : \n >>> foo(1,2,3,4,5, kwarg2='kwarg2', foo='foo', bar='bar')\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: foo() takes from 1 to 2 positional arguments \n    but 5 positional arguments (and 1 keyword-only argument) were given\n \n Again, more simply, here we require  kwarg  to be given by name, not positionally: \n def bar(*, kwarg=None): \n    return kwarg\n \n In this example, we see that if we try to pass  kwarg  positionally, we get an error: \n >>> bar('kwarg')\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: bar() takes 0 positional arguments but 1 was given\n \n We must explicitly pass the  kwarg  parameter as a keyword argument. \n >>> bar(kwarg='kwarg')\n'kwarg'\n \n Python 2 compatible demos \n *args  (typically said \"star-args\") and  **kwargs  (stars can be implied by saying \"kwargs\", but be explicit with \"double-star kwargs\") are common idioms of Python for using the  *  and  **  notation. These specific variable names aren't required (e.g. you could use  *foos  and  **bars ), but a departure from convention is likely to enrage your fellow Python coders. \n We typically use these when we don't know what our function is going to receive or how many arguments we may be passing, and sometimes even when naming every variable separately would get very messy and redundant (but this is a case where usually explicit is better than implicit). \n Example 1 \n The following function describes how they can be used, and demonstrates behavior. Note the named  b  argument will be consumed by the second positional argument before : \n def foo(a, b=10, *args, **kwargs):\n    '''\n    this function takes required argument a, not required keyword argument b\n    and any number of unknown positional arguments and keyword arguments after\n    '''\n    print('a is a required argument, and its value is {0}'.format(a))\n    print('b not required, its default value is 10, actual value: {0}'.format(b))\n    # we can inspect the unknown arguments we were passed:\n    #  - args:\n    print('args is of type {0} and length {1}'.format(type(args), len(args)))\n    for arg in args:\n        print('unknown arg: {0}'.format(arg))\n    #  - kwargs:\n    print('kwargs is of type {0} and length {1}'.format(type(kwargs),\n                                                        len(kwargs)))\n    for kw, arg in kwargs.items():\n        print('unknown kwarg - kw: {0}, arg: {1}'.format(kw, arg))\n    # But we don't have to know anything about them \n    # to pass them to other functions.\n    print('Args or kwargs can be passed without knowing what they are.')\n    # max can take two or more positional args: max(a, b, c...)\n    print('e.g. max(a, b, *args) \\n{0}'.format(\n      max(a, b, *args))) \n    kweg = 'dict({0})'.format( # named args same as unknown kwargs\n      ', '.join('{k}={v}'.format(k=k, v=v) \n                             for k, v in sorted(kwargs.items())))\n    print('e.g. dict(**kwargs) (same as {kweg}) returns: \\n{0}'.format(\n      dict(**kwargs), kweg=kweg))\n \n We can check the online help for the function's signature, with  help(foo) , which tells us \n foo(a, b=10, *args, **kwargs)\n \n Let's call this function with  foo(1, 2, 3, 4, e=5, f=6, g=7) \n which prints: \n a is a required argument, and its value is 1\nb not required, its default value is 10, actual value: 2\nargs is of type <type 'tuple'> and length 2\nunknown arg: 3\nunknown arg: 4\nkwargs is of type <type 'dict'> and length 3\nunknown kwarg - kw: e, arg: 5\nunknown kwarg - kw: g, arg: 7\nunknown kwarg - kw: f, arg: 6\nArgs or kwargs can be passed without knowing what they are.\ne.g. max(a, b, *args) \n4\ne.g. dict(**kwargs) (same as dict(e=5, f=6, g=7)) returns: \n{'e': 5, 'g': 7, 'f': 6}\n \n Example 2 \n We can also call it using another function, into which we just provide  a : \n def bar(a):\n    b, c, d, e, f = 2, 3, 4, 5, 6\n    # dumping every local variable into foo as a keyword argument \n    # by expanding the locals dict:\n    foo(**locals()) \n \n bar(100)  prints: \n a is a required argument, and its value is 100\nb not required, its default value is 10, actual value: 2\nargs is of type <type 'tuple'> and length 0\nkwargs is of type <type 'dict'> and length 4\nunknown kwarg - kw: c, arg: 3\nunknown kwarg - kw: e, arg: 5\nunknown kwarg - kw: d, arg: 4\nunknown kwarg - kw: f, arg: 6\nArgs or kwargs can be passed without knowing what they are.\ne.g. max(a, b, *args) \n100\ne.g. dict(**kwargs) (same as dict(c=3, d=4, e=5, f=6)) returns: \n{'c': 3, 'e': 5, 'd': 4, 'f': 6}\n \n Example 3: practical usage in decorators \n OK, so maybe we're not seeing the utility yet. So imagine you have several functions with redundant code before and/or after the differentiating code. The following named functions are just pseudo-code for illustrative purposes. \n def foo(a, b, c, d=0, e=100):\n    # imagine this is much more code than a simple function call\n    preprocess() \n    differentiating_process_foo(a,b,c,d,e)\n    # imagine this is much more code than a simple function call\n    postprocess()\n\ndef bar(a, b, c=None, d=0, e=100, f=None):\n    preprocess()\n    differentiating_process_bar(a,b,c,d,e,f)\n    postprocess()\n\ndef baz(a, b, c, d, e, f):\n    ... and so on\n \n We might be able to handle this differently, but we can certainly extract the redundancy with a decorator, and so our below example demonstrates how  *args  and  **kwargs  can be very useful: \n def decorator(function):\n    '''function to wrap other functions with a pre- and postprocess'''\n    @functools.wraps(function) # applies module, name, and docstring to wrapper\n    def wrapper(*args, **kwargs):\n        # again, imagine this is complicated, but we only write it once!\n        preprocess()\n        function(*args, **kwargs)\n        postprocess()\n    return wrapper\n \n And now every wrapped function can be written much more succinctly, as we've factored out the redundancy: \n @decorator\ndef foo(a, b, c, d=0, e=100):\n    differentiating_process_foo(a,b,c,d,e)\n\n@decorator\ndef bar(a, b, c=None, d=0, e=100, f=None):\n    differentiating_process_bar(a,b,c,d,e,f)\n\n@decorator\ndef baz(a, b, c=None, d=0, e=100, f=None, g=None):\n    differentiating_process_baz(a,b,c,d,e,f, g)\n\n@decorator\ndef quux(a, b, c=None, d=0, e=100, f=None, g=None, h=None):\n    differentiating_process_quux(a,b,c,d,e,f,g,h)\n \n And by factoring out our code, which  *args  and  **kwargs  allows us to do, we reduce lines of code, improve readability and maintainability, and have sole canonical locations for the logic in our program. If we need to change any part of this structure, we have one place in which to make each change. \n    ", "date_posted": "2021-04-30 21:55:47Z", "upvote": "\r\n            193\r\n        ", "accepted": "No", "user": {"stack_user_id": "7758804", "name": "Trenton McKinney", "reputation_score": "46.5k"}, "answer_comments": []}, {"stack_answer_id": "34899056", "answer_content": "\r\n Let us first understand what are positional arguments and keyword arguments.\nBelow is an example of function definition with  Positional arguments. \n\n def test(a,b,c):\n     print(a)\n     print(b)\n     print(c)\n\ntest(1,2,3)\n#output:\n1\n2\n3\n \n\n So this is a function definition with positional arguments.\nYou can call it with keyword/named arguments as well: \n\n def test(a,b,c):\n     print(a)\n     print(b)\n     print(c)\n\ntest(a=1,b=2,c=3)\n#output:\n1\n2\n3\n \n\n Now let us study an example of function definition with  keyword arguments : \n\n def test(a=0,b=0,c=0):\n     print(a)\n     print(b)\n     print(c)\n     print('-------------------------')\n\ntest(a=1,b=2,c=3)\n#output :\n1\n2\n3\n-------------------------\n \n\n You can call this function with positional arguments as well: \n\n def test(a=0,b=0,c=0):\n    print(a)\n    print(b)\n    print(c)\n    print('-------------------------')\n\ntest(1,2,3)\n# output :\n1\n2\n3\n---------------------------------\n \n\n So we now know function definitions with positional as well as keyword arguments. \n\n Now let us study the '*' operator and '**' operator. \n\n Please note these operators can be used in 2 areas: \n\n a)  function call \n\n b)  function definition \n\n The use of '*' operator and '**' operator in  function call.   \n\n Let us get straight to an example and then discuss it. \n\n def sum(a,b):  #receive args from function calls as sum(1,2) or sum(a=1,b=2)\n    print(a+b)\n\nmy_tuple = (1,2)\nmy_list = [1,2]\nmy_dict = {'a':1,'b':2}\n\n# Let us unpack data structure of list or tuple or dict into arguments with help of '*' operator\nsum(*my_tuple)   # becomes same as sum(1,2) after unpacking my_tuple with '*'\nsum(*my_list)    # becomes same as sum(1,2) after unpacking my_list with  '*'\nsum(**my_dict)   # becomes same as sum(a=1,b=2) after unpacking by '**' \n\n# output is 3 in all three calls to sum function.\n \n\n So remember  \n\n when the '*' or '**' operator is used in a  function call  - \n\n '*' operator unpacks data structure such as a list or tuple  into arguments needed by function definition. \n\n '**' operator unpacks a dictionary into arguments needed by function definition. \n\n Now let us study the '*' operator use in  function definition .\nExample: \n\n def sum(*args): #pack the received positional args into data structure of tuple. after applying '*' - def sum((1,2,3,4))\n    sum = 0\n    for a in args:\n        sum+=a\n    print(sum)\n\nsum(1,2,3,4)  #positional args sent to function sum\n#output:\n10\n \n\n In function  definition  the '*' operator packs the received arguments into a tuple. \n\n Now let us see an example of '**' used in function definition: \n\n def sum(**args): #pack keyword args into datastructure of dict after applying '**' - def sum({a:1,b:2,c:3,d:4})\n    sum=0\n    for k,v in args.items():\n        sum+=v\n    print(sum)\n\nsum(a=1,b=2,c=3,d=4) #positional args sent to function sum\n \n\n In function  definition  The '**' operator packs the received arguments into a dictionary. \n\n So remember: \n\n In a  function call  the '*'  unpacks  data structure of tuple or list into positional or keyword arguments to be received by function definition. \n\n In a  function call  the '**'  unpacks  data structure of dictionary into positional or keyword arguments to be received by function definition. \n\n In a  function definition  the '*'  packs  positional arguments into a tuple. \n\n In a  function definition  the '**'  packs  keyword arguments into a dictionary. \n    ", "date_posted": "2016-08-06 19:53:44Z", "upvote": "\r\n            62\r\n        ", "accepted": "No", "user": {"stack_user_id": "243392", "name": "Brian Burns", "reputation_score": "18.5k"}, "answer_comments": []}, {"stack_answer_id": "47580283", "answer_content": "\r\n This table is handy for using  *  and  **  in function  construction  and function  call : \n\n             In function construction         In function call\n=======================================================================\n          |  def f(*args):                 |  def f(a, b):\n*args     |      for arg in args:          |      return a + b\n          |          print(arg)            |  args = (1, 2)\n          |  f(1, 2)                       |  f(*args)\n----------|--------------------------------|---------------------------\n          |  def f(a, b):                  |  def f(a, b):\n**kwargs  |      return a + b              |      return a + b\n          |  def g(**kwargs):              |  kwargs = dict(a=1, b=2)\n          |      return f(**kwargs)        |  f(**kwargs)\n          |  g(a=1, b=2)                   |\n-----------------------------------------------------------------------\n \n\n This really just serves to summarize Lorin Hochstein's  answer  but I find it helpful. \n\n Relatedly: uses for the star/splat operators have been  expanded  in Python 3 \n    ", "date_posted": "2020-01-09 04:19:53Z", "upvote": "\r\n            46\r\n        ", "accepted": "No", "user": {"stack_user_id": "7954504", "name": "Brad Solomon", "reputation_score": "35.3k"}, "answer_comments": [{"stack_answer_id": "47580283", "stack_answer_comment_id": "124788773", "comment_content": "Apparently \"splat\" is jargon for asterisk ", "user_id": "None"}]}, {"stack_answer_id": "12362812", "answer_content": "\r\n *  and  **  have special usage in the function argument list.  * \nimplies that the argument is a list and  **  implies that the argument\nis a dictionary. This allows functions to take arbitrary number of\narguments \n    ", "date_posted": "2012-09-11 10:59:30Z", "upvote": "\r\n            29\r\n        ", "accepted": "No", "user": {"stack_user_id": "1288", "name": "Bill the Lizard", "reputation_score": "389k"}, "answer_comments": []}, {"stack_answer_id": "50461663", "answer_content": "\r\n For those of you who learn by examples! \n\n \n The purpose of  *   is to give you the ability to define a function that can take an arbitrary number of arguments provided as a list (e.g.  f(*myList)  ). \n The purpose of  **  is to give you the ability to feed a function's arguments by providing a dictionary (e.g.  f(**{'x' : 1, 'y' : 2})  ). \n \n\n Let us show this by defining a function that takes two normal variables  x ,  y , and can accept more arguments as  myArgs , and can accept even more arguments as  myKW . Later, we will show how to feed  y  using  myArgDict . \n\n def f(x, y, *myArgs, **myKW):\n    print(\"# x      = {}\".format(x))\n    print(\"# y      = {}\".format(y))\n    print(\"# myArgs = {}\".format(myArgs))\n    print(\"# myKW   = {}\".format(myKW))\n    print(\"# ----------------------------------------------------------------------\")\n\n# Define a list for demonstration purposes\nmyList    = [\"Left\", \"Right\", \"Up\", \"Down\"]\n# Define a dictionary for demonstration purposes\nmyDict    = {\"Wubba\": \"lubba\", \"Dub\": \"dub\"}\n# Define a dictionary to feed y\nmyArgDict = {'y': \"Why?\", 'y0': \"Why not?\", \"q\": \"Here is a cue!\"}\n\n# The 1st elem of myList feeds y\nf(\"myEx\", *myList, **myDict)\n# x      = myEx\n# y      = Left\n# myArgs = ('Right', 'Up', 'Down')\n# myKW   = {'Wubba': 'lubba', 'Dub': 'dub'}\n# ----------------------------------------------------------------------\n\n# y is matched and fed first\n# The rest of myArgDict becomes additional arguments feeding myKW\nf(\"myEx\", **myArgDict)\n# x      = myEx\n# y      = Why?\n# myArgs = ()\n# myKW   = {'y0': 'Why not?', 'q': 'Here is a cue!'}\n# ----------------------------------------------------------------------\n\n# The rest of myArgDict becomes additional arguments feeding myArgs\nf(\"myEx\", *myArgDict)\n# x      = myEx\n# y      = y\n# myArgs = ('y0', 'q')\n# myKW   = {}\n# ----------------------------------------------------------------------\n\n# Feed extra arguments manually and append even more from my list\nf(\"myEx\", 4, 42, 420, *myList, *myDict, **myDict)\n# x      = myEx\n# y      = 4\n# myArgs = (42, 420, 'Left', 'Right', 'Up', 'Down', 'Wubba', 'Dub')\n# myKW   = {'Wubba': 'lubba', 'Dub': 'dub'}\n# ----------------------------------------------------------------------\n\n# Without the stars, the entire provided list and dict become x, and y:\nf(myList, myDict)\n# x      = ['Left', 'Right', 'Up', 'Down']\n# y      = {'Wubba': 'lubba', 'Dub': 'dub'}\n# myArgs = ()\n# myKW   = {}\n# ----------------------------------------------------------------------\n \n\n Caveats \n\n \n **  is exclusively reserved for dictionaries. \n Non-optional argument assignment happens first. \n You cannot use a non-optional argument twice. \n If applicable,  **  must come after  * , always. \n \n    ", "date_posted": "2018-08-13 19:43:14Z", "upvote": "\r\n            24\r\n        ", "accepted": "No", "user": {"stack_user_id": "7428659", "name": "Miladiouss", "reputation_score": "3,631"}, "answer_comments": []}, {"stack_answer_id": "59630576", "answer_content": "\r\n TL;DR \n\n Below are 6 different use cases for  *  and  **  in python programming: \n\n \n To accept any number of positional arguments using  *args :   def foo(*args): pass , here  foo  accepts any number of positional arguments, i. e., the following calls are valid  foo(1) ,  foo(1, 'bar') \n To accept any number of keyword arguments using  **kwargs :   def foo(**kwargs): pass , here 'foo' accepts any number of keyword arguments, i. e., the following calls are valid  foo(name='Tom') ,  foo(name='Tom', age=33) \n To accept any number of positional and keyword arguments using  *args, **kwargs :   def foo(*args, **kwargs): pass , here  foo  accepts any number of positional and keyword arguments, i. e., the following calls are valid  foo(1,name='Tom') ,  foo(1, 'bar', name='Tom', age=33) \n To enforce keyword only arguments using  * :   def foo(pos1, pos2, *, kwarg1): pass , here  *  means that foo only accept keyword arguments after pos2, hence  foo(1, 2, 3)  raises TypeError but  foo(1, 2, kwarg1=3)  is ok. \n To express no further interest in more positional arguments using  *_  (Note: this is a convention only):   def foo(bar, baz, *_): pass  means (by convention)  foo  only uses  bar  and  baz  arguments in its working and will ignore others. \n To express no further interest in more keyword arguments using  \\**_  (Note: this is a convention only):   def foo(bar, baz, **_): pass  means (by convention)  foo  only uses  bar  and  baz  arguments in its working and will ignore others. \n \n\n BONUS:  From python 3.8 onward, one can use  /  in function definition to enforce  positional only parameters. In the following example, parameters a and b are  positional-only , while c or d can be positional or keyword, and e or f are required to be keywords: \n\n def f(a, b, /, c, d, *, e, f):\n    pass\n \n    ", "date_posted": "2020-01-08 14:25:16Z", "upvote": "\r\n            23\r\n        ", "accepted": "No", "user": {"stack_user_id": "3484477", "name": "Meysam Sadeghi", "reputation_score": "1,108"}, "answer_comments": [{"stack_answer_id": "59630576", "stack_answer_comment_id": "124788659", "comment_content": "One reason to use ", "user_id": "None"}]}, {"stack_answer_id": "36902", "answer_content": "\r\n From the Python documentation: \n\n \n   If there are more positional arguments than there are formal parameter slots, a TypeError exception is raised, unless a formal parameter using the syntax \"*identifier\" is present; in this case, that formal parameter receives a tuple containing the excess positional arguments (or an empty tuple if there were no excess positional arguments).  \n  \n   If any keyword argument does not correspond to a formal parameter name, a TypeError exception is raised, unless a formal parameter using the syntax \"**identifier\" is present; in this case, that formal parameter receives a dictionary containing the excess keyword arguments (using the keywords as keys and the argument values as corresponding values), or a (new) empty dictionary if there were no excess keyword arguments.  \n \n    ", "date_posted": "2008-08-31 15:07:48Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "2600", "name": "Chris Upchurch", "reputation_score": "15k"}, "answer_comments": []}, {"stack_answer_id": "51733267", "answer_content": "\r\n *  means receive variable arguments as tuple \n\n **  means receive variable arguments as dictionary \n\n Used like the following: \n\n 1) single * \n\n def foo(*args):\n    for arg in args:\n        print(arg)\n\nfoo(\"two\", 3)\n \n\n Output: \n\n two\n3\n \n\n 2) Now  ** \n\n def bar(**kwargs):\n    for key in kwargs:\n        print(key, kwargs[key])\n\nbar(dic1=\"two\", dic2=3)\n \n\n Output: \n\n dic1 two\ndic2 3\n \n    ", "date_posted": "2019-10-23 03:16:02Z", "upvote": "\r\n            17\r\n        ", "accepted": "No", "user": {"stack_user_id": "11997336", "name": "AnswerSeeker", "reputation_score": "291"}, "answer_comments": []}, {"stack_answer_id": "34166505", "answer_content": "\r\n In Python 3.5, you can also use this syntax in  list ,  dict ,  tuple , and  set  displays (also sometimes called literals). See  PEP 488: Additional Unpacking Generalizations . \n\n >>> (0, *range(1, 4), 5, *range(6, 8))\n(0, 1, 2, 3, 5, 6, 7)\n>>> [0, *range(1, 4), 5, *range(6, 8)]\n[0, 1, 2, 3, 5, 6, 7]\n>>> {0, *range(1, 4), 5, *range(6, 8)}\n{0, 1, 2, 3, 5, 6, 7}\n>>> d = {'one': 1, 'two': 2, 'three': 3}\n>>> e = {'six': 6, 'seven': 7}\n>>> {'zero': 0, **d, 'five': 5, **e}\n{'five': 5, 'seven': 7, 'two': 2, 'one': 1, 'three': 3, 'six': 6, 'zero': 0}\n \n\n It also allows multiple iterables to be unpacked in a single function call. \n\n >>> range(*[1, 10], *[2])\nrange(1, 10, 2)\n \n\n (Thanks to mgilson for the PEP link.) \n    ", "date_posted": "2015-12-08 22:29:06Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "2963903", "name": "leewz", "reputation_score": "3,101"}, "answer_comments": [{"stack_answer_id": "34166505", "stack_answer_comment_id": "56080415", "comment_content": "I'm not sure that this is a violation of \"there's only one way to do it\".  There's no other way to initialize a list/tuple from multiple iterables -- You currently need to chain them into a single iterable which isn't always convenient.  You can read about the rational in ", "user_id": "None"}]}, {"stack_answer_id": "40492308", "answer_content": "\r\n I want to give an example which others haven't  mentioned \n\n * can also unpack a  generator \n\n An example from Python3 Document \n\n x = [1, 2, 3]\ny = [4, 5, 6]\n\nunzip_x, unzip_y = zip(*zip(x, y))\n \n\n unzip_x will be [1, 2, 3], unzip_y will be [4, 5, 6] \n\n The zip() receives multiple iretable args, and return a generator.  \n\n zip(*zip(x,y)) -> zip((1, 4), (2, 5), (3, 6))\n \n    ", "date_posted": "2016-11-08 16:50:20Z", "upvote": "\r\n            10\r\n        ", "accepted": "No", "user": {"stack_user_id": "7132449", "name": "Lochu'an Chang", "reputation_score": "101"}, "answer_comments": [{"stack_answer_id": "40492308", "stack_answer_comment_id": "114888001", "comment_content": "unzip_x will be ", "user_id": "None"}]}, {"stack_answer_id": "55475113", "answer_content": "\r\n TL;DR \n It packs arguments passed to the function into  list  and  dict  respectively inside the function body. When you define a function signature like this: \n def func(*args, **kwds):\n    # do stuff\n \n it can be called with any number of arguments and keyword arguments. The non-keyword arguments get packed into a list called  args  inside the function body and the keyword arguments get packed into a dict called  kwds  inside the function body. \n func(\"this\", \"is a list of\", \"non-keyowrd\", \"arguments\", keyword=\"ligma\", options=[1,2,3])\n \n now inside the function body, when the function is called, there are two local variables,  args  which is a list having value  [\"this\", \"is a list of\", \"non-keyword\", \"arguments\"]  and  kwds  which is a  dict  having value  {\"keyword\" : \"ligma\", \"options\" : [1,2,3]} \n \n This also works in reverse, i.e. from the caller side. for example if you have a function defined as: \n def f(a, b, c, d=1, e=10):\n    # do stuff\n \n you can call it with by unpacking iterables or mappings you have in the calling scope: \n iterable = [1, 20, 500]\nmapping = {\"d\" : 100, \"e\": 3}\nf(*iterable, **mapping)\n# That call is equivalent to\nf(1, 20, 500, d=100, e=3)\n \n    ", "date_posted": "2020-08-27 20:40:25Z", "upvote": "\r\n            10\r\n        ", "accepted": "No", "user": {"stack_user_id": "2430549", "name": "HoldOffHunger", "reputation_score": "16.2k"}, "answer_comments": []}, {"stack_answer_id": "56962836", "answer_content": "\r\n Building on nickd's  answer ... \n\n def foo(param1, *param2):\n    print(param1)\n    print(param2)\n\n\ndef bar(param1, **param2):\n    print(param1)\n    print(param2)\n\n\ndef three_params(param1, *param2, **param3):\n    print(param1)\n    print(param2)\n    print(param3)\n\n\nfoo(1, 2, 3, 4, 5)\nprint(\"\\n\")\nbar(1, a=2, b=3)\nprint(\"\\n\")\nthree_params(1, 2, 3, 4, s=5)\n \n\n Output: \n\n 1\n(2, 3, 4, 5)\n\n1\n{'a': 2, 'b': 3}\n\n1\n(2, 3, 4)\n{'s': 5}\n \n\n Basically, any number of  positional arguments  can use *args and any  named arguments  (or kwargs aka keyword arguments) can use **kwargs. \n    ", "date_posted": "2020-02-13 09:23:21Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "1607450", "name": "Satbir Kira", "reputation_score": "742"}, "answer_comments": []}, {"stack_answer_id": "32031804", "answer_content": "\r\n In addition to function calls, *args and **kwargs are useful in class hierarchies and also avoid having to write  __init__  method in Python. Similar usage can seen in frameworks like Django code. \n\n For example, \n\n def __init__(self, *args, **kwargs):\n    for attribute_name, value in zip(self._expected_attributes, args):\n        setattr(self, attribute_name, value)\n        if kwargs.has_key(attribute_name):\n            kwargs.pop(attribute_name)\n\n    for attribute_name in kwargs.viewkeys():\n        setattr(self, attribute_name, kwargs[attribute_name])\n \n\n A subclass can then be \n\n class RetailItem(Item):\n    _expected_attributes = Item._expected_attributes + ['name', 'price', 'category', 'country_of_origin']\n\nclass FoodItem(RetailItem):\n    _expected_attributes = RetailItem._expected_attributes +  ['expiry_date']\n \n\n The subclass then be instantiated as  \n\n food_item = FoodItem(name = 'Jam', \n                     price = 12.0, \n                     category = 'Foods', \n                     country_of_origin = 'US', \n                     expiry_date = datetime.datetime.now())\n \n\n Also, a subclass with a new attribute which makes sense only to that subclass instance can call the Base class  __init__  to offload the attributes setting.\nThis is done through *args and **kwargs. kwargs mainly used so that code is readable using named arguments. For example, \n\n class ElectronicAccessories(RetailItem):\n    _expected_attributes = RetailItem._expected_attributes +  ['specifications']\n    # Depend on args and kwargs to populate the data as needed.\n    def __init__(self, specifications = None, *args, **kwargs):\n        self.specifications = specifications  # Rest of attributes will make sense to parent class.\n        super(ElectronicAccessories, self).__init__(*args, **kwargs)\n \n\n which can be instatiated as \n\n usb_key = ElectronicAccessories(name = 'Sandisk', \n                                price = '$6.00', \n                                category = 'Electronics',\n                                country_of_origin = 'CN',\n                                specifications = '4GB USB 2.0/USB 3.0')\n \n\n The complete code is  here \n    ", "date_posted": "2018-02-21 09:02:49Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "1086143", "name": "quiet_penguin", "reputation_score": "778"}, "answer_comments": []}, {"stack_answer_id": "50116852", "answer_content": "\r\n *args  and  **kwargs : allow you to pass a variable number of arguments to a function.  \n\n *args : is used to send a non-keyworded variable length argument list to the function: \n\n def args(normal_arg, *argv):\n    print(\"normal argument:\", normal_arg)\n\n    for arg in argv:\n        print(\"Argument in list of arguments from *argv:\", arg)\n\nargs('animals', 'fish', 'duck', 'bird')\n \n\n Will produce: \n\n normal argument: animals\nArgument in list of arguments from *argv: fish\nArgument in list of arguments from *argv: duck\nArgument in list of arguments from *argv: bird\n \n\n **kwargs* \n\n **kwargs  allows you to pass keyworded variable length of arguments to a function. You should use  **kwargs  if you want to handle named arguments in a function.  \n\n def who(**kwargs):\n    if kwargs is not None:\n        for key, value in kwargs.items():\n            print(\"Your %s is %s.\" % (key, value))\n\nwho(name=\"Nikola\", last_name=\"Tesla\", birthday=\"7.10.1856\", birthplace=\"Croatia\")  \n \n\n Will produce: \n\n Your name is Nikola.\nYour last_name is Tesla.\nYour birthday is 7.10.1856.\nYour birthplace is Croatia.\n \n    ", "date_posted": "2019-05-20 13:36:37Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": []}, {"stack_answer_id": "62442187", "answer_content": "\r\n Given a function that has 3 items as argument \n\n sum = lambda x, y, z: x + y + z\nsum(1,2,3) # sum 3 items\n\nsum([1,2,3]) # error, needs 3 items, not 1 list\n\nx = [1,2,3][0]\ny = [1,2,3][1]\nz = [1,2,3][2]\nsum(x,y,z) # ok\n\nsum(*[1,2,3]) # ok, 1 list becomes 3 items\n \n\n Imagine this toy with a bag of a triangle, a circle and a rectangle item. That bag does not directly fit. You need to unpack the bag to take those 3 items and now they fit. The Python * operator does this unpack process. \n\n \n    ", "date_posted": "2020-06-18 05:03:34Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "4710031", "name": "etoricky", "reputation_score": "571"}, "answer_comments": []}, {"stack_answer_id": "40262722", "answer_content": "\r\n A good example of using both in a function is: \n\n >>> def foo(*arg,**kwargs):\n...     print arg\n...     print kwargs\n>>>\n>>> a = (1, 2, 3)\n>>> b = {'aa': 11, 'bb': 22}\n>>>\n>>>\n>>> foo(*a,**b)\n(1, 2, 3)\n{'aa': 11, 'bb': 22}\n>>>\n>>>\n>>> foo(a,**b) \n((1, 2, 3),)\n{'aa': 11, 'bb': 22}\n>>>\n>>>\n>>> foo(a,b) \n((1, 2, 3), {'aa': 11, 'bb': 22})\n{}\n>>>\n>>>\n>>> foo(a,*b)\n((1, 2, 3), 'aa', 'bb')\n{}\n \n    ", "date_posted": "2016-10-26 12:48:05Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "3066559", "name": "amir jj", "reputation_score": "224"}, "answer_comments": []}, {"stack_answer_id": "40823181", "answer_content": "\r\n This example would help you remember  *args ,  **kwargs  and even  super  and inheritance in Python at once. \n\n class base(object):\n    def __init__(self, base_param):\n        self.base_param = base_param\n\n\nclass child1(base): # inherited from base class\n    def __init__(self, child_param, *args) # *args for non-keyword args\n        self.child_param = child_param\n        super(child1, self).__init__(*args) # call __init__ of the base class and initialize it with a NON-KEYWORD arg\n\nclass child2(base):\n    def __init__(self, child_param, **kwargs):\n        self.child_param = child_param\n        super(child2, self).__init__(**kwargs) # call __init__ of the base class and initialize it with a KEYWORD arg\n\nc1 = child1(1,0)\nc2 = child2(1,base_param=0)\nprint c1.base_param # 0\nprint c1.child_param # 1\nprint c2.base_param # 0\nprint c2.child_param # 1\n \n    ", "date_posted": "2016-11-26 21:09:43Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "5098762", "name": "thanhtang", "reputation_score": "836"}, "answer_comments": []}, {"stack_answer_id": "59217020", "answer_content": "\r\n Context \n\n \n python 3.x \n unpacking with  ** \n use with string formatting \n \n\n Use with string formatting \n\n In addition to the answers in this thread, here is another detail that was not mentioned elsewhere. This expands on the  answer by Brad Solomon \n\n Unpacking with  **  is also useful when using python  str.format .   \n\n This is somewhat similar to what you can do with python  f-strings   f-string  but with the added overhead of declaring a dict to hold the variables (f-string does not require a dict). \n\n Quick Example \n\n   ## init vars\n  ddvars = dict()\n  ddcalc = dict()\n  pass\n  ddvars['fname']     = 'Huomer'\n  ddvars['lname']     = 'Huimpson'\n  ddvars['motto']     = 'I love donuts!'\n  ddvars['age']       = 33\n  pass\n  ddcalc['ydiff']     = 5\n  ddcalc['ycalc']     = ddvars['age'] + ddcalc['ydiff']\n  pass\n  vdemo = []\n\n  ## ********************\n  ## single unpack supported in py 2.7\n  vdemo.append('''\n  Hello {fname} {lname}!\n\n  Today you are {age} years old!\n\n  We love your motto \"{motto}\" and we agree with you!\n  '''.format(**ddvars)) \n  pass\n\n  ## ********************\n  ## multiple unpack supported in py 3.x\n  vdemo.append('''\n  Hello {fname} {lname}!\n\n  In {ydiff} years you will be {ycalc} years old!\n  '''.format(**ddvars,**ddcalc)) \n  pass\n\n  ## ********************\n  print(vdemo[-1])\n\n \n    ", "date_posted": "2019-12-06 16:36:13Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "42223", "name": "dreftymac", "reputation_score": "30.1k"}, "answer_comments": []}, {"stack_answer_id": "66705594", "answer_content": "\r\n *args ( or *any ) means every parameters \n def any_param(*param):\n    pass\n\nany_param(1)\nany_param(1,1)\nany_param(1,1,1)\nany_param(1,...)\n \n NOTICE  : you can don't pass parameters to *args \n def any_param(*param):\n    pass\n\nany_param() # will work correct\n \n The *args is in type tuple \n def any_param(*param):\n    return type(param)\n\nany_param(1) #tuple\nany_param() # tuple\n \n for access to elements don't use of * \n def any(*param):\n    param[0] # correct\n\ndef any(*param):\n    *param[0] # incorrect\n \n The **kwd \n **kwd or **any\nThis is a dict type \n def func(**any):\n    return type(any) # dict\n\ndef func(**any):\n    return any\n\nfunc(width=\"10\",height=\"20\") # {width=\"10\",height=\"20\")\n\n\n \n    ", "date_posted": "2021-04-19 15:19:22Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "4038842", "name": "kjonsson", "reputation_score": "2,749"}, "answer_comments": []}, {"stack_answer_id": "52134172", "answer_content": "\r\n \n def foo(param1, *param2):  is a method can accept arbitrary number of values for  *param2 , \n def bar(param1, **param2):  is a method can accept arbitrary number of values with keys for  *param2 \n param1  is a simple parameter. \n \n\n For example, the syntax for implementing  varargs  in Java as follows: \n\n accessModifier methodName(datatype\u2026 arg) {\n    // method body\n}\n \n    ", "date_posted": "2018-09-02 05:14:05Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "1697099", "name": "Premraj", "reputation_score": "68.9k"}, "answer_comments": []}, {"stack_answer_id": "73178373", "answer_content": "\r\n \"Infinite\" Args with *args and **kwargs \n *args  and  **kwargs  are just some way to input unlimited characters to functions, like: \n \ndef print_all(*args, **kwargs):\n    print(args) # print any number of arguments like: \"print_all(\"foo\", \"bar\")\"\n    print(kwargs.get(\"to_print\")) # print the value of the keyworded argument \"to_print\"\n\n\n# example:\nprint_all(\"Hello\", \"World\", to_print=\"!\")\n# will print:\n\"\"\"\n('Hello', 'World')\n!\n\"\"\"\n \n    ", "date_posted": "2022-07-30 19:05:07Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "16892196", "name": "Isaac Vin\u00edcius", "reputation_score": "13"}, "answer_comments": [{"stack_answer_id": "73178373", "stack_answer_comment_id": "129241254", "comment_content": " can be anything, like ", "user_id": "None"}]}], "user": {"stack_user_id": "2572", "name": "Todd", "reputation_score": "32.1k"}, "question_comments": [{"stack_question_id": "36901", "stack_question_comment_id": "85121837", "comment_content": "see also ", "user_id": "None"}, {"stack_question_id": "36901", "stack_question_comment_id": "97343204", "comment_content": "This question is a very popular duplicate target, but unfortunately it's often used incorrectly. Keep in mind that this question asks about ", "user_id": "None"}, {"stack_question_id": "36901", "stack_question_comment_id": "115318596", "comment_content": "@Aran-Fey: I think a better target for \"what does it mean in function calls\" is ", "user_id": "None"}, {"stack_question_id": "36901", "stack_question_comment_id": "127051533", "comment_content": "This question is - like many very old questions - sort of backwards; usually a question should be about how to solve a problem in new code, rather than how to understand existing code. For the latter, if you are closing something else as a duplicate, consider ", "user_id": "None"}, {"stack_question_id": "36901", "stack_question_comment_id": "128406992", "comment_content": " was also closed as a duplicate of this, but you might find it better than this one.", "user_id": "None"}]},
{"stack_question_id": "59130200", "question_title": "Selenium - wait until element is present, visible and interactable", "question_content": "\r\n                I have a Selenium script (Python) that clicks a reply button to make the class anonemail appear. The time it takes for the class anonemail to appear varies. Because of that I have to use sleep until ...\r\n", "question_url": "/questions/59130200/selenium-wait-until-element-is-present-visible-and-interactable", "date_posted": "Dec 1, 2019 at 21:36", "upvote": "8", "view": "1", "tags": ["python", "selenium", "selenium-webdriver", "webdriverwait", "expected-condition"], "answers_count": "6", "answers": [{"stack_answer_id": "59130336", "answer_content": "\r\n As per the best practices: \n\n \n If your usecase is to validate the  presence  of any element you need to induce  WebDriverWait  setting the  expected_conditions  as  presence_of_element_located()  which is the expectation for checking that an element is present on the DOM of a page. This does not necessarily mean that the element is visible. So the effective line of code will be: \n\n WebDriverWait(browser, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, \".reply-button\"))).click()\n \n If your usecase is to  extract any attribute  of any element you need to induce  WebDriverWait  setting the  expected_conditions  as  visibility_of_element_located(locator)  which is an expectation for checking that an element is present on the DOM of a page and visible. Visibility means that the element is not only displayed but also has a height and width that is greater than 0. So in your usecase effectively the line of code will be: \n\n email = WebDriverWait(driver, 20).until(EC.visibility_of_element_located((By.CSS_SELECTOR, \"element_css\"))).get_attribute(\"value\")\n \n If your usecase is to invoke  click()  on any element you need to induce  WebDriverWait  setting the  expected_conditions  as  element_to_be_clickable()  which is an expectation for for checking an element is visible and enabled such that you can click it. So in your usecase effectively the line of code will be: \n\n WebDriverWait(browser, 20).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \".reply-button\"))).click()\n \n \n\n \n\n References \n\n You can find a couple of detailed discussion in: \n\n \n WebDriverWait not working as expected \n Selenium: Check for the presence of element \n \n    ", "date_posted": "2020-05-05 18:08:39Z", "upvote": "\r\n            111\r\n        ", "accepted": "No", "user": {"stack_user_id": "4575129", "name": "Josh Kot Sheiss", "reputation_score": "65"}, "answer_comments": []}, {"stack_answer_id": "59132328", "answer_content": "\r\n After clicking the  Reply  button, use  .visibility_of_element_located  like below: \n browser.find_element_by_css_selector(\".reply-button\").click()\n\n# Wait for initialize, in seconds\nwait = WebDriverWait(browser, 10)\n\nemail = wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, '.anonemail'))).get_attribute(\"value\")\nprint(email)\n \n Following import: \n from selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\n \n Waits documentation \n    ", "date_posted": "2021-02-06 22:56:43Z", "upvote": "\r\n            38\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "59130269", "answer_content": "\r\n You can use waits. Check for more information in  Selenium waits . \n In the example below we are waiting 10 seconds for the element to be visible, using the function  visibility_of_element_located . \n driver = webdriver.Firefox()\ndriver.get(\"http://somedomain/url_that_delays_loading\")\ntry:\n    element = WebDriverWait(driver, 10).until(\n        EC.visibility_of_element_located((By.ID, \"myDynamicElement\"))\n    )\nfinally:\n    driver.quit()\n \n    ", "date_posted": "2021-02-06 22:51:27Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "59130290", "answer_content": "\r\n You can use  implicitly_wait : \n from selenium import webdriver\n\ndriver = webdriver.Firefox()\ndriver.implicitly_wait(15)\ndriver.get(\"http://url\")\ndriver.find_element_by_id(\"id_of_element\").click()\n \n It waits until element is loaded. \n In your case the implementation would be, \n browser.implicitly_wait(10)\nbrowser.find_element_by_css_selector(\".reply-button\").click()\nemail = browser.find_element_by_css_selector(\".anonemail\").get_attribute(\"value\")\n \n    ", "date_posted": "2021-02-06 22:53:29Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "73087463", "answer_content": "\r\n \n WebDriverWait(driver, 5).until(         EC.presence_of_element_located((By.CSS_SELECTOR, \".reply-button\"))) : \n \n Hey driver, wait (0-5 seconds), when you see  .reply-button  is  presence , return that button to me! \n \n presence  is present on the DOM. Hidden element is good enough. \n \n \n \n \n WebDriverWait(driver, 5).until(         EC.visibility_of_element_located((By.CSS_SELECTOR, \".reply-button\u201d)))) : \n \n Hey driver, wait (0-5 seconds), when you see  .reply-button  is  visibility , return that button to me! \n \n visibility  is present and visible on the DOM. Hidden element is  not  good enough! \n \n \n \n \n WebDriverWait(driver, 5).until(         EC.element_to_be_clickable((By.CSS_SELECTOR, \".reply-button\u201d)))) : \n \n Hey driver, wait (0-5 seconds), when you see  .reply-button  is  clickable , return that button to me! \n \n clickable  is present and visible and clickable on the DOM. Hidden element or non-clickable is  not  good enough! \n \n \n \n \n \n \n    ", "date_posted": "2022-07-23 01:49:26Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "3927279", "name": "HoangYell", "reputation_score": "3,273"}, "answer_comments": []}, {"stack_answer_id": "72127317", "answer_content": "\r\n I also had a similar problem to yours, I tried using  implicit_wait()  and  WebDriverWait  but they did not work.\nSo I solved setting the  implicit_wait(10)  in the  web driver  instance and using this snippet to click on the button: \n element = driver.find_elements_by_xpath(\"//button[contains(string(), 'Log In')]\")[0]\ndriver.execute_script(\"arguments[0].click();\", element)\n \n    ", "date_posted": "2022-05-05 12:38:25Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "16966945", "name": "badr", "reputation_score": "54"}, "answer_comments": []}], "user": {"stack_user_id": "12458043", "name": "Benjamin Arvola", "reputation_score": "915"}, "question_comments": [{"stack_question_id": "59130200", "stack_question_comment_id": "120993427", "comment_content": "Do any of the answers address waiting for the element to be interactable? It can be present and clickable and still not ready for you to send keys to it.", "user_id": "None"}, {"stack_question_id": "59130200", "stack_question_comment_id": "126527567", "comment_content": "Try: ", "user_id": "None"}]},
{"stack_question_id": "986006", "question_title": "How do I pass a variable by reference?", "question_content": "\r\n                Are parameters passed by reference or by value? How do I pass by reference so that the code below outputs 'Changed' instead of 'Original'?\nclass PassByReference:\n    def __init__(self):\n        self....\r\n", "question_url": "/questions/986006/how-do-i-pass-a-variable-by-reference", "date_posted": "Jun 12, 2009 at 10:23", "upvote": "3", "view": "1", "tags": ["python", "reference", "parameter-passing", "pass-by-reference"], "answers_count": "3", "answers": [{"stack_answer_id": "986145", "answer_content": "\r\n Arguments are  passed by assignment . The rationale behind this is twofold: \n\n \n the parameter passed in is actually a  reference  to an object (but the reference is passed by value) \n some data types are mutable, but others aren't \n \n\n So: \n\n \n If you pass a  mutable  object into a method, the method gets a reference to that same object and you can mutate it to your heart's delight, but if you rebind the reference in the method, the outer scope will know nothing about it, and after you're done, the outer reference will still point at the original object.  \n If you pass an  immutable  object to a method, you still can't rebind the outer reference, and you can't even mutate the object. \n \n\n To make it even more clear, let's have some examples.  \n\n List - a mutable type \n\n Let's try to modify the list that was passed to a method: \n\n def try_to_change_list_contents(the_list):\n    print('got', the_list)\n    the_list.append('four')\n    print('changed to', the_list)\n\nouter_list = ['one', 'two', 'three']\n\nprint('before, outer_list =', outer_list)\ntry_to_change_list_contents(outer_list)\nprint('after, outer_list =', outer_list)\n \n\n Output: \n\n before, outer_list = ['one', 'two', 'three']\ngot ['one', 'two', 'three']\nchanged to ['one', 'two', 'three', 'four']\nafter, outer_list = ['one', 'two', 'three', 'four']\n \n\n Since the parameter passed in is a reference to  outer_list , not a copy of it, we can use the mutating list methods to change it and have the changes reflected in the outer scope. \n\n Now let's see what happens when we try to change the reference that was passed in as a parameter: \n\n def try_to_change_list_reference(the_list):\n    print('got', the_list)\n    the_list = ['and', 'we', 'can', 'not', 'lie']\n    print('set to', the_list)\n\nouter_list = ['we', 'like', 'proper', 'English']\n\nprint('before, outer_list =', outer_list)\ntry_to_change_list_reference(outer_list)\nprint('after, outer_list =', outer_list)\n \n\n Output: \n\n before, outer_list = ['we', 'like', 'proper', 'English']\ngot ['we', 'like', 'proper', 'English']\nset to ['and', 'we', 'can', 'not', 'lie']\nafter, outer_list = ['we', 'like', 'proper', 'English']\n \n\n Since the  the_list  parameter was passed by value, assigning a new list to it had no effect that the code outside the method could see. The  the_list  was a copy of the  outer_list  reference, and we had  the_list  point to a new list, but there was no way to change where  outer_list  pointed. \n\n String - an immutable type \n\n It's immutable, so there's nothing we can do to change the contents of the string \n\n Now, let's try to change the reference \n\n def try_to_change_string_reference(the_string):\n    print('got', the_string)\n    the_string = 'In a kingdom by the sea'\n    print('set to', the_string)\n\nouter_string = 'It was many and many a year ago'\n\nprint('before, outer_string =', outer_string)\ntry_to_change_string_reference(outer_string)\nprint('after, outer_string =', outer_string)\n \n\n Output: \n\n before, outer_string = It was many and many a year ago\ngot It was many and many a year ago\nset to In a kingdom by the sea\nafter, outer_string = It was many and many a year ago\n \n\n Again, since the  the_string  parameter was passed by value, assigning a new string to it had no effect that the code outside the method could see. The  the_string  was a copy of the  outer_string  reference, and we had  the_string  point to a new string, but there was no way to change where  outer_string  pointed. \n\n I hope this clears things up a little. \n\n EDIT:  It's been noted that this doesn't answer the question that @David originally asked, \"Is there something I can do to pass the variable by actual reference?\". Let's work on that. \n\n How do we get around this? \n\n As @Andrea's answer shows, you could return the new value. This doesn't change the way things are passed in, but does let you get the information you want back out: \n\n def return_a_whole_new_string(the_string):\n    new_string = something_to_do_with_the_old_string(the_string)\n    return new_string\n\n# then you could call it like\nmy_string = return_a_whole_new_string(my_string)\n \n\n If you really wanted to avoid using a return value, you could create a class to hold your value and pass it into the function or use an existing class, like a list: \n\n def use_a_wrapper_to_simulate_pass_by_reference(stuff_to_change):\n    new_string = something_to_do_with_the_old_string(stuff_to_change[0])\n    stuff_to_change[0] = new_string\n\n# then you could call it like\nwrapper = [my_string]\nuse_a_wrapper_to_simulate_pass_by_reference(wrapper)\n\ndo_something_with(wrapper[0])\n \n\n Although this seems a little cumbersome. \n    ", "date_posted": "2017-04-03 02:13:38Z", "upvote": "\r\n            3367\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "1087720", "name": "random_user", "reputation_score": "788"}, "answer_comments": [{"stack_answer_id": "986145", "stack_answer_comment_id": "794601", "comment_content": "Then the same is in C, when you pass \"by reference\" you're actually passing ", "user_id": "None"}, {"stack_answer_id": "986145", "stack_answer_comment_id": "794645", "comment_content": "I'm not sure I understand your terms. I've been out of the C game for a while, but back when I was in it, there was no \"pass by reference\" - you could pass things, and it was always pass by value, so whatever was in the parameter list was copied. But sometimes the thing was a pointer, which one could follow to the piece of memory (primitive, array, struct, whatever), but you couldn't change the pointer that was copied from the outer scope - when you were done with the function, the original pointer still pointed to the same address. C++ introduced references, which behaved differently.", "user_id": "None"}, {"stack_answer_id": "986145", "stack_answer_comment_id": "8874950", "comment_content": "@Zac Bowling I don't really get how what you're saying is relevant, in a practical sense, to this answer. If a Python newcomer wanted to know about passing by ref/val, then the takeaway from this answer is: ", "user_id": "None"}, {"stack_answer_id": "986145", "stack_answer_comment_id": "9988567", "comment_content": "@CamJackson, you need a better example - numbers are also immutable objects in Python. Besides, wouldn't it be true to say that ", "user_id": "None"}, {"stack_answer_id": "986145", "stack_answer_comment_id": "10928887", "comment_content": "-1. The code shown is good, the explanation as to how is completely wrong.  See the answers by DavidCournapeau or DarenThomas for correct explanations as to why.", "user_id": "None"}]}, {"stack_answer_id": "8140747", "answer_content": "\r\n The problem comes from a misunderstanding of what variables are in Python. If you're used to most traditional languages, you have a mental model of what happens in the following sequence: \n\n a = 1\na = 2\n \n\n You believe that  a  is a memory location that stores the value  1 , then is updated to store the value  2 . That's not how things work in Python. Rather,  a  starts as a reference to an object with the value  1 , then gets reassigned as a reference to an object with the value  2 . Those two objects may continue to coexist even though  a  doesn't refer to the first one anymore; in fact they may be shared by any number of other references within the program. \n\n When you call a function with a parameter, a new reference is created that refers to the object passed in. This is separate from the reference that was used in the function call, so there's no way to update that reference and make it refer to a new object. In your example: \n\n def __init__(self):\n    self.variable = 'Original'\n    self.Change(self.variable)\n\ndef Change(self, var):\n    var = 'Changed'\n \n\n self.variable  is a reference to the string object  'Original' . When you call  Change  you create a second reference  var  to the object. Inside the function you reassign the reference  var  to a different string object  'Changed' , but the reference  self.variable  is separate and does not change. \n\n The only way around this is to pass a mutable object. Because both references refer to the same object, any changes to the object are reflected in both places. \n\n def __init__(self):         \n    self.variable = ['Original']\n    self.Change(self.variable)\n\ndef Change(self, var):\n    var[0] = 'Changed'\n \n    ", "date_posted": "2017-04-03 00:39:27Z", "upvote": "\r\n            836\r\n        ", "accepted": "No", "user": {"stack_user_id": "1087720", "name": "random_user", "reputation_score": "788"}, "answer_comments": [{"stack_answer_id": "8140747", "stack_answer_comment_id": "9996492", "comment_content": "Good succinct explanation. Your paragraph \"When you call a function...\" is one of the best explanations I've heard of the rather cryptic phrase that 'Python function parameters are references, passed by value.' I think if you understand that paragraph alone, everything else kind of just makes sense and flows as a logical conclusion from there. Then you just have to be aware of when you're creating a new object and when you're modifying an existing one.", "user_id": "None"}, {"stack_answer_id": "8140747", "stack_answer_comment_id": "13535104", "comment_content": "But how can you reassign the reference? I thought you can't change the address of 'var' but that your string \"Changed\" was now going to be stored in the 'var' memory address. Your description makes it seem like \"Changed\" and \"Original\" belong to different places in memory instead and you just switch 'var' to a different address. Is that correct?", "user_id": "None"}, {"stack_answer_id": "8140747", "stack_answer_comment_id": "13535380", "comment_content": "@Glassjawed, I think you're getting it. \"Changed\" and \"Original\" are two different string objects at different memory addresses and 'var' changes from pointing to one to pointing to the other.", "user_id": "None"}, {"stack_answer_id": "8140747", "stack_answer_comment_id": "85424727", "comment_content": "@TonySuffolk66 ", "user_id": "None"}, {"stack_answer_id": "8140747", "stack_answer_comment_id": "92716352", "comment_content": "@MinhTran in the simplest terms, a reference is something that \"refers\" to an object. The physical representation of that is most likely a pointer, but that's simply an implementation detail. It really is an abstract notion at heart.", "user_id": "None"}]}, {"stack_answer_id": "25670170", "answer_content": "\r\n I found the other answers rather long and complicated, so I created this simple diagram to explain the way Python treats variables and parameters.\n \n    ", "date_posted": "2016-05-25 15:30:05Z", "upvote": "\r\n            435\r\n        ", "accepted": "No", "user": {"stack_user_id": "3718878", "name": "Zenadix", "reputation_score": "13.9k"}, "answer_comments": [{"stack_answer_id": "25670170", "stack_answer_comment_id": "56900547", "comment_content": "lovely, makes it easy to spot the subtle diff that there is an intermediate assignment, not obvious to a casual onlooker. +1", "user_id": "None"}, {"stack_answer_id": "25670170", "stack_answer_comment_id": "62356762", "comment_content": "It doesn't matter if A is mutable or not. If you assign something different to B, ", "user_id": "None"}, {"stack_answer_id": "25670170", "stack_answer_comment_id": "62387810", "comment_content": "@Martijn You're right. I removed the part of the answer that mentions mutability. I don't think it can get any simpler now.", "user_id": "None"}, {"stack_answer_id": "25670170", "stack_answer_comment_id": "62388292", "comment_content": "Thanks for the update, much better! What confuses most people is assignment to a subscription; e.g. ", "user_id": "None"}, {"stack_answer_id": "25670170", "stack_answer_comment_id": "63811790", "comment_content": "\"A is assigned to B.\" Is that not ambiguous? I think in ordinary English that can mean either ", "user_id": "None"}]}, {"stack_answer_id": "986495", "answer_content": "\r\n It is neither pass-by-value or pass-by-reference - it is call-by-object. See this, by Fredrik Lundh: \n http://effbot.org/zone/call-by-object.htm \n Here is a significant quote: \n \n \"...variables [names] are  not  objects; they cannot be denoted by other variables or referred to by objects.\" \n \n In your example, when the  Change  method is called--a  namespace  is created for it; and  var  becomes a name, within that namespace, for the string object  'Original' . That object then has a name in two namespaces. Next,  var = 'Changed'  binds  var  to a new string object, and thus the method's namespace forgets about  'Original' . Finally, that namespace is forgotten, and the string  'Changed'  along with it. \n    ", "date_posted": "2021-05-30 16:36:04Z", "upvote": "\r\n            268\r\n        ", "accepted": "No", "user": {"stack_user_id": "701315", "name": "waxwing", "reputation_score": "117"}, "answer_comments": [{"stack_answer_id": "986495", "stack_answer_comment_id": "10494915", "comment_content": "I find it hard to buy. To me is just as Java, the parameters are pointers to objects in memory, and those pointers are passed via the stack, or registers.", "user_id": "None"}, {"stack_answer_id": "986495", "stack_answer_comment_id": "10518161", "comment_content": "This is not like java. One of the case where it is not the same is immutable objects. Think about the trivial function lambda x: x. Apply this for x = [1, 2, 3] and x = (1, 2, 3). In the first case, the returned value will be a copy of the input, and identical in the second case.", "user_id": "None"}, {"stack_answer_id": "986495", "stack_answer_comment_id": "18284481", "comment_content": "No, it's ", "user_id": "None"}, {"stack_answer_id": "986495", "stack_answer_comment_id": "19264776", "comment_content": "It is exactly the same as in Java. Object references are passed by value. Anyone who thinks differently should attach the Python code for a ", "user_id": "None"}, {"stack_answer_id": "986495", "stack_answer_comment_id": "25806292", "comment_content": "It is exactly the same as Java when you pass objects in Java. However, Java also have primitives, which are passed by copying the value of the primitive. Thus they differ in that case.", "user_id": "None"}]}, {"stack_answer_id": "986339", "answer_content": "\r\n Think of stuff being passed  by assignment  instead of by reference/by value. That way, it is always clear, what is happening as long as you understand what happens during the normal assignment. \n\n So, when passing a list to a function/method, the list is assigned to the parameter name. Appending to the list will result in the list being modified. Reassigning the list  inside  the function will not change the original list, since: \n\n a = [1, 2, 3]\nb = a\nb.append(4)\nb = ['a', 'b']\nprint a, b      # prints [1, 2, 3, 4] ['a', 'b']\n \n\n Since immutable types cannot be modified, they  seem  like being passed by value - passing an int into a function means assigning the int to the function's parameter. You can only ever reassign that, but it won't change the original variables value. \n    ", "date_posted": "2019-11-20 04:37:51Z", "upvote": "\r\n            212\r\n        ", "accepted": "No", "user": {"stack_user_id": "5002179", "name": "MurugananthamS", "reputation_score": "2,351"}, "answer_comments": [{"stack_answer_id": "986339", "stack_answer_comment_id": "81843915", "comment_content": "At first glance this answer seems to sidestep the original question. After a second read I've come to realize that this makes the matter quite clear. A good follow up to this \"name assignment\" concept may be found  here: ", "user_id": "None"}]}, {"stack_answer_id": "21700609", "answer_content": "\r\n There are no variables in Python \n\n The key to understanding parameter passing is to stop thinking about \"variables\". There are names and objects in Python and together they\nappear like variables, but it is useful to always distinguish the three. \n\n \n Python has names and objects. \n Assignment binds a name to an object. \n Passing an argument into a function also binds a name (the parameter name of the function) to an object. \n \n\n That is all there is to it. Mutability is irrelevant to this question. \n\n Example: \n\n a = 1\n \n\n This binds the name  a  to an object of type integer that holds the value 1. \n\n b = x\n \n\n This binds the name  b  to the same object that the name  x  is currently bound to.\nAfterward, the name  b  has nothing to do with the name  x  anymore. \n\n See sections  3.1  and  4.2  in the Python 3 language reference. \n\n How to read the example in the question \n\n In the code shown in the question, the statement  self.Change(self.variable)  binds the name  var  (in the scope of function  Change ) to the object that holds the value  'Original'  and the assignment  var = 'Changed'  (in the body of function  Change ) assigns that same name again: to some other object (that happens to hold a string as well but could have been something else entirely). \n\n How to pass by reference \n\n So if the thing you want to change is a mutable object, there is no problem, as everything is effectively passed by reference. \n\n If it is an  immutable  object (e.g. a bool, number, string), the way to go is to wrap it in a mutable object. \nThe quick-and-dirty solution for this is a one-element list (instead of  self.variable , pass  [self.variable]  and in the function modify  var[0] ). \nThe more  pythonic  approach would be to introduce a trivial, one-attribute class. The function receives an instance of the class and manipulates the attribute. \n    ", "date_posted": "2020-04-27 10:17:30Z", "upvote": "\r\n            91\r\n        ", "accepted": "No", "user": {"stack_user_id": "11024053", "name": "faressalem", "reputation_score": "544"}, "answer_comments": [{"stack_answer_id": "21700609", "stack_answer_comment_id": "37695746", "comment_content": "\"Python has no variables\" is a silly and confusing slogan, and I really wish people would stop saying it... :(   The rest of this answer is good!", "user_id": "None"}, {"stack_answer_id": "21700609", "stack_answer_comment_id": "37747455", "comment_content": "It may be shocking, but it is not silly. And I don't think it is confusing either: It hopefully opens up the recipient's mind for the explanation that is coming and puts her in a useful \"I wonder what they have instead of variables\" attitude. (Yes, your mileage may vary.)", "user_id": "None"}, {"stack_answer_id": "21700609", "stack_answer_comment_id": "37755336", "comment_content": "would you also say that Javascript has no variables? They work the same as Python's.  Also, Java, Ruby, PHP, ....   I think a better teaching technique is, \"Python's variables work differently than C's.\"", "user_id": "None"}, {"stack_answer_id": "21700609", "stack_answer_comment_id": "41878922", "comment_content": "Yes, Java has variables. So does Python, and JavaScript, Ruby, PHP, etc.  You wouldn't say in Java that ", "user_id": "None"}, {"stack_answer_id": "21700609", "stack_answer_comment_id": "53893736", "comment_content": "The concept of \"variable\" is complex and often vague: ", "user_id": "None"}]}, {"stack_answer_id": "15697476", "answer_content": "\r\n Effbot (aka Fredrik Lundh) has described Python's variable passing style as call-by-object:   http://effbot.org/zone/call-by-object.htm \n\n Objects are allocated on the heap and pointers to them can be passed around anywhere.   \n\n \n When you make an assignment such as  x = 1000 , a dictionary entry is created that maps the string \"x\" in the current namespace to a pointer to the integer object containing one thousand.    \n When you update \"x\" with  x = 2000 , a new integer object is created and the dictionary is updated to point at the new object.  The old one thousand object is unchanged (and may or may not be alive depending on whether anything else refers to the object). \n When you do a new assignment such as  y = x , a new dictionary entry \"y\" is created that points to the same object as the entry for \"x\". \n Objects like strings and integers are  immutable .  This simply means that there are no methods that can change the object after it has been created.  For example, once the integer object one-thousand is created, it will never change.  Math is done by creating new integer objects. \n Objects like lists are  mutable .  This means that the contents of the object can be changed by anything pointing to the object.  For example,  x = []; y = x; x.append(10); print y  will print  [10] .  The empty list was created.  Both \"x\" and \"y\" point to the same list.  The  append  method mutates (updates) the list object (like adding a record to a database) and the result is visible to both \"x\" and \"y\" (just as a database update would be visible to every connection to that database). \n \n\n Hope that clarifies the issue for you.  \n    ", "date_posted": "2013-03-29 04:41:44Z", "upvote": "\r\n            84\r\n        ", "accepted": "No", "user": {"stack_user_id": "424499", "name": "Raymond Hettinger", "reputation_score": "205k"}, "answer_comments": [{"stack_answer_id": "15697476", "stack_answer_comment_id": "31747271", "comment_content": "I really appreciate learning about this from a developer. Is it true that the ", "user_id": "None"}, {"stack_answer_id": "15697476", "stack_answer_comment_id": "31758965", "comment_content": "@HonestAbe Yes, in CPython the ", "user_id": "None"}]}, {"stack_answer_id": "12440140", "answer_content": "\r\n Technically,  Python always uses pass by reference values . I am going to repeat  my other answer  to support my statement. \n\n Python always uses pass-by-reference values. There isn't any exception. Any variable assignment means copying the reference value. No exception. Any variable is the name bound to the reference value. Always. \n\n You can think about a reference value as the address of the target object. The address is automatically dereferenced when used. This way, working with the reference value, it seems you work directly with the target object. But there always is a reference in between, one step more to jump to the target. \n\n Here is the example that proves that Python uses passing by reference: \n\n \n\n If the argument was passed by value, the outer  lst  could not be modified. The green are the target objects (the black is the value stored inside, the red is the object type), the yellow is the memory with the reference value inside -- drawn as the arrow. The blue solid arrow is the reference value that was passed to the function (via the dashed blue arrow path). The ugly dark yellow is the internal dictionary. (It actually could be drawn also as a green ellipse. The colour and the shape only says it is internal.) \n\n You can use the  id()  built-in function to learn what the reference value is (that is, the address of the target object). \n\n In compiled languages, a variable is a memory space that is able to capture the value of the type. In Python, a variable is a name (captured internally as a string) bound to the reference variable that holds the reference value to the target object. The name of the variable is the key in the internal dictionary, the value part of that dictionary item stores the reference value to the target. \n\n Reference values are hidden in Python. There isn't any explicit user type for storing the reference value. However, you can use a list element (or element in any other suitable container type) as the reference variable, because all containers do store the elements also as references to the target objects. In other words, elements are actually not contained inside the container -- only the references to elements are. \n    ", "date_posted": "2017-05-23 12:18:21Z", "upvote": "\r\n            66\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": [{"stack_answer_id": "12440140", "stack_answer_comment_id": "17197207", "comment_content": "Actually this is confirmed its pass by reference value. +1 for this answer although the example wasnt good.", "user_id": "None"}, {"stack_answer_id": "12440140", "stack_answer_comment_id": "19264948", "comment_content": "Inventing new terminology (such as \"pass by reference value\" or \"call by object\" is not helpful). \"Call by (value|reference|name)\" are standard terms. \"reference\" is a standard term. Passing references by value accurately describes the behavior of Python, Java, and a host of other languages, using standard terminology.", "user_id": "None"}, {"stack_answer_id": "12440140", "stack_answer_comment_id": "19270112", "comment_content": "@cayhorstmann: The problem is that ", "user_id": "None"}, {"stack_answer_id": "12440140", "stack_answer_comment_id": "31746972", "comment_content": "I like this answer, but you might consider if the example is really helping or hurting the flow. Also, if you replaced 'reference value' with 'object reference' you would be using terminology that we could consider 'official', as seen here: ", "user_id": "None"}, {"stack_answer_id": "12440140", "stack_answer_comment_id": "31841961", "comment_content": "There is a footnote indicated at the end of that quote, which reads: ", "user_id": "None"}]}, {"stack_answer_id": "6963425", "answer_content": "\r\n A simple trick I normally use is to just wrap it in a list: \n\n def Change(self, var):\n    var[0] = 'Changed'\n\nvariable = ['Original']\nself.Change(variable)      \nprint variable[0]\n \n\n (Yeah I know this can be inconvenient, but sometimes it is simple enough to do this.) \n    ", "date_posted": "2011-08-08 10:39:48Z", "upvote": "\r\n            56\r\n        ", "accepted": "No", "user": {"stack_user_id": "381083", "name": "AmanicA", "reputation_score": "4,352"}, "answer_comments": [{"stack_answer_id": "6963425", "stack_answer_comment_id": "40468476", "comment_content": "+1 for small amount of text giving the essential workaround to the problem of Python not having pass-by-reference. (As a follow-on comment/question that fits here as well as anywhere on this page: It's not clear to my why python can't provide a \"ref\" keyword like C# does, that simply wraps the caller's argument in a list like this, and treat references to the argument within the function as the 0th element of the list.)", "user_id": "None"}, {"stack_answer_id": "6963425", "stack_answer_comment_id": "44877350", "comment_content": "Nice. To pass by ref, wrap in [ ]'s.", "user_id": "None"}]}, {"stack_answer_id": "3127336", "answer_content": "\r\n (edit - Blair has updated his enormously popular answer so that it is now accurate) \n\n I think it is important to note that the current post with the most votes (by Blair Conrad), while being correct with respect to its result, is misleading and is borderline incorrect based on its definitions.  While there are many languages (like C) that allow the user to either pass by reference or pass by value, Python is not one of them. \n\n David Cournapeau's answer points to the real answer and explains why the behavior in Blair Conrad's post seems to be correct while the definitions are not. \n\n To the extent that Python is pass by value, all languages are pass by value since some piece of data (be it a \"value\" or a \"reference\") must be sent. However, that does not mean that Python is pass by value in the sense that a C programmer would think of it. \n\n If you want the behavior, Blair Conrad's answer is fine.  But if you want to know the nuts and bolts of why Python is neither pass by value or pass by reference, read David Cournapeau's answer. \n    ", "date_posted": "2015-10-09 15:00:42Z", "upvote": "\r\n            39\r\n        ", "accepted": "No", "user": {"stack_user_id": "377366", "name": "KobeJohn", "reputation_score": "7,128"}, "answer_comments": [{"stack_answer_id": "3127336", "stack_answer_comment_id": "19264866", "comment_content": "It is simply not true that all languages are call by value. In C++ or Pascal (and surely many others that I don't know), you have call by reference. For example, in C++, ", "user_id": "None"}, {"stack_answer_id": "3127336", "stack_answer_comment_id": "53903706", "comment_content": "I thought I had replied to this long ago but I don't see it. For completeness - cayhorstmann misunderstood my answer. I was not saying everything is call by value ", "user_id": "None"}]}, {"stack_answer_id": "986335", "answer_content": "\r\n You got some really good answers here. \n\n x = [ 2, 4, 4, 5, 5 ]\nprint x  # 2, 4, 4, 5, 5\n\ndef go( li ) :\n  li = [ 5, 6, 7, 8 ]  # re-assigning what li POINTS TO, does not\n  # change the value of the ORIGINAL variable x\n\ngo( x ) \nprint x  # 2, 4, 4, 5, 5  [ STILL! ]\n\n\nraw_input( 'press any key to continue' )\n \n    ", "date_posted": "2012-01-27 04:28:48Z", "upvote": "\r\n            28\r\n        ", "accepted": "No", "user": {"stack_user_id": "1129194", "name": "Alex L", "reputation_score": "8,306"}, "answer_comments": [{"stack_answer_id": "986335", "stack_answer_comment_id": "37877580", "comment_content": "yea, however if you do   x = [ 2, 4, 4, 5, 5],  y = x,  X[0] = 1 , print x # [1, 4 ,4, 5, 5]  print y # [1, 4, 4, 5, 5]", "user_id": "None"}, {"stack_answer_id": "986335", "stack_answer_comment_id": "121249518", "comment_content": "X[0]   or x[0] ? don't get it", "user_id": "None"}]}, {"stack_answer_id": "986044", "answer_content": "\r\n In this case the variable titled  var  in the method  Change  is assigned a reference to  self.variable , and you immediately assign a string to  var . It's no longer pointing to  self.variable . The following code snippet shows what would happen if you modify the data structure pointed to by  var  and  self.variable , in this case a list: \n\n >>> class PassByReference:\n...     def __init__(self):\n...         self.variable = ['Original']\n...         self.change(self.variable)\n...         print self.variable\n...         \n...     def change(self, var):\n...         var.append('Changed')\n... \n>>> q = PassByReference()\n['Original', 'Changed']\n>>> \n \n\n I'm sure someone else could clarify this further. \n    ", "date_posted": "2009-06-12 10:39:59Z", "upvote": "\r\n            23\r\n        ", "accepted": "No", "user": {"stack_user_id": "2576", "name": "Mike Mazur", "reputation_score": "2,479"}, "answer_comments": []}, {"stack_answer_id": "29293411", "answer_content": "\r\n Python\u2019s pass-by-assignment scheme isn\u2019t quite the same as C++\u2019s reference parameters option, but it turns out to be very similar to the argument-passing model of the C language (and others) in practice: \n\n \n Immutable arguments are effectively passed \u201c by value .\u201d Objects such as integers and strings are passed by object reference instead of by copying, but because you can\u2019t change immutable objects in place anyhow, the effect is much like making a copy. \n Mutable arguments are effectively passed \u201c by pointer .\u201d Objects such as lists\nand dictionaries are also passed by object reference, which is similar to the way C\npasses arrays as pointers\u2014mutable objects can be changed in place in the function,\nmuch like C arrays. \n \n    ", "date_posted": "2015-03-27 04:38:18Z", "upvote": "\r\n            23\r\n        ", "accepted": "No", "user": {"stack_user_id": "1112163", "name": "ajknzhol", "reputation_score": "6,116"}, "answer_comments": []}, {"stack_answer_id": "25810863", "answer_content": "\r\n A lot of insights in answers here, but i think an additional point is not clearly mentioned here explicitly.   Quoting from python documentation  https://docs.python.org/2/faq/programming.html#what-are-the-rules-for-local-and-global-variables-in-python    \n\n \"In Python, variables that are only referenced inside a function are implicitly global. If a variable is assigned a new value anywhere within the function\u2019s body, it\u2019s assumed to be a local. If a variable is ever assigned a new value inside the function, the variable is implicitly local, and you need to explicitly declare it as \u2018global\u2019.\nThough a bit surprising at first, a moment\u2019s consideration explains this. On one hand, requiring global for assigned variables provides a bar against unintended side-effects. On the other hand, if global was required for all global references, you\u2019d be using global all the time. You\u2019d have to declare as global every reference to a built-in function or to a component of an imported module. This clutter would defeat the usefulness of the global declaration for identifying side-effects.\" \n\n Even when passing a mutable object to a function this still applies. And to me clearly explains the reason for the difference in behavior between assigning to the object and operating on the object in the function. \n\n def test(l):\n    print \"Received\", l , id(l)\n    l = [0, 0, 0]\n    print \"Changed to\", l, id(l)  # New local object created, breaking link to global l\n\nl= [1,2,3]\nprint \"Original\", l, id(l)\ntest(l)\nprint \"After\", l, id(l)\n \n\n gives: \n\n Original [1, 2, 3] 4454645632\nReceived [1, 2, 3] 4454645632\nChanged to [0, 0, 0] 4474591928\nAfter [1, 2, 3] 4454645632\n \n\n The assignment to an global variable that is not declared global therefore creates a new local object and breaks the link to the original object. \n    ", "date_posted": "2014-09-29 07:12:10Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "2107677", "name": "Joop", "reputation_score": "7,374"}, "answer_comments": [{"stack_answer_id": "25810863", "stack_answer_comment_id": "128530353", "comment_content": "+1 good answer, this mentioned what I was thinking. I was quite surprised when no one mentioned this. If no assignment is made, the alias and the original are one, but when we make a re-assignment, the link is broken, and a new local object is created inside the function.", "user_id": "None"}]}, {"stack_answer_id": "21684541", "answer_content": "\r\n As you can state you need to have a mutable object, but let me suggest you to check over the global variables as they can help you or even solve this kind of issue! \n\n http://docs.python.org/3/faq/programming.html#what-are-the-rules-for-local-and-global-variables-in-python \n\n example: \n\n >>> def x(y):\n...     global z\n...     z = y\n...\n\n>>> x\n<function x at 0x00000000020E1730>\n>>> y\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'y' is not defined\n>>> z\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'z' is not defined\n\n>>> x(2)\n>>> x\n<function x at 0x00000000020E1730>\n>>> y\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'y' is not defined\n>>> z\n2\n \n    ", "date_posted": "2016-08-09 02:23:54Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "3739391", "name": "John Smith", "reputation_score": "7,048"}, "answer_comments": [{"stack_answer_id": "21684541", "stack_answer_comment_id": "37922353", "comment_content": "I was tempted to post a similar response- the original questioner may not have known that what he wanted was in fact to use a global variable, shared among functions. Here's the link I would have shared: ", "user_id": "None"}]}, {"stack_answer_id": "12686527", "answer_content": "\r\n Here is the simple (I hope) explanation of the concept  pass by object  used in Python. \nWhenever you pass an object to the function, the object itself is passed (object in Python is actually what you'd call a value in other programming languages) not the reference to this object. In other words, when you call: \n\n def change_me(list):\n   list = [1, 2, 3]\n\nmy_list = [0, 1]\nchange_me(my_list)\n \n\n The actual object - [0, 1] (which would be called a value in other programming languages) is being passed. So in fact the function  change_me  will try to do something like: \n\n [0, 1] = [1, 2, 3]\n \n\n which obviously will not change the object passed to the function. If the function looked like this: \n\n def change_me(list):\n   list.append(2)\n \n\n Then the call would result in: \n\n [0, 1].append(2)\n \n\n which obviously will change the object.  This answer  explains it well. \n    ", "date_posted": "2017-05-23 11:54:59Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": [{"stack_answer_id": "12686527", "stack_answer_comment_id": "17172121", "comment_content": "The problem is that the assignment does something else than you expect. The ", "user_id": "None"}, {"stack_answer_id": "12686527", "stack_answer_comment_id": "36152119", "comment_content": "@pepr objects aren't literals. They are objects. The only way to talk about them is giving them some names. That's why it's so simple once you grasp it, but enormously complicated to explain. :-)", "user_id": "None"}, {"stack_answer_id": "12686527", "stack_answer_comment_id": "36239341", "comment_content": "@Veky: I am aware of that. Anyway, the list literal is converted to the list object. Actually, any object in Python can exist without a name, and it can be used even when not given any name. And you can think about them as about anonymous objects. Think about objects being the elements of a lists. They need not a name. You can access them through indexing of or iterating through the list. Anyway, I insist on ", "user_id": "None"}, {"stack_answer_id": "12686527", "stack_answer_comment_id": "36242700", "comment_content": "@pepr: I don't necessarily mean Python-definition names, just ordinary names. Of course ", "user_id": "None"}, {"stack_answer_id": "12686527", "stack_answer_comment_id": "36361122", "comment_content": "Argh. My English is obviously much worse than my Python. :-) I'll try just once more. I just said you have to give object some names just to talk about them. By that \"names\" I didn't mean \"names as defined by Python\". I know Python mechanisms, don't worry.", "user_id": "None"}]}, {"stack_answer_id": "35260424", "answer_content": "\r\n Aside from all the great explanations on how this stuff works in Python, I don't see a simple suggestion for the problem. As you seem to do create objects and instances, the pythonic way of handling instance variables and changing them is the following: \n\n class PassByReference:\n    def __init__(self):\n        self.variable = 'Original'\n        self.Change()\n        print self.variable\n\n    def Change(self):\n        self.variable = 'Changed'\n \n\n In instance methods, you normally refer to  self  to access instance attributes. It is normal to set instance attributes in  __init__  and read or change them in instance methods. That is also why you pass  self  als the first argument to  def Change . \n\n Another solution would be to create a static method like this: \n\n class PassByReference:\n    def __init__(self):\n        self.variable = 'Original'\n        self.variable = PassByReference.Change(self.variable)\n        print self.variable\n\n    @staticmethod\n    def Change(var):\n        var = 'Changed'\n        return var\n \n    ", "date_posted": "2016-08-09 02:23:27Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "3739391", "name": "John Smith", "reputation_score": "7,048"}, "answer_comments": []}, {"stack_answer_id": "38834546", "answer_content": "\r\n I used the following method to quickly convert a couple of Fortran codes to Python.  True, it's not pass by reference as the original question was posed, but is a simple work around in some cases. \n\n a=0\nb=0\nc=0\ndef myfunc(a,b,c):\n    a=1\n    b=2\n    c=3\n    return a,b,c\n\na,b,c = myfunc(a,b,c)\nprint a,b,c\n \n    ", "date_posted": "2016-08-09 02:22:25Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "3739391", "name": "John Smith", "reputation_score": "7,048"}, "answer_comments": [{"stack_answer_id": "38834546", "stack_answer_comment_id": "108869270", "comment_content": "Yes, this solves the 'pass by reference' in my use case as well. I have a function that basically cleans up values in a ", "user_id": "None"}, {"stack_answer_id": "38834546", "stack_answer_comment_id": "125476205", "comment_content": "@kasimir this is one of the things I really love about Python.  Because it's so easy to return multiple values as a tuple, it's very rare to even need to pass by reference.", "user_id": "None"}, {"stack_answer_id": "38834546", "stack_answer_comment_id": "125491812", "comment_content": "@MarkRansom me too! I did a lot of PHP programming and passing by reference is quite common there, but can be a pain when trying to debug. Python lets you avoid this, so yet another reason for me to love Python more :-)", "user_id": "None"}]}, {"stack_answer_id": "36775894", "answer_content": "\r\n There is a little trick to pass an object by reference, even though the language doesn't make it possible. It works in Java too, it's the list with one item. ;-) \n\n class PassByReference:\n    def __init__(self, name):\n        self.name = name\n\ndef changeRef(ref):\n    ref[0] = PassByReference('Michael')\n\nobj = PassByReference('Peter')\nprint obj.name\n\np = [obj] # A pointer to obj! ;-)\nchangeRef(p)\n\nprint p[0].name # p->name\n \n\n It's an ugly hack, but it works. ;-P \n    ", "date_posted": "2016-04-21 16:47:42Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "3021309", "name": "itmuckel", "reputation_score": "1,213"}, "answer_comments": [{"stack_answer_id": "36775894", "stack_answer_comment_id": "92715930", "comment_content": " is reference to a mutable list object which in turn stores the object ", "user_id": "None"}, {"stack_answer_id": "36775894", "stack_answer_comment_id": "92715951", "comment_content": "So now, the references ", "user_id": "None"}, {"stack_answer_id": "36775894", "stack_answer_comment_id": "92715979", "comment_content": "You have ", "user_id": "None"}, {"stack_answer_id": "36775894", "stack_answer_comment_id": "92716018", "comment_content": "Point being, I don't agree that it's a ", "user_id": "None"}]}, {"stack_answer_id": "40345432", "answer_content": "\r\n given the way python handles values and references to them, the only way you can reference an arbitrary instance attribute is by name: \n\n class PassByReferenceIsh:\n    def __init__(self):\n        self.variable = 'Original'\n        self.change('variable')\n        print self.variable\n\n    def change(self, var):\n        self.__dict__[var] = 'Changed'\n \n\n in real code you would, of course, add error checking on the dict lookup. \n    ", "date_posted": "2016-10-31 15:33:23Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "4761972", "name": "mARK bLOORE", "reputation_score": "158"}, "answer_comments": []}, {"stack_answer_id": "46136730", "answer_content": "\r\n Since your example happens to be object-oriented, you could make the following change to achieve a similar result: \n\n class PassByReference:\n    def __init__(self):\n        self.variable = 'Original'\n        self.change('variable')\n        print(self.variable)\n\n    def change(self, var):\n        setattr(self, var, 'Changed')\n\n# o.variable will equal 'Changed'\no = PassByReference()\nassert o.variable == 'Changed'\n \n    ", "date_posted": "2017-09-10 02:19:53Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "1639273", "name": "Jesse Hogan", "reputation_score": "2,917"}, "answer_comments": [{"stack_answer_id": "46136730", "stack_answer_comment_id": "85556278", "comment_content": "Although this works. It is not pass by reference. It is 'pass by object reference'.", "user_id": "None"}]}, {"stack_answer_id": "56069248", "answer_content": "\r\n Since it seems to be nowhere mentioned an approach to simulate references as known from e.g. C++ is to use an \"update\" function and pass that instead of the actual variable (or rather, \"name\"): \n\n def need_to_modify(update):\n    update(42) # set new value 42\n    # other code\n\ndef call_it():\n    value = 21\n    def update_value(new_value):\n        nonlocal value\n        value = new_value\n    need_to_modify(update_value)\n    print(value) # prints 42\n \n\n This is mostly useful for \"out-only references\" or in a situation with multiple threads / processes (by making the update function thread / multiprocessing safe). \n\n Obviously the above does not allow  reading  the value, only updating it. \n    ", "date_posted": "2019-05-10 00:37:33Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "1116364", "name": "Daniel Jour", "reputation_score": "15.6k"}, "answer_comments": []}, {"stack_answer_id": "55992875", "answer_content": "\r\n Since dictionaries are passed by reference, you can use a dict variable to store any referenced values inside it. \n # returns the result of adding numbers `a` and `b`\ndef AddNumbers(a, b, ref): # using a dict for reference\n    result = a + b\n    ref['multi'] = a * b # reference the multi. ref['multi'] is number\n    ref['msg'] = \"The result: \" + str(result) + \" was nice!\"\n    return result\n\nnumber1 = 5\nnumber2 = 10\nref = {} # init a dict like that so it can save all the referenced values. this is because all dictionaries are passed by reference, while strings and numbers do not.\n\nsum = AddNumbers(number1, number2, ref)\nprint(\"sum: \", sum)             # the returned value\nprint(\"multi: \", ref['multi'])  # a referenced value\nprint(\"msg: \", ref['msg'])      # a referenced value\n \n    ", "date_posted": "2021-06-01 08:29:19Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "2718972", "name": "Liakos", "reputation_score": "424"}, "answer_comments": []}, {"stack_answer_id": "39054982", "answer_content": "\r\n While pass by reference is nothing that fits well into python and should be rarely used there are some workarounds that actually can work to get the object currently assigned to a local variable or even reassign a local variable from inside of a called function. \n\n The basic idea is to have a function that can do that access and can be passed as object into other functions or stored in a class. \n\n One way is to use  global  (for global variables) or  nonlocal  (for local variables in a function) in a wrapper function. \n\n def change(wrapper):\n    wrapper(7)\n\nx = 5\ndef setter(val):\n    global x\n    x = val\nprint(x)\n \n\n The same idea works for reading and  del eting a variable. \n\n For just reading there is even a shorter way of just using  lambda: x  which returns a callable that when called returns the current value of x. This is somewhat like \"call by name\" used in languages in the distant past. \n\n Passing 3 wrappers to access a variable is a bit unwieldy so those can be wrapped into a class that has a proxy attribute: \n\n class ByRef:\n    def __init__(self, r, w, d):\n        self._read = r\n        self._write = w\n        self._delete = d\n    def set(self, val):\n        self._write(val)\n    def get(self):\n        return self._read()\n    def remove(self):\n        self._delete()\n    wrapped = property(get, set, remove)\n\n# left as an exercise for the reader: define set, get, remove as local functions using global / nonlocal\nr = ByRef(get, set, remove)\nr.wrapped = 15\n \n\n Pythons \"reflection\" support makes it possible to get a object that is capable of reassigning a name/variable in a given scope without defining functions explicitly in that scope: \n\n class ByRef:\n    def __init__(self, locs, name):\n        self._locs = locs\n        self._name = name\n    def set(self, val):\n        self._locs[self._name] = val\n    def get(self):\n        return self._locs[self._name]\n    def remove(self):\n        del self._locs[self._name]\n    wrapped = property(get, set, remove)\n\ndef change(x):\n    x.wrapped = 7\n\ndef test_me():\n    x = 6\n    print(x)\n    change(ByRef(locals(), \"x\"))\n    print(x)\n \n\n Here the  ByRef  class wraps a dictionary access. So attribute access to  wrapped  is translated to a item access in the passed dictionary. By passing the result of the builtin  locals  and the name of a local variable this ends up accessing a local variable. The python documentation as of 3.5 advises that changing the dictionary might not work but it seems to work for me. \n    ", "date_posted": "2016-08-20 14:02:37Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "4973666", "name": "textshell", "reputation_score": "1,436"}, "answer_comments": []}, {"stack_answer_id": "50157212", "answer_content": "\r\n You can merely use  an empty class  as an instance to store reference objects because internally object attributes are stored in an instance dictionary. See the example. \n\n class RefsObj(object):\n    \"A class which helps to create references to variables.\"\n    pass\n\n...\n\n# an example of usage\ndef change_ref_var(ref_obj):\n    ref_obj.val = 24\n\nref_obj = RefsObj()\nref_obj.val = 1\nprint(ref_obj.val) # or print ref_obj.val for python2\nchange_ref_var(ref_obj)\nprint(ref_obj.val)\n \n    ", "date_posted": "2018-05-03 14:14:11Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "749288", "name": "sergzach", "reputation_score": "6,311"}, "answer_comments": []}, {"stack_answer_id": "54315603", "answer_content": "\r\n Pass-By-Reference in Python is quite different from the concept of pass by reference in C++/Java.  \n\n \n Java&C#:  primitive types(include string)pass by value(copy), Reference type is passed by reference(address copy) so all changes made in the parameter in the called function are visible to the caller. \n C++:  Both pass-by-reference or pass-by-value are allowed. If a parameter is passed by reference, you can either modify it or not depending upon whether the parameter was passed as const or not. However, const or not, the parameter maintains the reference to the object and reference cannot be assigned to point to a different object within the called function. \n Python:  \nPython is \u201cpass-by-object-reference\u201d, of which it is often said: \u201cObject references are passed by value.\u201d[Read here] 1 . Both the caller and the function refer to the same object but the parameter in the function is a new variable which is just holding a copy of the object in the caller. Like C++, a parameter can be either modified or not in function - This depends upon the type of object passed. eg; An immutable object type cannot be modified in the called function whereas a mutable object can be either updated or re-initialized. A crucial difference between updating or re-assigning/re-initializing the mutable variable is that updated value gets reflected back in the called function whereas the reinitialized value does not. Scope of any assignment of new object to a mutable variable is local to the function in the python. Examples provided by @blair-conrad are great to understand this. \n \n    ", "date_posted": "2019-06-13 04:11:38Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "4877830", "name": "haidi ju", "reputation_score": "5"}, "answer_comments": [{"stack_answer_id": "54315603", "stack_answer_comment_id": "102208338", "comment_content": "Old but I feel obliged to correct it. Strings are passed by reference in both Java and C#, NOT by value", "user_id": "None"}, {"stack_answer_id": "54315603", "stack_answer_comment_id": "123598152", "comment_content": "No. Everything is passed by value in c#. It is that the value of variable that is an object in c# is exactly and heap ID/address of the object. So when you set something in a function to a new object you set the variable in function to address. Passing by reference means passing an adres to value which is an address to the value for struct types but address to pointer in case of objects.", "user_id": "None"}, {"stack_answer_id": "54315603", "stack_answer_comment_id": "125013192", "comment_content": "i Know you are expert when you said address copy (that why ref exist) which pass the reference it self not the copy in C#", "user_id": "None"}]}, {"stack_answer_id": "62970753", "answer_content": "\r\n I am new to Python, started yesterday (though I have been programming for 45 years). \n I came here because I was writing a function where I wanted to have two so called out-parameters. If it would have been only one out-parameter, I wouldn't get hung up right now on checking how reference/value works in Python. I would just have used the return value of the function instead. But since I needed  two  such out-parameters I felt I needed to sort it out. \n In this post I am going to show how I solved my situation. Perhaps others coming here can find it valuable, even though it is not exactly an answer to the topic question. Experienced Python programmers of course already know about the solution I used, but it was new to me. \n From the answers here I could quickly see that Python works a bit like Javascript in this regard, and that you need to use workarounds if you want the reference functionality. \n But then I found something neat in Python that I don't think I have seen in other languages before, namely that you can return more than one value from a function, in a simple comma separated way, like this: \n def somefunction(p):\n    a=p+1\n    b=p+2\n    c=-p\n    return a, b, c\n \n and that you can handle that on the calling side similarly, like this \n x, y, z = somefunction(w)\n \n That was good enough for me and I was satisfied. No need to use some workaround. \n In other languages you can of course also return many values, but then usually in the from of an object, and you need to adjust the calling side accordingly. \n The Python way of doing it was nice and simple. \n If you want to mimic  by reference  even more, you could do as follows: \n def somefunction(a, b, c):\n    a = a * 2\n    b = b + a\n    c = a * b * c\n    return a, b, c\n\nx = 3\ny = 5\nz = 10\nprint(F\"Before : {x}, {y}, {z}\")\n\nx, y, z = somefunction(x, y, z)\n\nprint(F\"After  : {x}, {y}, {z}\")\n \n which gives this result \n \nBefore : 3, 5, 10  \nAfter  : 6, 11, 660  \n \n    ", "date_posted": "2020-07-21 20:38:03Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "1765710", "name": "Magnus", "reputation_score": "1,398"}, "answer_comments": [{"stack_answer_id": "62970753", "stack_answer_comment_id": "112078719", "comment_content": "\"But then I found something neat in Python that I don't think I have seen in other languages before, namely that you can return more than one value from a function\" No, you can't. What you are doing is returning a single value, a ", "user_id": "None"}, {"stack_answer_id": "62970753", "stack_answer_comment_id": "112092512", "comment_content": "@juanpa.arrivillaga, yes, I was aware of that when I wrote my answer, I had just read about it. But I just described the whole thing in a practical way without going into the details of how it works and add unnecessary length to my answer. You can indeed return multiple values from a function, if it is done in an object or similar, like in a tuple (which in Python is taken care of in the neat way I showed). When I order things from a company, they can send me multiple things, even if it is all in one package.", "user_id": "None"}]}, {"stack_answer_id": "65935869", "answer_content": "\r\n alternatively you could use ctypes witch would look something like this \n import ctypes\n\ndef f(a):\n    a.value=2398 ## resign the value in a function\n\na = ctypes.c_int(0)\nprint(\"pre f\", a)\nf(a)\nprint(\"post f\", a)\n \n as a is a c int and not a python integer and apperently passed by reference. however you have to be carefull as strange things could happen and is therefor not advised \n    ", "date_posted": "2021-01-28 11:06:18Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "14826616", "name": "Julian wandhoven", "reputation_score": "260"}, "answer_comments": []}, {"stack_answer_id": "66819159", "answer_content": "\r\n Most likely not the most reliable method but this works, keep in mind that you are overloading the built-in str function which is typically something you don't want to do: \n import builtins\n\nclass sstr(str):\n    def __str__(self):\n        if hasattr(self, 'changed'):\n            return self.changed\n\n        return self\n\n    def change(self, value):\n        self.changed = value\n\nbuiltins.str = sstr\n\ndef change_the_value(val):\n    val.change('After')\n\nval = str('Before')\nprint (val)\nchange_the_value(val)\nprint (val)\n \n    ", "date_posted": "2021-03-26 14:49:25Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "5925257", "name": "Jop Knoppers", "reputation_score": "611"}, "answer_comments": []}, {"stack_answer_id": "68167731", "answer_content": "\r\n What about  dataclasses ? Also, it allows you to apply type restriction (aka \"type hint\"). \n from dataclasses import dataclass\n\n@dataclass\nclass Holder:\n    obj: your_type # Need any type? Use \"obj: object\" then.\n\ndef foo(ref: Holder):\n    ref.obj = do_something()\n \n I agree with folks that in most cases you'd better consider not to use it. \n And yet, when we're talking about  contexts  it's worth to know that way. \n You can design explicit context class though. When prototyping I prefer dataclasses, just because it's easy to serialize them back and forth. \n Cheers! \n    ", "date_posted": "2021-06-28 17:29:12Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "5160481", "name": "Stepan Dyatkovskiy", "reputation_score": "688"}, "answer_comments": []}], "user": {"stack_user_id": "259", "name": "David Sykes", "reputation_score": "46.6k"}, "question_comments": [{"stack_question_id": "986006", "stack_question_comment_id": "20442132", "comment_content": "For a short explanation/clarification see the first answer to ", "user_id": "None"}, {"stack_question_id": "986006", "stack_question_comment_id": "10928917", "comment_content": "The code in BlairConrad's answer is good, but the explanation provided by DavidCournapeau and DarenThomas is correct.", "user_id": "None"}, {"stack_question_id": "986006", "stack_question_comment_id": "18288970", "comment_content": "Before reading the selected answer, please consider reading this short text ", "user_id": "None"}, {"stack_question_id": "986006", "stack_question_comment_id": "42135694", "comment_content": "another workaround is to create a wrapper 'reference' like this: ref = type('', (), {'n':1}) ", "user_id": "None"}, {"stack_question_id": "986006", "stack_question_comment_id": "110167008", "comment_content": "New official how of Iqc's link: ", "user_id": "None"}]},
{"stack_question_id": "312443", "question_title": "How do I split a list into equally-sized chunks?", "question_content": "\r\n                How do I split a list of arbitrary length into equal sized chunks?\nRelated question: How to iterate over a list in chunks\r\n", "question_url": "/questions/312443/how-do-i-split-a-list-into-equally-sized-chunks", "date_posted": "Nov 23, 2008 at 12:15", "upvote": "2", "view": "1", "tags": ["python", "list", "split", "chunks"], "answers_count": "7", "answers": [{"stack_answer_id": "312464", "answer_content": "\r\n Here's a generator that yields evenly-sized chunks: \n def chunks(lst, n):\n    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n    for i in range(0, len(lst), n):\n        yield lst[i:i + n]\n \n import pprint\npprint.pprint(list(chunks(range(10, 75), 10)))\n[[10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n [70, 71, 72, 73, 74]]\n \n For Python 2, using  xrange  instead of  range : \n def chunks(lst, n):\n    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n    for i in xrange(0, len(lst), n):\n        yield lst[i:i + n]\n \n \n Below is a list comprehension one-liner. The method above is preferable, though, since using named functions makes code easier to understand. For Python 3: \n [lst[i:i + n] for i in range(0, len(lst), n)]\n \n For Python 2: \n [lst[i:i + n] for i in xrange(0, len(lst), n)]\n \n    ", "date_posted": "2022-06-04 21:22:56Z", "upvote": "\r\n            4153\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": []}, {"stack_answer_id": "1751478", "answer_content": "\r\n Something super simple: \n def chunks(xs, n):\n    n = max(1, n)\n    return (xs[i:i+n] for i in range(0, len(xs), n))\n \n For Python 2, use  xrange()  instead of  range() . \n    ", "date_posted": "2022-06-16 01:18:58Z", "upvote": "\r\n            642\r\n        ", "accepted": "No", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": [{"stack_answer_id": "1751478", "stack_answer_comment_id": "121518885", "comment_content": "Using short circuiting, ", "user_id": "None"}]}, {"stack_answer_id": "16935535", "answer_content": "\r\n I know this is kind of old but nobody yet mentioned  numpy.array_split : \n import numpy as np\n\nlst = range(50)\nnp.array_split(lst, 5)\n \n Result: \n [array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19]),\n array([20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n array([30, 31, 32, 33, 34, 35, 36, 37, 38, 39]),\n array([40, 41, 42, 43, 44, 45, 46, 47, 48, 49])]\n \n    ", "date_posted": "2022-04-01 01:59:49Z", "upvote": "\r\n            378\r\n        ", "accepted": "No", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": [{"stack_answer_id": "16935535", "stack_answer_comment_id": "52802258", "comment_content": "This allows you to set the total number of chunks, not the number of elements per chunk.", "user_id": "None"}, {"stack_answer_id": "16935535", "stack_answer_comment_id": "129310293", "comment_content": "This method change the type of the elements [ ['a', 1] , ['b', 2] ] with chunk one may become [ ['a', '1'] , ['b', '2'] ]. If type of first element is str then all element become numpy.str_  ...", "user_id": "None"}]}, {"stack_answer_id": "312644", "answer_content": "\r\n Directly from the (old) Python documentation (recipes for itertools): \n\n from itertools import izip, chain, repeat\n\ndef grouper(n, iterable, padvalue=None):\n    \"grouper(3, 'abcdefg', 'x') --> ('a','b','c'), ('d','e','f'), ('g','x','x')\"\n    return izip(*[chain(iterable, repeat(padvalue, n-1))]*n)\n \n\n The current version, as suggested by J.F.Sebastian: \n\n #from itertools import izip_longest as zip_longest # for Python 2.x\nfrom itertools import zip_longest # for Python 3.x\n#from six.moves import zip_longest # for both (uses the six compat library)\n\ndef grouper(n, iterable, padvalue=None):\n    \"grouper(3, 'abcdefg', 'x') --> ('a','b','c'), ('d','e','f'), ('g','x','x')\"\n    return zip_longest(*[iter(iterable)]*n, fillvalue=padvalue)\n \n\n I guess Guido's time machine works\u2014worked\u2014will work\u2014will have worked\u2014was working again. \n\n These solutions work because  [iter(iterable)]*n  (or the equivalent in the earlier version) creates  one  iterator, repeated  n  times in the list.  izip_longest  then effectively performs a round-robin of \"each\" iterator; because this is the same iterator, it is advanced by each such call, resulting in each such zip-roundrobin generating one tuple of  n  items. \n    ", "date_posted": "2017-09-21 09:47:29Z", "upvote": "\r\n            339\r\n        ", "accepted": "No", "user": {"stack_user_id": "6899", "name": "tzot", "reputation_score": "88.7k"}, "answer_comments": []}, {"stack_answer_id": "22045226", "answer_content": "\r\n I'm surprised nobody has thought of using  iter 's  two-argument form : \n\n from itertools import islice\n\ndef chunk(it, size):\n    it = iter(it)\n    return iter(lambda: tuple(islice(it, size)), ())\n \n\n Demo: \n\n >>> list(chunk(range(14), 3))\n[(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, 11), (12, 13)]\n \n\n This works with any iterable and produces output lazily. It returns tuples rather than iterators, but I think it has a certain elegance nonetheless. It also doesn't pad; if you want padding, a simple variation on the above will suffice: \n\n from itertools import islice, chain, repeat\n\ndef chunk_pad(it, size, padval=None):\n    it = chain(iter(it), repeat(padval))\n    return iter(lambda: tuple(islice(it, size)), (padval,) * size)\n \n\n Demo: \n\n >>> list(chunk_pad(range(14), 3))\n[(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, 11), (12, 13, None)]\n>>> list(chunk_pad(range(14), 3, 'a'))\n[(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, 11), (12, 13, 'a')]\n \n\n Like the  izip_longest -based solutions, the above  always  pads. As far as I know, there's no one- or two-line itertools recipe for a function that  optionally  pads. By combining the above two approaches, this one comes pretty close: \n\n _no_padding = object()\n\ndef chunk(it, size, padval=_no_padding):\n    if padval == _no_padding:\n        it = iter(it)\n        sentinel = ()\n    else:\n        it = chain(iter(it), repeat(padval))\n        sentinel = (padval,) * size\n    return iter(lambda: tuple(islice(it, size)), sentinel)\n \n\n Demo: \n\n >>> list(chunk(range(14), 3))\n[(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, 11), (12, 13)]\n>>> list(chunk(range(14), 3, None))\n[(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, 11), (12, 13, None)]\n>>> list(chunk(range(14), 3, 'a'))\n[(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, 11), (12, 13, 'a')]\n \n\n I believe this is the shortest chunker proposed that offers optional padding. \n\n As Tomasz Gandor  observed , the two padding chunkers will stop unexpectedly if they encounter a long sequence of pad values. Here's a final variation that works around that problem in a reasonable way: \n\n _no_padding = object()\ndef chunk(it, size, padval=_no_padding):\n    it = iter(it)\n    chunker = iter(lambda: tuple(islice(it, size)), ())\n    if padval == _no_padding:\n        yield from chunker\n    else:\n        for ch in chunker:\n            yield ch if len(ch) == size else ch + (padval,) * (size - len(ch))\n \n\n Demo: \n\n >>> list(chunk([1, 2, (), (), 5], 2))\n[(1, 2), ((), ()), (5,)]\n>>> list(chunk([1, 2, None, None, 5], 2, None))\n[(1, 2), (None, None), (5, None)]\n \n    ", "date_posted": "2018-11-17 01:16:27Z", "upvote": "\r\n            275\r\n        ", "accepted": "No", "user": {"stack_user_id": "577088", "name": "senderle", "reputation_score": "139k"}, "answer_comments": [{"stack_answer_id": "22045226", "stack_answer_comment_id": "124722445", "comment_content": "One-liner version:  ``` from itertools import islice from functools import partial  seq = [1,2,3,4,5,6,7] size = 3 result = list(iter(partial(lambda it: tuple(islice(it, size)), iter(seq)), ())) assert result == [(1, 2, 3), (4, 5, 6), (7,)] ```", "user_id": "None"}]}, {"stack_answer_id": "312467", "answer_content": "\r\n Here is a generator that work on arbitrary iterables: \n\n def split_seq(iterable, size):\n    it = iter(iterable)\n    item = list(itertools.islice(it, size))\n    while item:\n        yield item\n        item = list(itertools.islice(it, size))\n \n\n Example: \n\n >>> import pprint\n>>> pprint.pprint(list(split_seq(xrange(75), 10)))\n[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n [70, 71, 72, 73, 74]]\n \n    ", "date_posted": "2012-09-17 21:22:03Z", "upvote": "\r\n            118\r\n        ", "accepted": "No", "user": {"stack_user_id": "298479", "name": "ThiefMaster", "reputation_score": "301k"}, "answer_comments": []}, {"stack_answer_id": "3226719", "answer_content": "\r\n Simple yet elegant \n L = range(1, 1000)\nprint [L[x:x+10] for x in xrange(0, len(L), 10)]\n \n or if you prefer: \n def chunks(L, n): return [L[x: x+n] for x in xrange(0, len(L), n)]\nchunks(L, 10)\n \n    ", "date_posted": "2021-04-26 08:35:26Z", "upvote": "\r\n            80\r\n        ", "accepted": "No", "user": {"stack_user_id": "257299", "name": "kevinarpe", "reputation_score": "19.4k"}, "answer_comments": []}, {"stack_answer_id": "3125186", "answer_content": "\r\n def chunk(input, size):\n    return map(None, *([iter(input)] * size))\n \n    ", "date_posted": "2012-09-17 21:22:25Z", "upvote": "\r\n            63\r\n        ", "accepted": "No", "user": {"stack_user_id": "298479", "name": "ThiefMaster", "reputation_score": "301k"}, "answer_comments": [{"stack_answer_id": "3125186", "stack_answer_comment_id": "123652393", "comment_content": "Doesn't work in Python 3.8, is that for 2.x?", "user_id": "None"}, {"stack_answer_id": "3125186", "stack_answer_comment_id": "123652445", "comment_content": "For Python 3.x: ", "user_id": "None"}]}, {"stack_answer_id": "21767522", "answer_content": "\r\n How do you split a list into evenly sized chunks? \n \"Evenly sized chunks\", to me, implies that they are all the same length, or barring that option, at  minimal variance  in length. E.g. 5 baskets for 21 items could have the following results: \n >>> import statistics\n>>> statistics.variance([5,5,5,5,1]) \n3.2\n>>> statistics.variance([5,4,4,4,4]) \n0.19999999999999998\n \n A practical reason to prefer the latter result: if you were using these functions to distribute work, you've built-in the prospect of one likely finishing well before the others, so it would sit around doing nothing while the others continued working hard. \n Critique of other answers here \n When I originally wrote this answer, none of the other answers were evenly sized chunks - they all leave a runt chunk at the end, so they're not well balanced, and have a higher than necessary variance of lengths. \n For example, the current top answer ends with: \n [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n[70, 71, 72, 73, 74]]\n \n Others, like  list(grouper(3, range(7))) , and  chunk(range(7), 3)  both return:  [(0, 1, 2), (3, 4, 5), (6, None, None)] . The  None 's are just padding, and rather inelegant in my opinion. They are NOT evenly chunking the iterables. \n Why can't we divide these better? \n Cycle Solution \n A high-level balanced solution using  itertools.cycle , which is the way I might do it today. Here's the setup: \n from itertools import cycle\nitems = range(10, 75)\nnumber_of_baskets = 10\n \n Now we need our lists into which to populate the elements: \n baskets = [[] for _ in range(number_of_baskets)]\n \n Finally, we zip the elements we're going to allocate together with a cycle of the baskets until we run out of elements, which, semantically, it exactly what we want: \n for element, basket in zip(items, cycle(baskets)):\n    basket.append(element)\n \n Here's the result: \n >>> from pprint import pprint\n>>> pprint(baskets)\n[[10, 20, 30, 40, 50, 60, 70],\n [11, 21, 31, 41, 51, 61, 71],\n [12, 22, 32, 42, 52, 62, 72],\n [13, 23, 33, 43, 53, 63, 73],\n [14, 24, 34, 44, 54, 64, 74],\n [15, 25, 35, 45, 55, 65],\n [16, 26, 36, 46, 56, 66],\n [17, 27, 37, 47, 57, 67],\n [18, 28, 38, 48, 58, 68],\n [19, 29, 39, 49, 59, 69]]\n \n To productionize this solution, we write a function, and provide the type annotations: \n from itertools import cycle\nfrom typing import List, Any\n\ndef cycle_baskets(items: List[Any], maxbaskets: int) -> List[List[Any]]:\n    baskets = [[] for _ in range(min(maxbaskets, len(items)))]\n    for item, basket in zip(items, cycle(baskets)):\n        basket.append(item)\n    return baskets\n \n In the above, we take our list of items, and the max number of baskets. We create a list of empty lists, in which to append each element, in a round-robin style. \n Slices \n Another elegant solution is to use slices - specifically the less-commonly used  step  argument to slices. i.e.: \n start = 0\nstop = None\nstep = number_of_baskets\n\nfirst_basket = items[start:stop:step]\n \n This is especially elegant in that slices don't care how long the data are - the result, our first basket, is only as long as it needs to be. We'll only need to increment the starting point for each basket. \n In fact this could be a one-liner, but we'll go multiline for readability and to avoid an overlong line of code: \n from typing import List, Any\n\ndef slice_baskets(items: List[Any], maxbaskets: int) -> List[List[Any]]:\n    n_baskets = min(maxbaskets, len(items))\n    return [items[i::n_baskets] for i in range(n_baskets)]\n \n And  islice  from the itertools module will provide a lazily iterating approach, like that which was originally asked for in the question. \n I don't expect most use-cases to benefit very much, as the original data is already fully materialized in a list, but for large datasets, it could save nearly half the memory usage. \n from itertools import islice\nfrom typing import List, Any, Generator\n    \ndef yield_islice_baskets(items: List[Any], maxbaskets: int) -> Generator[List[Any], None, None]:\n    n_baskets = min(maxbaskets, len(items))\n    for i in range(n_baskets):\n        yield islice(items, i, None, n_baskets)\n \n View results with: \n from pprint import pprint\n\nitems = list(range(10, 75))\npprint(cycle_baskets(items, 10))\npprint(slice_baskets(items, 10))\npprint([list(s) for s in yield_islice_baskets(items, 10)])\n \n Updated prior solutions \n Here's another balanced solution, adapted from a function I've used in production in the past, that uses the modulo operator: \n def baskets_from(items, maxbaskets=25):\n    baskets = [[] for _ in range(maxbaskets)]\n    for i, item in enumerate(items):\n        baskets[i % maxbaskets].append(item)\n    return filter(None, baskets) \n \n And I created a generator that does the same if you put it into a list: \n def iter_baskets_from(items, maxbaskets=3):\n    '''generates evenly balanced baskets from indexable iterable'''\n    item_count = len(items)\n    baskets = min(item_count, maxbaskets)\n    for x_i in range(baskets):\n        yield [items[y_i] for y_i in range(x_i, item_count, baskets)]\n    \n \n And finally, since I see that all of the above functions return elements in a contiguous order (as they were given): \n def iter_baskets_contiguous(items, maxbaskets=3, item_count=None):\n    '''\n    generates balanced baskets from iterable, contiguous contents\n    provide item_count if providing a iterator that doesn't support len()\n    '''\n    item_count = item_count or len(items)\n    baskets = min(item_count, maxbaskets)\n    items = iter(items)\n    floor = item_count // baskets \n    ceiling = floor + 1\n    stepdown = item_count % baskets\n    for x_i in range(baskets):\n        length = ceiling if x_i < stepdown else floor\n        yield [items.next() for _ in range(length)]\n \n Output \n To test them out: \n print(baskets_from(range(6), 8))\nprint(list(iter_baskets_from(range(6), 8)))\nprint(list(iter_baskets_contiguous(range(6), 8)))\nprint(baskets_from(range(22), 8))\nprint(list(iter_baskets_from(range(22), 8)))\nprint(list(iter_baskets_contiguous(range(22), 8)))\nprint(baskets_from('ABCDEFG', 3))\nprint(list(iter_baskets_from('ABCDEFG', 3)))\nprint(list(iter_baskets_contiguous('ABCDEFG', 3)))\nprint(baskets_from(range(26), 5))\nprint(list(iter_baskets_from(range(26), 5)))\nprint(list(iter_baskets_contiguous(range(26), 5)))\n \n Which prints out: \n [[0], [1], [2], [3], [4], [5]]\n[[0], [1], [2], [3], [4], [5]]\n[[0], [1], [2], [3], [4], [5]]\n[[0, 8, 16], [1, 9, 17], [2, 10, 18], [3, 11, 19], [4, 12, 20], [5, 13, 21], [6, 14], [7, 15]]\n[[0, 8, 16], [1, 9, 17], [2, 10, 18], [3, 11, 19], [4, 12, 20], [5, 13, 21], [6, 14], [7, 15]]\n[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11], [12, 13, 14], [15, 16, 17], [18, 19], [20, 21]]\n[['A', 'D', 'G'], ['B', 'E'], ['C', 'F']]\n[['A', 'D', 'G'], ['B', 'E'], ['C', 'F']]\n[['A', 'B', 'C'], ['D', 'E'], ['F', 'G']]\n[[0, 5, 10, 15, 20, 25], [1, 6, 11, 16, 21], [2, 7, 12, 17, 22], [3, 8, 13, 18, 23], [4, 9, 14, 19, 24]]\n[[0, 5, 10, 15, 20, 25], [1, 6, 11, 16, 21], [2, 7, 12, 17, 22], [3, 8, 13, 18, 23], [4, 9, 14, 19, 24]]\n[[0, 1, 2, 3, 4, 5], [6, 7, 8, 9, 10], [11, 12, 13, 14, 15], [16, 17, 18, 19, 20], [21, 22, 23, 24, 25]]\n \n Notice that the contiguous generator provide chunks in the same length patterns as the other two, but the items are all in order, and they are as evenly divided as one may divide a list of discrete elements. \n    ", "date_posted": "2021-01-24 04:42:44Z", "upvote": "\r\n            58\r\n        ", "accepted": "No", "user": {"stack_user_id": "541136", "name": "Russia Must Remove Putin", "reputation_score": "347k"}, "answer_comments": [{"stack_answer_id": "21767522", "stack_answer_comment_id": "33423773", "comment_content": "You say that none of the above provides evenly-sized chunks. But ", "user_id": "None"}, {"stack_answer_id": "21767522", "stack_answer_comment_id": "33426910", "comment_content": "@senderle, The first one, ", "user_id": "None"}, {"stack_answer_id": "21767522", "stack_answer_comment_id": "39058786", "comment_content": "You raise the question (without doing it explicitly, so I do that now here) whether equally-sized chunks (except the last, if not possible) or whether a balanced (as good as possible) result is more often what will be needed.  You assume that the balanced solution is to prefer; this might be true if what you program is close to the real world (e. g. a card-dealing algorithm for a simulated card game).  In other cases (like filling lines with words) one will rather like to keep the lines as full as possible.  So I can't really prefer one over the other; they are just for different use cases.", "user_id": "None"}, {"stack_answer_id": "21767522", "stack_answer_comment_id": "40079600", "comment_content": "@ChristopherBarrington-Leigh Good point, for DataFrames, you should probably use slices, since I believe DataFrame objects do not usually copy on slicing, e.g. ", "user_id": "None"}, {"stack_answer_id": "21767522", "stack_answer_comment_id": "40080662", "comment_content": "@AaronHall Oops. I deleted my comment because I second-guessed my critique, but you were quick on the draw. Thanks! In fact, my claim that it doesn't work for dataframes is true.  If items is a dataframe, just use yield items[range(x_i, item_count, baskets)] as the last line. I offered a separate (yet another) answer, in which you specify the desired (minimum) group size.", "user_id": "None"}]}, {"stack_answer_id": "312466", "answer_content": "\r\n If you know list size: \n\n def SplitList(mylist, chunk_size):\n    return [mylist[offs:offs+chunk_size] for offs in range(0, len(mylist), chunk_size)]\n \n\n If you don't (an iterator): \n\n def IterChunks(sequence, chunk_size):\n    res = []\n    for item in sequence:\n        res.append(item)\n        if len(res) >= chunk_size:\n            yield res\n            res = []\n    if res:\n        yield res  # yield the last, incomplete, portion\n \n\n In the latter case, it can be rephrased in a more beautiful way if you can be sure that the sequence always contains a whole number of chunks of given size (i.e. there is no incomplete last chunk). \n    ", "date_posted": "2019-04-18 11:18:24Z", "upvote": "\r\n            54\r\n        ", "accepted": "No", "user": {"stack_user_id": "4288043", "name": "cardamom", "reputation_score": "6,164"}, "answer_comments": []}, {"stack_answer_id": "29009933", "answer_content": "\r\n I saw the most awesome Python-ish answer in a  duplicate  of this question: \n\n from itertools import zip_longest\n\na = range(1, 16)\ni = iter(a)\nr = list(zip_longest(i, i, i))\n>>> print(r)\n[(1, 2, 3), (4, 5, 6), (7, 8, 9), (10, 11, 12), (13, 14, 15)]\n \n\n You can create n-tuple for any n. If  a = range(1, 15) , then the result will be: \n\n [(1, 2, 3), (4, 5, 6), (7, 8, 9), (10, 11, 12), (13, 14, None)]\n \n\n If the list is divided evenly, then you can replace  zip_longest  with  zip , otherwise the triplet  (13, 14, None)  would be lost. Python 3 is used above. For Python 2, use  izip_longest . \n    ", "date_posted": "2017-06-21 13:36:41Z", "upvote": "\r\n            49\r\n        ", "accepted": "No", "user": {"stack_user_id": "1959808", "name": "0 _", "reputation_score": "9,502"}, "answer_comments": []}, {"stack_answer_id": "52022535", "answer_content": "\r\n Don't reinvent the wheel. \n Given \n import itertools as it\nimport collections as ct\n\nimport more_itertools as mit\n\n\niterable = range(11)\nn = 3\n \n Code \n more_itertools + \n list(mit.chunked(iterable, n))\n# [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10]]\n\nlist(mit.sliced(iterable, n))\n# [range(0, 3), range(3, 6), range(6, 9), range(9, 11)]\n\nlist(mit.grouper(n, iterable))\n# [(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, None)]\n\nlist(mit.windowed(iterable, len(iterable)//n, step=n))\n# [(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, None)]\n\nlist(mit.chunked_even(iterable, n))\n# [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10]]\n \n (or DIY, if you want) \n The Standard Library \n list(it.zip_longest(*[iter(iterable)] * n))\n# [(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, None)]\n \n\n d = {}\nfor i, x in enumerate(iterable):\n    d.setdefault(i//n, []).append(x)\n    \n\nlist(d.values())\n# [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10]]\n \n\n dd = ct.defaultdict(list)\nfor i, x in enumerate(iterable):\n    dd[i//n].append(x)\n    \n\nlist(dd.values())\n# [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10]]\n \n References \n \n more_itertools.chunked  ( related posted ) \n more_itertools.sliced \n more_itertools.grouper  ( related post ) \n more_itertools.windowed  (see also  stagger ,  zip_offset ) \n more_itertools.chunked_even \n zip_longest  ( related post ,  related post ) \n setdefault  (ordered results requires Python 3.6+) \n collections.defaultdict   (ordered results requires Python 3.6+) \n \n +  A third-party library that implements  itertools recipes  and more.  > pip install more_itertools   \n    ", "date_posted": "2021-09-08 00:57:12Z", "upvote": "\r\n            46\r\n        ", "accepted": "No", "user": {"stack_user_id": "4531270", "name": "pylang", "reputation_score": "35.7k"}, "answer_comments": []}, {"stack_answer_id": "34322647", "answer_content": "\r\n [AA[i:i+SS] for i in range(len(AA))[::SS]]\n \n Where AA is array, SS is chunk size. For example: \n >>> AA=range(10,21);SS=3\n>>> [AA[i:i+SS] for i in range(len(AA))[::SS]]\n[[10, 11, 12], [13, 14, 15], [16, 17, 18], [19, 20]]\n# or [range(10, 13), range(13, 16), range(16, 19), range(19, 21)] in py3\n \n To expand the ranges in py3 do \n (py3) >>> [list(AA[i:i+SS]) for i in range(len(AA))[::SS]]\n[[10, 11, 12], [13, 14, 15], [16, 17, 18], [19, 20]]\n \n    ", "date_posted": "2021-09-18 09:40:54Z", "upvote": "\r\n            39\r\n        ", "accepted": "No", "user": {"stack_user_id": "213307", "name": "Riaz Rizvi", "reputation_score": "9,251"}, "answer_comments": []}, {"stack_answer_id": "5711993", "answer_content": "\r\n If you had a chunk size of 3 for example, you could do: \n\n zip(*[iterable[i::3] for i in range(3)]) \n \n\n source:\n http://code.activestate.com/recipes/303060-group-a-list-into-sequential-n-tuples/ \n\n I would use this when my chunk size is fixed number I can type, e.g. '3', and would never change. \n    ", "date_posted": "2011-04-19 05:27:19Z", "upvote": "\r\n            26\r\n        ", "accepted": "No", "user": {"stack_user_id": "711085", "name": "ninjagecko", "reputation_score": "84.7k"}, "answer_comments": [{"stack_answer_id": "5711993", "stack_answer_comment_id": "14896419", "comment_content": "This doesn't work if len(iterable)%3 != 0.  The last (short) group of numbers won't be returned.", "user_id": "None"}, {"stack_answer_id": "5711993", "stack_answer_comment_id": "125031007", "comment_content": "@sherbang There is ", "user_id": "None"}]}, {"stack_answer_id": "20106816", "answer_content": "\r\n The  toolz  library has the  partition  function for this: \n\n from toolz.itertoolz.core import partition\n\nlist(partition(2, [1, 2, 3, 4]))\n[(1, 2), (3, 4)]\n \n    ", "date_posted": "2013-11-20 20:55:22Z", "upvote": "\r\n            25\r\n        ", "accepted": "No", "user": {"stack_user_id": "983191", "name": "zach", "reputation_score": "26.5k"}, "answer_comments": []}, {"stack_answer_id": "59266741", "answer_content": "\r\n With  Assignment Expressions  in Python 3.8 it becomes quite nice: \n\n import itertools\n\ndef batch(iterable, size):\n    it = iter(iterable)\n    while item := list(itertools.islice(it, size)):\n        yield item\n \n\n This works on an arbitrary iterable, not just a list. \n\n >>> import pprint\n>>> pprint.pprint(list(batch(range(75), 10)))\n[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n [70, 71, 72, 73, 74]]\n \n    ", "date_posted": "2019-12-10 11:59:57Z", "upvote": "\r\n            25\r\n        ", "accepted": "No", "user": {"stack_user_id": "5540279", "name": "nirvana-msu", "reputation_score": "3,607"}, "answer_comments": []}, {"stack_answer_id": "48135727", "answer_content": "\r\n I was curious about the performance of different approaches and here it is: \n\n Tested on Python 3.5.1 \n\n import time\nbatch_size = 7\narr_len = 298937\n\n#---------slice-------------\n\nprint(\"\\r\\nslice\")\nstart = time.time()\narr = [i for i in range(0, arr_len)]\nwhile True:\n    if not arr:\n        break\n\n    tmp = arr[0:batch_size]\n    arr = arr[batch_size:-1]\nprint(time.time() - start)\n\n#-----------index-----------\n\nprint(\"\\r\\nindex\")\narr = [i for i in range(0, arr_len)]\nstart = time.time()\nfor i in range(0, round(len(arr) / batch_size + 1)):\n    tmp = arr[batch_size * i : batch_size * (i + 1)]\nprint(time.time() - start)\n\n#----------batches 1------------\n\ndef batch(iterable, n=1):\n    l = len(iterable)\n    for ndx in range(0, l, n):\n        yield iterable[ndx:min(ndx + n, l)]\n\nprint(\"\\r\\nbatches 1\")\narr = [i for i in range(0, arr_len)]\nstart = time.time()\nfor x in batch(arr, batch_size):\n    tmp = x\nprint(time.time() - start)\n\n#----------batches 2------------\n\nfrom itertools import islice, chain\n\ndef batch(iterable, size):\n    sourceiter = iter(iterable)\n    while True:\n        batchiter = islice(sourceiter, size)\n        yield chain([next(batchiter)], batchiter)\n\n\nprint(\"\\r\\nbatches 2\")\narr = [i for i in range(0, arr_len)]\nstart = time.time()\nfor x in batch(arr, batch_size):\n    tmp = x\nprint(time.time() - start)\n\n#---------chunks-------------\ndef chunks(l, n):\n    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n    for i in range(0, len(l), n):\n        yield l[i:i + n]\nprint(\"\\r\\nchunks\")\narr = [i for i in range(0, arr_len)]\nstart = time.time()\nfor x in chunks(arr, batch_size):\n    tmp = x\nprint(time.time() - start)\n\n#-----------grouper-----------\n\nfrom itertools import zip_longest # for Python 3.x\n#from six.moves import zip_longest # for both (uses the six compat library)\n\ndef grouper(iterable, n, padvalue=None):\n    \"grouper(3, 'abcdefg', 'x') --> ('a','b','c'), ('d','e','f'), ('g','x','x')\"\n    return zip_longest(*[iter(iterable)]*n, fillvalue=padvalue)\n\narr = [i for i in range(0, arr_len)]\nprint(\"\\r\\ngrouper\")\nstart = time.time()\nfor x in grouper(arr, batch_size):\n    tmp = x\nprint(time.time() - start)\n \n\n Results: \n\n slice\n31.18285083770752\n\nindex\n0.02184295654296875\n\nbatches 1\n0.03503894805908203\n\nbatches 2\n0.22681021690368652\n\nchunks\n0.019841909408569336\n\ngrouper\n0.006506919860839844\n \n    ", "date_posted": "2018-01-07 08:58:54Z", "upvote": "\r\n            21\r\n        ", "accepted": "No", "user": {"stack_user_id": "3766751", "name": "Alex T", "reputation_score": "3,843"}, "answer_comments": []}, {"stack_answer_id": "19264525", "answer_content": "\r\n I like the Python doc's version proposed by tzot and J.F.Sebastian a lot,\n but it has two shortcomings: \n\n \n it is not very explicit \n I usually don't want a fill value in the last chunk \n \n\n I'm using this one a lot in my code: \n\n from itertools import islice\n\ndef chunks(n, iterable):\n    iterable = iter(iterable)\n    while True:\n        yield tuple(islice(iterable, n)) or iterable.next()\n \n\n UPDATE: A lazy chunks version: \n\n from itertools import chain, islice\n\ndef chunks(n, iterable):\n   iterable = iter(iterable)\n   while True:\n       yield chain([next(iterable)], islice(iterable, n-1))\n \n    ", "date_posted": "2013-11-09 08:21:23Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "1464540", "name": "nikipore", "reputation_score": "229"}, "answer_comments": []}, {"stack_answer_id": "41904532", "answer_content": "\r\n You may also use  get_chunks  function of  utilspie  library as: \n\n >>> from utilspie import iterutils\n>>> a = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n>>> list(iterutils.get_chunks(a, 5))\n[[1, 2, 3, 4, 5], [6, 7, 8, 9]]\n \n\n You can install  utilspie  via pip: \n\n sudo pip install utilspie\n \n\n Disclaimer: I am the creator of  utilspie  library . \n    ", "date_posted": "2017-01-27 23:12:07Z", "upvote": "\r\n            18\r\n        ", "accepted": "No", "user": {"stack_user_id": "2063361", "name": "Moinuddin Quadri", "reputation_score": "44.4k"}, "answer_comments": []}, {"stack_answer_id": "31178232", "answer_content": "\r\n code: \n\n def split_list(the_list, chunk_size):\n    result_list = []\n    while the_list:\n        result_list.append(the_list[:chunk_size])\n        the_list = the_list[chunk_size:]\n    return result_list\n\na_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\nprint split_list(a_list, 3)\n \n\n result: \n\n [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10]]\n \n    ", "date_posted": "2016-08-31 17:30:54Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "4865723", "name": "buhtz", "reputation_score": "8,631"}, "answer_comments": []}, {"stack_answer_id": "33510840", "answer_content": "\r\n At this point, I think we need a  recursive generator , just in case... \n\n In python 2: \n\n def chunks(li, n):\n    if li == []:\n        return\n    yield li[:n]\n    for e in chunks(li[n:], n):\n        yield e\n \n\n In python 3: \n\n def chunks(li, n):\n    if li == []:\n        return\n    yield li[:n]\n    yield from chunks(li[n:], n)\n \n\n Also, in case of massive Alien invasion, a  decorated recursive generator  might become handy: \n\n def dec(gen):\n    def new_gen(li, n):\n        for e in gen(li, n):\n            if e == []:\n                return\n            yield e\n    return new_gen\n\n@dec\ndef chunks(li, n):\n    yield li[:n]\n    for e in chunks(li[n:], n):\n        yield e\n \n    ", "date_posted": "2015-11-03 23:42:58Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "1565438", "name": "mazieres", "reputation_score": "1,927"}, "answer_comments": []}, {"stack_answer_id": "312472", "answer_content": "\r\n heh, one line version \n\n In [48]: chunk = lambda ulist, step:  map(lambda i: ulist[i:i+step],  xrange(0, len(ulist), step))\n\nIn [49]: chunk(range(1,100), 10)\nOut[49]: \n[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n [11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n [21, 22, 23, 24, 25, 26, 27, 28, 29, 30],\n [31, 32, 33, 34, 35, 36, 37, 38, 39, 40],\n [41, 42, 43, 44, 45, 46, 47, 48, 49, 50],\n [51, 52, 53, 54, 55, 56, 57, 58, 59, 60],\n [61, 62, 63, 64, 65, 66, 67, 68, 69, 70],\n [71, 72, 73, 74, 75, 76, 77, 78, 79, 80],\n [81, 82, 83, 84, 85, 86, 87, 88, 89, 90],\n [91, 92, 93, 94, 95, 96, 97, 98, 99]]\n \n    ", "date_posted": "2008-11-23 12:51:16Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "2201031", "name": "slav0nic", "reputation_score": "3,399"}, "answer_comments": [{"stack_answer_id": "312472", "stack_answer_comment_id": "155125", "comment_content": "Please, use \"def chunk\" instead of \"chunk = lambda\".  It works the same.  One line.  Same features.  MUCH easier to the n00bz to read and understand.", "user_id": "None"}, {"stack_answer_id": "312472", "stack_answer_comment_id": "14734130", "comment_content": "The function object resulting from ", "user_id": "None"}]}, {"stack_answer_id": "314771", "answer_content": "\r\n def split_seq(seq, num_pieces):\n    start = 0\n    for i in xrange(num_pieces):\n        stop = start + len(seq[i::num_pieces])\n        yield seq[start:stop]\n        start = stop\n \n\n usage: \n\n seq = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\nfor seq in split_seq(seq, 3):\n    print seq\n \n    ", "date_posted": "2008-11-24 16:56:57Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "16148", "name": "Corey Goldberg", "reputation_score": "56.9k"}, "answer_comments": []}, {"stack_answer_id": "28786255", "answer_content": "\r\n Another more explicit version. \n\n def chunkList(initialList, chunkSize):\n    \"\"\"\n    This function chunks a list into sub lists \n    that have a length equals to chunkSize.\n\n    Example:\n    lst = [3, 4, 9, 7, 1, 1, 2, 3]\n    print(chunkList(lst, 3)) \n    returns\n    [[3, 4, 9], [7, 1, 1], [2, 3]]\n    \"\"\"\n    finalList = []\n    for i in range(0, len(initialList), chunkSize):\n        finalList.append(initialList[i:i+chunkSize])\n    return finalList\n \n    ", "date_posted": "2015-02-28 20:05:03Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "3202915", "name": "Ranaivo", "reputation_score": "1,548"}, "answer_comments": []}, {"stack_answer_id": "2270932", "answer_content": "\r\n Without calling len() which is good for large lists: \n\n def splitter(l, n):\n    i = 0\n    chunk = l[:n]\n    while chunk:\n        yield chunk\n        i += n\n        chunk = l[i:i+n]\n \n\n And this is for iterables: \n\n def isplitter(l, n):\n    l = iter(l)\n    chunk = list(islice(l, n))\n    while chunk:\n        yield chunk\n        chunk = list(islice(l, n))\n \n\n The functional flavour of the above: \n\n def isplitter2(l, n):\n    return takewhile(bool,\n                     (tuple(islice(start, n))\n                            for start in repeat(iter(l))))\n \n\n OR: \n\n def chunks_gen_sentinel(n, seq):\n    continuous_slices = imap(islice, repeat(iter(seq)), repeat(0), repeat(n))\n    return iter(imap(tuple, continuous_slices).next,())\n \n\n OR: \n\n def chunks_gen_filter(n, seq):\n    continuous_slices = imap(islice, repeat(iter(seq)), repeat(0), repeat(n))\n    return takewhile(bool,imap(tuple, continuous_slices))\n \n    ", "date_posted": "2016-05-16 06:29:12Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "1454536", "name": "parity3", "reputation_score": "613"}, "answer_comments": [{"stack_answer_id": "2270932", "stack_answer_comment_id": "7179177", "comment_content": "There is no reason to avoid ", "user_id": "None"}]}, {"stack_answer_id": "14937534", "answer_content": "\r\n See  this reference \n\n >>> orange = range(1, 1001)\n>>> otuples = list( zip(*[iter(orange)]*10))\n>>> print(otuples)\n[(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), ... (991, 992, 993, 994, 995, 996, 997, 998, 999, 1000)]\n>>> olist = [list(i) for i in otuples]\n>>> print(olist)\n[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], ..., [991, 992, 993, 994, 995, 996, 997, 998, 999, 1000]]\n>>> \n \n\n Python3 \n    ", "date_posted": "2014-11-14 09:48:42Z", "upvote": "\r\n            10\r\n        ", "accepted": "No", "user": {"stack_user_id": "3999697", "name": "BomberMan", "reputation_score": "1,110"}, "answer_comments": [{"stack_answer_id": "14937534", "stack_answer_comment_id": "26750302", "comment_content": "Nice, but drops elements at the end if the size does not match whole numbers of chunks, e. g. ", "user_id": "None"}]}, {"stack_answer_id": "9255750", "answer_content": "\r\n def chunks(iterable,n):\n    \"\"\"assumes n is an integer>0\n    \"\"\"\n    iterable=iter(iterable)\n    while True:\n        result=[]\n        for i in range(n):\n            try:\n                a=next(iterable)\n            except StopIteration:\n                break\n            else:\n                result.append(a)\n        if result:\n            yield result\n        else:\n            break\n\ng1=(i*i for i in range(10))\ng2=chunks(g1,3)\nprint g2\n'<generator object chunks at 0x0337B9B8>'\nprint list(g2)\n'[[0, 1, 4], [9, 16, 25], [36, 49, 64], [81]]'\n \n    ", "date_posted": "2012-02-13 04:50:38Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "632088", "name": "Rusty Rob", "reputation_score": "15.6k"}, "answer_comments": []}, {"stack_answer_id": "40409475", "answer_content": "\r\n Since everybody here talking about iterators.  boltons  has perfect method for that, called  iterutils.chunked_iter . \n\n from boltons import iterutils\n\nlist(iterutils.chunked_iter(list(range(50)), 11))\n \n\n Output: \n\n [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21],\n [22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32],\n [33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43],\n [44, 45, 46, 47, 48, 49]]\n \n\n But if you don't want to be mercy on memory, you can use old-way and store the full  list  in the first place with  iterutils.chunked . \n    ", "date_posted": "2016-11-03 19:10:45Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "3124746", "name": "vishes_shell", "reputation_score": "20.7k"}, "answer_comments": []}, {"stack_answer_id": "5872632", "answer_content": "\r\n Consider using  matplotlib.cbook  pieces \n\n for example: \n\n import matplotlib.cbook as cbook\nsegments = cbook.pieces(np.arange(20), 3)\nfor s in segments:\n     print s\n \n    ", "date_posted": "2012-03-08 18:27:15Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "1257603", "name": "schwartrer", "reputation_score": "11"}, "answer_comments": [{"stack_answer_id": "5872632", "stack_answer_comment_id": "98934697", "comment_content": "Looks like you accidentally created two accounts. You can ", "user_id": "None"}]}, {"stack_answer_id": "31442939", "answer_content": "\r\n a = [1, 2, 3, 4, 5, 6, 7, 8, 9]\nCHUNK = 4\n[a[i*CHUNK:(i+1)*CHUNK] for i in xrange((len(a) + CHUNK - 1) / CHUNK )]\n \n    ", "date_posted": "2015-07-15 23:27:19Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "105748", "name": "AdvilUser", "reputation_score": "2,872"}, "answer_comments": [{"stack_answer_id": "31442939", "stack_answer_comment_id": "50855622", "comment_content": "Can you explain more your answer please ?", "user_id": "None"}, {"stack_answer_id": "31442939", "stack_answer_comment_id": "51320329", "comment_content": "Working from backwards:      (len(a) + CHUNK -1) / CHUNK  Gives you the number of chunks that you will end up with.  Then, for each chunk at index i, we are generating a sub-array of the original array like this:      a[ i * CHUNK : (i + 1) * CHUNK ]  where,      i * CHUNK is the index of the first element to put into the subarray, and,     (i + 1) * CHUNK is 1 past the last element to put into the subarray.  This solution uses list comprehension, so it might be faster for large arrays.", "user_id": "None"}]}], "user": {"stack_user_id": "112415", "name": "jespern", "reputation_score": "30.7k"}, "question_comments": [{"stack_question_id": "312443", "stack_question_comment_id": "106181784", "comment_content": "Before you post a new answer, consider there are already 60+ answers for this question. Please, make sure that your answer contributes information that is not among existing answers.", "user_id": "None"}, {"stack_question_id": "312443", "stack_question_comment_id": "124637801", "comment_content": "The string equivalent of this question: ", "user_id": "None"}]}
][
{"stack_question_id": "20109391", "question_title": "How to make good reproducible pandas examples", "question_content": "\r\n                Having spent a decent amount of time watching both the r and pandas tags on SO, the impression that I get is that pandas questions are less likely to contain reproducible data. This is something that ...\r\n", "question_url": "/questions/20109391/how-to-make-good-reproducible-pandas-examples", "date_posted": "Nov 20, 2013 at 23:31", "upvote": "2", "view": "4", "tags": ["python", "pandas"], "answers_count": "5", "answers": [{"stack_answer_id": "20159305", "answer_content": "\r\n Note: The ideas here are pretty generic for Stack Overflow, indeed  questions . \n Disclaimer: Writing a good question is  hard . \n The Good: \n \n do include small* example DataFrame, either as runnable code: \n In [1]: df = pd.DataFrame([[1, 2], [1, 3], [4, 6]], columns=['A', 'B'])\n \n or make it \"copy and pasteable\" using  pd.read_clipboard(sep='\\s\\s+') , you can format the text for Stack Overflow highlight and use  Ctrl + K  (or prepend four spaces to each line), or place three backticks (```) above and below your code with your code unindented: \n In [2]: df\nOut[2]:\n   A  B\n0  1  2\n1  1  3\n2  4  6\n \n test  pd.read_clipboard(sep='\\s\\s+')  yourself. \n *  I really do mean  small . The vast majority of example DataFrames could be fewer than 6 rows  [citation needed] , and  I bet I can do it in 5 rows.  Can you reproduce the error with  df = df.head() ? If not, fiddle around to see if you can make up a small DataFrame which exhibits the issue you are facing. \n *  Every rule has an exception, the obvious one is for performance issues  ( in which case definitely use %timeit and possibly %prun ), where you should generate:  df = pd.DataFrame(np.random.randn(100000000, 10)) . Consider using  np.random.seed  so we have the exact same frame. Saying that, \"make this code fast for me\" is not strictly on topic for the site. \n \n write out the outcome you desire (similarly to above) \n In [3]: iwantthis\nOut[3]:\n   A  B\n0  1  5\n1  4  6\n \n Explain what the numbers come from: the 5 is sum of the B column for the rows where A is 1. \n \n do show  the code  you've tried: \n In [4]: df.groupby('A').sum()\nOut[4]:\n   B\nA\n1  5\n4  6\n \n But say what's incorrect: the A column is in the index rather than a column. \n \n do show you've done some research ( search the documentation ,  search Stack\u00a0Overflow ), and give a summary: \n \n The docstring for sum simply states \"Compute sum of group values\" \n \n \n The  groupby documentation  doesn't give any examples for this. \n \n Aside: the answer here is to use  df.groupby('A', as_index=False).sum() . \n \n if it's relevant that you have Timestamp columns, e.g. you're resampling or something, then be explicit and apply  pd.to_datetime  to them for good measure**. \n df['date'] = pd.to_datetime(df['date']) # this column ought to be date..\n \n **  Sometimes this is the issue itself: they were strings. \n \n \n The Bad: \n \n don't include a MultiIndex, which  we can't copy and paste  (see above). This is kind of a grievance with Pandas' default display, but nonetheless annoying: \n In [11]: df\nOut[11]:\n     C\nA B\n1 2  3\n  2  6\n \n The correct way is to include an ordinary DataFrame with a  set_index  call: \n In [12]: df = pd.DataFrame([[1, 2, 3], [1, 2, 6]], columns=['A', 'B', 'C']).set_index(['A', 'B'])\n\nIn [13]: df\nOut[13]:\n     C\nA B\n1 2  3\n  2  6\n \n \n do provide insight to what it is when giving the outcome you want: \n    B\nA\n1  1\n5  0\n \n Be specific about how you got the numbers (what are they)... double check they're correct. \n \n If your code throws an error, do include the entire stack trace (this can be edited out later if it's too noisy). Show the line number (and the corresponding line of your code which it's raising against). \n \n \n The Ugly: \n \n don't link to a  CSV  file we don't have access to (ideally don't link to an external source at all...) \n df = pd.read_csv('my_secret_file.csv')  # ideally with lots of parsing options\n \n Most data is proprietary  we get that: Make up similar data and see if you can reproduce the problem (something small). \n \n don't explain the situation vaguely in words, like you have a DataFrame which is \"large\", mention some of the column names in passing (be sure not to mention their dtypes). Try and go into lots of detail about something which is completely meaningless without seeing the actual context. Presumably no one is even going to read to the end of this paragraph. \n Essays are bad, it's easier with small examples. \n \n don't include 10+ (100+??) lines of data munging before getting to your actual question. \n Please, we see enough of this in our day jobs. We want to help, but  not like this... . \n Cut the intro, and just show the relevant DataFrames (or small versions of them) in the step which is causing you trouble. \n \n \n Anyway, have fun learning Python, NumPy and Pandas! \n    ", "date_posted": "2022-04-03 17:29:39Z", "upvote": "\r\n            451\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "4518341", "name": "wjandrea", "reputation_score": "24.1k"}, "answer_comments": [{"stack_answer_id": "20159305", "stack_answer_comment_id": "60808128", "comment_content": "+1 for the ", "user_id": null}, {"stack_answer_id": "20159305", "stack_answer_comment_id": "69339225", "comment_content": "the ", "user_id": null}, {"stack_answer_id": "20159305", "stack_answer_comment_id": "94715719", "comment_content": "Why ", "user_id": null}, {"stack_answer_id": "20159305", "stack_answer_comment_id": "94739875", "comment_content": "@MarianD the reason that \\s\\s+ is so popular is that there is often one e.g. in a column name, but multiple is rarer, and pandas output nicely puts in at least two between columns. Since this is just for toy/small datasets it's pretty powerful/majority of cases. Note: tabs separated would be a different story, though stackoverflow replaces tabs with spaces, but if you have a tsv then just use \\t.", "user_id": null}, {"stack_answer_id": "20159305", "stack_answer_comment_id": "99634737", "comment_content": "Ugh, i always use ", "user_id": null}]}, {"stack_answer_id": "30424537", "answer_content": "\r\n How to create sample datasets \n This is to mainly to expand on  AndyHayden's answer  by providing examples of how you can create sample dataframes.  Pandas and (especially) NumPy give you a variety of tools for this such that you can generally create a reasonable facsimile of any real dataset with just a few lines of code. \n After importing NumPy and Pandas, be sure to provide a random seed if you want folks to be able to exactly reproduce your data and results. \n import numpy as np\nimport pandas as pd\n\nnp.random.seed(123)\n \n A kitchen sink example \n Here's an example showing a variety of things you can do.  All kinds of useful sample dataframes could be created from a subset of this: \n df = pd.DataFrame({\n\n    # some ways to create random data\n    'a':np.random.randn(6),\n    'b':np.random.choice( [5,7,np.nan], 6),\n    'c':np.random.choice( ['panda','python','shark'], 6),\n\n    # some ways to create systematic groups for indexing or groupby\n    # this is similar to R's expand.grid(), see note 2 below\n    'd':np.repeat( range(3), 2 ),\n    'e':np.tile(   range(2), 3 ),\n\n    # a date range and set of random dates\n    'f':pd.date_range('1/1/2011', periods=6, freq='D'),\n    'g':np.random.choice( pd.date_range('1/1/2011', periods=365,\n                          freq='D'), 6, replace=False)\n    })\n \n This produces: \n           a   b       c  d  e          f          g\n0 -1.085631 NaN   panda  0  0 2011-01-01 2011-08-12\n1  0.997345   7   shark  0  1 2011-01-02 2011-11-10\n2  0.282978   5   panda  1  0 2011-01-03 2011-10-30\n3 -1.506295   7  python  1  1 2011-01-04 2011-09-07\n4 -0.578600 NaN   shark  2  0 2011-01-05 2011-02-27\n5  1.651437   7  python  2  1 2011-01-06 2011-02-03\n \n Some notes: \n \n np.repeat  and  np.tile  (columns  d  and  e ) are very useful for creating groups and indices in a very regular way.  For 2 columns, this can be used to easily duplicate r's  expand.grid()  but is also more flexible in ability to provide a subset of all permutations.  However, for 3 or more columns the syntax quickly becomes unwieldy. \n For a more direct replacement for R's  expand.grid()  see the  itertools  solution in the  pandas cookbook  or the  np.meshgrid  solution shown  here .  Those will allow any number of dimensions. \n You can do quite a bit with  np.random.choice .  For example, in column  g , we have a random selection of six dates from 2011.  Additionally, by setting  replace=False  we can assure these dates are unique -- very handy if we want to use this as an index with unique values. \n \n Fake stock market data \n In addition to taking subsets of the above code, you can further combine the techniques to do just about anything.  For example, here's a short example that combines  np.tile  and  date_range  to create sample ticker data for 4 stocks covering the same dates: \n stocks = pd.DataFrame({\n    'ticker':np.repeat( ['aapl','goog','yhoo','msft'], 25 ),\n    'date':np.tile( pd.date_range('1/1/2011', periods=25, freq='D'), 4 ),\n    'price':(np.random.randn(100).cumsum() + 10) })\n \n Now we have a sample dataset with 100 lines (25 dates per ticker), but we have only used 4 lines to do it, making it easy for everyone else to reproduce without copying and pasting 100 lines of code.  You can then display subsets of the data if it helps to explain your question: \n >>> stocks.head(5)\n\n        date      price ticker\n0 2011-01-01   9.497412   aapl\n1 2011-01-02  10.261908   aapl\n2 2011-01-03   9.438538   aapl\n3 2011-01-04   9.515958   aapl\n4 2011-01-05   7.554070   aapl\n\n>>> stocks.groupby('ticker').head(2)\n\n         date      price ticker\n0  2011-01-01   9.497412   aapl\n1  2011-01-02  10.261908   aapl\n25 2011-01-01   8.277772   goog\n26 2011-01-02   7.714916   goog\n50 2011-01-01   5.613023   yhoo\n51 2011-01-02   6.397686   yhoo\n75 2011-01-01  11.736584   msft\n76 2011-01-02  11.944519   msft\n \n    ", "date_posted": "2021-07-24 21:01:22Z", "upvote": "\r\n            84\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "30424537", "stack_answer_comment_id": "48943556", "comment_content": "Great answer. After writing this question I actually did write a very short, simple implementation of ", "user_id": "/users/1222578/marius"}, {"stack_answer_id": "30424537", "stack_answer_comment_id": "114458561", "comment_content": "This is a really useful example and I'll be using it as a base for examples. Many thanks!", "user_id": null}]}, {"stack_answer_id": "38466059", "answer_content": "\r\n Diary of an Answerer \n\n My best advice for asking questions would be to play on the psychology of the people who answer questions.  Being one of those people, I can give insight into why I answer certain questions and why I don't answer others. \n\n Motivations \n\n I'm motivated to answer questions for several reasons \n\n \n Stackoverflow.com has been a tremendously valuable resource to me.  I wanted to give back. \n In my efforts to give back, I've found this site to be an even more powerful resource than before.  Answering questions is a learning experience for me and I like to learn.   Read this answer and comment from another vet .  This kind of interaction makes me happy. \n I like points! \n See #3. \n I like interesting problems. \n \n\n All my purest intentions are great and all, but I get that satisfaction if I answer 1 question or 30.   What drives my choices  for which questions to answer has a huge component of point maximization. \n\n I'll also spend time on interesting problems but that is few and far between and doesn't help an asker who needs a solution to a non-interesting question.  Your best bet to get me to answer a question is to serve that question up on a platter ripe for me to answer it with as little effort as possible.  If I'm looking at two questions and one has code I can copy paste to create all the variables I need... I'm taking that one!  I'll come back to the other one if I have time, maybe. \n\n Main Advice \n\n Make it easy for the people answering questions. \n\n \n Provide code that creates variables that are needed. \n Minimize that code.  If my eyes glaze over as I look at the post, I'm on to the next question or getting back to whatever else I'm doing. \n Think about what you're asking and be specific.  We want to see what you've done because natural languages (English) are inexact and confusing.  Code samples of what you've tried help resolve inconsistencies in a natural language description. \n PLEASE show what you expect!!!  I have to sit down and try things.  I almost never know the answer to a question without trying some things out.  If I don't see an example of what you're looking for, I might pass on the question because I don't feel like guessing. \n \n\n Your reputation is more than just your reputation. \n\n I like points (I mentioned that above).  But those points aren't really really my reputation.  My real reputation is an amalgamation of what others on the site think of me.  I strive to be fair and honest and I hope others can see that.  What that means for an asker is, we remember the behaviors of askers.  If you don't select answers and upvote good answers, I remember.  If you behave in ways I don't like or in ways I do like, I remember.  This also plays into which questions I'll answer. \n\n \n\n Anyway, I can probably go on, but I'll spare all of you who actually read this. \n    ", "date_posted": "2018-01-01 09:39:28Z", "upvote": "\r\n            59\r\n        ", "accepted": "No", "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "answer_comments": []}, {"stack_answer_id": "32536193", "answer_content": "\r\n The Challenge  One of the most challenging aspects of responding to SO questions is the time it takes to recreate the problem (including the data).  Questions which don't have a clear way to reproduce the data are less likely to be answered.  Given that you are taking the time to write a question and you have an issue that you'd like help with, you can easily help yourself by providing data that others can then use to help solve your problem. \n The instructions provided by @Andy for writing good Pandas questions are an excellent place to start.  For more information, refer to  how to ask  and how to create  Minimal, Complete, and Verifiable examples . \n Please clearly state your question upfront.   After taking the time to write your question and any sample code, try to read it and provide an 'Executive Summary' for your reader which summarizes the problem and clearly states the question. \n Original question : \n \n I have this data... \n I want to do this... \n I want my result to look like this... \n However, when I try to do [this], I get the following problem... \n I've tried to find solutions by doing [this] and [that]. \n How do I fix it? \n \n Depending on the amount of data, sample code and error stacks provided, the reader needs to go a long way before understanding what the problem is.  Try restating your question so that the question itself is on top, and then provide the necessary details. \n Revised Question : \n \n Qustion:   How can I do [this]? \n I've tried to find solutions by doing [this] and [that]. \n When I've tried to do [this], I get the following problem... \n I'd like my final results to look like this... \n Here is some minimal code that can reproduce my problem... \n And here is how to recreate my sample data:\n df = pd.DataFrame({'A': [...], 'B': [...], ...}) \n \n PROVIDE SAMPLE DATA IF NEEDED!!! \n Sometimes just the head or tail of the DataFrame is all that is needed.  You can also use the methods proposed by @JohnE to create larger datasets that can be reproduced by others.  Using his example to generate a 100 row DataFrame of stock prices: \n stocks = pd.DataFrame({ \n    'ticker':np.repeat( ['aapl','goog','yhoo','msft'], 25 ),\n    'date':np.tile( pd.date_range('1/1/2011', periods=25, freq='D'), 4 ),\n    'price':(np.random.randn(100).cumsum() + 10) })\n \n If this was your actual data, you may just want to include the head and/or tail of the dataframe as follows (be sure to anonymize any sensitive data): \n >>> stocks.head(5).to_dict()\n{'date': {0: Timestamp('2011-01-01 00:00:00'),\n  1: Timestamp('2011-01-01 00:00:00'),\n  2: Timestamp('2011-01-01 00:00:00'),\n  3: Timestamp('2011-01-01 00:00:00'),\n  4: Timestamp('2011-01-02 00:00:00')},\n 'price': {0: 10.284260107718254,\n  1: 11.930300761831457,\n  2: 10.93741046217319,\n  3: 10.884574289565609,\n  4: 11.78005850418319},\n 'ticker': {0: 'aapl', 1: 'aapl', 2: 'aapl', 3: 'aapl', 4: 'aapl'}}\n\n>>> pd.concat([stocks.head(), stocks.tail()], ignore_index=True).to_dict()\n{'date': {0: Timestamp('2011-01-01 00:00:00'),\n  1: Timestamp('2011-01-01 00:00:00'),\n  2: Timestamp('2011-01-01 00:00:00'),\n  3: Timestamp('2011-01-01 00:00:00'),\n  4: Timestamp('2011-01-02 00:00:00'),\n  5: Timestamp('2011-01-24 00:00:00'),\n  6: Timestamp('2011-01-25 00:00:00'),\n  7: Timestamp('2011-01-25 00:00:00'),\n  8: Timestamp('2011-01-25 00:00:00'),\n  9: Timestamp('2011-01-25 00:00:00')},\n 'price': {0: 10.284260107718254,\n  1: 11.930300761831457,\n  2: 10.93741046217319,\n  3: 10.884574289565609,\n  4: 11.78005850418319,\n  5: 10.017209045035006,\n  6: 10.57090128181566,\n  7: 11.442792747870204,\n  8: 11.592953372130493,\n  9: 12.864146419530938},\n 'ticker': {0: 'aapl',\n  1: 'aapl',\n  2: 'aapl',\n  3: 'aapl',\n  4: 'aapl',\n  5: 'msft',\n  6: 'msft',\n  7: 'msft',\n  8: 'msft',\n  9: 'msft'}}\n \n You may also want to provide a description of the DataFrame (using only the relevant columns).  This makes it easier for others to check the data types of each column and identify other common errors (e.g. dates as string vs. datetime64 vs. object): \n stocks.info()\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 100 entries, 0 to 99\nData columns (total 3 columns):\ndate      100 non-null datetime64[ns]\nprice     100 non-null float64\nticker    100 non-null object\ndtypes: datetime64[ns](1), float64(1), object(1)\n \n NOTE:  If your DataFrame has a MultiIndex: \n If your DataFrame has a multiindex, you must first reset before calling  to_dict .  You then need to recreate the index using  set_index : \n # MultiIndex example.  First create a MultiIndex DataFrame.\ndf = stocks.set_index(['date', 'ticker'])\n>>> df\n                       price\ndate       ticker           \n2011-01-01 aapl    10.284260\n           aapl    11.930301\n           aapl    10.937410\n           aapl    10.884574\n2011-01-02 aapl    11.780059\n...\n\n# After resetting the index and passing the DataFrame to `to_dict`, make sure to use \n# `set_index` to restore the original MultiIndex.  This DataFrame can then be restored.\n\nd = df.reset_index().to_dict()\ndf_new = pd.DataFrame(d).set_index(['date', 'ticker'])\n>>> df_new.head()\n                       price\ndate       ticker           \n2011-01-01 aapl    10.284260\n           aapl    11.930301\n           aapl    10.937410\n           aapl    10.884574\n2011-01-02 aapl    11.780059\n \n    ", "date_posted": "2020-06-20 09:12:55Z", "upvote": "\r\n            38\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}, {"stack_answer_id": "41189949", "answer_content": "\r\n Here is my version of  dput  - the standard R tool to produce reproducible reports - for Pandas  DataFrame s.\nIt will probably fail for more complex frames, but it seems to do the job in simple cases: \n import pandas as pd\ndef dput(x):\n    if isinstance(x,pd.Series):\n        return \"pd.Series(%s,dtype='%s',index=pd.%s)\" % (list(x),x.dtype,x.index)\n    if isinstance(x,pd.DataFrame):\n        return \"pd.DataFrame({\" + \", \".join([\n            \"'%s': %s\" % (c,dput(x[c])) for c in x.columns]) + (\n                \"}, index=pd.%s)\" % (x.index))\n    raise NotImplementedError(\"dput\",type(x),x)\n \n now, \n df = pd.DataFrame({'a':[1,2,3,4,2,1,3,1]})\nassert df.equals(eval(dput(df)))\ndu = pd.get_dummies(df.a,\"foo\")\nassert du.equals(eval(dput(du)))\ndi = df\ndi.index = list('abcdefgh')\nassert di.equals(eval(dput(di)))\n \n Note  that this produces a much more verbose output than  DataFrame.to_dict , e.g., \n \n pd.DataFrame({\n  'foo_1':pd.Series([1, 0, 0, 0, 0, 1, 0, 1],dtype='uint8',index=pd.RangeIndex(start=0, stop=8, step=1)),\n  'foo_2':pd.Series([0, 1, 0, 0, 1, 0, 0, 0],dtype='uint8',index=pd.RangeIndex(start=0, stop=8, step=1)),\n  'foo_3':pd.Series([0, 0, 1, 0, 0, 0, 1, 0],dtype='uint8',index=pd.RangeIndex(start=0, stop=8, step=1)),\n  'foo_4':pd.Series([0, 0, 0, 1, 0, 0, 0, 0],dtype='uint8',index=pd.RangeIndex(start=0, stop=8, step=1))},\n  index=pd.RangeIndex(start=0, stop=8, step=1))\n \n \n vs \n \n {'foo_1': {0: 1, 1: 0, 2: 0, 3: 0, 4: 0, 5: 1, 6: 0, 7: 1}, \n 'foo_2': {0: 0, 1: 1, 2: 0, 3: 0, 4: 1, 5: 0, 6: 0, 7: 0}, \n 'foo_3': {0: 0, 1: 0, 2: 1, 3: 0, 4: 0, 5: 0, 6: 1, 7: 0}, \n 'foo_4': {0: 0, 1: 0, 2: 0, 3: 1, 4: 0, 5: 0, 6: 0, 7: 0}}\n \n \n for  du  above, but it  preserves column types .\nE.g., in the above test case, \n du.equals(pd.DataFrame(du.to_dict()))\n==> False\n \n because  du.dtypes  is  uint8  and  pd.DataFrame(du.to_dict()).dtypes  is  int64 . \n    ", "date_posted": "2020-11-08 03:20:49Z", "upvote": "\r\n            21\r\n        ", "accepted": "No", "user": {"stack_user_id": "50065", "name": "BioGeek", "reputation_score": "21.1k"}, "answer_comments": [{"stack_answer_id": "41189949", "stack_answer_comment_id": "71988989", "comment_content": "it is clearer, though i admit i don't see why i would want to use it over ", "user_id": null}, {"stack_answer_id": "41189949", "stack_answer_comment_id": "71989097", "comment_content": "Because it preserves column types. More specifically, ", "user_id": null}, {"stack_answer_id": "41189949", "stack_answer_comment_id": "124382725", "comment_content": "I like this. I have a more modern version with interpolated strings, which also breaks up the output with line breaks: ", "user_id": null}]}], "user": {"stack_user_id": "1222578", "name": "Marius", "reputation_score": "55.5k"}, "question_comments": [{"stack_question_id": "20109391", "stack_question_comment_id": "29965074", "comment_content": "If you copy the output of printing, most of the time answerers can use read_clipboard()... except for MultiIndex :s. Saying that, dict is good addition", "user_id": null}, {"stack_question_id": "20109391", "stack_question_comment_id": "29965293", "comment_content": "In addition to what Andy said, I think copy-pasting ", "user_id": null}]},
{"stack_question_id": "240178", "question_title": "List of lists changes reflected across sublists unexpectedly", "question_content": "\r\n                I created a list of lists:\nxs = [[1] * 4] * 3\n\n# xs == [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]  \n\nThen, I changed one of the innermost values:\nxs[0][0] = 5\n\n# xs == [[5, 1, 1, 1], [5, 1, 1, 1], [5, ...\r\n", "question_url": "/questions/240178/list-of-lists-changes-reflected-across-sublists-unexpectedly", "date_posted": "Oct 27, 2008 at 14:57", "upvote": "8", "view": "6", "tags": ["python", "list", "nested-lists", "mutable"], "answers_count": "1", "answers": [{"stack_answer_id": "240205", "answer_content": "\r\n When you write  [x]*3  you get, essentially, the list  [x, x, x] . That is, a list with 3 references to the same  x . When you then modify this single  x  it is visible via all three references to it: \n x = [1] * 4\nxs = [x] * 3\nprint(f\"id(x): {id(x)}\")\n# id(x): 140560897920048\nprint(\n    f\"id(xs[0]): {id(xs[0])}\\n\"\n    f\"id(xs[1]): {id(xs[1])}\\n\"\n    f\"id(xs[2]): {id(xs[2])}\"\n)\n# id(xs[0]): 140560897920048\n# id(xs[1]): 140560897920048\n# id(xs[2]): 140560897920048\n\nx[0] = 42\nprint(f\"x: {x}\")\n# x: [42, 1, 1, 1]\nprint(f\"xs: {xs}\")\n# xs: [[42, 1, 1, 1], [42, 1, 1, 1], [42, 1, 1, 1]]\n \n To fix it, you need to make sure that you create a new list at each position. One way to do it is \n [[1]*4 for _ in range(3)]\n \n which will reevaluate  [1]*4  each time instead of evaluating it once and making 3 references to 1 list. \n \n You might wonder why  *  can't make independent objects the way the list comprehension does. That's because the multiplication operator  *  operates on objects, without seeing expressions. When you use  *  to multiply  [[1] * 4]  by 3,  *  only sees the 1-element list  [[1] * 4]  evaluates to, not the  [[1] * 4  expression text.  *  has no idea how to make copies of that element, no idea how to reevaluate  [[1] * 4] , and no idea you even want copies, and in general, there might not even be a way to copy the element. \n The only option  *  has is to make new references to the existing sublist instead of trying to make new sublists. Anything else would be inconsistent or require major redesigning of fundamental language design decisions. \n In contrast, a list comprehension reevaluates the element expression on every iteration.  [[1] * 4 for n in range(3)]  reevaluates  [1] * 4  every time for the same reason  [x**2 for x in range(3)]  reevaluates  x**2  every time. Every evaluation of  [1] * 4  generates a new list, so the list comprehension does what you wanted. \n Incidentally,  [1] * 4  also doesn't copy the elements of  [1] , but that doesn't matter, since integers are immutable. You can't do something like  1.value = 2  and turn a 1 into a 2. \n    ", "date_posted": "2022-05-22 19:55:56Z", "upvote": "\r\n            754\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": [{"stack_answer_id": "240205", "stack_answer_comment_id": "48862076", "comment_content": "I am surprised that no body points out  that, the answer here is misleading. ", "user_id": null}, {"stack_answer_id": "240205", "stack_answer_comment_id": "48871095", "comment_content": "Technically, it's still correct. ", "user_id": null}, {"stack_answer_id": "240205", "stack_answer_comment_id": "60950287", "comment_content": "@Allanqunzi you are wrong. Do ", "user_id": null}, {"stack_answer_id": "240205", "stack_answer_comment_id": "126691081", "comment_content": "can anyone find documents about the ", "user_id": null}, {"stack_answer_id": "240205", "stack_answer_comment_id": "127789351", "comment_content": "@LeiYang It's listed under ", "user_id": null}]}, {"stack_answer_id": "18454568", "answer_content": "\r\n size = 3\nmatrix_surprise = [[0] * size] * size\nmatrix = [[0]*size for _ in range(size)]\n \n Live visualization  using Python Tutor: \n \n    ", "date_posted": "2021-06-18 17:12:23Z", "upvote": "\r\n            168\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": [{"stack_answer_id": "18454568", "stack_answer_comment_id": "76707168", "comment_content": "So, why if we write matrix= [[x] * 2] doesn't make 2 elemnts for the same object like the example you describe, it seems to be the same concept, what am i missing?", "user_id": null}, {"stack_answer_id": "18454568", "stack_answer_comment_id": "76720889", "comment_content": "@AhmedMohamed Indeed it does make a list with two elements of the exact same object that ", "user_id": null}, {"stack_answer_id": "18454568", "stack_answer_comment_id": "76721203", "comment_content": "@nadrimajstor so why the change in matrix[0] doesn't affect matrix[1] like the example above with 2d matrix.", "user_id": null}, {"stack_answer_id": "18454568", "stack_answer_comment_id": "76723575", "comment_content": "@AhmedMohamed Surprise come when you make a \"copy\" of mutable sequence (in our example it is a ", "user_id": null}, {"stack_answer_id": "18454568", "stack_answer_comment_id": "76724009", "comment_content": "@AhmedMohamed Take a look at ", "user_id": null}]}, {"stack_answer_id": "240215", "answer_content": "\r\n Actually, this is exactly what you would expect. Let's decompose what is happening here: \n You write \n lst = [[1] * 4] * 3\n \n This is equivalent to: \n lst1 = [1]*4\nlst = [lst1]*3\n \n This means  lst  is a list with 3 elements all pointing to  lst1 . This means the two following lines are equivalent: \n lst[0][0] = 5\nlst1[0] = 5\n \n As  lst[0]  is nothing but  lst1 . \n To obtain the desired behavior, you can use a list comprehension: \n lst = [ [1]*4 for n in range(3) ]\n \n In this case, the expression is re-evaluated for each  n , leading to a different list. \n    ", "date_posted": "2021-06-18 16:49:18Z", "upvote": "\r\n            70\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": [{"stack_answer_id": "240215", "stack_answer_comment_id": "75062949", "comment_content": "Just a small addition to the nice answer here: it's evident that you're dealing with same object if you do ", "user_id": null}, {"stack_answer_id": "240215", "stack_answer_comment_id": "128207126", "comment_content": "Doesn't explain why modifying a 1d list causes a copy while a 2d list doesn't cause any copy", "user_id": null}]}, {"stack_answer_id": "240202", "answer_content": "\r\n [[1] * 4] * 3\n \n\n or even: \n\n [[1, 1, 1, 1]] * 3\n \n\n Creates a list that references the internal  [1,1,1,1]  3 times - not three copies of the inner list, so any time you modify the list (in any position), you'll see the change three times. \n\n It's the same as this example: \n\n >>> inner = [1,1,1,1]\n>>> outer = [inner]*3\n>>> outer\n[[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]\n>>> inner[0] = 5\n>>> outer\n[[5, 1, 1, 1], [5, 1, 1, 1], [5, 1, 1, 1]]\n \n\n where it's probably a little less surprising. \n    ", "date_posted": "2017-01-14 07:54:00Z", "upvote": "\r\n            47\r\n        ", "accepted": "No", "user": {"stack_user_id": "4952130", "name": "Dimitris Fasarakis Hilliard", "reputation_score": "139k"}, "answer_comments": [{"stack_answer_id": "240202", "stack_answer_comment_id": "103503", "comment_content": "You can use the \"is\" operator to discover this. ls[0] is ls[1] returns True.", "user_id": null}]}, {"stack_answer_id": "43246520", "answer_content": "\r\n my_list = [[1]*4] * 3  creates one list object  [1,1,1,1]  in memory and copies its reference 3 times over. This is equivalent to  obj = [1,1,1,1]; my_list = [obj]*3 . Any modification to  obj  will be reflected at three places, wherever  obj  is referenced in the list.\nThe right statement would be: \n my_list = [[1]*4 for _ in range(3)]\n \n or \n my_list = [[1 for __ in range(4)] for _ in range(3)]\n \n Important thing to note here  is that the  *  operator is  mostly  used to create a  list of literals . Although  1  is immutable,  obj = [1]*4  will still create a list of  1  repeated 4 times over to form  [1,1,1,1] . But if any reference to an immutable object is made, the object is overwritten with a new one. \n This means if we do  obj[1] = 42 , then  obj  will become  [1,42,1,1]   not   [42,42,42,42]  as some may assume. This can also be verified: \n >>> my_list = [1]*4\n>>> my_list\n[1, 1, 1, 1]\n\n>>> id(my_list[0])\n4522139440\n>>> id(my_list[1])  # Same as my_list[0]\n4522139440\n \n \n >>> my_list[1] = 42  # Since my_list[1] is immutable, this operation overwrites my_list[1] with a new object changing its id.\n>>> my_list\n[1, 42, 1, 1]\n\n>>> id(my_list[0])\n4522139440\n>>> id(my_list[1])  # id changed\n4522140752\n>>> id(my_list[2])  # id still same as my_list[0], still referring to value `1`.\n4522139440\n \n    ", "date_posted": "2021-06-18 16:32:37Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": [{"stack_answer_id": "43246520", "stack_answer_comment_id": "90015086", "comment_content": "It's not about literals. ", "user_id": null}]}, {"stack_answer_id": "30898048", "answer_content": "\r\n Alongside the accepted answer that explained the problem correctly, instead of creating a list with duplicated elements using following code: \n [[1]*4 for _ in range(3)]\n \n Also, you can use  itertools.repeat()  to create an iterator object of repeated elements: \n >>> a = list(repeat(1,4))\n[1, 1, 1, 1]\n>>> a[0] = 5\n>>> a\n[5, 1, 1, 1]\n \n P.S. If you're using NumPy and you only want to create an array of ones or zeroes you can use  np.ones  and  np.zeros  and/or for other numbers use  np.repeat : \n >>> import numpy as np\n>>> np.ones(4)\narray([1., 1., 1., 1.])\n>>> np.ones((4, 2))\narray([[1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.]])\n>>> np.zeros((4, 2))\narray([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]])\n>>> np.repeat([7], 10)\narray([7, 7, 7, 7, 7, 7, 7, 7, 7, 7])\n \n    ", "date_posted": "2021-06-18 17:26:13Z", "upvote": "\r\n            10\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": []}, {"stack_answer_id": "36452923", "answer_content": "\r\n Python containers contain references to other objects. See this example: \n\n >>> a = []\n>>> b = [a]\n>>> b\n[[]]\n>>> a.append(1)\n>>> b\n[[1]]\n \n\n In this  b  is a list that contains one item that is a reference to list  a . The list  a  is mutable. \n\n The multiplication of a list by an integer is equivalent to adding the list to itself multiple times (see  common sequence operations ). So continuing with the example: \n\n >>> c = b + b\n>>> c\n[[1], [1]]\n>>>\n>>> a[0] = 2\n>>> c\n[[2], [2]]\n \n\n We can see that the list  c  now contains two references to list  a  which is equivalent to  c = b * 2 . \n\n Python FAQ also contains explanation of this behavior:  How do I create a multidimensional list? \n    ", "date_posted": "2016-04-06 13:40:43Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "3185929", "name": "Zbyn\u011bk Winkler", "reputation_score": "1,043"}, "answer_comments": []}, {"stack_answer_id": "30759580", "answer_content": "\r\n Let's rewrite your code in the following way: \n x = 1\ny = [x]\nz = y * 4\n\nmy_list = [z] * 3\n \n Then having this, run the following code to make everything more clear. What the code does is basically print the  id s of the obtained objects, which \n \n Return[s] the \u201cidentity\u201d of an object \n \n and will help us identify them and analyse what happens: \n print(\"my_list:\")\nfor i, sub_list in enumerate(my_list):\n    print(\"\\t[{}]: {}\".format(i, id(sub_list)))\n    for j, elem in enumerate(sub_list):\n        print(\"\\t\\t[{}]: {}\".format(j, id(elem)))\n \n And you will get the following output: \n x: 1\ny: [1]\nz: [1, 1, 1, 1]\nmy_list:\n    [0]: 4300763792\n        [0]: 4298171528\n        [1]: 4298171528\n        [2]: 4298171528\n        [3]: 4298171528\n    [1]: 4300763792\n        [0]: 4298171528\n        [1]: 4298171528\n        [2]: 4298171528\n        [3]: 4298171528\n    [2]: 4300763792\n        [0]: 4298171528\n        [1]: 4298171528\n        [2]: 4298171528\n        [3]: 4298171528\n \n \n So now let's go step-by-step. You have  x  which is  1 , and a single element list  y  containing  x . Your first step is  y * 4  which will get you a new list  z , which is basically  [x, x, x, x] , i.e. it creates a new list which will have 4 elements, which are references to the initial  x  object. The next step is pretty similar. You basically do  z * 3 , which is  [[x, x, x, x]] * 3  and returns  [[x, x, x, x], [x, x, x, x], [x, x, x, x]] , for the same reason as for the first step. \n    ", "date_posted": "2021-06-18 16:36:25Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": []}, {"stack_answer_id": "62497944", "answer_content": "\r\n I am adding my answer to explain the same diagrammatically. \n The way you created the 2D, creates a shallow list \n arr = [[0]*cols]*row\n \n Instead, if you want to update the elements of the list, you should use \n rows, cols = (5, 5) \narr = [[0 for i in range(cols)] for j in range(rows)] \n \n Explanation : \n One can create a list using: \n arr = [0]*N \n \n or \n arr = [0 for i in range(N)] \n \n In the first case all the indices of the array point to the same integer object \n \n and when you assign a value to a particular index, a new int object is created, for example  arr[4] = 5  creates \n \n Now let us see what happens when we create a list of list, in this case, all the elements of our top list will point to the same list \n \n And if you update the value of any index a new int object will be created. But since all the top-level list indexes are pointing at the same list, all the rows will look the same. And you will get the feeling that updating an element is updating all the elements in that column. \n \n Credits:  Thanks to  Pranav Devarakonda  for the easy explanation  here \n    ", "date_posted": "2022-05-19 09:56:29Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "4621513", "name": "mkrieger1", "reputation_score": "15.4k"}, "answer_comments": []}, {"stack_answer_id": "37804636", "answer_content": "\r\n In simple words this is happening because in python everything works  by reference , so when you create a list of list that way you basically end up with such problems. \n\n To solve your issue you can do either one of them:\n1. Use numpy array  documentation for numpy.empty \n2. Append the list as you get to a list.\n3. You can also use dictionary if you want   \n    ", "date_posted": "2016-06-14 06:36:52Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "5801215", "name": "Neeraj Komuravalli", "reputation_score": "176"}, "answer_comments": []}, {"stack_answer_id": "36823796", "answer_content": "\r\n Everyone is explaining what is happening. I'll suggest one way to solve it: \n my_list = [[1 for i in range(4)] for j in range(3)]\n\nmy_list[0][0] = 5\nprint(my_list)\n \n And then you get: \n [[5, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]\n \n    ", "date_posted": "2021-06-18 16:39:24Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": []}, {"stack_answer_id": "57426328", "answer_content": "\r\n @spelchekr from  Python list multiplication: [[...]]*3 makes 3 lists which mirror each other when modified  and I had the same question about\n\"Why does only the outer  *3  create more references while the inner one doesn't? Why isn't it all 1s?\" \n li = [0] * 3\nprint([id(v) for v in li])  # [140724141863728, 140724141863728, 140724141863728]\nli[0] = 1\nprint([id(v) for v in li])  # [140724141863760, 140724141863728, 140724141863728]\nprint(id(0))  # 140724141863728\nprint(id(1))  # 140724141863760\nprint(li)     # [1, 0, 0]\n\nma = [[0]*3] * 3  # mainly discuss inner & outer *3 here\nprint([id(li) for li in ma])  # [1987013355080, 1987013355080, 1987013355080]\nma[0][0] = 1\nprint([id(li) for li in ma])  # [1987013355080, 1987013355080, 1987013355080]\nprint(ma)  # [[1, 0, 0], [1, 0, 0], [1, 0, 0]]\n \n Here is my explanation after trying the code above: \n \n The inner  *3  also creates references, but its references are immutable, something like  [&0, &0, &0] , then when you change  li[0] , you can't change any underlying reference of const int  0 , so you can just change the reference address into the new one  &1 ; \n while  ma = [&li, &li, &li]  and  li  is mutable, so when you call  ma[0][0] = 1 ,  ma[0][0]  is equal to  &li[0] , so all the  &li  instances will change its 1st address into  &1 . \n \n    ", "date_posted": "2021-06-18 17:02:12Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": []}, {"stack_answer_id": "38866487", "answer_content": "\r\n Trying to explain it more descriptively, \n\n Operation 1: \n\n x = [[0, 0], [0, 0]]\nprint(type(x)) # <class 'list'>\nprint(x) # [[0, 0], [0, 0]]\n\nx[0][0] = 1\nprint(x) # [[1, 0], [0, 0]]\n \n\n Operation 2: \n\n y = [[0] * 2] * 2\nprint(type(y)) # <class 'list'>\nprint(y) # [[0, 0], [0, 0]]\n\ny[0][0] = 1\nprint(y) # [[1, 0], [1, 0]]\n \n\n Noticed why doesn't modifying the first element of the first list didn't modify the second element of each list? That's because  [0] * 2  really is a list of two numbers, and a reference to 0 cannot be modified. \n\n If you want to create clone copies, try Operation 3: \n\n import copy\ny = [0] * 2   \nprint(y)   # [0, 0]\n\ny = [y, copy.deepcopy(y)]  \nprint(y) # [[0, 0], [0, 0]]\n\ny[0][0] = 1\nprint(y) # [[1, 0], [0, 0]]\n \n\n another interesting way to create clone copies, Operation 4: \n\n import copy\ny = [0] * 2\nprint(y) # [0, 0]\n\ny = [copy.deepcopy(y) for num in range(1,5)]\nprint(y) # [[0, 0], [0, 0], [0, 0], [0, 0]]\n\ny[0][0] = 5\nprint(y) # [[5, 0], [0, 0], [0, 0], [0, 0]]\n \n    ", "date_posted": "2016-08-10 07:29:38Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "2285848", "name": "Adil Abbasi", "reputation_score": "3,101"}, "answer_comments": []}, {"stack_answer_id": "38397772", "answer_content": "\r\n By using the inbuilt list function you can do like this \n\n a\nout:[[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]\n#Displaying the list\n\na.remove(a[0])\nout:[[1, 1, 1, 1], [1, 1, 1, 1]]\n# Removed the first element of the list in which you want altered number\n\na.append([5,1,1,1])\nout:[[1, 1, 1, 1], [1, 1, 1, 1], [5, 1, 1, 1]]\n# append the element in the list but the appended element as you can see is appended in last but you want that in starting\n\na.reverse()\nout:[[5, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]\n#So at last reverse the whole list to get the desired list\n \n    ", "date_posted": "2016-07-25 09:09:59Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "5230702", "name": "Anand Tripathi", "reputation_score": "12.4k"}, "answer_comments": [{"stack_answer_id": "38397772", "stack_answer_comment_id": "92685565", "comment_content": "Note, fourth step can be dropped if you make second step: ", "user_id": null}]}, {"stack_answer_id": "64489659", "answer_content": "\r\n I arrived here because I was looking to see how I could nest an arbitrary number of lists. There are a lot of explanations and specific examples above, but you can generalize N dimensional list of lists of lists of ... with the following recursive function: \n import copy\n\ndef list_ndim(dim, el=None, init=None):\n    if init is None:\n        init = el\n\n    if len(dim)> 1:\n        return list_ndim(dim[0:-1], None, [copy.copy(init) for x in range(dim[-1])])\n\n    return [copy.deepcopy(init) for x in range(dim[0])]\n \n You make your first call to the function like this: \n dim = (3,5,2)\nel = 1.0\nl = list_ndim(dim, el)\n \n where  (3,5,2)  is a tuple of the dimensions of the structure (similar to numpy  shape  argument), and  1.0  is the element you want the structure to be initialized with (works with None as well). Note that the  init  argument is only provided by the recursive call to carry forward the nested child lists \n output of above: \n [[[1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0]],\n [[1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0]],\n [[1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0]]]\n \n set specific elements: \n l[1][3][1] = 56\nl[2][2][0] = 36.0+0.0j\nl[0][1][0] = 'abc'\n \n resulting output: \n [[[1.0, 1.0], ['abc', 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0]],\n [[1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 56.0], [1.0, 1.0]],\n [[1.0, 1.0], [1.0, 1.0], [(36+0j), 1.0], [1.0, 1.0], [1.0, 1.0]]]\n \n the non-typed nature of lists is demonstrated above \n    ", "date_posted": "2020-10-22 19:57:45Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "8126390", "name": "Brian", "reputation_score": "533"}, "answer_comments": []}, {"stack_answer_id": "65616429", "answer_content": "\r\n While the original question constructed the  sublists  with the multiplication operator, I'll add an example that uses the  same  list for the sublists. Adding this answer for completeness as this question is often used as a canonical for the issue \n node_count = 4\ncolors = [0,1,2,3]\nsol_dict = {node:colors for node in range(0,node_count)}\n \n The list in each dictionary value is the same object, trying to change one of the dictionaries values will be seen in all. \n >>> sol_dict\n{0: [0, 1, 2, 3], 1: [0, 1, 2, 3], 2: [0, 1, 2, 3], 3: [0, 1, 2, 3]}\n>>> [v is colors for v in sol_dict.values()]\n[True, True, True, True]\n>>> sol_dict[0].remove(1)\n>>> sol_dict\n{0: [0, 2, 3], 1: [0, 2, 3], 2: [0, 2, 3], 3: [0, 2, 3]}\n \n The correct way to construct the dictionary would be to use a copy of the list for each value. \n >>> colors = [0,1,2,3]\n>>> sol_dict = {node:colors[:] for node in range(0,node_count)}\n>>> sol_dict\n{0: [0, 1, 2, 3], 1: [0, 1, 2, 3], 2: [0, 1, 2, 3], 3: [0, 1, 2, 3]}\n>>> sol_dict[0].remove(1)\n>>> sol_dict\n{0: [0, 2, 3], 1: [0, 1, 2, 3], 2: [0, 1, 2, 3], 3: [0, 1, 2, 3]}\n \n    ", "date_posted": "2021-01-07 16:39:52Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "65616429", "name": "\r\n        wwii\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "64958758", "answer_content": "\r\n Note that items in the sequence are not copied; they are referenced multiple times . This often haunts new Python programmers; consider: \n >>> lists = [[]] * 3\n>>> lists\n[[], [], []]\n>>> lists[0].append(3)\n>>> lists\n[[3], [3], [3]]\n \n What has happened is that  [[]]  is a one-element list containing an empty list, so all three elements of  [[]] * 3  are references to this single empty list. Modifying any of the elements of lists modifies this single list. \n Another example to explain this is using  multi-dimensional arrays . \n You probably tried to make a multidimensional array like this: \n >>> A = [[None] * 2] * 3\n \n This looks correct if you print it: \n >>> A\n[[None, None], [None, None], [None, None]]\n \n But when you assign a value, it shows up in multiple places: \n >>> A[0][0] = 5\n>>> A\n[[5, None], [5, None], [5, None]]\n \n The reason is that replicating a list with\u00a0 * \u00a0doesn\u2019t create copies, it only creates references to the existing objects. The\u00a03\u00a0creates a list containing 3 references to the same list of length two. Changes to one row will show in all rows, which is almost certainly not what you want. \n    ", "date_posted": "2021-03-20 14:25:08Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "7841468", "name": "mishsx", "reputation_score": "1,275"}, "answer_comments": []}], "user": {"stack_user_id": "11677", "name": "Charles Anderson", "reputation_score": "18.3k"}, "question_comments": [{"stack_question_id": "240178", "stack_question_comment_id": "124422290", "comment_content": "Note that the same logic applies to a list of dicts, because of the same fundamental problem of aliasing a mutable object. See ", "user_id": null}, {"stack_question_id": "240178", "stack_question_comment_id": "127396210", "comment_content": "Are there more specific questions for when the list of lists is created in other ways (but has the same problem)? For example, by using ", "user_id": null}, {"stack_question_id": "240178", "stack_question_comment_id": "128071922", "comment_content": "See also ", "user_id": null}, {"stack_question_id": "240178", "stack_question_comment_id": "128430067", "comment_content": "Related: ", "user_id": null}]},
{"stack_question_id": "509211", "question_title": "Understanding slicing", "question_content": "\r\n                I need a good explanation (references are a plus) on Python slicing.\r\n", "question_url": "/questions/509211/understanding-slicing", "date_posted": "Feb 3, 2009 at 22:31", "upvote": "4", "view": "2", "tags": ["python", "slice", "sequence"], "answers_count": "3", "answers": [{"stack_answer_id": "509295", "answer_content": "\r\n The syntax is: \n a[start:stop]  # items start through stop-1\na[start:]      # items start through the rest of the array\na[:stop]       # items from the beginning through stop-1\na[:]           # a copy of the whole array\n \n There is also the  step  value, which can be used with any of the above: \n a[start:stop:step] # start through not past stop, by step\n \n The key point to remember is that the  :stop  value represents the first value that is  not  in the selected slice. So, the difference between  stop  and  start  is the number of elements selected (if  step  is 1, the default). \n The other feature is that  start  or  stop  may be a  negative  number, which means it counts from the end of the array instead of the beginning. So: \n a[-1]    # last item in the array\na[-2:]   # last two items in the array\na[:-2]   # everything except the last two items\n \n Similarly,  step  may be a negative number: \n a[::-1]    # all items in the array, reversed\na[1::-1]   # the first two items, reversed\na[:-3:-1]  # the last two items, reversed\na[-3::-1]  # everything except the last two items, reversed\n \n Python is kind to the programmer if there are fewer items than you ask for. For example, if you ask for  a[:-2]  and  a  only contains one element, you get an empty list instead of an error. Sometimes you would prefer the error, so you have to be aware that this may happen. \n Relationship with the  slice  object \n A  slice  object  can represent a slicing operation, i.e.: \n a[start:stop:step]\n \n is equivalent to: \n a[slice(start, stop, step)]\n \n Slice objects also behave slightly differently depending on the number of arguments, similarly to  range() , i.e. both  slice(stop)  and  slice(start, stop[, step])  are supported.\nTo skip specifying a given argument, one might use  None , so that e.g.  a[start:]  is equivalent to  a[slice(start, None)]  or  a[::-1]  is equivalent to  a[slice(None, None, -1)] . \n While the  : -based notation is very helpful for simple slicing, the explicit use of  slice()  objects simplifies the programmatic generation of slicing. \n    ", "date_posted": "2022-05-22 19:33:18Z", "upvote": "\r\n            6103\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": [{"stack_answer_id": "509295", "stack_answer_comment_id": "27984940", "comment_content": "Slicing builtin types returns a copy but that's not universal.  Notably, ", "user_id": null}, {"stack_answer_id": "509295", "stack_answer_comment_id": "95272803", "comment_content": "This is a beautiful answer with the votes to prove it, but it misses one thing: you can substitute ", "user_id": null}, {"stack_answer_id": "509295", "stack_answer_comment_id": "99325528", "comment_content": "Note that contrary to usual Python slices (see above), in Pandas Dataframes both the start and the stop are included when present in the index. For further info see the ", "user_id": null}, {"stack_answer_id": "509295", "stack_answer_comment_id": "100203161", "comment_content": "What really annoys me is that python says that when you don't set the start and the end, they default to 0 and the length of sequence. So, in theory, when you use \"abcdef\"[::-1] it should be transformed to \"abcdef\"[0:6:-1], but these two expressions does not get the same output. I feel that something is missing in python documentation since the creation of the language.", "user_id": null}, {"stack_answer_id": "509295", "stack_answer_comment_id": "100203434", "comment_content": "And I know that \"abcdef\"[::-1] is transformed to \"abcdef\"[6:-7:-1], so, the best way to explain would be: let ", "user_id": null}]}, {"stack_answer_id": "509297", "answer_content": "\r\n The  Python tutorial  talks about it (scroll down a bit until you get to the part about slicing). \n\n The ASCII art diagram is helpful too for remembering how slices work: \n\n  +---+---+---+---+---+---+\n | P | y | t | h | o | n |\n +---+---+---+---+---+---+\n 0   1   2   3   4   5   6\n-6  -5  -4  -3  -2  -1\n \n\n \n   One way to remember how slices work is to think of the indices as pointing  between  characters, with the left edge of the first character numbered 0. Then the right edge of the last character of a string of  n  characters has index  n . \n \n    ", "date_posted": "2017-09-18 11:02:56Z", "upvote": "\r\n            662\r\n        ", "accepted": "No", "user": {"stack_user_id": "55075", "name": "kenorb", "reputation_score": "141k"}, "answer_comments": [{"stack_answer_id": "509297", "stack_answer_comment_id": "99270489", "comment_content": "This suggestion works for positive stride, but does not for a negative stride. From the diagram, I expect ", "user_id": null}, {"stack_answer_id": "509297", "stack_answer_comment_id": "100377224", "comment_content": "But there's no way to collapse to an empty set starting from the end (like ", "user_id": null}, {"stack_answer_id": "509297", "stack_answer_comment_id": "118360396", "comment_content": "@aguadopd You are absolutely right. The solution is to have the indices shifted to the right, centered just below the characters, and notice that the stop is always excluded. See another response just below.", "user_id": null}, {"stack_answer_id": "509297", "stack_answer_comment_id": "118606940", "comment_content": "Addendum to my comment: see my answer with diagrams below: ", "user_id": null}]}, {"stack_answer_id": "509377", "answer_content": "\r\n Enumerating the possibilities allowed by the grammar for the sequence  x : \n >>> x[:]                # [x[0],   x[1],          ..., x[-1]    ]\n>>> x[low:]             # [x[low], x[low+1],      ..., x[-1]    ]\n>>> x[:high]            # [x[0],   x[1],          ..., x[high-1]]\n>>> x[low:high]         # [x[low], x[low+1],      ..., x[high-1]]\n>>> x[::stride]         # [x[0],   x[stride],     ..., x[-1]    ]\n>>> x[low::stride]      # [x[low], x[low+stride], ..., x[-1]    ]\n>>> x[:high:stride]     # [x[0],   x[stride],     ..., x[high-1]]\n>>> x[low:high:stride]  # [x[low], x[low+stride], ..., x[high-1]]\n \n Of course, if  (high-low)%stride != 0 , then the end point will be a little lower than  high-1 . \n If  stride  is negative, the ordering is changed a bit since we're counting down: \n >>> x[::-stride]        # [x[-1],   x[-1-stride],   ..., x[0]    ]\n>>> x[high::-stride]    # [x[high], x[high-stride], ..., x[0]    ]\n>>> x[:low:-stride]     # [x[-1],   x[-1-stride],   ..., x[low+1]]\n>>> x[high:low:-stride] # [x[high], x[high-stride], ..., x[low+1]]\n \n Extended slicing (with commas and ellipses) are mostly used only by special data structures (like NumPy); the basic sequences don't support them. \n >>> class slicee:\n...     def __getitem__(self, item):\n...         return repr(item)\n...\n>>> slicee()[0, 1:2, ::5, ...]\n'(0, slice(1, 2, None), slice(None, None, 5), Ellipsis)'\n \n    ", "date_posted": "2022-05-22 19:38:32Z", "upvote": "\r\n            498\r\n        ", "accepted": "No", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": [{"stack_answer_id": "509377", "stack_answer_comment_id": "83074550", "comment_content": "Actually there is still something left out e.g. if I type 'apple'[4:-4:-1] I get 'elp', python is translating the -4 to a 1 maybe?", "user_id": null}, {"stack_answer_id": "509377", "stack_answer_comment_id": "95581586", "comment_content": "note that backticks are deprecated in favour of ", "user_id": null}, {"stack_answer_id": "509377", "stack_answer_comment_id": "102170688", "comment_content": "@liyuan The type implementing ", "user_id": null}, {"stack_answer_id": "509377", "stack_answer_comment_id": "124476274", "comment_content": "The first two tables are pure gold.", "user_id": null}]}, {"stack_answer_id": "4729334", "answer_content": "\r\n The answers above don't discuss slice assignment. To understand slice assignment, it's helpful to add another concept to the ASCII art: \n\n                 +---+---+---+---+---+---+\n                | P | y | t | h | o | n |\n                +---+---+---+---+---+---+\nSlice position: 0   1   2   3   4   5   6\nIndex position:   0   1   2   3   4   5\n\n>>> p = ['P','y','t','h','o','n']\n# Why the two sets of numbers:\n# indexing gives items, not lists\n>>> p[0]\n 'P'\n>>> p[5]\n 'n'\n\n# Slicing gives lists\n>>> p[0:1]\n ['P']\n>>> p[0:2]\n ['P','y']\n \n\n One heuristic is, for a slice from zero to n, think: \"zero is the beginning, start at the beginning and take n items in a list\". \n\n >>> p[5] # the last of six items, indexed from zero\n 'n'\n>>> p[0:5] # does NOT include the last item!\n ['P','y','t','h','o']\n>>> p[0:6] # not p[0:5]!!!\n ['P','y','t','h','o','n']\n \n\n Another heuristic is, \"for any slice, replace the start by zero, apply the previous heuristic to get the end of the list, then count the first number back up to chop items off the beginning\" \n\n >>> p[0:4] # Start at the beginning and count out 4 items\n ['P','y','t','h']\n>>> p[1:4] # Take one item off the front\n ['y','t','h']\n>>> p[2:4] # Take two items off the front\n ['t','h']\n# etc.\n \n\n The first rule of slice assignment is that since slicing  returns  a list, slice assignment  requires  a list (or other iterable): \n\n >>> p[2:3]\n ['t']\n>>> p[2:3] = ['T']\n>>> p\n ['P','y','T','h','o','n']\n>>> p[2:3] = 't'\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: can only assign an iterable\n \n\n The second rule of slice assignment, which you can also see above, is that whatever portion of the list is returned by slice indexing, that's the same portion that is changed by slice assignment: \n\n >>> p[2:4]\n ['T','h']\n>>> p[2:4] = ['t','r']\n>>> p\n ['P','y','t','r','o','n']\n \n\n The third rule of slice assignment is, the assigned list (iterable) doesn't have to have the same length; the indexed slice is simply sliced out and replaced en masse by whatever is being assigned: \n\n >>> p = ['P','y','t','h','o','n'] # Start over\n>>> p[2:4] = ['s','p','a','m']\n>>> p\n ['P','y','s','p','a','m','o','n']\n \n\n The trickiest part to get used to is assignment to empty slices. Using heuristic 1 and 2 it's easy to get your head around  indexing  an empty slice: \n\n >>> p = ['P','y','t','h','o','n']\n>>> p[0:4]\n ['P','y','t','h']\n>>> p[1:4]\n ['y','t','h']\n>>> p[2:4]\n ['t','h']\n>>> p[3:4]\n ['h']\n>>> p[4:4]\n []\n \n\n And then once you've seen that, slice assignment to the empty slice makes sense too: \n\n >>> p = ['P','y','t','h','o','n']\n>>> p[2:4] = ['x','y'] # Assigned list is same length as slice\n>>> p\n ['P','y','x','y','o','n'] # Result is same length\n>>> p = ['P','y','t','h','o','n']\n>>> p[3:4] = ['x','y'] # Assigned list is longer than slice\n>>> p\n ['P','y','t','x','y','o','n'] # The result is longer\n>>> p = ['P','y','t','h','o','n']\n>>> p[4:4] = ['x','y']\n>>> p\n ['P','y','t','h','x','y','o','n'] # The result is longer still\n \n\n Note that, since we are not changing the second number of the slice (4), the inserted items always stack right up against the 'o', even when we're assigning to the empty slice. So the position for the empty slice assignment is the logical extension of the positions for the non-empty slice assignments. \n\n Backing up a little bit, what happens when you keep going with our procession of counting up the slice beginning? \n\n >>> p = ['P','y','t','h','o','n']\n>>> p[0:4]\n ['P','y','t','h']\n>>> p[1:4]\n ['y','t','h']\n>>> p[2:4]\n ['t','h']\n>>> p[3:4]\n ['h']\n>>> p[4:4]\n []\n>>> p[5:4]\n []\n>>> p[6:4]\n []\n \n\n With slicing, once you're done, you're done; it doesn't start slicing backwards. In Python you don't get negative strides unless you explicitly ask for them by using a negative number. \n\n >>> p[5:3:-1]\n ['n','o']\n \n\n There are some weird consequences to the \"once you're done, you're done\" rule: \n\n >>> p[4:4]\n []\n>>> p[5:4]\n []\n>>> p[6:4]\n []\n>>> p[6]\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nIndexError: list index out of range\n \n\n In fact, compared to indexing, Python slicing is bizarrely error-proof: \n\n >>> p[100:200]\n []\n>>> p[int(2e99):int(1e99)]\n []\n \n\n This can come in handy sometimes, but it can also lead to somewhat strange behavior: \n\n >>> p\n ['P', 'y', 't', 'h', 'o', 'n']\n>>> p[int(2e99):int(1e99)] = ['p','o','w','e','r']\n>>> p\n ['P', 'y', 't', 'h', 'o', 'n', 'p', 'o', 'w', 'e', 'r']\n \n\n Depending on your application, that might... or might not... be what you were hoping for there! \n\n \n\n Below is the text of my original answer. It has been useful to many people, so I didn't want to delete it. \n\n >>> r=[1,2,3,4]\n>>> r[1:1]\n[]\n>>> r[1:1]=[9,8]\n>>> r\n[1, 9, 8, 2, 3, 4]\n>>> r[1:1]=['blah']\n>>> r\n[1, 'blah', 9, 8, 2, 3, 4]\n \n\n This may also clarify the difference between slicing and indexing. \n    ", "date_posted": "2019-01-02 16:44:22Z", "upvote": "\r\n            418\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "4729334", "stack_answer_comment_id": "129107053", "comment_content": "If I wanted to remove the 1st x elements of a list, what will be better: ", "user_id": null}, {"stack_answer_id": "4729334", "stack_answer_comment_id": "129131819", "comment_content": "The first way works for a list or a string; the second way only works for a list, because slice assignment isn't allowed for strings. Other than that I think the only difference is speed: it looks like it's a little faster the first way. Try it yourself with timeit.timeit() or preferably  timeit.repeat(). They are ", "user_id": null}]}, {"stack_answer_id": "24713353", "answer_content": "\r\n \n Explain Python's slice notation \n \n In short, the colons ( : ) in subscript notation ( subscriptable[subscriptarg] ) make slice notation, which has the optional arguments  start ,  stop , and  step : \n sliceable[start:stop:step]\n \n Python slicing is a computationally fast way to methodically access parts of your data. In my opinion, to be even an intermediate Python programmer, it's one aspect of the language that it is necessary to be familiar with. \n Important Definitions \n To begin with, let's define a few terms: \n \n start :  the beginning index of the slice, it will include the element at this index unless it is the same as  stop , defaults to 0, i.e. the first index. If it's negative, it means to start  n  items from the end. \n stop :  the ending index of the slice, it does  not  include the element at this index, defaults to length of the sequence being sliced, that is, up to and including the end. \n step :  the amount by which the index increases, defaults to 1. If it's negative, you're slicing over the iterable in reverse. \n \n How Indexing Works \n You can make any of these positive or negative numbers. The meaning of the positive numbers is straightforward, but for negative numbers, just like indexes in Python, you count backwards from the end for the  start  and  stop , and for the  step , you simply decrement your index. This example is  from the documentation's tutorial , but I've modified it slightly to indicate which item in a sequence each index references: \n  +---+---+---+---+---+---+\n | P | y | t | h | o | n |\n +---+---+---+---+---+---+\n   0   1   2   3   4   5 \n  -6  -5  -4  -3  -2  -1\n \n How Slicing Works \n To use slice notation with a sequence that supports it, you must include at least one colon in the square brackets that follow the sequence (which actually  implement the  __getitem__  method of the sequence, according to the Python data model .) \n Slice notation works like this: \n sequence[start:stop:step]\n \n And recall that there are defaults for  start ,  stop , and  step , so to access the defaults, simply leave out the argument. \n Slice notation to get the last nine elements from a list (or any other sequence that supports it, like a string) would look like this: \n my_list[-9:]\n \n When I see this, I read the part in the brackets as \"9th from the end, to the end.\" (Actually, I abbreviate it mentally as \"-9, on\") \n Explanation: \n The full notation is \n my_list[-9:None:None]\n \n and to substitute the defaults (actually when  step  is negative,  stop 's default is  -len(my_list) - 1 , so  None  for stop really just means it goes to whichever end step takes it to): \n my_list[-9:len(my_list):1]\n \n The  colon ,  : ,  is what tells Python you're giving it a slice and not a regular index. That's why the idiomatic way of making a shallow copy of lists in Python 2 is \n list_copy = sequence[:]\n \n And clearing them is with: \n del my_list[:]\n \n (Python 3 gets a  list.copy  and  list.clear  method.) \n When  step  is negative, the defaults for  start  and  stop  change \n By default, when the  step  argument is empty (or  None ), it is assigned to  +1 . \n But you can pass in a negative integer, and the list (or most other standard sliceables) will be sliced from the end to the beginning. \n Thus a negative slice will change the defaults for  start  and  stop ! \n Confirming this in the source \n I like to encourage users to read the source as well as the documentation. The  source code for slice objects and this logic is found here . First we determine if  step  is negative: \n \n step_is_negative = step_sign < 0;\n \n \n If so, the lower bound is  -1   meaning we slice all the way up to and including the beginning, and the upper bound is the length minus 1, meaning we start at the end. (Note that the semantics of this  -1  is  different  from a  -1  that users may pass indexes in Python indicating the last item.) \n \n if (step_is_negative) {\n    lower = PyLong_FromLong(-1L);\n    if (lower == NULL)\n        goto error;\n\n    upper = PyNumber_Add(length, lower);\n    if (upper == NULL)\n        goto error;\n}\n \n \n Otherwise  step  is positive, and the lower bound will be zero and the upper bound (which we go up to but not including) the length of the sliced list. \n \n else {\n    lower = _PyLong_Zero;\n    Py_INCREF(lower);\n    upper = length;\n    Py_INCREF(upper);\n}\n \n \n Then, we may need to apply the defaults for  start  and  stop \u2014the default then for  start  is calculated as the upper bound when  step  is negative: \n \n if (self->start == Py_None) {\n    start = step_is_negative ? upper : lower;\n    Py_INCREF(start);\n}\n \n \n and  stop , the lower bound: \n \n if (self->stop == Py_None) {\n    stop = step_is_negative ? lower : upper;\n    Py_INCREF(stop);\n}\n \n \n Give your slices a descriptive name! \n You may find it useful to separate forming the slice from passing it to the  list.__getitem__  method ( that's what the square brackets do ). Even if you're not new to it, it keeps your code more readable so that others that may have to read your code can more readily understand what you're doing. \n However, you can't just assign some integers separated by colons to a variable. You need to use the slice object: \n last_nine_slice = slice(-9, None)\n \n The second argument,  None , is required, so that the first argument is interpreted as the  start  argument  otherwise it would be the  stop  argument . \n You can then pass the slice object to your sequence: \n >>> list(range(100))[last_nine_slice]\n[91, 92, 93, 94, 95, 96, 97, 98, 99]\n \n It's interesting that ranges also take slices: \n >>> range(100)[last_nine_slice]\nrange(91, 100)\n \n Memory Considerations: \n Since slices of Python lists create new objects in memory, another important function to be aware of is  itertools.islice . Typically you'll want to iterate over a slice, not just have it created statically in memory.  islice  is perfect for this. A caveat, it doesn't support negative arguments to  start ,  stop , or  step , so if that's an issue you may need to calculate indices or reverse the iterable in advance. \n length = 100\nlast_nine_iter = itertools.islice(list(range(length)), length-9, None, 1)\nlist_last_nine = list(last_nine_iter)\n \n and now: \n >>> list_last_nine\n[91, 92, 93, 94, 95, 96, 97, 98, 99]\n \n The fact that list slices make a copy is a feature of lists themselves. If you're slicing advanced objects like a Pandas DataFrame, it may return a view on the original, and not a copy. \n    ", "date_posted": "2022-04-30 17:20:06Z", "upvote": "\r\n            282\r\n        ", "accepted": "No", "user": {"stack_user_id": "241211", "name": "Michael", "reputation_score": "7,466"}, "answer_comments": [{"stack_answer_id": "24713353", "stack_answer_comment_id": "113402270", "comment_content": "I like the idea of naming slices. I would suggest ", "user_id": null}, {"stack_answer_id": "24713353", "stack_answer_comment_id": "113403311", "comment_content": "@WinEunuuchs2Unix that's great feedback - this is a standard Python behavior, but it could be made clearer in that sort of way, so I'll consider updating my material to include this semantic.", "user_id": null}]}, {"stack_answer_id": "509415", "answer_content": "\r\n And a couple of things that weren't immediately obvious to me when I first saw the slicing syntax: \n\n >>> x = [1,2,3,4,5,6]\n>>> x[::-1]\n[6,5,4,3,2,1]\n \n\n Easy way to reverse sequences! \n\n And if you wanted, for some reason, every second item in the reversed sequence: \n\n >>> x = [1,2,3,4,5,6]\n>>> x[::-2]\n[6,4,2]\n \n    ", "date_posted": "2009-02-03 23:15:02Z", "upvote": "\r\n            157\r\n        ", "accepted": "No", "user": {"stack_user_id": "7856", "name": "Dana", "reputation_score": "30.8k"}, "answer_comments": []}, {"stack_answer_id": "13005464", "answer_content": "\r\n In Python 2.7 \n\n Slicing in Python \n\n [a:b:c]\n\nlen = length of string, tuple or list\n\nc -- default is +1. The sign of c indicates forward or backward, absolute value of c indicates steps. Default is forward with step size 1. Positive means forward, negative means backward.\n\na --  When c is positive or blank, default is 0. When c is negative, default is -1.\n\nb --  When c is positive or blank, default is len. When c is negative, default is -(len+1).\n \n\n Understanding index assignment is very important. \n\n In forward direction, starts at 0 and ends at len-1\n\nIn backward direction, starts at -1 and ends at -len\n \n\n When you say [a:b:c], you are saying depending on the sign of c (forward or backward), start at a and end at b (excluding element at bth index). Use the indexing rule above and remember you will only find elements in this range: \n\n -len, -len+1, -len+2, ..., 0, 1, 2,3,4 , len -1\n \n\n But this range continues in both directions infinitely: \n\n ...,-len -2 ,-len-1,-len, -len+1, -len+2, ..., 0, 1, 2,3,4 , len -1, len, len +1, len+2 , ....\n \n\n For example: \n\n              0    1    2   3    4   5   6   7   8   9   10   11\n             a    s    t   r    i   n   g\n    -9  -8  -7   -6   -5  -4   -3  -2  -1\n \n\n If your choice of a, b, and c allows overlap with the range above as you traverse using rules for a,b,c above you will either get a list with elements (touched during traversal) or you will get an empty list. \n\n One last thing: if a and b are equal, then also you get an empty list: \n\n >>> l1\n[2, 3, 4]\n\n>>> l1[:]\n[2, 3, 4]\n\n>>> l1[::-1] # a default is -1 , b default is -(len+1)\n[4, 3, 2]\n\n>>> l1[:-4:-1] # a default is -1\n[4, 3, 2]\n\n>>> l1[:-3:-1] # a default is -1\n[4, 3]\n\n>>> l1[::] # c default is +1, so a default is 0, b default is len\n[2, 3, 4]\n\n>>> l1[::-1] # c is -1 , so a default is -1 and b default is -(len+1)\n[4, 3, 2]\n\n\n>>> l1[-100:-200:-1] # Interesting\n[]\n\n>>> l1[-1:-200:-1] # Interesting\n[4, 3, 2]\n\n\n>>> l1[-1:-1:1]\n[]\n\n\n>>> l1[-1:5:1] # Interesting\n[4]\n\n\n>>> l1[1:-7:1]\n[]\n\n>>> l1[1:-7:-1] # Interesting\n[3, 2]\n\n>>> l1[:-2:-2] # a default is -1, stop(b) at -2 , step(c) by 2 in reverse direction\n[4]\n \n    ", "date_posted": "2017-07-10 16:59:26Z", "upvote": "\r\n            109\r\n        ", "accepted": "No", "user": {"stack_user_id": "494074", "name": "Ankur Agarwal", "reputation_score": "22.2k"}, "answer_comments": [{"stack_answer_id": "13005464", "stack_answer_comment_id": "77001814", "comment_content": "another one interesting example: ", "user_id": null}]}, {"stack_answer_id": "7315935", "answer_content": "\r\n Found this great table at  http://wiki.python.org/moin/MovingToPythonFromOtherLanguages \n\n Python indexes and slices for a six-element list.\nIndexes enumerate the elements, slices enumerate the spaces between the elements.\n\nIndex from rear:    -6  -5  -4  -3  -2  -1      a=[0,1,2,3,4,5]    a[1:]==[1,2,3,4,5]\nIndex from front:    0   1   2   3   4   5      len(a)==6          a[:5]==[0,1,2,3,4]\n                   +---+---+---+---+---+---+    a[0]==0            a[:-2]==[0,1,2,3]\n                   | a | b | c | d | e | f |    a[5]==5            a[1:2]==[1]\n                   +---+---+---+---+---+---+    a[-1]==5           a[1:-1]==[1,2,3,4]\nSlice from front:  :   1   2   3   4   5   :    a[-2]==4\nSlice from rear:   :  -5  -4  -3  -2  -1   :\n                                                b=a[:]\n                                                b==[0,1,2,3,4,5] (shallow copy of a) \n    ", "date_posted": "2011-09-06 06:50:08Z", "upvote": "\r\n            101\r\n        ", "accepted": "No", "user": {"stack_user_id": "43769", "name": "AdrianoFerrari", "reputation_score": "2,110"}, "answer_comments": []}, {"stack_answer_id": "567094", "answer_content": "\r\n After using it a bit I realise that the simplest description is that it is exactly the same as the arguments in a  for  loop... \n\n (from:to:step)\n \n\n Any of them are optional: \n\n (:to:step)\n(from::step)\n(from:to)\n \n\n Then the negative indexing just needs you to add the length of the string to the negative indices to understand it. \n\n This works for me anyway... \n    ", "date_posted": "2019-01-02 16:40:20Z", "upvote": "\r\n            70\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "9923354", "answer_content": "\r\n I find it easier to remember how it works, and then I can figure out any specific start/stop/step combination. \n\n It's instructive to understand  range()  first: \n\n def range(start=0, stop, step=1):  # Illegal syntax, but that's the effect\n    i = start\n    while (i < stop if step > 0 else i > stop):\n        yield i\n        i += step\n \n\n Begin from  start , increment by  step , do not reach  stop .  Very simple. \n\n The thing to remember about negative step is that  stop  is always the excluded end, whether it's higher or lower. If you want same slice in opposite order, it's much cleaner to do the reversal separately: e.g.  'abcde'[1:-2][::-1]  slices off one char from left, two from right, then reverses. (See also  reversed() .) \n\n Sequence slicing is same, except it first normalizes negative indexes, and it can never go outside the sequence: \n\n TODO : The code below had a bug with \"never go outside the sequence\" when abs(step)>1; I  think  I patched it to be correct, but it's hard to understand. \n\n def this_is_how_slicing_works(seq, start=None, stop=None, step=1):\n    if start is None:\n        start = (0 if step > 0 else len(seq)-1)\n    elif start < 0:\n        start += len(seq)\n    if not 0 <= start < len(seq):  # clip if still outside bounds\n        start = (0 if step > 0 else len(seq)-1)\n    if stop is None:\n        stop = (len(seq) if step > 0 else -1)  # really -1, not last element\n    elif stop < 0:\n        stop += len(seq)\n    for i in range(start, stop, step):\n        if 0 <= i < len(seq):\n            yield seq[i]\n \n\n Don't worry about the  is None  details - just remember that omitting  start  and/or  stop  always does the right thing to give you the whole sequence. \n\n Normalizing negative indexes first allows start and/or stop to be counted from the end independently:  'abcde'[1:-2] == 'abcde'[1:3] == 'bc'  despite  range(1,-2) == [] .\nThe normalization is sometimes thought of as \"modulo the length\", but note it adds the length just once: e.g.  'abcde'[-53:42]  is just the whole string. \n    ", "date_posted": "2019-01-02 16:46:18Z", "upvote": "\r\n            54\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "9923354", "stack_answer_comment_id": "67894582", "comment_content": "The ", "user_id": null}, {"stack_answer_id": "9923354", "stack_answer_comment_id": "67913261", "comment_content": "@Eastsun Oops, you're right!  A clearer case: ", "user_id": null}]}, {"stack_answer_id": "522212", "answer_content": "\r\n I use the \"an index points between elements\" method of thinking about it myself, but one way of describing it which sometimes helps others get it is this: \n\n mylist[X:Y]\n \n\n X is the index of the first element you want. \nY is the index of the first element you  don't  want. \n    ", "date_posted": "2009-02-06 21:16:28Z", "upvote": "\r\n            43\r\n        ", "accepted": "No", "user": {"stack_user_id": "13498", "name": "Steve Losh", "reputation_score": "19.4k"}, "answer_comments": []}, {"stack_answer_id": "14682039", "answer_content": "\r\n Index:\n      ------------>\n  0   1   2   3   4\n+---+---+---+---+---+\n| a | b | c | d | e |\n+---+---+---+---+---+\n  0  -4  -3  -2  -1\n      <------------\n\nSlice:\n    <---------------|\n|--------------->\n:   1   2   3   4   :\n+---+---+---+---+---+\n| a | b | c | d | e |\n+---+---+---+---+---+\n:  -4  -3  -2  -1   :\n|--------------->\n    <---------------|\n \n\n I hope this will help you to model the list in Python. \n\n Reference:  http://wiki.python.org/moin/MovingToPythonFromOtherLanguages \n    ", "date_posted": "2017-02-11 19:56:15Z", "upvote": "\r\n            43\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "29237560", "answer_content": "\r\n This is how I teach slices to newbies: \n\n Understanding the difference between indexing and slicing: \n\n Wiki Python has this amazing picture which clearly distinguishes indexing and slicing. \n\n \n\n It is a list with six elements in it. To understand slicing better, consider that list as a set of six boxes placed together. Each box has an alphabet in it. \n\n Indexing is like dealing with the contents of box. You can check contents of any box. But you can't check the contents of multiple boxes at once. You can even replace the contents of the box. But you can't place two balls in one box or replace two balls at a time. \n\n In [122]: alpha = ['a', 'b', 'c', 'd', 'e', 'f']\n\nIn [123]: alpha\nOut[123]: ['a', 'b', 'c', 'd', 'e', 'f']\n\nIn [124]: alpha[0]\nOut[124]: 'a'\n\nIn [127]: alpha[0] = 'A'\n\nIn [128]: alpha\nOut[128]: ['A', 'b', 'c', 'd', 'e', 'f']\n\nIn [129]: alpha[0,1]\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n<ipython-input-129-c7eb16585371> in <module>()\n----> 1 alpha[0,1]\n\nTypeError: list indices must be integers, not tuple\n \n\n Slicing is like dealing with boxes themselves. You can pick up the first box and place it on another table. To pick up the box, all you need to know is the position of beginning and ending of the box. \n\n You can even pick up the first three boxes or the last two boxes or all boxes between 1 and 4. So, you can pick any set of boxes if you know the beginning and ending. These positions are called start and stop positions. \n\n The interesting thing is that you can replace multiple boxes at once. Also you can place multiple boxes wherever you like. \n\n In [130]: alpha[0:1]\nOut[130]: ['A']\n\nIn [131]: alpha[0:1] = 'a'\n\nIn [132]: alpha\nOut[132]: ['a', 'b', 'c', 'd', 'e', 'f']\n\nIn [133]: alpha[0:2] = ['A', 'B']\n\nIn [134]: alpha\nOut[134]: ['A', 'B', 'c', 'd', 'e', 'f']\n\nIn [135]: alpha[2:2] = ['x', 'xx']\n\nIn [136]: alpha\nOut[136]: ['A', 'B', 'x', 'xx', 'c', 'd', 'e', 'f']\n \n\n Slicing With Step: \n\n Till now you have picked boxes continuously. But sometimes you need to pick up discretely. For example, you can pick up every second box. You can even pick up every third box from the end. This value is called step size. This represents the gap between your successive pickups. The step size should be positive if You are picking boxes from the beginning to end and vice versa. \n\n In [137]: alpha = ['a', 'b', 'c', 'd', 'e', 'f']\n\nIn [142]: alpha[1:5:2]\nOut[142]: ['b', 'd']\n\nIn [143]: alpha[-1:-5:-2]\nOut[143]: ['f', 'd']\n\nIn [144]: alpha[1:5:-2]\nOut[144]: []\n\nIn [145]: alpha[-1:-5:2]\nOut[145]: []\n \n\n How Python Figures Out Missing Parameters: \n\n When slicing, if you leave out any parameter, Python tries to figure it out automatically. \n\n If you check the source code of  CPython , you will find a function called PySlice_GetIndicesEx() which figures out indices to a slice for any given parameters. Here is the logical equivalent code in Python. \n\n This function takes a Python object and optional parameters for slicing and returns the start, stop, step, and slice length for the requested slice. \n\n def py_slice_get_indices_ex(obj, start=None, stop=None, step=None):\n\n    length = len(obj)\n\n    if step is None:\n        step = 1\n    if step == 0:\n        raise Exception(\"Step cannot be zero.\")\n\n    if start is None:\n        start = 0 if step > 0 else length - 1\n    else:\n        if start < 0:\n            start += length\n        if start < 0:\n            start = 0 if step > 0 else -1\n        if start >= length:\n            start = length if step > 0 else length - 1\n\n    if stop is None:\n        stop = length if step > 0 else -1\n    else:\n        if stop < 0:\n            stop += length\n        if stop < 0:\n            stop = 0 if step > 0 else -1\n        if stop >= length:\n            stop = length if step > 0 else length - 1\n\n    if (step < 0 and stop >= start) or (step > 0 and start >= stop):\n        slice_length = 0\n    elif step < 0:\n        slice_length = (stop - start + 1)/(step) + 1\n    else:\n        slice_length = (stop - start - 1)/(step) + 1\n\n    return (start, stop, step, slice_length)\n \n\n This is the intelligence that is present behind slices. Since Python has an built-in function called slice, you can pass some parameters and check how smartly it calculates missing parameters. \n\n In [21]: alpha = ['a', 'b', 'c', 'd', 'e', 'f']\n\nIn [22]: s = slice(None, None, None)\n\nIn [23]: s\nOut[23]: slice(None, None, None)\n\nIn [24]: s.indices(len(alpha))\nOut[24]: (0, 6, 1)\n\nIn [25]: range(*s.indices(len(alpha)))\nOut[25]: [0, 1, 2, 3, 4, 5]\n\nIn [26]: s = slice(None, None, -1)\n\nIn [27]: range(*s.indices(len(alpha)))\nOut[27]: [5, 4, 3, 2, 1, 0]\n\nIn [28]: s = slice(None, 3, -1)\n\nIn [29]: range(*s.indices(len(alpha)))\nOut[29]: [5, 4]\n \n\n Note:  This post was originally written in my blog,  The Intelligence Behind Python Slices . \n    ", "date_posted": "2019-09-26 07:58:01Z", "upvote": "\r\n            39\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "29237560", "stack_answer_comment_id": "125358697", "comment_content": "At last, I found here some explanation on why the slicing parameters ", "user_id": null}]}, {"stack_answer_id": "16267103", "answer_content": "\r\n Python slicing notation: \n\n a[start:end:step]\n \n\n \n For  start  and  end , negative values are interpreted as being relative to the end of the sequence. \n Positive indices for  end  indicate the position  after  the last element to be included. \n Blank values are defaulted as follows:  [+0:-0:1] . \n Using a negative step reverses the interpretation of  start  and  end \n \n\n The notation extends to (numpy) matrices and multidimensional arrays.  For example, to slice entire columns you can use: \n\n m[::,0:2:] ## slice the first two columns\n \n\n Slices hold references, not copies, of the array elements.  If you want to make a separate copy an array, you can use  deepcopy() . \n    ", "date_posted": "2017-05-23 12:34:44Z", "upvote": "\r\n            38\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}, {"stack_answer_id": "15824717", "answer_content": "\r\n You can also use slice assignment to remove one or more elements from a list: \n\n r = [1, 'blah', 9, 8, 2, 3, 4]\n>>> r[1:4] = []\n>>> r\n[1, 2, 3, 4]\n \n    ", "date_posted": "2013-04-19 16:28:16Z", "upvote": "\r\n            34\r\n        ", "accepted": "No", "user": {"stack_user_id": "1355221", "name": "dansalmo", "reputation_score": "11.1k"}, "answer_comments": []}, {"stack_answer_id": "9827284", "answer_content": "\r\n This is just for some extra info...\nConsider the list below  \n\n >>> l=[12,23,345,456,67,7,945,467]\n \n\n Few other tricks for reversing the list: \n\n >>> l[len(l):-len(l)-1:-1]\n[467, 945, 7, 67, 456, 345, 23, 12]\n\n>>> l[:-len(l)-1:-1]\n[467, 945, 7, 67, 456, 345, 23, 12]\n\n>>> l[len(l)::-1]\n[467, 945, 7, 67, 456, 345, 23, 12]\n\n>>> l[::-1]\n[467, 945, 7, 67, 456, 345, 23, 12]\n\n>>> l[-1:-len(l)-1:-1]\n[467, 945, 7, 67, 456, 345, 23, 12]\n \n    ", "date_posted": "2019-05-08 08:35:55Z", "upvote": "\r\n            33\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": []}, {"stack_answer_id": "41548529", "answer_content": "\r\n 1. Slice Notation \n\n To make it simple, remember  slice has only one form\uff1a \n\n s[start:end:step]\n \n\n and here is how it works: \n\n \n s : an object that can be sliced \n start : first index to start iteration \n end : last index,  NOTE that  end  index will not be included in the resulted slice \n step : pick element every  step  index \n \n\n Another import thing:  all  start , end ,  step  can be omitted!  And if they are omitted, their default value will be used:  0 , len(s) , 1  accordingly. \n\n So possible variations are: \n\n # Mostly used variations\ns[start:end]\ns[start:]\ns[:end]\n\n# Step-related variations\ns[:end:step]\ns[start::step]\ns[::step]\n\n# Make a copy\ns[:]\n \n\n NOTE: If  start >= end  (considering only when  step>0 ), Python will return a empty slice  [] . \n\n 2. Pitfalls \n\n The above part explains the core features on how slice works, and it will work on most occasions. However, there can be pitfalls you should watch out, and this part explains them. \n\n Negative indexes \n\n The very first thing that confuses Python learners is that  an index can be negative! \nDon't panic:  a negative index means count backwards. \n\n For example: \n\n s[-5:]    # Start at the 5th index from the end of array,\n          # thus returning the last 5 elements.\ns[:-5]    # Start at index 0, and end until the 5th index from end of array,\n          # thus returning s[0:len(s)-5].\n \n\n Negative step \n\n Making things more confusing is that  step  can be negative too! \n\n A negative step means iterate the array backwards: from the end to start, with the end index included, and the start index excluded from the result. \n\n NOTE : when step is negative, the default value for  start  is  len(s)  (while  end  does not equal to  0 , because  s[::-1]  contains  s[0] ). For example: \n\n s[::-1]            # Reversed slice\ns[len(s)::-1]      # The same as above, reversed slice\ns[0:len(s):-1]     # Empty list\n \n\n Out of range error? \n\n Be surprised:  slice does not raise an IndexError when the index is out of range! \n\n If the index is out of range, Python will try its best to set the index to  0  or  len(s)  according to the situation. For example: \n\n s[:len(s)+5]      # The same as s[:len(s)]\ns[-len(s)-5::]    # The same as s[0:]\ns[len(s)+5::-1]   # The same as s[len(s)::-1], and the same as s[::-1]\n \n\n 3. Examples \n\n Let's finish this answer with examples, explaining everything we have discussed: \n\n # Create our array for demonstration\nIn [1]: s = [i for i in range(10)]\n\nIn [2]: s\nOut[2]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\nIn [3]: s[2:]   # From index 2 to last index\nOut[3]: [2, 3, 4, 5, 6, 7, 8, 9]\n\nIn [4]: s[:8]   # From index 0 up to index 8\nOut[4]: [0, 1, 2, 3, 4, 5, 6, 7]\n\nIn [5]: s[4:7]  # From index 4 (included) up to index 7(excluded)\nOut[5]: [4, 5, 6]\n\nIn [6]: s[:-2]  # Up to second last index (negative index)\nOut[6]: [0, 1, 2, 3, 4, 5, 6, 7]\n\nIn [7]: s[-2:]  # From second last index (negative index)\nOut[7]: [8, 9]\n\nIn [8]: s[::-1] # From last to first in reverse order (negative step)\nOut[8]: [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n\nIn [9]: s[::-2] # All odd numbers in reversed order\nOut[9]: [9, 7, 5, 3, 1]\n\nIn [11]: s[-2::-2] # All even numbers in reversed order\nOut[11]: [8, 6, 4, 2, 0]\n\nIn [12]: s[3:15]   # End is out of range, and Python will set it to len(s).\nOut[12]: [3, 4, 5, 6, 7, 8, 9]\n\nIn [14]: s[5:1]    # Start > end; return empty list\nOut[14]: []\n\nIn [15]: s[11]     # Access index 11 (greater than len(s)) will raise an IndexError\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\n<ipython-input-15-79ffc22473a3> in <module>()\n----> 1 s[11]\n\nIndexError: list index out of range\n \n    ", "date_posted": "2019-09-26 08:04:23Z", "upvote": "\r\n            30\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "20443928", "answer_content": "\r\n As a general rule, writing code with a lot of hardcoded index values leads to a readability\nand maintenance mess. For example, if you come back to the code a year later, you\u2019ll\nlook at it and wonder what you were thinking when you wrote it. The solution shown\nis simply a way of more clearly stating what your code is actually doing.\nIn general, the built-in slice() creates a slice object that can be used anywhere a slice\nis allowed. For example: \n\n >>> items = [0, 1, 2, 3, 4, 5, 6]\n>>> a = slice(2, 4)\n>>> items[2:4]\n[2, 3]\n>>> items[a]\n[2, 3]\n>>> items[a] = [10,11]\n>>> items\n[0, 1, 10, 11, 4, 5, 6]\n>>> del items[a]\n>>> items\n[0, 1, 4, 5, 6]\n \n\n If you have a slice instance s, you can get more information about it by looking at its\ns.start, s.stop, and s.step attributes, respectively. For example: \n\n \n >>> a = slice(10, 50, 2)\n>>> a.start\n10\n>>> a.stop\n50\n>>> a.step\n2\n>>>\n \n \n    ", "date_posted": "2013-12-07 16:52:45Z", "upvote": "\r\n            29\r\n        ", "accepted": "No", "user": {"stack_user_id": "3048166", "name": "Python_Dude", "reputation_score": "507"}, "answer_comments": []}, {"stack_answer_id": "42522149", "answer_content": "\r\n The previous answers don't discuss multi-dimensional array slicing which is possible using the famous  NumPy  package: \n\n Slicing can also be applied to multi-dimensional arrays. \n\n # Here, a is a NumPy array\n\n>>> a\narray([[ 1,  2,  3,  4],\n       [ 5,  6,  7,  8],\n       [ 9, 10, 11, 12]])\n>>> a[:2, 0:3:2]\narray([[1, 3],\n       [5, 7]])\n \n\n The \" :2 \" before the comma operates on the first dimension and the \" 0:3:2 \" after the comma operates on the second dimension. \n    ", "date_posted": "2019-09-26 08:08:54Z", "upvote": "\r\n            29\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "42522149", "stack_answer_comment_id": "100958827", "comment_content": "Just a friendly reminder that you cannot do this on Python ", "user_id": null}]}, {"stack_answer_id": "63047385", "answer_content": "\r\n The rules of slicing are as follows: \n [lower bound : upper bound : step size]\n \n I-  Convert  upper bound   and  lower bound  into common signs. \n II-  Then check if the  step size  is a  positive  or a  negative  value. \n (i)  If the  step size  is a  positive value ,  upper bound  should be  greater than   lower bound , otherwise  empty string  is printed.  For example : \n s=\"Welcome\"\ns1=s[0:3:1]\nprint(s1)\n \n The output: \n Wel\n \n However if we run the following code: \n s=\"Welcome\"\ns1=s[3:0:1]\nprint(s1)\n \n It will return an  empty string . \n (ii)  If the  step size  if a  negative value ,  upper bound  should be  lesser than   lower bound , otherwise  empty string  will be printed. For example: \n s=\"Welcome\"\ns1=s[3:0:-1]\nprint(s1)\n \n The output: \n cle\n \n But if we run the following code: \n s=\"Welcome\"\ns1=s[0:5:-1]\nprint(s1)\n \n The output will be an  empty string . \n Thus in the code: \n str = 'abcd'\nl = len(str)\nstr2 = str[l-1:0:-1]    #str[3:0:-1] \nprint(str2)\nstr2 = str[l-1:-1:-1]    #str[3:-1:-1]\nprint(str2)\n \n In the first  str2=str[l-1:0:-1] , the  upper bound  is  lesser than  the  lower bound , thus  dcb  is printed. \n However in  str2=str[l-1:-1:-1] , the  upper bound  is  not less than  the  lower bound  (upon converting  lower bound  into  negative value  which is  -1 : since  index  of last element is -1 as well as 3). \n    ", "date_posted": "2020-07-23 05:22:23Z", "upvote": "\r\n            20\r\n        ", "accepted": "No", "user": {"stack_user_id": "13737990", "name": "Anshika Singh", "reputation_score": "866"}, "answer_comments": []}, {"stack_answer_id": "47765245", "answer_content": "\r\n In my opinion, you will understand and memorize better the Python string slicing notation if you look at it the following way (read on). \n\n Let's work with the following string ... \n\n azString = \"abcdefghijklmnopqrstuvwxyz\"\n \n\n For those who don't know, you can create any substring from  azString  using the notation  azString[x:y] \n\n Coming from other programming languages, that's when the common sense gets compromised. What are x and y? \n\n I had to sit down and run several scenarios in my quest for a memorization technique that will help me remember what x and y are and help me slice strings properly at the first attempt. \n\n My conclusion is that x and y should be seen as the boundary indexes that are surrounding the strings that we want to extra. So we should see the expression as  azString[index1, index2]  or even more clearer as  azString[index_of_first_character, index_after_the_last_character] . \n\n Here is an example visualization of that ... \n\n Letters   a b c d e f g h i j ...\n         \u2191 \u2191 \u2191 \u2191 \u2191 \u2191 \u2191 \u2191 \u2191 \u2191\n             \u250a           \u250a\nIndexes  0 1 2 3 4 5 6 7 8 9 ...\n             \u250a           \u250a\ncdefgh    index1       index2\n \n\n So all you have to do is setting index1 and index2 to the values that will surround the desired substring. For instance, to get the substring \"cdefgh\", you can use  azString[2:8] , because the index on the left side of \"c\" is 2 and the one on the right size of \"h\" is 8. \n\n Remember that we are setting the boundaries. And those boundaries are the positions where you could place some brackets that will be wrapped around the substring like this ... \n\n a b  [  c d e f g h  ]  i j \n\n That trick works all the time and is easy to memorize. \n    ", "date_posted": "2020-01-08 16:12:41Z", "upvote": "\r\n            18\r\n        ", "accepted": "No", "user": {"stack_user_id": "609862", "name": "asiby", "reputation_score": "2,909"}, "answer_comments": []}, {"stack_answer_id": "57628026", "answer_content": "\r\n I personally think about it like a  for  loop: \n\n a[start:end:step]\n# for(i = start; i < end; i += step)\n \n\n Also, note that negative values for  start  and  end  are relative to the end of the list and computed in the example above by  given_index + a.shape[0] . \n    ", "date_posted": "2020-01-15 12:29:43Z", "upvote": "\r\n            18\r\n        ", "accepted": "No", "user": {"stack_user_id": "806202", "name": "Arsen Khachaturyan", "reputation_score": "7,445"}, "answer_comments": []}, {"stack_answer_id": "26442691", "answer_content": "\r\n #!/usr/bin/env python\n\ndef slicegraphical(s, lista):\n\n    if len(s) > 9:\n        print \"\"\"Enter a string of maximum 9 characters,\n    so the printig would looki nice\"\"\"\n        return 0;\n    # print \" \",\n    print '  '+'+---' * len(s) +'+'\n    print ' ',\n    for letter in s:\n        print '| {}'.format(letter),\n    print '|'\n    print \" \",; print '+---' * len(s) +'+'\n\n    print \" \",\n    for letter in range(len(s) +1):\n        print '{}  '.format(letter),\n    print \"\"\n    for letter in range(-1*(len(s)), 0):\n        print ' {}'.format(letter),\n    print ''\n    print ''\n\n\n    for triada in lista:\n        if len(triada) == 3:\n            if triada[0]==None and triada[1] == None and triada[2] == None:\n                # 000\n                print s+'[   :   :   ]' +' = ', s[triada[0]:triada[1]:triada[2]]\n            elif triada[0] == None and triada[1] == None and triada[2] != None:\n                # 001\n                print s+'[   :   :{0:2d} ]'.format(triada[2], '','') +' = ', s[triada[0]:triada[1]:triada[2]]\n            elif triada[0] == None and triada[1] != None and triada[2] == None:\n                # 010\n                print s+'[   :{0:2d} :   ]'.format(triada[1]) +' = ', s[triada[0]:triada[1]:triada[2]]\n            elif triada[0] == None and triada[1] != None and triada[2] != None:\n                # 011\n                print s+'[   :{0:2d} :{1:2d} ]'.format(triada[1], triada[2]) +' = ', s[triada[0]:triada[1]:triada[2]]\n            elif triada[0] != None and triada[1] == None and triada[2] == None:\n                # 100\n                print s+'[{0:2d} :   :   ]'.format(triada[0]) +' = ', s[triada[0]:triada[1]:triada[2]]\n            elif triada[0] != None and triada[1] == None and triada[2] != None:\n                # 101\n                print s+'[{0:2d} :   :{1:2d} ]'.format(triada[0], triada[2]) +' = ', s[triada[0]:triada[1]:triada[2]]\n            elif triada[0] != None and triada[1] != None and triada[2] == None:\n                # 110\n                print s+'[{0:2d} :{1:2d} :   ]'.format(triada[0], triada[1]) +' = ', s[triada[0]:triada[1]:triada[2]]\n            elif triada[0] != None and triada[1] != None and triada[2] != None:\n                # 111\n                print s+'[{0:2d} :{1:2d} :{2:2d} ]'.format(triada[0], triada[1], triada[2]) +' = ', s[triada[0]:triada[1]:triada[2]]\n\n        elif len(triada) == 2:\n            if triada[0] == None and triada[1] == None:\n                # 00\n                print s+'[   :   ]    ' + ' = ', s[triada[0]:triada[1]]\n            elif triada[0] == None and triada[1] != None:\n                # 01\n                print s+'[   :{0:2d} ]    '.format(triada[1]) + ' = ', s[triada[0]:triada[1]]\n            elif triada[0] != None and triada[1] == None:\n                # 10\n                print s+'[{0:2d} :   ]    '.format(triada[0]) + ' = ', s[triada[0]:triada[1]]\n            elif triada[0] != None and triada[1] != None:\n                # 11\n                print s+'[{0:2d} :{1:2d} ]    '.format(triada[0],triada[1]) + ' = ', s[triada[0]:triada[1]]\n\n        elif len(triada) == 1:\n            print s+'[{0:2d} ]        '.format(triada[0]) + ' = ', s[triada[0]]\n\n\nif __name__ == '__main__':\n    # Change \"s\" to what ever string you like, make it 9 characters for\n    # better representation.\n    s = 'COMPUTERS'\n\n    # add to this list different lists to experement with indexes\n    # to represent ex. s[::], use s[None, None,None], otherwise you get an error\n    # for s[2:] use s[2:None]\n\n    lista = [[4,7],[2,5,2],[-5,1,-1],[4],[-4,-6,-1], [2,-3,1],[2,-3,-1], [None,None,-1],[-5,None],[-5,0,-1],[-5,None,-1],[-1,1,-2]]\n\n    slicegraphical(s, lista)\n \n\n You can run this script and experiment with it, below is some samples that I got from the script. \n\n   +---+---+---+---+---+---+---+---+---+\n  | C | O | M | P | U | T | E | R | S |\n  +---+---+---+---+---+---+---+---+---+\n  0   1   2   3   4   5   6   7   8   9   \n -9  -8  -7  -6  -5  -4  -3  -2  -1 \n\nCOMPUTERS[ 4 : 7 ]     =  UTE\nCOMPUTERS[ 2 : 5 : 2 ] =  MU\nCOMPUTERS[-5 : 1 :-1 ] =  UPM\nCOMPUTERS[ 4 ]         =  U\nCOMPUTERS[-4 :-6 :-1 ] =  TU\nCOMPUTERS[ 2 :-3 : 1 ] =  MPUT\nCOMPUTERS[ 2 :-3 :-1 ] =  \nCOMPUTERS[   :   :-1 ] =  SRETUPMOC\nCOMPUTERS[-5 :   ]     =  UTERS\nCOMPUTERS[-5 : 0 :-1 ] =  UPMO\nCOMPUTERS[-5 :   :-1 ] =  UPMOC\nCOMPUTERS[-1 : 1 :-2 ] =  SEUM\n[Finished in 0.9s]\n \n\n When using a negative step, notice that the answer is shifted to the right by 1. \n    ", "date_posted": "2014-10-18 17:40:45Z", "upvote": "\r\n            17\r\n        ", "accepted": "No", "user": {"stack_user_id": "1471004", "name": "mahmoh", "reputation_score": "792"}, "answer_comments": []}, {"stack_answer_id": "37455246", "answer_content": "\r\n My brain seems happy to accept that  lst[start:end]  contains the  start -th item. I might even say that it is a 'natural assumption'. \n\n But occasionally a doubt creeps in and my brain asks for reassurance that it does not contain the  end -th element. \n\n In these moments I rely on this simple theorem: \n\n for any n,    lst = lst[:n] + lst[n:]\n \n\n This pretty property tells me that  lst[start:end]  does not contain the  end -th item because it is in  lst[end:] . \n\n Note that this theorem is true for any  n  at all. For example, you can check that \n\n lst = range(10)\nlst[:-42] + lst[-42:] == lst\n \n\n returns  True . \n    ", "date_posted": "2016-05-26 08:16:54Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "1243435", "name": "Robert", "reputation_score": "1,402"}, "answer_comments": []}, {"stack_answer_id": "46040689", "answer_content": "\r\n In Python, the most basic form for slicing is the following: \n\n l[start:end]\n \n\n where  l  is some collection,  start  is an inclusive index, and  end  is an exclusive index. \n\n In [1]: l = list(range(10))\n\nIn [2]: l[:5] # First five elements\nOut[2]: [0, 1, 2, 3, 4]\n\nIn [3]: l[-5:] # Last five elements\nOut[3]: [5, 6, 7, 8, 9]\n \n\n When slicing from the start, you can omit the zero index, and when slicing to the end, you can omit the final index since it is redundant, so do not be verbose: \n\n In [5]: l[:3] == l[0:3]\nOut[5]: True\n\nIn [6]: l[7:] == l[7:len(l)]\nOut[6]: True\n \n\n Negative integers are useful when doing offsets relative to the end of a collection: \n\n In [7]: l[:-1] # Include all elements but the last one\nOut[7]: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n\nIn [8]: l[-3:] # Take the last three elements\nOut[8]: [7, 8, 9]\n \n\n It is possible to provide indices that are out of bounds when slicing such as: \n\n In [9]: l[:20] # 20 is out of index bounds, and l[20] will raise an IndexError exception\nOut[9]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\nIn [11]: l[-20:] # -20 is out of index bounds, and l[-20] will raise an IndexError exception\nOut[11]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n \n\n Keep in mind that the result of slicing a collection is a whole new collection. In addition, when using slice notation in assignments, the length of the slice assignments do not need to be the same. The values before and after the assigned slice will be kept, and the collection will shrink or grow to contain the new values: \n\n In [16]: l[2:6] = list('abc') # Assigning fewer elements than the ones contained in the sliced collection l[2:6]\n\nIn [17]: l\nOut[17]: [0, 1, 'a', 'b', 'c', 6, 7, 8, 9]\n\nIn [18]: l[2:5] = list('hello') # Assigning more elements than the ones contained in the sliced collection l [2:5]\n\nIn [19]: l\nOut[19]: [0, 1, 'h', 'e', 'l', 'l', 'o', 6, 7, 8, 9]\n \n\n If you omit the start and end index, you will make a copy of the collection: \n\n In [14]: l_copy = l[:]\n\nIn [15]: l == l_copy and l is not l_copy\nOut[15]: True\n \n\n If the start and end indexes are omitted when performing an assignment operation, the entire content of the collection will be replaced with a copy of what is referenced: \n\n In [20]: l[:] = list('hello...')\n\nIn [21]: l\nOut[21]: ['h', 'e', 'l', 'l', 'o', '.', '.', '.']\n \n\n Besides basic slicing, it is also possible to apply the following notation: \n\n l[start:end:step]\n \n\n where  l  is a collection,  start  is an inclusive index,  end  is an exclusive index, and  step  is a stride that can be used to take every  nth  item in  l . \n\n In [22]: l = list(range(10))\n\nIn [23]: l[::2] # Take the elements which indexes are even\nOut[23]: [0, 2, 4, 6, 8]\n\nIn [24]: l[1::2] # Take the elements which indexes are odd\nOut[24]: [1, 3, 5, 7, 9]\n \n\n Using  step  provides a useful trick to reverse a collection in Python: \n\n In [25]: l[::-1]\nOut[25]: [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n \n\n It is also possible to use negative integers for  step  as the following example: \n\n In[28]:  l[::-2]\nOut[28]: [9, 7, 5, 3, 1]\n \n\n However, using a negative value for  step  could become very confusing. Moreover, in order to be  Pythonic , you should avoid using  start ,  end , and  step  in a single slice. In case this is required, consider doing this in two assignments (one to slice, and the other to stride). \n\n In [29]: l = l[::2] # This step is for striding\n\nIn [30]: l\nOut[30]: [0, 2, 4, 6, 8]\n\nIn [31]: l = l[1:-1] # This step is for slicing\n\nIn [32]: l\nOut[32]: [2, 4, 6]\n \n    ", "date_posted": "2019-09-26 08:16:53Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "49647978", "answer_content": "\r\n I want to add one  Hello, World!  example that explains the basics of slices for the very beginners. It helped me a lot. \n\n Let's have a list with six values  ['P', 'Y', 'T', 'H', 'O', 'N'] : \n\n +---+---+---+---+---+---+\n| P | Y | T | H | O | N |\n+---+---+---+---+---+---+\n  0   1   2   3   4   5\n \n\n Now the simplest slices of that list are its sublists. The notation is  [<index>:<index>]  and the key is to read it like this: \n\n [ start cutting before this index : end cutting before this index ]\n \n\n Now if you make a slice  [2:5]  of the list above, this will happen: \n\n         |           |\n+---+---|---+---+---|---+\n| P | Y | T | H | O | N |\n+---+---|---+---+---|---+\n  0   1 | 2   3   4 | 5\n \n\n You made a cut  before  the element with index  2  and another cut  before  the element with index  5 . So the result will be a slice between those two cuts, a list  ['T', 'H', 'O'] . \n    ", "date_posted": "2019-09-26 08:23:54Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "46614773", "answer_content": "\r\n Most of the previous answers clears up questions about slice notation. \n\n The extended indexing syntax used for slicing is  aList[start:stop:step] , and basic examples are: \n\n : \n\n More slicing examples:  15 Extended Slices \n    ", "date_posted": "2019-09-26 08:19:02Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "45370737", "answer_content": "\r\n The below is the example of an index of a string: \n\n  +---+---+---+---+---+\n | H | e | l | p | A |\n +---+---+---+---+---+\n 0   1   2   3   4   5\n-5  -4  -3  -2  -1\n\nstr=\"Name string\"\n \n\n Slicing example: [start:end:step] \n\n str[start:end] # Items start through end-1\nstr[start:]    # Items start through the rest of the array\nstr[:end]      # Items from the beginning through end-1\nstr[:]         # A copy of the whole array\n \n\n Below is the example usage: \n\n print str[0] = N\nprint str[0:2] = Na\nprint str[0:7] = Name st\nprint str[0:7:2] = Nm t\nprint str[0:-1:2] = Nm ti\n \n    ", "date_posted": "2019-09-26 08:10:54Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "47880987", "answer_content": "\r\n If you feel negative indices in slicing is confusing, here's a very easy way to think about it: just replace the negative index with  len - index . So for example, replace -3 with  len(list) - 3 . \n\n The best way to illustrate what slicing does internally is just show it in code that implements this operation: \n\n def slice(list, start = None, end = None, step = 1):\n  # Take care of missing start/end parameters\n  start = 0 if start is None else start\n  end = len(list) if end is None else end\n\n  # Take care of negative start/end parameters\n  start = len(list) + start if start < 0 else start\n  end = len(list) + end if end < 0 else end\n\n  # Now just execute a for-loop with start, end and step\n  return [list[i] for i in range(start, end, step)]\n \n    ", "date_posted": "2019-09-26 08:22:50Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "51479594", "answer_content": "\r\n The basic slicing technique is to define the starting point, the stopping point, and the step size\u2014also known as stride. \n First, we will create a list of values to use in our slicing. \n Create two lists to slice. The first is a numeric list from 1 to 9 (List A). The second is also a numeric list, from 0 to 9 (List B): \n A = list(range(1, 10, 1)) # Start, stop, and step\nB = list(range(9))\n\nprint(\"This is List A:\", A)\nprint(\"This is List B:\", B)\n \n Index the number 3 from A and the number 6 from B. \n print(A[2])\nprint(B[6])\n \n Basic Slicing \n Extended indexing syntax used for slicing is  aList[start:stop:step] . The start argument and the step argument both default to  None \u2014the only required argument is stop. Did you notice this is similar to how range was used to define lists A and B? This is because the slice object represents the set of indices specified by  range(start, stop, step) . \n As you can see, defining only stop returns one element. Since the start defaults to none, this translates into retrieving only one element. \n It is important to note, the first element is index 0,  not  index 1. This is why we are using 2 lists for this exercise. List A's elements are numbered according to the ordinal position (the first element is 1, the second element is 2, etc.) while List B's elements are the numbers that would be used to index them ( [0]  for the first element, 0, etc.). \n With extended indexing syntax, we retrieve a range of values. For example, all values are retrieved with a colon. \n A[:]\n \n To retrieve a subset of elements, the start and stop positions need to be defined. \n Given the pattern  aList[start:stop] , retrieve the first two elements from List A. \n    ", "date_posted": "2022-04-30 17:09:16Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "241211", "name": "Michael", "reputation_score": "7,466"}, "answer_comments": []}], "user": {"stack_user_id": "24039", "name": "Simon", "reputation_score": "76.1k"}, "question_comments": []},
{"stack_question_id": "1373164", "question_title": "How do I create variable variables?", "question_content": "\r\n                How do I create the equivalent of PHP variable variable names in Python?\nI hear this is a bad idea, in general, though. Is that true?\n\nIf you are just trying to look up an existing variable by its ...\r\n", "question_url": "/questions/1373164/how-do-i-create-variable-variables", "date_posted": "Sep 3, 2009 at 12:37", "upvote": "5", "view": "2", "tags": ["python", "variable-variables"], "answers_count": "1", "answers": [{"stack_answer_id": "1373185", "answer_content": "\r\n You can use  dictionaries  to accomplish this. Dictionaries are stores of keys and values. \n >>> dct = {'x': 1, 'y': 2, 'z': 3}\n>>> dct\n{'y': 2, 'x': 1, 'z': 3}\n>>> dct[\"y\"]\n2\n \n You can use variable key names to achieve the effect of variable variables without the security risk. \n >>> x = \"spam\"\n>>> z = {x: \"eggs\"}\n>>> z[\"spam\"]\n'eggs'\n \n For cases where you're thinking of doing something like \n var1 = 'foo'\nvar2 = 'bar'\nvar3 = 'baz'\n...\n \n a  list  may be more appropriate than a dict. A list represents an ordered sequence of objects, with integer indices: \n lst = ['foo', 'bar', 'baz']\nprint(lst[1])           # prints bar, because indices start at 0\nlst.append('potatoes')  # lst is now ['foo', 'bar', 'baz', 'potatoes']\n \n For ordered sequences, lists are more convenient than dicts with integer keys, because lists support iteration in index order,  slicing ,  append , and other operations that would require awkward key management with a dict. \n    ", "date_posted": "2022-06-04 20:15:44Z", "upvote": "\r\n            404\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "4518341", "name": "wjandrea", "reputation_score": "24.1k"}, "answer_comments": []}, {"stack_answer_id": "1373198", "answer_content": "\r\n Use the built-in  getattr  function to get an attribute on an object by name.  Modify the name as needed. \n\n obj.spam = 'eggs'\nname = 'spam'\ngetattr(obj, name)  # returns 'eggs'\n \n    ", "date_posted": "2016-04-21 15:23:52Z", "upvote": "\r\n            109\r\n        ", "accepted": "No", "user": {"stack_user_id": "400617", "name": "davidism", "reputation_score": "112k"}, "answer_comments": []}, {"stack_answer_id": "1373201", "answer_content": "\r\n It's not a good idea. If you are accessing a global variable you can use  globals() . \n\n >>> a = 10\n>>> globals()['a']\n10\n \n\n If you want to access a variable in the local scope you can use  locals() , but you cannot assign values to the returned dict. \n\n A better solution  is to use  getattr  or store your variables in a dictionary and then access them by name. \n    ", "date_posted": "2017-04-24 02:03:14Z", "upvote": "\r\n            86\r\n        ", "accepted": "No", "user": {"stack_user_id": "2470818", "name": "vallentin", "reputation_score": "21.7k"}, "answer_comments": [{"stack_answer_id": "1373201", "stack_answer_comment_id": "107489989", "comment_content": " works just fine for me in Python 3.7.6; so I'm not sure what you mean when you say you cannot assign values through it.", "user_id": null}, {"stack_answer_id": "1373201", "stack_answer_comment_id": "107816343", "comment_content": "Given ", "user_id": null}, {"stack_answer_id": "1373201", "stack_answer_comment_id": "120374898", "comment_content": "The documentation of ", "user_id": null}, {"stack_answer_id": "1373201", "stack_answer_comment_id": "123583256", "comment_content": "@JimDennis`locals()`` provides a dictionary ", "user_id": null}, {"stack_answer_id": "1373201", "stack_answer_comment_id": "124099678", "comment_content": "The reason it doesn't work, at least on CPython, is that CPython allocates a fixed size array for locals, and the size of said array is determined when the function is defined, not when its run, and can't be changed (access to true locals doesn't even use the name; the name is replaced with the index into the array at function compile time). ", "user_id": null}]}, {"stack_answer_id": "38972761", "answer_content": "\r\n New coders sometimes write code like this: \n\n my_calculator.button_0 = tkinter.Button(root, text=0)\nmy_calculator.button_1 = tkinter.Button(root, text=1)\nmy_calculator.button_2 = tkinter.Button(root, text=2)\n...\n \n\n The coder is then left with a pile of named variables, with a coding effort of O( m  *  n ), where  m  is the number of named variables and  n  is the number of times that group of variables needs to be accessed (including creation). The more astute beginner observes that the only difference in each of those lines is a number that changes based on a rule, and decides to use a loop. However, they get stuck on how to dynamically create those variable names, and may try something like this: \n\n for i in range(10):\n    my_calculator.('button_%d' % i) = tkinter.Button(root, text=i)\n \n\n They soon find that this does not work. \n\n If the program requires arbitrary variable \"names,\" a dictionary is the best choice, as explained in other answers. However, if you're simply trying to create many variables and you don't mind referring to them with a sequence of integers, you're probably looking for a  list . This is particularly true if your data are homogeneous, such as daily temperature readings, weekly quiz scores, or a grid of graphical widgets. \n\n This can be assembled as follows: \n\n my_calculator.buttons = []\nfor i in range(10):\n    my_calculator.buttons.append(tkinter.Button(root, text=i))\n \n\n This  list  can also be created in one line with a comprehension: \n\n my_calculator.buttons = [tkinter.Button(root, text=i) for i in range(10)]\n \n\n The result in either case is a populated  list , with the first element accessed with  my_calculator.buttons[0] , the next with  my_calculator.buttons[1] , and so on. The \"base\" variable name becomes the name of the  list  and the varying identifier is used to access it. \n\n Finally, don't forget other data structures, such as the  set  - this is similar to a dictionary, except that each \"name\" doesn't have a value attached to it. If you simply need a \"bag\" of objects, this can be a great choice. Instead of something like this: \n\n keyword_1 = 'apple'\nkeyword_2 = 'banana'\n\nif query == keyword_1 or query == keyword_2:\n    print('Match.')\n \n\n You will have this: \n\n keywords = {'apple', 'banana'}\nif query in keywords:\n    print('Match.')\n \n\n Use a  list  for a sequence of similar objects, a  set  for an arbitrarily-ordered bag of objects, or a  dict  for a bag of names with associated values. \n    ", "date_posted": "2016-08-16 10:41:07Z", "upvote": "\r\n            67\r\n        ", "accepted": "No", "user": {"stack_user_id": "2617068", "name": "TigerhawkT3", "reputation_score": "47.3k"}, "answer_comments": []}, {"stack_answer_id": "1373192", "answer_content": "\r\n Whenever you want to use variable variables, it's probably better to use a dictionary. So instead of writing \n\n $foo = \"bar\"\n$$foo = \"baz\"\n \n\n you write  \n\n mydict = {}\nfoo = \"bar\"\nmydict[foo] = \"baz\"\n \n\n This way you won't accidentally overwrite previously existing variables (which is the security aspect) and you can have different \"namespaces\". \n    ", "date_posted": "2009-09-03 12:42:00Z", "upvote": "\r\n            43\r\n        ", "accepted": "No", "user": {"stack_user_id": "149392", "name": "sepp2k", "reputation_score": "356k"}, "answer_comments": []}, {"stack_answer_id": "53503041", "answer_content": "\r\n Use  globals()  (disclaimer: this is a bad practice, but is the most straightforward answer to your question, please use other data structure as in the accepted answer). \n You can actually assign variables to global scope dynamically, for instance, if you want 10 variables that can be accessed on a global scope  i_1 ,  i_2  ...  i_10 : \n for i in range(10):\n    globals()['i_{}'.format(i)] = 'a'\n \n This will assign 'a' to all of these 10 variables, of course you can change the value dynamically as well. All of these variables can be accessed now like other globally declared variable: \n >>> i_5\n'a'\n \n    ", "date_posted": "2022-08-07 18:16:34Z", "upvote": "\r\n            22\r\n        ", "accepted": "No", "user": {"stack_user_id": "8046232", "name": "Rocky Li", "reputation_score": "5,197"}, "answer_comments": [{"stack_answer_id": "53503041", "stack_answer_comment_id": "129164890", "comment_content": "Thanks for putting it in a minimal yet well explained form.", "user_id": null}]}, {"stack_answer_id": "37971967", "answer_content": "\r\n Instead of a dictionary you can also use  namedtuple  from the collections module, which makes access easier. \n\n For example: \n\n # using dictionary\nvariables = {}\nvariables[\"first\"] = 34\nvariables[\"second\"] = 45\nprint(variables[\"first\"], variables[\"second\"])\n\n# using namedtuple\nVariables = namedtuple('Variables', ['first', 'second'])\nvars = Variables(34, 45)\nprint(vars.first, vars.second)\n \n    ", "date_posted": "2019-05-13 14:39:12Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "37971967", "stack_answer_comment_id": "113874390", "comment_content": "Keep in mind ", "user_id": null}]}, {"stack_answer_id": "46269502", "answer_content": "\r\n The  SimpleNamespace  class could be used to create new attributes with  setattr , or subclass  SimpleNamespace  and create your own function to add new attribute names (variables).  \n\n from types import SimpleNamespace\n\nvariables = {\"b\":\"B\",\"c\":\"C\"}\na = SimpleNamespace(**variables)\nsetattr(a,\"g\",\"G\")\na.g = \"G+\"\nsomething = a.a\n \n    ", "date_posted": "2019-05-24 13:22:33Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "7212665", "name": "Demi-Lune", "reputation_score": "1,738"}, "answer_comments": []}, {"stack_answer_id": "46897025", "answer_content": "\r\n If you don't want to use any object, you can still use  setattr()  inside your current module: \n\n import sys\ncurrent_module = module = sys.modules[__name__]  # i.e the \"file\" where your code is written\nsetattr(current_module, 'variable_name', 15)  # 15 is the value you assign to the var\nprint(variable_name)  # >>> 15, created from a string\n \n    ", "date_posted": "2017-10-23 19:24:10Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "5823489", "name": "Guillaume Lebreton", "reputation_score": "2,178"}, "answer_comments": [{"stack_answer_id": "46897025", "stack_answer_comment_id": "84051166", "comment_content": "This does not work with ", "user_id": null}, {"stack_answer_id": "46897025", "stack_answer_comment_id": "84068764", "comment_content": " can do this", "user_id": null}]}, {"stack_answer_id": "37725729", "answer_content": "\r\n You have to use  globals()  built in method   to achieve that behaviour: \n def var_of_var(k, v):\n    globals()[k] = v\n\nprint variable_name # NameError: name 'variable_name' is not defined\nsome_name = 'variable_name'\nglobals()[some_name] = 123\nprint(variable_name) # 123\n\nsome_name = 'variable_name2'\nvar_of_var(some_name, 456)\nprint(variable_name2) # 456\n \n    ", "date_posted": "2020-10-17 07:06:59Z", "upvote": "\r\n            10\r\n        ", "accepted": "No", "user": {"stack_user_id": "2067976", "name": "Andriy Ivaneyko", "reputation_score": "18.9k"}, "answer_comments": []}, {"stack_answer_id": "40384282", "answer_content": "\r\n I'm am answering the question:  How to get the value of a variable given its name in a string? \nwhich is closed as a duplicate with a link to this question.  \n\n If the variables in question are part of an object (part of a class for example) then some useful functions to achieve exactly that are  hasattr ,  getattr , and  setattr .  \n\n So for example you can have: \n\n class Variables(object):\n    def __init__(self):\n        self.foo = \"initial_variable\"\n    def create_new_var(self,name,value):\n        setattr(self,name,value)\n    def get_var(self,name):\n        if hasattr(self,name):\n            return getattr(self,name)\n        else:\n            raise(\"Class does not have a variable named: \"+name)\n \n\n Then you can do: \n\n v = Variables()\nv.get_var(\"foo\")\n \n\n \n   \"initial_variable\" \n \n\n v.create_new_var(v.foo,\"is actually not initial\")\nv.initial_variable\n \n\n \n   \"is actually not initial\" \n \n    ", "date_posted": "2017-05-23 12:10:47Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}, {"stack_answer_id": "65673959", "answer_content": "\r\n # Python 3.8.2 (default, Feb 26 2020, 02:56:10)\n \n Variable variables in Python \n \"\"\"\n<?php\n$a = 'hello';\n$e = 'wow'\n?>\n<?php\n$$a = 'world';\n?>\n<?php\necho \"$a ${$a}\\n\";\necho \"$a ${$a[1]}\\n\";\n?>\n<?php\necho \"$a $hello\";\n?>\n\"\"\"\n\na = 'hello'  #<?php $a = 'hello'; ?>\ne = 'wow'   #<?php $e = 'wow'; ?>\nvars()[a] = 'world' #<?php $$a = 'world'; ?>\nprint(a, vars()[a]) #<?php echo \"$a ${$a}\\n\"; ?>\nprint(a, vars()[vars()['a'][1]]) #<?php echo \"$a ${$a[1]}\\n\"; ?>\nprint(a, hello) #<?php echo \"$a $hello\"; ?>\n \n Output: \n hello world\nhello wow\nhello world\n \n \n Using globals(), locals(), or vars() will produce the same results \n # Python 3.8.2 (default, Feb 26 2020, 02:56:10)\n\n#<?php $a = 'hello'; ?>\n#<?php $e = 'wow'; ?>\n#<?php $$a = 'world'; ?>\n#<?php echo \"$a ${$a}\\n\"; ?>\n#<?php echo \"$a ${$a[1]}\\n\"; ?>\n#<?php echo \"$a $hello\"; ?>\n\nprint('locals():\\n')\na = 'hello'\ne = 'wow'\nlocals()[a] = 'world'\nprint(a, locals()[a])\nprint(a, locals()[locals()['a'][1]])\nprint(a, hello)\n\nprint('\\n\\nglobals():\\n')\na = 'hello'\ne = 'wow'\nglobals()[a] = 'world'\nprint(a, globals()[a])\nprint(a, globals()[globals()['a'][1]])\nprint(a, hello)\n \n Output: \n locals():\n\nhello world\nhello wow\nhello world\n\n\nglobals():\n\nhello world\nhello wow\nhello world\n \n \n Bonus (creating variables from strings) \n # Python 2.7.16 (default, Jul 13 2019, 16:01:51)\n# [GCC 8.3.0] on linux2\n \n Creating variables and unpacking tuple: \n g = globals()\nlistB = []\nfor i in range(10):\n    g[\"num%s\" % i] = i ** 10\n    listB.append(\"num{0}\".format(i))\n\ndef printNum():\n    print \"Printing num0 to num9:\"\n    for i in range(10):\n        print \"num%s = \" % i, \n        print g[\"num%s\" % i]\n\nprintNum()\n\nlistA = []\nfor i in range(10):\n    listA.append(i)\n\nlistA = tuple(listA)\nprint listA, '\"Tuple to unpack\"'\n\nlistB = str(str(listB).strip(\"[]\").replace(\"'\", \"\") + \" = listA\")\n\nprint listB\n\nexec listB\n\nprintNum()\n \n Output: \n Printing num0 to num9:\nnum0 =  0\nnum1 =  1\nnum2 =  1024\nnum3 =  59049\nnum4 =  1048576\nnum5 =  9765625\nnum6 =  60466176\nnum7 =  282475249\nnum8 =  1073741824\nnum9 =  3486784401\n(0, 1, 2, 3, 4, 5, 6, 7, 8, 9) \"Tuple to unpack\"\nnum0, num1, num2, num3, num4, num5, num6, num7, num8, num9 = listA\nPrinting num0 to num9:\nnum0 =  0\nnum1 =  1\nnum2 =  2\nnum3 =  3\nnum4 =  4\nnum5 =  5\nnum6 =  6\nnum7 =  7\nnum8 =  8\nnum9 =  9\n \n    ", "date_posted": "2021-03-09 16:18:44Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "14916988", "name": "mOmOney", "reputation_score": "175"}, "answer_comments": []}, {"stack_answer_id": "59333920", "answer_content": "\r\n I have tried both in python 3.7.3, you can use either globals() or vars() \n\n >>> food #Error\n>>> milkshake #Error\n>>> food=\"bread\"\n>>> drink=\"milkshake\"\n>>> globals()[food] = \"strawberry flavor\"\n>>> vars()[drink] = \"chocolate flavor\"\n>>> bread\n'strawberry flavor'\n>>> milkshake\n'chocolate flavor'\n>>> globals()[drink]\n'chocolate flavor'\n>>> vars()[food]\n'strawberry flavor'\n \n\n \n\n Reference: \n https://www.daniweb.com/programming/software-development/threads/111526/setting-a-string-as-a-variable-name#post548936 \n    ", "date_posted": "2019-12-14 09:39:02Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "7069108", "name": "Hzzkygcs", "reputation_score": "1,091"}, "answer_comments": []}, {"stack_answer_id": "37725113", "answer_content": "\r\n The consensus is to use a dictionary for this - see the other answers. This is a good idea for most cases, however, there are many aspects arising from this: \n\n \n you'll yourself be responsible for this dictionary, including garbage collection (of in-dict variables) etc. \n there's either no locality or globality for variable variables, it depends on the globality of the dictionary \n if you want to rename a variable name, you'll have to do it manually \n however, you are much more flexible, e.g. \n\n \n you can decide to overwrite existing variables or  ... \n ... choose to implement const variables \n to raise an exception on overwriting for different types \n etc. \n \n \n\n That said, I've implemented a  variable variables manager -class which provides some of the above ideas. It works for python 2 and 3. \n\n You'd use  the class  like this: \n\n from variableVariablesManager import VariableVariablesManager\n\nmyVars = VariableVariablesManager()\nmyVars['test'] = 25\nprint(myVars['test'])\n\n# define a const variable\nmyVars.defineConstVariable('myconst', 13)\ntry:\n    myVars['myconst'] = 14 # <- this raises an error, since 'myconst' must not be changed\n    print(\"not allowed\")\nexcept AttributeError as e:\n    pass\n\n# rename a variable\nmyVars.renameVariable('myconst', 'myconstOther')\n\n# preserve locality\ndef testLocalVar():\n    myVars = VariableVariablesManager()\n    myVars['test'] = 13\n    print(\"inside function myVars['test']:\", myVars['test'])\ntestLocalVar()\nprint(\"outside function myVars['test']:\", myVars['test'])\n\n# define a global variable\nmyVars.defineGlobalVariable('globalVar', 12)\ndef testGlobalVar():\n    myVars = VariableVariablesManager()\n    print(\"inside function myVars['globalVar']:\", myVars['globalVar'])\n    myVars['globalVar'] = 13\n    print(\"inside function myVars['globalVar'] (having been changed):\", myVars['globalVar'])\ntestGlobalVar()\nprint(\"outside function myVars['globalVar']:\", myVars['globalVar'])\n \n\n If you wish to allow overwriting of variables with the same type only: \n\n myVars = VariableVariablesManager(enforceSameTypeOnOverride = True)\nmyVars['test'] = 25\nmyVars['test'] = \"Cat\" # <- raises Exception (different type on overwriting)\n \n    ", "date_posted": "2016-06-09 12:10:59Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "1150303", "name": "DomTomCat", "reputation_score": "7,753"}, "answer_comments": []}, {"stack_answer_id": "45643867", "answer_content": "\r\n Any set of variables can also be wrapped up in a class. \n\"Variable\" variables may be added to the class instance during runtime by directly accessing the built-in dictionary through __dict__ attribute.  \n\n The following code defines Variables class, which adds variables (in this case attributes) to its instance during the construction. Variable names are taken from a specified list (which, for example, could have been generated by program code): \n\n # some list of variable names\nL = ['a', 'b', 'c']\n\nclass Variables:\n    def __init__(self, L):\n        for item in L:\n            self.__dict__[item] = 100\n\nv = Variables(L)\nprint(v.a, v.b, v.c)\n#will produce 100 100 100\n \n    ", "date_posted": "2017-08-11 21:13:57Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "8418961", "name": "ru13r", "reputation_score": "174"}, "answer_comments": []}, {"stack_answer_id": "65963716", "answer_content": "\r\n It should be extremely risky...\nbut you can use exec(): \n a = 'b=5'\nexec(a)\nc = b*2\nprint (c)\n \n Result:\n10 \n    ", "date_posted": "2021-01-30 01:15:36Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "5832844", "name": "Ruben Medrano", "reputation_score": "141"}, "answer_comments": [{"stack_answer_id": "65963716", "stack_answer_comment_id": "122682749", "comment_content": "This won't work inside a function. It's essentially equivalent to the safer ", "user_id": null}, {"stack_answer_id": "65963716", "stack_answer_comment_id": "127047992", "comment_content": "@benrg Do you know how to get around Rubens failed suggestion because I'm stuck with the same situation? I have a file containing a long list of variable assignments as a collective string. I need to turn them into python assignments but eval() and exec() both fails.", "user_id": null}]}, {"stack_answer_id": "71715887", "answer_content": "\r\n The  setattr()  method sets the value of the specified attribute of the specified object. \n Syntax goes like this \u2013 \n setattr(object, name, value)\nExample \u2013\n\nsetattr(self,id,123)\n \n which is equivalent to  self.id = 123 \n As you might have observed, setattr() expects an object to be passed along with the value to generate/modify a new attribute. \n We can use setattr() with a workaround to be able to use within modules. Here\u2019 how \u2013 \n import sys\nx = \"pikachu\"\nvalue = 46\nthismodule = sys.modules[__name__]\nsetattr(thismodule, x, value)\nprint(pikachu)\n \n    ", "date_posted": "2022-04-02 08:12:48Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "14399724", "name": "kannappan", "reputation_score": "199"}, "answer_comments": []}], "user": {"stack_user_id": null, "name": null, "reputation_score": 0}, "question_comments": [{"stack_question_id": "1373164", "stack_question_comment_id": "1212436", "comment_content": "it's the maintainance and debugging aspects that cause the horror. Imagine trying to find out where variable 'foo' changed when there's no place in your code where you actually change 'foo'. Imagine further that it's someone else's code that you have to maintain... OK, you can go to your happy place now.", "user_id": null}, {"stack_question_id": "1373164", "stack_question_comment_id": "43554197", "comment_content": "A further pitfall that hasn't been mentioned so far is if such a dynamically-created variable has the same name as a variable used in your logic. You essentially open up your software as a hostage to the input it is given.", "user_id": null}, {"stack_question_id": "1373164", "stack_question_comment_id": "107490205", "comment_content": "You can modify your global and local variables by accessing the underlying dictionaries for them; it's a horrible idea from a maintenance perspective ... but it can be done via ", "user_id": null}, {"stack_question_id": "1373164", "stack_question_comment_id": "109448744", "comment_content": "@JimDennis actually, no it can't. Modifications to the dict returned by ", "user_id": null}, {"stack_question_id": "1373164", "stack_question_comment_id": "109570795", "comment_content": "@juanpa.arrivillaga: I had tried testing this in an IPython shell, but did so at the top level (where locals() behaves like globsls()).  Redoing that test within a nested code (within the definition of a function) does show that I can't modify locals() from within that.  As you say, the help for locals (3.7.6) does warn: ", "user_id": null}]},
{"stack_question_id": "23294658", "question_title": "Asking the user for input until they give a valid response", "question_content": "\r\n                I am writing a program that accepts user input.\n#note: Python 2.7 users should use `raw_input`, the equivalent of 3.X's `input`\nage = int(input(\"Please enter your age: \"))\nif age >= 18: \n ...\r\n", "question_url": "/questions/23294658/asking-the-user-for-input-until-they-give-a-valid-response", "date_posted": null, "upvote": "7", "view": "8", "tags": ["python", "validation", "input"], "answers_count": "2", "answers": [{"stack_answer_id": "23294659", "answer_content": "\r\n The simplest way to accomplish this is to put the  input  method in a while loop. Use  continue  when you get bad input, and  break  out of the loop when you're satisfied. \n\n When Your Input Might Raise an Exception \n\n Use  try  and  except  to detect when the user enters data that can't be parsed. \n\n while True:\n    try:\n        # Note: Python 2.x users should use raw_input, the equivalent of 3.x's input\n        age = int(input(\"Please enter your age: \"))\n    except ValueError:\n        print(\"Sorry, I didn't understand that.\")\n        #better try again... Return to the start of the loop\n        continue\n    else:\n        #age was successfully parsed!\n        #we're ready to exit the loop.\n        break\nif age >= 18: \n    print(\"You are able to vote in the United States!\")\nelse:\n    print(\"You are not able to vote in the United States.\")\n \n\n Implementing Your Own Validation Rules \n\n If you want to reject values that Python can successfully parse, you can add your own validation logic. \n\n while True:\n    data = input(\"Please enter a loud message (must be all caps): \")\n    if not data.isupper():\n        print(\"Sorry, your response was not loud enough.\")\n        continue\n    else:\n        #we're happy with the value given.\n        #we're ready to exit the loop.\n        break\n\nwhile True:\n    data = input(\"Pick an answer from A to D:\")\n    if data.lower() not in ('a', 'b', 'c', 'd'):\n        print(\"Not an appropriate choice.\")\n    else:\n        break\n \n\n Combining Exception Handling and Custom Validation \n\n Both of the above techniques can be combined into one loop. \n\n while True:\n    try:\n        age = int(input(\"Please enter your age: \"))\n    except ValueError:\n        print(\"Sorry, I didn't understand that.\")\n        continue\n\n    if age < 0:\n        print(\"Sorry, your response must not be negative.\")\n        continue\n    else:\n        #age was successfully parsed, and we're happy with its value.\n        #we're ready to exit the loop.\n        break\nif age >= 18: \n    print(\"You are able to vote in the United States!\")\nelse:\n    print(\"You are not able to vote in the United States.\")\n \n\n Encapsulating it All in a Function \n\n If you need to ask your user for a lot of different values, it might be useful to put this code in a function, so you don't have to retype it every time. \n\n def get_non_negative_int(prompt):\n    while True:\n        try:\n            value = int(input(prompt))\n        except ValueError:\n            print(\"Sorry, I didn't understand that.\")\n            continue\n\n        if value < 0:\n            print(\"Sorry, your response must not be negative.\")\n            continue\n        else:\n            break\n    return value\n\nage = get_non_negative_int(\"Please enter your age: \")\nkids = get_non_negative_int(\"Please enter the number of children you have: \")\nsalary = get_non_negative_int(\"Please enter your yearly earnings, in dollars: \")\n \n\n Putting It All Together \n\n You can extend this idea to make a very generic input function: \n\n def sanitised_input(prompt, type_=None, min_=None, max_=None, range_=None):\n    if min_ is not None and max_ is not None and max_ < min_:\n        raise ValueError(\"min_ must be less than or equal to max_.\")\n    while True:\n        ui = input(prompt)\n        if type_ is not None:\n            try:\n                ui = type_(ui)\n            except ValueError:\n                print(\"Input type must be {0}.\".format(type_.__name__))\n                continue\n        if max_ is not None and ui > max_:\n            print(\"Input must be less than or equal to {0}.\".format(max_))\n        elif min_ is not None and ui < min_:\n            print(\"Input must be greater than or equal to {0}.\".format(min_))\n        elif range_ is not None and ui not in range_:\n            if isinstance(range_, range):\n                template = \"Input must be between {0.start} and {0.stop}.\"\n                print(template.format(range_))\n            else:\n                template = \"Input must be {0}.\"\n                if len(range_) == 1:\n                    print(template.format(*range_))\n                else:\n                    expected = \" or \".join((\n                        \", \".join(str(x) for x in range_[:-1]),\n                        str(range_[-1])\n                    ))\n                    print(template.format(expected))\n        else:\n            return ui\n \n\n With usage such as: \n\n age = sanitised_input(\"Enter your age: \", int, 1, 101)\nanswer = sanitised_input(\"Enter your answer: \", str.lower, range_=('a', 'b', 'c', 'd'))\n \n\n Common Pitfalls, and Why you Should Avoid Them \n\n The Redundant Use of Redundant  input  Statements \n\n This method works but is generally considered poor style: \n\n data = input(\"Please enter a loud message (must be all caps): \")\nwhile not data.isupper():\n    print(\"Sorry, your response was not loud enough.\")\n    data = input(\"Please enter a loud message (must be all caps): \")\n \n\n It might look attractive initially because it's shorter than the  while True  method, but it violates the  Don't Repeat Yourself  principle of software development. This increases the likelihood of bugs in your system. What if you want to backport to 2.7 by changing  input  to  raw_input , but accidentally change only the first  input  above? It's a  SyntaxError  just waiting to happen. \n\n Recursion Will Blow Your Stack \n\n If you've just learned about recursion, you might be tempted to use it in  get_non_negative_int  so you can dispose of the while loop. \n\n def get_non_negative_int(prompt):\n    try:\n        value = int(input(prompt))\n    except ValueError:\n        print(\"Sorry, I didn't understand that.\")\n        return get_non_negative_int(prompt)\n\n    if value < 0:\n        print(\"Sorry, your response must not be negative.\")\n        return get_non_negative_int(prompt)\n    else:\n        return value\n \n\n This appears to work fine most of the time, but if the user enters invalid data enough times, the script will terminate with a  RuntimeError: maximum recursion depth exceeded . You may think \"no fool would make 1000 mistakes in a row\", but you're underestimating the ingenuity of fools! \n    ", "date_posted": "2020-06-06 17:56:58Z", "upvote": "\r\n            926\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "23294659", "name": "\r\n        9 revs, 7 users 73%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "23294659", "stack_answer_comment_id": "70076872", "comment_content": "Its fun reading it with many examples, kudos. Underrated lesson: \"Don't underestimate the ingenuity of fools!\"", "user_id": null}, {"stack_answer_id": "23294659", "stack_answer_comment_id": "84169769", "comment_content": "Not only would I have upvoted both the Q&A anyway, as they're great, but you sealed the deal with \"dickety six\". Well done, @Kevin.", "user_id": null}, {"stack_answer_id": "23294659", "stack_answer_comment_id": "98430983", "comment_content": "Don't estimate the ingenuity of fools... and clever attackers. A DOS attack would be easiest for this sort of thing, but others may be possible.", "user_id": null}, {"stack_answer_id": "23294659", "stack_answer_comment_id": "109126499", "comment_content": "@JArunMani I don't think it would be poor style, but might be a little less readable. You will indeed have only one ", "user_id": null}, {"stack_answer_id": "23294659", "stack_answer_comment_id": "111538982", "comment_content": "@laundmo,certainly I release the code blocks that I wrote into the public domain. Feel free to use them in any context, without my explicit permission or knowledge. Regarding the non-code-block segments, If you want to paste my entire answer into a \"Learn Python\" book you're writing, let's talk royalties ;-)", "user_id": "/users/953482/kevin"}]}, {"stack_answer_id": "34789951", "answer_content": "\r\n Why would you do a  while True  and then break out of this loop while you can also just put your requirements in the while statement since all you want is to stop once you have the age? \n\n age = None\nwhile age is None:\n    input_value = input(\"Please enter your age: \")\n    try:\n        # try and convert the string input to a number\n        age = int(input_value)\n    except ValueError:\n        # tell the user off\n        print(\"{input} is not a number, please enter a number only\".format(input=input_value))\nif age >= 18:\n    print(\"You are able to vote in the United States!\")\nelse:\n    print(\"You are not able to vote in the United States.\")\n \n\n This would result in the following: \n\n Please enter your age: *potato*\npotato is not a number, please enter a number only\nPlease enter your age: *5*\nYou are not able to vote in the United States.\n \n\n this will work since age will never have a value that will not make sense and the code follows the logic of your \"business process\" \n    ", "date_posted": "2018-02-24 16:44:54Z", "upvote": "\r\n            56\r\n        ", "accepted": "No", "user": {"stack_user_id": "34789951", "name": "\r\n        2 revs, 2 users 96%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "34789951", "stack_answer_comment_id": "128352468", "comment_content": "A well-designed ", "user_id": null}]}, {"stack_answer_id": "31105868", "answer_content": "\r\n Though the accepted answer is amazing. I would also like to share a quick hack for this problem. (This takes care of the negative age problem as well.)  \n\n f=lambda age: (age.isdigit() and ((int(age)>=18  and \"Can vote\" ) or \"Cannot vote\")) or \\\nf(input(\"invalid input. Try again\\nPlease enter your age: \"))\nprint(f(input(\"Please enter your age: \")))\n \n\n P.S. This code is for python 3.x. \n    ", "date_posted": "2018-12-21 18:25:22Z", "upvote": "\r\n            28\r\n        ", "accepted": "No", "user": {"stack_user_id": "31105868", "name": "\r\n        2 revs, 2 users 78%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "31105868", "stack_answer_comment_id": "57944049", "comment_content": "Note that this code is recursive, but recursion isn't necessary here, and as Kevin said, it can blow your stack.", "user_id": null}, {"stack_answer_id": "31105868", "stack_answer_comment_id": "58062327", "comment_content": "@PM2Ring - you are right. But my purpose here was just to show how \"short circuiting\" can minimise (beautify) long pieces of code.", "user_id": null}, {"stack_answer_id": "31105868", "stack_answer_comment_id": "75053395", "comment_content": "Why would you assign a lambda to a variable, just use ", "user_id": null}, {"stack_answer_id": "31105868", "stack_answer_comment_id": "75054358", "comment_content": "In some cases, you may need the age just once and then there is no use of that function. One may want to use a function and throw it away after the job is done. Also, this may not be the best way, but it definitely is a different way of doing it (which was the purpose of my solution).", "user_id": null}, {"stack_answer_id": "31105868", "stack_answer_comment_id": "100333779", "comment_content": "@aaveg how would you turn this code to actually save the age provided by the user?", "user_id": null}]}, {"stack_answer_id": "56081775", "answer_content": "\r\n Functional approach  or \" look mum no loops! \": \n from itertools import chain, repeat\n\nprompts = chain([\"Enter a number: \"], repeat(\"Not a number! Try again: \"))\nreplies = map(input, prompts)\nvalid_response = next(filter(str.isdigit, replies))\nprint(valid_response)\n \n Enter a number:  a\nNot a number! Try again:  b\nNot a number! Try again:  1\n1\n \n or if you want to have a \"bad input\" message separated from an input prompt as in other answers: \n prompt_msg = \"Enter a number: \"\nbad_input_msg = \"Sorry, I didn't understand that.\"\nprompts = chain([prompt_msg], repeat('\\n'.join([bad_input_msg, prompt_msg])))\nreplies = map(input, prompts)\nvalid_response = next(filter(str.isdigit, replies))\nprint(valid_response)\n \n Enter a number:  a\nSorry, I didn't understand that.\nEnter a number:  b\nSorry, I didn't understand that.\nEnter a number:  1\n1\n \n How does it work? \n \n \n prompts = chain([\"Enter a number: \"], repeat(\"Not a number! Try again: \"))\n \nThis combination of  itertools.chain  and  itertools.repeat  will create an iterator\nwhich will yield strings  \"Enter a number: \"  once, and  \"Not a number! Try again: \"  an infinite number of times:\n for prompt in prompts:\n    print(prompt)\n \n Enter a number: \nNot a number! Try again: \nNot a number! Try again: \nNot a number! Try again: \n# ... and so on\n \n \n replies = map(input, prompts)  - here  map  will apply all the  prompts  strings from the previous step to the  input  function. E.g.:\n for reply in replies:\n    print(reply)\n \n Enter a number:  a\na\nNot a number! Try again:  1\n1\nNot a number! Try again:  it doesn't care now\nit doesn't care now\n# and so on...\n \n \n We use  filter  and  str.isdigit  to filter out those strings that contain only digits:\n only_digits = filter(str.isdigit, replies)\nfor reply in only_digits:\n    print(reply)\n \n Enter a number:  a\nNot a number! Try again:  1\n1\nNot a number! Try again:  2\n2\nNot a number! Try again:  b\nNot a number! Try again: # and so on...\n \nAnd to get only the first digits-only string we use  next . \n \n Other validation rules: \n \n String methods:  Of course you can use other string methods like  str.isalpha  to get only alphabetic strings, or  str.isupper  to get only uppercase. See  docs  for the full list. \n \n Membership testing: \nThere are several different ways to perform it. One of them is by using  __contains__  method: \n from itertools import chain, repeat\n\nfruits = {'apple', 'orange', 'peach'}\nprompts = chain([\"Enter a fruit: \"], repeat(\"I don't know this one! Try again: \"))\nreplies = map(input, prompts)\nvalid_response = next(filter(fruits.__contains__, replies))\nprint(valid_response)\n \n Enter a fruit:  1\nI don't know this one! Try again:  foo\nI don't know this one! Try again:  apple\napple\n \n \n Numbers comparison: \nThere are useful comparison methods which we can use here. For example, for  __lt__  ( < ): \n from itertools import chain, repeat\n\nprompts = chain([\"Enter a positive number:\"], repeat(\"I need a positive number! Try again:\"))\nreplies = map(input, prompts)\nnumeric_strings = filter(str.isnumeric, replies)\nnumbers = map(float, numeric_strings)\nis_positive = (0.).__lt__\nvalid_response = next(filter(is_positive, numbers))\nprint(valid_response)\n \n Enter a positive number: a\nI need a positive number! Try again: -5\nI need a positive number! Try again: 0\nI need a positive number! Try again: 5\n5.0\n \n Or, if you don't like using dunder methods (dunder = double-underscore), you can always define your own function, or use the ones from the  operator  module. \n \n Path existance: \nHere one can use  pathlib  library and its  Path.exists  method: \n from itertools import chain, repeat\nfrom pathlib import Path\n\nprompts = chain([\"Enter a path: \"], repeat(\"This path doesn't exist! Try again: \"))\nreplies = map(input, prompts)\npaths = map(Path, replies)\nvalid_response = next(filter(Path.exists, paths))\nprint(valid_response)\n \n Enter a path:  a b c\nThis path doesn't exist! Try again:  1\nThis path doesn't exist! Try again:  existing_file.txt\nexisting_file.txt\n \n \n \n Limiting number of tries: \n If you don't want to torture a user by asking him something an infinite number of times, you can specify a limit in a call of  itertools.repeat . This can be combined with providing a default value to the  next  function: \n from itertools import chain, repeat\n\nprompts = chain([\"Enter a number:\"], repeat(\"Not a number! Try again:\", 2))\nreplies = map(input, prompts)\nvalid_response = next(filter(str.isdigit, replies), None)\nprint(\"You've failed miserably!\" if valid_response is None else 'Well done!')\n \n Enter a number: a\nNot a number! Try again: b\nNot a number! Try again: c\nYou've failed miserably!\n \n Preprocessing input data: \n Sometimes we don't want to reject an input if the user accidentally supplied it  IN CAPS  or with a space in the beginning or an end of the string. To take these simple mistakes into account we can preprocess the input data by applying  str.lower  and  str.strip  methods. For example, for the case of membership testing the code will look like this: \n from itertools import chain, repeat\n\nfruits = {'apple', 'orange', 'peach'}\nprompts = chain([\"Enter a fruit: \"], repeat(\"I don't know this one! Try again: \"))\nreplies = map(input, prompts)\nlowercased_replies = map(str.lower, replies)\nstripped_replies = map(str.strip, lowercased_replies)\nvalid_response = next(filter(fruits.__contains__, stripped_replies))\nprint(valid_response)\n \n Enter a fruit:  duck\nI don't know this one! Try again:     Orange\norange\n \n In the case when you have many functions to use for preprocessing, it might be easier to use a function performing a  function composition . For example, using the one from  here : \n from itertools import chain, repeat\n\nfrom lz.functional import compose\n\nfruits = {'apple', 'orange', 'peach'}\nprompts = chain([\"Enter a fruit: \"], repeat(\"I don't know this one! Try again: \"))\nreplies = map(input, prompts)\nprocess = compose(str.strip, str.lower)  # you can add more functions here\nprocessed_replies = map(process, replies)\nvalid_response = next(filter(fruits.__contains__, processed_replies))\nprint(valid_response)\n \n Enter a fruit:  potato\nI don't know this one! Try again:   PEACH\npeach\n \n Combining validation rules: \n For a simple case, for example, when the program asks for age between 1 and 120, one can just add another  filter : \n from itertools import chain, repeat\n\nprompt_msg = \"Enter your age (1-120): \"\nbad_input_msg = \"Wrong input.\"\nprompts = chain([prompt_msg], repeat('\\n'.join([bad_input_msg, prompt_msg])))\nreplies = map(input, prompts)\nnumeric_replies = filter(str.isdigit, replies)\nages = map(int, numeric_replies)\npositive_ages = filter((0).__lt__, ages)\nnot_too_big_ages = filter((120).__ge__, positive_ages)\nvalid_response = next(not_too_big_ages)\nprint(valid_response)\n \n But in the case when there are many rules, it's better to implement a function performing a  logical conjunction . In the following example I will use a ready one from  here : \n from functools import partial\nfrom itertools import chain, repeat\n\nfrom lz.logical import conjoin\n\n\ndef is_one_letter(string: str) -> bool:\n    return len(string) == 1\n\n\nrules = [str.isalpha, str.isupper, is_one_letter, 'C'.__le__, 'P'.__ge__]\n\nprompt_msg = \"Enter a letter (C-P): \"\nbad_input_msg = \"Wrong input.\"\nprompts = chain([prompt_msg], repeat('\\n'.join([bad_input_msg, prompt_msg])))\nreplies = map(input, prompts)\nvalid_response = next(filter(conjoin(*rules), replies))\nprint(valid_response)\n \n Enter a letter (C-P):  5\nWrong input.\nEnter a letter (C-P):  f\nWrong input.\nEnter a letter (C-P):  CDE\nWrong input.\nEnter a letter (C-P):  Q\nWrong input.\nEnter a letter (C-P):  N\nN\n \n Unfortunately, if someone needs a custom message for each failed case, then, I'm afraid, there is no  pretty  functional way. Or, at least, I couldn't find one. \n    ", "date_posted": "2020-06-20 09:12:55Z", "upvote": "\r\n            28\r\n        ", "accepted": "No", "user": {"stack_user_id": "56081775", "name": "\r\n        3 revs", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "56081775", "stack_answer_comment_id": "102050848", "comment_content": "What a thorough and wonderful answer, the explanation breakdown was great.", "user_id": null}, {"stack_answer_id": "56081775", "stack_answer_comment_id": "102061971", "comment_content": "Using your style, how would one go about stripping whitespace and lower-casing the input for membership testing? I don't want to create a set that must include both upper and lowercase examples. I would also like to allow for whitespace input mistakes.", "user_id": null}, {"stack_answer_id": "56081775", "stack_answer_comment_id": "102075725", "comment_content": "@Austin I added a new section on preprocessing. Take a look.", "user_id": null}, {"stack_answer_id": "56081775", "stack_answer_comment_id": "110069223", "comment_content": "That reminds me of ReactiveX. But perhaps that was inspired by functional languages in the first place?", "user_id": null}]}, {"stack_answer_id": "56084305", "answer_content": "\r\n Using  Click : \n Click  is a library for command-line interfaces and it provides functionality for asking a valid response from a user. \n Simple example: \n import click\n\nnumber = click.prompt('Please enter a number', type=float)\nprint(number)\n \n Please enter a number: \n a\nError: a is not a valid floating point value\nPlease enter a number: \n 10\n10.0\n \n Note how it converted the string value to a float automatically. \n Checking if a value is within a range: \n There are different  custom types  provided. To get a number in a specific range we can use  IntRange : \n age = click.prompt(\"What's your age?\", type=click.IntRange(1, 120))\nprint(age)\n \n What's your age?: \n a\nError: a is not a valid integer\nWhat's your age?: \n 0\nError: 0 is not in the valid range of 1 to 120.\nWhat's your age?: \n 5\n5\n \n We can also specify just one of the limits,  min  or  max : \n age = click.prompt(\"What's your age?\", type=click.IntRange(min=14))\nprint(age)\n \n What's your age?: \n 0\nError: 0 is smaller than the minimum valid value 14.\nWhat's your age?: \n 18\n18\n \n Membership testing: \n Using  click.Choice  type. By default this check is case-sensitive. \n choices = {'apple', 'orange', 'peach'}\nchoice = click.prompt('Provide a fruit', type=click.Choice(choices, case_sensitive=False))\nprint(choice)\n \n Provide a fruit (apple, peach, orange): \n banana\nError: invalid choice: banana. (choose from apple, peach, orange)\nProvide a fruit (apple, peach, orange): \n OrAnGe\norange\n \n Working with paths and files: \n Using a  click.Path  type we can check for existing paths and also resolve them: \n path = click.prompt('Provide path', type=click.Path(exists=True, resolve_path=True))\nprint(path)\n \n Provide path: \n nonexistent\nError: Path \"nonexistent\" does not exist.\nProvide path: \n existing_folder\n'/path/to/existing_folder\n \n Reading and writing files can be done by  click.File : \n file = click.prompt('In which file to write data?', type=click.File('w'))\nwith file.open():\n    file.write('Hello!')\n# More info about `lazy=True` at:\n# https://click.palletsprojects.com/en/7.x/arguments/#file-opening-safety\nfile = click.prompt('Which file you wanna read?', type=click.File(lazy=True))\nwith file.open():\n    print(file.read())\n \n In which file to write data?: \n         # <-- provided an empty string, which is an illegal name for a file\nIn which file to write data?: \n some_file.txt\nWhich file you wanna read?: \n nonexistent.txt\nError: Could not open file: nonexistent.txt: No such file or directory\nWhich file you wanna read?: \n some_file.txt\nHello!\n \n Other examples: \n Password confirmation: \n password = click.prompt('Enter password', hide_input=True, confirmation_prompt=True)\nprint(password)\n \n Enter password: \n \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\nRepeat for confirmation: \n \u00b7\nError: the two entered values do not match\nEnter password: \n \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\nRepeat for confirmation: \n \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\nqwerty\n \n Default values: \n In this case, simply pressing  Enter  (or whatever key you use) without entering a value, will give you a default one: \n number = click.prompt('Please enter a number', type=int, default=42)\nprint(number)\n \n Please enter a number [42]: \n a\nError: a is not a valid integer\nPlease enter a number [42]: \n \n42\n \n    ", "date_posted": "2020-06-20 09:12:55Z", "upvote": "\r\n            20\r\n        ", "accepted": "No", "user": {"stack_user_id": "56084305", "name": "\r\n        2 revs", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "56084305", "stack_answer_comment_id": "110338437", "comment_content": "Thanks, this is perfect. Looping with a number selection in a valid range was exactly what i was looking for.", "user_id": null}]}, {"stack_answer_id": "35110110", "answer_content": "\r\n So, I was messing around with something similar to this recently, and I came up with the following solution, which uses a way of getting input that rejects junk, before it's even checked in any logical way. \n\n read_single_keypress()  courtesy  https://stackoverflow.com/a/6599441/4532996 \n\n def read_single_keypress() -> str:\n    \"\"\"Waits for a single keypress on stdin.\n    -- from :: https://stackoverflow.com/a/6599441/4532996\n    \"\"\"\n\n    import termios, fcntl, sys, os\n    fd = sys.stdin.fileno()\n    # save old state\n    flags_save = fcntl.fcntl(fd, fcntl.F_GETFL)\n    attrs_save = termios.tcgetattr(fd)\n    # make raw - the way to do this comes from the termios(3) man page.\n    attrs = list(attrs_save) # copy the stored version to update\n    # iflag\n    attrs[0] &= ~(termios.IGNBRK | termios.BRKINT | termios.PARMRK\n                  | termios.ISTRIP | termios.INLCR | termios. IGNCR\n                  | termios.ICRNL | termios.IXON )\n    # oflag\n    attrs[1] &= ~termios.OPOST\n    # cflag\n    attrs[2] &= ~(termios.CSIZE | termios. PARENB)\n    attrs[2] |= termios.CS8\n    # lflag\n    attrs[3] &= ~(termios.ECHONL | termios.ECHO | termios.ICANON\n                  | termios.ISIG | termios.IEXTEN)\n    termios.tcsetattr(fd, termios.TCSANOW, attrs)\n    # turn off non-blocking\n    fcntl.fcntl(fd, fcntl.F_SETFL, flags_save & ~os.O_NONBLOCK)\n    # read a single keystroke\n    try:\n        ret = sys.stdin.read(1) # returns a single character\n    except KeyboardInterrupt:\n        ret = 0\n    finally:\n        # restore old state\n        termios.tcsetattr(fd, termios.TCSAFLUSH, attrs_save)\n        fcntl.fcntl(fd, fcntl.F_SETFL, flags_save)\n    return ret\n\ndef until_not_multi(chars) -> str:\n    \"\"\"read stdin until !(chars)\"\"\"\n    import sys\n    chars = list(chars)\n    y = \"\"\n    sys.stdout.flush()\n    while True:\n        i = read_single_keypress()\n        _ = sys.stdout.write(i)\n        sys.stdout.flush()\n        if i not in chars:\n            break\n        y += i\n    return y\n\ndef _can_you_vote() -> str:\n    \"\"\"a practical example:\n    test if a user can vote based purely on keypresses\"\"\"\n    print(\"can you vote? age : \", end=\"\")\n    x = int(\"0\" + until_not_multi(\"0123456789\"))\n    if not x:\n        print(\"\\nsorry, age can only consist of digits.\")\n        return\n    print(\"your age is\", x, \"\\nYou can vote!\" if x >= 18 else \"Sorry! you can't vote\")\n\n_can_you_vote()\n \n\n You can find the complete module  here . \n\n Example: \n\n $ ./input_constrain.py\ncan you vote? age : a\nsorry, age can only consist of digits.\n$ ./input_constrain.py \ncan you vote? age : 23<RETURN>\nyour age is 23\nYou can vote!\n$ _\n \n\n Note that the nature of this implementation is it closes stdin as soon as something that isn't a digit is read. I didn't hit enter after  a , but I needed to after the numbers. \n\n You could merge this with the  thismany()  function in the same module to only allow, say, three digits. \n    ", "date_posted": "2017-05-23 12:34:45Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "35110110", "name": "\r\n        3 revs", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "35110110", "stack_answer_comment_id": "114263253", "comment_content": "If you're already detecting key strokes, why allow characters at all and throw errors around, when you can just silently ignore them, until you get the desired number?", "user_id": null}, {"stack_answer_id": "35110110", "stack_answer_comment_id": "114279945", "comment_content": "@Kebman you could do that but it might be less obvious to the user what they can type", "user_id": null}]}, {"stack_answer_id": "64604056", "answer_content": "\r\n I am a big fan of Unix philosophy \"Do one thing and do it well\". Capturing user input and validating it are two separate steps: \n \n prompting the user for input with  get_input  until the input is ok \n validating using a  validator  function that can be passed to  get_input \n \n It can be kept as simple as (Python 3.8+, with  the walrus operator): \n def get_input(\n    prompt=\"Enter a value: \",\n    validator=lambda x: True,\n    error_message=\"Invalid input. Please try again.\",\n):\n    while not validator(value := input(prompt)):\n        print(error_message)\n    return value\n\ndef is_positive_int(value):\n    try:\n        return int(value) >= 0\n    except ValueError:\n        return False\n\nif __name__ == \"__main__\":\n    val = get_input(\"Give a positive number: \", is_positive_int)\n    print(f\"OK, thanks for {val}\")\n \n Sample run: \n Give a positive number: -5\nInvalid input. Please try again.\nGive a positive number: asdf\nInvalid input. Please try again.\nGive a positive number:\nInvalid input. Please try again.\nGive a positive number: 42\nOK, thanks for 42\n \n \n In Python < 3.8 you could use  get_input  like this: \n def get_input(\n    prompt=\"Enter a value: \",\n    validator=lambda x: True,\n    error_message=\"Invalid input. Please try again.\",\n):\n    while True:\n        value = input(prompt)\n        if validator(value):\n            return value\n        print(error_message)\n \n You might also handle  KeyboardInterrupt  and print a friendly exit message before terminating the application. A counter can be used to limit the allowed retries if desired. \n    ", "date_posted": "2022-01-28 06:18:26Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "64604056", "name": "\r\n        3 revs, 2 users 73%", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "63811753", "answer_content": "\r\n Use try-except to handle the error and repeat it again: \n while True:\n    try:\n        age = int(input(\"Please enter your age: \"))\n        if age >= 18:\n            print(\"You are able to vote in the United States!\")\n        else:\n            print(\"You are not able to vote in the United States.\")\n    except Exception as e:\n        print(\"please enter number\")\n \n    ", "date_posted": "2020-09-11 14:11:56Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "63811753", "name": "\r\n        2 revs, 2 users 62%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "63811753", "stack_answer_comment_id": "112906023", "comment_content": "You are missing a ", "user_id": null}]}, {"stack_answer_id": "53522191", "answer_content": "\r\n Building upon Daniel Q's and Patrick Artner's excellent suggestions,\nhere is an even more generalized solution. \n\n # Assuming Python3\nimport sys\n\nclass ValidationError(ValueError):  # thanks Patrick Artner\n    pass\n\ndef validate_input(prompt, cast=str, cond=(lambda x: True), onerror=None):\n    if onerror==None: onerror = {}\n    while True:\n        try:\n            data = cast(input(prompt))\n            if not cond(data): raise ValidationError\n            return data\n        except tuple(onerror.keys()) as e:  # thanks Daniel Q\n            print(onerror[type(e)], file=sys.stderr)\n \n\n I opted for explicit  if  and  raise  statements instead of an  assert ,\nbecause assertion checking may be turned off,\nwhereas validation should always be on to provide robustness. \n\n This may be used to get different kinds of input,\nwith different validation conditions.\nFor example: \n\n # No validation, equivalent to simple input:\nanystr = validate_input(\"Enter any string: \")\n\n# Get a string containing only letters:\nletters = validate_input(\"Enter letters: \",\n    cond=str.isalpha,\n    onerror={ValidationError: \"Only letters, please!\"})\n\n# Get a float in [0, 100]:\npercentage = validate_input(\"Percentage? \",\n    cast=float, cond=lambda x: 0.0<=x<=100.0,\n    onerror={ValidationError: \"Must be between 0 and 100!\",\n             ValueError: \"Not a number!\"})\n \n\n Or, to answer the original question: \n\n age = validate_input(\"Please enter your age: \",\n        cast=int, cond=lambda a:0<=a<150,\n        onerror={ValidationError: \"Enter a plausible age, please!\",\n                 ValueError: \"Enter an integer, please!\"})\nif age >= 18: \n    print(\"You are able to vote in the United States!\")\nelse:\n    print(\"You are not able to vote in the United States.\")\n \n    ", "date_posted": "2018-12-01 11:17:14Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "53522191", "name": "\r\n        3 revs", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "37989154", "answer_content": "\r\n def validate_age(age):\n    if age >=0 :\n        return True\n    return False\n\nwhile True:\n    try:\n        age = int(raw_input(\"Please enter your age:\"))\n        if validate_age(age): break\n    except ValueError:\n        print \"Error: Invalid age.\"\n \n    ", "date_posted": "2016-06-23 10:34:14Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "37989154", "name": "\r\n        ojas mohril\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "43704910", "answer_content": "\r\n Try this one:-  \n\n def takeInput(required):\n  print 'ooo or OOO to exit'\n  ans = raw_input('Enter: ')\n\n  if not ans:\n      print \"You entered nothing...!\"\n      return takeInput(required) \n\n      ##  FOR Exit  ## \n  elif ans in ['ooo', 'OOO']:\n    print \"Closing instance.\"\n    exit()\n\n  else:\n    if ans.isdigit():\n      current = 'int'\n    elif set('[~!@#$%^&*()_+{}\":/\\']+$').intersection(ans):\n      current = 'other'\n    elif isinstance(ans,basestring):\n      current = 'str'        \n    else:\n      current = 'none'\n\n  if required == current :\n    return ans\n  else:\n    return takeInput(required)\n\n## pass the value in which type you want [str/int/special character(as other )]\nprint \"input: \", takeInput('str')\n \n    ", "date_posted": "2017-04-30 09:29:28Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "43704910", "name": "\r\n        Pratik Anand\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "53827366", "answer_content": "\r\n Good question! You can try the following code for this. =) \n\n This code uses  ast.literal_eval()  to  find the data type of the input  ( age ). Then it follows the following algorithm: \n\n \n   \n   Ask user to input her/his  age . \n  \n   1.1. If  age  is  float  or  int  data type: \n  \n   \n   Check if  age>=18 . If  age>=18 , print appropriate output and exit. \n   Check if  0<age<18 . If  0<age<18 , print appropriate output and exit. \n   If  age<=0 , ask the user to input a valid number for age again, ( i.e.  go back to step 1.)  \n   \n  \n   1.2. If  age  is not  float  or  int  data type, then ask user to input her/his age again ( i.e.  go back to step 1.)  \n   \n \n\n Here is the code. \n\n from ast import literal_eval\n\n''' This function is used to identify the data type of input data.'''\ndef input_type(input_data):\n    try:\n        return type(literal_eval(input_data))\n    except (ValueError, SyntaxError):\n        return str\n\nflag = True\n\nwhile(flag):\n    age = raw_input(\"Please enter your age: \")\n\n    if input_type(age)==float or input_type(age)==int:\n        if eval(age)>=18: \n            print(\"You are able to vote in the United States!\") \n            flag = False \n        elif eval(age)>0 and eval(age)<18: \n            print(\"You are not able to vote in the United States.\") \n            flag = False\n        else: print(\"Please enter a valid number as your age.\")\n\n    else: print(\"Sorry, I didn't understand that.\") \n \n    ", "date_posted": "2018-12-18 06:54:35Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "53827366", "name": "\r\n        4 revs", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "46903575", "answer_content": "\r\n Use \"while\" statement till user enter a true value and if the input value is not a number or it's a null value skip it and try to ask again and so on.\nIn example I tried to answer truly your question. If we suppose that our age is between 1 and 150 then input value accepted, else it's a wrong value.\nFor terminating program, the user can use 0 key and enter it as a value. \n \n Note: Read comments top of code. \n \n # If your input value is only a number then use \"Value.isdigit() == False\".\n# If you need an input that is a text, you should remove \"Value.isdigit() == False\".\ndef Input(Message):\n    Value = None\n    while Value == None or Value.isdigit() == False:\n        try:        \n            Value = str(input(Message)).strip()\n        except Exception:\n            Value = None\n    return Value\n\n# Example:\nage = 0\n# If we suppose that our age is between 1 and 150 then input value accepted,\n# else it's a wrong value.\nwhile age <=0 or age >150:\n    age = int(Input(\"Please enter your age: \"))\n    # For terminating program, the user can use 0 key and enter it as an a value.\n    if age == 0:\n        print(\"Terminating ...\")\n        exit(0)\n        \nif age >= 18 and age <=150: \n    print(\"You are able to vote in the United States!\")\nelse:\n    print(\"You are not able to vote in the United States.\")\n \n    ", "date_posted": "2022-05-15 21:23:27Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "46903575", "name": "\r\n        6 revs, 2 users 99%", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "56833260", "answer_content": "\r\n You can always apply simple if-else logic and add one more  if  logic to your code along with a  for  loop. \n\n while True:\n     age = int(input(\"Please enter your age: \"))\n     if (age >= 18)  : \n         print(\"You are able to vote in the United States!\")\n     if (age < 18) & (age > 0):\n         print(\"You are not able to vote in the United States.\")\n     else:\n         print(\"Wrong characters, the input must be numeric\")\n         continue\n \n\n This will be an infinite loo and you would be asked to enter the age, indefinitely. \n    ", "date_posted": "2019-07-01 14:17:43Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "56833260", "name": "\r\n        2 revs", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "56833260", "stack_answer_comment_id": "100220085", "comment_content": "This doesn't really answer the question. The question was about getting a user input ", "user_id": null}]}, {"stack_answer_id": "37533486", "answer_content": "\r\n While a  try / except  block will work, a much faster and cleaner way to accomplish this task would be to use  str.isdigit() . \n\n while True:\n    age = input(\"Please enter your age: \")\n    if age.isdigit():\n        age = int(age)\n        break\n    else:\n        print(\"Invalid number '{age}'. Try again.\".format(age=age))\n\nif age >= 18: \n    print(\"You are able to vote in the United States!\")\nelse:\n    print(\"You are not able to vote in the United States.\")\n \n    ", "date_posted": "2016-06-06 07:15:17Z", "upvote": "\r\n            -1\r\n        ", "accepted": "No", "user": {"stack_user_id": "37533486", "name": "\r\n        2 revs", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "40396280", "answer_content": "\r\n You can write more general logic to allow user to enter only specific number of times, as the same use-case arises in many real-world applications. \n\n def getValidInt(iMaxAttemps = None):\n  iCount = 0\n  while True:\n    # exit when maximum attempt limit has expired\n    if iCount != None and iCount > iMaxAttemps:\n       return 0     # return as default value\n\n    i = raw_input(\"Enter no\")\n    try:\n       i = int(i)\n    except ValueError as e:\n       print \"Enter valid int value\"\n    else:\n       break\n\n    return i\n\nage = getValidInt()\n# do whatever you want to do.\n \n    ", "date_posted": "2016-11-03 07:49:29Z", "upvote": "\r\n            -1\r\n        ", "accepted": "No", "user": {"stack_user_id": "40396280", "name": "\r\n        Mangu Singh Rajpurohit\r\n        ", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "40396280", "stack_answer_comment_id": "72189955", "comment_content": "you forget to increase the iCount value after each loop", "user_id": null}]}, {"stack_answer_id": "48069871", "answer_content": "\r\n You can make the input statement a while True loop so it repeatedly asks for the users input and then break that loop if the user enters the response you would like. And you can use try and except blocks to handle invalid responses. \n\n while True:\n\n    var = True\n\n    try:\n        age = int(input(\"Please enter your age: \"))\n\n    except ValueError:\n        print(\"Invalid input.\")\n        var = False\n\n    if var == True:\n        if age >= 18:\n                print(\"You are able to vote in the United States.\")\n                break\n        else:\n            print(\"You are not able to vote in the United States.\")\n \n\n The var variable is just so that if the user enters a string instead of a integer the program wont return \"You are not able to vote in the United States.\" \n    ", "date_posted": "2018-01-03 00:59:37Z", "upvote": "\r\n            -1\r\n        ", "accepted": "No", "user": {"stack_user_id": "48069871", "name": "\r\n        user9142415\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "53207215", "answer_content": "\r\n One more solution for using input validation using a customized  ValidationError  and a (optional) range validation for integer inputs: \n\n class ValidationError(ValueError): \n    \"\"\"Special validation error - its message is supposed to be printed\"\"\"\n    pass\n\ndef RangeValidator(text,num,r):\n    \"\"\"Generic validator - raises 'text' as ValidationError if 'num' not in range 'r'.\"\"\"\n    if num in r:\n        return num\n    raise ValidationError(text)\n\ndef ValidCol(c): \n    \"\"\"Specialized column validator providing text and range.\"\"\"\n    return RangeValidator(\"Columns must be in the range of 0 to 3 (inclusive)\", \n                          c, range(4))\n\ndef ValidRow(r): \n    \"\"\"Specialized row validator providing text and range.\"\"\"\n    return RangeValidator(\"Rows must be in the range of 5 to 15(exclusive)\",\n                          r, range(5,15))\n \n\n Usage: \n\n def GetInt(text, validator=None):\n    \"\"\"Aks user for integer input until a valid integer is given. If provided, \n    a 'validator' function takes the integer and either raises a \n    ValidationError to be printed or returns the valid number. \n    Non integers display a simple error message.\"\"\"\n    print()\n    while True:\n        n = input(text)\n        try:\n            n = int(n)\n\n            return n if validator is None else validator(n)\n\n        except ValueError as ve:\n            # prints ValidationErrors directly - else generic message:\n            if isinstance(ve, ValidationError):\n                print(ve)\n            else:\n                print(\"Invalid input: \", n)\n\n\ncolumn = GetInt(\"Pleased enter column: \", ValidCol)\nrow = GetInt(\"Pleased enter row: \", ValidRow)\nprint( row, column)\n \n\n Output: \n\n Pleased enter column: 22\nColumns must be in the range of 0 to 3 (inclusive)\nPleased enter column: -2\nColumns must be in the range of 0 to 3 (inclusive)\nPleased enter column: 2\nPleased enter row: a\nInvalid input:  a\nPleased enter row: 72\nRows must be in the range of 5 to 15(exclusive)\nPleased enter row: 9  \n\n9, 2\n \n    ", "date_posted": "2018-11-08 12:04:20Z", "upvote": "\r\n            -1\r\n        ", "accepted": "No", "user": {"stack_user_id": "53207215", "name": "\r\n        3 revs", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "55681134", "answer_content": "\r\n Persistent user input using  recursive function : \n\n String \n\n def askName():\n    return input(\"Write your name: \").strip() or askName()\n\nname = askName()\n \n\n Integer \n\n def askAge():\n    try: return int(input(\"Enter your age: \"))\n    except ValueError: return askAge()\n\nage = askAge()\n \n\n and finally, the question requirement: \n\n def askAge():\n    try: return int(input(\"Enter your age: \"))\n    except ValueError: return askAge()\n\nage = askAge()\n\nresponseAge = [\n    \"You are able to vote in the United States!\",\n    \"You are not able to vote in the United States.\",\n][int(age < 18)]\n\nprint(responseAge)\n \n    ", "date_posted": "2019-04-15 13:56:05Z", "upvote": "\r\n            -1\r\n        ", "accepted": "No", "user": {"stack_user_id": "55681134", "name": "\r\n        4 revs", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "71106291", "answer_content": "\r\n You can try to convert it to a integer, but ask the user to repeat if it doesn't work. \n while True:\n    age = input('Please enter your age: ')\n    try:\n        age_int = int(age)\n        if age_int >= 18:\n            print('You can vote in the United States!')\n        else:\n            print('You cannot vote in the United States.')\n        break\n    except:\n        print('Please enter a meaningful answer.')\n        \n \n The while loop runs as long as the user has not inputted a meaningful answer, but breaks if it makes sense. \n    ", "date_posted": "2022-02-14 01:28:25Z", "upvote": "\r\n            -1\r\n        ", "accepted": "No", "user": {"stack_user_id": "71106291", "name": "\r\n        Python\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "67387649", "answer_content": "\r\n Use  isdigit()  to check if a string represents a valid integer. \n You could use a recursive function. \n def ask():\n    answer = input(\"Please enter amount to convert: \")\n    if not answer.isdigit():\n        print(\"Invalid\")\n        return ask()\n\n    return int(answer)\n\nGdp = ask()\n \n Or a while loop \n while True:\n    answer = input(\"Please enter amount to convert: \")\n    if not answer.isdigit():\n        print(\"Invalid\")\n        continue\n\n    Gbp = int(answer)\n \n    ", "date_posted": "2021-06-30 00:03:48Z", "upvote": "\r\n            -2\r\n        ", "accepted": "No", "user": {"stack_user_id": "67387649", "name": "\r\n        3 revs, 2 users 96%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "67387649", "stack_answer_comment_id": "119116330", "comment_content": "You're missing a ", "user_id": null}, {"stack_answer_id": "67387649", "stack_answer_comment_id": "119141460", "comment_content": "@Tomerikoo It recursively asks until the answer is valid, which I think is what was asked. I meant to write it in a way where you can put any code ", "user_id": null}, {"stack_answer_id": "67387649", "stack_answer_comment_id": "119142515", "comment_content": "What I mean is that you should test your code with some scenarios. In the first case, the ", "user_id": null}]}, {"stack_answer_id": "63447176", "answer_content": "\r\n Below code may help. \n age=(lambda i,f: f(i,f))(input(\"Please enter your age: \"),lambda i,f: i if i.isdigit() else f(input(\"Please enter your age: \"),f))\nprint(\"You are able to vote in the united states\" if int(age)>=18 else \"You are not able to vote in the united states\",end='')\n \n If you want to have maximum tries, say 3, use below code \n age=(lambda i,n,f: f(i,n,f))(input(\"Please enter your age: \"),1,lambda i,n,f: i if i.isdigit() else (None if n==3 else f(input(\"Please enter your age: \"),n+1,f)))\nprint(\"You are able to vote in the united states\" if age and int(age)>=18 else \"You are not able to vote in the united states\",end='')\n \n Note: This uses recursion. \n    ", "date_posted": "2020-08-17 17:21:22Z", "upvote": "\r\n            -4\r\n        ", "accepted": "No", "user": {"stack_user_id": "63447176", "name": "\r\n        3 revs", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "63447176", "stack_answer_comment_id": "125313509", "comment_content": "Don't use recursion to collect user input. Given enough retries, the app crashes. I don't understand the golfed code. Why not make it comprehensible?", "user_id": null}, {"stack_answer_id": "63447176", "stack_answer_comment_id": "125637607", "comment_content": "Teaching this to new users instead of a simple while-loop is obfuscatory and confusing.", "user_id": null}]}], "user": {"stack_user_id": null, "name": null, "reputation_score": 0}, "question_comments": []},
{"stack_question_id": "15112125", "question_title": "How to test multiple variables for equality against a single value?", "question_content": "\r\n                I'm trying to make a function that will compare multiple variables to an integer and output a string of three letters. I was wondering if there was a way to translate this into Python. So say:\nx = 0\ny ...\r\n", "question_url": "/questions/15112125/how-to-test-multiple-variables-for-equality-against-a-single-value", "date_posted": "Feb 27, 2013 at 12:26", "upvote": "8", "view": "4", "tags": ["python", "if-statement", "comparison", "match", "boolean-logic"], "answers_count": "3", "answers": [{"stack_answer_id": "15112149", "answer_content": "\r\n You misunderstand how boolean expressions work; they don't work like an English sentence and guess that you are talking about the same comparison for all names here. You are looking for: \n if x == 1 or y == 1 or z == 1:\n \n x  and  y  are otherwise evaluated on their own ( False  if  0 ,  True  otherwise). \n You can shorten that using a containment test against  a tuple : \n if 1 in (x, y, z):\n \n or better still: \n if 1 in {x, y, z}:\n \n using  a  set  to take advantage of the constant-cost membership test (i.e.  in  takes a fixed amount of time whatever the left-hand operand is). \n Explanation \n When you use  or , python sees each side of the operator as  separate  expressions. The expression  x or y == 1  is treated as first a boolean test for  x , then if that is False, the expression  y == 1  is tested. \n This is due to  operator precedence . The  or  operator has a lower precedence than the  ==  test, so the latter is evaluated  first . \n However, even if this were  not  the case, and the expression  x or y or z == 1  was actually interpreted as  (x or y or z) == 1  instead, this would still not do what you expect it to do. \n x or y or z  would evaluate to the first argument that is 'truthy', e.g. not  False , numeric 0 or empty (see  boolean expressions  for details on what Python considers false in a boolean context). \n So for the values  x = 2; y = 1; z = 0 ,  x or y or z  would resolve to  2 , because that is the first true-like value in the arguments. Then  2 == 1  would be  False , even though  y == 1  would be  True . \n The same would apply to the inverse; testing multiple values against a single variable;  x == 1 or 2 or 3  would fail for the same reasons. Use  x == 1 or x == 2 or x == 3  or  x in {1, 2, 3} . \n    ", "date_posted": "2021-04-02 01:51:27Z", "upvote": "\r\n            1068\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "4518341", "name": "wjandrea", "reputation_score": "24.1k"}, "answer_comments": [{"stack_answer_id": "15112149", "stack_answer_comment_id": "29042397", "comment_content": "I wouldn't be so quick to go for the ", "user_id": null}, {"stack_answer_id": "15112149", "stack_answer_comment_id": "29042516", "comment_content": "@dequestarmappartialsetattr: In Python 3.3 and up, the set is stored as a constant, bypassing the creation time altogether, eliminating the creation time. Tuples ", "user_id": null}, {"stack_answer_id": "15112149", "stack_answer_comment_id": "29042794", "comment_content": "@dequestarmappartialsetattr: If you time ", "user_id": null}, {"stack_answer_id": "15112149", "stack_answer_comment_id": "65957961", "comment_content": "@MartijnPieters: Using the ", "user_id": null}, {"stack_answer_id": "15112149", "stack_answer_comment_id": "65961841", "comment_content": "@ShadowRanger: yes, peephole optimisation (be it for ", "user_id": null}]}, {"stack_answer_id": "17604212", "answer_content": "\r\n Your problem is more easily addressed with a dictionary structure like: \n\n x = 0\ny = 1\nz = 3\nd = {0: 'c', 1:'d', 2:'e', 3:'f'}\nmylist = [d[k] for k in [x, y, z]]\n \n    ", "date_posted": "2017-10-25 14:45:52Z", "upvote": "\r\n            116\r\n        ", "accepted": "No", "user": {"stack_user_id": "3745896", "name": "River", "reputation_score": "8,150"}, "answer_comments": [{"stack_answer_id": "17604212", "stack_answer_comment_id": "29042877", "comment_content": "Or even ", "user_id": null}, {"stack_answer_id": "17604212", "stack_answer_comment_id": "36122660", "comment_content": "or ", "user_id": null}, {"stack_answer_id": "17604212", "stack_answer_comment_id": "96927060", "comment_content": "Aside from the list comprehension which I'm not yet fully accustomed to, most of us had the same reflex: build that dict !", "user_id": null}]}, {"stack_answer_id": "32085628", "answer_content": "\r\n As stated by Martijn Pieters, the correct, and fastest, format is: \n\n if 1 in {x, y, z}:\n \n\n Using his advice you would now have separate if-statements so that Python will read each statement whether the former were  True  or  False . Such as: \n\n if 0 in {x, y, z}:\n    mylist.append(\"c\")\nif 1 in {x, y, z}:\n    mylist.append(\"d\")\nif 2 in {x, y, z}:\n    mylist.append(\"e\")\n...\n \n\n This will work, but  if  you are comfortable using dictionaries (see what I did there), you can clean this up by making an initial dictionary mapping the numbers to the letters you want, then just using a for-loop: \n\n num_to_letters = {0: \"c\", 1: \"d\", 2: \"e\", 3: \"f\"}\nfor number in num_to_letters:\n    if number in {x, y, z}:\n        mylist.append(num_to_letters[number])\n \n    ", "date_posted": "2019-05-07 09:30:20Z", "upvote": "\r\n            76\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "32085628", "stack_answer_comment_id": "115011428", "comment_content": "@VisioN You mean ", "user_id": null}, {"stack_answer_id": "32085628", "stack_answer_comment_id": "115018668", "comment_content": "@wjandrea Yes, you are right, it's my mistake! I completely forgot about the default behaviour. Unfortunately, I cannot edit my comment, so I have deleted it since you have highlighted the better approach in your comment.", "user_id": null}]}, {"stack_answer_id": "17603667", "answer_content": "\r\n The direct way to write  x or y or z == 0  is \n\n if any(map((lambda value: value == 0), (x,y,z))):\n    pass # write your logic.\n \n\n But I dont think, you like it. :)\nAnd this way is ugly. \n\n The other way (a better) is: \n\n 0 in (x, y, z)\n \n\n BTW lots of  if s could be written as something like this \n\n my_cases = {\n    0: Mylist.append(\"c\"),\n    1: Mylist.append(\"d\")\n    # ..\n}\n\nfor key in my_cases:\n    if key in (x,y,z):\n        my_cases[key]()\n        break\n \n    ", "date_posted": "2013-07-11 21:24:59Z", "upvote": "\r\n            53\r\n        ", "accepted": "No", "user": {"stack_user_id": "1243636", "name": "akaRem", "reputation_score": "6,886"}, "answer_comments": [{"stack_answer_id": "17603667", "stack_answer_comment_id": "32723572", "comment_content": "In your example of the ", "user_id": null}, {"stack_answer_id": "17603667", "stack_answer_comment_id": "97810895", "comment_content": "the dict instead of a key is wrong, you will get Mylist=['c', 'd'] when the dictionary get initialized even if you commented out \"for..loop\" part", "user_id": null}, {"stack_answer_id": "17603667", "stack_answer_comment_id": "102313779", "comment_content": "In your first example ", "user_id": null}, {"stack_answer_id": "17603667", "stack_answer_comment_id": "106339378", "comment_content": "A comprehension is much simpler than a map of a lambda: ", "user_id": null}]}, {"stack_answer_id": "30430962", "answer_content": "\r\n If you ARE very very lazy, you can put the values inside an array. Such as \n\n list = []\nlist.append(x)\nlist.append(y)\nlist.append(z)\nnums = [add numbers here]\nletters = [add corresponding letters here]\nfor index in range(len(nums)):\n    for obj in list:\n        if obj == num[index]:\n            MyList.append(letters[index])\n            break\n \n\n You can also put the numbers and letters in a dictionary and do it, but this is probably a LOT more complicated than simply if statements. That's what you get for trying to be extra lazy :) \n\n One more thing, your  \n\n if x or y or z == 0:\n \n\n will compile, but not in the way you want it to. When you simply put a variable in an if statement (example) \n\n if b\n \n\n the program will check if the variable is not null. Another way to write the above statement (which makes more sense) is  \n\n if bool(b)\n \n\n Bool is an inbuilt function in python which basically does the command of verifying a boolean statement (If you don't know what that is, it is what you are trying to make in your if statement right now :)) \n\n Another lazy way I found is : \n\n if any([x==0, y==0, z==0])\n \n    ", "date_posted": "2015-08-13 18:06:52Z", "upvote": "\r\n            34\r\n        ", "accepted": "No", "user": {"stack_user_id": "4871483", "name": "rassa45", "reputation_score": "3,406"}, "answer_comments": [{"stack_answer_id": "30430962", "stack_answer_comment_id": "106339486", "comment_content": "-1 There's a lot of bad practice here. ", "user_id": null}]}, {"stack_answer_id": "24043508", "answer_content": "\r\n To check if a value is contained within a set of variables you can use the inbuilt modules            itertools  and  operator . \n\n For example: \n\n Imports: \n\n from itertools import repeat\nfrom operator import contains\n \n\n Declare variables: \n\n x = 0\ny = 1\nz = 3\n \n\n Create mapping of values (in the order you want to check): \n\n check_values = (0, 1, 3)\n \n\n Use  itertools  to allow repetition of the variables: \n\n check_vars = repeat((x, y, z))\n \n\n Finally, use the  map  function to create an iterator: \n\n checker = map(contains, check_vars, check_values)\n \n\n Then, when checking for the values (in the original order), use  next() : \n\n if next(checker)  # Checks for 0\n    # Do something\n    pass\nelif next(checker)  # Checks for 1\n    # Do something\n    pass\n \n\n etc... \n\n This has an advantage over the  lambda x: x in (variables)  because  operator  is an inbuilt module and is faster and more efficient than using  lambda  which has to create a custom in-place function. \n\n Another option for checking if there is a non-zero (or False) value in a list: \n\n not (x and y and z)\n \n\n Equivalent: \n\n not all((x, y, z))\n \n    ", "date_posted": "2014-06-05 11:31:39Z", "upvote": "\r\n            33\r\n        ", "accepted": "No", "user": {"stack_user_id": "3551468", "name": "GuiltyDolphin", "reputation_score": "738"}, "answer_comments": [{"stack_answer_id": "24043508", "stack_answer_comment_id": "37069084", "comment_content": "This doesn't answer the OP's question.  It only covers the first case in the provided example.", "user_id": null}]}, {"stack_answer_id": "30742519", "answer_content": "\r\n Set is the good approach here, because it orders the variables, what seems to be your goal here.  {z,y,x}  is  {0,1,3}  whatever the order of the parameters. \n\n >>> [\"cdef\"[i] for i in {z,x,y}]\n['c', 'd', 'f']\n \n\n This way, the whole solution is O(n). \n    ", "date_posted": "2018-04-01 13:10:46Z", "upvote": "\r\n            31\r\n        ", "accepted": "No", "user": {"stack_user_id": "4016285", "name": "B. M.", "reputation_score": "17.6k"}, "answer_comments": []}, {"stack_answer_id": "27921870", "answer_content": "\r\n I think this will handle it better: \n\n my_dict = {0: \"c\", 1: \"d\", 2: \"e\", 3: \"f\"}\n\ndef validate(x, y, z):\n    for ele in [x, y, z]:\n        if ele in my_dict.keys():\n            return my_dict[ele]\n \n\n Output: \n\n print validate(0, 8, 9)\nc\nprint validate(9, 8, 9)\nNone\nprint validate(9, 8, 2)\ne\n \n    ", "date_posted": "2015-02-10 14:58:02Z", "upvote": "\r\n            30\r\n        ", "accepted": "No", "user": {"stack_user_id": "296460", "name": "shuttle87", "reputation_score": "14.9k"}, "answer_comments": []}, {"stack_answer_id": "29552841", "answer_content": "\r\n If you want to use if, else statements following is another solution: \n\n myList = []\naList = [0, 1, 3]\n\nfor l in aList:\n    if l==0: myList.append('c')\n    elif l==1: myList.append('d')\n    elif l==2: myList.append('e')\n    elif l==3: myList.append('f')\n\nprint(myList)\n \n    ", "date_posted": "2018-09-04 03:53:17Z", "upvote": "\r\n            30\r\n        ", "accepted": "No", "user": {"stack_user_id": "1794144", "name": "Vishvajit Pathak", "reputation_score": "2,963"}, "answer_comments": []}, {"stack_answer_id": "39427752", "answer_content": "\r\n All of the excellent answers provided here concentrate on the specific requirement of the original poster and concentrate on the  if 1 in {x,y,z}  solution put forward by Martijn Pieters. \nWhat they ignore is the broader implication of the question: \n How do I test one variable against multiple values? \nThe solution provided will not work for partial hits if using strings for example: \nTest if the string \"Wild\" is in multiple values \n\n >>> x = \"Wild things\"\n>>> y = \"throttle it back\"\n>>> z = \"in the beginning\"\n>>> if \"Wild\" in {x, y, z}: print (True)\n... \n \n\n or \n\n >>> x = \"Wild things\"\n>>> y = \"throttle it back\"\n>>> z = \"in the beginning\"\n>>> if \"Wild\" in [x, y, z]: print (True)\n... \n \n\n for this scenario it's easiest to convert to a string \n\n >>> [x, y, z]\n['Wild things', 'throttle it back', 'in the beginning']\n>>> {x, y, z}\n{'in the beginning', 'throttle it back', 'Wild things'}\n>>> \n\n>>> if \"Wild\" in str([x, y, z]): print (True)\n... \nTrue\n>>> if \"Wild\" in str({x, y, z}): print (True)\n... \nTrue\n \n\n It should be noted however, as mentioned by  @codeforester , that word boundries are lost with this method, as in:     \n\n >>> x=['Wild things', 'throttle it back', 'in the beginning']\n>>> if \"rot\" in str(x): print(True)\n... \nTrue\n \n\n the 3 letters  rot  do exist in combination in the list but not as an individual word. Testing for \" rot \" would fail but if one of the list items were \"rot in hell\", that would fail as well. \nThe upshot being, be careful with your search criteria if using this method and be aware that it does have this limitation. \n    ", "date_posted": "2018-09-04 11:59:05Z", "upvote": "\r\n            30\r\n        ", "accepted": "No", "user": {"stack_user_id": "1794144", "name": "Vishvajit Pathak", "reputation_score": "2,963"}, "answer_comments": []}, {"stack_answer_id": "28756031", "answer_content": "\r\n d = {0:'c', 1:'d', 2:'e', 3: 'f'}\nx, y, z = (0, 1, 3)\nprint [v for (k,v) in d.items() if x==k or y==k or z==k]\n \n    ", "date_posted": "2015-02-27 01:48:29Z", "upvote": "\r\n            26\r\n        ", "accepted": "No", "user": {"stack_user_id": "4596008", "name": "Saksham Varma", "reputation_score": "2,072"}, "answer_comments": []}, {"stack_answer_id": "31109647", "answer_content": "\r\n This code may be helpful \n\n L ={x, y, z}\nT= ((0,\"c\"),(1,\"d\"),(2,\"e\"),(3,\"f\"),)\nList2=[]\nfor t in T :\nif t[0] in L :\n    List2.append(t[1])\n    break;\n \n    ", "date_posted": "2015-06-29 07:03:58Z", "upvote": "\r\n            26\r\n        ", "accepted": "No", "user": {"stack_user_id": "4621874", "name": "michael zxc858", "reputation_score": "385"}, "answer_comments": []}, {"stack_answer_id": "53587823", "answer_content": "\r\n You can try the method shown below. In this method, you will have the freedom to specify/input the number of variables that you wish to enter. \n\n mydict = {0:\"c\", 1:\"d\", 2:\"e\", 3:\"f\"}\nmylist= []\n\nnum_var = int(raw_input(\"How many variables? \")) #Enter 3 when asked for input.\n\nfor i in range(num_var): \n    ''' Enter 0 as first input, 1 as second input and 3 as third input.'''\n    globals()['var'+str('i').zfill(3)] = int(raw_input(\"Enter an integer between 0 and 3 \"))\n    mylist += mydict[globals()['var'+str('i').zfill(3)]]\n\nprint mylist\n>>> ['c', 'd', 'f']\n \n    ", "date_posted": "2018-12-03 05:13:18Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "10626090", "name": "Siddharth Satpathy", "reputation_score": "2,513"}, "answer_comments": []}, {"stack_answer_id": "44363221", "answer_content": "\r\n One line solution: \n\n mylist = [{0: 'c', 1: 'd', 2: 'e', 3: 'f'}[i] for i in [0, 1, 2, 3] if i in (x, y, z)]\n \n\n Or: \n\n mylist = ['cdef'[i] for i in range(4) if i in (x, y, z)]\n \n    ", "date_posted": "2017-06-05 06:50:28Z", "upvote": "\r\n            10\r\n        ", "accepted": "No", "user": {"stack_user_id": "3857234", "name": "Vinayak Kaniyarakkal", "reputation_score": "1,052"}, "answer_comments": []}, {"stack_answer_id": "54736001", "answer_content": "\r\n Maybe you need direct formula for output bits set. \n\n x=0 or y=0 or z=0   is equivalent to x*y*z = 0\n\nx=1 or y=1 or z=1   is equivalent to (x-1)*(y-1)*(z-1)=0\n\nx=2 or y=2 or z=2   is equivalent to (x-2)*(y-2)*(z-2)=0\n \n\n Let's map to bits:  'c':1 'd':0xb10 'e':0xb100 'f':0xb1000 \n\n Relation of isc (is 'c'): \n\n if xyz=0 then isc=1 else isc=0\n \n\n Use math if formula  https://youtu.be/KAdKCgBGK0k?list=PLnI9xbPdZUAmUL8htSl6vToPQRRN3hhFp&t=315 \n\n [c]:  (xyz=0 and isc=1) or (((xyz=0 and isc=1) or (isc=0)) and (isc=0)) \n\n [d]:  ((x-1)(y-1)(z-1)=0 and isc=2) or (((xyz=0 and isd=2) or (isc=0)) and (isc=0)) \n\n ... \n\n Connect these formulas by following logic: \n\n \n logic  and  is the sum of squares of equations \n logic  or  is the product of equations \n \n\n and you'll have a total equation\nexpress sum and you have total formula of sum \n\n then sum&1 is c, sum&2 is d, sum&4 is e, sum&5 is f \n\n After this you may form predefined array where index of string elements would correspond to ready string. \n\n array[sum]  gives you the string. \n    ", "date_posted": "2019-04-10 17:49:04Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "874188", "name": "tripleee", "reputation_score": "162k"}, "answer_comments": []}, {"stack_answer_id": "51701671", "answer_content": "\r\n The most pythonic way of representing your pseudo-code in Python would be: \n x = 0\ny = 1\nz = 3\nmylist = []\n\nif any(v == 0 for v in (x, y, z)):\n    mylist.append(\"c\")\nif any(v == 1 for v in (x, y, z)):\n    mylist.append(\"d\")\nif any(v == 2 for v in (x, y, z)):\n    mylist.append(\"e\")\nif any(v == 3 for v in (x, y, z)):\n    mylist.append(\"f\")\n \n    ", "date_posted": "2020-07-11 00:08:50Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "1296256", "name": "rsalmei", "reputation_score": "2,573"}, "answer_comments": [{"stack_answer_id": "51701671", "stack_answer_comment_id": "98608899", "comment_content": "This approach is more universal than ` if 2 in (x, y, z): mylist.append('e')` because allows arbitrary comparisons (e.g. ", "user_id": null}]}, {"stack_answer_id": "53173901", "answer_content": "\r\n It can be done easily as  \n\n for value in [var1,var2,var3]:\n     li.append(\"targetValue\")\n \n    ", "date_posted": "2018-11-06 14:26:24Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "6489768", "name": "Seeni", "reputation_score": "1,384"}, "answer_comments": []}, {"stack_answer_id": "52416636", "answer_content": "\r\n To test multiple variables with one single value:  if 1 in {a,b,c}: \n\n To test multiple values with one variable:  if a in {1, 2, 3}: \n    ", "date_posted": "2018-09-20 02:18:55Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "4813600", "name": "alamin", "reputation_score": "2,269"}, "answer_comments": []}, {"stack_answer_id": "52036618", "answer_content": "\r\n Looks like you're building some kind of Caesar cipher. \n\n A much more generalized approach is this: \n\n input_values = (0, 1, 3)\norigo = ord('c')\n[chr(val + origo) for val in inputs]\n \n\n outputs \n\n ['c', 'd', 'f']\n \n\n Not sure if it's a desired side effect of your code, but the order of your output will always be sorted. \n\n If this is what you want, the final line can be changed to: \n\n sorted([chr(val + origo) for val in inputs])\n \n    ", "date_posted": "2018-08-27 09:45:00Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "3730397", "name": "firelynx", "reputation_score": "29.2k"}, "answer_comments": []}, {"stack_answer_id": "51618459", "answer_content": "\r\n You can use dictionary : \n\n x = 0\ny = 1\nz = 3\nlist=[]\ndict = {0: 'c', 1: 'd', 2: 'e', 3: 'f'}\nif x in dict:\n    list.append(dict[x])\nelse:\n    pass\n\nif y in dict:\n    list.append(dict[y])\nelse:\n    pass\nif z in dict:\n    list.append(dict[z])\nelse:\n    pass\n\nprint list\n \n    ", "date_posted": "2018-07-31 16:54:00Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "9010283", "name": "Rohit Gawas", "reputation_score": "237"}, "answer_comments": [{"stack_answer_id": "51618459", "stack_answer_comment_id": "96299106", "comment_content": "This may append same more then once this. Set?", "user_id": null}]}, {"stack_answer_id": "58341108", "answer_content": "\r\n Without dict, try this solution: \n\n x, y, z = 0, 1, 3    \noffset = ord('c')\n[chr(i + offset) for i in (x,y,z)]\n \n\n and gives: \n\n ['c', 'd', 'f']\n \n    ", "date_posted": "2019-10-11 12:17:15Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "9302488", "name": "Massifox", "reputation_score": "3,921"}, "answer_comments": []}, {"stack_answer_id": "55543926", "answer_content": "\r\n This will help you. \n\n def test_fun(val):\n    x = 0\n    y = 1\n    z = 2\n    myList = []\n    if val in (x, y, z) and val == 0:\n        myList.append(\"C\")\n    if val in (x, y, z) and val == 1:\n        myList.append(\"D\")\n    if val in (x, y, z) and val == 2:\n        myList.append(\"E\")\n\ntest_fun(2);\n \n    ", "date_posted": "2019-04-08 05:18:38Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "9896794", "name": "Karan Shah", "reputation_score": "91"}, "answer_comments": []}, {"stack_answer_id": "57859331", "answer_content": "\r\n You can unite this \n\n x = 0\ny = 1\nz = 3\n \n\n in one variable. \n\n In [1]: xyz = (0,1,3,) \nIn [2]: mylist = []\n \n\n Change our conditions as: \n\n In [3]: if 0 in xyz: \n    ...:     mylist.append(\"c\") \n    ...: if 1 in xyz: \n    ...:     mylist.append(\"d\") \n    ...: if 2 in xyz: \n    ...:     mylist.append(\"e\") \n    ...: if 3 in xyz:  \n    ...:     mylist.append(\"f\") \n \n\n Output: \n\n In [21]: mylist                                                                                \nOut[21]: ['c', 'd', 'f']\n \n    ", "date_posted": "2019-09-09 18:23:24Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "9093112", "name": "Serhii", "reputation_score": "1,033"}, "answer_comments": []}, {"stack_answer_id": "63811246", "answer_content": "\r\n you can develop it through two ways \n     def compareVariables(x,y,z):\n        mylist = []\n        if x==0 or y==0 or z==0:\n            mylist.append('c')\n        if  x==1 or y==1 or z==1:\n            mylist.append('d')\n        if  x==2 or y==2 or z==2:\n            mylist.append('e')\n        if  x==3 or y==3 or z==3:\n            mylist.append('f')\n        else:\n            print(\"wrong input value!\")\n        print('first:',mylist)\n\n        compareVariables(1, 3, 2)\n \n Or \n     def compareVariables(x,y,z):\n        mylist = []\n        if 0 in (x,y,z):\n             mylist.append('c')\n        if 1 in (x,y,z):\n             mylist.append('d')\n        if 2 in (x,y,z):\n             mylist.append('e')\n        if 3 in (x,y,z):\n             mylist.append('f')\n        else:\n             print(\"wrong input value!\")\n        print('second:',mylist)\n\n        compareVariables(1, 3, 2)\n \n    ", "date_posted": "2020-09-24 15:21:04Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "2308683", "name": "OneCricketeer", "reputation_score": "157k"}, "answer_comments": []}, {"stack_answer_id": "67049356", "answer_content": "\r\n The  or  does not work like that, as  explained by this answer . \n While the generic answer would be use \n if 0 in (x, y, z):\n    ...\n \n this is not the best one for the  specific  problem. In your case you're doing  repeated tests , therefore it is worthwhile to compose a  set  of these variables: \n values = {x, y, z}\n\nif 0 in values:\n    mylist.append(\"c\")\n\nif 1 in values:\n    mylist.append(\"d\")\n \n We can simplify this using a dictionary - this will result in the same values: \n mappings = {0: \"c\", 1: \"d\", ...}\nfor k in mappings:\n    if k in values:\n        mylist.append(mappings[k])\n \n Or if the ordering of the  mylist  is arbitrary, you can loop over the  values  instead and match them to the mappings: \n mappings = {0: \"c\", 1: \"d\", ...}\nfor v in (x, y, z):\n    if v in mappings:\n        mylist.append(mappings[v])\n \n    ", "date_posted": "2021-04-11 19:30:17Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "918959", "name": "Antti Haapala -- \u0421\u043b\u0430\u0432\u0430 \u0423\u043a\u0440\u0430\u0457\u043d\u0456", "reputation_score": "125k"}, "answer_comments": []}, {"stack_answer_id": "58728816", "answer_content": "\r\n Problem \n\n While the pattern for testing multiple values \n\n >>> 2 in {1, 2, 3}\nTrue\n>>> 5 in {1, 2, 3}\nFalse\n \n\n is very readable and is working in many situation, there is one pitfall: \n\n >>> 0 in {True, False}\nTrue\n \n\n But we want to have \n\n >>> (0 is True) or (0 is False)\nFalse\n \n\n Solution \n\n One generalization of the previous expression is based on the answer from  ytpillai : \n\n >>> any([0 is True, 0 is False])\nFalse\n \n\n which can be written as \n\n >>> any(0 is item for item in (True, False))\nFalse\n \n\n While this expression returns the right result it is not as readable as the first expression :-( \n    ", "date_posted": "2019-11-06 11:20:35Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "5599281", "name": "fhgd", "reputation_score": "392"}, "answer_comments": []}, {"stack_answer_id": "66398859", "answer_content": "\r\n Here is one more way to do it: \n x = 0\ny = 1\nz = 3\nmylist = []\n\nif any(i in [0] for i in[x,y,z]):\n    mylist.append(\"c\")\nif any(i in [1] for i in[x,y,z]):\n    mylist.append(\"d\")\nif any(i in [2] for i in[x,y,z]):\n    mylist.append(\"e\")\nif any(i in [3] for i in[x,y,z]):\n    mylist.append(\"f\")\n \n It is a mix of  list comprehension  and  any  keyword. \n    ", "date_posted": "2021-04-12 01:33:17Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "15127315", "name": "Abhishek Kumar Saw", "reputation_score": "349"}, "answer_comments": [{"stack_answer_id": "66398859", "stack_answer_comment_id": "118539367", "comment_content": "Why ", "user_id": null}, {"stack_answer_id": "66398859", "stack_answer_comment_id": "118547903", "comment_content": "For a single comparison like in this question, you can use \"==\" but if you want multiple comparisons with multiple variables, then you can use the \"in\" operator like: if any(i in [0,5,4,9,7] for i in[x,y,z] )", "user_id": null}]}, {"stack_answer_id": "70816486", "answer_content": "\r\n usage without if example: \n x,y,z = 0,1,3\nvalues = {0:\"c\",1:\"d\",2:\"e\",3:\"f\"} # => as if usage\nmy_list = [values[i] for i in (x,y,z)]\n\nprint(my_list)\n \n    ", "date_posted": "2022-01-22 19:40:34Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "15343205", "name": "SimoN SavioR", "reputation_score": "469"}, "answer_comments": []}, {"stack_answer_id": "72422109", "answer_content": "\r\n FIRST, A CORRECTION TO THE  OR  CONDITIONAL: \n You need to say: \n if x == 0 or y == 0 or z == 0:\n \n The reason is that \"or\" splits up the condition into separate logical parts. The way your original statement was written, those parts were: \n x\ny\nz == 0   // or 1, 2, 3 depending on the if statement\n \n The last part was fine --- checking to see if z == 0, for instance --- but the first two parts just said essentially  if x  and  if y . Since integers always evaluate to  True  unless they're 0, that means the first part of your condition was always  True  when  x  or  y  didn't equal 0 (which in the case of y was always, since you had  y = 1 , causing your whole condition (because of how  OR  works) to always be  True . \n To avoid that, you need to make sure all parts of your condition (each side of the  OR ) make sense on their own (you can do that by pretending that the other side(s) of the  OR  statement doesn't exist). That's how you can confirm whether or not your  OR  condition is correctly defined. \n You would write the statements individually like so: \n if x == 0\nif y == 0\nif z == 0\n \n which means the correct mergin with the  OR  keyword would be: \n if x == 0 or y == 0 or z == 0\n \n SECOND, HOW TO SOLVE THE PROBLEM: \n You're basically wanting to check to see if any of the variables match a given integer and if so, assign it a letter that matches it in a one-to-one mapping. You want to do that for a certain list of integers so that the output is a list of letters. You'd do that like this: \n def func(x, y, z):\n\n    result = []\n\n    for integer, letter in zip([0, 1, 2, 3], ['c', 'd', 'e', 'f']):\n        if x == integer or y == integer or z == integer:\n            result.append(letter)\n            \n    return result\n        \n \n Similarly, you could use LIST COMPREHENSION to achieve the same result faster: \n def func(x, y, z):\n\n    return [ \n                letter \n                for integer, letter in zip([0, 1, 2, 3], ['c', 'd', 'e', 'f'])\n                if x == integer or y == integer or z == integer\n           ]\n    \n    \n \n    ", "date_posted": "2022-05-29 08:35:13Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "5026136", "name": "Elliptica", "reputation_score": "3,266"}, "answer_comments": []}, {"stack_answer_id": "72539339", "answer_content": "\r\n #selection\n: a=np.array([0,1,3])                                                                                                                                                 \n\n#options\n: np.diag(['c','d','e','f']) \narray([['c', '', '', ''],\n       ['', 'd', '', ''],\n       ['', '', 'e', ''],\n       ['', '', '', 'f']], dtype='<U1')\n \n now we can use  a  as [row,col] selector, which acts as if any(...) condition : \n #list of options[sel,sel]\n: np.diag(['c','d','e','f'])[a,a]                                                                                                                                     \n\n array(['c', 'd', 'f'], dtype='<U1')\n \n    ", "date_posted": "2022-07-18 23:51:34Z", "upvote": "\r\n            -1\r\n        ", "accepted": "No", "user": {"stack_user_id": "1019129", "name": "sten", "reputation_score": "6,476"}, "answer_comments": [{"stack_answer_id": "72539339", "stack_answer_comment_id": "129689739", "comment_content": "I don't think the question is asking about numpy", "user_id": null}]}], "user": {"stack_user_id": "1877442", "name": "user1877442", "reputation_score": "8,201"}, "question_comments": [{"stack_question_id": "15112125", "stack_question_comment_id": "82285672", "comment_content": "use ", "user_id": null}, {"stack_question_id": "15112125", "stack_question_comment_id": "88379334", "comment_content": "When you want to evaluate a list of statements in a any/all manner you can use ", "user_id": null}, {"stack_question_id": "15112125", "stack_question_comment_id": "97914247", "comment_content": "This question is a very popular duplicate target, but I think it's suboptimal for that purpose. Most people try to do something like ", "user_id": null}, {"stack_question_id": "15112125", "stack_question_comment_id": "97914372", "comment_content": "Take extra care when comparing to \"falsey\" values like ", "user_id": null}, {"stack_question_id": "15112125", "stack_question_comment_id": "105448818", "comment_content": "For the opposite, see ", "user_id": null}]},
{"stack_question_id": "20449427", "question_title": "How can I read inputs as numbers?", "question_content": "\r\n                Why are x and y strings instead of ints in the below code?\n\n(Note: in Python 2.x use raw_input(). In Python 3.x use input(). raw_input() was renamed to input() in Python 3.x)\n\nplay = True\n\nwhile play:\n...\r\n", "question_url": "/questions/20449427/how-can-i-read-inputs-as-numbers", "date_posted": "Dec 8, 2013 at 3:08", "upvote": "2", "view": "1", "tags": ["python", "python-3.x", "python-2.7", "input", "int"], "answers_count": "1", "answers": [{"stack_answer_id": "20449433", "answer_content": "\r\n Solution \n Since Python 3,  input  returns a string which you have to explicitly convert to  int s, with  int , like this \n x = int(input(\"Enter a number: \"))\ny = int(input(\"Enter a number: \"))\n \n You can accept numbers of any base and convert them directly to base-10 with the  int  function, like this \n >>> data = int(input(\"Enter a number: \"), 8)\nEnter a number: 777\n>>> data\n511\n>>> data = int(input(\"Enter a number: \"), 16)\nEnter a number: FFFF\n>>> data\n65535\n>>> data = int(input(\"Enter a number: \"), 2)\nEnter a number: 10101010101\n>>> data\n1365\n \n The second parameter tells what is the base of the numbers entered and then internally it understands and converts it. If the entered data is wrong it will throw a  ValueError . \n >>> data = int(input(\"Enter a number: \"), 2)\nEnter a number: 1234\nTraceback (most recent call last):\n  File \"<input>\", line 1, in <module>\nValueError: invalid literal for int() with base 2: '1234'\n \n For values that can have a fractional component, the type would be  float  rather than  int : \n x = float(input(\"Enter a number:\"))\n \n Differences between Python 2 and 3 \n Summary \n \n Python 2's  input  function evaluated the received data, converting it to an integer implicitly (read the next section to understand the implication), but Python 3's  input  function does not do that anymore. \n Python 2's equivalent of Python 3's  input  is the  raw_input  function. \n \n Python 2.x \n There were two functions to get user input, called  input  and  raw_input . The difference between them is,  raw_input  doesn't evaluate the data and returns as it is, in string form. But,  input  will evaluate whatever you entered and the result of evaluation will be returned. For example, \n >>> import sys\n>>> sys.version\n'2.7.6 (default, Mar 22 2014, 22:59:56) \\n[GCC 4.8.2]'\n>>> data = input(\"Enter a number: \")\nEnter a number: 5 + 17\n>>> data, type(data)\n(22, <type 'int'>)\n \n The data  5 + 17  is evaluated and the result is  22 . When it evaluates the expression  5 + 17 , it detects that you are adding two numbers and so the result will also be of the same  int  type. So, the type conversion is done for free and  22  is returned as the result of  input  and stored in  data  variable. You can think of  input  as the  raw_input  composed with an  eval  call. \n >>> data = eval(raw_input(\"Enter a number: \"))\nEnter a number: 5 + 17\n>>> data, type(data)\n(22, <type 'int'>)\n \n Note:  you should be careful when you are using  input  in Python 2.x. I explained why one should be careful when using it, in  this answer . \n But,  raw_input  doesn't evaluate the input and returns as it is, as a string. \n >>> import sys\n>>> sys.version\n'2.7.6 (default, Mar 22 2014, 22:59:56) \\n[GCC 4.8.2]'\n>>> data = raw_input(\"Enter a number: \")\nEnter a number: 5 + 17\n>>> data, type(data)\n('5 + 17', <type 'str'>)\n \n Python 3.x \n Python 3.x's  input  and Python 2.x's  raw_input  are similar and  raw_input  is not available in Python 3.x. \n >>> import sys\n>>> sys.version\n'3.4.0 (default, Apr 11 2014, 13:05:11) \\n[GCC 4.8.2]'\n>>> data = input(\"Enter a number: \")\nEnter a number: 5 + 17\n>>> data, type(data)\n('5 + 17', <class 'str'>)\n \n    ", "date_posted": "2021-01-28 13:45:16Z", "upvote": "\r\n            376\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "4621513", "name": "mkrieger1", "reputation_score": "15.4k"}, "answer_comments": [{"stack_answer_id": "20449433", "stack_answer_comment_id": "60632844", "comment_content": "Is there any other way, like a function or something so that we dont need to convert to int in 3.x other than doing explicit conversion to int??", "user_id": null}, {"stack_answer_id": "20449433", "stack_answer_comment_id": "60633361", "comment_content": "@ShreyanMehta ", "user_id": null}, {"stack_answer_id": "20449433", "stack_answer_comment_id": "86398645", "comment_content": "@thefourtheye at least use ", "user_id": null}]}, {"stack_answer_id": "20449436", "answer_content": "\r\n In Python 3.x,  raw_input  was renamed to  input  and the Python 2.x  input  was removed.   \n\n This means that, just like  raw_input ,  input  in Python 3.x always returns a string object. \n\n To fix the problem, you need to explicitly make those inputs into integers by putting them in  int : \n\n x = int(input(\"Enter a number: \"))\ny = int(input(\"Enter a number: \"))\n \n    ", "date_posted": "2019-05-17 12:08:00Z", "upvote": "\r\n            50\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": []}, {"stack_answer_id": "26855555", "answer_content": "\r\n For multiple integer in a single line,  map  might be better. \n\n arr = map(int, raw_input().split())\n \n\n If the number is already known, (like 2 integers), you can use \n\n num1, num2 = map(int, raw_input().split())\n \n    ", "date_posted": "2019-05-17 12:11:57Z", "upvote": "\r\n            34\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": []}, {"stack_answer_id": "20449435", "answer_content": "\r\n input()  (Python 3) and  raw_input()  (Python 2)  always  return strings. Convert the result to integer explicitly with  int() . \n\n x = int(input(\"Enter a number: \"))\ny = int(input(\"Enter a number: \"))\n \n    ", "date_posted": "2019-05-17 12:12:35Z", "upvote": "\r\n            18\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": []}, {"stack_answer_id": "24621885", "answer_content": "\r\n Multiple questions require multiple integers to be entered on a single line. The best way is to enter the entire string of numbers line by line and split them into integers. Here is the Python 3 version: \n a = []\np = input()\np = p.split()      \nfor i in p:\n    a.append(int(i))\n \n You can also use list comprehensions: \n p = input().split(\"whatever the seperator is\")\n \n To convert all input from string to int we do the following: \n x = [int(i) for i in p]\nprint(x, end=' ')\n \n List elements should be printed in straight lines. \n    ", "date_posted": "2022-03-18 02:20:10Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "3750257", "name": "pppery", "reputation_score": "3,606"}, "answer_comments": []}, {"stack_answer_id": "36679044", "answer_content": "\r\n Convert to integers: \n\n my_number = int(input(\"enter the number\"))\n \n\n Similarly for floating point numbers: \n\n my_decimalnumber = float(input(\"enter the number\"))\n \n    ", "date_posted": "2017-01-26 04:28:51Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "885922", "name": "xlm", "reputation_score": "5,754"}, "answer_comments": []}, {"stack_answer_id": "51676769", "answer_content": "\r\n n=int(input())\nfor i in range(n):\n    n=input()\n    n=int(n)\n    arr1=list(map(int,input().split()))\n \n\n the for loop shall run 'n' number of times . the second 'n' is the length of the array.\nthe last statement maps the integers to a list and takes input in space separated form .\nyou can also return the array at the end of for loop. \n    ", "date_posted": "2018-08-03 16:30:31Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "6481925", "name": "ravi tanwar", "reputation_score": "572"}, "answer_comments": []}, {"stack_answer_id": "23828100", "answer_content": "\r\n I encountered a problem of taking integer input while solving a problem on  CodeChef , where two integers - separated by space - should be read from one line. \n While  int(input())  is sufficient for a single integer, I did not find a direct way to input two integers.  I tried this: \n num = input()\nnum1 = 0\nnum2 = 0\n\nfor i in range(len(num)):\n    if num[i] == ' ':\n        break\n\nnum1 = int(num[:i])\nnum2 = int(num[i+1:])\n \n Now I use  num1  and  num2  as integers. \n    ", "date_posted": "2021-12-02 02:35:17Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "10794031", "name": "bad_coder", "reputation_score": "9,051"}, "answer_comments": [{"stack_answer_id": "23828100", "stack_answer_comment_id": "36673308", "comment_content": "This looks very interesting.  However, isn't ", "user_id": null}, {"stack_answer_id": "23828100", "stack_answer_comment_id": "36696794", "comment_content": " When a loop is exited, the value of the index variable (here, ", "user_id": null}, {"stack_answer_id": "23828100", "stack_answer_comment_id": "89589223", "comment_content": "For this kind of input manipulation, you can either ", "user_id": null}]}, {"stack_answer_id": "31134209", "answer_content": "\r\n def dbz():\n    try:\n        r = raw_input(\"Enter number:\")\n        if r.isdigit():\n            i = int(raw_input(\"Enter divident:\"))\n            d = int(r)/i\n            print \"O/p is -:\",d\n        else:\n            print \"Not a number\"\n    except Exception ,e:\n        print \"Program halted incorrect data entered\",type(e)\ndbz()\n\nOr \n\nnum = input(\"Enter Number:\")#\"input\" will accept only numbers\n \n    ", "date_posted": "2019-04-04 08:47:19Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "4628770", "name": "Sanyal", "reputation_score": "836"}, "answer_comments": []}, {"stack_answer_id": "40764414", "answer_content": "\r\n While in your example,  int(input(...))  does the trick in any case,  python-future 's  builtins.input  is worth consideration since that makes sure your code works for both Python 2 and 3  and  disables Python2's default behaviour of  input  trying to be \"clever\" about the input data type ( builtins.input  basically just behaves like  raw_input ). \n    ", "date_posted": "2016-11-23 12:19:52Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "321973", "name": "Tobias Kienzler", "reputation_score": "24.1k"}, "answer_comments": []}], "user": {"stack_user_id": null, "name": null, "reputation_score": 0}, "question_comments": [{"stack_question_id": "20449427", "stack_question_comment_id": "91590863", "comment_content": " ", "user_id": null}]},
{"stack_question_id": "1207406", "question_title": "How to remove items from a list while iterating?", "question_content": "\r\n                I'm iterating over a list of tuples in Python, and am attempting to remove them if they meet certain criteria. \n\nfor tup in somelist:\n    if determine(tup):\n         code_to_remove_tup\r\nWhat should I ...\r\n", "question_url": "/questions/1207406/how-to-remove-items-from-a-list-while-iterating", "date_posted": "Jul 30, 2009 at 15:36", "upvote": "9", "view": "7", "tags": ["python", "iteration"], "answers_count": "2", "answers": [{"stack_answer_id": "1207461", "answer_content": "\r\n You can use a list comprehension to create a new list containing only the elements you don't want to remove: \n somelist = [x for x in somelist if not determine(x)]\n \n Or, by assigning to the slice  somelist[:] , you can mutate the existing list to contain only the items you want: \n somelist[:] = [x for x in somelist if not determine(x)]\n \n This approach could be useful if there are other references to  somelist  that need to reflect the changes. \n Instead of a comprehension, you could also use  itertools . In Python 2: \n from itertools import ifilterfalse\nsomelist[:] = ifilterfalse(determine, somelist)\n \n Or in Python 3: \n from itertools import filterfalse\nsomelist[:] = filterfalse(determine, somelist)\n \n    ", "date_posted": "2021-03-19 21:52:42Z", "upvote": "\r\n            1035\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "2357112", "name": "user2357112", "reputation_score": "240k"}, "answer_comments": [{"stack_answer_id": "1207461", "stack_answer_comment_id": "6561137", "comment_content": "Can you make it faster if you know only a few will be deleted, i.e., only delete those and leave the others in-place rather than re-writing them?", "user_id": null}, {"stack_answer_id": "1207461", "stack_answer_comment_id": "42444805", "comment_content": "What if my list is huge and can't afford making a copy?", "user_id": null}, {"stack_answer_id": "1207461", "stack_answer_comment_id": "48015591", "comment_content": "@jpcgt You should use ", "user_id": null}, {"stack_answer_id": "1207461", "stack_answer_comment_id": "48333544", "comment_content": "@RostislavKondratenko: ", "user_id": null}, {"stack_answer_id": "1207461", "stack_answer_comment_id": "91913010", "comment_content": "Would you care to explain what the differences are between assigning the list comprehension to the list and list clone please? Wouldn't the original list ", "user_id": null}]}, {"stack_answer_id": "1208792", "answer_content": "\r\n The answers suggesting list comprehensions are ALMOST correct -- except that they build a completely new list and then give it the same name the old list as, they do NOT modify the old list in place. That's different from what you'd be doing by selective removal, as in  @Lennart's suggestion  -- it's faster, but if your list is accessed via multiple references the fact that you're just reseating one of the references and NOT altering the list object itself can lead to subtle, disastrous bugs. \n\n Fortunately, it's extremely easy to get both the speed of list comprehensions AND the required semantics of in-place alteration -- just code: \n\n somelist[:] = [tup for tup in somelist if determine(tup)]\n \n\n Note the subtle difference with other answers: this one is NOT assigning to a barename - it's assigning to a list slice that just happens to be the entire list, thereby replacing the list  contents   within the same Python list object , rather than just reseating one reference (from previous list object to new list object) like the other answers. \n    ", "date_posted": "2019-05-17 06:05:40Z", "upvote": "\r\n            674\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": [{"stack_answer_id": "1208792", "stack_answer_comment_id": "6156944", "comment_content": "How do I do the same sliced assignment with a dict? In Python 2.6?", "user_id": null}, {"stack_answer_id": "1208792", "stack_answer_comment_id": "6269193", "comment_content": "@Paul: Since dicts are unordered, slices are meaningless for dicts.  If your want to replace the contents of dict ", "user_id": null}, {"stack_answer_id": "1208792", "stack_answer_comment_id": "8322580", "comment_content": "Why can 'reseating' one of the references by replacing what the variable refers to cause bugs?  It seems like that would only be a potential problem in multi-threaded applications, not single-threaded.", "user_id": null}, {"stack_answer_id": "1208792", "stack_answer_comment_id": "9992070", "comment_content": "@Derek ", "user_id": null}, {"stack_answer_id": "1208792", "stack_answer_comment_id": "64106747", "comment_content": "in fact, using ", "user_id": null}]}, {"stack_answer_id": "1207427", "answer_content": "\r\n You need to take a copy of the list and iterate over it first, or the iteration will fail with what may be unexpected results. \n\n For example (depends on what type of list): \n\n for tup in somelist[:]:\n    etc....\n \n\n An example: \n\n >>> somelist = range(10)\n>>> for x in somelist:\n...     somelist.remove(x)\n>>> somelist\n[1, 3, 5, 7, 9]\n\n>>> somelist = range(10)\n>>> for x in somelist[:]:\n...     somelist.remove(x)\n>>> somelist\n[]\n \n    ", "date_posted": "2019-12-02 14:50:05Z", "upvote": "\r\n            376\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "1207427", "stack_answer_comment_id": "37528195", "comment_content": "@Zen Because the second one iterates over a copy of the list. So when you modify the original list, you do not modify the copy that you iterate over.", "user_id": null}, {"stack_answer_id": "1207427", "stack_answer_comment_id": "44985743", "comment_content": "What's better in doing somelist[:] compared to list(somelist) ?", "user_id": null}, {"stack_answer_id": "1207427", "stack_answer_comment_id": "45032005", "comment_content": " will convert an iterable into a list. ", "user_id": null}, {"stack_answer_id": "1207427", "stack_answer_comment_id": "45258605", "comment_content": "Note to anyone reading this, this is VERY slow for lists. ", "user_id": null}, {"stack_answer_id": "1207427", "stack_answer_comment_id": "64982024", "comment_content": "Big O time doesn't matter when dealing with lists of only a dozen items.  Often clear and simple for future programmers to understand is far more valuable than performance.", "user_id": null}]}, {"stack_answer_id": "1207485", "answer_content": "\r\n for i in range(len(somelist) - 1, -1, -1):\n    if some_condition(somelist, i):\n        del somelist[i]\n \n\n You need to go backwards otherwise it's a bit like sawing off the tree-branch that you are sitting on :-) \n\n Python 2 users: replace  range  by  xrange  to avoid creating a hardcoded list \n    ", "date_posted": "2018-10-26 15:10:03Z", "upvote": "\r\n            174\r\n        ", "accepted": "No", "user": {"stack_user_id": "6451573", "name": "Jean-Fran\u00e7ois Fabre", "reputation_score": "133k"}, "answer_comments": [{"stack_answer_id": "1207485", "stack_answer_comment_id": "6110404", "comment_content": "In recent versions of Python, you can do this even more cleanly by using the ", "user_id": null}, {"stack_answer_id": "1207485", "stack_answer_comment_id": "45266349", "comment_content": "reversed() does not create a new list, it creates a reverse iterator over the supplied sequence. Like enumerate(), you have to wrap it in list() to actually get a list out of it.  You may be thinking of sorted(), which ", "user_id": null}, {"stack_answer_id": "1207485", "stack_answer_comment_id": "51485366", "comment_content": "@Mauris because ", "user_id": null}, {"stack_answer_id": "1207485", "stack_answer_comment_id": "53032679", "comment_content": "This is O(N*M) for arrays, it is very slow if you remove many items from a large list.  So not recommended.", "user_id": null}, {"stack_answer_id": "1207485", "stack_answer_comment_id": "58231194", "comment_content": "@SamWatkins Yeah, this answer is for when you're removing a couple of elements from a very large array. Less memory usage, but it can be ", "user_id": null}]}, {"stack_answer_id": "34238688", "answer_content": "\r\n Overview of workarounds \n Either: \n \n use a linked list implementation/roll your own. \n A linked list is the proper data structure to support efficient item removal, and does not force you to make space/time tradeoffs. \n A CPython  list  is implemented with  dynamic arrays  as  mentioned here , which is not a good data type to support removals. \n There doesn't seem to be a linked list in the standard library however: \n \n Is there a linked list predefined library in Python? \n https://github.com/ajakubek/python-llist \n \n \n start a new  list()  from scratch, and  .append()  back at the end as mentioned at:  https://stackoverflow.com/a/1207460/895245 \n This time efficient, but less space efficient because it keeps an extra copy of the array around during iteration. \n \n use  del  with an index as mentioned at:  https://stackoverflow.com/a/1207485/895245 \n This is more space efficient since it dispenses the array copy, but it is less time efficient, because removal from dynamic arrays requires shifting all following items back by one, which is O(N). \n \n \n Generally, if you are doing it quick and dirty and don't want to add a custom  LinkedList  class, you just want to go for the faster  .append()  option by default unless memory is a big concern. \n Official Python 2 tutorial 4.2. \"for Statements\" \n https://docs.python.org/2/tutorial/controlflow.html#for-statements \n This part of the docs makes it clear that: \n \n you need to make a copy of the iterated list to modify it \n one way to do it is with the slice notation  [:] \n \n \n If you need to modify the sequence you are iterating over while inside the loop (for example to duplicate selected items), it is recommended that you first make a copy. Iterating over a sequence does not implicitly make a copy. The slice notation makes this especially convenient: \n >>> words = ['cat', 'window', 'defenestrate']\n>>> for w in words[:]:  # Loop over a slice copy of the entire list.\n...     if len(w) > 6:\n...         words.insert(0, w)\n...\n>>> words\n['defenestrate', 'cat', 'window', 'defenestrate']\n \n \n Python 2 documentation 7.3. \"The for statement\" \n https://docs.python.org/2/reference/compound_stmts.html#for \n This part of the docs says once again that you have to make a copy, and gives an actual removal example: \n \n Note: There is a subtlety when the sequence is being modified by the loop (this can only occur for mutable sequences, i.e. lists). An internal counter is used to keep track of which item is used next, and this is incremented on each iteration. When this counter has reached the length of the sequence the loop terminates. This means that if the suite deletes the current (or a previous) item from the sequence, the next item will be skipped (since it gets the index of the current item which has already been treated). Likewise, if the suite inserts an item in the sequence before the current item, the current item will be treated again the next time through the loop. This can lead to nasty bugs that can be avoided by making a temporary copy using a slice of the whole sequence, e.g., \n for x in a[:]:\n \n \n     if x < 0: a.remove(x)\n \n However, I disagree with this implementation, since  .remove()  has to iterate the  entire list  to find the value. \n Could Python do this better? \n It seems like this particular Python API could be improved. Compare it, for instance, with: \n \n Java  ListIterator::remove  which documents \"This call can only be made once per call to next or previous\" \n C++  std::vector::erase  which returns a valid interator to the element after the one removed \n \n both of which make it crystal clear that you cannot modify a list being iterated except with the iterator itself, and gives you efficient ways to do so without copying the list. \n Perhaps the underlying rationale is that Python lists are assumed to be dynamic array backed, and therefore any type of removal will be time inefficient anyways, while Java has a nicer interface hierarchy with both  ArrayList  and  LinkedList  implementations of  ListIterator . \n There doesn't seem to be an explicit linked list type in the Python stdlib either:  Python Linked List \n    ", "date_posted": "2020-09-25 05:15:39Z", "upvote": "\r\n            66\r\n        ", "accepted": "No", "user": {"stack_user_id": "895245", "name": "Ciro Santilli \u041f\u0443\u0442\u043b\u0435\u0440 \u041a\u0430\u043f\u0443\u0442 \u516d\u56db\u4e8b", "reputation_score": "312k"}, "answer_comments": [{"stack_answer_id": "34238688", "stack_answer_comment_id": "120740698", "comment_content": "Finally someone pointed out the actual documentation. I couldn't understand any answers before this one.", "user_id": null}]}, {"stack_answer_id": "1207460", "answer_content": "\r\n Your best approach for such an example would be a  list comprehension \n\n somelist = [tup for tup in somelist if determine(tup)]\n \n\n In cases where you're doing something more complex than calling a  determine  function, I prefer constructing a new list and simply appending to it as I go.  For example \n\n newlist = []\nfor tup in somelist:\n    # lots of code here, possibly setting things up for calling determine\n    if determine(tup):\n        newlist.append(tup)\nsomelist = newlist\n \n\n Copying the list using  remove  might make your code look a little cleaner, as described in one of the answers below.  You should definitely not do this for extremely large lists, since this involves first copying the entire list, and also performing an  O(n)   remove  operation for each element being removed, making this an  O(n^2)  algorithm. \n\n for tup in somelist[:]:\n    # lots of code here, possibly setting things up for calling determine\n    if determine(tup):\n        newlist.append(tup)\n \n    ", "date_posted": "2009-07-30 17:30:54Z", "upvote": "\r\n            51\r\n        ", "accepted": "No", "user": {"stack_user_id": "1694", "name": "Eli Courtwright", "reputation_score": "178k"}, "answer_comments": []}, {"stack_answer_id": "1207500", "answer_content": "\r\n For those that like functional programming: \n\n somelist[:] = filter(lambda tup: not determine(tup), somelist)\n \n\n or \n\n from itertools import ifilterfalse\nsomelist[:] = list(ifilterfalse(determine, somelist))\n \n    ", "date_posted": "2016-05-24 12:50:20Z", "upvote": "\r\n            41\r\n        ", "accepted": "No", "user": {"stack_user_id": "1843331", "name": "Tim", "reputation_score": "40.2k"}, "answer_comments": [{"stack_answer_id": "1207500", "stack_answer_comment_id": "67641698", "comment_content": "1. List comprehension and generator expressions are borrowed from Haskell, a pure functional language; they're exactly as functional as ", "user_id": null}]}, {"stack_answer_id": "42773232", "answer_content": "\r\n I needed to do this with a huge list, and duplicating the list seemed expensive, especially since in my case the number of deletions would be few compared to the items that remain. I took this low-level approach. \n\n array = [lots of stuff]\narraySize = len(array)\ni = 0\nwhile i < arraySize:\n    if someTest(array[i]):\n        del array[i]\n        arraySize -= 1\n    else:\n        i += 1\n \n\n What I don't know is how efficient a couple of deletes are compared to copying a large list. Please comment if you have any insight. \n    ", "date_posted": "2017-03-13 20:54:41Z", "upvote": "\r\n            23\r\n        ", "accepted": "No", "user": {"stack_user_id": "1031265", "name": "Michael", "reputation_score": "499"}, "answer_comments": [{"stack_answer_id": "42773232", "stack_answer_comment_id": "74631480", "comment_content": "In my case I need to move those 'unwanted' elements into another list. Do you have any new comment about this solution? I also think that it is better to use some deletions instead of duplicate the list.", "user_id": null}, {"stack_answer_id": "42773232", "stack_answer_comment_id": "74646602", "comment_content": "This is the right answer if performance is an issue (although same as @Alexey). That said, the choice of ", "user_id": null}, {"stack_answer_id": "42773232", "stack_answer_comment_id": "74646698", "comment_content": "@GVelascoh why not create ", "user_id": null}, {"stack_answer_id": "42773232", "stack_answer_comment_id": "75747098", "comment_content": "Note that this is likely time inefficient: if ", "user_id": null}, {"stack_answer_id": "42773232", "stack_answer_comment_id": "115963470", "comment_content": "@CiroSantilli\u90dd\u6d77\u4e1c\u51a0\u72b6\u75c5\u516d\u56db\u4e8b\u4ef6\u6cd5\u8f6e\u529f : The pop(i) operation is still O(n). I'll take storage efficiency over incremental improvements in O(n), but I can see why someone might do this differently.", "user_id": null}]}, {"stack_answer_id": "52947607", "answer_content": "\r\n Most of the answers here want you to create a copy of the list. I had a use case where the list was quite long (110K items) and it was smarter to keep reducing the list instead. \n\n First of all you'll need to  replace foreach loop with while loop , \n\n i = 0\nwhile i < len(somelist):\n    if determine(somelist[i]):\n         del somelist[i]\n    else:\n        i += 1\n \n\n The value of  i  is not changed in the if block because you'll want to get value of the new item FROM THE SAME INDEX, once the old item is deleted. \n    ", "date_posted": "2018-10-23 11:13:00Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "4008392", "name": "Mujeeb", "reputation_score": "805"}, "answer_comments": [{"stack_answer_id": "52947607", "stack_answer_comment_id": "124290302", "comment_content": "I don't want to like this but I do :)", "user_id": null}, {"stack_answer_id": "52947607", "stack_answer_comment_id": "126884873", "comment_content": "I think this is very creative! I would like to see more community input on this algorithm. It's easy to understand and appears to be overlooked by the contributors!", "user_id": null}, {"stack_answer_id": "52947607", "stack_answer_comment_id": "126900456", "comment_content": "@tonysepia glad to see this solution is still helpful :)", "user_id": null}, {"stack_answer_id": "52947607", "stack_answer_comment_id": "126900474", "comment_content": "@Mujeeb oh Yes, you can see me using it in my algo here: ", "user_id": null}]}, {"stack_answer_id": "36096883", "answer_content": "\r\n It might be smart to also just create a new list if the current list item meets the desired criteria.  \n\n so: \n\n for item in originalList:\n   if (item != badValue):\n        newList.append(item)\n \n\n and to avoid having to re-code the entire project with the new lists name: \n\n originalList[:] = newList\n \n\n note, from Python documentation:  \n\n \n   copy.copy(x) \n  Return a shallow copy of x. \n  \n   copy.deepcopy(x) \n  Return a deep copy of x. \n \n    ", "date_posted": "2016-10-23 02:33:13Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "5425664", "name": "ntk4", "reputation_score": "1,199"}, "answer_comments": [{"stack_answer_id": "36096883", "stack_answer_comment_id": "63359622", "comment_content": "This adds no new information that wasn't in the accepted answer years earlier.", "user_id": null}, {"stack_answer_id": "36096883", "stack_answer_comment_id": "63408517", "comment_content": "It's simple and just another way to look at a problem @MarkAmery. It's less condensed for those people that don't like compressed coding syntax.", "user_id": null}]}, {"stack_answer_id": "40177544", "answer_content": "\r\n This answer was originally written in response to a question which has since been marked as duplicate:\n Removing coordinates from list on python \n\n There are two problems in your code: \n\n 1) When using remove(), you attempt to remove integers whereas you need to remove a tuple. \n\n 2) The for loop will skip items in your list. \n\n Let's run through what happens when we execute your code: \n\n >>> L1 = [(1,2), (5,6), (-1,-2), (1,-2)]\n>>> for (a,b) in L1:\n...   if a < 0 or b < 0:\n...     L1.remove(a,b)\n... \nTraceback (most recent call last):\n  File \"<stdin>\", line 3, in <module>\nTypeError: remove() takes exactly one argument (2 given)\n \n\n The first problem is that you are passing both 'a' and 'b' to remove(), but remove() only accepts a single argument. So how can we get remove() to work properly with your list? We need to figure out what each element of your list is. In this case, each one is a tuple. To see this, let's access one element of the list (indexing starts at 0): \n\n >>> L1[1]\n(5, 6)\n>>> type(L1[1])\n<type 'tuple'>\n \n\n Aha! Each element of L1 is actually a tuple. So that's what we need to be passing to remove(). Tuples in python are very easy, they're simply made by enclosing values in parentheses. \"a, b\" is not a tuple, but \"(a, b)\" is a tuple. So we modify your code and run it again: \n\n # The remove line now includes an extra \"()\" to make a tuple out of \"a,b\"\nL1.remove((a,b))\n \n\n This code runs without any error, but let's look at the list it outputs:  \n\n L1 is now: [(1, 2), (5, 6), (1, -2)]\n \n\n Why is (1,-2) still in your list? It turns out modifying the list while using a loop to iterate over it is a very bad idea without special care. The reason that (1, -2) remains in the list is that the locations of each item within the list changed between iterations of the for loop. Let's look at what happens if we feed the above code a longer list: \n\n L1 = [(1,2),(5,6),(-1,-2),(1,-2),(3,4),(5,7),(-4,4),(2,1),(-3,-3),(5,-1),(0,6)]\n### Outputs:\nL1 is now: [(1, 2), (5, 6), (1, -2), (3, 4), (5, 7), (2, 1), (5, -1), (0, 6)]\n \n\n As you can infer from that result, every time that the conditional statement evaluates to true and a list item is removed, the next iteration of the loop will skip evaluation of the next item in the list because its values are now located at different indices. \n\n The most intuitive solution is to copy the list, then iterate over the original list and only modify the copy. You can try doing so like this: \n\n L2 = L1\nfor (a,b) in L1:\n    if a < 0 or b < 0 :\n        L2.remove((a,b))\n# Now, remove the original copy of L1 and replace with L2\nprint L2 is L1\ndel L1\nL1 = L2; del L2\nprint (\"L1 is now: \", L1)\n \n\n However, the output will be identical to before: \n\n 'L1 is now: ', [(1, 2), (5, 6), (1, -2), (3, 4), (5, 7), (2, 1), (5, -1), (0, 6)]\n \n\n This is because when we created L2, python did not actually create a new object. Instead, it merely referenced L2 to the same object as L1. We can verify this with 'is' which is different from merely \"equals\" (==). \n\n >>> L2=L1\n>>> L1 is L2\nTrue\n \n\n We can make a true copy using copy.copy(). Then everything works as expected: \n\n import copy\nL1 = [(1,2), (5,6),(-1,-2), (1,-2),(3,4),(5,7),(-4,4),(2,1),(-3,-3),(5,-1),(0,6)]\nL2 = copy.copy(L1)\nfor (a,b) in L1:\n    if a < 0 or b < 0 :\n        L2.remove((a,b))\n# Now, remove the original copy of L1 and replace with L2\ndel L1\nL1 = L2; del L2\n>>> L1 is now: [(1, 2), (5, 6), (3, 4), (5, 7), (2, 1), (0, 6)]\n \n\n Finally, there is one cleaner solution than having to make an entirely new copy of L1. The reversed() function: \n\n L1 = [(1,2), (5,6),(-1,-2), (1,-2),(3,4),(5,7),(-4,4),(2,1),(-3,-3),(5,-1),(0,6)]\nfor (a,b) in reversed(L1):\n    if a < 0 or b < 0 :\n        L1.remove((a,b))\nprint (\"L1 is now: \", L1)\n>>> L1 is now: [(1, 2), (5, 6), (3, 4), (5, 7), (2, 1), (0, 6)]\n \n\n Unfortunately, I cannot adequately describe how reversed() works. It returns a 'listreverseiterator' object when a list is passed to it. For practical purposes, you can think of it as creating a reversed copy of its argument. This is the solution I recommend. \n    ", "date_posted": "2017-05-23 12:18:24Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}, {"stack_answer_id": "58314595", "answer_content": "\r\n If you want to delete elements from a list while iterating, use a while-loop so you can alter the current index and end index after each deletion. \n\n Example: \n\n i = 0\nlength = len(list1)\n\nwhile i < length:\n    if condition:\n        list1.remove(list1[i])\n        i -= 1\n        length -= 1\n\n    i += 1\n \n    ", "date_posted": "2019-10-10 02:24:59Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "2619038", "name": "NoName", "reputation_score": "9,114"}, "answer_comments": []}, {"stack_answer_id": "25363359", "answer_content": "\r\n If you want to do anything else during the iteration, it may be nice to get both the index (which guarantees you being able to reference it, for example if you have a list of dicts) and the actual list item contents. \n\n inlist = [{'field1':10, 'field2':20}, {'field1':30, 'field2':15}]    \nfor idx, i in enumerate(inlist):\n    do some stuff with i['field1']\n    if somecondition:\n        xlist.append(idx)\nfor i in reversed(xlist): del inlist[i]\n \n\n enumerate  gives you access to the item and the index at once.  reversed  is so that the indices that you're going to later delete don't change on you.  \n    ", "date_posted": "2014-08-18 12:30:16Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "3427777", "name": "fantabolous", "reputation_score": "19.5k"}, "answer_comments": [{"stack_answer_id": "25363359", "stack_answer_comment_id": "63359580", "comment_content": "Why is getting the index any more relevant in the case where you have a list of dicts than in the case of any other kind of list? This doesn't make sense as far as I can tell.", "user_id": null}]}, {"stack_answer_id": "39293411", "answer_content": "\r\n One possible solution, useful if you want not only remove some things, but also do something with all elements in a single loop: \n\n alist = ['good', 'bad', 'good', 'bad', 'good']\ni = 0\nfor x in alist[:]:\n    if x == 'bad':\n        alist.pop(i)\n        i -= 1\n    # do something cool with x or just print x\n    print(x)\n    i += 1\n \n    ", "date_posted": "2018-06-13 19:38:52Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "6740698", "name": "Xenolion", "reputation_score": "11.1k"}, "answer_comments": [{"stack_answer_id": "39293411", "stack_answer_comment_id": "85623994", "comment_content": "You should really just use comprehensions. They're much easier to understand.", "user_id": null}, {"stack_answer_id": "39293411", "stack_answer_comment_id": "85632089", "comment_content": "What if I want to remove ", "user_id": null}, {"stack_answer_id": "39293411", "stack_answer_comment_id": "86135096", "comment_content": "Actually, I realized there's some cleverness here in that you make a copy of the list with an open slice (", "user_id": null}]}, {"stack_answer_id": "55915047", "answer_content": "\r\n for loop will be iterate through index.. \n\n consider you have a list, \n\n [5, 7, 13, 29, 65, 91]\n \n\n you have using list variable called  lis . and you using same to remove.. \n\n your variable  \n\n lis = [5, 7, 13, 29, 35, 65, 91]\n       0  1   2   3   4   5   6\n \n\n during 5th iteration, \n\n your  number 35  was not a prime so you removed it from a list. \n\n lis.remove(y)\n \n\n and then  next value (65)  move on to previous index. \n\n lis = [5, 7, 13, 29, 65, 91]\n       0  1   2   3   4   5\n \n\n so 4th iteration done pointer moved onto 5th..  \n\n thats why your loop doesnt cover 65 since its moved into previous index. \n\n so you shouldn't reference list into another variable which still reference original instead of copy. \n\n ite = lis #dont do it will reference instead copy\n \n\n so do copy of list using  list[::] \n\n now you it will give, \n\n [5, 7, 13, 29]\n \n\n Problem is you removed a value from a list during iteration then your list index will collapse. \n\n so you can try comprehension instead. \n\n which supports all the iterable like, list, tuple, dict, string etc  \n    ", "date_posted": "2019-04-30 06:25:49Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "4453737", "name": "Mohideen bin Mohammed", "reputation_score": "17.2k"}, "answer_comments": [{"stack_answer_id": "55915047", "stack_answer_comment_id": "128054348", "comment_content": "To put in a simpler way: do ", "user_id": null}]}, {"stack_answer_id": "49311061", "answer_content": "\r\n The other answers are correct that it is usually a bad idea to delete from a list that you're iterating. Reverse iterating avoids some of the pitfalls, but it is much more difficult to follow code that does that, so usually you're better off using a list comprehension or  filter . \n There is, however, one case where it is safe to remove elements from a sequence that you are iterating: if you're only removing one item while you're iterating. This can be ensured using a  return  or a  break . For example: \n for i, item in enumerate(lst):\n    if item % 4 == 0:\n        foo(item)\n        del lst[i]\n        break\n \n This is often easier to understand than a list comprehension when you're doing some operations with side effects on the first item in a list that meets some condition and then removing that item from the list immediately after. \n    ", "date_posted": "2022-05-16 21:25:13Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "5079779", "name": "Beefster", "reputation_score": "665"}, "answer_comments": []}, {"stack_answer_id": "4639072", "answer_content": "\r\n You might want to use  filter()  available as the built-in. \n\n For more details  check here \n    ", "date_posted": "2017-07-27 07:40:53Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "5872484", "name": "Bharat Mane", "reputation_score": "296"}, "answer_comments": []}, {"stack_answer_id": "31350162", "answer_content": "\r\n You can try for-looping in reverse so for some_list you'll do something like: \n\n list_len = len(some_list)\nfor i in range(list_len):\n    reverse_i = list_len - 1 - i\n    cur = some_list[reverse_i]\n\n    # some logic with cur element\n\n    if some_condition:\n        some_list.pop(reverse_i)\n \n\n This way the index is aligned and doesn't suffer from the list updates (regardless whether you pop cur element or not). \n    ", "date_posted": "2015-07-10 20:58:49Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "975975", "name": "Queequeg", "reputation_score": "939"}, "answer_comments": [{"stack_answer_id": "31350162", "stack_answer_comment_id": "63359845", "comment_content": "Looping over ", "user_id": null}, {"stack_answer_id": "31350162", "stack_answer_comment_id": "63603723", "comment_content": "@MarkAmery don't think you can alter the list this way.", "user_id": null}]}, {"stack_answer_id": "53236774", "answer_content": "\r\n The most effective method is list comprehension, many people show their case, of course, it is also a good way to get an  iterator  through  filter . \n\n \n   Filter  receives a function and a sequence.  Filter  applies the passed function to each element in turn, and then decides whether to retain or discard the element depending on whether the function return value is  True  or  False . \n \n\n There is an example  (get the odds in the tuple): \n\n list(filter(lambda x:x%2==1, (1, 2, 4, 5, 6, 9, 10, 15)))  \n# result: [1, 5, 9, 15]\n \n\n Caution: You can also not handle iterators. Iterators are sometimes better than sequences. \n    ", "date_posted": "2018-11-10 07:05:16Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "10599390", "name": "chseng", "reputation_score": "116"}, "answer_comments": [{"stack_answer_id": "53236774", "stack_answer_comment_id": "121449764", "comment_content": "I probably think this is the most idiomatic way of removing the items from list. This behaviour will also be thread safe since your application is not mutating the variable.", "user_id": null}]}, {"stack_answer_id": "34310158", "answer_content": "\r\n I needed to do something similar and in my case the problem was memory - I needed to merge multiple dataset objects within a list, after doing some stuff with them, as a new object, and needed to get rid of each entry I was merging to avoid duplicating all of them and blowing up memory. In my case having the objects in a dictionary instead of a list worked fine: \n\n ``` \n\n k = range(5)\nv = ['a','b','c','d','e']\nd = {key:val for key,val in zip(k, v)}\n\nprint d\nfor i in range(5):\n    print d[i]\n    d.pop(i)\nprint d\n \n\n ``` \n    ", "date_posted": "2015-12-16 11:05:41Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "4577738", "name": "rafa", "reputation_score": "205"}, "answer_comments": []}, {"stack_answer_id": "37277264", "answer_content": "\r\n TLDR: \n\n I wrote a library that allows you to do this: \n\n from fluidIter import FluidIterable\nfSomeList = FluidIterable(someList)  \nfor tup in fSomeList:\n    if determine(tup):\n        # remove 'tup' without \"breaking\" the iteration\n        fSomeList.remove(tup)\n        # tup has also been removed from 'someList'\n        # as well as 'fSomeList'\n \n\n It's best to use another method if possible that doesn't require modifying your iterable while iterating over it, but for some algorithms it might not be that straight forward. And so if you are sure that you really do want the code pattern described in the original question, it is possible. \n\n Should work on all mutable sequences not just lists. \n\n \n\n Full answer: \n\n Edit: The last code example in this answer gives a use case for  why  you might sometimes want to modify a list in place rather than use a list comprehension. The first part of the answers serves as tutorial of  how  an array can be modified in place. \n\n The solution follows on from  this  answer (for a related question) from senderle. Which explains how the the array index is updated while iterating through a list that has been modified. The solution below is designed to correctly track the array index even if the list is modified. \n\n Download  fluidIter.py  from  here   https://github.com/alanbacon/FluidIterator , it is just a single file so no need to install git. There is no installer so you will need to make sure that the file is in the python path your self. The code has been written for python 3 and is untested on python 2. \n\n from fluidIter import FluidIterable\nl = [0,1,2,3,4,5,6,7,8]  \nfluidL = FluidIterable(l)                       \nfor i in fluidL:\n    print('initial state of list on this iteration: ' + str(fluidL)) \n    print('current iteration value: ' + str(i))\n    print('popped value: ' + str(fluidL.pop(2)))\n    print(' ')\n\nprint('Final List Value: ' + str(l))\n \n\n This will produce the following output: \n\n initial state of list on this iteration: [0, 1, 2, 3, 4, 5, 6, 7, 8]\ncurrent iteration value: 0\npopped value: 2\n\ninitial state of list on this iteration: [0, 1, 3, 4, 5, 6, 7, 8]\ncurrent iteration value: 1\npopped value: 3\n\ninitial state of list on this iteration: [0, 1, 4, 5, 6, 7, 8]\ncurrent iteration value: 4\npopped value: 4\n\ninitial state of list on this iteration: [0, 1, 5, 6, 7, 8]\ncurrent iteration value: 5\npopped value: 5\n\ninitial state of list on this iteration: [0, 1, 6, 7, 8]\ncurrent iteration value: 6\npopped value: 6\n\ninitial state of list on this iteration: [0, 1, 7, 8]\ncurrent iteration value: 7\npopped value: 7\n\ninitial state of list on this iteration: [0, 1, 8]\ncurrent iteration value: 8\npopped value: 8\n\nFinal List Value: [0, 1]\n \n\n Above we have used the  pop  method on the fluid list object. Other common iterable methods are also implemented such as  del fluidL[i] ,  .remove ,  .insert ,  .append ,  .extend . The list can also be modified using slices ( sort  and  reverse  methods are not implemented). \n\n The only condition is that you must only modify the list in place, if at any point  fluidL  or  l  were reassigned to a different list object the code would not work. The original  fluidL  object would still be used by the for loop but would become out of scope for us to modify. \n\n i.e. \n\n fluidL[2] = 'a'   # is OK\nfluidL = [0, 1, 'a', 3, 4, 5, 6, 7, 8]  # is not OK\n \n\n If we want to access the current index value of the list we cannot use enumerate, as this only counts how many times the for loop has run. Instead we will use the iterator object directly. \n\n fluidArr = FluidIterable([0,1,2,3])\n# get iterator first so can query the current index\nfluidArrIter = fluidArr.__iter__()\nfor i, v in enumerate(fluidArrIter):\n    print('enum: ', i)\n    print('current val: ', v)\n    print('current ind: ', fluidArrIter.currentIndex)\n    print(fluidArr)\n    fluidArr.insert(0,'a')\n    print(' ')\n\nprint('Final List Value: ' + str(fluidArr))\n \n\n This will output the following: \n\n enum:  0\ncurrent val:  0\ncurrent ind:  0\n[0, 1, 2, 3]\n\nenum:  1\ncurrent val:  1\ncurrent ind:  2\n['a', 0, 1, 2, 3]\n\nenum:  2\ncurrent val:  2\ncurrent ind:  4\n['a', 'a', 0, 1, 2, 3]\n\nenum:  3\ncurrent val:  3\ncurrent ind:  6\n['a', 'a', 'a', 0, 1, 2, 3]\n\nFinal List Value: ['a', 'a', 'a', 'a', 0, 1, 2, 3]\n \n\n The  FluidIterable  class just provides a wrapper for the original list object. The original object can be accessed as a property of the fluid object like so: \n\n originalList = fluidArr.fixedIterable\n \n\n More examples / tests can be found in the  if __name__ is \"__main__\":  section at the bottom of  fluidIter.py . These are worth looking at because they explain what happens in various situations. Such as: Replacing a large sections of the list using a slice. Or using (and modifying) the same iterable in nested for loops. \n\n As I stated to start with: this is a complicated solution that will hurt the readability of your code and make it more difficult to debug. Therefore other solutions such as the list comprehensions mentioned in David Raznick's  answer  should be considered first. That being said, I have found times where this class has been useful to me and has been easier to use than keeping track of the indices of elements that need deleting. \n\n \n\n Edit: As mentioned in the comments, this answer does not really present a problem for which this approach provides a solution. I will try to address that here: \n\n List comprehensions provide a way to generate a new list but these approaches tend to look at each element in isolation rather than the current state of the list as a whole. \n\n i.e. \n\n newList = [i for i in oldList if testFunc(i)]\n \n\n But what if the result of the  testFunc  depends on the elements that have been added to  newList  already? Or the elements still in  oldList  that might be added next? There might still be a way to use a list comprehension but it will begin to lose it's elegance, and for me it feels easier to modify a list in place. \n\n The code below is one example of an algorithm that suffers from the above problem. The algorithm will reduce a list so that no element is a multiple of any other element. \n\n randInts = [70, 20, 61, 80, 54, 18, 7, 18, 55, 9]\nfRandInts = FluidIterable(randInts)\nfRandIntsIter = fRandInts.__iter__()\n# for each value in the list (outer loop)\n# test against every other value in the list (inner loop)\nfor i in fRandIntsIter:\n    print(' ')\n    print('outer val: ', i)\n    innerIntsIter = fRandInts.__iter__()\n    for j in innerIntsIter:\n        innerIndex = innerIntsIter.currentIndex\n        # skip the element that the outloop is currently on\n        # because we don't want to test a value against itself\n        if not innerIndex == fRandIntsIter.currentIndex:\n            # if the test element, j, is a multiple \n            # of the reference element, i, then remove 'j'\n            if j%i == 0:\n                print('remove val: ', j)\n                # remove element in place, without breaking the\n                # iteration of either loop\n                del fRandInts[innerIndex]\n            # end if multiple, then remove\n        # end if not the same value as outer loop\n    # end inner loop\n# end outerloop\n\nprint('')\nprint('final list: ', randInts)\n \n\n The output and the final reduced list are shown below \n\n outer val:  70\n\nouter val:  20\nremove val:  80\n\nouter val:  61\n\nouter val:  54\n\nouter val:  18\nremove val:  54\nremove val:  18\n\nouter val:  7\nremove val:  70\n\nouter val:  55\n\nouter val:  9\nremove val:  18\n\nfinal list:  [20, 61, 7, 55, 9]\n \n    ", "date_posted": "2017-05-23 12:18:24Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": [{"stack_answer_id": "37277264", "stack_answer_comment_id": "63359804", "comment_content": "It's hard to tell whether this is over-engineered because it's unclear what problem it's trying to solve; what does removing elements using this approach achieve that ", "user_id": null}, {"stack_answer_id": "37277264", "stack_answer_comment_id": "63591681", "comment_content": "@MarkAmery. The main use case for when this is when trying to determine if an item should be removed (or added or moved) based not on just the item itself, but on the state of another item in the list or the state of the list as a whole. For example, it is not possible with list comprehensions to write something like ", "user_id": null}]}, {"stack_answer_id": "52447608", "answer_content": "\r\n In some situations, where you're doing more than simply filtering a list one item at time, you want your iteration to change while iterating. \n\n Here is an example where copying the list beforehand is incorrect, reverse iteration is impossible and a list comprehension is also not an option. \n\n \"\"\" Sieve of Eratosthenes \"\"\"\n\ndef generate_primes(n):\n    \"\"\" Generates all primes less than n. \"\"\"\n    primes = list(range(2,n))\n    idx = 0\n    while idx < len(primes):\n        p = primes[idx]\n        for multiple in range(p+p, n, p):\n            try:\n                primes.remove(multiple)\n            except ValueError:\n                pass #EAFP\n        idx += 1\n        yield p\n \n    ", "date_posted": "2018-09-21 16:14:52Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "2780179", "name": "MathKid", "reputation_score": "1,513"}, "answer_comments": []}, {"stack_answer_id": "53600740", "answer_content": "\r\n I can think of three approaches to solve your problem. As an example, I will create a random list of tuples  somelist = [(1,2,3), (4,5,6), (3,6,6), (7,8,9), (15,0,0), (10,11,12)] . The condition that I choose is  sum of elements of a tuple = 15 . In the final list we will only have those tuples whose sum is not equal to 15.  \n\n What I have chosen is a randomly chosen example.  Feel free to change  the  list of tuples  and the  condition  that I have chosen.   \n\n Method 1.>  Use the framework that you had suggested (where one fills in a code inside a for loop). I use a small code with  del  to delete a tuple that meets the said condition. However, this method will miss a tuple (which satisfies the said condition) if two consecutively placed tuples meet the given condition.  \n\n for tup in somelist:\n    if ( sum(tup)==15 ): \n        del somelist[somelist.index(tup)]\n\nprint somelist\n>>> [(1, 2, 3), (3, 6, 6), (7, 8, 9), (10, 11, 12)]\n \n\n Method 2.>  Construct a new list which contains elements (tuples) where the given condition is not met (this is the same thing as removing elements of list where the given condition is met). Following is the code for that: \n\n newlist1 = [somelist[tup] for tup in range(len(somelist)) if(sum(somelist[tup])!=15)]\n\nprint newlist1\n>>>[(1, 2, 3), (7, 8, 9), (10, 11, 12)]\n \n\n Method 3.>  Find indices where the given condition is met, and then use remove elements (tuples) corresponding to those indices. Following is the code for that. \n\n indices = [i for i in range(len(somelist)) if(sum(somelist[i])==15)]\nnewlist2 = [tup for j, tup in enumerate(somelist) if j not in indices]\n\nprint newlist2\n>>>[(1, 2, 3), (7, 8, 9), (10, 11, 12)]\n \n\n Method 1 and method 2 are faster than method 3 . Method2 and method3 are more efficient than method1. I  prefer method2 . For the aforementioned example,  time(method1) : time(method2) : time(method3) = 1 : 1 : 1.7 \n    ", "date_posted": "2018-12-03 21:04:05Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "10626090", "name": "Siddharth Satpathy", "reputation_score": "2,513"}, "answer_comments": []}, {"stack_answer_id": "55704504", "answer_content": "\r\n If you will use the new list later, you can simply set the elem to None, and then judge it in the later loop, like this \n\n for i in li:\n    i = None\n\nfor elem in li:\n    if elem is None:\n        continue\n \n\n In this way, you dont't need copy the list and it's easier to understand.  \n    ", "date_posted": "2019-04-16 09:08:13Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "2899160", "name": "Mark Zhang", "reputation_score": "918"}, "answer_comments": []}, {"stack_answer_id": "51976515", "answer_content": "\r\n For anything that has the potential to be really big, I use the following.  \n\n import numpy as np\n\norig_list = np.array([1, 2, 3, 4, 5, 100, 8, 13])\n\nremove_me = [100, 1]\n\ncleaned = np.delete(orig_list, remove_me)\nprint(cleaned)\n \n\n That should be significantly faster than anything else.  \n    ", "date_posted": "2018-08-22 23:36:31Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "5893677", "name": "CENTURION", "reputation_score": "325"}, "answer_comments": [{"stack_answer_id": "51976515", "stack_answer_comment_id": "98893393", "comment_content": "From what I measured, NumPy starts to be faster for lists of more than 20 elements, and reaches >12x faster filtering for big lists of 1000 elements and more.", "user_id": null}]}], "user": {"stack_user_id": "90777", "name": "lfaraone", "reputation_score": "48.3k"}, "question_comments": [{"stack_question_id": "1207406", "stack_question_comment_id": "104658488", "comment_content": "Most answers on this page don't really explain why removing elements while iterating over a list produces strange results, but the ", "user_id": null}]},
{"stack_question_id": "53645882", "question_title": "Pandas Merging 101", "question_content": "\r\n                How can I perform a (INNER| (LEFT|RIGHT|FULL) OUTER) JOIN with pandas?\nHow do I add NaNs for missing rows after a merge?\nHow do I get rid of NaNs after merging?\nCan I merge on the index?\nHow do I ...\r\n", "question_url": "/questions/53645882/pandas-merging-101", "date_posted": "Dec 6, 2018 at 6:41", "upvote": "7", "view": "3", "tags": ["python", "pandas", "join", "merge", "concatenation"], "answers_count": "8", "answers": [{"stack_answer_id": "53645883", "answer_content": "\r\n This post aims to give readers a primer on SQL-flavored merging with Pandas, how to use it, and when not to use it. \n In particular, here's what this post will go through: \n \n The basics - types of joins (LEFT, RIGHT, OUTER, INNER) \n \n merging with different column names \n merging with multiple columns \n avoiding duplicate merge key column in output \n \n \n \n What this post (and other posts by me on this thread) will not go through: \n \n Performance-related discussions and timings (for now). Mostly notable mentions of better alternatives, wherever appropriate. \n Handling suffixes, removing extra columns, renaming outputs, and other specific use cases. There are other (read: better) posts that deal with that, so figure it out! \n \n \n Note \nMost examples default to INNER JOIN operations while demonstrating various features, unless otherwise specified. \n Furthermore, all the DataFrames here can be copied and replicated so\nyou can play with them. Also, see  this\npost \non how to read DataFrames from your clipboard. \n Lastly, all visual representation of JOIN operations have been hand-drawn using Google Drawings. Inspiration from  here . \n \n \n \n Enough talk - just show me how to use  merge ! \n Setup & Basics \n np.random.seed(0)\nleft = pd.DataFrame({'key': ['A', 'B', 'C', 'D'], 'value': np.random.randn(4)})\nright = pd.DataFrame({'key': ['B', 'D', 'E', 'F'], 'value': np.random.randn(4)})\n\nleft\n\n  key     value\n0   A  1.764052\n1   B  0.400157\n2   C  0.978738\n3   D  2.240893\n\nright\n\n  key     value\n0   B  1.867558\n1   D -0.977278\n2   E  0.950088\n3   F -0.151357\n \n For the sake of simplicity, the key column has the same name (for now). \n An  INNER JOIN  is represented by \n \n \n Note \nThis, along with the forthcoming figures all follow this convention: \n \n blue  indicates rows that are present in the merge result \n red  indicates rows that are excluded from the result (i.e., removed) \n green  indicates missing values that are replaced with  NaN s in the result \n \n \n To perform an INNER JOIN, call  merge  on the left DataFrame, specifying the right DataFrame and the join key (at the very least) as arguments. \n left.merge(right, on='key')\n# Or, if you want to be explicit\n# left.merge(right, on='key', how='inner')\n\n  key   value_x   value_y\n0   B  0.400157  1.867558\n1   D  2.240893 -0.977278\n \n This returns only rows from  left  and  right  which share a common key (in this example, \"B\" and \"D). \n A  LEFT OUTER JOIN , or LEFT JOIN  is represented by \n \n This can be performed by specifying  how='left' . \n left.merge(right, on='key', how='left')\n\n  key   value_x   value_y\n0   A  1.764052       NaN\n1   B  0.400157  1.867558\n2   C  0.978738       NaN\n3   D  2.240893 -0.977278\n \n Carefully note the placement of NaNs here. If you specify  how='left' , then only keys from  left  are used, and missing data from  right  is replaced by NaN. \n And similarly, for a  RIGHT OUTER JOIN , or RIGHT JOIN which is... \n \n ...specify  how='right' : \n left.merge(right, on='key', how='right')\n\n  key   value_x   value_y\n0   B  0.400157  1.867558\n1   D  2.240893 -0.977278\n2   E       NaN  0.950088\n3   F       NaN -0.151357\n \n Here, keys from  right  are used, and missing data from  left  is replaced by NaN. \n Finally, for the  FULL OUTER JOIN , given by \n \n specify  how='outer' . \n left.merge(right, on='key', how='outer')\n\n  key   value_x   value_y\n0   A  1.764052       NaN\n1   B  0.400157  1.867558\n2   C  0.978738       NaN\n3   D  2.240893 -0.977278\n4   E       NaN  0.950088\n5   F       NaN -0.151357\n \n This uses the keys from both frames, and NaNs are inserted for missing rows in both. \n The documentation summarizes these various merges nicely: \n \n \n Other JOINs - LEFT-Excluding, RIGHT-Excluding, and FULL-Excluding/ANTI JOINs \n If you need  LEFT-Excluding JOINs  and  RIGHT-Excluding JOINs  in two steps. \n For LEFT-Excluding JOIN, represented as \n \n Start by performing a LEFT OUTER JOIN and then filtering to rows coming from  left  only (excluding everything from the right), \n (left.merge(right, on='key', how='left', indicator=True)\n     .query('_merge == \"left_only\"')\n     .drop('_merge', 1))\n\n  key   value_x  value_y\n0   A  1.764052      NaN\n2   C  0.978738      NaN\n \n Where, \n left.merge(right, on='key', how='left',  indicator=True )\n\n  key   value_x   value_y     _merge\n0   A  1.764052       NaN  left_only\n1   B  0.400157  1.867558       both\n2   C  0.978738       NaN  left_only\n3   D  2.240893 -0.977278       both \n And similarly, for a RIGHT-Excluding JOIN, \n \n (left.merge(right, on='key', how='right',  indicator=True )\n     .query('_merge == \"right_only\"')\n     .drop('_merge', 1))\n\n  key  value_x   value_y\n2   E      NaN  0.950088\n3   F      NaN -0.151357 \n Lastly, if you are required to do a merge that only retains keys from the left or right, but not both (IOW, performing an  ANTI-JOIN ), \n \n You can do this in similar fashion\u2014 \n (left.merge(right, on='key', how='outer', indicator=True)\n     .query('_merge != \"both\"')\n     .drop('_merge', 1))\n\n  key   value_x   value_y\n0   A  1.764052       NaN\n2   C  0.978738       NaN\n4   E       NaN  0.950088\n5   F       NaN -0.151357\n \n \n Different names for key columns \n If the key columns are named differently\u2014for example,  left  has  keyLeft , and  right  has  keyRight  instead of  key \u2014then you will have to specify  left_on  and  right_on  as arguments instead of  on : \n left2 = left.rename({'key':'keyLeft'}, axis=1)\nright2 = right.rename({'key':'keyRight'}, axis=1)\n\nleft2\n\n  keyLeft     value\n0       A  1.764052\n1       B  0.400157\n2       C  0.978738\n3       D  2.240893\n\nright2\n\n  keyRight     value\n0        B  1.867558\n1        D -0.977278\n2        E  0.950088\n3        F -0.151357\n \n\n left2.merge(right2, left_on='keyLeft', right_on='keyRight', how='inner')\n\n  keyLeft   value_x keyRight   value_y\n0       B  0.400157        B  1.867558\n1       D  2.240893        D -0.977278\n \n \n Avoiding duplicate key column in output \n When merging on  keyLeft  from  left  and  keyRight  from  right , if you only want either of the  keyLeft  or  keyRight  (but not both) in the output, you can start by setting the index as a preliminary step. \n left3 = left2.set_index('keyLeft')\nleft3.merge(right2, left_index=True, right_on='keyRight')\n\n    value_x keyRight   value_y\n0  0.400157        B  1.867558\n1  2.240893        D -0.977278\n \n Contrast this with the output of the command just before (that is, the output of  left2.merge(right2, left_on='keyLeft', right_on='keyRight', how='inner') ), you'll notice  keyLeft  is missing. You can figure out what column to keep based on which frame's index is set as the key. This may matter when, say, performing some OUTER JOIN operation. \n \n Merging only a single column from one of the  DataFrames \n For example, consider \n right3 = right.assign(newcol=np.arange(len(right)))\nright3\n  key     value  newcol\n0   B  1.867558       0\n1   D -0.977278       1\n2   E  0.950088       2\n3   F -0.151357       3\n \n If you are required to merge only \"newcol\" (without any of the other columns), you can usually just subset columns before merging: \n left.merge(right3[['key', 'newcol']], on='key')\n\n  key     value  newcol\n0   B  0.400157       0\n1   D  2.240893       1\n \n If you're doing a LEFT OUTER JOIN, a more performant solution would involve  map : \n # left['newcol'] = left['key'].map(right3.set_index('key')['newcol']))\nleft.assign(newcol=left['key'].map(right3.set_index('key')['newcol']))\n\n  key     value  newcol\n0   A  1.764052     NaN\n1   B  0.400157     0.0\n2   C  0.978738     NaN\n3   D  2.240893     1.0\n \n As mentioned, this is similar to, but faster than \n left.merge(right3[['key', 'newcol']], on='key', how='left')\n\n  key     value  newcol\n0   A  1.764052     NaN\n1   B  0.400157     0.0\n2   C  0.978738     NaN\n3   D  2.240893     1.0\n \n \n Merging on multiple columns \n To join on more than one column, specify a list for  on  (or  left_on  and  right_on , as appropriate). \n left.merge(right, on=['key1', 'key2'] ...)\n \n Or, in the event the names are different, \n left.merge(right, left_on=['lkey1', 'lkey2'], right_on=['rkey1', 'rkey2'])\n \n \n Other useful  merge*  operations and functions \n \n Merging a DataFrame with Series on index: See  this answer . \n \n Besides  merge ,  DataFrame.update  and  DataFrame.combine_first  are also used in certain cases to update one DataFrame with another. \n \n pd.merge_ordered  is a useful function for ordered JOINs. \n \n pd.merge_asof  (read: merge_asOf) is useful for  approximate  joins. \n \n \n This section only covers the very basics, and is designed to only whet your appetite. For more examples and cases, see the  documentation on  merge ,  join , and  concat  as well as the links to the function specifications. \n \n \n Continue Reading \n Jump to other topics in Pandas Merging 101 to continue learning: \n \n Merging basics - basic types of joins   * \n \n Index-based joins \n \n Generalizing to multiple DataFrames \n \n Cross join \n \n \n *You are here. \n    ", "date_posted": "2022-07-01 21:01:48Z", "upvote": "\r\n            1112\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "7967588", "name": "creanion", "reputation_score": "1,821"}, "answer_comments": [{"stack_answer_id": "53645883", "stack_answer_comment_id": "115512450", "comment_content": "If anyone is confused by the table of contents at the end of each post, I split up this massive answer into 4 separate ones, 3 on this question and 1 on another. The way it was setup previously made it harder to reference folks to specific topics. This allows you to bookmark separate topics easily now!", "user_id": "/users/4909087/cs95"}, {"stack_answer_id": "53645883", "stack_answer_comment_id": "118452869", "comment_content": "This is an awesome resource! The only question I still have is why call it merge instead of join, and join instead of merge?", "user_id": null}]}, {"stack_answer_id": "55858991", "answer_content": "\r\n A supplemental visual view of  pd.concat([df0, df1], kwargs) . \nNotice that, kwarg  axis=0  or  axis=1  's meaning is not as intuitive as  df.mean()  or  df.apply(func) \n\n \n\n \n    ", "date_posted": "2019-10-11 17:36:29Z", "upvote": "\r\n            89\r\n        ", "accepted": "No", "user": {"stack_user_id": "11884237", "name": "ansev", "reputation_score": "29.3k"}, "answer_comments": [{"stack_answer_id": "55858991", "stack_answer_comment_id": "99071795", "comment_content": "This is a nice diagram. May I ask how you produced it?", "user_id": "/users/4909087/cs95"}, {"stack_answer_id": "55858991", "stack_answer_comment_id": "99107100", "comment_content": "google doc's built-in \"insert ==> drawing... ==> new\" (as of 2019-May). But, to be clear: the only reason I used google doc for this picture  is because my notes is stored in google doc, and I would like a picture that can be modified quickly within google doc itself. Actually now you mentioned it, the google doc's drawing tool is pretty neat.", "user_id": null}, {"stack_answer_id": "55858991", "stack_answer_comment_id": "101107976", "comment_content": "Wow, this is great. Coming from the SQL world, \"vertical\" join is not a join in my head, as the table's structure is always fixed. Now even think pandas should consolidate ", "user_id": null}, {"stack_answer_id": "55858991", "stack_answer_comment_id": "101246910", "comment_content": "@Ufos Isn't that exactly what ", "user_id": "/users/4909087/cs95"}, {"stack_answer_id": "55858991", "stack_answer_comment_id": "101569956", "comment_content": "yes, there're now ", "user_id": null}]}, {"stack_answer_id": "69115959", "answer_content": "\r\n Joins 101 \n These animations might be better to explain you visually.\nCredits:  Garrick Aden-Buie tidyexplain repo \n Inner Join \n \n Outer Join or Full Join \n \n Right Join \n \n Left Join \n \n    ", "date_posted": "2021-09-18 04:58:49Z", "upvote": "\r\n            54\r\n        ", "accepted": "No", "user": {"stack_user_id": "8277795", "name": "Anurag Dhadse", "reputation_score": "1,340"}, "answer_comments": [{"stack_answer_id": "69115959", "stack_answer_comment_id": "124057875", "comment_content": "These are awesome!", "user_id": null}, {"stack_answer_id": "69115959", "stack_answer_comment_id": "125963015", "comment_content": "I appreciate the effort put in to achieve this. Beautifully done.", "user_id": null}]}, {"stack_answer_id": "63338203", "answer_content": "\r\n In this answer, I will consider practical examples. \n The first one, is of  pandas.concat . \n The second one, of merging dataframes from the index of one and the column of another one. \n \n 1 .  pandas.concat \n Considering the following  DataFrames  with the same column names: \n Preco2018  with size (8784, 5) \n \n Preco 2019  with size (8760, 5) \n \n That have the same column names. \n You can combine them using  pandas.concat , by simply \n import pandas as pd\n\nframes = [Preco2018, Preco2019]\n\ndf_merged = pd.concat(frames)\n \n Which results in a DataFrame with the following size (17544, 5) \n \n If you want to visualize, it ends up working like this \n \n ( Source ) \n \n 2 . Merge by Column and Index \n In this part, I will consider a specific case: If one wants to merge the index of one dataframe and the column of another dataframe. \n Let's say one has the dataframe  Geo  with 54 columns, being one of the columns the Date  Data , which is of type  datetime64[ns] . \n \n And the dataframe  Price  that has one column with the price and the index corresponds to the dates \n \n In this specific case, to merge them, one uses  pd.merge \n merged = pd.merge(Price, Geo, left_index=True, right_on='Data')\n \n Which results in the following dataframe \n \n    ", "date_posted": "2021-01-24 00:26:49Z", "upvote": "\r\n            22\r\n        ", "accepted": "No", "user": {"stack_user_id": "7109869", "name": "Gon\u00e7alo Peres", "reputation_score": "6,422"}, "answer_comments": []}, {"stack_answer_id": "65167356", "answer_content": "\r\n This post will go through the following topics: \n \n Merging with index under different conditions\n \n options for index-based joins:  merge ,  join ,  concat \n merging on indexes \n merging on index of one, column of other \n \n \n effectively using named indexes to simplify merging syntax \n \n BACK TO TOP \n \n \n Index-based joins \n TL;DR \n \n There are a few options, some simpler than others depending on the use\ncase. \n \n DataFrame.merge  with  left_index  and  right_index  (or  left_on  and  right_on  using named indexes)\n \n supports inner/left/right/full \n can only join two at a time \n supports column-column, index-column, index-index joins \n \n \n DataFrame.join  (join on index)\n \n supports inner/left (default)/right/full \n can join multiple DataFrames at a time \n supports index-index joins \n \n \n pd.concat  (joins on index)\n \n supports inner/full (default) \n can join multiple DataFrames at a time \n supports index-index joins \n \n \n \n \n \n Index to index joins \n Setup & Basics \n import pandas as pd\nimport numpy as np\n\nnp.random.seed([3, 14])\nleft = pd.DataFrame(data={'value': np.random.randn(4)}, \n                    index=['A', 'B', 'C', 'D'])    \nright = pd.DataFrame(data={'value': np.random.randn(4)},  \n                     index=['B', 'D', 'E', 'F'])\nleft.index.name = right.index.name = 'idxkey'\n\nleft\n           value\nidxkey          \nA      -0.602923\nB      -0.402655\nC       0.302329\nD      -0.524349\n\nright\n \n           value\nidxkey          \nB       0.543843\nD       0.013135\nE      -0.326498\nF       1.385076\n \n Typically, an  inner join on index  would look like this: \n left.merge(right, left_index=True, right_index=True)\n\n         value_x   value_y\nidxkey                    \nB      -0.402655  0.543843\nD      -0.524349  0.013135\n \n Other joins follow similar syntax. \n Notable Alternatives \n \n DataFrame.join  defaults to joins on the index.  DataFrame.join  does a LEFT OUTER JOIN by default, so  how='inner'  is necessary here. \n  left.join(right, how='inner', lsuffix='_x', rsuffix='_y')\n\n          value_x   value_y\n idxkey                    \n B      -0.402655  0.543843\n D      -0.524349  0.013135\n \n Note that I needed to specify the  lsuffix  and  rsuffix  arguments since  join  would otherwise error out: \n  left.join(right)\n ValueError: columns overlap but no suffix specified: Index(['value'], dtype='object')\n \n Since the column names are the same. This would not be a problem if they were differently named. \n  left.rename(columns={'value':'leftvalue'}).join(right, how='inner')\n\n         leftvalue     value\n idxkey                     \n B       -0.402655  0.543843\n D       -0.524349  0.013135\n \n \n pd.concat  joins on the index and can join two or more DataFrames at once. It does a full outer join by default, so  how='inner'  is required here.. \n  pd.concat([left, right], axis=1, sort=False, join='inner')\n\n            value     value\n idxkey                    \n B      -0.402655  0.543843\n D      -0.524349  0.013135\n \n For more information on  concat , see  this post . \n \n \n \n Index to Column joins \n To perform an inner join using index of left, column of right, you will use  DataFrame.merge  a combination of  left_index=True  and  right_on=... . \n right2 = right.reset_index().rename({'idxkey' : 'colkey'}, axis=1)\nright2\n \n  colkey     value\n0      B  0.543843\n1      D  0.013135\n2      E -0.326498\n3      F  1.385076\n\nleft.merge(right2, left_index=True, right_on='colkey')\n\n    value_x colkey   value_y\n0 -0.402655      B  0.543843\n1 -0.524349      D  0.013135\n \n Other joins follow a similar structure. Note that only  merge  can perform index to column joins. You can join on multiple columns, provided the number of index levels on the left equals the number of columns on the right. \n join  and  concat  are not capable of mixed merges. You will need to set the index as a pre-step using  DataFrame.set_index . \n \n Effectively using Named Index [pandas >= 0.23] \n If your index is named, then from pandas >= 0.23,  DataFrame.merge  allows you to specify the index name to  on  (or  left_on  and  right_on  as necessary). \n left.merge(right, on='idxkey')\n\n         value_x   value_y\nidxkey                    \nB      -0.402655  0.543843\nD      -0.524349  0.013135\n \n For the previous example of merging with the index of left, column of right, you can use  left_on  with the index name of left: \n left.merge(right2, left_on='idxkey', right_on='colkey')\n\n    value_x colkey   value_y\n0 -0.402655      B  0.543843\n1 -0.524349      D  0.013135\n \n \n \n Continue Reading \n Jump to other topics in Pandas Merging 101 to continue learning: \n \n Merging basics - basic types of joins \n \n Index-based joins * \n \n Generalizing to multiple DataFrames \n \n Cross join \n \n \n * you are here  \n    ", "date_posted": "2022-06-05 19:09:34Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "65167356", "name": "\r\n        6 revs, 2 users 100%", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "65167327", "answer_content": "\r\n This post will go through the following topics: \n \n how to correctly generalize to multiple DataFrames (and why  merge  has shortcomings here) \n merging on unique keys \n merging on non-unqiue keys \n \n BACK TO TOP \n \n \n Generalizing to multiple DataFrames \n Oftentimes, the situation arises when multiple DataFrames are to be merged together. Naively, this can be done by chaining  merge  calls: \n df1.merge(df2, ...).merge(df3, ...)\n \n However, this quickly gets out of hand for many DataFrames. Furthermore, it may be necessary to generalise for an unknown number of DataFrames. \n Here I introduce  pd.concat  for multi-way joins on  unique  keys, and  DataFrame.join  for multi-way joins on  non-unique  keys. First, the setup. \n # Setup.\nnp.random.seed(0)\nA = pd.DataFrame({'key': ['A', 'B', 'C', 'D'], 'valueA': np.random.randn(4)})    \nB = pd.DataFrame({'key': ['B', 'D', 'E', 'F'], 'valueB': np.random.randn(4)})\nC = pd.DataFrame({'key': ['D', 'E', 'J', 'C'], 'valueC': np.ones(4)})\ndfs = [A, B, C] \n\n# Note: the \"key\" column values are unique, so the index is unique.\nA2 = A.set_index('key')\nB2 = B.set_index('key')\nC2 = C.set_index('key')\n\ndfs2 = [A2, B2, C2]\n \n \n Multiway merge on unique keys \n If your keys (here, the key could either be a column or an index) are unique, then you can use  pd.concat . Note that  pd.concat  joins DataFrames on the index . \n # Merge on `key` column. You'll need to set the index before concatenating\npd.concat(\n    [df.set_index('key') for df in dfs], axis=1, join='inner'\n).reset_index()\n\n  key    valueA    valueB  valueC\n0   D  2.240893 -0.977278     1.0\n\n# Merge on `key` index.\npd.concat(dfs2, axis=1, sort=False, join='inner')\n\n       valueA    valueB  valueC\nkey                            \nD    2.240893 -0.977278     1.0\n \n Omit  join='inner'  for a FULL OUTER JOIN. Note that you cannot specify LEFT or RIGHT OUTER joins (if you need these, use  join , described below). \n \n Multiway merge on keys with duplicates \n concat  is fast, but has its shortcomings. It cannot handle duplicates. \n A3 = pd.DataFrame({'key': ['A', 'B', 'C', 'D', 'D'], 'valueA': np.random.randn(5)})\npd.concat([df.set_index('key') for df in [A3, B, C]], axis=1, join='inner')\n \n ValueError: Shape of passed values is (3, 4), indices imply (3, 2)\n \n In this situation, we can use  join  since it can handle non-unique keys (note that  join  joins DataFrames on their index; it calls  merge  under the hood and does a LEFT OUTER JOIN unless otherwise specified). \n # Join on `key` column. Set as the index first.\n# For inner join. For left join, omit the \"how\" argument.\nA.set_index('key').join([B2, C2], how='inner').reset_index()\n\n  key    valueA    valueB  valueC\n0   D  2.240893 -0.977278     1.0\n\n# Join on `key` index.\nA3.set_index('key').join([B2, C2], how='inner')\n\n       valueA    valueB  valueC\nkey                            \nD    1.454274 -0.977278     1.0\nD    0.761038 -0.977278     1.0\n \n \n \n Continue Reading \n Jump to other topics in Pandas Merging 101 to continue learning: \n \n Merging basics - basic types of joins \n \n Index-based joins \n \n Generalizing to multiple DataFrames   * \n \n Cross join \n \n \n * you are here  \n    ", "date_posted": "2022-06-05 19:24:17Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "65167327", "name": "\r\n        6 revs, 2 users 87%", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "73285069", "answer_content": "\r\n Pandas at the moment does not support inequality joins within the merge syntax; one option is with the  conditional_join  function from  pyjanitor  - I am a contributor to this library: \n # pip install pyjanitor\nimport pandas as pd\nimport janitor \n\nleft.conditional_join(right, ('value', 'value', '>'))\n\n   left           right\n    key     value   key     value\n0     A  1.764052     D -0.977278\n1     A  1.764052     F -0.151357\n2     A  1.764052     E  0.950088\n3     B  0.400157     D -0.977278\n4     B  0.400157     F -0.151357\n5     C  0.978738     D -0.977278\n6     C  0.978738     F -0.151357\n7     C  0.978738     E  0.950088\n8     D  2.240893     D -0.977278\n9     D  2.240893     F -0.151357\n10    D  2.240893     E  0.950088\n11    D  2.240893     B  1.867558\n\nleft.conditional_join(right, ('value', 'value', '<'))\n\n  left           right\n   key     value   key     value\n0    A  1.764052     B  1.867558\n1    B  0.400157     E  0.950088\n2    B  0.400157     B  1.867558\n3    C  0.978738     B  1.867558\n \n The columns are passed as a variable argument of tuples, each tuple comprising of a column from the left dataframe, column from the right dataframe, and the join operator, which can be any of  (>, <, >=, <=, !=) . In the example above, a MultiIndex column is returned, because of overlaps in the column names. \n Performance wise, this is better than a naive cross join: \n np.random.seed(0)\ndd = pd.DataFrame({'value':np.random.randint(100000, size=50_000)})\ndf = pd.DataFrame({'start':np.random.randint(100000, size=1_000), \n                   'end':np.random.randint(100000, size=1_000)})\n\ndd.head()\n\n   value\n0  68268\n1  43567\n2  42613\n3  45891\n4  21243\n\ndf.head()\n\n   start    end\n0  71915  47005\n1  64284  44913\n2  13377  96626\n3  75823  38673\n4  29151    575\n\n\n%%timeit\nout = df.merge(dd, how='cross')\nout.loc[(out.start < out.value) & (out.end > out.value)]\n5.12 s \u00b1 19 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n\n%timeit df.conditional_join(dd, ('start', 'value' ,'<'), ('end', 'value' ,'>'))\n280 ms \u00b1 5.56 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n\nout = df.merge(dd, how='cross')\nout = out.loc[(out.start < out.value) & (out.end > out.value)]\nA = df.conditional_join(dd, ('start', 'value' ,'<'), ('end', 'value' ,'>'))\ncolumns = A.columns.tolist()\nA = A.sort_values(columns, ignore_index = True)\nout = out.sort_values(columns, ignore_index = True)\n\nA.equals(out)\nTrue\n \n    ", "date_posted": "2022-08-08 23:35:35Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "7175713", "name": "sammywemmy", "reputation_score": "23.6k"}, "answer_comments": []}, {"stack_answer_id": "53787691", "answer_content": "\r\n I think you should include this in your explanation as it is a relevant merge that I see fairly often, which is termed  cross-join  I believe. This is a merge that occurs when unique df's share no columns, and it simply merging 2 dfs side-by-side: \n The setup: \n names1 = [{'A':'Jack', 'B':'Jill'}]\n\nnames2 = [{'C':'Tommy', 'D':'Tammy'}]\n\ndf1=pd.DataFrame(names1)\ndf2=pd.DataFrame(names2)\ndf_merged= pd.merge(df1.assign(X=1), df2.assign(X=1), on='X').drop('X', 1)\n \n This creates a dummy X column, merges on the X, and then drops it to produce \n df_merged: \n       A     B      C      D\n0  Jack  Jill  Tommy  Tammy\n \n    ", "date_posted": "2022-08-09 07:20:23Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "6296561", "name": "Zoe stands with Ukraine", "reputation_score": "25.5k"}, "answer_comments": [{"stack_answer_id": "53787691", "stack_answer_comment_id": "94427861", "comment_content": "Please check the second comment under the question. Cross join was initially a part of this (see edit history) but was later edited out into it's own post for volume.", "user_id": "/users/4909087/cs95"}, {"stack_answer_id": "53787691", "stack_answer_comment_id": "94427874", "comment_content": "I see! do you want me to delete this so it is not convoluted?", "user_id": null}, {"stack_answer_id": "53787691", "stack_answer_comment_id": "94427904", "comment_content": "Seeing as cross join was not meant to be covered here, yes... However I appreciate your intent to contribute in good faith :)", "user_id": "/users/4909087/cs95"}]}], "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "question_comments": []},
{"stack_question_id": "47152691", "question_title": "How can I pivot a dataframe?", "question_content": "\r\n                What is pivot?\nHow do I pivot?\nIs this a pivot?\nLong format to wide format?\n\nI've seen a lot of questions that ask about pivot tables.  Even if they don't know that they are asking about pivot tables, ...\r\n", "question_url": "/questions/47152691/how-can-i-pivot-a-dataframe", "date_posted": "Nov 7, 2017 at 8:00", "upvote": "5", "view": "5", "tags": ["python", "pandas", "group-by", "pivot", "pandas-groupby"], "answers_count": "4", "answers": [{"stack_answer_id": "47152692", "answer_content": "\r\n We start by answering the first question: \n Question 1 \n \n Why do I get  ValueError: Index contains duplicate entries, cannot reshape \n \n This occurs because pandas is attempting to reindex either a  columns  or  index  object with duplicate entries.  There are varying methods to use that can perform a pivot.  Some of them are not well suited to when there are duplicates of the keys in which it is being asked to pivot on.  For example.  Consider  pd.DataFrame.pivot .  I know there are duplicate entries that share the  row  and  col  values: \n df.duplicated(['row', 'col']).any()\n\nTrue\n \n So when I  pivot  using \n df.pivot(index='row', columns='col', values='val0')\n \n I get the error mentioned above.  In fact, I get the same error when I try to perform the same task with: \n df.set_index(['row', 'col'])['val0'].unstack()\n \n Here is a list of idioms we can use to pivot \n \n pd.DataFrame.groupby  +  pd.DataFrame.unstack \n \n Good general approach for doing just about any type of pivot \n You specify all columns that will constitute the pivoted row levels and column levels in one group by.  You follow that by selecting the remaining columns you want to aggregate and the function(s) you want to perform the aggregation.  Finally, you  unstack  the levels that you want to be in the column index. \n \n \n pd.DataFrame.pivot_table \n \n A glorified version of  groupby  with more intuitive API.  For many people, this is the preferred approach.  And is the intended approach by the developers. \n Specify row level, column levels, values to be aggregated, and function(s) to perform aggregations. \n \n \n pd.DataFrame.set_index  +  pd.DataFrame.unstack \n \n Convenient and intuitive for some (myself included).  Cannot handle duplicate grouped keys. \n Similar to the  groupby  paradigm, we specify all columns that will eventually be either row or column levels and set those to be the index.  We then  unstack  the levels we want in the columns.  If either the remaining index levels or column levels are not unique, this method will fail. \n \n \n pd.DataFrame.pivot \n \n Very similar to  set_index  in that it shares the duplicate key limitation.  The API is very limited as well.  It only takes scalar values for  index ,  columns ,  values . \n Similar to the  pivot_table  method in that we select rows, columns, and values on which to pivot.  However, we cannot aggregate and if either rows or columns are not unique, this method will fail. \n \n \n pd.crosstab \n \n This a specialized version of  pivot_table  and in its purest form is the most intuitive way to perform several tasks. \n \n \n pd.factorize  +  np.bincount \n \n This is a highly advanced technique that is very obscure but is very fast.  It cannot be used in all circumstances, but when it can be used and you are comfortable using it, you will reap the performance rewards. \n \n \n pd.get_dummies  +  pd.DataFrame.dot \n \n I use this for cleverly performing cross tabulation. \n \n \n \n \n Examples \n What I'm going to do for each subsequent answer and question is to answer it using  pd.DataFrame.pivot_table .  Then I'll provide alternatives to perform the same task. \n Question 3 \n \n How do I pivot  df  such that the  col  values are columns,  row  values are the index, mean of  val0  are the values, and missing values are  0 ? \n \n \n pd.DataFrame.pivot_table \n \n fill_value  is not set by default.  I tend to set it appropriately.  In this case I set it to  0 .  Notice I skipped  question 2  as it's the same as this answer without the  fill_value \n \n aggfunc='mean'  is the default and I didn't have to set it.  I included it to be explicit. \n     df.pivot_table(\n        values='val0', index='row', columns='col',\n        fill_value=0, aggfunc='mean')\n\n    col   col0   col1   col2   col3  col4\n    row\n    row0  0.77  0.605  0.000  0.860  0.65\n    row2  0.13  0.000  0.395  0.500  0.25\n    row3  0.00  0.310  0.000  0.545  0.00\n    row4  0.00  0.100  0.395  0.760  0.24\n \n \n \n \n pd.DataFrame.groupby \n   df.groupby(['row', 'col'])['val0'].mean().unstack(fill_value=0)\n \n \n pd.crosstab \n   pd.crosstab(\n      index=df['row'], columns=df['col'],\n      values=df['val0'], aggfunc='mean').fillna(0)\n \n \n \n \n Question 4 \n \n Can I get something other than  mean , like maybe  sum ? \n \n \n pd.DataFrame.pivot_table \n   df.pivot_table(\n      values='val0', index='row', columns='col',\n      fill_value=0, aggfunc='sum')\n\n  col   col0  col1  col2  col3  col4\n  row\n  row0  0.77  1.21  0.00  0.86  0.65\n  row2  0.13  0.00  0.79  0.50  0.50\n  row3  0.00  0.31  0.00  1.09  0.00\n  row4  0.00  0.10  0.79  1.52  0.24\n \n \n pd.DataFrame.groupby \n   df.groupby(['row', 'col'])['val0'].sum().unstack(fill_value=0)\n \n \n pd.crosstab \n   pd.crosstab(\n      index=df['row'], columns=df['col'],\n      values=df['val0'], aggfunc='sum').fillna(0)\n \n \n \n \n Question 5 \n \n Can I do more that one aggregation at a time? \n \n Notice that for  pivot_table  and  crosstab  I needed to pass list of callables.  On the other hand,  groupby.agg  is able to take strings for a limited number of special functions.   groupby.agg  would also have taken the same callables we passed to the others, but it is often more efficient to leverage the string function names as there are efficiencies to be gained. \n \n pd.DataFrame.pivot_table \n   df.pivot_table(\n      values='val0', index='row', columns='col',\n      fill_value=0, aggfunc=[np.size, np.mean])\n\n       size                      mean\n  col  col0 col1 col2 col3 col4  col0   col1   col2   col3  col4\n  row\n  row0    1    2    0    1    1  0.77  0.605  0.000  0.860  0.65\n  row2    1    0    2    1    2  0.13  0.000  0.395  0.500  0.25\n  row3    0    1    0    2    0  0.00  0.310  0.000  0.545  0.00\n  row4    0    1    2    2    1  0.00  0.100  0.395  0.760  0.24\n \n \n pd.DataFrame.groupby \n   df.groupby(['row', 'col'])['val0'].agg(['size', 'mean']).unstack(fill_value=0)\n \n \n pd.crosstab \n   pd.crosstab(\n      index=df['row'], columns=df['col'],\n      values=df['val0'], aggfunc=[np.size, np.mean]).fillna(0, downcast='infer')\n \n \n \n \n Question 6 \n \n Can I aggregate over multiple value columns? \n \n \n pd.DataFrame.pivot_table  we pass  values=['val0', 'val1']  but we could've left that off completely \n   df.pivot_table(\n      values=['val0', 'val1'], index='row', columns='col',\n      fill_value=0, aggfunc='mean')\n\n        val0                             val1\n  col   col0   col1   col2   col3  col4  col0   col1  col2   col3  col4\n  row\n  row0  0.77  0.605  0.000  0.860  0.65  0.01  0.745  0.00  0.010  0.02\n  row2  0.13  0.000  0.395  0.500  0.25  0.45  0.000  0.34  0.440  0.79\n  row3  0.00  0.310  0.000  0.545  0.00  0.00  0.230  0.00  0.075  0.00\n  row4  0.00  0.100  0.395  0.760  0.24  0.00  0.070  0.42  0.300  0.46\n \n \n pd.DataFrame.groupby \n   df.groupby(['row', 'col'])['val0', 'val1'].mean().unstack(fill_value=0)\n \n \n \n \n Question 7 \n \n Can Subdivide by multiple columns? \n \n \n pd.DataFrame.pivot_table \n   df.pivot_table(\n      values='val0', index='row', columns=['item', 'col'],\n      fill_value=0, aggfunc='mean')\n\n  item item0             item1                         item2\n  col   col2  col3  col4  col0  col1  col2  col3  col4  col0   col1  col3  col4\n  row\n  row0  0.00  0.00  0.00  0.77  0.00  0.00  0.00  0.00  0.00  0.605  0.86  0.65\n  row2  0.35  0.00  0.37  0.00  0.00  0.44  0.00  0.00  0.13  0.000  0.50  0.13\n  row3  0.00  0.00  0.00  0.00  0.31  0.00  0.81  0.00  0.00  0.000  0.28  0.00\n  row4  0.15  0.64  0.00  0.00  0.10  0.64  0.88  0.24  0.00  0.000  0.00  0.00\n \n \n pd.DataFrame.groupby \n   df.groupby(\n      ['row', 'item', 'col']\n  )['val0'].mean().unstack(['item', 'col']).fillna(0).sort_index(1)\n \n \n \n \n Question 8 \n \n Can Subdivide by multiple columns? \n \n \n pd.DataFrame.pivot_table \n   df.pivot_table(\n      values='val0', index=['key', 'row'], columns=['item', 'col'],\n      fill_value=0, aggfunc='mean')\n\n  item      item0             item1                         item2\n  col        col2  col3  col4  col0  col1  col2  col3  col4  col0  col1  col3  col4\n  key  row\n  key0 row0  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.86  0.00\n       row2  0.00  0.00  0.37  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.50  0.00\n       row3  0.00  0.00  0.00  0.00  0.31  0.00  0.81  0.00  0.00  0.00  0.00  0.00\n       row4  0.15  0.64  0.00  0.00  0.00  0.00  0.00  0.24  0.00  0.00  0.00  0.00\n  key1 row0  0.00  0.00  0.00  0.77  0.00  0.00  0.00  0.00  0.00  0.81  0.00  0.65\n       row2  0.35  0.00  0.00  0.00  0.00  0.44  0.00  0.00  0.00  0.00  0.00  0.13\n       row3  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.28  0.00\n       row4  0.00  0.00  0.00  0.00  0.10  0.00  0.00  0.00  0.00  0.00  0.00  0.00\n  key2 row0  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.40  0.00  0.00\n       row2  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.13  0.00  0.00  0.00\n       row4  0.00  0.00  0.00  0.00  0.00  0.64  0.88  0.00  0.00  0.00  0.00  0.00\n \n \n pd.DataFrame.groupby \n   df.groupby(\n      ['key', 'row', 'item', 'col']\n  )['val0'].mean().unstack(['item', 'col']).fillna(0).sort_index(1)\n \n \n pd.DataFrame.set_index  because the set of keys are unique for both rows and columns \n   df.set_index(\n      ['key', 'row', 'item', 'col']\n  )['val0'].unstack(['item', 'col']).fillna(0).sort_index(1)\n \n \n \n \n Question 9 \n \n Can I aggregate the frequency in which the column and rows occur together, aka \"cross tabulation\"? \n \n \n pd.DataFrame.pivot_table \n   df.pivot_table(index='row', columns='col', fill_value=0, aggfunc='size')\n\n      col   col0  col1  col2  col3  col4\n  row\n  row0     1     2     0     1     1\n  row2     1     0     2     1     2\n  row3     0     1     0     2     0\n  row4     0     1     2     2     1\n \n \n pd.DataFrame.groupby \n   df.groupby(['row', 'col'])['val0'].size().unstack(fill_value=0)\n \n \n pd.crosstab \n   pd.crosstab(df['row'], df['col'])\n \n \n pd.factorize  +  np.bincount \n   # get integer factorization `i` and unique values `r`\n  # for column `'row'`\n  i, r = pd.factorize(df['row'].values)\n  # get integer factorization `j` and unique values `c`\n  # for column `'col'`\n  j, c = pd.factorize(df['col'].values)\n  # `n` will be the number of rows\n  # `m` will be the number of columns\n  n, m = r.size, c.size\n  # `i * m + j` is a clever way of counting the\n  # factorization bins assuming a flat array of length\n  # `n * m`.  Which is why we subsequently reshape as `(n, m)`\n  b = np.bincount(i * m + j, minlength=n * m).reshape(n, m)\n  # BTW, whenever I read this, I think 'Bean, Rice, and Cheese'\n  pd.DataFrame(b, r, c)\n\n        col3  col2  col0  col1  col4\n  row3     2     0     0     1     0\n  row2     1     2     1     0     2\n  row0     1     0     1     2     1\n  row4     2     2     0     1     1\n \n \n pd.get_dummies \n   pd.get_dummies(df['row']).T.dot(pd.get_dummies(df['col']))\n\n        col0  col1  col2  col3  col4\n  row0     1     2     0     1     1\n  row2     1     0     2     1     2\n  row3     0     1     0     2     0\n  row4     0     1     2     2     1\n \n \n \n \n Question 10 \n \n How do I convert a DataFrame from long to wide by pivoting on ONLY two\ncolumns? \n \n \n DataFrame.pivot \n The first step is to assign a number to each row - this number will be the row index of that value in the pivoted result. This is done using  GroupBy.cumcount : \n   df2.insert(0, 'count', df2.groupby('A').cumcount())\n  df2\n\n     count  A   B\n  0      0  a   0\n  1      1  a  11\n  2      2  a   2\n  3      3  a  11\n  4      0  b  10\n  5      1  b  10\n  6      2  b  14\n  7      0  c   7\n \n The second step is to use the newly created column as the index to call  DataFrame.pivot . \n   df2.pivot(*df2)\n  # df2.pivot(index='count', columns='A', values='B')\n\n  A         a     b    c\n  count\n  0       0.0  10.0  7.0\n  1      11.0  10.0  NaN\n  2       2.0  14.0  NaN\n  3      11.0   NaN  NaN\n \n \n DataFrame.pivot_table \n Whereas  DataFrame.pivot  only accepts columns,  DataFrame.pivot_table  also accepts arrays, so the  GroupBy.cumcount  can be passed directly as the  index  without creating an explicit column. \n   df2.pivot_table(index=df2.groupby('A').cumcount(), columns='A', values='B')\n\n  A         a     b    c\n  0       0.0  10.0  7.0\n  1      11.0  10.0  NaN\n  2       2.0  14.0  NaN\n  3      11.0   NaN  NaN\n \n \n \n \n Question 11 \n \n How do I flatten the multiple index to single index after  pivot \n \n If  columns  type  object  with string  join \n df.columns = df.columns.map('|'.join)\n \n else  format \n df.columns = df.columns.map('{0[0]}|{0[1]}'.format)\n \n    ", "date_posted": "2021-08-07 11:42:55Z", "upvote": "\r\n            415\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "13138364", "name": "tdy", "reputation_score": "28.3k"}, "answer_comments": [{"stack_answer_id": "47152692", "stack_answer_comment_id": "82623451", "comment_content": "Could you please consider extending ", "user_id": null}, {"stack_answer_id": "47152692", "stack_answer_comment_id": "102665493", "comment_content": "what happened with the answer to Question #10? I get ", "user_id": null}, {"stack_answer_id": "47152692", "stack_answer_comment_id": "107880395", "comment_content": "it is not necessary to insert the column in question 10, it can be passed directly as an argument in the pivot table", "user_id": null}, {"stack_answer_id": "47152692", "stack_answer_comment_id": "108269681", "comment_content": "@MonicaHeddneck I believe the references to ", "user_id": null}, {"stack_answer_id": "47152692", "stack_answer_comment_id": "124327698", "comment_content": "When I would want to pivot a DataFrame, my first question would not be \"Why do I get some error\", but rather: given some input and some desired pivoted output, what function do I need to call and which parameters do I need to pass to get that output? If you already know it's called \"pivot\", that probably isn't too difficult to figure out, but a basic example can still help and perhaps the bigger problem is when questions that just ask ", "user_id": null}]}, {"stack_answer_id": "62219652", "answer_content": "\r\n To extend  @piRSquared's answer  another version of  Question 10 \n\n Question 10.1 \n\n DataFrame: \n\n d = data = {'A': {0: 1, 1: 1, 2: 1, 3: 2, 4: 2, 5: 3, 6: 5},\n 'B': {0: 'a', 1: 'b', 2: 'c', 3: 'a', 4: 'b', 5: 'a', 6: 'c'}}\ndf = pd.DataFrame(d)\n\n   A  B\n0  1  a\n1  1  b\n2  1  c\n3  2  a\n4  2  b\n5  3  a\n6  5  c\n \n\n Output: \n\n    0     1     2\nA\n1  a     b     c\n2  a     b  None\n3  a  None  None\n5  c  None  None\n \n\n \n\n Using  df.groupby  and  pd.Series.tolist \n\n t = df.groupby('A')['B'].apply(list)\nout = pd.DataFrame(t.tolist(),index=t.index)\nout\n   0     1     2\nA\n1  a     b     c\n2  a     b  None\n3  a  None  None\n5  c  None  None\n \n\n Or \nA much better alternative using  pd.pivot_table  with  df.squeeze. \n\n t = df.pivot_table(index='A',values='B',aggfunc=list).squeeze()\nout = pd.DataFrame(t.tolist(),index=t.index)\n \n    ", "date_posted": "2020-06-05 20:59:49Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "12416453", "name": "Ch3steR", "reputation_score": "19.3k"}, "answer_comments": []}, {"stack_answer_id": "66237613", "answer_content": "\r\n To better understand how  pivot  works you can look at the  example  from Pandas documentation: \n \n df = pd.DataFrame({\n    'foo': ['one', 'one', 'one', 'two', 'two', 'two'],\n    'bar': ['A', 'B', 'C', 'A', 'B', 'C'],\n    'baz': [1, 2, 3, 4, 5, 6],\n    'zoo': ['x', 'y', 'z', 'q', 'w', 't']\n})\n \n Input Table: \n    foo bar  baz zoo\n0  one   A    1   x\n1  one   B    2   y\n2  one   C    3   z\n3  two   A    4   q\n4  two   B    5   w\n5  two   C    6   t\n \n Pivot : \n pd.pivot(\n    data=df,        \n    index='foo',    # Column to use to make new frame\u2019s index. If None, uses existing index.\n    columns='bar',  # Column to use to make new frame\u2019s columns.\n    values='baz'    # Column(s) to use for populating new frame\u2019s values.\n)\n \n Output table: \n bar  A  B  C\nfoo         \none  1  2  3\ntwo  4  5  6\n \n    ", "date_posted": "2021-02-17 07:42:14Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "8973620", "name": "Mykola Zotko", "reputation_score": "12.6k"}, "answer_comments": []}, {"stack_answer_id": "73060100", "answer_content": "\r\n You can use list of column names as  index ,  columns  and  values  arguments. \n rows, cols, vals, aggfuncs = ['row', 'key'], ['col', 'item'], ['val0', 'val1'], ['mean', 'sum']\n\ndf.groupby(rows+cols)[vals].agg(aggfuncs).unstack(cols)\n# equivalently,\ndf.pivot_table(vals, rows, cols, aggfuncs)\n\n\ndf.set_index(rows+cols)[vals].unstack(cols)\n# equivalently, \ndf.pivot(rows, cols, vals)\n \n You can also apply the insight from Question 10 to multi-column pivot operation as well. Simply append the auxiliary index from  groupby().cumcount()  to either  rows  or  cols  depending on how you want your result to be (appending it to  rows  makes the result \"long\", and appending it to  cols  makes it \"wide\"). Additionally, calling  droplevel().reset_index()  fixes the surplus and duplicate index issue. \n # for \"long\" result\ndf.assign(ix=df.groupby(rows+cols).cumcount()).pivot(rows+['ix'], cols, vals).droplevel(-1).reset_index()\n\n# for \"wide\" result\ndf.assign(ix=df.groupby(rows+cols).cumcount()).pivot(rows, cols+['ix'], vals).droplevel(-1, axis=1).reset_index()\n \n For example, the following doesn't work. \n df = pd.DataFrame({'A': [1, 1, 2], 'B': ['a', 'a', 'b'], 'C': range(3)})\ndf.pivot('A','B','C')\n \n But the following work: \n # long\n(\n    df.assign(ix=df.groupby(['A','B']).cumcount())\n    .pivot(['A','ix'], 'B', 'C')\n    .droplevel(-1).reset_index()\n)\n\nB  A    a    b\n0  1  0.0  NaN\n1  1  1.0  NaN\n2  2  NaN  2.0\n\n\n\n# wide\n(\n    df.assign(ix=df.groupby(['A','B']).cumcount())\n    .pivot('A', ['B', 'ix'], 'C')\n    .droplevel(-1, axis=1).reset_index()\n)\n\nB  A    a    a    b\n0  1  0.0  1.0  NaN\n1  2  NaN  NaN  2.0\n \n \n pivot_table()  with  aggfunc  results in aggregated data, which is very similar to a  groupby.agg() .  pivot()  is simply reshaping and/or stacking data (reminiscent of numpy reshape and stack methods), so naturally, it's related to their pandas cousins,  unstack()  and  stack() . \n In fact, if we check the  source code , internally, each method pair are the same. \n \n pivot_table = groupby + unstack \n pivot = set_index + unstack \n crosstab = pivot_table \n \n Using the setup in the OP: \n from numpy.core.defchararray import add\nnp.random.seed([3,1415])\nn = 20\n\ncols = np.array(['key', 'row', 'item', 'col'])\narr1 = (np.random.randint(5, size=(n, 4)) // [2, 1, 2, 1]).astype(str)\n\ndf = pd.DataFrame(add(cols, arr1), columns=cols).join(pd.DataFrame(np.random.rand(n, 2).round(2)).add_prefix('val'))\n\nrows, cols, vals, aggfuncs = ['row', 'key'], ['col', 'val1'], ['val0'], ['mean', 'sum']\n \n \n pivot_table()  aggregates the values and unstacks it. Specifically, it creates a single flat list out of index and columns, calls  groupby()  with this list as the grouper and aggregates using the passed aggregator methods (the default is  mean ). Then after aggregation, it calls  unstack()  by the list of columns. So internally,  pivot_table = groupby + unstack . Moreover, if  fill_value  is passed,  fillna()  is called. \n In other words, the method that produces  pv_1  is the same as the method that produces  gb_1  in the example below. \n \n \n pv_1 = df.pivot_table(index=rows, columns=cols, values=vals, aggfunc=aggfuncs, fill_value=0)\n# internal operation of `pivot_table()`\ngb_1 = df.groupby(rows+cols)[vals].agg(aggfuncs).unstack(cols).fillna(0, downcast=\"infer\")\npv_1.equals(gb_1) # True\n \n \n pivot()  creates a MultiIndex from the column values passed as index and columns, builds a MultiIndex DataFrame and calls  unstack()  by the list of columns. So internally,  pivot = set_index + unstack . \n In other words, all of the following are True: \n \n \n # if the entire df needs to be pivoted\npv_2 = df.pivot(index=rows, columns=cols)\n# internal operation of `pivot()`\nsu_2 = df.set_index(rows+cols).unstack(cols)\npv_2.equals(su_2) # True\n\n# if only subset of df.columns need to be considered for pivot, specify so\npv_3 = df.pivot(index=rows, columns=cols, values=vals)\nsu_3 = df.set_index(rows+cols)[vals].unstack(cols)\npv_3.equals(su_3) # True\n\n# this is the precise method used internally (building a new DF seems to be faster than set_index of an existing one)\npv_4 = df.pivot(index=rows, columns=cols, values=vals)\nsu_4 = pd.DataFrame(df[vals].values, index=pd.MultiIndex.from_arrays([df[c] for c in rows+cols]), columns=vals).unstack(cols)\npv_4.equals(su_4) # True\n \n \n crosstab()  calls  pivot_table() , i.e.,  crosstab = pivot_table . Specifically, it builds a DataFrame out of the passed arrays of values, filters it by the common indices and calls  pivot_table() . It's more limited than  pivot_table()  because it only allows a one-dimensional array-like as  values , unlike  pivot_table()  that can have multiple columns as  values . \n In other words, the following is True. \n \n \n indexes, columns, values = [df[r] for r in rows], [df[c] for c in cols], next(df[v] for v in vals)\n# crosstab\nct_5 = pd.crosstab(indexes, columns, values, aggfunc=aggfuncs)\n# internal operation (abbreviated)\nfrom functools import reduce\ndata = pd.DataFrame({f'row_{i}': r for i, r in enumerate(indexes)} | {f'col_{i}': c for i, c in enumerate(columns)} | {'v': values}, \n                    index = reduce(lambda x, y: x.intersection(y.index), indexes[1:]+columns, indexes[0].index)\n                   )\npv_5 = data.pivot_table('v', [k for k in data if k[:4]=='row_'], [k for k in data if k[:4]=='col_'], aggfuncs)\nct_5.equals(pv_5) # True\n \n    ", "date_posted": "2022-07-21 02:41:29Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "19123103", "name": "not a robot", "reputation_score": "4,023"}, "answer_comments": []}], "user": {"stack_user_id": "2336654", "name": "piRSquared", "reputation_score": "270k"}, "question_comments": []},
{"stack_question_id": "2612802", "question_title": "How do I clone a list so that it doesn't change unexpectedly after assignment?", "question_content": "\r\n                While using new_list = my_list, any modifications to new_list changes my_list every time. Why is this, and how can I clone or copy the list to prevent it?\r\n", "question_url": "/questions/2612802/how-do-i-clone-a-list-so-that-it-doesnt-change-unexpectedly-after-assignment", "date_posted": "Apr 10, 2010 at 8:49", "upvote": "3", "view": "2", "tags": ["python", "list", "reference", "copy", "clone"], "answers_count": "2", "answers": [{"stack_answer_id": "2612815", "answer_content": "\r\n new_list = my_list  doesn't actually create a second list. The assignment just copies the reference to the list, not the actual list, so both  new_list  and  my_list  refer to the same list after the assignment. \n To actually copy the list, you have several options: \n \n You can use the builtin  list.copy()  method (available since Python 3.3): \n new_list = old_list.copy()\n \n \n You can slice it: \n new_list = old_list[:]\n \n Alex Martelli 's opinion (at least  back in 2007 ) about this is, that  it is a weird syntax and it does not make sense to use it ever . ;) (In his opinion, the next one is more readable). \n \n You can use the built in  list()  constructor: \n new_list = list(old_list)\n \n \n You can use generic  copy.copy() : \n import copy\nnew_list = copy.copy(old_list)\n \n This is a little slower than  list()  because it has to find out the datatype of  old_list  first. \n \n If you need to copy the elements of the list as well, use generic  copy.deepcopy() : \n import copy\nnew_list = copy.deepcopy(old_list)\n \n Obviously the slowest and most memory-needing method, but sometimes unavoidable. This operates recursively; it will handle any number of levels of nested lists (or other containers). \n \n \n Example: \n import copy\n\nclass Foo(object):\n    def __init__(self, val):\n         self.val = val\n\n    def __repr__(self):\n        return f'Foo({self.val!r})'\n\nfoo = Foo(1)\n\na = ['foo', foo]\nb = a.copy()\nc = a[:]\nd = list(a)\ne = copy.copy(a)\nf = copy.deepcopy(a)\n\n# edit orignal list and instance \na.append('baz')\nfoo.val = 5\n\nprint(f'original: {a}\\nlist.copy(): {b}\\nslice: {c}\\nlist(): {d}\\ncopy: {e}\\ndeepcopy: {f}')\n \n Result: \n original: ['foo', Foo(5), 'baz']\nlist.copy(): ['foo', Foo(5)]\nslice: ['foo', Foo(5)]\nlist(): ['foo', Foo(5)]\ncopy: ['foo', Foo(5)]\ndeepcopy: ['foo', Foo(1)]\n \n    ", "date_posted": "2022-08-16 00:48:58Z", "upvote": "\r\n            3875\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "4518341", "name": "wjandrea", "reputation_score": "24.1k"}, "answer_comments": [{"stack_answer_id": "2612815", "stack_answer_comment_id": "115618926", "comment_content": "As @Georgy points out correctly in the answer below, any changes to the new_list values will also change the values in my_list. So actually the copy.deepcopy() method is the only real copy without reference to the original list and it's values.", "user_id": null}, {"stack_answer_id": "2612815", "stack_answer_comment_id": "129567928", "comment_content": "@moojen If ", "user_id": null}, {"stack_answer_id": "2612815", "stack_answer_comment_id": "129602871", "comment_content": "@wjandrea Why copy a list of immutable objects?", "user_id": null}, {"stack_answer_id": "2612815", "stack_answer_comment_id": "129605566", "comment_content": "@moojen Because the list itself is mutable, and a new assignment only creates a reference. E.g. ", "user_id": null}]}, {"stack_answer_id": "2612990", "answer_content": "\r\n Felix already provided an excellent answer, but I thought I'd do a speed comparison of the various methods: \n \n 10.59 sec (105.9 \u00b5s/itn) -   copy.deepcopy(old_list) \n 10.16 sec (101.6 \u00b5s/itn) - pure Python  Copy()  method copying classes with deepcopy \n 1.488 sec (14.88 \u00b5s/itn) - pure Python  Copy()  method not copying classes (only dicts/lists/tuples) \n 0.325 sec (3.25 \u00b5s/itn) -  for item in old_list: new_list.append(item) \n 0.217 sec (2.17 \u00b5s/itn) -  [i for i in old_list]  (a  list comprehension ) \n 0.186 sec (1.86 \u00b5s/itn) -  copy.copy(old_list) \n 0.075 sec (0.75 \u00b5s/itn) -  list(old_list) \n 0.053 sec (0.53 \u00b5s/itn) -  new_list = []; new_list.extend(old_list) \n 0.039 sec (0.39 \u00b5s/itn) -  old_list[:]  ( list slicing ) \n \n So the fastest is list slicing. But be aware that  copy.copy() ,  list[:]  and  list(list) , unlike  copy.deepcopy()  and the python version don't copy any lists, dictionaries and class instances in the list, so if the originals change, they will change in the copied list too and vice versa. \n (Here's the script if anyone's interested or wants to raise any issues:) \n from copy import deepcopy\n\nclass old_class:\n    def __init__(self):\n        self.blah = 'blah'\n\nclass new_class(object):\n    def __init__(self):\n        self.blah = 'blah'\n\ndignore = {str: None, unicode: None, int: None, type(None): None}\n\ndef Copy(obj, use_deepcopy=True):\n    t = type(obj)\n\n    if t in (list, tuple):\n        if t == tuple:\n            # Convert to a list if a tuple to\n            # allow assigning to when copying\n            is_tuple = True\n            obj = list(obj)\n        else:\n            # Otherwise just do a quick slice copy\n            obj = obj[:]\n            is_tuple = False\n\n        # Copy each item recursively\n        for x in xrange(len(obj)):\n            if type(obj[x]) in dignore:\n                continue\n            obj[x] = Copy(obj[x], use_deepcopy)\n\n        if is_tuple:\n            # Convert back into a tuple again\n            obj = tuple(obj)\n\n    elif t == dict:\n        # Use the fast shallow dict copy() method and copy any\n        # values which aren't immutable (like lists, dicts etc)\n        obj = obj.copy()\n        for k in obj:\n            if type(obj[k]) in dignore:\n                continue\n            obj[k] = Copy(obj[k], use_deepcopy)\n\n    elif t in dignore:\n        # Numeric or string/unicode?\n        # It's immutable, so ignore it!\n        pass\n\n    elif use_deepcopy:\n        obj = deepcopy(obj)\n    return obj\n\nif __name__ == '__main__':\n    import copy\n    from time import time\n\n    num_times = 100000\n    L = [None, 'blah', 1, 543.4532,\n         ['foo'], ('bar',), {'blah': 'blah'},\n         old_class(), new_class()]\n\n    t = time()\n    for i in xrange(num_times):\n        Copy(L)\n    print 'Custom Copy:', time()-t\n\n    t = time()\n    for i in xrange(num_times):\n        Copy(L, use_deepcopy=False)\n    print 'Custom Copy Only Copying Lists/Tuples/Dicts (no classes):', time()-t\n\n    t = time()\n    for i in xrange(num_times):\n        copy.copy(L)\n    print 'copy.copy:', time()-t\n\n    t = time()\n    for i in xrange(num_times):\n        copy.deepcopy(L)\n    print 'copy.deepcopy:', time()-t\n\n    t = time()\n    for i in xrange(num_times):\n        L[:]\n    print 'list slicing [:]:', time()-t\n\n    t = time()\n    for i in xrange(num_times):\n        list(L)\n    print 'list(L):', time()-t\n\n    t = time()\n    for i in xrange(num_times):\n        [i for i in L]\n    print 'list expression(L):', time()-t\n\n    t = time()\n    for i in xrange(num_times):\n        a = []\n        a.extend(L)\n    print 'list extend:', time()-t\n\n    t = time()\n    for i in xrange(num_times):\n        a = []\n        for y in L:\n            a.append(y)\n    print 'list append:', time()-t\n\n    t = time()\n    for i in xrange(num_times):\n        a = []\n        a.extend(i for i in L)\n    print 'generator expression extend:', time()-t\n \n    ", "date_posted": "2021-05-11 21:36:34Z", "upvote": "\r\n            732\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "2612990", "stack_answer_comment_id": "119115083", "comment_content": "Does it mean that append and list comprehension are the best options?", "user_id": null}, {"stack_answer_id": "2612990", "stack_answer_comment_id": "124242121", "comment_content": "I keep on coming back to this answer to make sure that I am using the most efficient method. What is the easiest way to test this? Or is there a database with all of the best ways to minimise run time?", "user_id": null}, {"stack_answer_id": "2612990", "stack_answer_comment_id": "129567914", "comment_content": "These numbers might be outdated. I tried running ", "user_id": null}]}, {"stack_answer_id": "17810305", "answer_content": "\r\n I've  been told  that Python 3.3+  adds the  list.copy()  method, which should be as fast as slicing: \n newlist = old_list.copy()\n \n    ", "date_posted": "2021-05-11 21:37:30Z", "upvote": "\r\n            178\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "17810305", "stack_answer_comment_id": "91949096", "comment_content": "Yes, and as per docs ", "user_id": null}, {"stack_answer_id": "17810305", "stack_answer_comment_id": "108624099", "comment_content": "Actually it seems that currently, ", "user_id": null}, {"stack_answer_id": "17810305", "stack_answer_comment_id": "115053799", "comment_content": "@loved.by.Jesus: Yeah, they ", "user_id": null}, {"stack_answer_id": "17810305", "stack_answer_comment_id": "115053871", "comment_content": "Of course, they're working on ", "user_id": null}]}, {"stack_answer_id": "26562235", "answer_content": "\r\n \n   What are the options to clone or copy a list in Python? \n \n\n In Python 3, a shallow copy can be made with: \n\n a_copy = a_list.copy()\n \n\n In Python 2 and 3, you can get a shallow copy with a full slice of the original: \n\n a_copy = a_list[:]\n \n\n Explanation \n\n There are two semantic ways to copy a list. A shallow copy creates a new list of the same objects, a deep copy creates a new list containing new equivalent objects. \n\n Shallow list copy \n\n A shallow copy only copies the list itself, which is a container of references to the objects in the list. If the objects contained themselves are mutable and one is changed, the change will be reflected in both lists.  \n\n There are different ways to do this in Python 2 and 3. The Python 2 ways will also work in Python 3. \n\n Python 2 \n\n In Python 2, the idiomatic way of making a shallow copy of a list is with a complete slice of the original: \n\n a_copy = a_list[:]\n \n\n You can also accomplish the same thing by passing the list through the list constructor,  \n\n a_copy = list(a_list)\n \n\n but using the constructor is less efficient: \n\n >>> timeit\n>>> l = range(20)\n>>> min(timeit.repeat(lambda: l[:]))\n0.30504298210144043\n>>> min(timeit.repeat(lambda: list(l)))\n0.40698814392089844\n \n\n Python 3 \n\n In Python 3, lists get the  list.copy  method: \n\n a_copy = a_list.copy()\n \n\n In Python 3.5: \n\n >>> import timeit\n>>> l = list(range(20))\n>>> min(timeit.repeat(lambda: l[:]))\n0.38448613602668047\n>>> min(timeit.repeat(lambda: list(l)))\n0.6309100328944623\n>>> min(timeit.repeat(lambda: l.copy()))\n0.38122922903858125\n \n\n Making another pointer does  not  make a copy \n\n \n   Using new_list = my_list then modifies new_list every time my_list changes. Why is this? \n \n\n my_list  is just a name that points to the actual list in memory. When you say  new_list = my_list  you're not making a copy, you're just adding another name that points at that original list in memory. We can have similar issues when we make copies of lists.  \n\n >>> l = [[], [], []]\n>>> l_copy = l[:]\n>>> l_copy\n[[], [], []]\n>>> l_copy[0].append('foo')\n>>> l_copy\n[['foo'], [], []]\n>>> l\n[['foo'], [], []]\n \n\n The list is just an array of pointers to the contents, so a shallow copy just copies the pointers, and so you have two different lists, but they have the same contents. To make copies of the contents, you need a deep copy. \n\n Deep copies \n\n To make a  deep copy of a list, in Python 2 or 3, use  deepcopy  in the  copy  module : \n\n import copy\na_deep_copy = copy.deepcopy(a_list)\n \n\n To demonstrate how this allows us to make new sub-lists: \n\n >>> import copy\n>>> l\n[['foo'], [], []]\n>>> l_deep_copy = copy.deepcopy(l)\n>>> l_deep_copy[0].pop()\n'foo'\n>>> l_deep_copy\n[[], [], []]\n>>> l\n[['foo'], [], []]\n \n\n And so we see that the deep copied list is an entirely different list from the original. You could roll your own function - but don't. You're likely to create bugs you otherwise wouldn't have by using the standard library's deepcopy function. \n\n Don't use  eval \n\n You may see this used as a way to deepcopy, but don't do it: \n\n problematic_deep_copy = eval(repr(a_list))\n \n\n \n It's dangerous, particularly if you're evaluating something from a source you don't trust. \n It's not reliable, if a subelement you're copying doesn't have a representation that can be eval'd to reproduce an equivalent element. \n It's also less performant.  \n \n\n In 64 bit Python 2.7: \n\n >>> import timeit\n>>> import copy\n>>> l = range(10)\n>>> min(timeit.repeat(lambda: copy.deepcopy(l)))\n27.55826997756958\n>>> min(timeit.repeat(lambda: eval(repr(l))))\n29.04534101486206\n \n\n on 64 bit Python 3.5: \n\n >>> import timeit\n>>> import copy\n>>> l = list(range(10))\n>>> min(timeit.repeat(lambda: copy.deepcopy(l)))\n16.84255409205798\n>>> min(timeit.repeat(lambda: eval(repr(l))))\n34.813894678023644\n \n    ", "date_posted": "2018-01-09 15:33:11Z", "upvote": "\r\n            148\r\n        ", "accepted": "No", "user": {"stack_user_id": "541136", "name": "Russia Must Remove Putin", "reputation_score": "347k"}, "answer_comments": [{"stack_answer_id": "26562235", "stack_answer_comment_id": "95089106", "comment_content": "You don't need a deepcopy if the list is 2D. If it is a list of lists, and those lists don't have lists inside of them, you can use a for loop. Presently, I am using   ", "user_id": null}]}, {"stack_answer_id": "47258728", "answer_content": "\r\n Let's start from the beginning and explore this question. \n So let's suppose you have two lists: \n list_1 = ['01', '98']\nlist_2 = [['01', '98']]\n \n And we have to copy both lists, now starting from the first list: \n So first let's try by setting the variable  copy  to our original list,  list_1 : \n copy = list_1\n \n Now if you are thinking copy copied the  list_1 , then you are wrong. The  id  function can show us if two variables can point to the same object. Let's try this: \n print(id(copy))\nprint(id(list_1))\n \n The output is: \n 4329485320\n4329485320\n \n Both variables are the exact same argument. Are you surprised? \n So as we know, Python doesn't store anything in a variable, Variables are just referencing to the object and object store the value. Here object is a  list  but we created two references to that same object by two different variable names. This means that both variables are pointing to the same object, just with different names. \n When you do  copy = list_1 , it is actually doing: \n \n Here in the image  list_1  and  copy  are two variable names, but the object is same for both variable which is  list . \n So if you try to modify copied list then it will modify the original list too because the list is only one there, you will modify that list no matter you do from the copied list or from the original list: \n copy[0] = \"modify\"\n\nprint(copy)\nprint(list_1)\n \n Output: \n ['modify', '98']\n['modify', '98']\n \n So it modified the original list: \n Now let's move onto a Pythonic method for copying lists. \n copy_1 = list_1[:]\n \n This method fixes the first issue we had: \n print(id(copy_1))\nprint(id(list_1))\n\n4338792136\n4338791432\n \n So as we can see our both list having different id and it means that both variables are pointing to different objects. So what actually going on here is: \n \n Now let's try to modify the list and let's see if we still face the previous problem: \n copy_1[0] = \"modify\"\n\nprint(list_1)\nprint(copy_1)\n \n The output is: \n ['01', '98']\n['modify', '98']\n \n As you can see, it only modified the copied list. That means it worked. \n Do you think we're done? No. Let's try to copy our nested list. \n copy_2 = list_2[:]\n \n list_2  should reference to another object which is copy of  list_2 . Let's check: \n print(id((list_2)), id(copy_2))\n \n We get the output: \n 4330403592 4330403528\n \n Now we can assume both lists are pointing different object, so now let's try to modify it and let's see it is giving what we want: \n copy_2[0][1] = \"modify\"\n\nprint(list_2, copy_2)\n \n This gives us the output: \n [['01', 'modify']] [['01', 'modify']]\n \n This may seem a little bit confusing, because the same method we previously used worked. Let's try to understand this. \n When you do: \n copy_2 = list_2[:]\n \n You're only copying the outer list, not the inside list. We can use the  id  function once again to check this. \n print(id(copy_2[0]))\nprint(id(list_2[0]))\n \n The output is: \n 4329485832\n4329485832\n \n When we do  copy_2 = list_2[:] , this happens: \n \n It creates the copy of list, but only outer list copy, not the nested list copy. The nested list is same for both variable, so if you try to modify the nested list then it will modify the original list too as the nested list object is same for both lists. \n What is the solution? The solution is the  deepcopy  function. \n from copy import deepcopy\ndeep = deepcopy(list_2)\n \n Let's check this: \n print(id((list_2)), id(deep))\n\n4322146056 4322148040\n \n Both outer lists have different IDs. Let's try this on the inner nested lists. \n print(id(deep[0]))\nprint(id(list_2[0]))\n \n The output is: \n 4322145992\n4322145800\n \n As you can see both IDs are different, meaning we can assume that both nested lists are pointing different object now. \n This means when you do  deep = deepcopy(list_2)  what actually happens: \n \n Both nested lists are pointing different object and they have separate copy of nested list now. \n Now let's try to modify the nested list and see if it solved the previous issue or not: \n deep[0][1] = \"modify\"\nprint(list_2, deep)\n \n It outputs: \n [['01', '98']] [['01', 'modify']]\n \n As you can see, it didn't modify the original nested list, it only modified the copied list. \n    ", "date_posted": "2021-05-11 21:53:58Z", "upvote": "\r\n            71\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "27091494", "answer_content": "\r\n There are many answers already that tell you how to make a proper copy, but none of them say why your original 'copy' failed.  \n\n Python doesn't store values in variables; it binds names to objects. Your original assignment took the object referred to by  my_list  and bound it to  new_list  as well. No matter which name you use there is still only one list, so changes made when referring to it as  my_list  will persist when referring to it as  new_list . Each of the other answers to this question give you different ways of creating a new object to bind to  new_list .  \n\n Each element of a list acts like a name, in that each element binds non-exclusively to an object. A shallow copy creates a new list whose elements bind to the same objects as before. \n\n new_list = list(my_list)  # or my_list[:], but I prefer this syntax\n# is simply a shorter way of:\nnew_list = [element for element in my_list]\n \n\n To take your list copy one step further, copy each object that your list refers to, and bind those element copies to a new list.  \n\n import copy  \n# each element must have __copy__ defined for this...\nnew_list = [copy.copy(element) for element in my_list]\n \n\n This is not yet a deep copy, because each element of a list may refer to other objects, just like the list is bound to its elements. To recursively copy every element in the list, and then each other object referred to by each element, and so on: perform a deep copy.  \n\n import copy\n# each element must have __deepcopy__ defined for this...\nnew_list = copy.deepcopy(my_list)\n \n\n See  the documentation  for more information about corner cases in copying. \n    ", "date_posted": "2020-06-05 16:01:12Z", "upvote": "\r\n            65\r\n        ", "accepted": "No", "user": {"stack_user_id": "894381", "name": "jack", "reputation_score": "1,984"}, "answer_comments": []}, {"stack_answer_id": "2612808", "answer_content": "\r\n Use  thing[:] \n\n >>> a = [1,2]\n>>> b = a[:]\n>>> a += [3]\n>>> a\n[1, 2, 3]\n>>> b\n[1, 2]\n>>> \n \n    ", "date_posted": "2010-04-10 08:53:06Z", "upvote": "\r\n            48\r\n        ", "accepted": "No", "user": {"stack_user_id": "90025", "name": "Paul Tarjan", "reputation_score": "47.3k"}, "answer_comments": []}, {"stack_answer_id": "43220129", "answer_content": "\r\n Python 3.6 Timings \n Here are the timing results using Python 3.6.8. Keep in mind these times are relative to one another, not absolute. \n I stuck to only doing shallow copies, and also added some new methods that weren't possible in Python\u00a02, such as  list.copy()  (the Python\u00a03  slice equivalent ) and two forms of  list unpacking  ( *new_list, = list  and  new_list = [*list] ): \n METHOD                TIME TAKEN\nb = [*a]               2.75180600000021\nb = a * 1              3.50215399999990\nb = a[:]               3.78278899999986  # Python 2 winner (see above)\nb = a.copy()           4.20556500000020  # Python 3 \"slice equivalent\" (see above)\nb = []; b.extend(a)    4.68069800000012\nb = a[0:len(a)]        6.84498999999959\n*b, = a                7.54031799999984\nb = list(a)            7.75815899999997\nb = [i for i in a]    18.4886440000000\nb = copy.copy(a)      18.8254879999999\nb = []\nfor item in a:\n  b.append(item)      35.4729199999997\n \n We can see the Python 2 winner still does well, but doesn't edge out Python 3  list.copy()  by much, especially considering the superior readability of the latter. \n The dark horse is the unpacking and repacking method ( b = [*a] ), which is ~25% faster than raw slicing, and more than twice as fast as the other unpacking method ( *b, = a ). \n b = a * 1  also does surprisingly well. \n Note that these methods do  not  output equivalent results for any input other than lists.  They all work for sliceable objects, a few work for any iterable, but only  copy.copy()  works for more general Python objects. \n \n Here is the testing code for interested parties ( Template from here ): \n import timeit\n\nCOUNT = 50000000\nprint(\"Array duplicating. Tests run\", COUNT, \"times\")\nsetup = 'a = [0,1,2,3,4,5,6,7,8,9]; import copy'\n\nprint(\"b = list(a)\\t\\t\", timeit.timeit(stmt='b = list(a)', setup=setup, number=COUNT))\nprint(\"b = copy.copy(a)\\t\", timeit.timeit(stmt='b = copy.copy(a)', setup=setup, number=COUNT))\nprint(\"b = a.copy()\\t\\t\", timeit.timeit(stmt='b = a.copy()', setup=setup, number=COUNT))\nprint(\"b = a[:]\\t\\t\", timeit.timeit(stmt='b = a[:]', setup=setup, number=COUNT))\nprint(\"b = a[0:len(a)]\\t\\t\", timeit.timeit(stmt='b = a[0:len(a)]', setup=setup, number=COUNT))\nprint(\"*b, = a\\t\\t\\t\", timeit.timeit(stmt='*b, = a', setup=setup, number=COUNT))\nprint(\"b = []; b.extend(a)\\t\", timeit.timeit(stmt='b = []; b.extend(a)', setup=setup, number=COUNT))\nprint(\"b = []; for item in a: b.append(item)\\t\", timeit.timeit(stmt='b = []\\nfor item in a:  b.append(item)', setup=setup, number=COUNT))\nprint(\"b = [i for i in a]\\t\", timeit.timeit(stmt='b = [i for i in a]', setup=setup, number=COUNT))\nprint(\"b = [*a]\\t\\t\", timeit.timeit(stmt='b = [*a]', setup=setup, number=COUNT))\nprint(\"b = a * 1\\t\\t\", timeit.timeit(stmt='b = a * 1', setup=setup, number=COUNT))\n \n    ", "date_posted": "2021-05-11 21:40:12Z", "upvote": "\r\n            42\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "43220129", "stack_answer_comment_id": "106994593", "comment_content": "Can confirm still a similar story on 3.8 ", "user_id": null}, {"stack_answer_id": "43220129", "stack_answer_comment_id": "114824554", "comment_content": "Some of these timing comparisons aren't particularly meaningful when copying such tiny lists. It would be more informative to test with a range of list lengths (including some very large ones).", "user_id": null}, {"stack_answer_id": "43220129", "stack_answer_comment_id": "119298412", "comment_content": "The timing numbers ought to rounded to the appropriate number of significant digits. 15 significant digits do not make any sense.", "user_id": null}, {"stack_answer_id": "43220129", "stack_answer_comment_id": "119447900", "comment_content": "I've essentially just pasted the raw output of the timing code here. Seems like your gripe is more about how ", "user_id": null}, {"stack_answer_id": "43220129", "stack_answer_comment_id": "128722434", "comment_content": "Is the ", "user_id": null}]}, {"stack_answer_id": "2612810", "answer_content": "\r\n Python's idiom for doing this is  newList = oldList[:] \n    ", "date_posted": "2010-04-10 08:53:19Z", "upvote": "\r\n            36\r\n        ", "accepted": "No", "user": {"stack_user_id": "260584", "name": "erisco", "reputation_score": "13.9k"}, "answer_comments": []}, {"stack_answer_id": "31332158", "answer_content": "\r\n All of the other contributors gave  great  answers, which work when you have a single dimension (leveled) list, however of the methods mentioned so far, only  copy.deepcopy()  works to clone/copy a list and not have it point to the nested  list  objects when you are working with multidimensional, nested lists (list of lists). While  Felix Kling  refers to it in his answer, there is a little bit more to the issue and possibly a workaround using built-ins that might prove a faster alternative to  deepcopy . \n While  new_list = old_list[:] ,  copy.copy(old_list)'  and for Py3k  old_list.copy()  work for single-leveled lists, they revert to pointing at the  list  objects nested within the  old_list  and the  new_list , and changes to one of the  list  objects are perpetuated in the other. \n Edit: New information brought to light \n \n As was pointed out by both  Aaron Hall  and  PM 2Ring   using  eval()  is not only a bad idea, it is also much slower than  copy.deepcopy() . \n This means that for multidimensional lists, the only option is  copy.deepcopy() . With that being said, it really isn't an option as the performance goes way south when you try to use it on a moderately sized multidimensional array.  I tried to  timeit  using a 42x42 array, not unheard of or even that large for bioinformatics applications, and I gave up on waiting for a response and just started typing my edit to this post. \n It would seem that the only real option then is to initialize multiple lists and work on them independently. If anyone has any other suggestions, for how to handle multidimensional list copying, it would be appreciated. \n \n As others have stated, there   are significant  performance issues using the  copy  module and  copy.deepcopy   for multidimensional lists . \n    ", "date_posted": "2020-06-20 09:12:55Z", "upvote": "\r\n            21\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": [{"stack_answer_id": "31332158", "stack_answer_comment_id": "50671649", "comment_content": "This won't always work, since there's no guarantee that the string returned by ", "user_id": null}, {"stack_answer_id": "31332158", "stack_answer_comment_id": "50675773", "comment_content": "Fair point. Though I think that Batchelder's point is that the having the ", "user_id": null}, {"stack_answer_id": "31332158", "stack_answer_comment_id": "50676956", "comment_content": "As @AaronHall has pointed out, there is likely a significant performance issue to using ", "user_id": null}]}, {"stack_answer_id": "48980683", "answer_content": "\r\n It surprises me that this hasn't been mentioned yet, so for the sake of completeness... \n\n You can perform list unpacking with the \"splat operator\":  * , which will also copy elements of your list. \n\n old_list = [1, 2, 3]\n\nnew_list = [*old_list]\n\nnew_list.append(4)\nold_list == [1, 2, 3]\nnew_list == [1, 2, 3, 4]\n \n\n The obvious downside to this method is that it is only available in Python 3.5+. \n\n Timing wise though, this appears to perform better than other common methods. \n\n x = [random.random() for _ in range(1000)]\n\n%timeit a = list(x)\n%timeit a = x.copy()\n%timeit a = x[:]\n\n%timeit a = [*x]\n\n#: 2.47 \u00b5s \u00b1 38.1 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n#: 2.47 \u00b5s \u00b1 54.6 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n#: 2.39 \u00b5s \u00b1 58.2 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n\n#: 2.22 \u00b5s \u00b1 43.2 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n \n    ", "date_posted": "2018-02-26 02:33:47Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "1112586", "name": "SCB", "reputation_score": "5,501"}, "answer_comments": [{"stack_answer_id": "48980683", "stack_answer_comment_id": "91902477", "comment_content": "How does this method behave when modifying copies?", "user_id": null}, {"stack_answer_id": "48980683", "stack_answer_comment_id": "91940819", "comment_content": "@not2qubit do you mean appending to or editing elements of the new list. In the example ", "user_id": null}]}, {"stack_answer_id": "44768652", "answer_content": "\r\n new_list = my_list[:]\n \n new_list = my_list \n Try to understand this. Let's say that  my_list  is in the heap memory at location X, i.e.,  my_list  is pointing to the X. Now by assigning  new_list = my_list  you're letting  new_list  point to the X. This is known as a  shallow copy . \n Now if you assign  new_list = my_list[:] , you're simply copying each object of  my_list  to  new_list . This is known as a  deep copy . \n The  other  ways you can do this are: \n \n \n new_list = list(old_list)\n \n \n \n import copy\nnew_list = copy.deepcopy(old_list)\n \n \n \n    ", "date_posted": "2021-11-19 17:44:52Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "1871033", "name": "CherryDT", "reputation_score": "21.9k"}, "answer_comments": [{"stack_answer_id": "44768652", "stack_answer_comment_id": "125710533", "comment_content": "Technically, ", "user_id": null}]}, {"stack_answer_id": "47050612", "answer_content": "\r\n A very simple approach independent of python version was missing in already-given answers which you can use most of the time (at least I do): \n new_list = my_list * 1       # Solution 1 when you are not using nested lists\n \n However,  if   my_list  contains other containers (for example, nested lists) you must use  deepcopy  as others suggested in the answers above from the copy library. For example: \n import copy\nnew_list = copy.deepcopy(my_list)   # Solution 2 when you are using nested lists\n \n . Bonus : If you don't want to copy elements use (AKA shallow copy): \n new_list = my_list[:]\n \n \n Let's understand difference between solution #1 and solution #2 \n >>> a = range(5)\n>>> b = a*1\n>>> a,b\n([0, 1, 2, 3, 4], [0, 1, 2, 3, 4])\n>>> a[2] = 55\n>>> a,b\n([0, 1, 55, 3, 4], [0, 1, 2, 3, 4])\n \n As you can see, solution #1 worked perfectly when we were not using the nested lists. Let's check what will happen when we apply solution #1 to nested lists. \n >>> from copy import deepcopy\n>>> a = [range(i,i+4) for i in range(3)]\n>>> a\n[[0, 1, 2, 3], [1, 2, 3, 4], [2, 3, 4, 5]]\n>>> b = a*1\n>>> c = deepcopy(a)\n>>> for i in (a, b, c): print i\n[[0, 1, 2, 3], [1, 2, 3, 4], [2, 3, 4, 5]]\n[[0, 1, 2, 3], [1, 2, 3, 4], [2, 3, 4, 5]]\n[[0, 1, 2, 3], [1, 2, 3, 4], [2, 3, 4, 5]]\n>>> a[2].append('99')\n>>> for i in (a, b, c): print i\n[[0, 1, 2, 3], [1, 2, 3, 4], [2, 3, 4, 5, 99]]\n[[0, 1, 2, 3], [1, 2, 3, 4], [2, 3, 4, 5, 99]]   # Solution #1 didn't work in nested list\n[[0, 1, 2, 3], [1, 2, 3, 4], [2, 3, 4, 5]]       # Solution #2 - DeepCopy worked in nested list\n \n    ", "date_posted": "2021-05-11 21:48:59Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "57838754", "answer_content": "\r\n I wanted to post something a bit different than some of the other answers. Even though this is most likely not the most understandable, or fastest option, it provides a bit of an inside view of how deep copy works, as well as being another alternative option for deep copying. It doesn't really matter if my function has bugs, since the point of this is to show a way to copy objects like the question answers, but also to use this as a point to explain how deepcopy works at its core. \n At the core of any deep copy function is way to make a shallow copy. How? Simple. Any deep copy function only duplicates the containers of immutable objects. When you deepcopy a nested list, you are only duplicating the outer lists, not the mutable objects inside of the lists. You are only duplicating the containers. The same works for classes, too. When you deepcopy a class, you deepcopy all of its mutable attributes. So, how? How come you only have to copy the containers, like lists, dicts, tuples, iters, classes, and class instances? \n It's simple. A mutable object can't really be duplicated. It can never be changed, so it is only a single value. That means you never have to duplicate strings, numbers, bools, or any of those. But how would you duplicate the containers? Simple. You make just initialize a new container with all of the values. Deepcopy relies on recursion. It duplicates all the containers, even ones with containers inside of them, until no containers are left. A container is an immutable object. \n Once you know that, completely duplicating an object without any references is pretty easy. Here's a function for deepcopying basic data-types (wouldn't work for custom classes but you could always add that) \n def deepcopy(x):\n  immutables = (str, int, bool, float)\n  mutables = (list, dict, tuple)\n  if isinstance(x, immutables):\n    return x\n  elif isinstance(x, mutables):\n    if isinstance(x, tuple):\n      return tuple(deepcopy(list(x)))\n    elif isinstance(x, list):\n      return [deepcopy(y) for y in x]\n    elif isinstance(x, dict):\n      values = [deepcopy(y) for y in list(x.values())]\n      keys = list(x.keys())\n      return dict(zip(keys, values))\n \n Python's own built-in deepcopy is based around that example. The only difference is it supports other types, and also supports user-classes by duplicating the attributes into a new duplicate class, and also blocks infinite-recursion with a reference to an object it's already seen using a memo list or dictionary. And that's really it for making deep copies. At its core, making a deep copy is just making shallow copies. I hope this answer adds something to the question. \n EXAMPLES \n Say you have this list:  [1, 2, 3] . The immutable numbers cannot be duplicated, but the other layer can. You can duplicate it using a list comprehension:  [x for x in [1, 2, 3]] \n Now, imagine you have this list:  [[1, 2], [3, 4], [5, 6]] . This time, you want to make a function, which uses recursion to deep copy all layers of the list. Instead of the previous list comprehension: \n [x for x in _list]\n \n It uses a new one for lists: \n [deepcopy_list(x) for x in _list]\n \n And  deepcopy_list  looks like this: \n def deepcopy_list(x):\n  if isinstance(x, (str, bool, float, int)):\n    return x\n  else:\n    return [deepcopy_list(y) for y in x]\n \n Then now you have a function which can deepcopy any list of  strs, bools, floast, ints  and even  lists  to infinitely many layers using recursion. And there you have it, deepcopying. \n TLDR : Deepcopy uses recursion to duplicate objects, and merely returns the same immutable objects as before, as immutable objects cannot be duplicated. However, it deepcopies the most inner layers of mutable objects until it reaches the outermost mutable layer of an object. \n    ", "date_posted": "2021-08-26 16:10:55Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "11741338", "name": "Corman", "reputation_score": "669"}, "answer_comments": []}, {"stack_answer_id": "50373643", "answer_content": "\r\n Note that there are some cases where if you have defined your own custom class and you want to keep the attributes then you should use  copy.copy()  or  copy.deepcopy()  rather than the alternatives, for example in Python 3: \n\n import copy\n\nclass MyList(list):\n    pass\n\nlst = MyList([1,2,3])\n\nlst.name = 'custom list'\n\nd = {\n'original': lst,\n'slicecopy' : lst[:],\n'lstcopy' : lst.copy(),\n'copycopy': copy.copy(lst),\n'deepcopy': copy.deepcopy(lst)\n}\n\n\nfor k,v in d.items():\n    print('lst: {}'.format(k), end=', ')\n    try:\n        name = v.name\n    except AttributeError:\n        name = 'NA'\n    print('name: {}'.format(name))\n \n\n Outputs: \n\n lst: original, name: custom list\nlst: slicecopy, name: NA\nlst: lstcopy, name: NA\nlst: copycopy, name: custom list\nlst: deepcopy, name: custom list\n \n    ", "date_posted": "2018-05-16 14:31:22Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "6260170", "name": "Chris_Rands", "reputation_score": "35.9k"}, "answer_comments": []}, {"stack_answer_id": "60352267", "answer_content": "\r\n Remember that in Python when you do: \n\n     list1 = ['apples','bananas','pineapples']\n    list2 = list1\n \n\n List2 isn't storing the actual list, but a reference to list1. So when you do anything to list1, list2 changes as well. use the copy module (not default, download on pip) to make an original copy of the list( copy.copy()  for simple lists,  copy.deepcopy()  for nested ones). This makes a copy that doesn't change with the first list. \n    ", "date_posted": "2020-02-22 12:44:40Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "12908850", "name": "Dr. Hippo", "reputation_score": "61"}, "answer_comments": []}, {"stack_answer_id": "59011118", "answer_content": "\r\n A slight practical perspective to look into memory through id and gc.  \n\n >>> b = a = ['hell', 'word']\n>>> c = ['hell', 'word']\n\n>>> id(a), id(b), id(c)\n(4424020872, 4424020872, 4423979272) \n     |           |\n      -----------\n\n>>> id(a[0]), id(b[0]), id(c[0])\n(4424018328, 4424018328, 4424018328) # all referring to same 'hell'\n     |           |           |\n      -----------------------\n\n>>> id(a[0][0]), id(b[0][0]), id(c[0][0])\n(4422785208, 4422785208, 4422785208) # all referring to same 'h'\n     |           |           |\n      -----------------------\n\n>>> a[0] += 'o'\n>>> a,b,c\n(['hello', 'word'], ['hello', 'word'], ['hell', 'word'])  # b changed too\n>>> id(a[0]), id(b[0]), id(c[0])\n(4424018384, 4424018384, 4424018328) # augmented assignment changed a[0],b[0]\n     |           |\n      -----------\n\n>>> b = a = ['hell', 'word']\n>>> id(a[0]), id(b[0]), id(c[0])\n(4424018328, 4424018328, 4424018328) # the same hell\n     |           |           |\n      -----------------------\n\n>>> import gc\n>>> gc.get_referrers(a[0]) \n[['hell', 'word'], ['hell', 'word']]  # one copy belong to a,b, the another for c\n>>> gc.get_referrers(('hell'))\n[['hell', 'word'], ['hell', 'word'], ('hell', None)] # ('hello', None) \n \n    ", "date_posted": "2019-11-23 19:01:46Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "1953475", "name": "B.Mr.W.", "reputation_score": "17.9k"}, "answer_comments": []}, {"stack_answer_id": "62716254", "answer_content": "\r\n There is another way of copying a list that was not listed until now: adding an empty list:  l2 = l + [] . \n I tested it with Python 3.8: \n l = [1,2,3]\nl2 = l + []\nprint(l,l2)\nl[0] = 'a'\nprint(l,l2)\n \n It is not the best answer, but it works. \n    ", "date_posted": "2021-11-19 23:13:45Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "6296561", "name": "Zoe stands with Ukraine", "reputation_score": "25.5k"}, "answer_comments": [{"stack_answer_id": "62716254", "stack_answer_comment_id": "128722772", "comment_content": "This works and, in my testing, is as fast as the fastest options for longer lists, and only slightly worse than ", "user_id": null}]}, {"stack_answer_id": "61155939", "answer_content": "\r\n The deepcopy option is the only method that works for me: \n\n from copy import deepcopy\n\na = [   [ list(range(1, 3)) for i in range(3) ]   ]\nb = deepcopy(a)\nb[0][1]=[3]\nprint('Deep:')\nprint(a)\nprint(b)\nprint('-----------------------------')\na = [   [ list(range(1, 3)) for i in range(3) ]   ]\nb = a*1\nb[0][1]=[3]\nprint('*1:')\nprint(a)\nprint(b)\nprint('-----------------------------')\na = [   [ list(range(1, 3)) for i in range(3) ] ]\nb = a[:]\nb[0][1]=[3]\nprint('Vector copy:')\nprint(a)\nprint(b)\nprint('-----------------------------')\na = [   [ list(range(1, 3)) for i in range(3) ]  ]\nb = list(a)\nb[0][1]=[3]\nprint('List copy:')\nprint(a)\nprint(b)\nprint('-----------------------------')\na = [   [ list(range(1, 3)) for i in range(3) ]  ]\nb = a.copy()\nb[0][1]=[3]\nprint('.copy():')\nprint(a)\nprint(b)\nprint('-----------------------------')\na = [   [ list(range(1, 3)) for i in range(3) ]  ]\nb = a\nb[0][1]=[3]\nprint('Shallow:')\nprint(a)\nprint(b)\nprint('-----------------------------')\n \n\n leads to output of: \n\n Deep:\n[[[1, 2], [1, 2], [1, 2]]]\n[[[1, 2], [3], [1, 2]]]\n-----------------------------\n*1:\n[[[1, 2], [3], [1, 2]]]\n[[[1, 2], [3], [1, 2]]]\n-----------------------------\nVector copy:\n[[[1, 2], [3], [1, 2]]]\n[[[1, 2], [3], [1, 2]]]\n-----------------------------\nList copy:\n[[[1, 2], [3], [1, 2]]]\n[[[1, 2], [3], [1, 2]]]\n-----------------------------\n.copy():\n[[[1, 2], [3], [1, 2]]]\n[[[1, 2], [3], [1, 2]]]\n-----------------------------\nShallow:\n[[[1, 2], [3], [1, 2]]]\n[[[1, 2], [3], [1, 2]]]\n-----------------------------\n \n    ", "date_posted": "2020-04-11 11:19:40Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "662770", "name": "shahar_m", "reputation_score": "3,236"}, "answer_comments": [{"stack_answer_id": "61155939", "stack_answer_comment_id": "114764971", "comment_content": "deepcopy must be used only when needed and one should be aware of what it really does.", "user_id": null}]}, {"stack_answer_id": "62192645", "answer_content": "\r\n This is because, the line  new_list = my_list  assigns a new reference to the variable  my_list  which is  new_list \nThis is similar to the  C  code given below, \n\n int my_list[] = [1,2,3,4];\nint *new_list;\nnew_list = my_list;\n \n\n You should use the copy module to create a new list by \n\n import copy\nnew_list = copy.deepcopy(my_list)\n \n    ", "date_posted": "2020-06-04 10:40:28Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "13328195", "name": "Roshin Raphel", "reputation_score": "2,506"}, "answer_comments": []}, {"stack_answer_id": "65972710", "answer_content": "\r\n The method to use depends on the contents of the list being copied. If the list contains nested  dicts  than deepcopy is the only method that works, otherwise most of the methods listed in the answers (slice, loop [for], copy, extend, combine, or unpack) will work and execute in similar time (except for loop and deepcopy, which preformed the worst). \n Script \n from random import randint\nfrom time import time\nimport copy\n\nitem_count = 100000\n\ndef copy_type(l1: list, l2: list):\n  if l1 == l2:\n    return 'shallow'\n  return 'deep'\n\ndef run_time(start, end):\n  run = end - start\n  return int(run * 1000000)\n\ndef list_combine(data):\n  l1 = [data for i in range(item_count)]\n  start = time()\n  l2 = [] + l1\n  end = time()\n  if type(data) == dict:\n    l2[0]['test'].append(1)\n  elif type(data) == list:\n    l2.append(1)\n  return {'method': 'combine', 'copy_type': copy_type(l1, l2), \n          'time_\u00b5s': run_time(start, end)}\n\ndef list_extend(data):\n  l1 = [data for i in range(item_count)]\n  start = time()\n  l2 = []\n  l2.extend(l1)\n  end = time()\n  if type(data) == dict:\n    l2[0]['test'].append(1)\n  elif type(data) == list:\n    l2.append(1)\n  return {'method': 'extend', 'copy_type': copy_type(l1, l2), \n          'time_\u00b5s': run_time(start, end)}\n\ndef list_unpack(data):\n  l1 = [data for i in range(item_count)]\n  start = time()\n  l2 = [*l1]\n  end = time()\n  if type(data) == dict:\n    l2[0]['test'].append(1)\n  elif type(data) == list:\n    l2.append(1)\n  return {'method': 'unpack', 'copy_type': copy_type(l1, l2), \n          'time_\u00b5s': run_time(start, end)}\n\ndef list_deepcopy(data):\n  l1 = [data for i in range(item_count)]\n  start = time()\n  l2 = copy.deepcopy(l1)\n  end = time()\n  if type(data) == dict:\n    l2[0]['test'].append(1)\n  elif type(data) == list:\n    l2.append(1)\n  return {'method': 'deepcopy', 'copy_type': copy_type(l1, l2), \n          'time_\u00b5s': run_time(start, end)}\n\ndef list_copy(data):\n  l1 = [data for i in range(item_count)]\n  start = time()\n  l2 = list.copy(l1)\n  end = time()\n  if type(data) == dict:\n    l2[0]['test'].append(1)\n  elif type(data) == list:\n    l2.append(1)\n  return {'method': 'copy', 'copy_type': copy_type(l1, l2), \n          'time_\u00b5s': run_time(start, end)}\n\ndef list_slice(data):\n  l1 = [data for i in range(item_count)]\n  start = time()\n  l2 = l1[:]\n  end = time()\n  if type(data) == dict:\n    l2[0]['test'].append(1)\n  elif type(data) == list:\n    l2.append(1)\n  return {'method': 'slice', 'copy_type': copy_type(l1, l2), \n          'time_\u00b5s': run_time(start, end)}\n\ndef list_loop(data):\n  l1 = [data for i in range(item_count)]\n  start = time()\n  l2 = []\n  for i in range(len(l1)):\n    l2.append(l1[i])\n  end = time()\n  if type(data) == dict:\n    l2[0]['test'].append(1)\n  elif type(data) == list:\n    l2.append(1)\n  return {'method': 'loop', 'copy_type': copy_type(l1, l2), \n          'time_\u00b5s': run_time(start, end)}\n\ndef list_list(data):\n  l1 = [data for i in range(item_count)]\n  start = time()\n  l2 = list(l1)\n  end = time()\n  if type(data) == dict:\n    l2[0]['test'].append(1)\n  elif type(data) == list:\n    l2.append(1)\n  return {'method': 'list()', 'copy_type': copy_type(l1, l2), \n          'time_\u00b5s': run_time(start, end)}\n\nif __name__ == '__main__':\n  list_type = [{'list[dict]': {'test': [1, 1]}}, \n          {'list[list]': [1, 1]}]\n  store = []\n  for data in list_type:\n    key = list(data.keys())[0]\n    store.append({key: [list_unpack(data[key]), list_extend(data[key]), \n                list_combine(data[key]), list_deepcopy(data[key]), \n                list_copy(data[key]), list_slice(data[key]),           \n                list_loop(data[key])]})\n  print(store)\n \n Results \n [{\"list[dict]\": [\n  {\"method\": \"unpack\", \"copy_type\": \"shallow\", \"time_\u00b5s\": 56149},\n  {\"method\": \"extend\", \"copy_type\": \"shallow\", \"time_\u00b5s\": 52991},\n  {\"method\": \"combine\", \"copy_type\": \"shallow\", \"time_\u00b5s\": 53726},\n  {\"method\": \"deepcopy\", \"copy_type\": \"deep\", \"time_\u00b5s\": 2702616},\n  {\"method\": \"copy\", \"copy_type\": \"shallow\", \"time_\u00b5s\": 52204},\n  {\"method\": \"slice\", \"copy_type\": \"shallow\", \"time_\u00b5s\": 52223},\n  {\"method\": \"loop\", \"copy_type\": \"shallow\", \"time_\u00b5s\": 836928}]},\n{\"list[list]\": [\n  {\"method\": \"unpack\", \"copy_type\": \"deep\", \"time_\u00b5s\": 52313},\n  {\"method\": \"extend\", \"copy_type\": \"deep\", \"time_\u00b5s\": 52550},\n  {\"method\": \"combine\", \"copy_type\": \"deep\", \"time_\u00b5s\": 53203},\n  {\"method\": \"deepcopy\", \"copy_type\": \"deep\", \"time_\u00b5s\": 2608560},\n  {\"method\": \"copy\", \"copy_type\": \"deep\", \"time_\u00b5s\": 53210},\n  {\"method\": \"slice\", \"copy_type\": \"deep\", \"time_\u00b5s\": 52937},\n  {\"method\": \"loop\", \"copy_type\": \"deep\", \"time_\u00b5s\": 834774}\n]}]\n \n    ", "date_posted": "2021-01-30 20:17:42Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "10773184", "name": "fjemi", "reputation_score": "11"}, "answer_comments": []}], "user": {"stack_user_id": "187730", "name": "aF.", "reputation_score": "63.1k"}, "question_comments": [{"stack_question_id": "2612802", "stack_question_comment_id": "123683957", "comment_content": " just assigns the name ", "user_id": null}, {"stack_question_id": "2612802", "stack_question_comment_id": "125187420", "comment_content": "See the ", "user_id": null}, {"stack_question_id": "2612802", "stack_question_comment_id": "128071906", "comment_content": "See also: ", "user_id": null}, {"stack_question_id": "2612802", "stack_question_comment_id": "128097571", "comment_content": "Related: ", "user_id": null}]},
{"stack_question_id": "1132941", "question_title": "\"Least Astonishment\" and the Mutable Default Argument", "question_content": "\r\n                Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:\ndef foo(a=[]):\n    a.append(5)\n    return a\n\nPython novices would expect this function called with ...\r\n", "question_url": "/questions/1132941/least-astonishment-and-the-mutable-default-argument", "date_posted": "Jul 15, 2009 at 18:00", "upvote": "3", "view": "2", "tags": ["python", "language-design", "default-parameters", "least-astonishment"], "answers_count": "3", "answers": [{"stack_answer_id": "1145781", "answer_content": "\r\n Actually, this is not a design flaw, and it is not because of internals or performance. It comes simply from the fact that functions in Python are first-class objects, and not only a piece of code. \n As soon as you think of it this way, then it completely makes sense: a function is an object being evaluated on its definition; default parameters are kind of \"member data\" and therefore their state may change from one call to the other - exactly as in any other object. \n In any case, the effbot (Fredrik Lundh) has a very nice explanation of the reasons for this behavior in  Default Parameter Values in Python .\nI found it very clear, and I really suggest reading it for a better knowledge of how function objects work. \n    ", "date_posted": "2022-06-10 08:20:18Z", "upvote": "\r\n            1836\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "355230", "name": "martineau", "reputation_score": "115k"}, "answer_comments": [{"stack_answer_id": "1145781", "stack_answer_comment_id": "9448792", "comment_content": "To anyone reading the above answer, I strongly recommend you take the time to read through the linked Effbot article. As well as all the other useful info, the part on how this language feature can be used for result caching/memoisation is very handy to know!", "user_id": null}, {"stack_answer_id": "1145781", "stack_answer_comment_id": "19820636", "comment_content": "Even if it's a first-class object, one might still envision a design where the ", "user_id": null}, {"stack_answer_id": "1145781", "stack_answer_comment_id": "24551066", "comment_content": "Sorry, but anything considered \"The biggest WTF in Python\" is ", "user_id": null}, {"stack_answer_id": "1145781", "stack_answer_comment_id": "31573411", "comment_content": "Whether or not it's a design flaw, your answer seems to imply that this behaviour is somehow necessary, natural and obvious given that functions are first-class objects, and that simply isn't the case. Python has closures. If you replace the default argument with an assignment on the first line of the function, it evaluates the expression each call (potentially using names declared in an enclosing scope). There is no reason at all that it wouldn't be possible or reasonable to have default arguments evaluated each time the function is called in exactly the same way.", "user_id": null}, {"stack_answer_id": "1145781", "stack_answer_comment_id": "35944779", "comment_content": "The design doesn't directly follow from ", "user_id": null}]}, {"stack_answer_id": "1133013", "answer_content": "\r\n Suppose you have the following code \n fruits = (\"apples\", \"bananas\", \"loganberries\")\n\ndef eat(food=fruits):\n    ...\n \n When I see the declaration of eat, the least astonishing thing is to think that if the first parameter is not given, that it will be equal to the tuple  (\"apples\", \"bananas\", \"loganberries\") \n However, suppose later on in the code, I do something like \n def some_random_function():\n    global fruits\n    fruits = (\"blueberries\", \"mangos\")\n \n then if default parameters were bound at function execution rather than function declaration, I would be astonished (in a very bad way) to discover that fruits had been changed. This would be more astonishing IMO than discovering that your  foo  function above was mutating the list. \n The real problem lies with mutable variables, and all languages have this problem to some extent. Here's a question: suppose in Java I have the following code: \n StringBuffer s = new StringBuffer(\"Hello World!\");\nMap<StringBuffer,Integer> counts = new HashMap<StringBuffer,Integer>();\ncounts.put(s, 5);\ns.append(\"!!!!\");\nSystem.out.println( counts.get(s) );  // does this work?\n \n Now, does my map use the value of the  StringBuffer  key when it was placed into the map, or does it store the key by reference? Either way, someone is astonished; either the person who tried to get the object out of the  Map  using a value identical to the one they put it in with, or the person who can't seem to retrieve their object even though the key they're using is literally the same object that was used to put it into the map (this is actually why Python doesn't allow its mutable built-in data types to be used as dictionary keys). \n Your example is a good one of a case where Python newcomers will be surprised and bitten. But I'd argue that if we \"fixed\" this, then that would only create a different situation where they'd be bitten instead, and that one would be even less intuitive. Moreover, this is always the case when dealing with mutable variables; you always run into cases where someone could intuitively expect one or the opposite behavior depending on what code they're writing. \n I personally like Python's current approach: default function arguments are evaluated when the function is defined and that object is always the default. I suppose they could special-case using an empty list, but that kind of special casing would cause even more astonishment, not to mention be backwards incompatible. \n    ", "date_posted": "2021-07-30 23:44:28Z", "upvote": "\r\n            319\r\n        ", "accepted": "No", "user": {"stack_user_id": "7487335", "name": "Josh Correia", "reputation_score": "2,999"}, "answer_comments": [{"stack_answer_id": "1133013", "stack_answer_comment_id": "950511", "comment_content": "I think it's a matter of debate. You are acting on a global variable. Any evaluation performed anywhere in your code involving your global variable will now (correctly) refer to (\"blueberries\", \"mangos\"). the default parameter could just be like any other case.", "user_id": "/users/78374/stefano-borini"}, {"stack_answer_id": "1133013", "stack_answer_comment_id": "950592", "comment_content": "Actually, I don't think I agree with your first example.  I'm not sure I like the idea of modifying an initializer like that in the first place, but if I did, I'd expect it to behave exactly as you describe \u2014 changing the default value to ", "user_id": null}, {"stack_answer_id": "1133013", "stack_answer_comment_id": "950800", "comment_content": "The default parameter ", "user_id": null}, {"stack_answer_id": "1133013", "stack_answer_comment_id": "41236608", "comment_content": "I find the example misleading rather than brilliant. If ", "user_id": null}, {"stack_answer_id": "1133013", "stack_answer_comment_id": "44679235", "comment_content": "You just explicitly declared ", "user_id": null}]}, {"stack_answer_id": "11416002", "answer_content": "\r\n The relevant part of the  documentation : \n\n \n   Default parameter values are evaluated from left to right when the function definition is executed.  This means that the expression is evaluated once, when the function is defined, and that the same \u201cpre-computed\u201d value is used for each call. This is especially important to understand when a default parameter is a mutable object, such as a list or a dictionary: if the function modifies the object (e.g. by appending an item to a list), the default value is in effect modified. This is generally not what was intended. A way around this is to use  None  as the default, and explicitly test for it in the body of the function, e.g.: \n\n def whats_on_the_telly(penguin=None):\n    if penguin is None:\n        penguin = []\n    penguin.append(\"property of the zoo\")\n    return penguin\n \n \n    ", "date_posted": "2020-01-30 18:00:14Z", "upvote": "\r\n            295\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": [{"stack_answer_id": "11416002", "stack_answer_comment_id": "35944900", "comment_content": "The phrases \"this is not generally what was intended\" and \"a way around this is\" smell like they're documenting a design flaw.", "user_id": null}, {"stack_answer_id": "11416002", "stack_answer_comment_id": "37577356", "comment_content": "@bukzor: Pitfalls need to be noted and documented, which is why this question is good and has received so many upvotes. At the same time, pitfalls don't necessarily need to be removed. How many Python beginners have passed a list to a function that modified it, and were shocked to see the changes show up in the original variable? Yet mutable object types are wonderful, when you understand how to use them. I guess it just boils down to opinion on this particular pitfall.", "user_id": null}, {"stack_answer_id": "11416002", "stack_answer_comment_id": "43555974", "comment_content": "The phrase \"this is not generally what was intended\" means \"not what the programmer actually wanted to happen,\" not \"not what Python is supposed to do.\"", "user_id": null}, {"stack_answer_id": "11416002", "stack_answer_comment_id": "80032999", "comment_content": "@holdenweb Wow, I'm mega-late to the party. Given the context, bukzor is completely right: they're documenting behavior/consequence that was not \"intended\" when they they decided the language should exec the function's definition. Since it's an unintended consequence of their design choice, it's a design flaw. If it were not a design flaw, there'd be no need to even offer \"a way around this\".", "user_id": null}, {"stack_answer_id": "11416002", "stack_answer_comment_id": "80051888", "comment_content": "We could take it to chat and discuss how else it could be, but the semantics have been thoroughly debated and nobody could come up with a sensible mechanism for create-default-value-on-call. One serious issue is that the scope on call is often entirely different from that on definition, making name resolution uncertain if defaults were evaluated at call time. A \"way around\" means \"you can achieve your desired end in the following way,\" not \"this is a mistake in Python's design.\"", "user_id": null}]}, {"stack_answer_id": "1134623", "answer_content": "\r\n I know nothing about the Python interpreter inner workings (and I'm not an expert in compilers and interpreters either) so don't blame me if I propose anything unsensible or impossible. \n\n Provided that python objects  are mutable  I think that this should be taken into account when designing the default arguments stuff.\nWhen you instantiate a list: \n\n a = []\n \n\n you expect to get a  new  list referenced by  a . \n\n Why should the  a=[]  in \n\n def x(a=[]):\n \n\n instantiate a new list on function definition and not on invocation?\nIt's just like you're asking \"if the user doesn't provide the argument then  instantiate  a new list and use it as if it was produced by the caller\".\nI think this is ambiguous instead: \n\n def x(a=datetime.datetime.now()):\n \n\n user, do you want  a  to default to the datetime corresponding to when you're defining or executing  x ?\nIn this case, as in the previous one, I'll keep the same behaviour as if the default argument \"assignment\" was the first instruction of the function ( datetime.now()  called on function invocation).\nOn the other hand, if the user wanted the definition-time mapping he could write: \n\n b = datetime.datetime.now()\ndef x(a=b):\n \n\n I know, I know: that's a closure. Alternatively Python might provide a keyword to force definition-time binding: \n\n def x(static a=b):\n \n    ", "date_posted": "2019-05-09 09:15:36Z", "upvote": "\r\n            139\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "1134623", "stack_answer_comment_id": "952595", "comment_content": "You could do: def x(a=None): And then, if a is None, set a=datetime.datetime.now()", "user_id": null}, {"stack_answer_id": "1134623", "stack_answer_comment_id": "6587169", "comment_content": "Thank you for this. I couldn't really put my finger on why this  irks me to no end. You have done it beautifully with a minimum of fuzz and confusion. As someone comming from systems programming in C++ and sometimes naively \"translating\" language features, this false friend kicked me in the in the soft of the head big time, just like class attributes. I understand why things are this way, but I cannot help but dislike it, no matter what positive might come of it. At least it is so contrary to my experience, that I'll probably (hopefully) never forget it...", "user_id": null}, {"stack_answer_id": "1134623", "stack_answer_comment_id": "8065966", "comment_content": "@Andreas once you use Python for long enough, you begin to see how logical it is for Python to interpret things as class attributes the way it does - it is only because of the particular quirks and limitations of languages like C++ (and Java, and C#...) that it makes any sense for contents of the ", "user_id": null}, {"stack_answer_id": "1134623", "stack_answer_comment_id": "8112414", "comment_content": "Normative structure is no quirk or limitation in my book. I know it can be clumsy and ugly, but you can call it a \"definition\" of something. The dynamic languages seem a bit like anarchists to me: Sure everybody is free, but you need structure to get someone to empty the trash and pave the road. Guess I'm old... :)", "user_id": null}, {"stack_answer_id": "1134623", "stack_answer_comment_id": "46876103", "comment_content": "The function ", "user_id": null}]}, {"stack_answer_id": "1133255", "answer_content": "\r\n Well, the reason is quite simply that bindings are done when code is executed, and the function definition is executed, well... when the functions is defined. \n\n Compare this: \n\n class BananaBunch:\n    bananas = []\n\n    def addBanana(self, banana):\n        self.bananas.append(banana)\n \n\n This code suffers from the exact same unexpected happenstance. bananas is a class attribute, and hence, when you add things to it, it's added to all instances of that class. The reason is exactly the same. \n\n It's just \"How It Works\", and making it work differently in the function case would probably be complicated, and in the class case likely impossible, or at least slow down object instantiation a lot, as you would have to keep the class code around and execute it when objects are created. \n\n Yes, it is unexpected. But once the penny drops, it fits in perfectly with how Python works in general. In fact, it's a good teaching aid, and once you understand why this happens, you'll grok python much better. \n\n That said it should feature prominently in any good Python tutorial. Because as you mention, everyone runs into this problem sooner or later. \n    ", "date_posted": "2014-12-19 22:53:35Z", "upvote": "\r\n            93\r\n        ", "accepted": "No", "user": {"stack_user_id": "126214", "name": "Lennart Regebro", "reputation_score": "161k"}, "answer_comments": [{"stack_answer_id": "1133255", "stack_answer_comment_id": "950835", "comment_content": "How do you define a class attribute that is different for each instance of a class?", "user_id": null}, {"stack_answer_id": "1133255", "stack_answer_comment_id": "950938", "comment_content": "If it's different for each instance it's not a class attribute. Class attributes are attributes on the CLASS. Hence the name. Hence they are the same for all instances.", "user_id": null}, {"stack_answer_id": "1133255", "stack_answer_comment_id": "955561", "comment_content": "How do you define an attribute in a class that is different for each instance of a class? (Re-defined for those who could not determine that a person not familiar with Python's naming convenctions might be asking about normal member variables of a class).", "user_id": null}, {"stack_answer_id": "1133255", "stack_answer_comment_id": "955627", "comment_content": "@Kievieli: You ARE talking about normal member variables of a class. :-)  You define instance attributes by saying self.attribute = value in any method. For example __init__().", "user_id": null}, {"stack_answer_id": "1133255", "stack_answer_comment_id": "10928164", "comment_content": "@Kieveli: Two answers:  you can't, because any thing you define at a class level will be a class attribute, and any instance that accesses that attribute will access the same class attribute; you can, /sort of/, by using ", "user_id": null}]}, {"stack_answer_id": "34172768", "answer_content": "\r\n Why don't you introspect? \n\n I'm  really  surprised no one has performed the insightful introspection offered by Python ( 2  and  3  apply) on callables.  \n\n Given a simple little function  func  defined as: \n\n >>> def func(a = []):\n...    a.append(5)\n \n\n When Python encounters it, the first thing it will do is compile it in order to create a  code  object for this function. While this compilation step is done,  Python  evaluates * and then  stores  the default arguments (an empty list  []  here) in the function object itself . As the top answer mentioned: the list  a  can now be considered a  member  of the function  func . \n\n So, let's do some introspection, a before and after to examine how the list gets expanded  inside  the function object. I'm using  Python 3.x  for this, for Python 2 the same applies (use  __defaults__  or  func_defaults  in Python 2; yes, two names for the same thing). \n\n Function Before Execution: \n\n >>> def func(a = []):\n...     a.append(5)\n...     \n \n\n After Python executes this definition it will take any default parameters specified ( a = []  here) and  cram them in the  __defaults__  attribute for the function object  (relevant section: Callables):      \n\n >>> func.__defaults__\n([],)\n \n\n O.k, so an empty list as the single entry in  __defaults__ , just as expected.  \n\n Function After Execution: \n\n Let's now execute this function: \n\n >>> func()\n \n\n Now, let's see those  __defaults__  again:  \n\n >>> func.__defaults__\n([5],)\n \n\n Astonished?  The value inside the object changes! Consecutive calls to the function will now simply append to that embedded  list  object: \n\n >>> func(); func(); func()\n>>> func.__defaults__\n([5, 5, 5, 5],)\n \n\n So, there you have it, the reason why this  'flaw'  happens, is because default arguments are part of the function object. There's nothing weird going on here, it's all just a bit surprising. \n\n The common solution to combat this is to use  None  as the default and then initialize in the function body: \n\n def func(a = None):\n    # or: a = [] if a is None else a\n    if a is None:\n        a = []\n \n\n Since the function body is executed anew each time, you always get a fresh new empty list if no argument was passed for  a . \n\n \n\n To further verify that the list in  __defaults__  is the same as that used in the function  func  you can just change your function to return the  id  of the list  a  used inside the function body. Then, compare it to the list in  __defaults__  (position  [0]  in  __defaults__ ) and you'll see how these are indeed refering to the same list instance: \n\n >>> def func(a = []): \n...     a.append(5)\n...     return id(a)\n>>>\n>>> id(func.__defaults__[0]) == func()\nTrue\n \n\n All with the power of introspection!  \n\n \n\n *  To verify that Python evaluates the default arguments during compilation of the function, try executing the following: \n\n def bar(a=input('Did you just see me without calling the function?')): \n    pass  # use raw_input in Py2\n \n\n as you'll notice,  input()  is called before the process of building the function and binding it to the name  bar  is made. \n    ", "date_posted": "2018-10-11 16:33:49Z", "upvote": "\r\n            81\r\n        ", "accepted": "No", "user": {"stack_user_id": "4850040", "name": "Toby Speight", "reputation_score": "25.5k"}, "answer_comments": [{"stack_answer_id": "34172768", "stack_answer_comment_id": "59433843", "comment_content": "Is ", "user_id": null}, {"stack_answer_id": "34172768", "stack_answer_comment_id": "59434204", "comment_content": "@das-g ", "user_id": null}, {"stack_answer_id": "34172768", "stack_answer_comment_id": "103227664", "comment_content": "Using ", "user_id": null}]}, {"stack_answer_id": "1136611", "answer_content": "\r\n I used to think that creating the objects at runtime would be the better approach.  I'm less certain now, since you do lose some useful features, though it may be worth it regardless simply to prevent newbie confusion.  The disadvantages of doing so are: \n\n 1. Performance \n\n def foo(arg=something_expensive_to_compute())):\n    ...\n \n\n If call-time evaluation is used, then the expensive function is called every time your function is used without an argument.  You'd either pay an expensive price on each call, or need to manually cache the value externally, polluting your namespace and adding verbosity. \n\n 2. Forcing bound parameters \n\n A useful trick is to bind parameters of a lambda to the  current  binding of a variable when the lambda is created.  For example: \n\n funcs = [ lambda i=i: i for i in range(10)]\n \n\n This returns a list of functions that return 0,1,2,3... respectively.  If the behaviour is changed, they will instead bind  i  to the  call-time  value of i, so you would get a list of functions that all returned  9 . \n\n The only way to implement this otherwise would be to create a further closure with the i bound, ie: \n\n def make_func(i): return lambda: i\nfuncs = [make_func(i) for i in range(10)]\n \n\n 3. Introspection \n\n Consider the code: \n\n def foo(a='test', b=100, c=[]):\n   print a,b,c\n \n\n We can get information about the arguments and defaults using the  inspect  module, which  \n\n >>> inspect.getargspec(foo)\n(['a', 'b', 'c'], None, None, ('test', 100, []))\n \n\n This information is very useful for things like document generation, metaprogramming, decorators etc. \n\n Now, suppose the behaviour of defaults could be changed so that this is the equivalent of: \n\n _undefined = object()  # sentinel value\n\ndef foo(a=_undefined, b=_undefined, c=_undefined)\n    if a is _undefined: a='test'\n    if b is _undefined: b=100\n    if c is _undefined: c=[]\n \n\n However, we've lost the ability to introspect, and see what the default arguments  are .  Because the objects haven't been constructed, we can't ever get hold of them without actually calling the function.  The best we could do is to store off the source code and return that as a string. \n    ", "date_posted": "2009-07-16 19:13:35Z", "upvote": "\r\n            65\r\n        ", "accepted": "No", "user": {"stack_user_id": "9493", "name": "Brian", "reputation_score": "114k"}, "answer_comments": [{"stack_answer_id": "1136611", "stack_answer_comment_id": "954490", "comment_content": "you could achieve introspection also if for each there was a function to create the default argument instead of a value. the inspect module will just call that function.", "user_id": null}, {"stack_answer_id": "1136611", "stack_answer_comment_id": "954611", "comment_content": "@SilentGhost:  I'm talking about if the behaviour was changed to recreate it - creating it once is the current behaviour, and why the mutable default problem exists.", "user_id": null}, {"stack_answer_id": "1136611", "stack_answer_comment_id": "954628", "comment_content": "@yairchu: That assumes the construction is safe to so (ie has no side effects).  Introspecting the args shouldn't ", "user_id": null}, {"stack_answer_id": "1136611", "stack_answer_comment_id": "957188", "comment_content": "A different language design often just means writing things differently.  Your first example could easily be written as: _expensive = expensive(); def foo(arg=_expensive), if you specifically ", "user_id": null}, {"stack_answer_id": "1136611", "stack_answer_comment_id": "957359", "comment_content": "@Glenn - that's what I was referring to with \"cache the variable externally\" - it is a bit more verbose, and you end up with extra variables in your namespace though.", "user_id": null}]}, {"stack_answer_id": "29344819", "answer_content": "\r\n 5 points in defense of Python \n \n Simplicity : The behavior is simple in the following sense:\nMost people fall into this trap only once, not several times. \n \n Consistency : Python  always  passes objects, not names.\nThe default parameter is, obviously, part of the function\nheading (not the function body). It therefore ought to be evaluated\nat module load time (and only at module load time, unless nested), not\nat function call time. \n \n Usefulness : As Frederik Lundh points out in his explanation\nof  \"Default Parameter Values in Python\" , the\ncurrent behavior can be quite useful for advanced programming.\n(Use sparingly.) \n \n Sufficient documentation : In the most basic Python documentation,\nthe tutorial, the issue is loudly announced as\nan  \"Important warning\"  in the  first  subsection of Section\n \"More on Defining Functions\" .\nThe warning even uses boldface,\nwhich is rarely applied outside of headings.\nRTFM: Read the fine manual. \n \n Meta-learning : Falling into the trap is actually a very\nhelpful moment (at least if you are a reflective learner),\nbecause you will subsequently better understand the point\n\"Consistency\" above and that will\nteach you a great deal about Python. \n \n \n    ", "date_posted": "2021-01-21 12:41:46Z", "upvote": "\r\n            65\r\n        ", "accepted": "No", "user": {"stack_user_id": "13367995", "name": "jakubde", "reputation_score": "27"}, "answer_comments": [{"stack_answer_id": "29344819", "stack_answer_comment_id": "52693997", "comment_content": "It took me a year to find this behavior is messing up my code on production, ended up removing a complete feature until I bumped into this design flaw by chance.  I'm using Django.  Since the staging environment did not have many requests, this bug never had any impact on QA.  When we went live and received many simultaneous requests - some utility functions started overwriting each other's parameters!  Making security holes, bugs and what not.", "user_id": null}, {"stack_answer_id": "29344819", "stack_answer_comment_id": "65774123", "comment_content": "@oriadam, no offense, but I wonder how you learned Python without running into this before.  I am just learning Python now and this possible pitfall is ", "user_id": null}, {"stack_answer_id": "29344819", "stack_answer_comment_id": "65920805", "comment_content": "Also, it would be surprising (to me) if a function of unknown complexity was called in addition to the function call I am making.", "user_id": null}, {"stack_answer_id": "29344819", "stack_answer_comment_id": "115930547", "comment_content": "@oriadam, your company needs code review and actual expert coders in the language they write in by the time they have development, staging and production environments. Newbie bugs and bad code habits should not make it to production code", "user_id": null}]}, {"stack_answer_id": "1133375", "answer_content": "\r\n This behavior is easy explained by: \n\n \n function (class etc.) declaration is executed only once, creating all default value objects \n everything is passed by reference \n \n\n So: \n\n def x(a=0, b=[], c=[], d=0):\n    a = a + 1\n    b = b + [1]\n    c.append(1)\n    print a, b, c\n \n\n \n a  doesn't change - every assignment call creates new int object - new object is printed \n b  doesn't change - new array is build from default value and printed \n c  changes - operation is performed on same object - and it is printed \n \n    ", "date_posted": "2017-10-24 06:34:34Z", "upvote": "\r\n            57\r\n        ", "accepted": "No", "user": {"stack_user_id": "4952130", "name": "Dimitris Fasarakis Hilliard", "reputation_score": "139k"}, "answer_comments": [{"stack_answer_id": "1133375", "stack_answer_comment_id": "952500", "comment_content": "(Actually, ", "user_id": null}, {"stack_answer_id": "1133375", "stack_answer_comment_id": "952539", "comment_content": "Realized it to my chagrin after checking to see that, with b set to [], b.__add__([1]) returns [1] but also leaves b still [] even though lists are mutable.  My bad.", "user_id": null}, {"stack_answer_id": "1133375", "stack_answer_comment_id": "36118858", "comment_content": "@ANon: there is ", "user_id": null}]}, {"stack_answer_id": "13518071", "answer_content": "\r\n 1)  The so-called problem of \"Mutable Default Argument\" is in general a special example demonstrating that: \n\"All functions with this problem  suffer also from similar side effect problem on the actual parameter ,\" \nThat is against the rules of functional programming, usually undesiderable and should be fixed both together. \n\n Example: \n\n def foo(a=[]):                 # the same problematic function\n    a.append(5)\n    return a\n\n>>> somevar = [1, 2]           # an example without a default parameter\n>>> foo(somevar)\n[1, 2, 5]\n>>> somevar\n[1, 2, 5]                      # usually expected [1, 2]\n \n\n Solution :  a  copy \nAn absolutely safe solution is to  copy  or  deepcopy  the input object first and then to do whatever with the copy. \n\n def foo(a=[]):\n    a = a[:]     # a copy\n    a.append(5)\n    return a     # or everything safe by one line: \"return a + [5]\"\n \n\n Many builtin mutable types have a copy method like  some_dict.copy()  or  some_set.copy()  or can be copied easy like  somelist[:]  or  list(some_list) . Every object can be also copied by  copy.copy(any_object)  or more thorough by  copy.deepcopy()  (the latter useful if the mutable object is composed from mutable objects). Some objects are fundamentally based on side effects like \"file\" object and can not be meaningfully reproduced by copy.  copying \n\n Example problem for  a similar SO question \n\n class Test(object):            # the original problematic class\n  def __init__(self, var1=[]):\n    self._var1 = var1\n\nsomevar = [1, 2]               # an example without a default parameter\nt1 = Test(somevar)\nt2 = Test(somevar)\nt1._var1.append([1])\nprint somevar                  # [1, 2, [1]] but usually expected [1, 2]\nprint t2._var1                 # [1, 2, [1]] but usually expected [1, 2]\n \n\n It shouldn't be neither saved in any  public  attribute of an instance returned by this function. (Assuming that  private  attributes of instance should not be modified from outside of this class or subclasses by convention. i.e.  _var1  is a private attribute ) \n\n Conclusion: \nInput parameters objects shouldn't be modified in place (mutated) nor they should not be binded into an object returned by the function. (If we prefere programming without side effects which is strongly recommended. see  Wiki about \"side effect\"  (The first two paragraphs are relevent in this context.)\n.) \n\n 2) \nOnly if the side effect on the actual parameter is required but unwanted on the default parameter then the useful solution is  def ...(var1=None):   if var1 is None:   var1 = []   More.. \n\n 3) In some cases is  the mutable behavior of default parameters useful . \n    ", "date_posted": "2017-05-23 11:47:32Z", "upvote": "\r\n            39\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": [{"stack_answer_id": "13518071", "stack_answer_comment_id": "36118939", "comment_content": "I hope you're aware that Python is ", "user_id": null}, {"stack_answer_id": "13518071", "stack_answer_comment_id": "36126140", "comment_content": "Yes, Python is a multi-paragigm language with some functional features. (\"Don't make every problem look like a nail just because you have a hammer.\") Many of them are in Python best practicies. Python has an interesting ", "user_id": null}, {"stack_answer_id": "13518071", "stack_answer_comment_id": "83550760", "comment_content": "I'd also add, at this late stage, that Python's assignment semantics have been designed explicitly to avoid data copying where necessary, so the creation of copies (and especially of deep copies) will affect both run-time and memory usage adversely. They should therefore be used only when necessary, but newcomers often have difficulty understanding when that is.", "user_id": null}, {"stack_answer_id": "13518071", "stack_answer_comment_id": "83606638", "comment_content": "@holdenweb I agree. A temporary copy is the most usual way and sometimes the only possible way how to protect the original mutable data from an extraneous function that modifies them potentially. Fortunately a function that unreasonably modifies data is considered a bug and therefore uncommon.", "user_id": null}, {"stack_answer_id": "13518071", "stack_answer_comment_id": "84665509", "comment_content": "I agree with this answer. And I don't understand why the ", "user_id": null}]}, {"stack_answer_id": "1133737", "answer_content": "\r\n What you're asking is why this: \n\n def func(a=[], b = 2):\n    pass\n \n\n isn't internally equivalent to this: \n\n def func(a=None, b = None):\n    a_default = lambda: []\n    b_default = lambda: 2\n    def actual_func(a=None, b=None):\n        if a is None: a = a_default()\n        if b is None: b = b_default()\n    return actual_func\nfunc = func()\n \n\n except for the case of explicitly calling func(None, None), which we'll ignore. \n\n In other words, instead of evaluating default parameters, why not store each of them, and evaluate them when the function is called? \n\n One answer is probably right there--it would effectively turn every function with default parameters into a closure.  Even if it's all hidden away in the interpreter and not a full-blown closure, the data's got to be stored somewhere.  It'd be slower and use more memory. \n    ", "date_posted": "2009-07-15 20:18:14Z", "upvote": "\r\n            38\r\n        ", "accepted": "No", "user": {"stack_user_id": "136829", "name": "Glenn Maynard", "reputation_score": "54k"}, "answer_comments": [{"stack_answer_id": "1133737", "stack_answer_comment_id": "954338", "comment_content": "It wouldn't need to be a closure - a better way to think of it would simply to make the bytecode creating defaults the first line of code - after all you're compiling the body at that point anyway - there's no real difference between code in the arguments and code in the body.", "user_id": null}, {"stack_answer_id": "1133737", "stack_answer_comment_id": "954824", "comment_content": "True, but it would still slow Python down, and it would actually be quite surprising, unless you do the same for class definitions, which would make it stupidly slow as you would have to re-run the whole class definition each time you instantiate a class.  As mentioned, the fix would be more surprising than the problem.", "user_id": null}, {"stack_answer_id": "1133737", "stack_answer_comment_id": "955297", "comment_content": "Agreed with Lennart.  As Guido is fond of saying, for every language feature or standard library, there's ", "user_id": null}, {"stack_answer_id": "1133737", "stack_answer_comment_id": "957116", "comment_content": "Changing it now would be insanity--we're just exploring why it is the way it is.  If it did late default evaluation to begin with, it wouldn't necessarily be surprising.  It's definitely true that such a core a difference of parsing would have sweeping, and probably many obscure, effects on the language as a whole.", "user_id": null}]}, {"stack_answer_id": "6092808", "answer_content": "\r\n This actually has nothing to do with default values, other than that it often comes up as an unexpected behaviour when you write functions with mutable default values. \n\n >>> def foo(a):\n    a.append(5)\n    print a\n\n>>> a  = [5]\n>>> foo(a)\n[5, 5]\n>>> foo(a)\n[5, 5, 5]\n>>> foo(a)\n[5, 5, 5, 5]\n>>> foo(a)\n[5, 5, 5, 5, 5]\n \n\n No default values in sight in this code, but you get exactly the same problem. \n\n The problem is that  foo  is  modifying  a mutable variable passed in from the caller, when the caller doesn't expect this. Code like this would be fine if the function was called something like  append_5 ; then the caller would be calling the function in order to modify the value they pass in, and the behaviour would be expected. But such a function would be very unlikely to take a default argument, and probably wouldn't return the list (since the caller already has a reference to that list; the one it just passed in). \n\n Your original  foo , with a default argument, shouldn't be modifying  a  whether it was explicitly passed in or got the default value. Your code should leave mutable arguments alone unless it is clear from the context/name/documentation that the arguments are supposed to be modified. Using mutable values passed in as arguments as local temporaries is an extremely bad idea, whether we're in Python or not and whether there are default arguments involved or not. \n\n If you need to destructively manipulate a local temporary in the course of computing something, and you need to start your manipulation from an argument value, you need to make a copy. \n    ", "date_posted": "2011-05-23 04:24:30Z", "upvote": "\r\n            30\r\n        ", "accepted": "No", "user": {"stack_user_id": "450128", "name": "Ben", "reputation_score": "63.9k"}, "answer_comments": [{"stack_answer_id": "6092808", "stack_answer_comment_id": "16186544", "comment_content": "Although related, I think this is distinct behaviour (as we expect ", "user_id": null}, {"stack_answer_id": "6092808", "stack_answer_comment_id": "80529225", "comment_content": "@AndyHayden if the function is ", "user_id": null}, {"stack_answer_id": "6092808", "stack_answer_comment_id": "80539521", "comment_content": "@AndyHayden I left my own answer here with an expansion of that sentiment. Let me know what you think. I might add your example of ", "user_id": null}, {"stack_answer_id": "6092808", "stack_answer_comment_id": "80546281", "comment_content": "@AndyHayden The point of my answer is that if you are ever astonished by accidentally mutating the default value of an argument, then you have another bug, which is that your code can accidentally mutate a caller's value when the default ", "user_id": null}, {"stack_answer_id": "6092808", "stack_answer_comment_id": "80548974", "comment_content": "@AndyHayden That's the subtle thing though, what happens in the case you describe if the caller of the constructor provides a value instead of using the default? Now you've gone and aliased your object's internal attribute to an external value owned by the caller! That sort of thing is a very rich source of hard-to-track-down bugs; it's almost ", "user_id": null}]}, {"stack_answer_id": "36968932", "answer_content": "\r\n Python: The Mutable Default Argument \n\n Default arguments get evaluated at the time the function is compiled into a function object. When used by the function, multiple times by that function, they are and remain the same object.  \n\n When they are mutable, when mutated (for example, by adding an element to it) they remain mutated on consecutive calls. \n\n They stay mutated because they are the same object each time. \n\n Equivalent code: \n\n Since the list is bound to the function when the function object is compiled and instantiated, this: \n\n def foo(mutable_default_argument=[]): # make a list the default argument\n    \"\"\"function that uses a list\"\"\"\n \n\n is almost exactly equivalent to this: \n\n _a_list = [] # create a list in the globals\n\ndef foo(mutable_default_argument=_a_list): # make it the default argument\n    \"\"\"function that uses a list\"\"\"\n\ndel _a_list # remove globals name binding\n \n\n Demonstration \n\n Here's a demonstration - you can verify that they are the same object each time they are referenced by  \n\n \n seeing that the list is created before the function has finished compiling to a function object, \n observing that the id is the same each time the list is referenced, \n observing that the list stays changed when the function that uses it is called a second time, \n observing the order in which the output is printed from the source (which I conveniently numbered for you): \n \n\n example.py \n\n print('1. Global scope being evaluated')\n\ndef create_list():\n    '''noisily create a list for usage as a kwarg'''\n    l = []\n    print('3. list being created and returned, id: ' + str(id(l)))\n    return l\n\nprint('2. example_function about to be compiled to an object')\n\ndef example_function(default_kwarg1=create_list()):\n    print('appending \"a\" in default default_kwarg1')\n    default_kwarg1.append(\"a\")\n    print('list with id: ' + str(id(default_kwarg1)) + \n          ' - is now: ' + repr(default_kwarg1))\n\nprint('4. example_function compiled: ' + repr(example_function))\n\n\nif __name__ == '__main__':\n    print('5. calling example_function twice!:')\n    example_function()\n    example_function()\n \n\n and running it with  python example.py : \n\n 1. Global scope being evaluated\n2. example_function about to be compiled to an object\n3. list being created and returned, id: 140502758808032\n4. example_function compiled: <function example_function at 0x7fc9590905f0>\n5. calling example_function twice!:\nappending \"a\" in default default_kwarg1\nlist with id: 140502758808032 - is now: ['a']\nappending \"a\" in default default_kwarg1\nlist with id: 140502758808032 - is now: ['a', 'a']\n \n\n Does this violate the principle of \"Least Astonishment\"? \n\n This order of execution is frequently confusing to new users of Python. If you understand the Python execution model, then it becomes quite expected.  \n\n The usual instruction to new Python users: \n\n But this is why the usual instruction to new users is to create their default arguments like this instead: \n\n def example_function_2(default_kwarg=None):\n    if default_kwarg is None:\n        default_kwarg = []\n \n\n This uses the None singleton as a sentinel object to tell the function whether or not we've gotten an argument other than the default. If we get no argument, then we actually want to use a new empty list,  [] , as the default. \n\n As the  tutorial section on control flow  says: \n\n \n   If you don\u2019t want the default to be shared between subsequent calls,\n  you can write the function like this instead: \n\n def f(a, L=None):\n    if L is None:\n        L = []\n    L.append(a)\n    return L\n \n \n    ", "date_posted": "2017-12-23 21:18:35Z", "upvote": "\r\n            28\r\n        ", "accepted": "No", "user": {"stack_user_id": "541136", "name": "Russia Must Remove Putin", "reputation_score": "347k"}, "answer_comments": []}, {"stack_answer_id": "1137164", "answer_content": "\r\n The shortest answer would probably be \"definition is execution\", therefore the whole argument makes no strict sense. As a more contrived example, you may cite this: \n\n def a(): return []\n\ndef b(x=a()):\n    print x\n \n\n Hopefully it's enough to show that not executing the default argument expressions at the execution time of the  def  statement isn't easy or doesn't make sense, or both. \n\n I agree it's a gotcha when you try to use default constructors, though. \n    ", "date_posted": "2018-05-20 23:22:19Z", "upvote": "\r\n            28\r\n        ", "accepted": "No", "user": {"stack_user_id": "3951861", "name": "Ashraf.Shk786", "reputation_score": "600"}, "answer_comments": []}, {"stack_answer_id": "29290566", "answer_content": "\r\n Already busy topic, but from what I read here, the following helped me realizing how it's working internally: \n\n def bar(a=[]):\n     print id(a)\n     a = a + [1]\n     print id(a)\n     return a\n\n>>> bar()\n4484370232\n4484524224\n[1]\n>>> bar()\n4484370232\n4484524152\n[1]\n>>> bar()\n4484370232 # Never change, this is 'class property' of the function\n4484523720 # Always a new object \n[1]\n>>> id(bar.func_defaults[0])\n4484370232\n \n    ", "date_posted": "2015-03-26 23:14:01Z", "upvote": "\r\n            27\r\n        ", "accepted": "No", "user": {"stack_user_id": "554374", "name": "St\u00e9phane", "reputation_score": "1,947"}, "answer_comments": [{"stack_answer_id": "29290566", "stack_answer_comment_id": "73656522", "comment_content": "actually this might be a bit confusing for newcomers as ", "user_id": null}]}, {"stack_answer_id": "1134613", "answer_content": "\r\n It's a performance optimization.  As a result of this functionality, which of these two function calls do you think is faster? \n\n def print_tuple(some_tuple=(1,2,3)):\n    print some_tuple\n\nprint_tuple()        #1\nprint_tuple((1,2,3)) #2\n \n\n I'll give you a hint.  Here's the disassembly (see  http://docs.python.org/library/dis.html ): \n\n # 1 \n\n 0 LOAD_GLOBAL              0 (print_tuple)\n3 CALL_FUNCTION            0\n6 POP_TOP\n7 LOAD_CONST               0 (None)\n10 RETURN_VALUE\n \n\n # 2 \n\n  0 LOAD_GLOBAL              0 (print_tuple)\n 3 LOAD_CONST               4 ((1, 2, 3))\n 6 CALL_FUNCTION            1\n 9 POP_TOP\n10 LOAD_CONST               0 (None)\n13 RETURN_VALUE\n \n\n \n   I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs ?) \n \n\n As you can see, there  is  a performance benefit when using immutable default arguments.  This can make a difference if it's a frequently called function or the default argument takes a long time to construct.  Also, bear in mind that Python isn't C.  In C you have constants that are pretty much free.  In Python you don't have this benefit. \n    ", "date_posted": "2013-04-02 21:52:30Z", "upvote": "\r\n            26\r\n        ", "accepted": "No", "user": {"stack_user_id": "2147", "name": "Jason Baker", "reputation_score": "184k"}, "answer_comments": []}, {"stack_answer_id": "10304917", "answer_content": "\r\n This behavior is not surprising if you take the following into consideration: \n \n The behavior of read-only class attributes upon assignment attempts, and that \n Functions are objects (explained well in the accepted answer). \n \n The role of  (2)  has been covered extensively in this thread.  (1)  is likely the astonishment causing factor, as this behavior is not \"intuitive\" when coming from other languages. \n (1)  is described in the Python  tutorial on classes . In an attempt to assign a value to a read-only class attribute: \n \n ...all variables found outside of the innermost scope are\nread-only ( an attempt to write to such a variable will simply create a\nnew local variable in the innermost scope, leaving the identically\nnamed outer variable unchanged ). \n \n Look back to the original example and consider the above points: \n def foo(a=[]):\n    a.append(5)\n    return a\n \n Here  foo  is an object and  a  is an attribute of  foo  (available at  foo.func_defs[0] ). Since  a  is a list,  a  is mutable and is thus a read-write attribute of  foo . It is initialized to the empty list as specified by the signature when the function is instantiated, and is available for reading and writing as long as the function object exists. \n Calling  foo  without overriding a default uses that default's value from  foo.func_defs . In this case,  foo.func_defs[0]  is used for  a  within function object's code scope. Changes to  a  change  foo.func_defs[0] , which is part of the  foo  object and persists between execution of the code in  foo . \n Now, compare this to the example from the documentation on  emulating the default argument behavior of other languages , such that the function signature defaults are used every time the function is executed: \n def foo(a, L=None):\n    if L is None:\n        L = []\n    L.append(a)\n    return L\n \n Taking  (1)  and  (2)  into account, one can see why this accomplishes the desired behavior: \n \n When the  foo  function object is instantiated,  foo.func_defs[0]  is set to  None , an immutable object. \n When the function is executed with defaults (with no parameter specified for  L  in the function call),  foo.func_defs[0]  ( None ) is available in the local scope as  L . \n Upon  L = [] , the assignment cannot succeed at  foo.func_defs[0] , because that attribute is read-only. \n Per  (1) ,  a new local variable also named  L  is created in the local scope  and used for the remainder of the function call.  foo.func_defs[0]  thus remains unchanged for future invocations of  foo . \n \n    ", "date_posted": "2020-08-27 20:44:25Z", "upvote": "\r\n            22\r\n        ", "accepted": "No", "user": {"stack_user_id": "2430549", "name": "HoldOffHunger", "reputation_score": "16.2k"}, "answer_comments": []}, {"stack_answer_id": "15133978", "answer_content": "\r\n A simple workaround using None \n\n >>> def bar(b, data=None):\n...     data = data or []\n...     data.append(b)\n...     return data\n... \n>>> bar(3)\n[3]\n>>> bar(3)\n[3]\n>>> bar(3)\n[3]\n>>> bar(3, [34])\n[34, 3]\n>>> bar(3, [34])\n[34, 3]\n \n    ", "date_posted": "2013-02-28 11:10:16Z", "upvote": "\r\n            21\r\n        ", "accepted": "No", "user": {"stack_user_id": "252135", "name": "hugo24", "reputation_score": "1,071"}, "answer_comments": [{"stack_answer_id": "15133978", "stack_answer_comment_id": "126670851", "comment_content": "This isn't an answer to the question.", "user_id": null}]}, {"stack_answer_id": "1139730", "answer_content": "\r\n It may be true that: \n\n \n Someone is using every language/library feature, and \n Switching the behavior here would be ill-advised, but \n \n\n it is entirely consistent to hold to both of the features above and still make another point: \n\n \n It is a confusing feature and it is unfortunate in Python. \n \n\n The other answers, or at least some of them either make points 1 and 2 but not 3, or make point 3 and downplay points 1 and 2.  But all three are true. \n\n It may be true that switching horses in midstream here would be asking for significant breakage, and that there could be more problems created by changing Python to intuitively handle Stefano's opening snippet. And it may be true that someone who knew Python internals well could explain a minefield of consequences.  However, \n\n The existing behavior is not Pythonic, and Python is successful because very little about the language violates the principle of least astonishment anywhere  near  this badly. It is a real problem, whether or not it would be wise to uproot it. It is a design flaw. If you understand the language much better by trying to trace out the behavior, I can say that C++ does all of this and more; you learn a lot by navigating, for instance, subtle pointer errors. But this is not Pythonic: people who care about Python enough to persevere in the face of this behavior are people who are drawn to the language because Python has far fewer surprises than other language. Dabblers and the curious become Pythonistas when they are astonished at how little time it takes to get something working--not because of a design fl--I mean, hidden logic puzzle--that cuts against the intuitions of programmers who are drawn to Python because it  Just Works . \n    ", "date_posted": "2009-07-16 19:17:59Z", "upvote": "\r\n            20\r\n        ", "accepted": "No", "user": {"stack_user_id": "116906", "name": "Christos Hayward", "reputation_score": "5,621"}, "answer_comments": [{"stack_answer_id": "1139730", "stack_answer_comment_id": "14994287", "comment_content": "-1 Although a defensible perspective, this not an answer, ", "user_id": null}, {"stack_answer_id": "1139730", "stack_answer_comment_id": "19435546", "comment_content": "So then, it is \"amazingly ignorant\" to say that in Python it would make more sense for a default argument of [] to remain [] every time the function is called?", "user_id": null}, {"stack_answer_id": "1139730", "stack_answer_comment_id": "19435596", "comment_content": "And it is ignorant to consider as an unfortunate idiom setting a default argument to None, and then in the body of the body of the function setting if argument == None: argument = []? Is it ignorant to consider this idiom unfortunate as often people want what a naive newcomer would expect, that if you assign f(argument = []), argument will automatically default to a value of []?", "user_id": null}, {"stack_answer_id": "1139730", "stack_answer_comment_id": "19436087", "comment_content": "But in Python, part of the spirit of the language is that you don't have to take too many deep dives; array.sort() works, and works  regardless of how little you understand about sorting, big-O, and constants. The beauty of Python in the array sorting mechanism, to give one of innumerable examples, is that you are not required to take a deep dive into internals. And to say it differently, the beauty of Python is that one is not ordinarily required to take a deep dive into implementation to get something that Just Works. And there is a workaround (...if argument == None: argument = []), FAIL.", "user_id": null}, {"stack_answer_id": "1139730", "stack_answer_comment_id": "28401661", "comment_content": "As a standalone, the statement ", "user_id": null}]}, {"stack_answer_id": "32535706", "answer_content": "\r\n I am going to demonstrate an alternative structure to pass a default list value to a function (it works equally well with dictionaries).   \n\n As others have extensively commented, the list parameter is bound to the function when it is defined as opposed to when it is executed.  Because lists and dictionaries are mutable, any alteration to this parameter will affect other calls to this function.  As a result, subsequent calls to the function will receive this shared list which may have been altered by any other calls to the function.  Worse yet, two parameters are using this function's shared parameter at the same time oblivious to the changes made by the other. \n\n Wrong Method (probably...) : \n\n def foo(list_arg=[5]):\n    return list_arg\n\na = foo()\na.append(6)\n>>> a\n[5, 6]\n\nb = foo()\nb.append(7)\n# The value of 6 appended to variable 'a' is now part of the list held by 'b'.\n>>> b\n[5, 6, 7]  \n\n# Although 'a' is expecting to receive 6 (the last element it appended to the list),\n# it actually receives the last element appended to the shared list.\n# It thus receives the value 7 previously appended by 'b'.\n>>> a.pop()             \n7\n \n\n You can verify that they are one and the same object by using  id : \n\n >>> id(a)\n5347866528\n\n>>> id(b)\n5347866528\n \n\n Per Brett Slatkin's \"Effective Python: 59 Specific Ways to Write Better Python\",  Item 20: Use  None  and Docstrings to specify dynamic default arguments  (p. 48) \n\n \n   The convention for achieving the desired result in Python is to\n  provide a default value of  None  and to document the actual behaviour\n  in the docstring. \n \n\n This implementation ensures that each call to the function either receives the default list or else the list passed to the function. \n\n Preferred Method : \n\n def foo(list_arg=None):\n   \"\"\"\n   :param list_arg:  A list of input values. \n                     If none provided, used a list with a default value of 5.\n   \"\"\"\n   if not list_arg:\n       list_arg = [5]\n   return list_arg\n\na = foo()\na.append(6)\n>>> a\n[5, 6]\n\nb = foo()\nb.append(7)\n>>> b\n[5, 7]\n\nc = foo([10])\nc.append(11)\n>>> c\n[10, 11]\n \n\n There may be legitimate use cases for the 'Wrong Method' whereby the programmer intended the default list parameter to be shared, but this is more likely the exception than the rule. \n    ", "date_posted": "2015-09-12 20:41:53Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "2411802", "name": "Alexander", "reputation_score": "98.5k"}, "answer_comments": []}, {"stack_answer_id": "9791799", "answer_content": "\r\n The solutions here are: \n\n \n Use  None  as your default value (or a nonce  object ), and switch on that to create your values at runtime; or \n Use a  lambda  as your default parameter, and call it within a try block to get the default value (this is the sort of thing that lambda abstraction is for). \n \n\n The second option is nice because users of the function can pass in a callable, which may be already existing (such as a  type ) \n    ", "date_posted": "2013-06-30 16:20:35Z", "upvote": "\r\n            17\r\n        ", "accepted": "No", "user": {"stack_user_id": "21640", "name": "Marcin", "reputation_score": "47.1k"}, "answer_comments": [{"stack_answer_id": "9791799", "stack_answer_comment_id": "126670870", "comment_content": "This doesn't answer the question.", "user_id": null}]}, {"stack_answer_id": "14336301", "answer_content": "\r\n You can get round this by replacing the object (and therefore the tie with the scope): \n\n def foo(a=[]):\n    a = list(a)\n    a.append(5)\n    return a\n \n\n Ugly, but it works. \n    ", "date_posted": "2013-01-15 11:02:03Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "734463", "name": "joedborg", "reputation_score": "16.6k"}, "answer_comments": [{"stack_answer_id": "14336301", "stack_answer_comment_id": "20074742", "comment_content": "This is a nice solution in cases where you're using automatic documentation generation software to document the types of arguments expected by the function.  Putting a=None and then setting a to [] if a is None doesn't help a reader understand at a glance what is expected.", "user_id": null}, {"stack_answer_id": "14336301", "stack_answer_comment_id": "83550838", "comment_content": "Cool idea: rebinding that name guarantees it can never be modified. I really like that.", "user_id": null}, {"stack_answer_id": "14336301", "stack_answer_comment_id": "88079491", "comment_content": "This is exactly the way to do it. Python doesn't make a copy of the parameter, so it's up to you to make the copy explicitly. Once you have a copy, it's yours to modify as you please without any unexpected side effects.", "user_id": null}, {"stack_answer_id": "14336301", "stack_answer_comment_id": "126670875", "comment_content": "This doesn't answer the question, though.", "user_id": null}]}, {"stack_answer_id": "25797695", "answer_content": "\r\n When we do this: \n\n def foo(a=[]):\n    ...\n \n\n ... we assign the argument  a  to an  unnamed  list, if the caller does not pass the value of a. \n\n To make things simpler for this discussion, let's temporarily give the unnamed list a name. How about  pavlo  ? \n\n def foo(a=pavlo):\n   ...\n \n\n At any time, if the caller doesn't tell us what  a  is, we reuse  pavlo . \n\n If  pavlo  is mutable (modifiable), and  foo  ends up modifying it, an effect we notice the next time  foo  is called without specifying  a . \n\n So this is what you see (Remember,  pavlo  is initialized to []): \n\n  >>> foo()\n [5]\n \n\n Now,  pavlo  is [5]. \n\n Calling  foo()  again modifies  pavlo  again: \n\n >>> foo()\n[5, 5]\n \n\n Specifying  a  when calling  foo()  ensures  pavlo  is not touched. \n\n >>> ivan = [1, 2, 3, 4]\n>>> foo(a=ivan)\n[1, 2, 3, 4, 5]\n>>> ivan\n[1, 2, 3, 4, 5]\n \n\n So,  pavlo  is still  [5, 5] . \n\n >>> foo()\n[5, 5, 5]\n \n    ", "date_posted": "2014-09-11 22:05:43Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "1639436", "name": "Saish", "reputation_score": "501"}, "answer_comments": []}, {"stack_answer_id": "28354667", "answer_content": "\r\n I sometimes exploit this behavior as an alternative to the following pattern: \n\n singleton = None\n\ndef use_singleton():\n    global singleton\n\n    if singleton is None:\n        singleton = _make_singleton()\n\n    return singleton.use_me()\n \n\n If  singleton  is only used by  use_singleton , I like the following pattern as a replacement: \n\n # _make_singleton() is called only once when the def is executed\ndef use_singleton(singleton=_make_singleton()):\n    return singleton.use_me()\n \n\n I've used this for instantiating client classes that access external resources, and also for creating dicts or lists for memoization. \n\n Since I don't think this pattern is well known, I do put a short comment in to guard against future misunderstandings. \n    ", "date_posted": "2015-02-06 12:56:53Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "4513367", "name": "bgreen-litl", "reputation_score": "414"}, "answer_comments": [{"stack_answer_id": "28354667", "stack_answer_comment_id": "45063880", "comment_content": "I prefer to add a decorator for memoization, and put the memoization cache onto the function object itself.", "user_id": "/users/78374/stefano-borini"}, {"stack_answer_id": "28354667", "stack_answer_comment_id": "81702357", "comment_content": "This example doesn't replace the more complex pattern you show, because you call ", "user_id": null}]}, {"stack_answer_id": "54018161", "answer_content": "\r\n Every other answer explains why this is actually a nice and desired behavior, or why you shouldn't be needing this anyway. Mine is for those stubborn ones who want to exercise their right to bend the language to their will, not the other way around. \n We will \"fix\" this behavior with a decorator that will copy the default value instead of reusing the same instance for each positional argument left at its default value. \n\n import inspect\nfrom copy import deepcopy  # copy would fail on deep arguments like nested dicts\n\ndef sanify(function):\n    def wrapper(*a, **kw):\n        # store the default values\n        defaults = inspect.getargspec(function).defaults # for python2\n        # construct a new argument list\n        new_args = []\n        for i, arg in enumerate(defaults):\n            # allow passing positional arguments\n            if i in range(len(a)):\n                new_args.append(a[i])\n            else:\n                # copy the value\n                new_args.append(deepcopy(arg))\n        return function(*new_args, **kw)\n    return wrapper\n \n Now let's redefine our function using this decorator: \n @sanify\ndef foo(a=[]):\n    a.append(5)\n    return a\n\nfoo() # '[5]'\nfoo() # '[5]' -- as desired\n \n This is particularly neat for functions that take multiple arguments. Compare: \n # the 'correct' approach\ndef bar(a=None, b=None, c=None):\n    if a is None:\n        a = []\n    if b is None:\n        b = []\n    if c is None:\n        c = []\n    # finally do the actual work\n \n with \n # the nasty decorator hack\n@sanify\ndef bar(a=[], b=[], c=[]):\n    # wow, works right out of the box!\n \n It's important to note that the above solution breaks if you try to use keyword args, like so: \n foo(a=[4])\n \n The decorator could be adjusted to allow for that, but we leave this as an exercise for the reader ;) \n    ", "date_posted": "2022-03-31 10:09:47Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "6919631", "name": "Przemek D", "reputation_score": "624"}, "answer_comments": [{"stack_answer_id": "54018161", "stack_answer_comment_id": "126670698", "comment_content": "This also breaks if the default argument is deep, like ", "user_id": null}, {"stack_answer_id": "54018161", "stack_answer_comment_id": "126698761", "comment_content": "@Flimm I find your phrase \"this breaks\" rather unfair as it seems to suggests the entire concept is somehow flawed, while it is in fact only a minor detail of the implementation. But thank you for the comment nonetheless, I shall edit and improve my answer.", "user_id": null}]}, {"stack_answer_id": "17782210", "answer_content": "\r\n This \"bug\" gave me a lot of overtime work hours! But I'm beginning to see a potential use of it (but I would have liked it to be at the execution time, still) \n\n I'm gonna give you what I see as a useful example. \n\n def example(errors=[]):\n    # statements\n    # Something went wrong\n    mistake = True\n    if mistake:\n        tryToFixIt(errors)\n        # Didn't work.. let's try again\n        tryToFixItAnotherway(errors)\n        # This time it worked\n    return errors\n\ndef tryToFixIt(err):\n    err.append('Attempt to fix it')\n\ndef tryToFixItAnotherway(err):\n    err.append('Attempt to fix it by another way')\n\ndef main():\n    for item in range(2):\n        errors = example()\n    print '\\n'.join(errors)\n\nmain()\n \n\n prints the following \n\n Attempt to fix it\nAttempt to fix it by another way\nAttempt to fix it\nAttempt to fix it by another way\n \n    ", "date_posted": "2013-07-23 10:07:58Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "618099", "name": "Norfeldt", "reputation_score": "6,648"}, "answer_comments": [{"stack_answer_id": "17782210", "stack_answer_comment_id": "119658319", "comment_content": "Your example doesn't seem very realistic.  Why would you pass ", "user_id": null}]}, {"stack_answer_id": "46796007", "answer_content": "\r\n This is not a design flaw . Anyone who trips over this is doing something wrong. \n\n There are 3 cases I see where you might run into this problem: \n\n \n You intend to modify the argument as a side effect of the function. In this case it  never makes sense  to have a default argument. The only exception is when you're abusing the argument list to have function attributes, e.g.  cache={} , and you wouldn't be expected to call the function with an actual argument at all. \n You intend to leave the argument unmodified, but you accidentally  did  modify it. That's a bug, fix it. \n You intend to modify the argument for use inside the function, but didn't expect the modification to be viewable outside of the function. In that case you need to make a  copy  of the argument, whether it was the default or not! Python is not a call-by-value language so it doesn't make the copy for you, you need to be explicit about it. \n \n\n The example in the question could fall into category 1 or 3. It's odd that it both modifies the passed list and returns it; you should pick one or the other. \n    ", "date_posted": "2017-10-17 18:04:59Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "5987", "name": "Mark Ransom", "reputation_score": "289k"}, "answer_comments": [{"stack_answer_id": "46796007", "stack_answer_comment_id": "80540093", "comment_content": "\"Doing something wrong\" is the diagnosis. That said, I think there are times were =None pattern is useful, but generally you don't want to modify if passed a mutable in that case (2). The ", "user_id": null}, {"stack_answer_id": "46796007", "stack_answer_comment_id": "119639032", "comment_content": "Totally disagree, its absolutely a design flaw in many cases and not the programmer doing something wong", "user_id": null}, {"stack_answer_id": "46796007", "stack_answer_comment_id": "119654728", "comment_content": "I have never run into the problem of the OP even though it is so highly upvoted, because having a default argument be mutable is weird design to me.", "user_id": null}, {"stack_answer_id": "46796007", "stack_answer_comment_id": "119879935", "comment_content": "@MarkRansom If we take it as given that side effects are OK, there's nothing wrong with modifying a default argument as part of a side-effect-ful function. Let's say you have a function that does ", "user_id": null}, {"stack_answer_id": "46796007", "stack_answer_comment_id": "119970601", "comment_content": "@MarkRansom No, they're not; for example, ", "user_id": null}]}, {"stack_answer_id": "30447095", "answer_content": "\r\n Just change the function to be: \n\n def notastonishinganymore(a = []): \n    '''The name is just a joke :)'''\n    a = a[:]\n    a.append(5)\n    return a\n \n    ", "date_posted": "2018-09-06 21:29:08Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "4785185", "name": "Prune", "reputation_score": "75.6k"}, "answer_comments": [{"stack_answer_id": "30447095", "stack_answer_comment_id": "126670893", "comment_content": "This doesn't answer the question, though.", "user_id": null}]}, {"stack_answer_id": "53792207", "answer_content": "\r\n TLDR: Define-time defaults are consistent and strictly more expressive. \n\n \n\n Defining a function affects two scopes: the defining scope  containing  the function, and the execution  scope  contained by  the function. While it is pretty clear how blocks map to scopes, the question is where  def <name>(<args=defaults>):  belongs to: \n\n ...                           # defining scope\ndef name(parameter=default):  # ???\n    ...                       # execution scope\n \n\n The  def name  part  must  evaluate in the defining scope - we want  name  to be available there, after all. Evaluating the function only inside itself would make it inaccessible. \n\n Since  parameter  is a constant name, we can \"evaluate\" it at the same time as  def name . This also has the advantage it produces the function with a known signature as  name(parameter=...): , instead of a bare  name(...): . \n\n Now, when to evaluate  default ? \n\n Consistency already says \"at definition\": everything else of  def <name>(<args=defaults>):  is best evaluated at definition as well. Delaying parts of it would be the astonishing choice. \n\n The two choices are not equivalent, either: If  default  is evaluated at definition time, it  can still  affect execution time. If  default  is evaluated at execution time, it  cannot  affect definition time. Choosing \"at definition\" allows expressing both cases, while choosing \"at execution\" can express only one: \n\n def name(parameter=defined):  # set default at definition time\n    ...\n\ndef name(parameter=default):     # delay default until execution time\n    parameter = default if parameter is None else parameter\n    ...\n \n    ", "date_posted": "2019-08-08 07:39:43Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "5349916", "name": "MisterMiyagi", "reputation_score": "38.6k"}, "answer_comments": [{"stack_answer_id": "53792207", "stack_answer_comment_id": "102525948", "comment_content": "\"Consistency already says \"at definition\": everything else of ", "user_id": null}, {"stack_answer_id": "53792207", "stack_answer_comment_id": "102527403", "comment_content": "@LarsH Function definitions are ", "user_id": null}, {"stack_answer_id": "53792207", "stack_answer_comment_id": "102560686", "comment_content": "OK, creating a function means evaluation in some sense, but obviously not in the sense that every expression within it is evaluated at the time of definition. Most aren't. It's not clear to me in what sense the signature is especially \"evaluated\" at definition time any more than the function body is \"evaluated\" (parsed into a suitable representation); whereas expressions in the function body are clearly not evaluated in the full sense. From this point of view, consistency would say that expressions in the signature shouldn't be \"fully\" evaluated either.", "user_id": null}, {"stack_answer_id": "53792207", "stack_answer_comment_id": "102560689", "comment_content": "I don't mean that you're wrong, only that your conclusion doesn't follow from consistency alone.", "user_id": null}, {"stack_answer_id": "53792207", "stack_answer_comment_id": "102560884", "comment_content": "@LarsH Defaults are neither part of the body, nor am I claiming that consistency is the only criteria. Can you make a suggestion how to clarify the answer?", "user_id": null}]}, {"stack_answer_id": "18372696", "answer_content": "\r\n I think the answer to this question lies in how python pass data to parameter (pass by value or by reference), not mutability or how python handle the \"def\" statement. \n\n A brief introduction. First, there are two type of data types in python, one is simple elementary data type, like numbers, and another data type is objects. Second, when passing data to parameters, python pass elementary data type by value, i.e., make a local copy of the value to a local variable, but pass object by reference, i.e., pointers to the object. \n\n Admitting the above two points, let's explain what happened to the python code. It's only because of passing by reference for objects, but has nothing to do with mutable/immutable, or arguably the fact that \"def\" statement is executed only once when it is defined. \n\n [] is an object, so python pass the reference of [] to  a , i.e.,  a  is only a pointer to [] which lies in memory as an object. There is only one copy of [] with, however, many references to it. For the first foo(), the list [] is changed to  1  by append method. But Note that there is only one copy of the list object and this object now becomes  1 . When running the second foo(), what effbot webpage says (items is not evaluated any more) is wrong.  a  is evaluated to be the list object, although now the content of the object is  1 . This is the effect of passing by reference! The result of foo(3) can be easily derived in the same way. \n\n To further validate my answer, let's take a look at two additional codes. \n\n ====== No. 2 ======== \n\n def foo(x, items=None):\n    if items is None:\n        items = []\n    items.append(x)\n    return items\n\nfoo(1)  #return [1]\nfoo(2)  #return [2]\nfoo(3)  #return [3]\n \n\n []  is an object, so is  None  (the former is mutable while the latter is immutable. But the mutability has nothing to do with the question). None is somewhere in the space but we know it's there and there is only one copy of None there. So every time foo is invoked, items is evaluated (as opposed to some answer that it is only evaluated once) to be None, to be clear, the reference (or the address) of None. Then in the foo, item is changed to [], i.e., points to another object which has a different address.  \n\n ====== No. 3 ======= \n\n def foo(x, items=[]):\n    items.append(x)\n    return items\n\nfoo(1)    # returns [1]\nfoo(2,[]) # returns [2]\nfoo(3)    # returns [1,3]\n \n\n The invocation of foo(1) make items point to a list object [] with an address, say, 11111111. the content of the list is changed to  1  in the foo function in the sequel, but the address is not changed, still 11111111. Then foo(2,[]) is coming. Although the [] in foo(2,[]) has the same content as the default parameter [] when calling foo(1), their address are different! Since we provide the parameter explicitly,  items  has to take the address of this new  [] , say 2222222, and return it after making some change. Now foo(3) is executed. since only  x  is provided, items has to take its default value again. What's the default value? It is set when defining the foo function: the list object located in 11111111. So the items is evaluated to be the address 11111111 having an element 1. The list located at 2222222 also contains one element 2, but it is not pointed by items any more. Consequently, An append of 3 will make  items  [1,3].  \n\n From the above explanations, we can see that the  effbot  webpage recommended in the accepted answer failed to give a relevant answer to this question. What is more, I think a point in the effbot webpage is wrong. I think the code regarding the UI.Button is correct: \n\n for i in range(10):\n    def callback():\n        print \"clicked button\", i\n    UI.Button(\"button %s\" % i, callback)\n \n\n Each button can hold a distinct callback function which will display different value of  i . I can provide an example to show this: \n\n x=[]\nfor i in range(10):\n    def callback():\n        print(i)\n    x.append(callback) \n \n\n If we execute  x[7]()  we'll get 7 as expected, and  x[9]()  will gives 9, another value of  i . \n    ", "date_posted": "2013-08-22 05:58:41Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "2384994", "name": "user2384994", "reputation_score": "1,669"}, "answer_comments": [{"stack_answer_id": "18372696", "stack_answer_comment_id": "28304217", "comment_content": "Your last point is wrong. Try it and you'll see that ", "user_id": null}, {"stack_answer_id": "18372696", "stack_answer_comment_id": "42551885", "comment_content": "\"python pass elementary data type by value, i.e., make a local copy of the value to a local variable\" is completely incorrect. I am astonished that someone can obviously know Python very well, yet have such horrible misunderstanding of fundamentals. :-(", "user_id": null}]}], "user": {"stack_user_id": "78374", "name": "Stefano Borini", "reputation_score": "133k"}, "question_comments": [{"stack_question_id": "1132941", "stack_question_comment_id": "11530621", "comment_content": "Complementary question - ", "user_id": null}, {"stack_question_id": "1132941", "stack_question_comment_id": "73589342", "comment_content": "I have not doubt mutable arguments violate least astonishment principle for an average person, and I have seen beginners stepping there, then heroically replacing mailing lists with mailing tuples. Nevertheless mutable arguments are still in line with Python Zen (Pep 20) and falls into \"obvious for Dutch\" (understood/exploited by hard core python programmers) clause.  The recommended  workaround with doc string is the best, yet resistance to doc strings and any (written) docs is not so uncommon nowadays. Personally, I would prefer a decorator (say @fixed_defaults).", "user_id": null}, {"stack_question_id": "1132941", "stack_question_comment_id": "75640338", "comment_content": "My argument when I come across this is:  \"Why do you need to create a function that returns a mutable that could optionally be a mutable you would pass to the function?  Either it alters a mutable or creates a new one.  Why do you need to do both with one function?  And why should the interpreter be rewritten to allow you to do that without adding three lines to your code?\" Because we are talking about rewriting the way the interpreter handles function definitions and evocations here.  That's a lot to do for a barely necessary use case.", "user_id": null}, {"stack_question_id": "1132941", "stack_question_comment_id": "76883169", "comment_content": "\"Python novices would expect this function to always return a list with only one element: ", "user_id": null}, {"stack_question_id": "1132941", "stack_question_comment_id": "98233496", "comment_content": "This question asks ", "user_id": null}]},
{"stack_question_id": "423379", "question_title": "Using global variables in a function", "question_content": "\r\n                How do I create or use a global variable inside a function?\nHow do I use a global variable that was defined in one function inside other functions?\r\n", "question_url": "/questions/423379/using-global-variables-in-a-function", "date_posted": "Jan 8, 2009 at 5:45", "upvote": "3", "view": "3", "tags": ["python", "global-variables", "scope"], "answers_count": "2", "answers": [{"stack_answer_id": "423596", "answer_content": "\r\n You can use a global variable within other functions by declaring it as  global  within each function that assigns a value to it: \n globvar = 0\n\ndef set_globvar_to_one():\n    global globvar    # Needed to modify global copy of globvar\n    globvar = 1\n\ndef print_globvar():\n    print(globvar)     # No need for global declaration to read value of globvar\n\nset_globvar_to_one()\nprint_globvar()       # Prints 1\n \n Since it's unclear whether  globvar = 1  is creating a local variable or changing a global variable, Python defaults to creating a local variable, and makes you explicitly choose the other behavior with the  global  keyword. \n See other answers if you want to share a global variable across modules. \n    ", "date_posted": "2022-01-28 21:03:06Z", "upvote": "\r\n            4936\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "128023", "name": "Zarel", "reputation_score": "2,201"}, "answer_comments": [{"stack_answer_id": "423596", "stack_answer_comment_id": "19339130", "comment_content": "It's extreme exaggeration to refer to globals as \"so dangerous.\" Globals are perfectly fine in every language that has ever existed and ever will exist. They have their place. What you should have said is they can cause issues if you have no clue how to program.", "user_id": null}, {"stack_answer_id": "423596", "stack_answer_comment_id": "20143828", "comment_content": "I think they are fairly dangerous. However in python \"global\" variables are actually module-level, which solves a lot of issues.", "user_id": null}]}, {"stack_answer_id": "423668", "answer_content": "\r\n If I'm understanding your situation correctly, what you're seeing is the result of how Python handles local (function) and global (module) namespaces. \n Say you've got a module like this: \n # sample.py\n_my_global = 5\n\ndef func1():\n    _my_global = 42\n\ndef func2():\n    print _my_global\n\nfunc1()\nfunc2()\n \n You might expecting this to print 42, but instead it prints 5.  As has already been mentioned, if you add a ' global ' declaration to  func1() , then  func2()  will print 42. \n def func1():\n    global _my_global \n    _my_global = 42\n \n What's going on here is that Python assumes that any name that is  assigned to , anywhere within a function, is local to that function unless explicitly told otherwise.  If it is only  reading  from a name, and the name doesn't exist locally, it will try to look up the name in any containing scopes (e.g. the module's global scope). \n When you assign 42 to the name  _my_global , therefore, Python creates a local variable that shadows the global variable of the same name.  That local goes out of scope and is  garbage-collected  when  func1()  returns; meanwhile,  func2()  can never see anything other than the (unmodified) global name.  Note that this namespace decision happens at compile time, not at runtime -- if you were to read the value of  _my_global  inside  func1()  before you assign to it, you'd get an  UnboundLocalError , because Python has already decided that it must be a local variable but it has not had any value associated with it yet.  But by using the ' global ' statement, you tell Python that it should look elsewhere for the name instead of assigning to it locally. \n (I believe that this behavior originated largely through an optimization of local namespaces -- without this behavior,  Python's VM would need to perform at least three name lookups each time a new name is assigned to inside a function (to ensure that the name didn't already exist at module/builtin level), which would significantly slow down a very common operation.) \n    ", "date_posted": "2022-06-13 10:11:24Z", "upvote": "\r\n            861\r\n        ", "accepted": "No", "user": {"stack_user_id": "4298200", "name": "Neuron", "reputation_score": "4,509"}, "answer_comments": [{"stack_answer_id": "423668", "stack_answer_comment_id": "53998527", "comment_content": "You mentioned that the namespace decision happens at ", "user_id": null}, {"stack_answer_id": "423668", "stack_answer_comment_id": "83833173", "comment_content": "It is common to use a capital letter for global variables like ", "user_id": null}, {"stack_answer_id": "423668", "stack_answer_comment_id": "83890430", "comment_content": "@watashiSHUN: The namespace decision ", "user_id": null}, {"stack_answer_id": "423668", "stack_answer_comment_id": "83890525", "comment_content": "@Vassilis: It is common to upper case ", "user_id": null}]}, {"stack_answer_id": "423401", "answer_content": "\r\n You may want to explore the notion of  namespaces . In Python, the  module  is the natural place for  global  data: \n \n Each module has its own private symbol table, which is used as the global symbol table by all functions defined in the module. Thus, the author of a module can use global variables in the module without worrying about accidental clashes with a user\u2019s global variables. On the other hand, if you know what you are doing you can touch a module\u2019s global variables with the same notation used to refer to its functions,  modname.itemname . \n \n A specific use of global-in-a-module is described here -  How do I share global variables across modules? , and for completeness the contents are shared here: \n \n The canonical way to share information across modules within a single program is to create a special configuration module (often called  config  or  cfg ). Just import the configuration module in all modules of your application; the module then becomes available as a global name. Because there is only one instance of each module, any changes made to the module object get reflected everywhere. For example: \n \n \n File: config.py \n \n \n x = 0   # Default value of the 'x' configuration setting\n \n \n \n File: mod.py \n \n import config\nconfig.x = 1\n \n \n File: main.py \n \n import config\nimport mod\nprint config.x\n \n    ", "date_posted": "2020-12-16 04:50:21Z", "upvote": "\r\n            262\r\n        ", "accepted": "No", "user": {"stack_user_id": "2038264", "name": "congusbongus", "reputation_score": "12.3k"}, "answer_comments": [{"stack_answer_id": "423401", "stack_answer_comment_id": "83098999", "comment_content": "for a reason I don't like the ", "user_id": null}, {"stack_answer_id": "423401", "stack_answer_comment_id": "94196170", "comment_content": "@vladosaurus does  ", "user_id": null}]}, {"stack_answer_id": "6664227", "answer_content": "\r\n Python uses a simple heuristic to decide which scope it should load a variable from, between local and global.  If a variable name appears on the left hand side of an assignment, but is not declared global, it is assumed to be local.  If it does not appear on the left hand side of an assignment, it is assumed to be global.   \n\n >>> import dis\n>>> def foo():\n...     global bar\n...     baz = 5\n...     print bar\n...     print baz\n...     print quux\n... \n>>> dis.disassemble(foo.func_code)\n  3           0 LOAD_CONST               1 (5)\n              3 STORE_FAST               0 (baz)\n\n  4           6 LOAD_GLOBAL              0 (bar)\n              9 PRINT_ITEM          \n             10 PRINT_NEWLINE       \n\n  5          11 LOAD_FAST                0 (baz)\n             14 PRINT_ITEM          \n             15 PRINT_NEWLINE       \n\n  6          16 LOAD_GLOBAL              1 (quux)\n             19 PRINT_ITEM          \n             20 PRINT_NEWLINE       \n             21 LOAD_CONST               0 (None)\n             24 RETURN_VALUE        \n>>> \n \n\n See how baz, which appears on the left side of an assignment in  foo() , is the only  LOAD_FAST  variable. \n    ", "date_posted": "2011-07-12 12:35:08Z", "upvote": "\r\n            109\r\n        ", "accepted": "No", "user": {"stack_user_id": "65696", "name": "SingleNegationElimination", "reputation_score": "146k"}, "answer_comments": [{"stack_answer_id": "6664227", "stack_answer_comment_id": "51714387", "comment_content": "The heuristic looks for ", "user_id": null}, {"stack_answer_id": "6664227", "stack_answer_comment_id": "106317214", "comment_content": "@MartijnPieters For the name after ", "user_id": null}, {"stack_answer_id": "6664227", "stack_answer_comment_id": "106317485", "comment_content": "@Robert: not to save memory, but to avoid creating a circular reference, which can lead to memory leaks. That's because an exception references a traceback, and the traceback references every local and global namespace along the whole call stack, including the ", "user_id": null}]}, {"stack_answer_id": "423641", "answer_content": "\r\n If you want to refer to a global variable in a function, you can use the  global  keyword to declare which variables are global. You don't have to use it in all cases (as someone here incorrectly claims) - if the name referenced in an expression cannot be found in local scope or scopes in the functions in which this function is defined, it is looked up among global variables. \n\n However, if you assign to a new variable not declared as global in the function, it is implicitly declared as local, and it can overshadow any existing global variable with the same name. \n\n Also, global variables are useful, contrary to some OOP zealots who claim otherwise - especially for smaller scripts, where OOP is overkill. \n    ", "date_posted": "2017-03-04 22:00:48Z", "upvote": "\r\n            70\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "423641", "stack_answer_comment_id": "102505940", "comment_content": "Absolutely re. zealots.  Most Python users use it for scripting and create little functions to separate out small bits of code.", "user_id": null}]}, {"stack_answer_id": "34559513", "answer_content": "\r\n \n   If I create a global variable in one function, how can I use that variable in another function? \n \n\n We can create a global with the following function: \n\n def create_global_variable():\n    global global_variable # must declare it to be a global first\n    # modifications are thus reflected on the module's global scope\n    global_variable = 'Foo' \n \n\n Writing a function does not actually run its code. So we call the  create_global_variable  function: \n\n >>> create_global_variable()\n \n\n Using globals without modification \n\n You can just use it, so long as you don't expect to change which object it points to:  \n\n For example,  \n\n def use_global_variable():\n    return global_variable + '!!!'\n \n\n and now we can use the global variable: \n\n >>> use_global_variable()\n'Foo!!!'\n \n\n Modification of the global variable from inside a function \n\n To point the global variable at a different object, you are required to use the global keyword again: \n\n def change_global_variable():\n    global global_variable\n    global_variable = 'Bar'\n \n\n Note that after writing this function, the code actually changing it has still not run: \n\n >>> use_global_variable()\n'Foo!!!'\n \n\n So after calling the function: \n\n >>> change_global_variable()\n \n\n we can see that the global variable has been changed. The  global_variable  name now points to  'Bar' : \n\n >>> use_global_variable()\n'Bar!!!'\n \n\n Note that \"global\" in Python is not truly global - it's only global to the module level. So it is only available to functions written in the modules in which it is global. Functions remember the module in which they are written, so when they are exported into other modules, they still look in the module in which they were created to find global variables. \n\n Local variables with the same name \n\n If you create a local variable with the same name, it will overshadow a global variable: \n\n def use_local_with_same_name_as_global():\n    # bad name for a local variable, though.\n    global_variable = 'Baz' \n    return global_variable + '!!!'\n\n>>> use_local_with_same_name_as_global()\n'Baz!!!'\n \n\n But using that misnamed local variable does not change the global variable: \n\n >>> use_global_variable()\n'Bar!!!'\n \n\n Note that you should avoid using the local variables with the same names as globals unless you know precisely what you are doing and have a very good reason to do so. I have not yet encountered such a reason. \n\n We get the same behavior in classes \n\n A follow on comment asks: \n\n \n   what to do if I want to create a global variable inside a function inside a class and want to use that variable inside another function inside another class? \n \n\n Here I demonstrate we get the same behavior in methods as we do in regular functions: \n\n class Foo:\n    def foo(self):\n        global global_variable\n        global_variable = 'Foo'\n\nclass Bar:\n    def bar(self):\n        return global_variable + '!!!'\n\nFoo().foo()\n \n\n And now: \n\n >>> Bar().bar()\n'Foo!!!'\n \n\n But I would suggest instead of using global variables you use class attributes, to avoid cluttering the module namespace. Also note we don't use  self  arguments here - these could be class methods (handy if mutating the class attribute from the usual  cls  argument) or static methods (no  self  or  cls ). \n    ", "date_posted": "2020-01-19 14:41:24Z", "upvote": "\r\n            65\r\n        ", "accepted": "No", "user": {"stack_user_id": "541136", "name": "Russia Must Remove Putin", "reputation_score": "347k"}, "answer_comments": [{"stack_answer_id": "34559513", "stack_answer_comment_id": "105760662", "comment_content": "Cool, but what to do if I want to create a global variable inside a function inside a class and want to use that variable inside another function inside another class? Kinda stuck here", "user_id": null}, {"stack_answer_id": "34559513", "stack_answer_comment_id": "105760720", "comment_content": "@anonmanx I don't know why you're stuck, it's the same behavior in a method as in a regular function. But I'll update my answer with your remark and some demo code, ok?", "user_id": null}, {"stack_answer_id": "34559513", "stack_answer_comment_id": "105760875", "comment_content": "okay, got it. So I will have to explicitly call that function for using that global variable.", "user_id": null}]}, {"stack_answer_id": "24572187", "answer_content": "\r\n In addition to already existing answers and to make this more confusing: \n\n \n   In Python, variables that are only referenced inside a function are\n   implicitly global . If a variable is assigned a new value anywhere\n  within the function\u2019s body, it\u2019s assumed to be a  local . If a variable\n  is ever assigned a new value inside the function, the variable is\n  implicitly local, and you need to explicitly declare it as \u2018global\u2019. \n  \n   Though a bit surprising at first, a moment\u2019s consideration explains\n  this. On one hand, requiring global for assigned variables provides a\n  bar against unintended side-effects. On the other hand, if global was\n  required for all global references, you\u2019d be using global all the\n  time. You\u2019d have to declare as global every reference to a built-in\n  function or to a component of an imported module. This clutter would\n  defeat the usefulness of the global declaration for identifying\n  side-effects. \n \n\n Source:  What are the rules for local and global variables in Python? . \n    ", "date_posted": "2014-07-20 10:36:29Z", "upvote": "\r\n            54\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "19151605", "answer_content": "\r\n With parallel execution, global variables can cause unexpected results if you don't understand what is happening. Here is an example of using a global variable within multiprocessing. We can clearly see that each process works with its own copy of the variable: \n\n import multiprocessing\nimport os\nimport random\nimport sys\nimport time\n\ndef worker(new_value):\n    old_value = get_value()\n    set_value(random.randint(1, 99))\n    print('pid=[{pid}] '\n          'old_value=[{old_value:2}] '\n          'new_value=[{new_value:2}] '\n          'get_value=[{get_value:2}]'.format(\n          pid=str(os.getpid()),\n          old_value=old_value,\n          new_value=new_value,\n          get_value=get_value()))\n\ndef get_value():\n    global global_variable\n    return global_variable\n\ndef set_value(new_value):\n    global global_variable\n    global_variable = new_value\n\nglobal_variable = -1\n\nprint('before set_value(), get_value() = [%s]' % get_value())\nset_value(new_value=-2)\nprint('after  set_value(), get_value() = [%s]' % get_value())\n\nprocessPool = multiprocessing.Pool(processes=5)\nprocessPool.map(func=worker, iterable=range(15))\n \n\n Output: \n\n before set_value(), get_value() = [-1]\nafter  set_value(), get_value() = [-2]\npid=[53970] old_value=[-2] new_value=[ 0] get_value=[23]\npid=[53971] old_value=[-2] new_value=[ 1] get_value=[42]\npid=[53970] old_value=[23] new_value=[ 4] get_value=[50]\npid=[53970] old_value=[50] new_value=[ 6] get_value=[14]\npid=[53971] old_value=[42] new_value=[ 5] get_value=[31]\npid=[53972] old_value=[-2] new_value=[ 2] get_value=[44]\npid=[53973] old_value=[-2] new_value=[ 3] get_value=[94]\npid=[53970] old_value=[14] new_value=[ 7] get_value=[21]\npid=[53971] old_value=[31] new_value=[ 8] get_value=[34]\npid=[53972] old_value=[44] new_value=[ 9] get_value=[59]\npid=[53973] old_value=[94] new_value=[10] get_value=[87]\npid=[53970] old_value=[21] new_value=[11] get_value=[21]\npid=[53971] old_value=[34] new_value=[12] get_value=[82]\npid=[53972] old_value=[59] new_value=[13] get_value=[ 4]\npid=[53973] old_value=[87] new_value=[14] get_value=[70]\n \n    ", "date_posted": "2017-01-03 02:34:20Z", "upvote": "\r\n            39\r\n        ", "accepted": "No", "user": {"stack_user_id": "875915", "name": "Rob Bednark", "reputation_score": "23.5k"}, "answer_comments": []}, {"stack_answer_id": "19347254", "answer_content": "\r\n As it turns out the answer is always simple. \n\n Here is a small sample module with a simple way to show it in a  main  definition: \n\n def five(enterAnumber,sumation):\n    global helper\n    helper  = enterAnumber + sumation\n\ndef isTheNumber():\n    return helper\n \n\n Here is how to show it in a  main  definition: \n\n import TestPy\n\ndef main():\n    atest  = TestPy\n    atest.five(5,8)\n    print(atest.isTheNumber())\n\nif __name__ == '__main__':\n    main()\n \n\n This simple code works just like that, and it will execute. I hope it helps. \n    ", "date_posted": "2018-09-28 11:34:54Z", "upvote": "\r\n            32\r\n        ", "accepted": "No", "user": {"stack_user_id": "6664578", "name": "AEF", "reputation_score": "5,143"}, "answer_comments": [{"stack_answer_id": "19347254", "stack_answer_comment_id": "28873293", "comment_content": "thanks, i'm new to python, but know a bit of java.  what you said worked for me. and writing global a<ENTER> within the class.. seems to make more sense to me than within a function writing 'global a'..  I notice you can't say  global a=4", "user_id": null}, {"stack_answer_id": "19347254", "stack_answer_comment_id": "40543494", "comment_content": "This is probably the simplest yet very useful python trick for me. I name this module ", "user_id": null}, {"stack_answer_id": "19347254", "stack_answer_comment_id": "47268475", "comment_content": "What if there are many many global variables and I don't want to have to list them one-by-one after a global statement?", "user_id": null}]}, {"stack_answer_id": "27287648", "answer_content": "\r\n What you are saying is to use the method like this: \n globvar = 5\n\ndef f():\n    var = globvar\n    print(var)\n\nf()  # Prints 5\n \n But the better way is to use the global variable like this: \n globvar = 5\ndef f():\n    global globvar\n    print(globvar)\nf()   #prints 5\n \n Both give the same output. \n    ", "date_posted": "2020-12-01 07:45:16Z", "upvote": "\r\n            31\r\n        ", "accepted": "No", "user": {"stack_user_id": "8873143", "name": "funie200", "reputation_score": "3,384"}, "answer_comments": []}, {"stack_answer_id": "27580376", "answer_content": "\r\n You need to reference the global variable in every function you want to use. \n\n As follows: \n\n var = \"test\"\n\ndef printGlobalText():\n    global var #wWe are telling to explicitly use the global version\n    var = \"global from printGlobalText fun.\"\n    print \"var from printGlobalText: \" + var\n\ndef printLocalText():\n    #We are NOT telling to explicitly use the global version, so we are creating a local variable\n    var = \"local version from printLocalText fun\"\n    print \"var from printLocalText: \" + var\n\nprintGlobalText()\nprintLocalText()\n\"\"\"\nOutput Result:\nvar from printGlobalText: global from printGlobalText fun.\nvar from printLocalText: local version from printLocalText\n[Finished in 0.1s]\n\"\"\"\n \n    ", "date_posted": "2015-02-04 18:45:42Z", "upvote": "\r\n            29\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "27580376", "stack_answer_comment_id": "46534476", "comment_content": "'in every function you want to use' is subtly incorrect, should be closer to: 'in every function where you want to ", "user_id": null}]}, {"stack_answer_id": "28329600", "answer_content": "\r\n Try this: \n def x1():\n    global x\n    x += 1\n    print('x1: ', x)\n\ndef x2():\n    global x\n    x = x+1\n    print('x2: ', x)\n\nx = 5\nprint('x:  ', x)\nx1()\nx2()\n\n# Output:\n# x:   5\n# x1:  6\n# x2:  7\n \n    ", "date_posted": "2020-11-27 17:41:31Z", "upvote": "\r\n            28\r\n        ", "accepted": "No", "user": {"stack_user_id": "1147688", "name": "not2qubit", "reputation_score": "12.4k"}, "answer_comments": [{"stack_answer_id": "28329600", "stack_answer_comment_id": "114987502", "comment_content": "Congratulations! Finally someone who got the most important point of using ", "user_id": null}]}, {"stack_answer_id": "427818", "answer_content": "\r\n You're not actually storing the global in a local variable, just creating a local reference to the same object that your original global reference refers to. Remember that pretty much everything in Python is a name referring to an object, and nothing gets copied in usual operation. \n\n If you didn't have to explicitly specify when an identifier was to refer to a predefined global, then you'd presumably have to explicitly specify when an identifier is a new local variable instead (for example, with something like the 'var' command seen in JavaScript). Since local variables are more common than global variables in any serious and non-trivial system, Python's system makes more sense in most cases. \n\n You  could  have a language which attempted to guess, using a global variable if it existed or creating a local variable if it didn't. However, that would be very error-prone. For example, importing another module could inadvertently introduce a global variable by that name, changing the behaviour of your program. \n    ", "date_posted": "2011-05-30 21:09:51Z", "upvote": "\r\n            26\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "43285234", "answer_content": "\r\n In case you have a local variable with the same name, you might want to use the  globals()  function . \n\n globals()['your_global_var'] = 42\n \n    ", "date_posted": "2017-04-07 19:15:55Z", "upvote": "\r\n            21\r\n        ", "accepted": "No", "user": {"stack_user_id": "562769", "name": "Martin Thoma", "reputation_score": "111k"}, "answer_comments": []}, {"stack_answer_id": "33320055", "answer_content": "\r\n Following on and as an add on, use a file to contain all global variables all declared locally and then  import as : \n\n File  initval.py : \n\n Stocksin = 300\nPrices = []\n \n\n File  getstocks.py : \n\n import initval as iv\n\ndef getmystocks(): \n    iv.Stocksin = getstockcount()\n\n\ndef getmycharts():\n    for ic in range(iv.Stocksin):\n \n    ", "date_posted": "2019-05-21 10:59:46Z", "upvote": "\r\n            18\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "33320055", "stack_answer_comment_id": "75306337", "comment_content": "What is the advantage to move the global variables to another file? Is it just to group together the global variables in a tiny file? And why using the statement ", "user_id": null}, {"stack_answer_id": "33320055", "stack_answer_comment_id": "75306618", "comment_content": "Ah... I have finally understood the advantage: No need to use the keyword ", "user_id": null}]}, {"stack_answer_id": "34664752", "answer_content": "\r\n Writing to explicit elements of a global array does not apparently need the global declaration, though writing to it \"wholesale\" does have that requirement: \n\n import numpy as np\n\nhostValue = 3.14159\nhostArray = np.array([2., 3.])\nhostMatrix = np.array([[1.0, 0.0],[ 0.0, 1.0]])\n\ndef func1():\n    global hostValue    # mandatory, else local.\n    hostValue = 2.0\n\ndef func2():\n    global hostValue    # mandatory, else UnboundLocalError.\n    hostValue += 1.0\n\ndef func3():\n    global hostArray    # mandatory, else local.\n    hostArray = np.array([14., 15.])\n\ndef func4():            # no need for globals\n    hostArray[0] = 123.4\n\ndef func5():            # no need for globals\n    hostArray[1] += 1.0\n\ndef func6():            # no need for globals\n    hostMatrix[1][1] = 12.\n\ndef func7():            # no need for globals\n    hostMatrix[0][0] += 0.33\n\nfunc1()\nprint \"After func1(), hostValue = \", hostValue\nfunc2()\nprint \"After func2(), hostValue = \", hostValue\nfunc3()\nprint \"After func3(), hostArray = \", hostArray\nfunc4()\nprint \"After func4(), hostArray = \", hostArray\nfunc5()\nprint \"After func5(), hostArray = \", hostArray\nfunc6()\nprint \"After func6(), hostMatrix = \\n\", hostMatrix\nfunc7()\nprint \"After func7(), hostMatrix = \\n\", hostMatrix\n \n    ", "date_posted": "2016-01-08 22:35:22Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "5266381", "name": "Mike Lampton", "reputation_score": "181"}, "answer_comments": []}, {"stack_answer_id": "46058078", "answer_content": "\r\n I'm adding this as I haven't seen it in any of the other answers and it might be useful for someone struggling with something similar. The  globals()  function returns a mutable global symbol dictionary where you can \"magically\" make data available for the rest of your code. \nFor example: \n\n from pickle import load\ndef loaditem(name):\n    with open(r\"C:\\pickle\\file\\location\"+\"\\{}.dat\".format(name), \"rb\") as openfile:\n        globals()[name] = load(openfile)\n    return True\n \n\n and  \n\n from pickle import dump\ndef dumpfile(name):\n    with open(name+\".dat\", \"wb\") as outfile:\n        dump(globals()[name], outfile)\n    return True\n \n\n Will just let you dump/load variables out of and into the global namespace. Super convenient, no muss, no fuss. Pretty sure it's Python 3 only. \n    ", "date_posted": "2019-05-21 12:08:51Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "46058078", "stack_answer_comment_id": "98710279", "comment_content": " always returns globals available in the local context, so a mutation here may not reflect in another module.", "user_id": null}]}, {"stack_answer_id": "45769568", "answer_content": "\r\n Reference the class namespace where you want the change to show up.   \n\n In this example, runner is using  max  from the file config. I want my test to change the value of  max  when runner is using it. \n\n main/config.py \n\n max = 15000\n \n\n main/runner.py \n\n from main import config\ndef check_threads():\n    return max < thread_count \n \n\n tests/runner_test.py \n\n from main import runner                # <----- 1. add file\nfrom main.runner import check_threads\nclass RunnerTest(unittest):\n   def test_threads(self):\n       runner.max = 0                  # <----- 2. set global \n       check_threads()\n \n    ", "date_posted": "2017-08-19 08:48:27Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "1303587", "name": "llewellyn falco", "reputation_score": "2,181"}, "answer_comments": []}, {"stack_answer_id": "61992762", "answer_content": "\r\n Globals are fine - Except with Multiprocessing \n\n Globals in connection with multiprocessing on different platforms/envrionments \nas Windows/Mac OS on the one side and Linux on the other are troublesome. \n\n I will show you this with a simple example pointing out a problem which I run into some time ago.  \n\n If you want to understand, why things are different on Windows/MacOs and Linux you \nneed to know that, the default mechanism to start a new process on ... \n\n \n Windows/MacOs is 'spawn' \n Linux is 'fork' \n \n\n They are different in Memory allocation an initialisation ... (but I don't go into this\nhere).  \n\n Let's have a look at the problem/example ... \n\n import multiprocessing\n\ncounter = 0\n\ndef do(task_id):\n    global counter\n    counter +=1\n    print(f'task {task_id}: counter = {counter}')\n\nif __name__ == '__main__':\n\n    pool = multiprocessing.Pool(processes=4)\n    task_ids = list(range(4))\n    pool.map(do, task_ids)\n \n\n Windows \n\n If you run this on Windows (And I suppose on MacOS too), you get the following output ... \n\n task 0: counter = 1\ntask 1: counter = 2\ntask 2: counter = 3\ntask 3: counter = 4\n \n\n Linux \n\n If you run this on Linux, you get the following instead.  \n\n task 0: counter = 1\ntask 1: counter = 1\ntask 2: counter = 1\ntask 3: counter = 1\n \n    ", "date_posted": "2020-05-24 21:41:53Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "6229784", "name": "thomas", "reputation_score": "259"}, "answer_comments": []}, {"stack_answer_id": "63629668", "answer_content": "\r\n There are 2 ways to declare a variable as global: \n 1. assign variable inside functions and use global line \n def declare_a_global_variable():\n    global global_variable_1\n    global_variable_1 = 1\n\n# Note to use the function to global variables\ndeclare_a_global_variable() \n \n 2. assign variable outside functions: \n global_variable_2 = 2\n \n Now we can use these declared global variables in the other functions: \n def declare_a_global_variable():\n    global global_variable_1\n    global_variable_1 = 1\n\n# Note to use the function to global variables\ndeclare_a_global_variable() \nglobal_variable_2 = 2\n\ndef print_variables():\n    print(global_variable_1)\n    print(global_variable_2)\nprint_variables() # prints 1 & 2\n \n Note 1: \n If you want to change a global variable inside another function like  update_variables()  you should use global line in that function before assigning the variable: \n global_variable_1 = 1\nglobal_variable_2 = 2\n\ndef update_variables():\n    global global_variable_1\n    global_variable_1 = 11\n    global_variable_2 = 12 # will update just locally for this function\n\nupdate_variables()\nprint(global_variable_1) # prints 11\nprint(global_variable_2) # prints 2\n \n Note 2: \n There is a exception for note 1 for list and dictionary variables while not using global line inside a function: \n # declaring some global variables\nvariable = 'peter'\nlist_variable_1 = ['a','b']\nlist_variable_2 = ['c','d']\n\ndef update_global_variables():\n    \"\"\"without using global line\"\"\"\n    variable = 'PETER' # won't update in global scope\n    list_variable_1 = ['A','B'] # won't update in global scope\n    list_variable_2[0] = 'C' # updated in global scope surprisingly this way\n    list_variable_2[1] = 'D' # updated in global scope surprisingly this way\n\nupdate_global_variables()\n\nprint('variable is: %s'%variable) # prints peter\nprint('list_variable_1 is: %s'%list_variable_1) # prints ['a', 'b']\nprint('list_variable_2 is: %s'%list_variable_2) # prints ['C', 'D']\n \n    ", "date_posted": "2020-09-12 09:23:03Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "6756530", "name": "Mohsen Haddadi", "reputation_score": "1,198"}, "answer_comments": []}, {"stack_answer_id": "67339244", "answer_content": "\r\n Though this has been answered, I am giving solution again as I prefer single line\nThis is if you wish to create global variable within function \n def someFunc():\n    x=20\n    globals()['y']=50\nsomeFunc() # invoking function so that variable Y is created globally \nprint(y) # output 50\nprint(x) #NameError: name 'x' is not defined as x was defined locally within function\n \n    ", "date_posted": "2021-04-30 19:26:17Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "15132261", "name": "Pavn", "reputation_score": "123"}, "answer_comments": []}, {"stack_answer_id": "71663780", "answer_content": "\r\n global_var = 10  # will be considered as a global variable\n\n\ndef func_1():\n    global global_var  # access variable using variable keyword\n    global_var += 1\n\n\ndef func_2():\n    global global_var\n    global_var *= 2\n    print(f\"func_2: {global_var}\")\n\n\nfunc_1()\nfunc_2()\nprint(\"Global scope:\", global_var) # will print 22\n \n Explanation: \n global_var  is a global variable and all functions and classes can access that variable. \n The  func_1()  accessed that global variable using the keyword  global  which points to the variable which is written in the global scope. If I didn't write the global keyword the variable  global_var  inside  func_1  is considered a local variable that is only usable inside the function. Then inside  func_1 , I have incremented that global variable by 1. \n The same happened in  func_2() . \n After calling  func_1  and  func_2 , you'll see the  global_var  is changed \n    ", "date_posted": "2022-04-04 14:58:25Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "15531189", "name": "SHIVAM SINGH", "reputation_score": "65"}, "answer_comments": [{"stack_answer_id": "71663780", "stack_answer_comment_id": "126780096", "comment_content": " is a global variable and all functions and classes can access that variable.  The func_1() accessed that global variable using the keyword ", "user_id": null}]}, {"stack_answer_id": "71074895", "answer_content": "\r\n Like this code: \n myVar = 12\n\ndef myFunc():\n  myVar += 12\n \n Key: \n If you declare a variable outside the strings, it become global. \n If you declare a variable inside the strings, it become local. \n If you want to declare a global variable inside the strings, use the keyword  global  before the variable you want to declare: \n myVar = 124\ndef myFunc():\n  global myVar2\n  myVar2 = 100\nmyFunc()\nprint(myVar2)\n \n and then you have 100 in the document. \n    ", "date_posted": "2022-02-22 09:19:20Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "17754099", "name": "Oscar Nguyen", "reputation_score": "43"}, "answer_comments": []}, {"stack_answer_id": "71883300", "answer_content": "\r\n Initialized = 0  #Here This Initialized is global variable  \n\ndef Initialize():\n     print(\"Initialized!\")\n     Initialized = 1  #This is local variable and assigning 1 to local variable\nwhile Initialized == 0:  \n \n Here we are comparing global variable Initialized that 0, so while loop condition got true \n      Initialize()\n \n Function will get called.Loop will be infinite \n #if we do Initialized=1 then loop will terminate  \n\nelse:\n    print(\"Lets do something else now!\")\n \n    ", "date_posted": "2022-04-15 11:10:50Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "15512418", "name": "zeeshan12396", "reputation_score": "378"}, "answer_comments": []}], "user": {"stack_user_id": "46646", "name": "user46646", "reputation_score": "146k"}, "question_comments": [{"stack_question_id": "423379", "stack_question_comment_id": "129288933", "comment_content": "No matter where you mentioned 'global' before variable name, it can be used anywhere  like normal local variable, once the python read it as with 'global' keyword. But it is a very bad idea to unless the variable is common to the entire project. For example, project_name, database_url", "user_id": null}]},
{"stack_question_id": "20625582", "question_title": "How to deal with SettingWithCopyWarning in Pandas", "question_content": "\r\n                Background\nI just upgraded my Pandas from 0.11 to 0.13.0rc1. Now, the application is popping out many new warnings. One of them like this:\nE:\\FinReporter\\FM_EXT.py:449: SettingWithCopyWarning: A value ...\r\n", "question_url": "/questions/20625582/how-to-deal-with-settingwithcopywarning-in-pandas", "date_posted": "Dec 17, 2013 at 3:48", "upvote": "1", "view": "1", "tags": ["python", "pandas", "dataframe", "chained-assignment"], "answers_count": "2", "answers": [{"stack_answer_id": "20627316", "answer_content": "\r\n The  SettingWithCopyWarning  was created to flag potentially confusing \"chained\" assignments, such as the following, which does not always work as expected, particularly when the first selection returns a  copy .  [see  GH5390  and  GH5597  for background discussion.] \n df[df['A'] > 2]['B'] = new_val  # new_val not set in df\n \n The warning offers a suggestion to rewrite as follows: \n df.loc[df['A'] > 2, 'B'] = new_val\n \n However, this doesn't fit your usage, which is equivalent to: \n df = df[df['A'] > 2]\ndf['B'] = new_val\n \n While it's clear that you don't care about writes making it back to the original frame (since you are overwriting the reference to it), unfortunately this pattern cannot be differentiated from the first chained assignment example. Hence the (false positive) warning. The potential for false positives is addressed in the  docs on indexing , if you'd like to read further.  You can safely disable this new warning with the following assignment. \n import pandas as pd\npd.options.mode.chained_assignment = None  # default='warn'\n \n \n Other Resources \n \n pandas User Guide: Indexing and selecting data \n Python Data Science Handbook: Data Indexing and Selection \n Real Python: SettingWithCopyWarning in Pandas: Views vs Copies \n Dataquest: SettingwithCopyWarning: How to Fix This Warning in Pandas \n Towards Data Science: Explaining the SettingWithCopyWarning in pandas \n \n    ", "date_posted": "2022-07-28 19:28:08Z", "upvote": "\r\n            1416\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "7758804", "name": "Trenton McKinney", "reputation_score": "46.5k"}, "answer_comments": [{"stack_answer_id": "20627316", "stack_answer_comment_id": "119156609", "comment_content": "I was using a slice of a dataframe, doing modifications in that slice and was getting this error. I created this slice by doing a ", "user_id": null}, {"stack_answer_id": "20627316", "stack_answer_comment_id": "121147727", "comment_content": "How should I deal with ", "user_id": null}]}, {"stack_answer_id": "53954986", "answer_content": "\r\n \n How to deal with  SettingWithCopyWarning  in Pandas? \n \n This post is meant for readers who, \n \n Would like to understand what this warning means \n Would like to understand different ways of suppressing this warning \n Would like to understand how to improve their code and follow good practices to avoid this warning in the future. \n \n Setup \n np.random.seed(0)\ndf = pd.DataFrame(np.random.choice(10, (3, 5)), columns=list('ABCDE'))\ndf\n   A  B  C  D  E\n0  5  0  3  3  7\n1  9  3  5  2  4\n2  7  6  8  8  1\n \n \n What is the  SettingWithCopyWarning ? \n To know how to deal with this warning, it is important to understand what it means and why it is raised in the first place. \n When filtering DataFrames, it is possible slice/index a frame to return either a  view , or a  copy , depending on the internal layout and various implementation details. A \"view\" is, as the term suggests, a view into the original data, so modifying the view may modify the original object. On the other hand, a \"copy\" is a replication of data from the original, and modifying the copy has no effect on the original. \n As mentioned by other answers, the  SettingWithCopyWarning  was created to flag \"chained assignment\" operations. Consider  df  in the setup above. Suppose you would like to select all values in column \"B\" where values in column \"A\" is > 5. Pandas allows you to do this in different ways, some more correct than others. For example, \n df[df.A > 5]['B']\n \n1    3\n2    6\nName: B, dtype: int64\n \n And, \n df.loc[df.A > 5, 'B']\n\n1    3\n2    6\nName: B, dtype: int64\n \n These return the same result, so if you are only reading these values, it makes no difference. So, what is the issue? The problem with chained assignment, is that it is generally difficult to predict whether a view or a copy is returned,  so this largely becomes an issue when you are attempting to assign values back.  To build on the earlier example, consider how this code is executed by the interpreter: \n df.loc[df.A > 5, 'B'] = 4\n# becomes\ndf.__setitem__((df.A > 5, 'B'), 4)\n \n With a single  __setitem__  call to  df . OTOH, consider this code: \n df[df.A > 5]['B'] = 4\n# becomes\ndf.__getitem__(df.A > 5).__setitem__('B', 4)\n \n Now, depending on whether  __getitem__  returned a view or a copy, the  __setitem__  operation  may not work . \n In general, you should use  loc  for label-based assignment, and  iloc  for integer/positional based assignment, as the spec guarantees that they always operate on the original. Additionally, for setting a single cell, you should use  at  and  iat . \n More can be found in the  documentation . \n \n Note \nAll boolean indexing operations done with  loc  can also be done with  iloc . The only difference is that  iloc  expects either\nintegers/positions for index or a numpy array of boolean values, and\ninteger/position indexes for the columns. \n For example, \n df.loc[df.A > 5, 'B'] = 4\n \n Can be written nas \n df.iloc[(df.A > 5).values, 1] = 4\n \n And, \n df.loc[1, 'A'] = 100\n \n Can be written as \n df.iloc[1, 0] = 100\n \n And so on. \n \n \n Just tell me how to suppress the warning! \n Consider a simple operation on the \"A\" column of  df . Selecting \"A\" and dividing by 2 will raise the warning, but the operation will work. \n df2 = df[['A']]\ndf2['A'] /= 2\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/__main__.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\ndf2\n     A\n0  2.5\n1  4.5\n2  3.5\n \n There are a couple ways of directly silencing this warning: \n \n (recommended)  Use  loc  to slice subsets : \n  df2 = df.loc[:, ['A']]\n df2['A'] /= 2     # Does not raise \n \n \n Change  pd.options.mode.chained_assignment \nCan be set to  None ,  \"warn\" , or  \"raise\" .  \"warn\"  is the default.  None  will suppress the warning entirely, and  \"raise\"  will throw a  SettingWithCopyError , preventing the operation from going through. \n  pd.options.mode.chained_assignment = None\n df2['A'] /= 2\n \n \n Make a  deepcopy \n  df2 = df[['A']].copy(deep=True)\n df2['A'] /= 2\n \n \n \n @Peter Cotton  in the comments, came up with a nice way of non-intrusively changing the mode (modified from  this gist ) using a context manager, to set the mode only as long as it is required, and the reset it back to the original state when finished. \n \n class ChainedAssignent:\n    def __init__(self, chained=None):\n        acceptable = [None, 'warn', 'raise']\n        assert chained in acceptable, \"chained must be in \" + str(acceptable)\n        self.swcw = chained\n\n    def __enter__(self):\n        self.saved_swcw = pd.options.mode.chained_assignment\n        pd.options.mode.chained_assignment = self.swcw\n        return self\n\n    def __exit__(self, *args):\n        pd.options.mode.chained_assignment = self.saved_swcw\n \n \n The usage is as follows: \n # some code here\nwith ChainedAssignent():\n    df2['A'] /= 2\n# more code follows\n \n Or, to raise the exception \n with ChainedAssignent(chained='raise'):\n    df2['A'] /= 2\n\nSettingWithCopyError: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n \n \n The \"XY Problem\": What am I doing wrong? \n A lot of the time, users attempt to look for ways of suppressing this exception without fully understanding why it was raised in the first place. This is a good example of an  XY problem , where users attempt to solve a problem \"Y\" that is actually a symptom of a deeper rooted problem \"X\". Questions will be raised based on common problems that encounter this warning, and solutions will then be presented. \n \n Question 1 \nI have a DataFrame \n df\n       A  B  C  D  E\n    0  5  0  3  3  7\n    1  9  3  5  2  4\n    2  7  6  8  8  1\n \n I want to assign values in col \"A\" > 5 to 1000. My expected output is \n       A  B  C  D  E\n0     5  0  3  3  7\n1  1000  3  5  2  4\n2  1000  6  8  8  1\n \n \n Wrong way to do this: \n df.A[df.A > 5] = 1000         # works, because df.A returns a view\ndf[df.A > 5]['A'] = 1000      # does not work\ndf.loc[df.A > 5]['A'] = 1000   # does not work\n \n Right way using  loc : \n df.loc[df.A > 5, 'A'] = 1000\n \n \n \n Question 2 1 \nI am trying to set the value in cell (1, 'D') to 12345. My expected output is \n    A  B  C      D  E\n0  5  0  3      3  7\n1  9  3  5  12345  4\n2  7  6  8      8  1\n \n I have tried different ways of accessing this cell, such as\n df['D'][1] . What is the best way to do this? \n 1. This question isn't specifically related to the warning, but\nit is good to understand how to do this particular operation correctly\nso as to avoid situations where the warning could potentially arise in\nfuture. \n \n You can use any of the following methods to do this. \n df.loc[1, 'D'] = 12345\ndf.iloc[1, 3] = 12345\ndf.at[1, 'D'] = 12345\ndf.iat[1, 3] = 12345\n \n \n \n Question 3 \nI am trying to subset values based on some condition. I have a\nDataFrame \n    A  B  C  D  E\n1  9  3  5  2  4\n2  7  6  8  8  1\n \n I would like to assign values in \"D\" to 123 such that \"C\" == 5. I\ntried \n df2.loc[df2.C == 5, 'D'] = 123\n \n Which seems fine but I am  still  getting the\n SettingWithCopyWarning ! How do I fix this? \n \n This is actually probably because of code higher up in your pipeline. Did you create  df2  from something larger, like \n df2 = df[df.A > 5]\n \n ? In this case, boolean indexing will return a view, so  df2  will reference the original. What you'd need to do is assign  df2  to a  copy : \n df2 = df[df.A > 5].copy()\n# Or,\n# df2 = df.loc[df.A > 5, :]\n \n \n \n Question 4 \nI'm trying to drop column \"C\" in-place from \n \n \n    A  B  C  D  E\n1  9  3  5  2  4\n2  7  6  8  8  1\n \n But using \n df2.drop('C', axis=1, inplace=True)\n \n Throws  SettingWithCopyWarning . Why is this happening? \n \n This is because  df2  must have been created as a view from some other slicing operation, such as \n df2 = df[df.A > 5]\n \n The solution here is to either make a  copy()  of  df , or use  loc , as before. \n\n    ", "date_posted": "2021-11-07 08:54:25Z", "upvote": "\r\n            691\r\n        ", "accepted": "No", "user": {"stack_user_id": "155137", "name": "Martijn Courteaux", "reputation_score": "66k"}, "answer_comments": [{"stack_answer_id": "53954986", "stack_answer_comment_id": "97716054", "comment_content": "P.S.: Let me know if your situation is not covered under section 3's list of questions. I will amend my post.", "user_id": null}, {"stack_answer_id": "53954986", "stack_answer_comment_id": "113259726", "comment_content": "I think it would be helpful for Question 2 to link to a question addressing the differences between loc, iloc, at, and iat.  You are probably more aware of such a question than I am, but I'm happy to seek one if it would be helpful.", "user_id": null}, {"stack_answer_id": "53954986", "stack_answer_comment_id": "113259845", "comment_content": " address the case where you want to use loc and iloc at the same time, iloc for rows and loc for columns", "user_id": null}, {"stack_answer_id": "53954986", "stack_answer_comment_id": "114720974", "comment_content": "@cs95: Could you add  an XY description around the case where you are trying to create a new column based on simple math operations on an existing one. As in df['new_col'] = df['old_col']/2. Where 'new_col' does not yet exist. Thx", "user_id": null}, {"stack_answer_id": "53954986", "stack_answer_comment_id": "114723885", "comment_content": "@BryanP unless I'm mistaken that should more or less be covered under the \"Just tell me how to suppress the warning!\" section.", "user_id": null}]}, {"stack_answer_id": "20644369", "answer_content": "\r\n In general the point of the  SettingWithCopyWarning  is to show users (and especially new users) that they  may  be operating on a copy and not the original as they think. There  are  false positives (IOW if you know what you are doing it could be  ok ). One possibility is simply to turn off the (by default  warn ) warning as @Garrett suggest. \n\n Here is another option: \n\n In [1]: df = DataFrame(np.random.randn(5, 2), columns=list('AB'))\n\nIn [2]: dfa = df.ix[:, [1, 0]]\n\nIn [3]: dfa.is_copy\nOut[3]: True\n\nIn [4]: dfa['A'] /= 2\n/usr/local/bin/ipython:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_index,col_indexer] = value instead\n  #!/usr/local/bin/python\n \n\n You can set the  is_copy  flag to  False , which will effectively turn off the check,  for that object : \n\n In [5]: dfa.is_copy = False\n\nIn [6]: dfa['A'] /= 2\n \n\n If you explicitly copy then no further warning will happen: \n\n In [7]: dfa = df.ix[:, [1, 0]].copy()\n\nIn [8]: dfa['A'] /= 2\n \n\n The code the OP is showing above, while legitimate, and probably something I do as well, is technically a case for this warning, and not a false positive. Another way to  not  have the warning would be to do the selection operation via  reindex , e.g. \n\n quote_df = quote_df.reindex(columns=['STK', ...])\n \n\n Or,  \n\n quote_df = quote_df.reindex(['STK', ...], axis=1)  # v.0.21\n \n    ", "date_posted": "2018-11-09 19:23:22Z", "upvote": "\r\n            170\r\n        ", "accepted": "No", "user": {"stack_user_id": "1840471", "name": "Max Ghenis", "reputation_score": "13.3k"}, "answer_comments": [{"stack_answer_id": "20644369", "stack_answer_comment_id": "119840558", "comment_content": "I think it's an understatement to say that there are false positives. I don't think I've ever had this warning help me, and the number of times I've had it clog up my output is insane. It's also bad programming practice: if you start ignoring the warnings in your output because you know they are pure rubbish, you can start to miss real problems. It's also annoying to have to turn off the same warnings all the time.", "user_id": null}]}, {"stack_answer_id": "40214434", "answer_content": "\r\n Pandas dataframe copy warning \n When you go and do something like this: \n quote_df = quote_df.ix[:,[0,3,2,1,4,5,8,9,30,31]]\n \n pandas.ix   in this case  returns a new, stand alone dataframe. \n Any values you decide to change in this dataframe, will not change the original dataframe. \n This is what pandas tries to warn you about. \n \n Why  .ix  is a bad idea \n The  .ix  object tries to do more than one thing, and for anyone who has read anything about clean code, this is a strong smell. \n Given this dataframe: \n df = pd.DataFrame({\"a\": [1,2,3,4], \"b\": [1,1,2,2]})\n \n Two behaviors: \n dfcopy = df.ix[:,[\"a\"]]\ndfcopy.a.ix[0] = 2\n \n Behavior one:  dfcopy  is now a stand alone dataframe. Changing it will not change  df \n df.ix[0, \"a\"] = 3\n \n Behavior two: This changes the original dataframe. \n \n Use  .loc  instead \n The pandas developers recognized that the  .ix  object was quite smelly[speculatively] and thus created two new objects which helps in the accession and assignment of data. (The other being  .iloc ) \n .loc  is faster, because it does not try to create a copy of the data. \n .loc  is meant to modify your existing dataframe inplace, which is more memory efficient. \n .loc  is predictable, it has one behavior. \n \n The solution \n What you are doing in your code example is loading a big file with lots of columns, then modifying it to be smaller. \n The  pd.read_csv  function can help you out with a lot of this and also make the loading of the file a lot faster. \n So instead of doing this \n quote_df = pd.read_csv(StringIO(str_of_all), sep=',', names=list('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefg')) #dtype={'A': object, 'B': object, 'C': np.float64}\nquote_df.rename(columns={'A':'STK', 'B':'TOpen', 'C':'TPCLOSE', 'D':'TPrice', 'E':'THigh', 'F':'TLow', 'I':'TVol', 'J':'TAmt', 'e':'TDate', 'f':'TTime'}, inplace=True)\nquote_df = quote_df.ix[:,[0,3,2,1,4,5,8,9,30,31]]\n \n Do this \n columns = ['STK', 'TPrice', 'TPCLOSE', 'TOpen', 'THigh', 'TLow', 'TVol', 'TAmt', 'TDate', 'TTime']\ndf = pd.read_csv(StringIO(str_of_all), sep=',', usecols=[0,3,2,1,4,5,8,9,30,31])\ndf.columns = columns\n \n This will only read the columns you are interested in, and name them properly. No need for using the evil  .ix  object to do magical stuff. \n    ", "date_posted": "2020-06-20 09:12:55Z", "upvote": "\r\n            47\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}, {"stack_answer_id": "54914752", "answer_content": "\r\n Here I answer the question directly. How to deal with it? \n\n Make a  .copy(deep=False)  after you slice. See  pandas.DataFrame.copy . \n\n Wait, doesn't a slice return a copy? After all, this is what the warning message is attempting to say? Read the long answer: \n\n import pandas as pd\ndf = pd.DataFrame({'x':[1,2,3]})\n \n\n This gives a warning: \n\n df0 = df[df.x>2]\ndf0['foo'] = 'bar'\n \n\n This does not: \n\n df1 = df[df.x>2].copy(deep=False)\ndf1['foo'] = 'bar'\n \n\n Both  df0  and  df1  are  DataFrame  objects, but something about them is different that enables pandas to print the warning. Let's find out what it is. \n\n import inspect\nslice= df[df.x>2]\nslice_copy = df[df.x>2].copy(deep=False)\ninspect.getmembers(slice)\ninspect.getmembers(slice_copy)\n \n\n Using your diff tool of choice, you will see that beyond a couple of addresses, the only material difference is this: \n\n |          | slice   | slice_copy |\n| _is_copy | weakref | None       |\n \n\n The method that decides whether to warn is  DataFrame._check_setitem_copy  which checks  _is_copy . So here you go. Make a  copy  so that your DataFrame is not  _is_copy . \n\n The warning is suggesting to use  .loc , but if you use  .loc  on a frame that  _is_copy , you will still get the same warning. Misleading? Yes. Annoying? You bet. Helpful? Potentially, when chained assignment is used. But it cannot correctly detect chain assignment and prints the warning indiscriminately. \n    ", "date_posted": "2019-05-24 18:36:09Z", "upvote": "\r\n            47\r\n        ", "accepted": "No", "user": {"stack_user_id": "443854", "name": "user443854", "reputation_score": "6,574"}, "answer_comments": [{"stack_answer_id": "54914752", "stack_answer_comment_id": "119747857", "comment_content": "Good sleuthing.  FWIW I also found that ", "user_id": null}, {"stack_answer_id": "54914752", "stack_answer_comment_id": "124723865", "comment_content": "This answer surely deserves a separate badge for writing style.", "user_id": null}, {"stack_answer_id": "54914752", "stack_answer_comment_id": "125406269", "comment_content": "Hands-down the most concrete and direct answer to the question. Very well put.", "user_id": null}]}, {"stack_answer_id": "56507986", "answer_content": "\r\n This topic is really confusing with Pandas. Luckily, it has a relatively simple solution. \n The problem is that it is not always clear whether data filtering operations (e.g. loc) return a copy or a view of the DataFrame. Further use of such filtered DataFrame could therefore be confusing. \n The simple solution is (unless you need to work with very large sets of data): \n Whenever you need to update any values, always make sure that you explicitly copy the DataFrame before the assignment. \n df  # Some DataFrame\ndf = df.loc[:, 0:2]  # Some filtering (unsure whether a view or copy is returned)\ndf = df.copy()  # Ensuring a copy is made\ndf[df[\"Name\"] == \"John\"] = \"Johny\"  # Assignment can be done now (no warning)\n \n    ", "date_posted": "2020-12-09 17:57:58Z", "upvote": "\r\n            29\r\n        ", "accepted": "No", "user": {"stack_user_id": "832230", "name": "Asclepius", "reputation_score": "51.5k"}, "answer_comments": [{"stack_answer_id": "56507986", "stack_answer_comment_id": "115403288", "comment_content": "For large datasets you can make a shallow (deep=False) copy. Still it seems too much to suppress a warning.", "user_id": null}]}, {"stack_answer_id": "60885847", "answer_content": "\r\n I had been getting this issue with  .apply()  when assigning a new dataframe from a pre-existing dataframe on which i've used the  .query()  method. For instance: \n\n prop_df = df.query('column == \"value\"')\nprop_df['new_column'] = prop_df.apply(function, axis=1)\n \n\n Would return this error. The fix that seems to resolve the error in this case is by changing this to: \n\n prop_df = df.copy(deep=True)\nprop_df = prop_df.query('column == \"value\"')\nprop_df['new_column'] = prop_df.apply(function, axis=1)\n \n\n However, this is NOT efficient especially when using large dataframes, due to having to make a new copy. \n\n If you're using the  .apply()  method in generating a new column and its values, a fix that resolves the error and is more efficient is by adding  .reset_index(drop=True) : \n\n prop_df = df.query('column == \"value\"').reset_index(drop=True)\nprop_df['new_column'] = prop_df.apply(function, axis=1)\n \n    ", "date_posted": "2020-03-27 12:46:02Z", "upvote": "\r\n            18\r\n        ", "accepted": "No", "user": {"stack_user_id": "3604584", "name": "Zilbert97", "reputation_score": "442"}, "answer_comments": []}, {"stack_answer_id": "45361923", "answer_content": "\r\n To remove any doubt, my solution was to make a deep copy of the slice instead of a regular copy.\nThis may not be applicable depending on your context (Memory constraints / size of the slice, potential for performance degradation - especially if the copy occurs in a loop like it did for me, etc...) \n To be clear, here is the warning I received: \n /opt/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:54:\nSettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame\nSee the caveats in the documentation:\nhttp://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n \n Illustration \n I had doubts that the warning was thrown because of a column I was dropping on a copy of the slice. While not technically trying to set a value in the copy of the slice, that was still a modification of the copy of the slice.\nBelow are the (simplified) steps I have taken to confirm the suspicion, I hope it will help those of us who are trying to understand the warning. \n Example 1: dropping a column on the original affects the copy \n We knew that already but this is a healthy reminder. This is  NOT  what the warning is about. \n >> data1 = {'A': [111, 112, 113], 'B':[121, 122, 123]}\n>> df1 = pd.DataFrame(data1)\n>> df1\n\n    A   B\n0   111 121\n1   112 122\n2   113 123\n\n\n>> df2 = df1\n>> df2\n\nA   B\n0   111 121\n1   112 122\n2   113 123\n\n# Dropping a column on df1 affects df2\n>> df1.drop('A', axis=1, inplace=True)\n>> df2\n    B\n0   121\n1   122\n2   123\n \n It is possible to avoid changes made on df1 to affect df2. Note: you can avoid importing  copy.deepcopy  by doing  df.copy()  instead. \n >> data1 = {'A': [111, 112, 113], 'B':[121, 122, 123]}\n>> df1 = pd.DataFrame(data1)\n>> df1\n\nA   B\n0   111 121\n1   112 122\n2   113 123\n\n>> import copy\n>> df2 = copy.deepcopy(df1)\n>> df2\nA   B\n0   111 121\n1   112 122\n2   113 123\n\n# Dropping a column on df1 does not affect df2\n>> df1.drop('A', axis=1, inplace=True)\n>> df2\n    A   B\n0   111 121\n1   112 122\n2   113 123\n \n Example 2: dropping a column on the copy may affect the original \n This actually illustrates the warning. \n >> data1 = {'A': [111, 112, 113], 'B':[121, 122, 123]}\n>> df1 = pd.DataFrame(data1)\n>> df1\n\n    A   B\n0   111 121\n1   112 122\n2   113 123\n\n>> df2 = df1\n>> df2\n\n    A   B\n0   111 121\n1   112 122\n2   113 123\n\n# Dropping a column on df2 can affect df1\n# No slice involved here, but I believe the principle remains the same?\n# Let me know if not\n>> df2.drop('A', axis=1, inplace=True)\n>> df1\n\nB\n0   121\n1   122\n2   123\n \n It is possible to avoid changes made on df2 to affect df1 \n >> data1 = {'A': [111, 112, 113], 'B':[121, 122, 123]}\n>> df1 = pd.DataFrame(data1)\n>> df1\n\n    A   B\n0   111 121\n1   112 122\n2   113 123\n\n>> import copy\n>> df2 = copy.deepcopy(df1)\n>> df2\n\nA   B\n0   111 121\n1   112 122\n2   113 123\n\n>> df2.drop('A', axis=1, inplace=True)\n>> df1\n\nA   B\n0   111 121\n1   112 122\n2   113 123\n \n Cheers! \n    ", "date_posted": "2021-02-05 19:57:52Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "5009287", "name": "Raphvanns", "reputation_score": "1,536"}, "answer_comments": []}, {"stack_answer_id": "69595276", "answer_content": "\r\n For me worked: \n import pandas as pd\n# ...\npd.set_option('mode.chained_assignment', None)\n \n    ", "date_posted": "2021-10-16 11:43:25Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "13947931", "name": "mikolaj semeniuk", "reputation_score": "1,288"}, "answer_comments": []}, {"stack_answer_id": "49190903", "answer_content": "\r\n This should work: \n\n quote_df.loc[:,'TVol'] = quote_df['TVol']/TVOL_SCALE\n \n    ", "date_posted": "2018-03-09 09:48:49Z", "upvote": "\r\n            10\r\n        ", "accepted": "No", "user": {"stack_user_id": "1315131", "name": "jrouquie", "reputation_score": "4,255"}, "answer_comments": []}, {"stack_answer_id": "56183831", "answer_content": "\r\n Some may want to simply suppress the warning: \n\n class SupressSettingWithCopyWarning:\n    def __enter__(self):\n        pd.options.mode.chained_assignment = None\n\n    def __exit__(self, *args):\n        pd.options.mode.chained_assignment = 'warn'\n\nwith SupressSettingWithCopyWarning():\n    #code that produces warning\n \n    ", "date_posted": "2019-05-17 09:47:34Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "7027346", "name": "delica", "reputation_score": "1,557"}, "answer_comments": []}, {"stack_answer_id": "54664893", "answer_content": "\r\n Followup beginner question / remark \n\n Maybe a clarification for other beginners like me (I come from R which seems to work a bit differently under the hood). The following harmless-looking and functional code kept producing the SettingWithCopy warning, and I couldn't figure out why. I had both read and understood the issued with \"chained indexing\", but my code doesn't contain any: \n\n def plot(pdb, df, title, **kw):\n    df['target'] = (df['ogg'] + df['ugg']) / 2\n    # ...\n \n\n But then, later, much too late, I looked at where the plot() function is called: \n\n     df = data[data['anz_emw'] > 0]\n    pixbuf = plot(pdb, df, title)\n \n\n So \"df\" isn't a data frame but an object that somehow remembers that it was created by indexing a data frame (so is that a view?) which would make the line in plot() \n\n  df['target'] = ...\n \n\n equivalent to \n\n  data[data['anz_emw'] > 0]['target'] = ...\n \n\n which is a chained indexing. Did I get that right? \n\n Anyway,  \n\n def plot(pdb, df, title, **kw):\n    df.loc[:,'target'] = (df['ogg'] + df['ugg']) / 2\n \n\n fixed it. \n    ", "date_posted": "2019-02-13 07:39:54Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "9940188", "name": "musbur", "reputation_score": "499"}, "answer_comments": [{"stack_answer_id": "54664893", "stack_answer_comment_id": "117318843", "comment_content": "A tad late to the party, but the ", "user_id": null}, {"stack_answer_id": "54664893", "stack_answer_comment_id": "117864677", "comment_content": "This explanation was the only one that got through to me (maybe because I'm also coming from R). Thanks!", "user_id": null}]}, {"stack_answer_id": "60040464", "answer_content": "\r\n As this question is already fully explained and discussed in existing answers I will just provide a neat  pandas  approach to the context manager using  pandas.option_context  (links to  docs  and  example ) - there is absolutely no need to create a custom class with all the dunder methods and other bells and whistles. \n\n First the context manager code itself: \n\n from contextlib import contextmanager\n\n@contextmanager\ndef SuppressPandasWarning():\n    with pd.option_context(\"mode.chained_assignment\", None):\n        yield\n \n\n Then an example: \n\n import pandas as pd\nfrom string import ascii_letters\n\na = pd.DataFrame({\"A\": list(ascii_letters[0:4]), \"B\": range(0,4)})\n\nmask = a[\"A\"].isin([\"c\", \"d\"])\n# Even shallow copy below is enough to not raise the warning, but why is a mystery to me.\nb = a.loc[mask]  # .copy(deep=False)\n\n# Raises the `SettingWithCopyWarning`\nb[\"B\"] = b[\"B\"] * 2\n\n# Does not!\nwith SuppressPandasWarning():\n    b[\"B\"] = b[\"B\"] * 2\n \n\n Worth noticing is that both approches do not modify  a , which is a bit surprising to me, and even a shallow df copy with  .copy(deep=False)  would prevent this warning to be raised (as far as I understand shallow copy should at least modify  a  as well, but it doesn't.  pandas  magic.). \n    ", "date_posted": "2020-02-03 13:41:12Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "4272484", "name": "m-dz", "reputation_score": "2,282"}, "answer_comments": []}, {"stack_answer_id": "46732545", "answer_content": "\r\n You could avoid the whole problem like this, I believe: \n\n return (\n    pd.read_csv(StringIO(str_of_all), sep=',', names=list('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefg')) #dtype={'A': object, 'B': object, 'C': np.float64}\n    .rename(columns={'A':'STK', 'B':'TOpen', 'C':'TPCLOSE', 'D':'TPrice', 'E':'THigh', 'F':'TLow', 'I':'TVol', 'J':'TAmt', 'e':'TDate', 'f':'TTime'}, inplace=True)\n    .ix[:,[0,3,2,1,4,5,8,9,30,31]]\n    .assign(\n        TClose=lambda df: df['TPrice'],\n        RT=lambda df: 100 * (df['TPrice']/quote_df['TPCLOSE'] - 1),\n        TVol=lambda df: df['TVol']/TVOL_SCALE,\n        TAmt=lambda df: df['TAmt']/TAMT_SCALE,\n        STK_ID=lambda df: df['STK'].str.slice(13,19),\n        STK_Name=lambda df: df['STK'].str.slice(21,30)#.decode('gb2312'),\n        TDate=lambda df: df.TDate.map(lambda x: x[0:4]+x[5:7]+x[8:10]),\n    )\n)\n \n\n Using Assign. From the  documentation : Assign new columns to a DataFrame, returning a new object (a copy) with all the original columns in addition to the new ones.  \n\n See Tom Augspurger's article on method chaining in pandas:  https://tomaugspurger.github.io/method-chaining \n    ", "date_posted": "2018-01-16 21:27:38Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "6238102", "name": "Halee", "reputation_score": "473"}, "answer_comments": []}, {"stack_answer_id": "44731898", "answer_content": "\r\n If you have assigned the slice to a variable and want to set using the variable as in the following: \n\n df2 = df[df['A'] > 2]\ndf2['B'] = value\n \n\n And you do not want to use Jeffs solution because your condition computing  df2  is to long or for some other reason, then you can use the following: \n\n df.loc[df2.index.tolist(), 'B'] = value\n \n\n df2.index.tolist()  returns the indices from all entries in df2, which will then be used to set column B in the original dataframe. \n    ", "date_posted": "2017-06-24 01:30:48Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "2128832", "name": "Steohan", "reputation_score": "446"}, "answer_comments": [{"stack_answer_id": "44731898", "stack_answer_comment_id": "88721524", "comment_content": "this is 9 time more expensive then df[\"B\"] = value", "user_id": null}, {"stack_answer_id": "44731898", "stack_answer_comment_id": "91880924", "comment_content": "Can you explain this more deeply @ClaudiuCreanga?", "user_id": null}]}, {"stack_answer_id": "70545685", "answer_content": "\r\n this might apply to numpy only, which means you might need to import it,  but the data i used for my examples numpy was not essential with the calculations, but you can simply stop this settingwithcopy warning message, by using this 1 Line of Code below, \n np.warnings.filterwarnings('ignore')\n \n    ", "date_posted": "2021-12-31 21:12:04Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "5315363", "name": "Calculate", "reputation_score": "171"}, "answer_comments": [{"stack_answer_id": "70545685", "stack_answer_comment_id": "127376857", "comment_content": "This one is the best one! Thanks. The copy warning is really annoying!", "user_id": null}]}, {"stack_answer_id": "47507827", "answer_content": "\r\n For me this issue occured in a following >simplified< example. And I was also able to solve it (hopefully with a correct solution): \n\n old code with warning: \n\n def update_old_dataframe(old_dataframe, new_dataframe):\n    for new_index, new_row in new_dataframe.iterrorws():\n        old_dataframe.loc[new_index] = update_row(old_dataframe.loc[new_index], new_row)\n\ndef update_row(old_row, new_row):\n    for field in [list_of_columns]:\n        # line with warning because of chain indexing old_dataframe[new_index][field]\n        old_row[field] = new_row[field]  \n    return old_row\n \n\n This printed the warning for the line  old_row[field] = new_row[field] \n\n Since the rows in update_row method are actually type  Series , I replaced the line with: \n\n old_row.at[field] = new_row.at[field]\n \n\n i.e.  method  for accessing/lookups for a  Series . Eventhough both works just fine and the result is same, this way I don't have to disable the warnings (=keep them for other chain indexing issues somewhere else). \n\n I hope this may help someone. \n    ", "date_posted": "2017-11-27 09:39:57Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "7920758", "name": "Petr Szturc", "reputation_score": "784"}, "answer_comments": []}, {"stack_answer_id": "68362289", "answer_content": "\r\n I was facing the same warning, while I executed this  part of my code: \n     def scaler(self, numericals):\n        scaler = MinMaxScaler()\n        self.data.loc[:, numericals[0]] = scaler.fit_transform(self.data.loc[:, numericals[0]])\n        self.data.loc[:, numericals[1]] = scaler.fit_transform(self.data.loc[:, numericals[1]])\n \n which  scaler  is a MinMaxScaler and  numericals[0]   contains names of 3 of my numerical columns.\nthe  warning was removed as I changed the code to: \n     def scaler(self, numericals):\n        scaler = MinMaxScaler()\n        self.data.loc[:][numericals[0]] = scaler.fit_transform(self.data.loc[:][numericals[0]])\n        self.data.loc[:][numericals[1]] = scaler.fit_transform(self.data.loc[:][numericals[1]])\n \n So, Just change  [:, ~]  to  [:][~] \n    ", "date_posted": "2021-07-13 12:19:16Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "13046916", "name": "mossishahi", "reputation_score": "68"}, "answer_comments": []}, {"stack_answer_id": "71089974", "answer_content": "\r\n In my case, I would create a new column based on the index but I got this warning as you: \n df_temp[\"Quarter\"] = df_temp.index.quarter\n \n I use insert() instead of direct assignment and it works for me: \n df_temp.insert(loc=0, column='Quarter', value=df_temp.index.quarter)\n \n    ", "date_posted": "2022-02-12 07:54:18Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "16733101", "name": "Phoenix", "reputation_score": "2,121"}, "answer_comments": []}, {"stack_answer_id": "69558039", "answer_content": "\r\n Just create a copy of your dataframe(s) using  .copy()  method before the warning appears, to remove all of your warnings. This happens because we do not want to make changes to the original quote_df. In other words, we do not want to play with the reference of the object of the quote_df which we have created for quote_df. \n quote_df = quote_df.copy()\n \n    ", "date_posted": "2021-10-13 15:13:50Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "3874009", "name": "Vaibhav Hiwase", "reputation_score": "171"}, "answer_comments": [{"stack_answer_id": "69558039", "stack_answer_comment_id": "124723905", "comment_content": "This is needlessly a deep copy (default option is ", "user_id": null}]}], "user": {"stack_user_id": "1072888", "name": "bigbug", "reputation_score": "50.9k"}, "question_comments": [{"stack_question_id": "20625582", "stack_question_comment_id": "62589711", "comment_content": "Here's a context manager to temporarily set the warning level ", "user_id": null}, {"stack_question_id": "20625582", "stack_question_comment_id": "88200031", "comment_content": " official document explain in detail", "user_id": null}, {"stack_question_id": "20625582", "stack_question_comment_id": "95242599", "comment_content": "@leonprou ", "user_id": null}, {"stack_question_id": "20625582", "stack_question_comment_id": "112079428", "comment_content": "Using ", "user_id": null}, {"stack_question_id": "20625582", "stack_question_comment_id": "121588951", "comment_content": "Does this answer your question? ", "user_id": null}]},
{"stack_question_id": "59130200", "question_title": "Selenium - wait until element is present, visible and interactable", "question_content": "\r\n                I have a Selenium script (Python) that clicks a reply button to make the class anonemail appear. The time it takes for the class anonemail to appear varies. Because of that I have to use sleep until ...\r\n", "question_url": "/questions/59130200/selenium-wait-until-element-is-present-visible-and-interactable", "date_posted": "Dec 1, 2019 at 21:36", "upvote": "8", "view": "1", "tags": ["python", "selenium", "selenium-webdriver", "webdriverwait", "expected-condition"], "answers_count": "6", "answers": [{"stack_answer_id": "59130336", "answer_content": "\r\n As per the best practices: \n\n \n If your usecase is to validate the  presence  of any element you need to induce  WebDriverWait  setting the  expected_conditions  as  presence_of_element_located()  which is the expectation for checking that an element is present on the DOM of a page. This does not necessarily mean that the element is visible. So the effective line of code will be: \n\n WebDriverWait(browser, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, \".reply-button\"))).click()\n \n If your usecase is to  extract any attribute  of any element you need to induce  WebDriverWait  setting the  expected_conditions  as  visibility_of_element_located(locator)  which is an expectation for checking that an element is present on the DOM of a page and visible. Visibility means that the element is not only displayed but also has a height and width that is greater than 0. So in your usecase effectively the line of code will be: \n\n email = WebDriverWait(driver, 20).until(EC.visibility_of_element_located((By.CSS_SELECTOR, \"element_css\"))).get_attribute(\"value\")\n \n If your usecase is to invoke  click()  on any element you need to induce  WebDriverWait  setting the  expected_conditions  as  element_to_be_clickable()  which is an expectation for for checking an element is visible and enabled such that you can click it. So in your usecase effectively the line of code will be: \n\n WebDriverWait(browser, 20).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \".reply-button\"))).click()\n \n \n\n \n\n References \n\n You can find a couple of detailed discussion in: \n\n \n WebDriverWait not working as expected \n Selenium: Check for the presence of element \n \n    ", "date_posted": "2020-05-05 18:08:39Z", "upvote": "\r\n            111\r\n        ", "accepted": "No", "user": {"stack_user_id": "4575129", "name": "Josh Kot Sheiss", "reputation_score": "65"}, "answer_comments": []}, {"stack_answer_id": "59132328", "answer_content": "\r\n After clicking the  Reply  button, use  .visibility_of_element_located  like below: \n browser.find_element_by_css_selector(\".reply-button\").click()\n\n# Wait for initialize, in seconds\nwait = WebDriverWait(browser, 10)\n\nemail = wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, '.anonemail'))).get_attribute(\"value\")\nprint(email)\n \n Following import: \n from selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\n \n Waits documentation \n    ", "date_posted": "2021-02-06 22:56:43Z", "upvote": "\r\n            38\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "59130269", "answer_content": "\r\n You can use waits. Check for more information in  Selenium waits . \n In the example below we are waiting 10 seconds for the element to be visible, using the function  visibility_of_element_located . \n driver = webdriver.Firefox()\ndriver.get(\"http://somedomain/url_that_delays_loading\")\ntry:\n    element = WebDriverWait(driver, 10).until(\n        EC.visibility_of_element_located((By.ID, \"myDynamicElement\"))\n    )\nfinally:\n    driver.quit()\n \n    ", "date_posted": "2021-02-06 22:51:27Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "59130290", "answer_content": "\r\n You can use  implicitly_wait : \n from selenium import webdriver\n\ndriver = webdriver.Firefox()\ndriver.implicitly_wait(15)\ndriver.get(\"http://url\")\ndriver.find_element_by_id(\"id_of_element\").click()\n \n It waits until element is loaded. \n In your case the implementation would be, \n browser.implicitly_wait(10)\nbrowser.find_element_by_css_selector(\".reply-button\").click()\nemail = browser.find_element_by_css_selector(\".anonemail\").get_attribute(\"value\")\n \n    ", "date_posted": "2021-02-06 22:53:29Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "73087463", "answer_content": "\r\n \n WebDriverWait(driver, 5).until(         EC.presence_of_element_located((By.CSS_SELECTOR, \".reply-button\"))) : \n \n Hey driver, wait (0-5 seconds), when you see  .reply-button  is  presence , return that button to me! \n \n presence  is present on the DOM. Hidden element is good enough. \n \n \n \n \n WebDriverWait(driver, 5).until(         EC.visibility_of_element_located((By.CSS_SELECTOR, \".reply-button\u201d)))) : \n \n Hey driver, wait (0-5 seconds), when you see  .reply-button  is  visibility , return that button to me! \n \n visibility  is present and visible on the DOM. Hidden element is  not  good enough! \n \n \n \n \n WebDriverWait(driver, 5).until(         EC.element_to_be_clickable((By.CSS_SELECTOR, \".reply-button\u201d)))) : \n \n Hey driver, wait (0-5 seconds), when you see  .reply-button  is  clickable , return that button to me! \n \n clickable  is present and visible and clickable on the DOM. Hidden element or non-clickable is  not  good enough! \n \n \n \n \n \n \n    ", "date_posted": "2022-07-23 01:49:26Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "3927279", "name": "HoangYell", "reputation_score": "3,273"}, "answer_comments": []}, {"stack_answer_id": "72127317", "answer_content": "\r\n I also had a similar problem to yours, I tried using  implicit_wait()  and  WebDriverWait  but they did not work.\nSo I solved setting the  implicit_wait(10)  in the  web driver  instance and using this snippet to click on the button: \n element = driver.find_elements_by_xpath(\"//button[contains(string(), 'Log In')]\")[0]\ndriver.execute_script(\"arguments[0].click();\", element)\n \n    ", "date_posted": "2022-05-05 12:38:25Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "16966945", "name": "badr", "reputation_score": "54"}, "answer_comments": []}], "user": {"stack_user_id": "12458043", "name": "Benjamin Arvola", "reputation_score": "915"}, "question_comments": [{"stack_question_id": "59130200", "stack_question_comment_id": "120993427", "comment_content": "Do any of the answers address waiting for the element to be interactable? It can be present and clickable and still not ready for you to send keys to it.", "user_id": null}, {"stack_question_id": "59130200", "stack_question_comment_id": "126527567", "comment_content": "Try: ", "user_id": null}]},
{"stack_question_id": "986006", "question_title": "How do I pass a variable by reference?", "question_content": "\r\n                Are parameters passed by reference or by value? How do I pass by reference so that the code below outputs 'Changed' instead of 'Original'?\nclass PassByReference:\n    def __init__(self):\n        self....\r\n", "question_url": "/questions/986006/how-do-i-pass-a-variable-by-reference", "date_posted": "Jun 12, 2009 at 10:23", "upvote": "3", "view": "1", "tags": ["python", "reference", "parameter-passing", "pass-by-reference"], "answers_count": "3", "answers": [{"stack_answer_id": "986145", "answer_content": "\r\n Arguments are  passed by assignment . The rationale behind this is twofold: \n\n \n the parameter passed in is actually a  reference  to an object (but the reference is passed by value) \n some data types are mutable, but others aren't \n \n\n So: \n\n \n If you pass a  mutable  object into a method, the method gets a reference to that same object and you can mutate it to your heart's delight, but if you rebind the reference in the method, the outer scope will know nothing about it, and after you're done, the outer reference will still point at the original object.  \n If you pass an  immutable  object to a method, you still can't rebind the outer reference, and you can't even mutate the object. \n \n\n To make it even more clear, let's have some examples.  \n\n List - a mutable type \n\n Let's try to modify the list that was passed to a method: \n\n def try_to_change_list_contents(the_list):\n    print('got', the_list)\n    the_list.append('four')\n    print('changed to', the_list)\n\nouter_list = ['one', 'two', 'three']\n\nprint('before, outer_list =', outer_list)\ntry_to_change_list_contents(outer_list)\nprint('after, outer_list =', outer_list)\n \n\n Output: \n\n before, outer_list = ['one', 'two', 'three']\ngot ['one', 'two', 'three']\nchanged to ['one', 'two', 'three', 'four']\nafter, outer_list = ['one', 'two', 'three', 'four']\n \n\n Since the parameter passed in is a reference to  outer_list , not a copy of it, we can use the mutating list methods to change it and have the changes reflected in the outer scope. \n\n Now let's see what happens when we try to change the reference that was passed in as a parameter: \n\n def try_to_change_list_reference(the_list):\n    print('got', the_list)\n    the_list = ['and', 'we', 'can', 'not', 'lie']\n    print('set to', the_list)\n\nouter_list = ['we', 'like', 'proper', 'English']\n\nprint('before, outer_list =', outer_list)\ntry_to_change_list_reference(outer_list)\nprint('after, outer_list =', outer_list)\n \n\n Output: \n\n before, outer_list = ['we', 'like', 'proper', 'English']\ngot ['we', 'like', 'proper', 'English']\nset to ['and', 'we', 'can', 'not', 'lie']\nafter, outer_list = ['we', 'like', 'proper', 'English']\n \n\n Since the  the_list  parameter was passed by value, assigning a new list to it had no effect that the code outside the method could see. The  the_list  was a copy of the  outer_list  reference, and we had  the_list  point to a new list, but there was no way to change where  outer_list  pointed. \n\n String - an immutable type \n\n It's immutable, so there's nothing we can do to change the contents of the string \n\n Now, let's try to change the reference \n\n def try_to_change_string_reference(the_string):\n    print('got', the_string)\n    the_string = 'In a kingdom by the sea'\n    print('set to', the_string)\n\nouter_string = 'It was many and many a year ago'\n\nprint('before, outer_string =', outer_string)\ntry_to_change_string_reference(outer_string)\nprint('after, outer_string =', outer_string)\n \n\n Output: \n\n before, outer_string = It was many and many a year ago\ngot It was many and many a year ago\nset to In a kingdom by the sea\nafter, outer_string = It was many and many a year ago\n \n\n Again, since the  the_string  parameter was passed by value, assigning a new string to it had no effect that the code outside the method could see. The  the_string  was a copy of the  outer_string  reference, and we had  the_string  point to a new string, but there was no way to change where  outer_string  pointed. \n\n I hope this clears things up a little. \n\n EDIT:  It's been noted that this doesn't answer the question that @David originally asked, \"Is there something I can do to pass the variable by actual reference?\". Let's work on that. \n\n How do we get around this? \n\n As @Andrea's answer shows, you could return the new value. This doesn't change the way things are passed in, but does let you get the information you want back out: \n\n def return_a_whole_new_string(the_string):\n    new_string = something_to_do_with_the_old_string(the_string)\n    return new_string\n\n# then you could call it like\nmy_string = return_a_whole_new_string(my_string)\n \n\n If you really wanted to avoid using a return value, you could create a class to hold your value and pass it into the function or use an existing class, like a list: \n\n def use_a_wrapper_to_simulate_pass_by_reference(stuff_to_change):\n    new_string = something_to_do_with_the_old_string(stuff_to_change[0])\n    stuff_to_change[0] = new_string\n\n# then you could call it like\nwrapper = [my_string]\nuse_a_wrapper_to_simulate_pass_by_reference(wrapper)\n\ndo_something_with(wrapper[0])\n \n\n Although this seems a little cumbersome. \n    ", "date_posted": "2017-04-03 02:13:38Z", "upvote": "\r\n            3367\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "1087720", "name": "random_user", "reputation_score": "788"}, "answer_comments": [{"stack_answer_id": "986145", "stack_answer_comment_id": "794601", "comment_content": "Then the same is in C, when you pass \"by reference\" you're actually passing ", "user_id": null}, {"stack_answer_id": "986145", "stack_answer_comment_id": "794645", "comment_content": "I'm not sure I understand your terms. I've been out of the C game for a while, but back when I was in it, there was no \"pass by reference\" - you could pass things, and it was always pass by value, so whatever was in the parameter list was copied. But sometimes the thing was a pointer, which one could follow to the piece of memory (primitive, array, struct, whatever), but you couldn't change the pointer that was copied from the outer scope - when you were done with the function, the original pointer still pointed to the same address. C++ introduced references, which behaved differently.", "user_id": null}, {"stack_answer_id": "986145", "stack_answer_comment_id": "8874950", "comment_content": "@Zac Bowling I don't really get how what you're saying is relevant, in a practical sense, to this answer. If a Python newcomer wanted to know about passing by ref/val, then the takeaway from this answer is: ", "user_id": null}, {"stack_answer_id": "986145", "stack_answer_comment_id": "9988567", "comment_content": "@CamJackson, you need a better example - numbers are also immutable objects in Python. Besides, wouldn't it be true to say that ", "user_id": null}, {"stack_answer_id": "986145", "stack_answer_comment_id": "10928887", "comment_content": "-1. The code shown is good, the explanation as to how is completely wrong.  See the answers by DavidCournapeau or DarenThomas for correct explanations as to why.", "user_id": null}]}, {"stack_answer_id": "8140747", "answer_content": "\r\n The problem comes from a misunderstanding of what variables are in Python. If you're used to most traditional languages, you have a mental model of what happens in the following sequence: \n\n a = 1\na = 2\n \n\n You believe that  a  is a memory location that stores the value  1 , then is updated to store the value  2 . That's not how things work in Python. Rather,  a  starts as a reference to an object with the value  1 , then gets reassigned as a reference to an object with the value  2 . Those two objects may continue to coexist even though  a  doesn't refer to the first one anymore; in fact they may be shared by any number of other references within the program. \n\n When you call a function with a parameter, a new reference is created that refers to the object passed in. This is separate from the reference that was used in the function call, so there's no way to update that reference and make it refer to a new object. In your example: \n\n def __init__(self):\n    self.variable = 'Original'\n    self.Change(self.variable)\n\ndef Change(self, var):\n    var = 'Changed'\n \n\n self.variable  is a reference to the string object  'Original' . When you call  Change  you create a second reference  var  to the object. Inside the function you reassign the reference  var  to a different string object  'Changed' , but the reference  self.variable  is separate and does not change. \n\n The only way around this is to pass a mutable object. Because both references refer to the same object, any changes to the object are reflected in both places. \n\n def __init__(self):         \n    self.variable = ['Original']\n    self.Change(self.variable)\n\ndef Change(self, var):\n    var[0] = 'Changed'\n \n    ", "date_posted": "2017-04-03 00:39:27Z", "upvote": "\r\n            836\r\n        ", "accepted": "No", "user": {"stack_user_id": "1087720", "name": "random_user", "reputation_score": "788"}, "answer_comments": [{"stack_answer_id": "8140747", "stack_answer_comment_id": "9996492", "comment_content": "Good succinct explanation. Your paragraph \"When you call a function...\" is one of the best explanations I've heard of the rather cryptic phrase that 'Python function parameters are references, passed by value.' I think if you understand that paragraph alone, everything else kind of just makes sense and flows as a logical conclusion from there. Then you just have to be aware of when you're creating a new object and when you're modifying an existing one.", "user_id": null}, {"stack_answer_id": "8140747", "stack_answer_comment_id": "13535104", "comment_content": "But how can you reassign the reference? I thought you can't change the address of 'var' but that your string \"Changed\" was now going to be stored in the 'var' memory address. Your description makes it seem like \"Changed\" and \"Original\" belong to different places in memory instead and you just switch 'var' to a different address. Is that correct?", "user_id": null}, {"stack_answer_id": "8140747", "stack_answer_comment_id": "13535380", "comment_content": "@Glassjawed, I think you're getting it. \"Changed\" and \"Original\" are two different string objects at different memory addresses and 'var' changes from pointing to one to pointing to the other.", "user_id": null}, {"stack_answer_id": "8140747", "stack_answer_comment_id": "85424727", "comment_content": "@TonySuffolk66 ", "user_id": null}, {"stack_answer_id": "8140747", "stack_answer_comment_id": "92716352", "comment_content": "@MinhTran in the simplest terms, a reference is something that \"refers\" to an object. The physical representation of that is most likely a pointer, but that's simply an implementation detail. It really is an abstract notion at heart.", "user_id": null}]}, {"stack_answer_id": "25670170", "answer_content": "\r\n I found the other answers rather long and complicated, so I created this simple diagram to explain the way Python treats variables and parameters.\n \n    ", "date_posted": "2016-05-25 15:30:05Z", "upvote": "\r\n            435\r\n        ", "accepted": "No", "user": {"stack_user_id": "3718878", "name": "Zenadix", "reputation_score": "13.9k"}, "answer_comments": [{"stack_answer_id": "25670170", "stack_answer_comment_id": "56900547", "comment_content": "lovely, makes it easy to spot the subtle diff that there is an intermediate assignment, not obvious to a casual onlooker. +1", "user_id": null}, {"stack_answer_id": "25670170", "stack_answer_comment_id": "62356762", "comment_content": "It doesn't matter if A is mutable or not. If you assign something different to B, ", "user_id": null}, {"stack_answer_id": "25670170", "stack_answer_comment_id": "62387810", "comment_content": "@Martijn You're right. I removed the part of the answer that mentions mutability. I don't think it can get any simpler now.", "user_id": null}, {"stack_answer_id": "25670170", "stack_answer_comment_id": "62388292", "comment_content": "Thanks for the update, much better! What confuses most people is assignment to a subscription; e.g. ", "user_id": null}, {"stack_answer_id": "25670170", "stack_answer_comment_id": "63811790", "comment_content": "\"A is assigned to B.\" Is that not ambiguous? I think in ordinary English that can mean either ", "user_id": null}]}, {"stack_answer_id": "986495", "answer_content": "\r\n It is neither pass-by-value or pass-by-reference - it is call-by-object. See this, by Fredrik Lundh: \n http://effbot.org/zone/call-by-object.htm \n Here is a significant quote: \n \n \"...variables [names] are  not  objects; they cannot be denoted by other variables or referred to by objects.\" \n \n In your example, when the  Change  method is called--a  namespace  is created for it; and  var  becomes a name, within that namespace, for the string object  'Original' . That object then has a name in two namespaces. Next,  var = 'Changed'  binds  var  to a new string object, and thus the method's namespace forgets about  'Original' . Finally, that namespace is forgotten, and the string  'Changed'  along with it. \n    ", "date_posted": "2021-05-30 16:36:04Z", "upvote": "\r\n            268\r\n        ", "accepted": "No", "user": {"stack_user_id": "701315", "name": "waxwing", "reputation_score": "117"}, "answer_comments": [{"stack_answer_id": "986495", "stack_answer_comment_id": "10494915", "comment_content": "I find it hard to buy. To me is just as Java, the parameters are pointers to objects in memory, and those pointers are passed via the stack, or registers.", "user_id": null}, {"stack_answer_id": "986495", "stack_answer_comment_id": "10518161", "comment_content": "This is not like java. One of the case where it is not the same is immutable objects. Think about the trivial function lambda x: x. Apply this for x = [1, 2, 3] and x = (1, 2, 3). In the first case, the returned value will be a copy of the input, and identical in the second case.", "user_id": null}, {"stack_answer_id": "986495", "stack_answer_comment_id": "18284481", "comment_content": "No, it's ", "user_id": null}, {"stack_answer_id": "986495", "stack_answer_comment_id": "19264776", "comment_content": "It is exactly the same as in Java. Object references are passed by value. Anyone who thinks differently should attach the Python code for a ", "user_id": null}, {"stack_answer_id": "986495", "stack_answer_comment_id": "25806292", "comment_content": "It is exactly the same as Java when you pass objects in Java. However, Java also have primitives, which are passed by copying the value of the primitive. Thus they differ in that case.", "user_id": null}]}, {"stack_answer_id": "986339", "answer_content": "\r\n Think of stuff being passed  by assignment  instead of by reference/by value. That way, it is always clear, what is happening as long as you understand what happens during the normal assignment. \n\n So, when passing a list to a function/method, the list is assigned to the parameter name. Appending to the list will result in the list being modified. Reassigning the list  inside  the function will not change the original list, since: \n\n a = [1, 2, 3]\nb = a\nb.append(4)\nb = ['a', 'b']\nprint a, b      # prints [1, 2, 3, 4] ['a', 'b']\n \n\n Since immutable types cannot be modified, they  seem  like being passed by value - passing an int into a function means assigning the int to the function's parameter. You can only ever reassign that, but it won't change the original variables value. \n    ", "date_posted": "2019-11-20 04:37:51Z", "upvote": "\r\n            212\r\n        ", "accepted": "No", "user": {"stack_user_id": "5002179", "name": "MurugananthamS", "reputation_score": "2,351"}, "answer_comments": [{"stack_answer_id": "986339", "stack_answer_comment_id": "81843915", "comment_content": "At first glance this answer seems to sidestep the original question. After a second read I've come to realize that this makes the matter quite clear. A good follow up to this \"name assignment\" concept may be found  here: ", "user_id": null}]}, {"stack_answer_id": "21700609", "answer_content": "\r\n There are no variables in Python \n\n The key to understanding parameter passing is to stop thinking about \"variables\". There are names and objects in Python and together they\nappear like variables, but it is useful to always distinguish the three. \n\n \n Python has names and objects. \n Assignment binds a name to an object. \n Passing an argument into a function also binds a name (the parameter name of the function) to an object. \n \n\n That is all there is to it. Mutability is irrelevant to this question. \n\n Example: \n\n a = 1\n \n\n This binds the name  a  to an object of type integer that holds the value 1. \n\n b = x\n \n\n This binds the name  b  to the same object that the name  x  is currently bound to.\nAfterward, the name  b  has nothing to do with the name  x  anymore. \n\n See sections  3.1  and  4.2  in the Python 3 language reference. \n\n How to read the example in the question \n\n In the code shown in the question, the statement  self.Change(self.variable)  binds the name  var  (in the scope of function  Change ) to the object that holds the value  'Original'  and the assignment  var = 'Changed'  (in the body of function  Change ) assigns that same name again: to some other object (that happens to hold a string as well but could have been something else entirely). \n\n How to pass by reference \n\n So if the thing you want to change is a mutable object, there is no problem, as everything is effectively passed by reference. \n\n If it is an  immutable  object (e.g. a bool, number, string), the way to go is to wrap it in a mutable object. \nThe quick-and-dirty solution for this is a one-element list (instead of  self.variable , pass  [self.variable]  and in the function modify  var[0] ). \nThe more  pythonic  approach would be to introduce a trivial, one-attribute class. The function receives an instance of the class and manipulates the attribute. \n    ", "date_posted": "2020-04-27 10:17:30Z", "upvote": "\r\n            91\r\n        ", "accepted": "No", "user": {"stack_user_id": "11024053", "name": "faressalem", "reputation_score": "544"}, "answer_comments": [{"stack_answer_id": "21700609", "stack_answer_comment_id": "37695746", "comment_content": "\"Python has no variables\" is a silly and confusing slogan, and I really wish people would stop saying it... :(   The rest of this answer is good!", "user_id": null}, {"stack_answer_id": "21700609", "stack_answer_comment_id": "37747455", "comment_content": "It may be shocking, but it is not silly. And I don't think it is confusing either: It hopefully opens up the recipient's mind for the explanation that is coming and puts her in a useful \"I wonder what they have instead of variables\" attitude. (Yes, your mileage may vary.)", "user_id": null}, {"stack_answer_id": "21700609", "stack_answer_comment_id": "37755336", "comment_content": "would you also say that Javascript has no variables? They work the same as Python's.  Also, Java, Ruby, PHP, ....   I think a better teaching technique is, \"Python's variables work differently than C's.\"", "user_id": null}, {"stack_answer_id": "21700609", "stack_answer_comment_id": "41878922", "comment_content": "Yes, Java has variables. So does Python, and JavaScript, Ruby, PHP, etc.  You wouldn't say in Java that ", "user_id": null}, {"stack_answer_id": "21700609", "stack_answer_comment_id": "53893736", "comment_content": "The concept of \"variable\" is complex and often vague: ", "user_id": null}]}, {"stack_answer_id": "15697476", "answer_content": "\r\n Effbot (aka Fredrik Lundh) has described Python's variable passing style as call-by-object:   http://effbot.org/zone/call-by-object.htm \n\n Objects are allocated on the heap and pointers to them can be passed around anywhere.   \n\n \n When you make an assignment such as  x = 1000 , a dictionary entry is created that maps the string \"x\" in the current namespace to a pointer to the integer object containing one thousand.    \n When you update \"x\" with  x = 2000 , a new integer object is created and the dictionary is updated to point at the new object.  The old one thousand object is unchanged (and may or may not be alive depending on whether anything else refers to the object). \n When you do a new assignment such as  y = x , a new dictionary entry \"y\" is created that points to the same object as the entry for \"x\". \n Objects like strings and integers are  immutable .  This simply means that there are no methods that can change the object after it has been created.  For example, once the integer object one-thousand is created, it will never change.  Math is done by creating new integer objects. \n Objects like lists are  mutable .  This means that the contents of the object can be changed by anything pointing to the object.  For example,  x = []; y = x; x.append(10); print y  will print  [10] .  The empty list was created.  Both \"x\" and \"y\" point to the same list.  The  append  method mutates (updates) the list object (like adding a record to a database) and the result is visible to both \"x\" and \"y\" (just as a database update would be visible to every connection to that database). \n \n\n Hope that clarifies the issue for you.  \n    ", "date_posted": "2013-03-29 04:41:44Z", "upvote": "\r\n            84\r\n        ", "accepted": "No", "user": {"stack_user_id": "424499", "name": "Raymond Hettinger", "reputation_score": "205k"}, "answer_comments": [{"stack_answer_id": "15697476", "stack_answer_comment_id": "31747271", "comment_content": "I really appreciate learning about this from a developer. Is it true that the ", "user_id": null}, {"stack_answer_id": "15697476", "stack_answer_comment_id": "31758965", "comment_content": "@HonestAbe Yes, in CPython the ", "user_id": null}]}, {"stack_answer_id": "12440140", "answer_content": "\r\n Technically,  Python always uses pass by reference values . I am going to repeat  my other answer  to support my statement. \n\n Python always uses pass-by-reference values. There isn't any exception. Any variable assignment means copying the reference value. No exception. Any variable is the name bound to the reference value. Always. \n\n You can think about a reference value as the address of the target object. The address is automatically dereferenced when used. This way, working with the reference value, it seems you work directly with the target object. But there always is a reference in between, one step more to jump to the target. \n\n Here is the example that proves that Python uses passing by reference: \n\n \n\n If the argument was passed by value, the outer  lst  could not be modified. The green are the target objects (the black is the value stored inside, the red is the object type), the yellow is the memory with the reference value inside -- drawn as the arrow. The blue solid arrow is the reference value that was passed to the function (via the dashed blue arrow path). The ugly dark yellow is the internal dictionary. (It actually could be drawn also as a green ellipse. The colour and the shape only says it is internal.) \n\n You can use the  id()  built-in function to learn what the reference value is (that is, the address of the target object). \n\n In compiled languages, a variable is a memory space that is able to capture the value of the type. In Python, a variable is a name (captured internally as a string) bound to the reference variable that holds the reference value to the target object. The name of the variable is the key in the internal dictionary, the value part of that dictionary item stores the reference value to the target. \n\n Reference values are hidden in Python. There isn't any explicit user type for storing the reference value. However, you can use a list element (or element in any other suitable container type) as the reference variable, because all containers do store the elements also as references to the target objects. In other words, elements are actually not contained inside the container -- only the references to elements are. \n    ", "date_posted": "2017-05-23 12:18:21Z", "upvote": "\r\n            66\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": [{"stack_answer_id": "12440140", "stack_answer_comment_id": "17197207", "comment_content": "Actually this is confirmed its pass by reference value. +1 for this answer although the example wasnt good.", "user_id": null}, {"stack_answer_id": "12440140", "stack_answer_comment_id": "19264948", "comment_content": "Inventing new terminology (such as \"pass by reference value\" or \"call by object\" is not helpful). \"Call by (value|reference|name)\" are standard terms. \"reference\" is a standard term. Passing references by value accurately describes the behavior of Python, Java, and a host of other languages, using standard terminology.", "user_id": null}, {"stack_answer_id": "12440140", "stack_answer_comment_id": "19270112", "comment_content": "@cayhorstmann: The problem is that ", "user_id": null}, {"stack_answer_id": "12440140", "stack_answer_comment_id": "31746972", "comment_content": "I like this answer, but you might consider if the example is really helping or hurting the flow. Also, if you replaced 'reference value' with 'object reference' you would be using terminology that we could consider 'official', as seen here: ", "user_id": null}, {"stack_answer_id": "12440140", "stack_answer_comment_id": "31841961", "comment_content": "There is a footnote indicated at the end of that quote, which reads: ", "user_id": null}]}, {"stack_answer_id": "6963425", "answer_content": "\r\n A simple trick I normally use is to just wrap it in a list: \n\n def Change(self, var):\n    var[0] = 'Changed'\n\nvariable = ['Original']\nself.Change(variable)      \nprint variable[0]\n \n\n (Yeah I know this can be inconvenient, but sometimes it is simple enough to do this.) \n    ", "date_posted": "2011-08-08 10:39:48Z", "upvote": "\r\n            56\r\n        ", "accepted": "No", "user": {"stack_user_id": "381083", "name": "AmanicA", "reputation_score": "4,352"}, "answer_comments": [{"stack_answer_id": "6963425", "stack_answer_comment_id": "40468476", "comment_content": "+1 for small amount of text giving the essential workaround to the problem of Python not having pass-by-reference. (As a follow-on comment/question that fits here as well as anywhere on this page: It's not clear to my why python can't provide a \"ref\" keyword like C# does, that simply wraps the caller's argument in a list like this, and treat references to the argument within the function as the 0th element of the list.)", "user_id": null}, {"stack_answer_id": "6963425", "stack_answer_comment_id": "44877350", "comment_content": "Nice. To pass by ref, wrap in [ ]'s.", "user_id": null}]}, {"stack_answer_id": "3127336", "answer_content": "\r\n (edit - Blair has updated his enormously popular answer so that it is now accurate) \n\n I think it is important to note that the current post with the most votes (by Blair Conrad), while being correct with respect to its result, is misleading and is borderline incorrect based on its definitions.  While there are many languages (like C) that allow the user to either pass by reference or pass by value, Python is not one of them. \n\n David Cournapeau's answer points to the real answer and explains why the behavior in Blair Conrad's post seems to be correct while the definitions are not. \n\n To the extent that Python is pass by value, all languages are pass by value since some piece of data (be it a \"value\" or a \"reference\") must be sent. However, that does not mean that Python is pass by value in the sense that a C programmer would think of it. \n\n If you want the behavior, Blair Conrad's answer is fine.  But if you want to know the nuts and bolts of why Python is neither pass by value or pass by reference, read David Cournapeau's answer. \n    ", "date_posted": "2015-10-09 15:00:42Z", "upvote": "\r\n            39\r\n        ", "accepted": "No", "user": {"stack_user_id": "377366", "name": "KobeJohn", "reputation_score": "7,128"}, "answer_comments": [{"stack_answer_id": "3127336", "stack_answer_comment_id": "19264866", "comment_content": "It is simply not true that all languages are call by value. In C++ or Pascal (and surely many others that I don't know), you have call by reference. For example, in C++, ", "user_id": null}, {"stack_answer_id": "3127336", "stack_answer_comment_id": "53903706", "comment_content": "I thought I had replied to this long ago but I don't see it. For completeness - cayhorstmann misunderstood my answer. I was not saying everything is call by value ", "user_id": null}]}, {"stack_answer_id": "986335", "answer_content": "\r\n You got some really good answers here. \n\n x = [ 2, 4, 4, 5, 5 ]\nprint x  # 2, 4, 4, 5, 5\n\ndef go( li ) :\n  li = [ 5, 6, 7, 8 ]  # re-assigning what li POINTS TO, does not\n  # change the value of the ORIGINAL variable x\n\ngo( x ) \nprint x  # 2, 4, 4, 5, 5  [ STILL! ]\n\n\nraw_input( 'press any key to continue' )\n \n    ", "date_posted": "2012-01-27 04:28:48Z", "upvote": "\r\n            28\r\n        ", "accepted": "No", "user": {"stack_user_id": "1129194", "name": "Alex L", "reputation_score": "8,306"}, "answer_comments": [{"stack_answer_id": "986335", "stack_answer_comment_id": "37877580", "comment_content": "yea, however if you do   x = [ 2, 4, 4, 5, 5],  y = x,  X[0] = 1 , print x # [1, 4 ,4, 5, 5]  print y # [1, 4, 4, 5, 5]", "user_id": null}, {"stack_answer_id": "986335", "stack_answer_comment_id": "121249518", "comment_content": "X[0]   or x[0] ? don't get it", "user_id": null}]}, {"stack_answer_id": "986044", "answer_content": "\r\n In this case the variable titled  var  in the method  Change  is assigned a reference to  self.variable , and you immediately assign a string to  var . It's no longer pointing to  self.variable . The following code snippet shows what would happen if you modify the data structure pointed to by  var  and  self.variable , in this case a list: \n\n >>> class PassByReference:\n...     def __init__(self):\n...         self.variable = ['Original']\n...         self.change(self.variable)\n...         print self.variable\n...         \n...     def change(self, var):\n...         var.append('Changed')\n... \n>>> q = PassByReference()\n['Original', 'Changed']\n>>> \n \n\n I'm sure someone else could clarify this further. \n    ", "date_posted": "2009-06-12 10:39:59Z", "upvote": "\r\n            23\r\n        ", "accepted": "No", "user": {"stack_user_id": "2576", "name": "Mike Mazur", "reputation_score": "2,479"}, "answer_comments": []}, {"stack_answer_id": "29293411", "answer_content": "\r\n Python\u2019s pass-by-assignment scheme isn\u2019t quite the same as C++\u2019s reference parameters option, but it turns out to be very similar to the argument-passing model of the C language (and others) in practice: \n\n \n Immutable arguments are effectively passed \u201c by value .\u201d Objects such as integers and strings are passed by object reference instead of by copying, but because you can\u2019t change immutable objects in place anyhow, the effect is much like making a copy. \n Mutable arguments are effectively passed \u201c by pointer .\u201d Objects such as lists\nand dictionaries are also passed by object reference, which is similar to the way C\npasses arrays as pointers\u2014mutable objects can be changed in place in the function,\nmuch like C arrays. \n \n    ", "date_posted": "2015-03-27 04:38:18Z", "upvote": "\r\n            23\r\n        ", "accepted": "No", "user": {"stack_user_id": "1112163", "name": "ajknzhol", "reputation_score": "6,116"}, "answer_comments": []}, {"stack_answer_id": "25810863", "answer_content": "\r\n A lot of insights in answers here, but i think an additional point is not clearly mentioned here explicitly.   Quoting from python documentation  https://docs.python.org/2/faq/programming.html#what-are-the-rules-for-local-and-global-variables-in-python    \n\n \"In Python, variables that are only referenced inside a function are implicitly global. If a variable is assigned a new value anywhere within the function\u2019s body, it\u2019s assumed to be a local. If a variable is ever assigned a new value inside the function, the variable is implicitly local, and you need to explicitly declare it as \u2018global\u2019.\nThough a bit surprising at first, a moment\u2019s consideration explains this. On one hand, requiring global for assigned variables provides a bar against unintended side-effects. On the other hand, if global was required for all global references, you\u2019d be using global all the time. You\u2019d have to declare as global every reference to a built-in function or to a component of an imported module. This clutter would defeat the usefulness of the global declaration for identifying side-effects.\" \n\n Even when passing a mutable object to a function this still applies. And to me clearly explains the reason for the difference in behavior between assigning to the object and operating on the object in the function. \n\n def test(l):\n    print \"Received\", l , id(l)\n    l = [0, 0, 0]\n    print \"Changed to\", l, id(l)  # New local object created, breaking link to global l\n\nl= [1,2,3]\nprint \"Original\", l, id(l)\ntest(l)\nprint \"After\", l, id(l)\n \n\n gives: \n\n Original [1, 2, 3] 4454645632\nReceived [1, 2, 3] 4454645632\nChanged to [0, 0, 0] 4474591928\nAfter [1, 2, 3] 4454645632\n \n\n The assignment to an global variable that is not declared global therefore creates a new local object and breaks the link to the original object. \n    ", "date_posted": "2014-09-29 07:12:10Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "2107677", "name": "Joop", "reputation_score": "7,374"}, "answer_comments": [{"stack_answer_id": "25810863", "stack_answer_comment_id": "128530353", "comment_content": "+1 good answer, this mentioned what I was thinking. I was quite surprised when no one mentioned this. If no assignment is made, the alias and the original are one, but when we make a re-assignment, the link is broken, and a new local object is created inside the function.", "user_id": null}]}, {"stack_answer_id": "21684541", "answer_content": "\r\n As you can state you need to have a mutable object, but let me suggest you to check over the global variables as they can help you or even solve this kind of issue! \n\n http://docs.python.org/3/faq/programming.html#what-are-the-rules-for-local-and-global-variables-in-python \n\n example: \n\n >>> def x(y):\n...     global z\n...     z = y\n...\n\n>>> x\n<function x at 0x00000000020E1730>\n>>> y\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'y' is not defined\n>>> z\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'z' is not defined\n\n>>> x(2)\n>>> x\n<function x at 0x00000000020E1730>\n>>> y\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'y' is not defined\n>>> z\n2\n \n    ", "date_posted": "2016-08-09 02:23:54Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "3739391", "name": "John Smith", "reputation_score": "7,048"}, "answer_comments": [{"stack_answer_id": "21684541", "stack_answer_comment_id": "37922353", "comment_content": "I was tempted to post a similar response- the original questioner may not have known that what he wanted was in fact to use a global variable, shared among functions. Here's the link I would have shared: ", "user_id": null}]}, {"stack_answer_id": "12686527", "answer_content": "\r\n Here is the simple (I hope) explanation of the concept  pass by object  used in Python. \nWhenever you pass an object to the function, the object itself is passed (object in Python is actually what you'd call a value in other programming languages) not the reference to this object. In other words, when you call: \n\n def change_me(list):\n   list = [1, 2, 3]\n\nmy_list = [0, 1]\nchange_me(my_list)\n \n\n The actual object - [0, 1] (which would be called a value in other programming languages) is being passed. So in fact the function  change_me  will try to do something like: \n\n [0, 1] = [1, 2, 3]\n \n\n which obviously will not change the object passed to the function. If the function looked like this: \n\n def change_me(list):\n   list.append(2)\n \n\n Then the call would result in: \n\n [0, 1].append(2)\n \n\n which obviously will change the object.  This answer  explains it well. \n    ", "date_posted": "2017-05-23 11:54:59Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": [{"stack_answer_id": "12686527", "stack_answer_comment_id": "17172121", "comment_content": "The problem is that the assignment does something else than you expect. The ", "user_id": null}, {"stack_answer_id": "12686527", "stack_answer_comment_id": "36152119", "comment_content": "@pepr objects aren't literals. They are objects. The only way to talk about them is giving them some names. That's why it's so simple once you grasp it, but enormously complicated to explain. :-)", "user_id": null}, {"stack_answer_id": "12686527", "stack_answer_comment_id": "36239341", "comment_content": "@Veky: I am aware of that. Anyway, the list literal is converted to the list object. Actually, any object in Python can exist without a name, and it can be used even when not given any name. And you can think about them as about anonymous objects. Think about objects being the elements of a lists. They need not a name. You can access them through indexing of or iterating through the list. Anyway, I insist on ", "user_id": null}, {"stack_answer_id": "12686527", "stack_answer_comment_id": "36242700", "comment_content": "@pepr: I don't necessarily mean Python-definition names, just ordinary names. Of course ", "user_id": null}, {"stack_answer_id": "12686527", "stack_answer_comment_id": "36361122", "comment_content": "Argh. My English is obviously much worse than my Python. :-) I'll try just once more. I just said you have to give object some names just to talk about them. By that \"names\" I didn't mean \"names as defined by Python\". I know Python mechanisms, don't worry.", "user_id": null}]}, {"stack_answer_id": "35260424", "answer_content": "\r\n Aside from all the great explanations on how this stuff works in Python, I don't see a simple suggestion for the problem. As you seem to do create objects and instances, the pythonic way of handling instance variables and changing them is the following: \n\n class PassByReference:\n    def __init__(self):\n        self.variable = 'Original'\n        self.Change()\n        print self.variable\n\n    def Change(self):\n        self.variable = 'Changed'\n \n\n In instance methods, you normally refer to  self  to access instance attributes. It is normal to set instance attributes in  __init__  and read or change them in instance methods. That is also why you pass  self  als the first argument to  def Change . \n\n Another solution would be to create a static method like this: \n\n class PassByReference:\n    def __init__(self):\n        self.variable = 'Original'\n        self.variable = PassByReference.Change(self.variable)\n        print self.variable\n\n    @staticmethod\n    def Change(var):\n        var = 'Changed'\n        return var\n \n    ", "date_posted": "2016-08-09 02:23:27Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "3739391", "name": "John Smith", "reputation_score": "7,048"}, "answer_comments": []}, {"stack_answer_id": "38834546", "answer_content": "\r\n I used the following method to quickly convert a couple of Fortran codes to Python.  True, it's not pass by reference as the original question was posed, but is a simple work around in some cases. \n\n a=0\nb=0\nc=0\ndef myfunc(a,b,c):\n    a=1\n    b=2\n    c=3\n    return a,b,c\n\na,b,c = myfunc(a,b,c)\nprint a,b,c\n \n    ", "date_posted": "2016-08-09 02:22:25Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "3739391", "name": "John Smith", "reputation_score": "7,048"}, "answer_comments": [{"stack_answer_id": "38834546", "stack_answer_comment_id": "108869270", "comment_content": "Yes, this solves the 'pass by reference' in my use case as well. I have a function that basically cleans up values in a ", "user_id": null}, {"stack_answer_id": "38834546", "stack_answer_comment_id": "125476205", "comment_content": "@kasimir this is one of the things I really love about Python.  Because it's so easy to return multiple values as a tuple, it's very rare to even need to pass by reference.", "user_id": null}, {"stack_answer_id": "38834546", "stack_answer_comment_id": "125491812", "comment_content": "@MarkRansom me too! I did a lot of PHP programming and passing by reference is quite common there, but can be a pain when trying to debug. Python lets you avoid this, so yet another reason for me to love Python more :-)", "user_id": null}]}, {"stack_answer_id": "36775894", "answer_content": "\r\n There is a little trick to pass an object by reference, even though the language doesn't make it possible. It works in Java too, it's the list with one item. ;-) \n\n class PassByReference:\n    def __init__(self, name):\n        self.name = name\n\ndef changeRef(ref):\n    ref[0] = PassByReference('Michael')\n\nobj = PassByReference('Peter')\nprint obj.name\n\np = [obj] # A pointer to obj! ;-)\nchangeRef(p)\n\nprint p[0].name # p->name\n \n\n It's an ugly hack, but it works. ;-P \n    ", "date_posted": "2016-04-21 16:47:42Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "3021309", "name": "itmuckel", "reputation_score": "1,213"}, "answer_comments": [{"stack_answer_id": "36775894", "stack_answer_comment_id": "92715930", "comment_content": " is reference to a mutable list object which in turn stores the object ", "user_id": null}, {"stack_answer_id": "36775894", "stack_answer_comment_id": "92715951", "comment_content": "So now, the references ", "user_id": null}, {"stack_answer_id": "36775894", "stack_answer_comment_id": "92715979", "comment_content": "You have ", "user_id": null}, {"stack_answer_id": "36775894", "stack_answer_comment_id": "92716018", "comment_content": "Point being, I don't agree that it's a ", "user_id": null}]}, {"stack_answer_id": "40345432", "answer_content": "\r\n given the way python handles values and references to them, the only way you can reference an arbitrary instance attribute is by name: \n\n class PassByReferenceIsh:\n    def __init__(self):\n        self.variable = 'Original'\n        self.change('variable')\n        print self.variable\n\n    def change(self, var):\n        self.__dict__[var] = 'Changed'\n \n\n in real code you would, of course, add error checking on the dict lookup. \n    ", "date_posted": "2016-10-31 15:33:23Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "4761972", "name": "mARK bLOORE", "reputation_score": "158"}, "answer_comments": []}, {"stack_answer_id": "46136730", "answer_content": "\r\n Since your example happens to be object-oriented, you could make the following change to achieve a similar result: \n\n class PassByReference:\n    def __init__(self):\n        self.variable = 'Original'\n        self.change('variable')\n        print(self.variable)\n\n    def change(self, var):\n        setattr(self, var, 'Changed')\n\n# o.variable will equal 'Changed'\no = PassByReference()\nassert o.variable == 'Changed'\n \n    ", "date_posted": "2017-09-10 02:19:53Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "1639273", "name": "Jesse Hogan", "reputation_score": "2,917"}, "answer_comments": [{"stack_answer_id": "46136730", "stack_answer_comment_id": "85556278", "comment_content": "Although this works. It is not pass by reference. It is 'pass by object reference'.", "user_id": null}]}, {"stack_answer_id": "56069248", "answer_content": "\r\n Since it seems to be nowhere mentioned an approach to simulate references as known from e.g. C++ is to use an \"update\" function and pass that instead of the actual variable (or rather, \"name\"): \n\n def need_to_modify(update):\n    update(42) # set new value 42\n    # other code\n\ndef call_it():\n    value = 21\n    def update_value(new_value):\n        nonlocal value\n        value = new_value\n    need_to_modify(update_value)\n    print(value) # prints 42\n \n\n This is mostly useful for \"out-only references\" or in a situation with multiple threads / processes (by making the update function thread / multiprocessing safe). \n\n Obviously the above does not allow  reading  the value, only updating it. \n    ", "date_posted": "2019-05-10 00:37:33Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "1116364", "name": "Daniel Jour", "reputation_score": "15.6k"}, "answer_comments": []}, {"stack_answer_id": "55992875", "answer_content": "\r\n Since dictionaries are passed by reference, you can use a dict variable to store any referenced values inside it. \n # returns the result of adding numbers `a` and `b`\ndef AddNumbers(a, b, ref): # using a dict for reference\n    result = a + b\n    ref['multi'] = a * b # reference the multi. ref['multi'] is number\n    ref['msg'] = \"The result: \" + str(result) + \" was nice!\"\n    return result\n\nnumber1 = 5\nnumber2 = 10\nref = {} # init a dict like that so it can save all the referenced values. this is because all dictionaries are passed by reference, while strings and numbers do not.\n\nsum = AddNumbers(number1, number2, ref)\nprint(\"sum: \", sum)             # the returned value\nprint(\"multi: \", ref['multi'])  # a referenced value\nprint(\"msg: \", ref['msg'])      # a referenced value\n \n    ", "date_posted": "2021-06-01 08:29:19Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "2718972", "name": "Liakos", "reputation_score": "424"}, "answer_comments": []}, {"stack_answer_id": "39054982", "answer_content": "\r\n While pass by reference is nothing that fits well into python and should be rarely used there are some workarounds that actually can work to get the object currently assigned to a local variable or even reassign a local variable from inside of a called function. \n\n The basic idea is to have a function that can do that access and can be passed as object into other functions or stored in a class. \n\n One way is to use  global  (for global variables) or  nonlocal  (for local variables in a function) in a wrapper function. \n\n def change(wrapper):\n    wrapper(7)\n\nx = 5\ndef setter(val):\n    global x\n    x = val\nprint(x)\n \n\n The same idea works for reading and  del eting a variable. \n\n For just reading there is even a shorter way of just using  lambda: x  which returns a callable that when called returns the current value of x. This is somewhat like \"call by name\" used in languages in the distant past. \n\n Passing 3 wrappers to access a variable is a bit unwieldy so those can be wrapped into a class that has a proxy attribute: \n\n class ByRef:\n    def __init__(self, r, w, d):\n        self._read = r\n        self._write = w\n        self._delete = d\n    def set(self, val):\n        self._write(val)\n    def get(self):\n        return self._read()\n    def remove(self):\n        self._delete()\n    wrapped = property(get, set, remove)\n\n# left as an exercise for the reader: define set, get, remove as local functions using global / nonlocal\nr = ByRef(get, set, remove)\nr.wrapped = 15\n \n\n Pythons \"reflection\" support makes it possible to get a object that is capable of reassigning a name/variable in a given scope without defining functions explicitly in that scope: \n\n class ByRef:\n    def __init__(self, locs, name):\n        self._locs = locs\n        self._name = name\n    def set(self, val):\n        self._locs[self._name] = val\n    def get(self):\n        return self._locs[self._name]\n    def remove(self):\n        del self._locs[self._name]\n    wrapped = property(get, set, remove)\n\ndef change(x):\n    x.wrapped = 7\n\ndef test_me():\n    x = 6\n    print(x)\n    change(ByRef(locals(), \"x\"))\n    print(x)\n \n\n Here the  ByRef  class wraps a dictionary access. So attribute access to  wrapped  is translated to a item access in the passed dictionary. By passing the result of the builtin  locals  and the name of a local variable this ends up accessing a local variable. The python documentation as of 3.5 advises that changing the dictionary might not work but it seems to work for me. \n    ", "date_posted": "2016-08-20 14:02:37Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "4973666", "name": "textshell", "reputation_score": "1,436"}, "answer_comments": []}, {"stack_answer_id": "50157212", "answer_content": "\r\n You can merely use  an empty class  as an instance to store reference objects because internally object attributes are stored in an instance dictionary. See the example. \n\n class RefsObj(object):\n    \"A class which helps to create references to variables.\"\n    pass\n\n...\n\n# an example of usage\ndef change_ref_var(ref_obj):\n    ref_obj.val = 24\n\nref_obj = RefsObj()\nref_obj.val = 1\nprint(ref_obj.val) # or print ref_obj.val for python2\nchange_ref_var(ref_obj)\nprint(ref_obj.val)\n \n    ", "date_posted": "2018-05-03 14:14:11Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "749288", "name": "sergzach", "reputation_score": "6,311"}, "answer_comments": []}, {"stack_answer_id": "54315603", "answer_content": "\r\n Pass-By-Reference in Python is quite different from the concept of pass by reference in C++/Java.  \n\n \n Java&C#:  primitive types(include string)pass by value(copy), Reference type is passed by reference(address copy) so all changes made in the parameter in the called function are visible to the caller. \n C++:  Both pass-by-reference or pass-by-value are allowed. If a parameter is passed by reference, you can either modify it or not depending upon whether the parameter was passed as const or not. However, const or not, the parameter maintains the reference to the object and reference cannot be assigned to point to a different object within the called function. \n Python:  \nPython is \u201cpass-by-object-reference\u201d, of which it is often said: \u201cObject references are passed by value.\u201d[Read here] 1 . Both the caller and the function refer to the same object but the parameter in the function is a new variable which is just holding a copy of the object in the caller. Like C++, a parameter can be either modified or not in function - This depends upon the type of object passed. eg; An immutable object type cannot be modified in the called function whereas a mutable object can be either updated or re-initialized. A crucial difference between updating or re-assigning/re-initializing the mutable variable is that updated value gets reflected back in the called function whereas the reinitialized value does not. Scope of any assignment of new object to a mutable variable is local to the function in the python. Examples provided by @blair-conrad are great to understand this. \n \n    ", "date_posted": "2019-06-13 04:11:38Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "4877830", "name": "haidi ju", "reputation_score": "5"}, "answer_comments": [{"stack_answer_id": "54315603", "stack_answer_comment_id": "102208338", "comment_content": "Old but I feel obliged to correct it. Strings are passed by reference in both Java and C#, NOT by value", "user_id": null}, {"stack_answer_id": "54315603", "stack_answer_comment_id": "123598152", "comment_content": "No. Everything is passed by value in c#. It is that the value of variable that is an object in c# is exactly and heap ID/address of the object. So when you set something in a function to a new object you set the variable in function to address. Passing by reference means passing an adres to value which is an address to the value for struct types but address to pointer in case of objects.", "user_id": null}, {"stack_answer_id": "54315603", "stack_answer_comment_id": "125013192", "comment_content": "i Know you are expert when you said address copy (that why ref exist) which pass the reference it self not the copy in C#", "user_id": null}]}, {"stack_answer_id": "62970753", "answer_content": "\r\n I am new to Python, started yesterday (though I have been programming for 45 years). \n I came here because I was writing a function where I wanted to have two so called out-parameters. If it would have been only one out-parameter, I wouldn't get hung up right now on checking how reference/value works in Python. I would just have used the return value of the function instead. But since I needed  two  such out-parameters I felt I needed to sort it out. \n In this post I am going to show how I solved my situation. Perhaps others coming here can find it valuable, even though it is not exactly an answer to the topic question. Experienced Python programmers of course already know about the solution I used, but it was new to me. \n From the answers here I could quickly see that Python works a bit like Javascript in this regard, and that you need to use workarounds if you want the reference functionality. \n But then I found something neat in Python that I don't think I have seen in other languages before, namely that you can return more than one value from a function, in a simple comma separated way, like this: \n def somefunction(p):\n    a=p+1\n    b=p+2\n    c=-p\n    return a, b, c\n \n and that you can handle that on the calling side similarly, like this \n x, y, z = somefunction(w)\n \n That was good enough for me and I was satisfied. No need to use some workaround. \n In other languages you can of course also return many values, but then usually in the from of an object, and you need to adjust the calling side accordingly. \n The Python way of doing it was nice and simple. \n If you want to mimic  by reference  even more, you could do as follows: \n def somefunction(a, b, c):\n    a = a * 2\n    b = b + a\n    c = a * b * c\n    return a, b, c\n\nx = 3\ny = 5\nz = 10\nprint(F\"Before : {x}, {y}, {z}\")\n\nx, y, z = somefunction(x, y, z)\n\nprint(F\"After  : {x}, {y}, {z}\")\n \n which gives this result \n \nBefore : 3, 5, 10  \nAfter  : 6, 11, 660  \n \n    ", "date_posted": "2020-07-21 20:38:03Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "1765710", "name": "Magnus", "reputation_score": "1,398"}, "answer_comments": [{"stack_answer_id": "62970753", "stack_answer_comment_id": "112078719", "comment_content": "\"But then I found something neat in Python that I don't think I have seen in other languages before, namely that you can return more than one value from a function\" No, you can't. What you are doing is returning a single value, a ", "user_id": null}, {"stack_answer_id": "62970753", "stack_answer_comment_id": "112092512", "comment_content": "@juanpa.arrivillaga, yes, I was aware of that when I wrote my answer, I had just read about it. But I just described the whole thing in a practical way without going into the details of how it works and add unnecessary length to my answer. You can indeed return multiple values from a function, if it is done in an object or similar, like in a tuple (which in Python is taken care of in the neat way I showed). When I order things from a company, they can send me multiple things, even if it is all in one package.", "user_id": null}]}, {"stack_answer_id": "65935869", "answer_content": "\r\n alternatively you could use ctypes witch would look something like this \n import ctypes\n\ndef f(a):\n    a.value=2398 ## resign the value in a function\n\na = ctypes.c_int(0)\nprint(\"pre f\", a)\nf(a)\nprint(\"post f\", a)\n \n as a is a c int and not a python integer and apperently passed by reference. however you have to be carefull as strange things could happen and is therefor not advised \n    ", "date_posted": "2021-01-28 11:06:18Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "14826616", "name": "Julian wandhoven", "reputation_score": "260"}, "answer_comments": []}, {"stack_answer_id": "66819159", "answer_content": "\r\n Most likely not the most reliable method but this works, keep in mind that you are overloading the built-in str function which is typically something you don't want to do: \n import builtins\n\nclass sstr(str):\n    def __str__(self):\n        if hasattr(self, 'changed'):\n            return self.changed\n\n        return self\n\n    def change(self, value):\n        self.changed = value\n\nbuiltins.str = sstr\n\ndef change_the_value(val):\n    val.change('After')\n\nval = str('Before')\nprint (val)\nchange_the_value(val)\nprint (val)\n \n    ", "date_posted": "2021-03-26 14:49:25Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "5925257", "name": "Jop Knoppers", "reputation_score": "611"}, "answer_comments": []}, {"stack_answer_id": "68167731", "answer_content": "\r\n What about  dataclasses ? Also, it allows you to apply type restriction (aka \"type hint\"). \n from dataclasses import dataclass\n\n@dataclass\nclass Holder:\n    obj: your_type # Need any type? Use \"obj: object\" then.\n\ndef foo(ref: Holder):\n    ref.obj = do_something()\n \n I agree with folks that in most cases you'd better consider not to use it. \n And yet, when we're talking about  contexts  it's worth to know that way. \n You can design explicit context class though. When prototyping I prefer dataclasses, just because it's easy to serialize them back and forth. \n Cheers! \n    ", "date_posted": "2021-06-28 17:29:12Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "5160481", "name": "Stepan Dyatkovskiy", "reputation_score": "688"}, "answer_comments": []}], "user": {"stack_user_id": "259", "name": "David Sykes", "reputation_score": "46.6k"}, "question_comments": [{"stack_question_id": "986006", "stack_question_comment_id": "20442132", "comment_content": "For a short explanation/clarification see the first answer to ", "user_id": null}, {"stack_question_id": "986006", "stack_question_comment_id": "10928917", "comment_content": "The code in BlairConrad's answer is good, but the explanation provided by DavidCournapeau and DarenThomas is correct.", "user_id": null}, {"stack_question_id": "986006", "stack_question_comment_id": "18288970", "comment_content": "Before reading the selected answer, please consider reading this short text ", "user_id": null}, {"stack_question_id": "986006", "stack_question_comment_id": "42135694", "comment_content": "another workaround is to create a wrapper 'reference' like this: ref = type('', (), {'n':1}) ", "user_id": null}, {"stack_question_id": "986006", "stack_question_comment_id": "110167008", "comment_content": "New official how of Iqc's link: ", "user_id": null}]},
{"stack_question_id": "48054321", "question_title": "Of the many findElement(s)/By functions in Selenium, when would you use one over the other?", "question_content": "\r\n                Selenium includes findElement functions, like so... \n\n.find_element_by_\n\nid\nlink_text\npartial_link_text\nname\nclass_name\ntag_name\ncss_selector\nxpath\r\nIt's apparent that some are limited by design due ...\r\n", "question_url": "/questions/48054321/of-the-many-findelements-by-functions-in-selenium-when-would-you-use-one-over", "date_posted": "Jan 2, 2018 at 0:20", "upvote": "0", "view": "1", "tags": ["python", "python-3.x", "selenium", "selenium-webdriver", "css-selectors"], "answers_count": "2", "answers": [{"stack_answer_id": "48067003", "answer_content": "\r\n In my experience  CSS  is the preferable selector because it can be concise, is well documented and web developers are likely to have more experience and exposure to it. \n\n id ,  name ,  tag_name  and  class_name  can all be easily reproduced with simple CSS so I would avoid explicitly using those. \n\n e.g.  \n\n id  ;  #my_id \n\n name ;  [name=\"my_name\"] \n\n tag_name ;  my_tag \n\n class_name ;  .my_class \n\n The use of  XPath  is often much maligned; labeled as slow and unstable.  However I disagree with this view point. \n\n When I interview people I cringe when they say they avoid Xpath because it is slow and brittle. The speed is no longer a concern, and xpath is only as brittle as the person who wrote it.  However, I prefer the syntax of CSS Selectors so that is why I would choose over XPath for the majority of use cases. \n\n There are 3 scenarios in which XPath is the better choice; \n\n \n Multiple CSS Selectors may be replaced with one XPath query (e.g find element then iterate through sub elements can be performed in one xpath) \n XPath can select based on Text where as CSS Selector cannot \n XPath allows you walk up the DOM Tree which can be really useful if you can only identify a control by its child \n \n\n I would always avoid selecting by text if possible, but if I had to, I would prefer to use XPath over the built in  Link Text  and  Partial Link Text  methods because the Xpath query woudl allow me to be more expressive and allow me to select more than just anchor tags. \n\n Finally, once gotcha when using XPath is that \"class\" is treated as a literal string rather than an array of class names as supported in CSS selectors; \n\n HTML: <div class=\"ab cd\">\n\nCSS matches: div.ab\nCSS matches: div.cd\nCSS matches: div.cd.ab\nCSS matches: div.ab.cd\n\nXPath matches: //div[@class=\"ab cd\"]\nXPath matches: //div[contains(@class, \"ab\")]\nXPath matches: //div[contains(@class, \"cd\")]\nXPath matches: //div[contains(@class, \"ab\") and contains(@class, \"cd\")]\n\nXPath DOES NOT match: //div[@class=\"cd\"]\nXPath DOES NOT match: //div[@class=\"ab\"]\nXPath DOES NOT match: //div[@class=\"cd ab\"]\n \n    ", "date_posted": "2018-01-04 14:30:37Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "1644596", "name": "Robbie Wareham", "reputation_score": "3,277"}, "answer_comments": [{"stack_answer_id": "48067003", "stack_answer_comment_id": "83188957", "comment_content": "Hmm, this was a very interesting read. I appreciate the info! When you say that xpath is only as brittle as the person who wrote it, how would I know if i'm using the correct path or not(assuming this is the weak point)?", "user_id": "/users/6402048/matt-i"}, {"stack_answer_id": "48067003", "stack_answer_comment_id": "83202051", "comment_content": "There is no \"correct path\" for xpath, but that is true for CSS Selectors too.  As an example take this page and your signature image.  The following XPATH would work;  //body/div[3]/div[1]/div[1]/div[1]/div[2]/div[1]/table/tbody/tr[1]/td[2]/div[1]/table[1]/tbody/tr/td[2]/div[1]/div[2]/a/div/img  It would find your image everytime BUT if there was a small change in the HTML layout, it could easily break.  I would call this a brittle XPATH.  It is important to appreciate that I could just as easily write this in CSS just as bad!", "user_id": null}, {"stack_answer_id": "48067003", "stack_answer_comment_id": "83202157", "comment_content": "A better xpath could be '//div[contains(@class, \"question\")]//a[@href=\"/users/6402048/matt-i\"]//img'.  This will more resilient to structural changes.  NB. In this case I would probably use CSS as it could be clearer; '.question a[href=\"/users/6402048/matt-i\"] >img'  However, to create the Xpath (or indeed CSS selctor) you need to understand the AUT and what your are trying to test", "user_id": null}, {"stack_answer_id": "48067003", "stack_answer_comment_id": "86132359", "comment_content": "@MattI Feel free to mark this as an answer if you think it addresses your question", "user_id": null}]}, {"stack_answer_id": "48056120", "answer_content": "\r\n This question have been asked and answered in numerous forums in different formats. Considering them all if we prioritize the locators the list would be as follows : \n \n id : Select element with the specified  id  attribute. \n name : Select first element with the specified  name  attribute. \n link_text : Select link (anchor tag) element which contains  text  matching the specified  LinkText . \n partial_link_text : Select link (anchor tag) element which contains  text  matching the specified  PartialLinkText . \n tag_name : Locate Element using a  Tag Name . \n class_name : Locate Element using a  ClassName . \n css_selector : Select the element using  CssSelectors . \n xpath : Locate an element using an  XPath  expression. \n \n So the question now is  Whats New ? \n The answer is  Selenium have evolved a lot recently .  WebDriver  is now a  W3C Recommendation Candidate . Things within  Selenium  are changing pretty fast. It's no more only about choosing the locator. We need to use a locator which will : \n \n Uniquely identify an element . \n The performance of the locator must be optimized. \n \n Keeping these two factors in mind, the best strategy would be to  Mock the DOM . The  W3C Recommendation Candidate  does mentions the list of the locators as per the below : \n \n So the verdict is clear and concise. \n    ", "date_posted": "2021-03-08 12:47:05Z", "upvote": "\r\n            4\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "7429447", "name": "undetected Selenium", "reputation_score": "160k"}, "answer_comments": [{"stack_answer_id": "48056120", "stack_answer_comment_id": "83088740", "comment_content": "Obviously you have not read my question correctly. I know what these functions do, but i'm wondering why one would choose one over the other. Would there be a certain instance where xpaths would be more beneficial to use than css_selector, and vice versa.", "user_id": "/users/6402048/matt-i"}, {"stack_answer_id": "48056120", "stack_answer_comment_id": "83088832", "comment_content": "Definitely you haven't read the full verbatim of my ", "user_id": null}, {"stack_answer_id": "48056120", "stack_answer_comment_id": "83089044", "comment_content": "I did read it, but that line doesn't specify anything. All you did was post what each tag does and some info that barely gets into what i'm looking for.   How about this. When you go to a web page and inspect the HTML doc, when would you want to use xpath over css_selector, or vice versa? Is one more stable than the other, in terms of clicking the elements that I so desire to click on?", "user_id": "/users/6402048/matt-i"}, {"stack_answer_id": "48056120", "stack_answer_comment_id": "83089358", "comment_content": "Stability depends on how effectively you write the automation code which I have detailed out in my Answer. To achieve the optimum performance I did provide you the sequential options starting with ", "user_id": null}]}], "user": {"stack_user_id": "6402048", "name": "Matt I", "reputation_score": "155"}, "question_comments": [{"stack_question_id": "48054321", "stack_question_comment_id": "83081056", "comment_content": "I use the function whichever gives me ", "user_id": null}, {"stack_question_id": "48054321", "stack_question_comment_id": "83081163", "comment_content": "This discussion might be relevant: ", "user_id": null}, {"stack_question_id": "48054321", "stack_question_comment_id": "83082781", "comment_content": "I pretty much only use xpaths if I need to find something by text, or if the only way to find the element I want is to find another element, traverse back up the dom tree to some shared element, and then back down to the element I want. In my experience css selectors end up being cleaner and easier to read. You'll find people arguing that xpaths are also slower, but in practice you'll probably not notice a difference.", "user_id": null}, {"stack_question_id": "48054321", "stack_question_comment_id": "83092905", "comment_content": "@Matt Yes, mostly they are unique. If I see id, I use findelementbyid; if that's missing, I use xpath/CSS selector. I do however have trust issues with findelementbyclass, as class names can be used in multiple places. I don't worry about performance in the beginning, will chose the easy path. If performance is bad, only then I think about optimization. Hope it helps!", "user_id": null}, {"stack_question_id": "48054321", "stack_question_comment_id": "83104090", "comment_content": "@MattI let's say you have a bunch of similar looking rows that all have some button in it you want to click. There is no way to directly uniquely get the button you want because all the rows have similar buttons with similar attributes. However, there is some other element in the row that is unique. So I could get that element, traverse back up the dom tree to get the row that contains it, and back down to get the button using xpath.", "user_id": null}]},
{"stack_question_id": "1680528", "question_title": "How to avoid having class data shared among instances?", "question_content": "\r\n                What I want is this behavior:\n\nclass a:\n    list = []\n\nx = a()\ny = a()\n\nx.list.append(1)\ny.list.append(2)\nx.list.append(3)\ny.list.append(4)\n\nprint(x.list) # prints [1, 3]\nprint(y.list) # prints [2, 4]\r...\r\n", "question_url": "/questions/1680528/how-to-avoid-having-class-data-shared-among-instances", "date_posted": "Nov 5, 2009 at 13:19", "upvote": "1", "view": "3", "tags": ["python", "class"], "answers_count": "7", "answers": [{"stack_answer_id": "1680555", "answer_content": "\r\n You want this: \n\n class a:\n    def __init__(self):\n        self.list = []\n \n\n Declaring the variables inside the class declaration makes them \"class\" members and not instance members. Declaring them inside the  __init__  method makes sure that a new instance of the members is created alongside every new instance of the object, which is the behavior you're looking for. \n    ", "date_posted": "2009-11-05 13:28:53Z", "upvote": "\r\n            175\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "573", "name": "abyx", "reputation_score": "66.6k"}, "answer_comments": [{"stack_answer_id": "1680555", "stack_answer_comment_id": "1554819", "comment_content": "An added clarification: if you were to reassign the list property in one of the instances, it would not affect the others. So if you did something like ", "user_id": null}, {"stack_answer_id": "1680555", "stack_answer_comment_id": "48776247", "comment_content": "But why does this happens only for list? When i declared an integer or string outside the ", "user_id": null}, {"stack_answer_id": "1680555", "stack_answer_comment_id": "57726690", "comment_content": "@AmalTs It looks like you don't understand how assignment in python works. See ", "user_id": null}, {"stack_answer_id": "1680555", "stack_answer_comment_id": "57727008", "comment_content": "@AmalTs Note: it's considered a bad practice to use class attributes as \"lazy\" default values for instance attributes. Even if the attributes are of an immutable type it's better to assign them inside ", "user_id": null}, {"stack_answer_id": "1680555", "stack_answer_comment_id": "119016248", "comment_content": "I \"wow\" more every day I program in Python.", "user_id": null}]}, {"stack_answer_id": "15590354", "answer_content": "\r\n The accepted answer works but a little more explanation does not hurt.  \n\n Class attributes do not become instance attributes when an instance is created. They become instance attributes when a value is assigned to them. \n\n In the original code no value is assigned to  list  attribute after instantiation; so it remains a class attribute. Defining list inside  __init__  works because  __init__  is called after instantiation. Alternatively, this code would also produce the desired output: \n\n >>> class a:\n    list = []\n\n>>> y = a()\n>>> x = a()\n>>> x.list = []\n>>> y.list = []\n>>> x.list.append(1)\n>>> y.list.append(2)\n>>> x.list.append(3)\n>>> y.list.append(4)\n>>> print(x.list)\n[1, 3]\n>>> print(y.list)\n[2, 4]\n \n\n However, the confusing scenario in the question will never happen to immutable objects such as numbers and strings, because their value cannot be changed without assignment. For example a code similar to the original with string attribute type works without any problem: \n\n >>> class a:\n    string = ''\n\n\n>>> x = a()\n>>> y = a()\n>>> x.string += 'x'\n>>> y.string += 'y'\n>>> x.string\n'x'\n>>> y.string\n'y'\n \n\n So to summarize:  class attributes become instance attributes if and only if a value is assigned to them after instantiation, being in the  __init__  method or not . This is a good thing because this way you can have static attributes if you never assign a value to an attribute after instantiation. \n    ", "date_posted": "2013-03-23 18:12:40Z", "upvote": "\r\n            27\r\n        ", "accepted": "No", "user": {"stack_user_id": "1988148", "name": "jurgenreza", "reputation_score": "5,606"}, "answer_comments": [{"stack_answer_id": "15590354", "stack_answer_comment_id": "123884694", "comment_content": "I know this is an old answer, but... disagree with ", "user_id": null}]}, {"stack_answer_id": "41683345", "answer_content": "\r\n Although the accepted anwer is spot on, I would like to add a bit description. \n\n Let's do a small exercise  \n\n first of all define a class as follows: \n\n class A:\n    temp = 'Skyharbor'\n\n    def __init__(self, x):\n        self.x = x\n\n    def change(self, y):\n        self.temp = y\n \n\n So what do we have here? \n\n \n We have a very simple class which has an attribute  temp  which is a string \n An  __init__  method which sets  self.x   \n A change method sets  self.temp \n \n\n Pretty straight forward so far yeah? Now let's start playing around with this class. Let's initialize  this class first: \n\n a = A('Tesseract')\n \n\n Now do the following: \n\n >>> print(a.temp)\nSkyharbor\n>>> print(A.temp)\nSkyharbor\n \n\n Well,  a.temp  worked as expected but how the hell did  A.temp  work? Well it worked because temp is a class attribute. Everything in python is an object. Here A is also an object of class  type . Thus the attribute temp is an attribute held by the  A  class and if you change the value of temp through  A  (and not through an instance of  a ), the changed value is going to be reflected in all the instance of  A  class.\nLet's go ahead and do that: \n\n >>> A.temp = 'Monuments'\n>>> print(A.temp)\nMonuments\n>>> print(a.temp)\nMonuments\n \n\n Interesting isn't it? And  note that  id(a.temp)  and  id(A.temp)  are still the same . \n\n Any Python object is automatically given a  __dict__  attribute, which contains its list of attributes. Let's investigate what this dictionary contains for our example objects: \n\n >>> print(A.__dict__)\n{\n    'change': <function change at 0x7f5e26fee6e0>,\n    '__module__': '__main__',\n    '__init__': <function __init__ at 0x7f5e26fee668>,\n    'temp': 'Monuments',\n    '__doc__': None\n}\n>>> print(a.__dict__)\n{x: 'Tesseract'}\n \n\n Note that  temp  attribute is listed among  A  class's attributes while  x  is listed for the instance. \n\n So how come that we get a defined value of  a.temp  if it is not even listed for the instance  a . Well that's the magic of  __getattribute__()  method. In Python the dotted syntax automatically invokes this method so when we write  a.temp , Python executes  a.__getattribute__('temp') . That method performs the attribute lookup action, i.e. finds the value of the attribute by looking in different places. \n\n The standard implementation of  __getattribute__()  searches first the internal dictionary ( dict ) of an object, then the type of the object itself. In this case  a.__getattribute__('temp')  executes first  a.__dict__['temp']  and then  a.__class__.__dict__['temp'] \n\n Okay now let's use our  change  method: \n\n >>> a.change('Intervals')\n>>> print(a.temp)\nIntervals\n>>> print(A.temp)\nMonuments\n \n\n Well now that we have used  self ,  print(a.temp)  gives us a different value from  print(A.temp) .  \n\n Now if we compare  id(a.temp)  and  id(A.temp) , they will be different. \n    ", "date_posted": "2019-02-15 11:34:35Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "1222951", "name": "Aran-Fey", "reputation_score": "36.4k"}, "answer_comments": []}, {"stack_answer_id": "1680545", "answer_content": "\r\n You declared \"list\" as a \"class level property\" and not \"instance level property\".  In order to have properties scoped at the instance level, you need to initialize them through referencing with the \"self\" parameter in the  __init__  method (or elsewhere depending on the situation). \n\n You don't strictly have to initialize the instance properties in the  __init__  method but it makes for easier understanding. \n    ", "date_posted": "2009-11-05 13:27:29Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "171461", "name": "jldupont", "reputation_score": "89.2k"}, "answer_comments": []}, {"stack_answer_id": "21492237", "answer_content": "\r\n So nearly every response here seems to miss a particular point.  Class variables  never  become instance variables as demonstrated by the code below.  By utilizing a metaclass to intercept variable assignment at the class level, we can see that when a.myattr is reassigned, the field assignment magic method on the class is not called.  This is because the assignment  creates a new instance variable .  This behavior has  absolutely nothing  to do with the class variable as demonstrated by the second class which has no class variables and yet still allows field assignment. \n\n class mymeta(type):\n    def __init__(cls, name, bases, d):\n        pass\n\n    def __setattr__(cls, attr, value):\n        print(\"setting \" + attr)\n        super(mymeta, cls).__setattr__(attr, value)\n\nclass myclass(object):\n    __metaclass__ = mymeta\n    myattr = []\n\na = myclass()\na.myattr = []           #NOTHING IS PRINTED\nmyclass.myattr = [5]    #change is printed here\nb = myclass()\nprint(b.myattr)         #pass through lookup on the base class\n\nclass expando(object):\n    pass\n\na = expando()\na.random = 5            #no class variable required\nprint(a.random)         #but it still works\n \n\n IN SHORT  Class variables have NOTHING to do with instance variables. \n\n More clearly  They just happen to be in the scope for lookups on instances. Class variables are in fact  instance variables  on the class object itself.  You can also have  metaclass variables  if you want as well because metaclasses themselves are objects too.  Everything is an object whether it is used to create other objects or not, so do not get bound up in the semantics of other languages usage of the word class.  In python, a class is really just an object that is used to determine how to create other objects and what their behaviors will be.  Metaclasses are classes that create classes, just to further illustrate this point.  \n    ", "date_posted": "2014-01-31 23:52:55Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "2735812", "name": "TheQabalist", "reputation_score": "51"}, "answer_comments": []}, {"stack_answer_id": "1680581", "answer_content": "\r\n Yes you must declare in the \"constructor\" if you want that the list becomes an object property and not a class property. \n    ", "date_posted": "2009-11-05 13:27:04Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "201847", "name": "osanchezmon", "reputation_score": "544"}, "answer_comments": []}, {"stack_answer_id": "51728891", "answer_content": "\r\n To protect your variable shared by other instance you need to create new instance variable each time you create an instance. When you are declaring a variable inside a class it's class variable and shared by all instance. If you want to make it for instance wise need to use the  init  method to reinitialize the variable as  refer to the instance   \n\n From  Python Objects and Class  by Programiz.com : \n\n \n   __init__()  function. This special function gets called whenever a new object of that class is instantiated. \n  \n   This type of function is also called constructors in Object Oriented\n  Programming (OOP). We normally use it to initialize all the variables. \n \n\n For example: \n\n class example:\n    list=[] #This is class variable shared by all instance\n    def __init__(self):\n        self.list = [] #This is instance variable referred to specific instance\n \n    ", "date_posted": "2018-08-24 16:24:57Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "100297", "name": "Martijn Pieters", "reputation_score": "979k"}, "answer_comments": []}], "user": {"stack_user_id": "150564", "name": "8steve8", "reputation_score": "2,173"}, "question_comments": [{"stack_question_id": "1680528", "stack_question_comment_id": "48173061", "comment_content": "Please, do not use ", "user_id": null}]},
{"stack_question_id": "36921951", "question_title": "Truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()", "question_content": "\r\n                I want to filter my dataframe with an or condition to keep rows with a particular column's values that are outside the range [-0.25, 0.25]. I tried:\ndf = df[(df['col'] < -0.25) or (df['col'] > 0....\r\n", "question_url": "/questions/36921951/truth-value-of-a-series-is-ambiguous-use-a-empty-a-bool-a-item-a-any-o", "date_posted": "Apr 28, 2016 at 17:46", "upvote": "7", "view": "1", "tags": ["python", "pandas", "dataframe", "boolean", "filtering"], "answers_count": "1", "answers": [{"stack_answer_id": "36922103", "answer_content": "\r\n The  or  and  and  python statements require  truth -values. For  pandas , these are considered ambiguous so you should use \"bitwise\"  |  (or) or  &  (and) operations: \n df = df[(df['col'] < -0.25) | (df['col'] > 0.25)]\n \n These are overloaded for these kinds of data structures to yield the element-wise  or  or  and . \n \n Just to add some more explanation to this statement: \n The exception is thrown when you want to get the  bool  of a  pandas.Series : \n >>> import pandas as pd\n>>> x = pd.Series([1])\n>>> bool(x)\nValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n \n What you hit was a place where the operator  implicitly  converted the operands to  bool  (you used  or  but it also happens for  and ,  if  and  while ): \n >>> x or x\nValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n>>> x and x\nValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n>>> if x:\n...     print('fun')\nValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n>>> while x:\n...     print('fun')\nValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n \n Besides these 4 statements there are several python functions that hide some  bool  calls (like  any ,  all ,  filter , ...) these are normally not problematic with  pandas.Series  but for completeness I wanted to mention these. \n \n In your case, the exception isn't really helpful, because it doesn't mention the  right alternatives . For  and  and  or , if you want element-wise comparisons, you can use: \n \n numpy.logical_or : \n   >>> import numpy as np\n  >>> np.logical_or(x, y)\n \n or simply the  |  operator: \n   >>> x | y\n \n \n numpy.logical_and : \n   >>> np.logical_and(x, y)\n \n or simply the  &  operator: \n   >>> x & y\n \n \n \n If you're using the operators, then be sure to set your parentheses correctly because of  operator precedence . \n There are  several logical numpy functions  which  should  work on  pandas.Series . \n \n The alternatives mentioned in the Exception are more suited if you encountered it when doing  if  or  while . I'll shortly explain each of these: \n \n If you want to check if your Series is  empty : \n   >>> x = pd.Series([])\n  >>> x.empty\n  True\n  >>> x = pd.Series([1])\n  >>> x.empty\n  False\n \n Python normally interprets the  len gth of containers (like  list ,  tuple , ...) as truth-value if it has no explicit boolean interpretation. So if you want the python-like check, you could do:  if x.size  or  if not x.empty  instead of  if x . \n \n If your  Series  contains  one and only one  boolean value: \n   >>> x = pd.Series([100])\n  >>> (x > 50).bool()\n  True\n  >>> (x < 50).bool()\n  False\n \n \n If you want to check the  first and only item  of your Series (like  .bool()  but works even for not boolean contents): \n   >>> x = pd.Series([100])\n  >>> x.item()\n  100\n \n \n If you want to check if  all  or  any  item is not-zero, not-empty or not-False: \n   >>> x = pd.Series([0, 1, 2])\n  >>> x.all()   # because one element is zero\n  False\n  >>> x.any()   # because one (or more) elements are non-zero\n  True\n \n \n \n    ", "date_posted": "2022-05-31 16:32:35Z", "upvote": "\r\n            981\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": []}, {"stack_answer_id": "57897625", "answer_content": "\r\n Well pandas use bitwise  &   |  and each condition should be wrapped in a  () \n For example following works \n data_query = data[(data['year'] >= 2005) & (data['year'] <= 2010)]\n \n But the same query without proper brackets does not \n data_query = data[(data['year'] >= 2005 & data['year'] <= 2010)]\n \n    ", "date_posted": "2020-10-14 15:37:22Z", "upvote": "\r\n            105\r\n        ", "accepted": "No", "user": {"stack_user_id": "7403431", "name": "Stefan", "reputation_score": "1,427"}, "answer_comments": [{"stack_answer_id": "57897625", "stack_answer_comment_id": "122452906", "comment_content": "Wonderful, the only answer mentioning the importance of wrapping conditions in parenthesis. The only problem with my syntax. But why is this mandatory?", "user_id": null}, {"stack_answer_id": "57897625", "stack_answer_comment_id": "123087979", "comment_content": "Yes, wrapping with parens was the key!", "user_id": null}]}, {"stack_answer_id": "36922486", "answer_content": "\r\n For boolean logic, use  &  and  | . \n np.random.seed(0)\ndf = pd.DataFrame(np.random.randn(5,3), columns=list('ABC'))\n\n>>> df\n          A         B         C\n0  1.764052  0.400157  0.978738\n1  2.240893  1.867558 -0.977278\n2  0.950088 -0.151357 -0.103219\n3  0.410599  0.144044  1.454274\n4  0.761038  0.121675  0.443863\n\n>>> df.loc[(df.C > 0.25) | (df.C < -0.25)]\n          A         B         C\n0  1.764052  0.400157  0.978738\n1  2.240893  1.867558 -0.977278\n3  0.410599  0.144044  1.454274\n4  0.761038  0.121675  0.443863\n \n To see what is happening, you get a column of booleans for each comparison, e.g. \n df.C > 0.25\n0     True\n1    False\n2    False\n3     True\n4     True\nName: C, dtype: bool\n \n When you have multiple criteria, you will get multiple columns returned.  This is why the join logic is ambiguous.  Using  and  or  or  treats each column separately, so you first need to reduce that column to a single boolean value.  For example, to see if any value or all values in each of the columns is True. \n # Any value in either column is True?\n(df.C > 0.25).any() or (df.C < -0.25).any()\nTrue\n\n# All values in either column is True?\n(df.C > 0.25).all() or (df.C < -0.25).all()\nFalse\n \n One convoluted way to achieve the same thing is to zip all of these columns together, and perform the appropriate logic. \n >>> df[[any([a, b]) for a, b in zip(df.C > 0.25, df.C < -0.25)]]\n          A         B         C\n0  1.764052  0.400157  0.978738\n1  2.240893  1.867558 -0.977278\n3  0.410599  0.144044  1.454274\n4  0.761038  0.121675  0.443863\n \n For more details, refer to  Boolean Indexing  in the docs. \n    ", "date_posted": "2020-08-27 20:44:10Z", "upvote": "\r\n            61\r\n        ", "accepted": "No", "user": {"stack_user_id": "2430549", "name": "HoldOffHunger", "reputation_score": "16.2k"}, "answer_comments": []}, {"stack_answer_id": "41736427", "answer_content": "\r\n Or, alternatively, you could use Operator module. More detailed information is here  Python docs \n\n import operator\nimport numpy as np\nimport pandas as pd\nnp.random.seed(0)\ndf = pd.DataFrame(np.random.randn(5,3), columns=list('ABC'))\ndf.loc[operator.or_(df.C > 0.25, df.C < -0.25)]\n\n          A         B         C\n0  1.764052  0.400157  0.978738\n1  2.240893  1.867558 -0.977278\n3  0.410599  0.144044  1.454274\n4  0.761038  0.121675  0.4438\n \n    ", "date_posted": "2017-01-19 07:48:25Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "2464237", "name": "C\u1ea3nh To\u00e0n Nguy\u1ec5n", "reputation_score": "440"}, "answer_comments": []}, {"stack_answer_id": "47073907", "answer_content": "\r\n This excellent answer  explains very well what is happening and provides a solution. I would like to add another solution that might be suitable in similar cases: using the  query  method: \n df = df.query(\"(col > 0.25) or (col < -0.25)\")\n \n See also  http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-query . \n (Some tests with a dataframe I'm currently working with suggest that this method is a bit slower than using the bitwise operators on series of booleans: 2 ms vs. 870 \u00b5s) \n A piece of warning : At least one situation where this is not straightforward is when column names happen to be python expressions. I had columns named  WT_38hph_IP_2 ,  WT_38hph_input_2  and  log2(WT_38hph_IP_2/WT_38hph_input_2)  and wanted to perform the following query:  \"(log2(WT_38hph_IP_2/WT_38hph_input_2) > 1) and (WT_38hph_IP_2 > 20)\" \n I obtained the following exception cascade: \n \n KeyError: 'log2' \n UndefinedVariableError: name 'log2' is not defined \n ValueError: \"log2\" is not a supported function \n \n I guess this happened because the query parser was trying to make something from the first two columns instead of identifying the expression with the name of the third column. \n A possible workaround is proposed  here . \n    ", "date_posted": "2022-03-30 05:01:29Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": []}, {"stack_answer_id": "71956180", "answer_content": "\r\n This is quite a common question for beginners when making multiple conditions in Pandas. Generally speaking, there are two possible conditions causing this error: \n Condition 1: Python Operator Precedence \n There is a paragraph of  Boolean indexing | Indexing and selecting data \u2014 pandas documentation  explains this \n \n Another common operation is the use of boolean vectors to filter the data. The operators are:  |  for  or ,  &  for  and , and  ~  for  not . These  must  be grouped by using  parentheses . \n By default Python will evaluate an expression such as  df['A'] > 2 & df['B'] < 3  as  df['A'] > (2 & df['B']) < 3 , while the desired evaluation order is  (df['A'] > 2) & (df['B'] < 3) . \n \n # Wrong\ndf['col'] < -0.25 | df['col'] > 0.25\n\n# Right\n(df['col'] < -0.25) | (df['col'] > 0.25)\n \n There are some possible ways to get rid off the parentheses, I will cover this later. \n \n Condition 2: Improper Operator/Statement \n As is explained in previous quotation, you need use  |  for  or ,  &  for  and , and  ~  for  not \n # Wrong\n(df['col'] < -0.25) or (df['col'] > 0.25)\n\n# Right\n(df['col'] < -0.25) | (df['col'] > 0.25)\n \n \n Another possible situation is that you are using a boolean Series in  if  statement. \n # Wrong\nif pd.Series([True, False]):\n    pass\n \n It's clear that Python  if  statement accepts boolean like expression rather than Pandas Series. You should use  pandas.Series.any  or methods listed in the error message to convert the Series to a value according to your need. \n For example: \n # Right\nif df['col'].eq(0).all():\n    # If you want all column values equal to zero\n    print('do something')\n\n# Right\nif df['col'].eq(0).any():\n    # If you want at least one column value equal to zero\n    print('do something')\n \n \n Let's talk about ways to escape the parentheses in the first situation. \n \n Use Pandas mathematical functions \n \n Pandas has defined a lot of mathematical functions including comparison as follows: \n \n pandas.Series.lt()  for  less than ; \n pandas.Series.gt()  for  greater than ; \n pandas.Series.le()  for  less and equal ; \n pandas.Series.ge()  for  greater and equal ; \n pandas.Series.ne()  for  not equal ; \n pandas.Series.eq()  for  equal ; \n \n As a result, you can use \n df = df[(df['col'] < -0.25) | (df['col'] > 0.25)]\n\n# is equal to\n\ndf = df[df['col'].lt(-0.25) | df['col'].gt(0.25)]\n \n \n Use  pandas.Series.between() \n \n If you want to select rows in between two values, you can use  pandas.Series.between \n \n df['col].between(left, right)  is equal to  \n (left <= df['col']) & (df['col'] <= right) ; \n df['col].between(left, right, inclusive='left)  is equal to  \n (left <= df['col']) & (df['col'] < right) ; \n df['col].between(left, right, inclusive='right')  is equal to  \n (left < df['col']) & (df['col'] <= right) ; \n df['col].between(left, right, inclusive='neither')  is equal to  \n (left < df['col']) & (df['col'] < right) ; \n \n df = df[(df['col'] > -0.25) & (df['col'] < 0.25)]\n\n# is equal to\n\ndf = df[df['col'].between(-0.25, 0.25, inclusive='neither')]\n \n \n Use  pandas.DataFrame.query() \n \n Document referenced before has a chapter  The  query()  Method  explains this well. \n pandas.DataFrame.query()  can help you select a DataFrame with a condition string. Within the query string, you can use both bitwise operators( &  and  | ) and their boolean cousins( and  and  or ). Moreover, you can omit the parentheses, but I don't recommend for readable reason. \n df = df[(df['col'] < -0.25) | (df['col'] > 0.25)]\n\n# is equal to\n\ndf = df.query('col < -0.25 or col > 0.25')\n \n \n Use  pandas.DataFrame.eval() \n \n pandas.DataFrame.eval()  evaluates a string describing operations on DataFrame columns. Thus, we can use this method to build our multiple condition. The syntax is same with  pandas.DataFrame.query() . \n df = df[(df['col'] < -0.25) | (df['col'] > 0.25)]\n\n# is equal to\n\ndf = df[df.eval('col < -0.25 or col > 0.25')]\n \n pandas.DataFrame.query()  and  pandas.DataFrame.eval()  can do more things than I describe here, you are recommended to read their documentation and have fun with them. \n    ", "date_posted": "2022-05-14 05:47:41Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "10315163", "name": "Ynjxsjmh", "reputation_score": "22.9k"}, "answer_comments": []}, {"stack_answer_id": "69256931", "answer_content": "\r\n If you have more than one value: \n df['col'].all()\n \n If its only a single value: \n df['col'].item()\n \n    ", "date_posted": "2022-03-30 05:01:04Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": []}, {"stack_answer_id": "68258741", "answer_content": "\r\n I was getting error in this command: \n if df != '':\n    pass\n \n But it worked when I changed it to this: \n if df is not '':\n    pass\n \n    ", "date_posted": "2022-04-17 02:42:29Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "6153082", "name": "Mehdi Rostami", "reputation_score": "119"}, "answer_comments": []}, {"stack_answer_id": "62929797", "answer_content": "\r\n You need to use bitwise operators  |  instead of  or  and  &  instead of  and  in pandas, you can't simply use the bool statements from python. \n \nFor much complex filtering create a  mask  and apply the mask on the dataframe. \nPut all your query in the mask and apply it. \nSuppose, \n mask = (df[\"col1\"]>=df[\"col2\"]) & (stock[\"col1\"]<=df[\"col2\"])\ndf_new = df[mask]\n \n    ", "date_posted": "2020-07-16 07:39:08Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "11534375", "name": "Hemanth Kollipara", "reputation_score": "692"}, "answer_comments": []}, {"stack_answer_id": "64504183", "answer_content": "\r\n I'll try to give the benchmark of the three most common way (also mentioned above): \n from timeit import repeat\n\nsetup = \"\"\"\nimport numpy as np;\nimport random;\nx = np.linspace(0,100);\nlb, ub = np.sort([random.random() * 100, random.random() * 100]).tolist()\n\"\"\"\nstmts = 'x[(x > lb) * (x <= ub)]', 'x[(x > lb) & (x <= ub)]', 'x[np.logical_and(x > lb, x <= ub)]'\n\nfor _ in range(3):\n    for stmt in stmts:\n        t = min(repeat(stmt, setup, number=100_000))\n        print('%.4f' % t, stmt)\n    print()\n \n result: \n 0.4808 x[(x > lb) * (x <= ub)]\n0.4726 x[(x > lb) & (x <= ub)]\n0.4904 x[np.logical_and(x > lb, x <= ub)]\n\n0.4725 x[(x > lb) * (x <= ub)]\n0.4806 x[(x > lb) & (x <= ub)]\n0.5002 x[np.logical_and(x > lb, x <= ub)]\n\n0.4781 x[(x > lb) * (x <= ub)]\n0.4336 x[(x > lb) & (x <= ub)]\n0.4974 x[np.logical_and(x > lb, x <= ub)]\n \n But,  *  is not supported in Panda Series, and NumPy Array is faster than pandas data frame (arround 1000 times slower, see number): \n from timeit import repeat\n\nsetup = \"\"\"\nimport numpy as np;\nimport random;\nimport pandas as pd;\nx = pd.DataFrame(np.linspace(0,100));\nlb, ub = np.sort([random.random() * 100, random.random() * 100]).tolist()\n\"\"\"\nstmts = 'x[(x > lb) & (x <= ub)]', 'x[np.logical_and(x > lb, x <= ub)]'\n\nfor _ in range(3):\n    for stmt in stmts:\n        t = min(repeat(stmt, setup, number=100))\n        print('%.4f' % t, stmt)\n    print()\n \n result: \n 0.1964 x[(x > lb) & (x <= ub)]\n0.1992 x[np.logical_and(x > lb, x <= ub)]\n\n0.2018 x[(x > lb) & (x <= ub)]\n0.1838 x[np.logical_and(x > lb, x <= ub)]\n\n0.1871 x[(x > lb) & (x <= ub)]\n0.1883 x[np.logical_and(x > lb, x <= ub)]\n \n Note: adding one line of code  x = x.to_numpy()  will need about 20 \u00b5s. \n For those who prefer  %timeit : \n import numpy as np\nimport random\nlb, ub = np.sort([random.random() * 100, random.random() * 100]).tolist()\nlb, ub\nx = pd.DataFrame(np.linspace(0,100))\n\ndef asterik(x):\n    x = x.to_numpy()\n    return x[(x > lb) * (x <= ub)]\n\ndef and_symbol(x):\n    x = x.to_numpy()\n    return x[(x > lb) & (x <= ub)]\n\ndef numpy_logical(x):\n    x = x.to_numpy()\n    return x[np.logical_and(x > lb, x <= ub)]\n\nfor i in range(3):\n    %timeit asterik(x)\n    %timeit and_symbol(x)\n    %timeit numpy_logical(x)\n    print('\\n')\n \n result: \n 23 \u00b5s \u00b1 3.62 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\n35.6 \u00b5s \u00b1 9.53 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n31.3 \u00b5s \u00b1 8.9 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n\n\n21.4 \u00b5s \u00b1 3.35 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\n21.9 \u00b5s \u00b1 1.02 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n21.7 \u00b5s \u00b1 500 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n\n\n25.1 \u00b5s \u00b1 3.71 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n36.8 \u00b5s \u00b1 18.3 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n28.2 \u00b5s \u00b1 5.97 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\n \n    ", "date_posted": "2020-10-23 16:49:37Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "11671779", "name": "Muhammad Yasirroni", "reputation_score": "779"}, "answer_comments": []}, {"stack_answer_id": "61719230", "answer_content": "\r\n I encountered the same error and got stalled with a pyspark dataframe for few days,  I was able to resolve it successfully by filling na values with 0  since I was comparing integer values from 2 fields. \n    ", "date_posted": "2020-05-10 21:54:06Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "7901426", "name": "iretex", "reputation_score": "43"}, "answer_comments": []}, {"stack_answer_id": "64277449", "answer_content": "\r\n One minor thing, which wasted my time. \n Put the conditions(if comparing using \" = \", \" != \") in parenthesis, failing to do so also raises this exception.\nThis will work \n df[(some condition) conditional operator (some conditions)]\n \n This will not \n df[some condition conditional-operator some condition]\n \n    ", "date_posted": "2020-10-09 09:37:01Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "8486505", "name": "satinder singh", "reputation_score": "160"}, "answer_comments": []}], "user": {"stack_user_id": "6267003", "name": "obabs", "reputation_score": "7,611"}, "question_comments": [{"stack_question_id": "36921951", "stack_question_comment_id": "61405699", "comment_content": "use ", "user_id": null}, {"stack_question_id": "36921951", "stack_question_comment_id": "94761896", "comment_content": "Here's a workaround: ", "user_id": null}, {"stack_question_id": "36921951", "stack_question_comment_id": "96891030", "comment_content": "Related: ", "user_id": null}, {"stack_question_id": "36921951", "stack_question_comment_id": "116738206", "comment_content": "I ran into the same error message using the standard ", "user_id": null}]},
{"stack_question_id": "1436703", "question_title": "What is the difference between __str__ and __repr__?", "question_content": "\r\n                What is the difference between __str__ and __repr__ in Python?\r\n", "question_url": "/questions/1436703/what-is-the-difference-between-str-and-repr", "date_posted": "Sep 17, 2009 at 4:27", "upvote": "3", "view": "8", "tags": ["python", "magic-methods", "repr"], "answers_count": "2", "answers": [{"stack_answer_id": "2626364", "answer_content": "\r\n Alex  summarized well but, surprisingly, was too succinct. \n First, let me reiterate the main points in  Alex\u2019s post : \n \n The default implementation is useless (it\u2019s hard to think of one which wouldn\u2019t be, but yeah) \n __repr__  goal is to be unambiguous \n __str__  goal is to be readable \n Container\u2019s  __str__  uses contained objects\u2019  __repr__ \n \n Default implementation is useless \n This is mostly a surprise because Python\u2019s defaults tend to be fairly useful. However, in this case, having a default for  __repr__  which would act like: \n return \"%s(%r)\" % (self.__class__, self.__dict__)\n \n would have been too dangerous (for example, too easy to get into infinite recursion if objects reference each other). So Python cops out. Note that there is one default which is true: if  __repr__  is defined, and  __str__  is not, the object will behave as though  __str__=__repr__ . \n This means, in simple terms: almost every object you implement should have a functional  __repr__  that\u2019s usable for understanding the object. Implementing  __str__  is optional: do that if you need a \u201cpretty print\u201d functionality (for example, used by a report generator). \n The goal of  __repr__  is to be unambiguous \n Let me come right out and say it \u2014 I do not believe in debuggers. I don\u2019t really know how to use any debugger, and have never used one seriously. Furthermore, I believe that the big fault in debuggers is their basic nature \u2014 most failures I debug happened a long long time ago, in a galaxy far far away. This means that I do believe, with religious fervor, in logging. Logging is the lifeblood of any decent fire-and-forget server system. Python makes it easy to log: with maybe some project specific wrappers, all you need is a \n log(INFO, \"I am in the weird function and a is\", a, \"and b is\", b, \"but I got a null C \u2014 using default\", default_c)\n \n But you have to do the last step \u2014 make sure every object you implement has a useful repr, so code like that can just work. This is why the \u201ceval\u201d thing comes up: if you have enough information so  eval(repr(c))==c , that means you know everything there is to know about  c . If that\u2019s easy enough, at least in a fuzzy way, do it. If not, make sure you have enough information about  c  anyway. I usually use an eval-like format:  \"MyClass(this=%r,that=%r)\" % (self.this,self.that) . It does not mean that you can actually construct MyClass, or that those are the right constructor arguments \u2014 but it is a useful form to express \u201cthis is everything you need to know about this instance\u201d. \n Note: I used  %r  above, not  %s . You always want to use  repr()  [or  %r  formatting character, equivalently] inside  __repr__  implementation, or you\u2019re defeating the goal of repr. You want to be able to differentiate  MyClass(3)  and  MyClass(\"3\") . \n The goal of  __str__  is to be readable \n Specifically, it is not intended to be unambiguous \u2014 notice that  str(3)==str(\"3\") . Likewise, if you implement an IP abstraction, having the str of it look like 192.168.1.1 is just fine. When implementing a date/time abstraction, the str can be \"2010/4/12 15:35:22\", etc. The goal is to represent it in a way that a user, not a programmer, would want to read it. Chop off useless digits, pretend to be some other class \u2014 as long is it supports readability, it is an improvement. \n Container\u2019s  __str__  uses contained objects\u2019  __repr__ \n This seems surprising, doesn\u2019t it? It is a little, but how readable would it be if it used their  __str__ ? \n [moshe is, 3, hello\nworld, this is a list, oh I don't know, containing just 4 elements]\n \n Not very. Specifically, the strings in a container would find it way too easy to disturb its string representation. In the face of ambiguity, remember, Python resists the temptation to guess. If you want the above behavior when you\u2019re printing a list, just \n print(\"[\" + \", \".join(l) + \"]\")\n \n (you can probably also figure out what to do about dictionaries. \n Summary \n Implement  __repr__  for any class you implement. This should be second nature. Implement  __str__  if you think it would be useful to have a string version which errs on the side of readability. \n    ", "date_posted": "2021-12-23 06:11:33Z", "upvote": "\r\n            3281\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "1192111", "name": "Francisco", "reputation_score": "10.3k"}, "answer_comments": [{"stack_answer_id": "2626364", "stack_answer_comment_id": "45597487", "comment_content": "Definitely disagree with your opinion that debugging isn't the way to go. For development use a debugger (and/or logging), for production use logging. With a debugger you have a view of everything that went wrong when the problem occurred. You can see the full picture. Unless you are logging EVERYTHING you can't get that. Plus if you are logging everything you're going have to wade through tons of data to get at what you want.", "user_id": null}, {"stack_answer_id": "2626364", "stack_answer_comment_id": "46649638", "comment_content": "Great answer (except the bit about not using debuggers). I'd just like to add a link to this ", "user_id": null}, {"stack_answer_id": "2626364", "stack_answer_comment_id": "100485156", "comment_content": "I heard that a variable ", "user_id": null}, {"stack_answer_id": "2626364", "stack_answer_comment_id": "101141471", "comment_content": "on debugger vs no debugger: don't get such entrenched opinions. In some applications debugging is not realistic, typically when real-time is involved, or when your code only executes remotely on a platform with little access or no console. In most other cases it will be much quicker to stop at an exception to investigate, or to set a breakpoint, because you don't have to go through thousands of lines of logging (which will clutter your disk and slow down the application). Finally, it's not always possible to log, for example on embedded devices, there debugger is your friend too.", "user_id": null}, {"stack_answer_id": "2626364", "stack_answer_comment_id": "105654853", "comment_content": "About debuggging vs logging, they are both useful. If a bug is reproducible, debugging is more simple. If the bug is randomic, logging is essential.", "user_id": null}]}, {"stack_answer_id": "1438297", "answer_content": "\r\n My rule of thumb:   __repr__  is for developers,  __str__  is for customers. \n    ", "date_posted": "2009-09-17 11:35:13Z", "upvote": "\r\n            730\r\n        ", "accepted": "No", "user": {"stack_user_id": "14343", "name": "Ned Batchelder", "reputation_score": "350k"}, "answer_comments": [{"stack_answer_id": "1438297", "stack_answer_comment_id": "98926405", "comment_content": "This is true because for obj = uuid.uuid1(), obj.__str__() is \"2d7fc7f0-7706-11e9-94ae-0242ac110002\" and obj.__repr__() is \"UUID('2d7fc7f0-7706-11e9-94ae-0242ac110002')\". Developers need (value + origin) whereas customers need a value and they don't care how they got it!", "user_id": null}, {"stack_answer_id": "1438297", "stack_answer_comment_id": "105488427", "comment_content": "Here ", "user_id": null}, {"stack_answer_id": "1438297", "stack_answer_comment_id": "124456934", "comment_content": "@NarenYellavula if you're exposing a UUID to a customer you're probably doing something wrong.", "user_id": null}, {"stack_answer_id": "1438297", "stack_answer_comment_id": "126975289", "comment_content": "@MarkRansom why is that?", "user_id": null}, {"stack_answer_id": "1438297", "stack_answer_comment_id": "126982587", "comment_content": "@AbdessabourMtk they're overly complex, and there's no protection against typing them wrong.  Maybe in certain contexts like as part of a QR code they would be OK.", "user_id": null}]}, {"stack_answer_id": "1436756", "answer_content": "\r\n Unless you specifically act to ensure otherwise, most classes don't have helpful results for either: \n >>> class Sic(object): pass\n... \n>>> print(str(Sic()))\n<__main__.Sic object at 0x8b7d0>\n>>> print(repr(Sic()))\n<__main__.Sic object at 0x8b7d0>\n>>> \n \n As you see -- no difference, and no info beyond the class and object's  id .  If you only override one of the two...: \n >>> class Sic(object): \n...   def __repr__(self): return 'foo'\n... \n>>> print(str(Sic()))\nfoo\n>>> print(repr(Sic()))\nfoo\n>>> class Sic(object):\n...   def __str__(self): return 'foo'\n... \n>>> print(str(Sic()))\nfoo\n>>> print(repr(Sic()))\n<__main__.Sic object at 0x2617f0>\n>>> \n \n as you see, if you override  __repr__ , that's ALSO used for  __str__ , but not vice versa. \n Other crucial tidbits to know:  __str__  on a built-on container uses the  __repr__ , NOT the  __str__ , for the items it contains. And, despite the words on the subject found in typical docs, hardly anybody bothers making the  __repr__  of objects be a string that  eval  may use to build an equal object (it's just too hard, AND not knowing how the relevant module was actually imported makes it actually flat out impossible). \n So, my advice: focus on making  __str__  reasonably human-readable, and  __repr__  as unambiguous as you possibly can, even if that interferes with the fuzzy unattainable goal of making  __repr__ 's returned value acceptable as input to  __eval__ ! \n    ", "date_posted": "2022-02-09 22:35:24Z", "upvote": "\r\n            484\r\n        ", "accepted": "No", "user": {"stack_user_id": "2311167", "name": "Adrian W", "reputation_score": "4,163"}, "answer_comments": [{"stack_answer_id": "1436756", "stack_answer_comment_id": "9992427", "comment_content": "In my unit tests I always check that ", "user_id": null}, {"stack_answer_id": "1436756", "stack_answer_comment_id": "40619938", "comment_content": "I always try to make sure that either ", "user_id": null}, {"stack_answer_id": "1436756", "stack_answer_comment_id": "83919034", "comment_content": "Why would not containers (lists, tuples) use  ", "user_id": null}, {"stack_answer_id": "1436756", "stack_answer_comment_id": "95167441", "comment_content": "Just ran into an annoying bug related to the fact that ", "user_id": null}, {"stack_answer_id": "1436756", "stack_answer_comment_id": "115164858", "comment_content": "@abarnert: for a custom ", "user_id": null}]}, {"stack_answer_id": "1436721", "answer_content": "\r\n __repr__ : representation of python object usually eval will convert it back to that object \n\n __str__ : is whatever you think is that object in text form \n\n e.g. \n\n >>> s=\"\"\"w'o\"w\"\"\"\n>>> repr(s)\n'\\'w\\\\\\'o\"w\\''\n>>> str(s)\n'w\\'o\"w'\n>>> eval(str(s))==s\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"<string>\", line 1\n    w'o\"w\n       ^\nSyntaxError: EOL while scanning single-quoted string\n>>> eval(repr(s))==s\nTrue\n \n    ", "date_posted": "2012-08-15 19:40:17Z", "upvote": "\r\n            203\r\n        ", "accepted": "No", "user": {"stack_user_id": "505154", "name": "Andrew Clark", "reputation_score": "194k"}, "answer_comments": [{"stack_answer_id": "1436721", "stack_answer_comment_id": "124693632", "comment_content": "__repr__() : used to create \"constructor-like expression\" in string, so that eval() can re-construct an object back from this string representation   __str__() : used to create string containing a printable representation of an object", "user_id": null}]}, {"stack_answer_id": "19597196", "answer_content": "\r\n \n   In short, the goal of  __repr__  is to be unambiguous and  __str__  is to be\n  readable. \n \n\n Here is a good example: \n\n >>> import datetime\n>>> today = datetime.datetime.now()\n>>> str(today)\n'2012-03-14 09:21:58.130922'\n>>> repr(today)\n'datetime.datetime(2012, 3, 14, 9, 21, 58, 130922)'\n \n\n Read this documentation for repr: \n\n \n   repr(object) \n  \n   Return a string containing a printable representation of an object. This is the same value yielded by conversions (reverse\n  quotes). It is sometimes useful to be able to access this operation as\n  an ordinary function. For many types, this function makes an attempt\n  to return a string that would yield an object with the same value when\n  passed to  eval() , otherwise the representation is a string enclosed in\n  angle brackets that contains the name of the type of the object\n  together with additional information often including the name and\n  address of the object. A class can control what this function returns\n  for its instances by defining a  __repr__()  method. \n \n\n Here is the documentation for str: \n\n \n   str(object='') \n  \n   Return a string containing a nicely printable\n  representation of an object. For strings, this returns the string\n  itself. The difference with  repr(object)  is that  str(object)  does not\n  always attempt to return a string that is acceptable to  eval() ; its\n  goal is to return a printable string. If no argument is given, returns\n  the empty string,  '' . \n \n    ", "date_posted": "2013-10-28 00:23:46Z", "upvote": "\r\n            196\r\n        ", "accepted": "No", "user": {"stack_user_id": "1442342", "name": "deadly", "reputation_score": "1,198"}, "answer_comments": [{"stack_answer_id": "19597196", "stack_answer_comment_id": "90779593", "comment_content": "What is the meaning of printable string here? Can you explain it please?", "user_id": null}, {"stack_answer_id": "19597196", "stack_answer_comment_id": "111199240", "comment_content": "building upon the above example  by \"bitoffdev\" and  @deadly we can see how ", "user_id": null}]}, {"stack_answer_id": "28132458", "answer_content": "\r\n \n What is the difference between  __str__  and  __repr__  in Python? \n \n __str__  (read as \"dunder (double-underscore) string\") and  __repr__  (read as \"dunder-repper\" (for \"representation\")) are both special methods that return strings based on the state of the object. \n __repr__  provides backup behavior if  __str__  is missing. \n So one should first write a  __repr__  that allows you to reinstantiate an equivalent object from the string it returns e.g. using  eval  or by typing it in character-for-character in a Python shell. \n At any time later, one can write a  __str__  for a user-readable string representation of the instance, when one believes it to be necessary. \n __str__ \n If you print an object, or pass it to  format ,  str.format , or  str , then if a  __str__  method is defined, that method will be called, otherwise,  __repr__  will be used. \n __repr__ \n The  __repr__  method is called by the builtin function  repr  and is what is echoed on your python shell when it evaluates an expression that returns an object. \n Since it provides a backup for  __str__ , if you can only write one, start with  __repr__ \n Here's the builtin help on  repr : \n repr(...)\n    repr(object) -> string\n    \n    Return the canonical string representation of the object.\n    For most object types, eval(repr(object)) == object.\n \n That is, for most objects, if you type in what is printed by  repr , you should be able to create an equivalent object.  But this is not the default implementation. \n Default Implementation of  __repr__ \n The default object  __repr__  is ( C Python source ) something like: \n def __repr__(self):\n    return '<{0}.{1} object at {2}>'.format(\n      type(self).__module__, type(self).__qualname__, hex(id(self)))\n \n That means by default you'll print the module the object is from, the class name, and the hexadecimal representation of its location in memory - for example: \n <__main__.Foo object at 0x7f80665abdd0>\n \n This information isn't very useful, but there's no way to derive how one might accurately create a canonical representation of any given instance, and it's better than nothing, at least telling us how we might uniquely identify it in memory. \n How can  __repr__  be useful? \n Let's look at how useful it can be, using the Python shell and  datetime  objects. First we need to import the  datetime  module: \n import datetime\n \n If we call  datetime.now  in the shell, we'll see everything we need to recreate an equivalent datetime object. This is created by the datetime  __repr__ : \n >>> datetime.datetime.now()\ndatetime.datetime(2015, 1, 24, 20, 5, 36, 491180)\n \n If we print a datetime object, we see a nice human readable (in fact, ISO) format. This is implemented by datetime's  __str__ : \n >>> print(datetime.datetime.now())\n2015-01-24 20:05:44.977951\n \n It is a simple matter to recreate the object we lost because we didn't assign it to a variable by copying and pasting from the  __repr__  output, and then printing it, and we get it in the same human readable output as the other object: \n >>> the_past = datetime.datetime(2015, 1, 24, 20, 5, 36, 491180)\n>>> print(the_past)\n2015-01-24 20:05:36.491180\n \n #How do I implement them? \n As you're developing, you'll want to be able to reproduce objects in the same state, if possible. This, for example, is how the datetime object defines  __repr__  ( Python source ). It is fairly complex, because of all of the attributes needed to reproduce such an object: \n def __repr__(self):\n    \"\"\"Convert to formal string, for repr().\"\"\"\n    L = [self._year, self._month, self._day,  # These are never zero\n         self._hour, self._minute, self._second, self._microsecond]\n    if L[-1] == 0:\n        del L[-1]\n    if L[-1] == 0:\n        del L[-1]\n    s = \"%s.%s(%s)\" % (self.__class__.__module__,\n                       self.__class__.__qualname__,\n                       \", \".join(map(str, L)))\n    if self._tzinfo is not None:\n        assert s[-1:] == \")\"\n        s = s[:-1] + \", tzinfo=%r\" % self._tzinfo + \")\"\n    if self._fold:\n        assert s[-1:] == \")\"\n        s = s[:-1] + \", fold=1)\"\n    return s\n \n If you want your object to have a more human readable representation, you can implement  __str__  next. Here's how the datetime object ( Python source ) implements  __str__ , which it easily does because it already has a function to display it in ISO format: \n def __str__(self):\n    \"Convert to string, for str().\"\n    return self.isoformat(sep=' ')\n \n Set  __repr__ = __str__ ? \n This is a critique of another answer here that suggests setting  __repr__ = __str__ . \n Setting  __repr__ = __str__  is silly -  __repr__  is a fallback for  __str__  and a  __repr__ , written for developers usage in debugging, should be written before you write a  __str__ . \n You need a  __str__  only when you need a textual representation of the object. \n Conclusion \n Define  __repr__  for objects you write so you and other developers have a reproducible example when using it as you develop. Define  __str__  when you need a human readable string representation of it. \n    ", "date_posted": "2022-03-31 17:05:03Z", "upvote": "\r\n            162\r\n        ", "accepted": "No", "user": {"stack_user_id": "2326961", "name": "Maggyero", "reputation_score": "4,880"}, "answer_comments": [{"stack_answer_id": "28132458", "stack_answer_comment_id": "93999470", "comment_content": "Shouldn't it be something along the lines of ", "user_id": null}, {"stack_answer_id": "28132458", "stack_answer_comment_id": "94014066", "comment_content": "@SolomonUcko yes in Python 3, that would seem to be the case - I've been hunting down the source code where this is implemented and I'll update my answer with that information when I get it together.", "user_id": null}, {"stack_answer_id": "28132458", "stack_answer_comment_id": "125520621", "comment_content": "This answer will be more helpful for beginners. Nice explanation!!", "user_id": null}, {"stack_answer_id": "28132458", "stack_answer_comment_id": "126709060", "comment_content": "I have changed ", "user_id": null}]}, {"stack_answer_id": "44099267", "answer_content": "\r\n On page 358 of the book  Python scripting for computational science  by Hans Petter Langtangen, it clearly states that  \n\n \n The  __repr__  aims at a complete string representation of the object; \n The  __str__  is to return a nice string for printing. \n \n\n So, I prefer to understand them as \n\n \n repr = reproduce \n str = string (representation) \n \n\n from the user's point of view\nalthough this is a misunderstanding I made when learning python. \n\n A small but good example is also given on the same page as follows: \n\n Example \n\n In [38]: str('s')\nOut[38]: 's'\n\nIn [39]: repr('s')\nOut[39]: \"'s'\"\n\nIn [40]: eval(str('s'))\nTraceback (most recent call last):\n\n  File \"<ipython-input-40-abd46c0c43e7>\", line 1, in <module>\n    eval(str('s'))\n\n  File \"<string>\", line 1, in <module>\n\nNameError: name 's' is not defined\n\n\nIn [41]: eval(repr('s'))\nOut[41]: 's'\n \n    ", "date_posted": "2019-06-19 07:47:15Z", "upvote": "\r\n            47\r\n        ", "accepted": "No", "user": {"stack_user_id": "10323798", "name": "NelsonGon", "reputation_score": "12.7k"}, "answer_comments": [{"stack_answer_id": "44099267", "stack_answer_comment_id": "94617094", "comment_content": "It is at pg. #351.", "user_id": null}, {"stack_answer_id": "44099267", "stack_answer_comment_id": "99893843", "comment_content": "It's kind of misleading to refer to ", "user_id": null}]}, {"stack_answer_id": "39382137", "answer_content": "\r\n Apart from all the answers given, I would like to add few points :- \n\n 1)  __repr__()  is invoked when you simply write object's name on interactive python console and press enter. \n\n 2)  __str__()  is invoked when you use object with print statement. \n\n 3) In case, if  __str__  is missing, then print and any function using  str()  invokes  __repr__()  of object. \n\n 4)  __str__()  of containers, when invoked will execute  __repr__()  method of its contained elements. \n\n 5)  str()  called within  __str__()  could potentially recurse without a base case, and error on maximum recursion depth. \n\n 6)  __repr__()  can call  repr()  which will attempt to avoid infinite recursion automatically, replacing an already represented object with  ... . \n    ", "date_posted": "2018-06-05 07:47:41Z", "upvote": "\r\n            46\r\n        ", "accepted": "No", "user": {"stack_user_id": "9542308", "name": "David Augusto Villa", "reputation_score": "63"}, "answer_comments": []}, {"stack_answer_id": "63464185", "answer_content": "\r\n (2020 entry) \n Q:  What's the difference between  __str__()  and  __repr__() ? \n TL;DR: \n \n LONG \n This question has been around a long time, and there are a variety of answers of which most are correct (not to mention from several Python community legends[!]). However when it comes down to the nitty-gritty, this question is analogous to asking the difference between the  str()  and  repr()  built-in functions. I'm going to describe the differences in my own words (which means I may be \"borrowing\" liberally from  Core Python Programming  so pls forgive me). \n Both   str()  and  repr()  have the same basic job: their goal is to return a string representation of a Python object. What  kind  of string representation is what differentiates them. \n \n str()  &  __str__()  return a  printable  string representation of\nan object... something human-readable/for human consumption \n repr()  &  __repr__()  return a string representation of an object that is a  valid Python expression , an object you can pass to  eval()  or type into the Python shell without getting an error. \n \n For example, let's assign a string to  x  and an  int  to  y , and simply showing human-readable string versions of each: \n >>> x, y = 'foo', 123\n>>> str(x), str(y)\n('foo', '123')\n \n Can we take  what is inside the quotes  in both cases and enter them verbatim into the Python interpreter? Let's give it a try: \n >>> 123\n123\n>>> foo\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'foo' is not defined\n \n Clearly you can for an  int  but not necessarily for a  str . Similarly, while I can pass  '123'  to  eval() , that doesn't work for  'foo' : \n >>> eval('123')\n123\n>>> eval('foo')\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"<string>\", line 1, in <module>\nNameError: name 'foo' is not defined\n \n So this tells you the Python shell just  eval() s what you give it. Got it? Now, let's  repr()  both expressions and see what we get. More specifically, take its output and dump  those  out in the interpreter (there's a point to this which we'll address afterwards): \n >>> repr(x), repr(y)\n(\"'foo'\", '123')\n>>> 123\n123\n>>> 'foo'\n'foo'\n \n Wow, they  both  work? That's because  'foo' , while a printable string representation of that string, it's  not  evaluatable, but  \"'foo'\"  is.  123  is a valid Python  int  called by either  str()  or  repr() . What happens when we call  eval()  with these? \n >>> eval('123')\n123\n>>> eval(\"'foo'\")\n'foo'\n \n It works because  123  and  'foo'  are valid Python objects. Another key takeaway is that while sometimes both return the same thing (the same string representation), that's not always the case. (And yes, yes, I can go create a variable  foo  where the  eval()  works, but that's not the point.) \n More factoids about both pairs \n \n Sometimes,  str()  and  repr()  are called  implicitly , meaning they're called on behalf of users: when users execute  print  (Py1/Py2) or call  print()  (Py3+), even if users don't call  str()  explicitly, such a call is made on their behalf before the object is displayed. \n In the Python shell (interactive interpreter), if you enter a variable at the  >>>  prompt and press RETURN, the interpreter displays the results of  repr()  implicitly called on that object. \n To connect  str()  and  repr()  to  __str__()  and  __repr__() , realize that calls to the built-in functions, i.e.,  str(x)  or  repr(y)  result in calling their object's corresponding special methods:  x.__str__()  or  y.__repr()__ \n By implementing  __str__()  and  __repr__()  for  your  Python classes, you overload the built-in functions ( str()  and  repr() ), allowing instances of your classes to be passed in to  str()  and  repr() . When such calls are made, they turn around and call the class'  __str__()  and  __repr__()  (per #3). \n \n    ", "date_posted": "2022-02-03 06:36:55Z", "upvote": "\r\n            36\r\n        ", "accepted": "No", "user": {"stack_user_id": "305689", "name": "wescpy", "reputation_score": "10.1k"}, "answer_comments": []}, {"stack_answer_id": "34734815", "answer_content": "\r\n To put it simply: \n\n __str__  is used in to show a string representation of your object  to be read easily  by others. \n\n __repr__  is used to show a string representation of  the  object. \n\n Let's say I want to create a  Fraction  class where the string representation of a fraction is '(1/2)' and the object (Fraction class) is to be represented as 'Fraction (1,2)' \n\n So we can create a simple Fraction class: \n\n class Fraction:\n    def __init__(self, num, den):\n        self.__num = num\n        self.__den = den\n\n    def __str__(self):\n        return '(' + str(self.__num) + '/' + str(self.__den) + ')'\n\n    def __repr__(self):\n        return 'Fraction (' + str(self.__num) + ',' + str(self.__den) + ')'\n\n\n\nf = Fraction(1,2)\nprint('I want to represent the Fraction STRING as ' + str(f)) # (1/2)\nprint('I want to represent the Fraction OBJECT as ', repr(f)) # Fraction (1,2)\n \n    ", "date_posted": "2016-07-28 04:08:32Z", "upvote": "\r\n            15\r\n        ", "accepted": "No", "user": {"stack_user_id": "222758", "name": "user222758", "reputation_score": "12.6k"}, "answer_comments": []}, {"stack_answer_id": "1436706", "answer_content": "\r\n From  an (An Unofficial) Python Reference Wiki (archive copy)  by effbot: \n\n __str__  \" computes the \"informal\" string representation of an object. This differs from  __repr__  in that it does not have to be a valid Python expression: a more convenient or concise representation may be used instead. \" \n    ", "date_posted": "2019-05-29 12:51:25Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "1436706", "stack_answer_comment_id": "80631615", "comment_content": " is by no means required to return a vaild Python expression.", "user_id": null}]}, {"stack_answer_id": "13395755", "answer_content": "\r\n In all honesty,  eval(repr(obj))  is never used. If you find yourself using it, you should stop, because  eval  is dangerous, and strings are a very inefficient way to serialize your objects (use  pickle  instead). \n Therefore, I would recommend setting  __repr__ = __str__ . The reason is that  str(list)  calls  repr  on the elements (I consider this to be one of the biggest design flaws of Python that was not addressed by Python 3). An actual  repr  will probably not be very helpful as the output of  print([your, objects]) . \n To qualify this, in my experience, the most useful use case of the  repr  function is to put a string inside another string (using string formatting). This way, you don't have to worry about escaping quotes or anything. But note that there is no  eval  happening here. \n    ", "date_posted": "2021-12-23 06:13:22Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "1192111", "name": "Francisco", "reputation_score": "10.3k"}, "answer_comments": [{"stack_answer_id": "13395755", "stack_answer_comment_id": "37141861", "comment_content": "I think this misses the point. The use of ", "user_id": null}, {"stack_answer_id": "13395755", "stack_answer_comment_id": "59127770", "comment_content": " is not inherently dangerous. Is not more dangerous than ", "user_id": null}]}, {"stack_answer_id": "40960730", "answer_content": "\r\n str  - Creates a new string object from the given object. \n\n repr  - Returns the canonical string representation of the object. \n\n The differences: \n\n str(): \n\n \n makes object readable \n generates output for end-user \n \n\n repr(): \n\n \n needs code that reproduces object \n generates output for developer \n \n    ", "date_posted": "2016-12-04 16:18:48Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "5401681", "name": "Taufiq Rahman", "reputation_score": "5,453"}, "answer_comments": []}, {"stack_answer_id": "44201752", "answer_content": "\r\n One aspect that is missing in other answers. It's true that in general the pattern is: \n\n \n Goal of  __str__ : human-readable \n Goal of  __repr__ : unambiguous, possibly machine-readable via  eval \n \n\n Unfortunately, this differentiation is flawed, because the Python REPL and also IPython use  __repr__  for printing objects in a REPL console (see related questions for  Python  and  IPython ). Thus, projects which are targeted for interactive console work (e.g., Numpy or Pandas) have started to ignore above rules and provide a human-readable  __repr__  implementation instead. \n    ", "date_posted": "2017-05-26 12:33:51Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "1804173", "name": "bluenote10", "reputation_score": "20.5k"}, "answer_comments": []}, {"stack_answer_id": "43207419", "answer_content": "\r\n From the book  Fluent Python : \n\n \n   A basic requirement for a Python object is to provide usable \n       string   representations of itself, one used for debugging and\n       logging, another for presentation to end users. That is why the \n       special methods  __repr__  and  __str__  exist in the data model. \n \n    ", "date_posted": "2019-05-29 12:57:22Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": []}, {"stack_answer_id": "68665826", "answer_content": "\r\n You can get some insight from this code: \n class Foo():\n    def __repr__(self):\n        return(\"repr\")\n    def __str__(self):\n        return(\"str\")\n\nfoo = Foo()\nfoo #repr\nprint(foo) #str\n \n    ", "date_posted": "2021-08-05 11:36:27Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "1291302", "name": "JonnyRobbie", "reputation_score": "487"}, "answer_comments": []}, {"stack_answer_id": "56481986", "answer_content": "\r\n __str__  can be invoked on an object by calling  str(obj)  and should return a human readable string.  \n\n __repr__  can be invoked on an object by calling  repr(obj)  and should return internal object (object fields/attributes) \n\n This example may help: \n\n class C1:pass\n\nclass C2:        \n    def __str__(self):\n        return str(f\"{self.__class__.__name__} class str \")\n\nclass C3:        \n    def __repr__(self):        \n         return str(f\"{self.__class__.__name__} class repr\")\n\nclass C4:        \n    def __str__(self):\n        return str(f\"{self.__class__.__name__} class str \")\n    def __repr__(self):        \n         return str(f\"{self.__class__.__name__} class repr\")\n\n\nci1 = C1()    \nci2 = C2()  \nci3 = C3()  \nci4 = C4()\n\nprint(ci1)       #<__main__.C1 object at 0x0000024C44A80C18>\nprint(str(ci1))  #<__main__.C1 object at 0x0000024C44A80C18>\nprint(repr(ci1)) #<__main__.C1 object at 0x0000024C44A80C18>\nprint(ci2)       #C2 class str\nprint(str(ci2))  #C2 class str\nprint(repr(ci2)) #<__main__.C2 object at 0x0000024C44AE12E8>\nprint(ci3)       #C3 class repr\nprint(str(ci3))  #C3 class repr\nprint(repr(ci3)) #C3 class repr\nprint(ci4)       #C4 class str \nprint(str(ci4))  #C4 class str \nprint(repr(ci4)) #C4 class repr\n \n    ", "date_posted": "2019-06-06 16:53:43Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "5884955", "name": "prosti", "reputation_score": "36.9k"}, "answer_comments": []}, {"stack_answer_id": "33421226", "answer_content": "\r\n Excellent answers already cover the difference between  __str__  and  __repr__ , which for me boils down to the former being readable even by an end user, and the latter being as useful as possible to developers. Given that, I find that the default implementation of  __repr__  often fails to achieve this goal because it  omits  information useful to developers. \n\n For this reason, if I have a simple enough  __str__ , I generally just try to get the best of both worlds with something like: \n\n def __repr__(self):\n    return '{0} ({1})'.format(object.__repr__(self), str(self))\n \n    ", "date_posted": "2018-04-25 19:35:20Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "answer_comments": []}, {"stack_answer_id": "31427937", "answer_content": "\r\n >>> print(decimal.Decimal(23) / decimal.Decimal(\"1.05\"))\n21.90476190476190476190476190\n>>> decimal.Decimal(23) / decimal.Decimal(\"1.05\")\nDecimal('21.90476190476190476190476190')\n \n\n When  print()  is called on the result of  decimal.Decimal(23) / decimal.Decimal(\"1.05\")  the raw number is printed; this output is in  string form  which can be achieved with  __str__() . If we simply enter the expression we get a  decimal.Decimal  output \u2014 this output is in  representational form  which can be achieved with  __repr__() . All Python objects have two output forms. String form is designed to be human-readable. The representational form is designed to produce output that if fed to a Python interpreter would (when possible) reproduce the represented object. \n    ", "date_posted": "2019-05-29 12:58:50Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": []}, {"stack_answer_id": "33727876", "answer_content": "\r\n \n   One important thing to keep in mind is that container's  __str__  uses contained objects'  __repr__ . \n \n\n >>> from datetime import datetime\n>>> from decimal import Decimal\n>>> print (Decimal('52'), datetime.now())\n(Decimal('52'), datetime.datetime(2015, 11, 16, 10, 51, 26, 185000))\n>>> str((Decimal('52'), datetime.now()))\n\"(Decimal('52'), datetime.datetime(2015, 11, 16, 10, 52, 22, 176000))\"\n \n\n Python favors unambiguity over readability , the  __str__  call of a  tuple  calls the contained objects'  __repr__ , the  \"formal\"  representation of an object. Although the formal representation is harder to read than an informal one, it is unambiguous and more robust against bugs. \n    ", "date_posted": "2015-11-16 03:02:21Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "3011380", "name": "zangw", "reputation_score": "38.2k"}, "answer_comments": [{"stack_answer_id": "33727876", "stack_answer_comment_id": "94618177", "comment_content": "It uses ", "user_id": null}]}, {"stack_answer_id": "49447574", "answer_content": "\r\n In a nutshell: \n\n class Demo:\n  def __repr__(self):\n    return 'repr'\n  def __str__(self):\n    return 'str'\n\ndemo = Demo()\nprint(demo) # use __str__, output 'str' to stdout\n\ns = str(demo) # __str__ is used, return 'str'\nr = repr(demo) # __repr__ is used, return 'repr'\n\nimport logging\nlogger = logging.getLogger(logging.INFO)\nlogger.info(demo) # use __str__, output 'str' to stdout\n\nfrom pprint import pprint, pformat\npprint(demo) # use __repr__, output 'repr' to stdout\nresult = pformat(demo) # use __repr__, result is string which value is 'str'\n \n    ", "date_posted": "2018-04-16 09:28:38Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "50065", "name": "BioGeek", "reputation_score": "21.1k"}, "answer_comments": []}, {"stack_answer_id": "47690304", "answer_content": "\r\n Understand  __str__  and  __repr__  intuitively and permanently distinguish them at all. \n\n __str__  return the string disguised body of a given object for readable of eyes \n __repr__  return the real flesh body of a given object (return itself) for unambiguity to identify. \n\n See it in an example \n\n In [30]: str(datetime.datetime.now())\nOut[30]: '2017-12-07 15:41:14.002752'\nDisguised in string form\n \n\n As to  __repr__ \n\n In [32]: datetime.datetime.now()\nOut[32]: datetime.datetime(2017, 12, 7, 15, 43, 27, 297769)\nPresence in real body which allows to be manipulated directly.\n \n\n We can do arithmetic operation on  __repr__  results conveniently. \n\n In [33]: datetime.datetime.now()\nOut[33]: datetime.datetime(2017, 12, 7, 15, 47, 9, 741521)\nIn [34]: datetime.datetime(2017, 12, 7, 15, 47, 9, 741521) - datetime.datetime(2\n    ...: 017, 12, 7, 15, 43, 27, 297769)\nOut[34]: datetime.timedelta(0, 222, 443752)\n \n\n if apply the operation on  __str__ \n\n In [35]: '2017-12-07 15:43:14.002752' - '2017-12-07 15:41:14.002752'\nTypeError: unsupported operand type(s) for -: 'str' and 'str'\n \n\n Returns nothing but error. \n\n Another example. \n\n In [36]: str('string_body')\nOut[36]: 'string_body' # in string form\n\nIn [37]: repr('real_body')\nOut[37]: \"'real_body'\" #its real body hide inside\n \n\n Hope this help you build concrete grounds to explore more answers. \n    ", "date_posted": "2018-01-02 10:36:32Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "7301792", "name": "AbstProcDo", "reputation_score": "18.1k"}, "answer_comments": []}, {"stack_answer_id": "55744921", "answer_content": "\r\n \n __str__  must return string object whereas  __repr__  can return any python expression. \n If  __str__  implementation is missing then  __repr__  function is used as fallback. There is no fallback if  __repr__  function implementation is missing. \n If  __repr__  function is returning String representation of the object, we can skip implementation of  __str__  function. \n \n\n Source:  https://www.journaldev.com/22460/python-str-repr-functions \n    ", "date_posted": "2019-04-18 11:20:28Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "811625", "name": "Sampath", "reputation_score": "1,059"}, "answer_comments": []}, {"stack_answer_id": "50229578", "answer_content": "\r\n __repr__  is used everywhere, except by  print  and  str  methods (when a  __str__ is defined !) \n    ", "date_posted": "2019-04-14 07:50:40Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "7127824", "name": "techkuz", "reputation_score": "3,158"}, "answer_comments": []}, {"stack_answer_id": "65164408", "answer_content": "\r\n Every object inherits  __repr__   from the base class that all objects created. \n class Person:\n     pass\n\np=Person()\n \n if you call  repr(p)  you will get this as default: \n  <__main__.Person object at 0x7fb2604f03a0>\n \n But if you call  str(p)  you will get the same output. it is because when  __str__  does not exist, Python calls  __repr__ \n Let's implement our own  __str__ \n class Person:\n    def __init__(self,name,age):\n        self.name=name\n        self.age=age\n    def __repr__(self):\n        print(\"__repr__ called\")\n        return f\"Person(name='{self.name}',age={self.age})\"\n\np=Person(\"ali\",20)\n \n print(p)  and  str(p) will return \n  __repr__ called\n     Person(name='ali',age=20)\n \n let's add  __str__() \n class Person:\n    def __init__(self, name, age):\n        self.name = name\n        self.age = age\n        \n    def __repr__(self):\n        print('__repr__ called')\n        return f\"Person(name='{self.name}, age=self.age')\"\n    \n    def __str__(self):\n        print('__str__ called')\n        return self.name\n\np=Person(\"ali\",20)\n \n if we call  print(p)  and str(p), it will call  __str__()  so it will return \n __str__ called\nali\n \n repr(p)  will return \n repr  called\n\"Person(name='ali, age=self.age')\" \n Let's omit  __repr__  and just implement  __str__ . \n class Person:\ndef __init__(self, name, age):\n    self.name = name\n    self.age = age\n\ndef __str__(self):\n    print('__str__ called')\n    return self.name\n\np=Person('ali',20)\n \n print(p)  will look for the  __str__  and will return: \n __str__ called\nali\n \n NOTE= if we had  __repr__  and  __str__  defined,  f'name is {p}'  would call  __str__ \n    ", "date_posted": "2020-12-06 03:31:59Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "10262805", "name": "Yilmaz", "reputation_score": "16.9k"}, "answer_comments": []}, {"stack_answer_id": "72027825", "answer_content": "\r\n \n Programmers with prior experience in languages with a  toString  method tend to implement  __str__  and not  __repr__ .\nIf you only implement one of these special methods in Python, choose  __repr__ . \n \n From  Fluent Python  book, by Ramalho, Luciano. \n    ", "date_posted": "2022-04-27 11:19:34Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "30038", "name": "Vlad Bezden", "reputation_score": "74.9k"}, "answer_comments": []}, {"stack_answer_id": "72238659", "answer_content": "\r\n Basically  __str__  or  str()  is used for creating output that is human-readable are must be for end-users.\nOn the other hand,  repr()  or  __repr__  mainly returns canonical string representation of objects which serve the purpose of debugging and development helps the programmers. \n    ", "date_posted": "2022-05-14 08:47:49Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "13829776", "name": "barii", "reputation_score": "275"}, "answer_comments": []}], "user": {"stack_user_id": "165495", "name": "Casebash", "reputation_score": "109k"}, "question_comments": []},
{"stack_question_id": "370357", "question_title": "UnboundLocalError on local variable when reassigned after first use", "question_content": "\r\n                The following code works as expected in both Python 2.5 and 3.0:\n\na, b, c = (1, 2, 3)\n\nprint(a, b, c)\n\ndef test():\n    print(a)\n    print(b)\n    print(c)    # (A)\n    #c+=1       # (B)\ntest()\r\nHowever,...\r\n", "question_url": "/questions/370357/unboundlocalerror-on-local-variable-when-reassigned-after-first-use", "date_posted": "Dec 16, 2008 at 3:06", "upvote": "2", "view": "8", "tags": ["python", "variables", "scope"], "answers_count": "1", "answers": [{"stack_answer_id": "370363", "answer_content": "\r\n Python treats variables in functions differently depending on whether you assign values to them from inside or outside the function.  If a variable is assigned within a function, it is treated by default as a local variable.  Therefore, when you uncomment the line, you are trying to reference the local variable  c  before any value has been assigned to it. \n If you want the variable  c  to refer to the global  c = 3  assigned before the function, put \n global c\n \n as the first line of the function. \n As for python 3, there is now \n nonlocal c\n \n that you can use to refer to the nearest enclosing function scope that has a  c  variable. \n    ", "date_posted": "2022-01-03 18:12:36Z", "upvote": "\r\n            275\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "4518341", "name": "wjandrea", "reputation_score": "24.1k"}, "answer_comments": [{"stack_answer_id": "370363", "stack_answer_comment_id": "199343", "comment_content": "Thanks. Quick question. Does this imply that Python decides the scope of each variable before running a program? Before running a function?", "user_id": "/users/46521/tba"}, {"stack_answer_id": "370363", "stack_answer_comment_id": "199347", "comment_content": "The variable scope decision is made by the compiler, which normally runs once when you first start the program. However it is worth keeping in mind that the compiler might also run later if you have \"eval\" or \"exec\" statements in your program.", "user_id": null}, {"stack_answer_id": "370363", "stack_answer_comment_id": "199358", "comment_content": "Okay thank you. I guess \"interpreted language\" doesn't imply quite as much as I had thought.", "user_id": "/users/46521/tba"}, {"stack_answer_id": "370363", "stack_answer_comment_id": "1634018", "comment_content": "Ah that 'nonlocal' keyword was exactly what I was looking for, it seemed Python was missing this. Presumably this 'cascades' through each enclosing scope that imports the variable using this keyword?", "user_id": null}, {"stack_answer_id": "370363", "stack_answer_comment_id": "8941039", "comment_content": "@brainfsck: it is easiest to understand if you make the distinction between \"looking up\" and \"assigning\" a variable. Lookup falls back to a higher scope if the name is not found in the current scope. Assignment is always done in the local scope (unless you use ", "user_id": null}]}, {"stack_answer_id": "370380", "answer_content": "\r\n Python is a little weird in that it keeps everything in a dictionary for the various scopes.  The original a,b,c are in the uppermost scope and so in that uppermost dictionary.  The function has its own dictionary.  When you reach the  print(a)  and  print(b)  statements, there's nothing by that name in the dictionary, so Python looks up the list and finds them in the global dictionary. \n\n Now we get to  c+=1 , which is, of course, equivalent to  c=c+1 .  When Python scans that line, it says \"aha, there's a variable named c, I'll put it into my local scope dictionary.\"  Then when it goes looking for a value for c for the c on the right hand side of the assignment, it finds its  local variable named c , which has no value yet, and so throws the error. \n\n The statement  global c  mentioned above simply tells the parser that it uses the  c  from the global scope and so doesn't need a new one. \n\n The reason it says there's an issue on the line it does is because it is effectively looking for the names before it tries to generate code, and so in some sense doesn't think it's really doing that line yet.  I'd argue that is a usability bug, but it's generally a good practice to just learn not to take a compiler's messages  too  seriously. \n\n If it's any comfort, I spent probably a day digging and experimenting with this same issue before I found something Guido had written about the dictionaries that Explained Everything. \n\n Update, see comments: \n\n It doesn't scan the code twice, but it does scan the code in two phases, lexing and parsing. \n\n Consider how the parse of this line of code works.  The lexer reads the source text and breaks it into lexemes, the \"smallest components\" of the grammar.  So when it hits the line \n\n c+=1\n \n\n it breaks it up into something like \n\n SYMBOL(c) OPERATOR(+=) DIGIT(1)\n \n\n The parser eventually wants to make this into a parse tree and execute it, but since it's an assignment, before it does, it looks for the name c in the local dictionary, doesn't see it, and inserts it in the dictionary, marking it as uninitialized. In a fully compiled language, it would just go into the symbol table and wait for the parse, but since it WON'T have the luxury of a second pass, the lexer does a little extra work to make life easier later on.   Only, then it sees the OPERATOR, sees that the rules say \"if you have an operator += the left hand side must have been initialized\" and says \"whoops!\" \n\n The point here is that it  hasn't really started the parse of the line yet .  This is all happening sort of preparatory to the actual parse, so the line counter hasn't advanced to the next line.  Thus when it signals the error, it still thinks its on the previous line. \n\n As I say, you could argue it's a usability bug, but its actually a fairly common thing.  Some compilers are more honest about it and say \"error on or around line XXX\", but this one doesn't. \n    ", "date_posted": "2016-12-10 07:09:58Z", "upvote": "\r\n            87\r\n        ", "accepted": "No", "user": {"stack_user_id": "15168", "name": "Jonathan Leffler", "reputation_score": "704k"}, "answer_comments": [{"stack_answer_id": "370380", "stack_answer_comment_id": "199333", "comment_content": "Okay thank you for your response; it cleared some things up for me about scopes in python. However, I still don't understand why the error is raised at line (A) rather than line (B). Does Python create its variable scope dictionary BEFORE running the program?", "user_id": "/users/46521/tba"}, {"stack_answer_id": "370380", "stack_answer_comment_id": "199744", "comment_content": "No, it's on the expression level.  I'll add to the answer, I don't think I can fit this in a comment.", "user_id": null}, {"stack_answer_id": "370380", "stack_answer_comment_id": "60085042", "comment_content": "Note on implementation details: In CPython, the local scope isn't usually handled as a ", "user_id": null}]}, {"stack_answer_id": "370830", "answer_content": "\r\n Taking a look at the disassembly may clarify what is happening: \n\n >>> def f():\n...    print a\n...    print b\n...    a = 1\n\n>>> import dis\n>>> dis.dis(f)\n\n  2           0 LOAD_FAST                0 (a)\n              3 PRINT_ITEM\n              4 PRINT_NEWLINE\n\n  3           5 LOAD_GLOBAL              0 (b)\n              8 PRINT_ITEM\n              9 PRINT_NEWLINE\n\n  4          10 LOAD_CONST               1 (1)\n             13 STORE_FAST               0 (a)\n             16 LOAD_CONST               0 (None)\n             19 RETURN_VALUE\n \n\n As you can see, the bytecode for accessing a is  LOAD_FAST , and for b,  LOAD_GLOBAL .  This is because the compiler has identified that a is assigned to within the function, and classified it as a local variable.  The access mechanism for locals is fundamentally different for globals - they are statically assigned an offset in the frame's variables table, meaning lookup is a quick index, rather than the more expensive dict lookup as for globals.  Because of this, Python is reading the  print a  line as \"get the value of local variable 'a' held in slot 0, and print it\", and when it detects that this variable is still uninitialised, raises an exception. \n    ", "date_posted": "2008-12-16 09:49:28Z", "upvote": "\r\n            51\r\n        ", "accepted": "No", "user": {"stack_user_id": "9493", "name": "Brian", "reputation_score": "114k"}, "answer_comments": []}, {"stack_answer_id": "370364", "answer_content": "\r\n Python has rather interesting behavior when you try traditional global variable semantics.  I don't remember the details, but you can read the value of a variable declared in 'global' scope just fine, but if you want to modify it, you have to use the  global  keyword.  Try changing  test()  to this: \n\n def test():\n    global c\n    print(a)\n    print(b)\n    print(c)    # (A)\n    c+=1        # (B)\n \n\n Also, the reason you are getting this error is because you can also declare a new variable inside that function with the same name as a 'global' one, and it would be completely separate.  The interpreter thinks you are trying to make a new variable in this scope called  c  and modify it all in one operation, which isn't allowed in Python because this new  c  wasn't initialized. \n    ", "date_posted": "2016-12-10 06:53:57Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "15168", "name": "Jonathan Leffler", "reputation_score": "704k"}, "answer_comments": [{"stack_answer_id": "370364", "stack_answer_comment_id": "199334", "comment_content": "Thanks for your response, but I don't think it explains why the error is thrown at line (A), where I'm merely trying to print a variable. The program never gets to line (B) where it is trying to modify an un-initialized variable.", "user_id": "/users/46521/tba"}, {"stack_answer_id": "370364", "stack_answer_comment_id": "199708", "comment_content": "Python will read, parse and turn the whole function into internal bytecode before it starts running the program, so the fact that the \"turn c to local variable\" happens textually after the printing of the value doesn't, as it were, matter.", "user_id": null}, {"stack_answer_id": "370364", "stack_answer_comment_id": "129046450", "comment_content": "Python lets you access global variables in a local scope for reading, but not for writing.  This answer has a nice work-around with explanation in comment below... +=1.", "user_id": null}]}, {"stack_answer_id": "24035261", "answer_content": "\r\n The best example that makes it clear is: \n\n bar = 42\ndef foo():\n    print bar\n    if False:\n        bar = 0\n \n\n when calling  foo()  , this also  raises   UnboundLocalError  although we will never reach to line  bar=0 , so logically local variable should never be created. \n\n The mystery lies in \" Python is an Interpreted Language \" and the declaration of the function  foo  is interpreted as a single statement (i.e. a compound statement), it just interprets it dumbly and creates local and global scopes. So  bar  is recognized in local scope before execution. \n\n For  more examples  like this Read this post:  http://blog.amir.rachum.com/blog/2013/07/09/python-common-newbie-mistakes-part-2/ \n\n This post provides a Complete Description and Analyses of the Python Scoping of variables: \n    ", "date_posted": "2014-06-04 10:39:21Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "1731648", "name": "Sahil kalra", "reputation_score": "7,578"}, "answer_comments": []}, {"stack_answer_id": "1745180", "answer_content": "\r\n Here are two links that may help \n\n 1:  docs.python.org/3.1/faq/programming.html?highlight=nonlocal#why-am-i-getting-an-unboundlocalerror-when-the-variable-has-a-value \n\n 2:  docs.python.org/3.1/faq/programming.html?highlight=nonlocal#how-do-i-write-a-function-with-output-parameters-call-by-reference \n\n link one describes the error UnboundLocalError.  Link two can help with with re-writing your test function.  Based on link two, the original problem could be rewritten as: \n\n >>> a, b, c = (1, 2, 3)\n>>> print (a, b, c)\n(1, 2, 3)\n>>> def test (a, b, c):\n...     print (a)\n...     print (b)\n...     print (c)\n...     c += 1\n...     return a, b, c\n...\n>>> a, b, c = test (a, b, c)\n1\n2\n3\n>>> print (a, b ,c)\n(1, 2, 4)\n \n    ", "date_posted": "2011-09-13 04:00:56Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "68210", "name": "Daniel X Moore", "reputation_score": "14.2k"}, "answer_comments": []}, {"stack_answer_id": "476123", "answer_content": "\r\n This is not a direct answer to your question, but it is closely related, as it's another gotcha caused by the relationship between augmented assignment and function scopes. \n\n In most cases, you tend to think of augmented assignment ( a += b ) as exactly equivalent to simple assignment ( a = a + b ). It is possible to get into some trouble with this though, in one corner case. Let me explain: \n\n The way Python's simple assignment works means that if  a  is passed into a function (like  func(a) ; note that Python is always pass-by-reference), then  a = a + b  will not modify the  a  that is passed in. Instead, it will just modify the local pointer to  a .  \n\n But if you use  a += b , then it is sometimes implemented as: \n\n a = a + b\n \n\n or sometimes (if the method exists) as: \n\n a.__iadd__(b)\n \n\n In the first case (as long as  a  is not declared global), there are no side-effects outside local scope, as the assignment to  a  is just a pointer update. \n\n In the second case,  a  will actually modify itself, so all references to  a  will point to the modified version. This is demonstrated by the following code: \n\n def copy_on_write(a):\n      a = a + a\ndef inplace_add(a):\n      a += a\na = [1]\ncopy_on_write(a)\nprint a # [1]\ninplace_add(a)\nprint a # [1, 1]\nb = 1\ncopy_on_write(b)\nprint b # [1]\ninplace_add(b)\nprint b # 1\n \n\n So the trick is to avoid augmented assignment on function arguments (I try to only use it for local/loop variables). Use simple assignment, and you will be safe from ambiguous behaviour.  \n    ", "date_posted": "2016-12-10 07:07:03Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "15168", "name": "Jonathan Leffler", "reputation_score": "704k"}, "answer_comments": []}, {"stack_answer_id": "370752", "answer_content": "\r\n The Python interpreter will read a function as a complete unit. I think of it as reading it in two passes, once to gather its closure (the local variables), then again to turn it into byte-code. \n\n As I'm sure you were already aware, any name used on the left of a '=' is implicitly a local variable. More than once I've been caught out by changing a variable access to a += and it's suddenly a different variable. \n\n I also wanted to point out it's not really anything to do with global scope specifically. You get the same behaviour with nested functions. \n    ", "date_posted": "2008-12-16 08:58:10Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "11828", "name": "James Hopkin", "reputation_score": "13.5k"}, "answer_comments": []}, {"stack_answer_id": "40409182", "answer_content": "\r\n c+=1  assigns  c , python assumes assigned variables are local, but in this case it hasn't been declared locally. \n\n Either use the  global  or  nonlocal  keywords.  \n\n nonlocal  works only in python 3, so if you're using python 2 and don't want to make your variable global, you can use a mutable object: \n\n my_variables = { # a mutable object\n    'c': 3\n}\n\ndef test():\n    my_variables['c'] +=1\n\ntest()\n \n    ", "date_posted": "2016-11-03 18:52:39Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "2392540", "name": "Colegram", "reputation_score": "106"}, "answer_comments": []}, {"stack_answer_id": "34153129", "answer_content": "\r\n The best way to reach class variable is directly accesing by class name \n\n class Employee:\n    counter=0\n\n    def __init__(self):\n        Employee.counter+=1\n \n    ", "date_posted": "2015-12-08 10:09:47Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "4104008", "name": "Harun ERGUL", "reputation_score": "5,446"}, "answer_comments": []}, {"stack_answer_id": "71914016", "answer_content": "\r\n You can also get this message if you define a variable with the same name as a method. \n For example: \n def teams():\n    ...\n\ndef some_other_method():\n    teams = teams()\n \n The solution, is to rename method  teams()  to something else like  get_teams() . \n Since it is only used locally, the Python message is rather misleading! \n You end up with something like this to get around it: \n def teams():\n    ...\n\ndef some_other_method():\n    teams = get_teams()\n \n    ", "date_posted": "2022-04-18 15:47:47Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "495157", "name": "JGFMK", "reputation_score": "7,889"}, "answer_comments": []}, {"stack_answer_id": "72633950", "answer_content": "\r\n This issue can also occur when the  del  keyword is utilized on the variable down the line, after initialization, typically in a loop or a conditional block. \n    ", "date_posted": "2022-06-15 15:21:05Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "221781", "name": "izilotti", "reputation_score": "4,659"}, "answer_comments": []}, {"stack_answer_id": "58002885", "answer_content": "\r\n The same problem bothers me. Using  nonlocal  and  global  can solve the problem. \nHowever, attention is needed for the usage of  nonlocal , it works for nested functions. However, at the module level, it does not work. See  examples  here. \n    ", "date_posted": "2020-12-06 21:16:23Z", "upvote": "\r\n            -1\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}], "user": {"stack_user_id": "46521", "name": "tba", "reputation_score": "5,881"}, "question_comments": [{"stack_question_id": "370357", "stack_question_comment_id": "110835190", "comment_content": "Does this answer your question? ", "user_id": null}, {"stack_question_id": "370357", "stack_question_comment_id": "123548687", "comment_content": "Same error but different cause: ", "user_id": null}]},
{"stack_question_id": "6260089", "question_title": "Strange result when removing item from a list while iterating over it", "question_content": "\r\n                I've got this piece of code:\nnumbers = list(range(1, 50))\n\nfor i in numbers:\n    if i < 20:\n        numbers.remove(i)\n\nprint(numbers)\n\nbut the result I'm getting is:\n[2, 4, 6, 8, 10, 12, 14, 16, 18,...\r\n", "question_url": "/questions/6260089/strange-result-when-removing-item-from-a-list-while-iterating-over-it", "date_posted": "Jun 7, 2011 at 2:29", "upvote": "7", "view": "1", "tags": ["python", "list", "loops"], "answers_count": "8", "answers": [{"stack_answer_id": "6260097", "answer_content": "\r\n You're modifying the list while you iterate over it. That means that the first time through the loop,  i == 1 , so 1 is removed from the list. Then the  for  loop goes to the second item in the list, which is not 2, but 3! Then that's removed from the list, and then the  for  loop goes on to the third item in the list, which is now 5. And so on. Perhaps it's easier to visualize like so, with a ^ pointing to the value of  i : \n\n [1, 2, 3, 4, 5, 6...]\n ^\n \n\n That's the state of the list initially; then 1 is removed and the loop goes to the second item in the list: \n\n [2, 3, 4, 5, 6...]\n    ^\n[2, 4, 5, 6...]\n       ^\n \n\n And so on.  \n\n There's no good way to alter a list's length while iterating over it. The best you can do is something like this: \n\n numbers = [n for n in numbers if n >= 20]\n \n\n or this, for in-place alteration (the thing in parens is a generator expression, which is implicitly converted into a tuple before slice-assignment): \n\n numbers[:] = (n for in in numbers if n >= 20)\n \n\n If you want to perform an operation on n before removing it, one trick you could try is this: \n\n for i, n in enumerate(numbers):\n    if n < 20 :\n        print(\"do something\")\n        numbers[i] = None\nnumbers = [n for n in numbers if n is not None]\n \n    ", "date_posted": "2020-05-28 12:59:52Z", "upvote": "\r\n            133\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "1398841", "name": "phoenix", "reputation_score": "6,278"}, "answer_comments": [{"stack_answer_id": "6260097", "stack_answer_comment_id": "125375319", "comment_content": "Related note on ", "user_id": null}, {"stack_answer_id": "6260097", "stack_answer_comment_id": "126368556", "comment_content": "This is a good answer, but with the final solution, \"if you want to perform an operation...\", is slightly unsatisfactory because 1) in fact there is no need to include that qualification: it is just a waste of effort to try and remove elements while iterating in a single operation, so this 2-stage solution applies in all cases, and 2) because there should be a warning that setting to ", "user_id": null}, {"stack_answer_id": "6260097", "stack_answer_comment_id": "126369014", "comment_content": "When I say that about the \"waste of effort\", I am referring to the \"general\" solution by the way, i.e. when random elements may need removing, rather than the \"specialist\" case of removing elements only at the start (or only at the end), which lends itself to something simple, like your list comprehension solution...", "user_id": null}]}, {"stack_answer_id": "8752528", "answer_content": "\r\n Begin at the list's end and go backwards: \n li = list(range(1, 15))\nprint(li)\n\nfor i in range(len(li) - 1, -1, -1):\n    if li[i] < 6:\n        del li[i]\n        \nprint(li)\n \n Result: \n [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14] \n[6, 7, 8, 9, 10, 11, 12, 13, 14]\n \n    ", "date_posted": "2022-04-07 11:47:31Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": [{"stack_answer_id": "8752528", "stack_answer_comment_id": "124218137", "comment_content": "How I wish I could +2 this answer!  Elegant, easy...not entirely obfuscated.", "user_id": null}, {"stack_answer_id": "8752528", "stack_answer_comment_id": "126368881", "comment_content": "This is a very specialised answer: it is not in fact clear whether we're meant to be looking for a general solution to the problem of how to remove elements while iterating, or how to do this exclusively when we just want to remove the first n elements of a list. The chosen answer provides the former, which is infinitely more helpful, but also the latter, in the shape of a one-line list comprehension solution.", "user_id": null}, {"stack_answer_id": "8752528", "stack_answer_comment_id": "126851697", "comment_content": "@mikerodent no it's not. It's pretty common when you want to modify a list while iterating over it that going backwards works", "user_id": null}, {"stack_answer_id": "8752528", "stack_answer_comment_id": "126853332", "comment_content": "@Boris you haven't understood my comment. The OP's question does not specify that we are removing contiguous elements (either from the start or end of the list).", "user_id": null}, {"stack_answer_id": "8752528", "stack_answer_comment_id": "126853360", "comment_content": "I still don't understand your comment then because it doesn't matter whether the list is shuffled or ordered, this code will still work.", "user_id": null}]}, {"stack_answer_id": "6260408", "answer_content": "\r\n @senderle's  answer is the way to go! \n Having said that to further illustrate even a bit more your problem, if you think about it, you will always want to remove the index 0 twenty times: \n [1,2,3,4,5............50]\n ^\n[2,3,4,5............50]\n ^\n[3,4,5............50]\n ^\n \n So you could actually go with something like this: \n aList = list(range(50))\ni = 0\nwhile i < 20:\n    aList.pop(0)\n    i += 1\n\nprint(aList) #[21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n \n I hope it helps. \n \n The ones below are  not  bad practices AFAIK. \n EDIT (Some more): \n lis = range(50)\nlis = lis[20:]\n \n Will do the job also. \n EDIT2 (I'm bored): \n functional = filter(lambda x: x> 20, range(50))\n \n    ", "date_posted": "2021-06-15 09:17:27Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "7496129", "name": "Sneha Valabailu", "reputation_score": "95"}, "answer_comments": []}, {"stack_answer_id": "64835673", "answer_content": "\r\n So I found a solution but it's really clumsy... \n First of all you make an index array, where you list all the index' you want to delete like in the following \n numbers = range(1, 50)\nindex_arr = []\n\nfor i in range(len(numbers):\n    if numbers[i] < 20:\n        index_arr.append(i)\n\n \n after that you want to delete all the entries from the numbers list with the index saved in the index_arr. The problem you will encounter is the same as before. Therefore you have to subtract 1 from every index in the index_arr after you just removed a number from the numbers arr, like in the following: \n numbers = range(1, 50)\nindex_arr = []\n\nfor i in range(len(numbers):\n    if numbers[i] < 20:\n        index_arr.append(i)\n\nfor del_index in index_list:\n    numbers.pop(del_index)\n\n    #the nasty part\n    for i in range(len(index_list)):\n        index_list[i] -= 1\n \n It will work, but I guess it's not the intended way to do it \n    ", "date_posted": "2020-11-14 15:44:33Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "13761698", "name": "Yassin Julian", "reputation_score": "39"}, "answer_comments": []}, {"stack_answer_id": "70269930", "answer_content": "\r\n Building on and simplying the answer by @eyquem ... \n The problem is that elements are being yanked out from under you as you iterate, skipping numbers as you progress to what  was  the next number. \n If you start from the end and go backwards, removing items on-the-go won't matter, because when it steps to the \"next\" item (actually the prior item), the deletion does not affect the first half of the list. \n Simply adding  reversed()  to your iterator solves the problem. A comment would be good form to preclude future developers from \"tidying up\" your code and breaking it mysteriously. \n for i in reversed(numbers): # `reversed` so removing doesn't foobar iteration\n  if i < 20:\n    numbers.remove(i)\n \n    ", "date_posted": "2021-12-08 04:24:02Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "4454732", "name": "David Hempy", "reputation_score": "4,434"}, "answer_comments": []}, {"stack_answer_id": "67652659", "answer_content": "\r\n As an additional information to @Senderle's answer, just for records,  I thought it's helpful to visualize the logic behind the scene when python sees  for  on a \" Sequence type \". \n Let's say we have : \n lst = [1, 2, 3, 4, 5]\n\nfor i in lst:\n    print(i ** 2)\n \n It is actually going to be : \n index = 0\nwhile True:\n    try:\n        i = lst.__getitem__(index)\n    except IndexError:\n        break\n    print(i ** 2)\n    index += 1\n \n That's what it is, there is a try-catch mechanism that  for  has when we use it on a Sequence types or Iterables(It's a little different though - calling  next()  and  StopIteration  Exception). \n *All I'm trying to say is, python will keep track of an independent variable here called  index , so no matter what happens to the list (removing or adding), python increments that variable and calls  __getitem__()  method with \"this variable\" and asks for item. \n    ", "date_posted": "2021-05-22 17:59:27Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "13944524", "name": "S.B", "reputation_score": "8,308"}, "answer_comments": []}, {"stack_answer_id": "67703510", "answer_content": "\r\n You could also use continue to  ignore the values less than 20 \n mylist = []\n\nfor i in range(51):\n    if i<20:\n        continue\n    else:\n        mylist.append(i)\nprint(mylist)\n \n    ", "date_posted": "2021-05-26 10:57:47Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "13734451", "name": "Moses", "reputation_score": "1,025"}, "answer_comments": []}, {"stack_answer_id": "71138926", "answer_content": "\r\n Since  Python 3.3  you may use the list  copy()  method as the iterator: \n numbers = list(range(1, 50))\n\nfor i in numbers.copy():\n    if i < 20:\n        numbers.remove(i)\nprint(numbers)\n\n[20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n \n    ", "date_posted": "2022-02-16 09:07:21Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "3474282", "name": "Cosmittus", "reputation_score": "622"}, "answer_comments": [{"stack_answer_id": "71138926", "stack_answer_comment_id": "126368658", "comment_content": "This looks like a neat suggestion to a classic problem, but I'm not sure that in practice it will prove better than the 2-stage solution suggested at the end of the chosen answer: firstly, what is the cost of the ", "user_id": null}]}], "user": {"stack_user_id": "415088", "name": "Finger twist", "reputation_score": "3,314"}, "question_comments": [{"stack_question_id": "6260089", "stack_question_comment_id": "129230071", "comment_content": "See also: ", "user_id": null}]},
{"stack_question_id": "38987", "question_title": "How do I merge two dictionaries in a single expression?", "question_content": "\r\n                I want to merge two dictionaries into a new dictionary.\nx = {'a': 1, 'b': 2}\ny = {'b': 3, 'c': 4}\nz = merge(x, y)\n\n>>> z\n{'a': 1, 'b': 3, 'c': 4}\n\nWhenever a key k is present in both ...\r\n", "question_url": "/questions/38987/how-do-i-merge-two-dictionaries-in-a-single-expression", "date_posted": "Sep 2, 2008 at 7:44", "upvote": "6", "view": "2", "tags": ["python", "dictionary", "merge"], "answers_count": "4", "answers": [{"stack_answer_id": "26853961", "answer_content": "\r\n How can I merge two Python dictionaries in a single expression? \n For dictionaries  x  and  y , their shallowly-merged dictionary  z  takes values from  y , replacing those from  x . \n \n In Python 3.9.0 or greater (released 17 October 2020,  PEP-584 ,  discussed here ): \n z = x | y\n \n \n In Python 3.5 or greater: \n z = {**x, **y}\n \n \n In Python 2, (or 3.4 or lower) write a function: \n def merge_two_dicts(x, y):\n    z = x.copy()   # start with keys and values of x\n    z.update(y)    # modifies z with keys and values of y\n    return z\n \n and now: \n z = merge_two_dicts(x, y)\n \n \n \n Explanation \n Say you have two dictionaries and you want to merge them into a new dictionary without altering the original dictionaries: \n x = {'a': 1, 'b': 2}\ny = {'b': 3, 'c': 4}\n \n The desired result is to get a new dictionary ( z ) with the values merged, and the second dictionary's values overwriting those from the first. \n >>> z\n{'a': 1, 'b': 3, 'c': 4}\n \n A new syntax for this, proposed in  PEP 448  and  available as of Python 3.5 , is \n z = {**x, **y}\n \n And it is indeed a single expression. \n Note that we can merge in with literal notation as well: \n z = {**x, 'foo': 1, 'bar': 2, **y}\n \n and now: \n >>> z\n{'a': 1, 'b': 3, 'foo': 1, 'bar': 2, 'c': 4}\n \n It is now showing as implemented in the  release schedule for 3.5, PEP 478 , and it has now made its way into the  What's New in Python 3.5  document. \n However, since many organizations are still on Python 2, you may wish to do this in a backward-compatible way. The classically Pythonic way, available in Python 2 and Python 3.0-3.4, is to do this as a two-step process: \n z = x.copy()\nz.update(y) # which returns None since it mutates z\n \n In both approaches,  y  will come second and its values will replace  x 's values, thus  b  will point to  3  in our final result. \n Not yet on Python 3.5, but want a  single expression \n If you are not yet on Python 3.5 or need to write backward-compatible code, and you want this in a  single expression , the most performant while the correct approach is to put it in a function: \n def merge_two_dicts(x, y):\n    \"\"\"Given two dictionaries, merge them into a new dict as a shallow copy.\"\"\"\n    z = x.copy()\n    z.update(y)\n    return z\n \n and then you have a single expression: \n z = merge_two_dicts(x, y)\n \n You can also make a function to merge an arbitrary number of dictionaries, from zero to a very large number: \n def merge_dicts(*dict_args):\n    \"\"\"\n    Given any number of dictionaries, shallow copy and merge into a new dict,\n    precedence goes to key-value pairs in latter dictionaries.\n    \"\"\"\n    result = {}\n    for dictionary in dict_args:\n        result.update(dictionary)\n    return result\n \n This function will work in Python 2 and 3 for all dictionaries. e.g. given dictionaries  a  to  g : \n z = merge_dicts(a, b, c, d, e, f, g) \n \n and key-value pairs in  g  will take precedence over dictionaries  a  to  f , and so on. \n Critiques of Other Answers \n Don't use what you see in the formerly accepted answer: \n z = dict(x.items() + y.items())\n \n In Python 2, you create two lists in memory for each dict, create a third list in memory with length equal to the length of the first two put together, and then discard all three lists to create the dict.  In Python 3, this will fail  because you're adding two  dict_items  objects together, not two lists - \n >>> c = dict(a.items() + b.items())\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: unsupported operand type(s) for +: 'dict_items' and 'dict_items'\n \n and you would have to explicitly create them as lists, e.g.  z = dict(list(x.items()) + list(y.items())) . This is a waste of resources and computation power. \n Similarly, taking the union of  items()  in Python 3 ( viewitems()  in Python 2.7) will also fail when values are unhashable objects (like lists, for example). Even if your values are hashable,  since sets are semantically unordered, the behavior is undefined in regards to precedence. So don't do this: \n >>> c = dict(a.items() | b.items())\n \n This example demonstrates what happens when values are unhashable: \n >>> x = {'a': []}\n>>> y = {'b': []}\n>>> dict(x.items() | y.items())\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: unhashable type: 'list'\n \n Here's an example where  y  should have precedence, but instead the value from  x  is retained due to the arbitrary order of sets: \n >>> x = {'a': 2}\n>>> y = {'a': 1}\n>>> dict(x.items() | y.items())\n{'a': 2}\n \n Another hack you should not use: \n z = dict(x, **y)\n \n This uses the  dict  constructor and is very fast and memory-efficient (even slightly more so than our two-step process) but unless you know precisely what is happening here (that is, the second dict is being passed as keyword arguments to the dict constructor), it's difficult to read, it's not the intended usage, and so it is not Pythonic. \n Here's an example of the usage being  remediated in django . \n Dictionaries are intended to take hashable keys (e.g.  frozenset s or tuples), but  this method fails in Python 3 when keys are not strings. \n >>> c = dict(a, **b)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: keyword arguments must be strings\n \n From the  mailing list , Guido van Rossum, the creator of the language, wrote: \n \n I am fine with\ndeclaring dict({}, **{1:3}) illegal, since after all it is abuse of\nthe ** mechanism. \n \n and \n \n Apparently dict(x, **y) is going around as \"cool hack\" for \"call\nx.update(y) and return x\". Personally, I find it more despicable than\ncool. \n \n It is my understanding (as well as the understanding of the  creator of the language ) that the intended usage for  dict(**y)  is for creating dictionaries for readability purposes, e.g.: \n dict(a=1, b=10, c=11)\n \n instead of \n {'a': 1, 'b': 10, 'c': 11}\n \n Response to comments \n \n Despite what Guido says,  dict(x, **y)  is in line with the dict specification, which btw. works for both Python 2 and 3. The fact that this only works for string keys is a direct consequence of how keyword parameters work and not a short-coming of dict. Nor is using the ** operator in this place an abuse of the mechanism, in fact, ** was designed precisely to pass dictionaries as keywords. \n \n Again, it doesn't work for 3 when keys are not strings. The implicit calling contract is that namespaces take ordinary dictionaries, while users must only pass keyword arguments that are strings. All other callables enforced it.  dict  broke this consistency in Python 2: \n >>> foo(**{('a', 'b'): None})\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: foo() keywords must be strings\n>>> dict(**{('a', 'b'): None})\n{('a', 'b'): None}\n \n This inconsistency was bad given other implementations of Python (PyPy, Jython, IronPython). Thus it was fixed in Python 3, as this usage could be a breaking change. \n I submit to you that it is malicious incompetence to intentionally write code that only works in one version of a language or that only works given certain arbitrary constraints. \n More comments: \n \n dict(x.items() + y.items())  is still the most readable solution for Python 2. Readability counts. \n \n My response:  merge_two_dicts(x, y)  actually seems much clearer to me, if we're actually concerned about readability. And it is not forward compatible, as Python 2 is increasingly deprecated. \n \n {**x, **y}  does not seem to handle nested dictionaries. the contents of nested keys are simply overwritten, not merged [...] I ended up being burnt by these answers that do not merge recursively and I was surprised no one mentioned it. In my interpretation of the word \"merging\" these answers describe \"updating one dict with another\", and not merging. \n \n Yes. I must refer you back to the question, which is asking for a  shallow  merge of  two  dictionaries, with the first's values being overwritten by the second's - in a single expression. \n Assuming two dictionaries of dictionaries, one might recursively merge them in a single function, but you should be careful not to modify the dictionaries from either source, and the surest way to avoid that is to make a copy when assigning values. As keys must be hashable and are usually therefore immutable, it is pointless to copy them: \n from copy import deepcopy\n\ndef dict_of_dicts_merge(x, y):\n    z = {}\n    overlapping_keys = x.keys() & y.keys()\n    for key in overlapping_keys:\n        z[key] = dict_of_dicts_merge(x[key], y[key])\n    for key in x.keys() - overlapping_keys:\n        z[key] = deepcopy(x[key])\n    for key in y.keys() - overlapping_keys:\n        z[key] = deepcopy(y[key])\n    return z\n \n Usage: \n >>> x = {'a':{1:{}}, 'b': {2:{}}}\n>>> y = {'b':{10:{}}, 'c': {11:{}}}\n>>> dict_of_dicts_merge(x, y)\n{'b': {2: {}, 10: {}}, 'a': {1: {}}, 'c': {11: {}}}\n \n Coming up with contingencies for other value types is far beyond the scope of this question, so I will point you at  my answer to the canonical question on a \"Dictionaries of dictionaries merge\" . \n Less Performant But Correct Ad-hocs \n These approaches are less performant, but they will provide correct behavior.\nThey will be  much less  performant than  copy  and  update  or the new unpacking because they iterate through each key-value pair at a higher level of abstraction, but they  do  respect the order of precedence (latter dictionaries have precedence) \n You can also chain the dictionaries manually inside a  dict comprehension : \n {k: v for d in dicts for k, v in d.items()} # iteritems in Python 2.7\n \n or in Python 2.6 (and perhaps as early as 2.4 when generator expressions were introduced): \n dict((k, v) for d in dicts for k, v in d.items()) # iteritems in Python 2\n \n itertools.chain  will chain the iterators over the key-value pairs in the correct order: \n from itertools import chain\nz = dict(chain(x.items(), y.items())) # iteritems in Python 2\n \n Performance Analysis \n I'm only going to do the performance analysis of the usages known to behave correctly. (Self-contained so you can copy and paste yourself.) \n from timeit import repeat\nfrom itertools import chain\n\nx = dict.fromkeys('abcdefg')\ny = dict.fromkeys('efghijk')\n\ndef merge_two_dicts(x, y):\n    z = x.copy()\n    z.update(y)\n    return z\n\nmin(repeat(lambda: {**x, **y}))\nmin(repeat(lambda: merge_two_dicts(x, y)))\nmin(repeat(lambda: {k: v for d in (x, y) for k, v in d.items()}))\nmin(repeat(lambda: dict(chain(x.items(), y.items()))))\nmin(repeat(lambda: dict(item for d in (x, y) for item in d.items())))\n \n In Python 3.8.1, NixOS: \n >>> min(repeat(lambda: {**x, **y}))\n1.0804965235292912\n>>> min(repeat(lambda: merge_two_dicts(x, y)))\n1.636518670246005\n>>> min(repeat(lambda: {k: v for d in (x, y) for k, v in d.items()}))\n3.1779992282390594\n>>> min(repeat(lambda: dict(chain(x.items(), y.items()))))\n2.740647904574871\n>>> min(repeat(lambda: dict(item for d in (x, y) for item in d.items())))\n4.266070580109954\n \n $ uname -a\nLinux nixos 4.19.113 #1-NixOS SMP Wed Mar 25 07:06:15 UTC 2020 x86_64 GNU/Linux\n \n Resources on Dictionaries \n \n My explanation of Python's  dictionary implementation , updated for 3.6. \n Answer on how to add new keys to a dictionary \n Mapping two lists into a dictionary \n The official Python docs on dictionaries \n The Dictionary Even Mightier  - talk by Brandon Rhodes at Pycon 2017 \n Modern Python Dictionaries, A Confluence of Great Ideas  - talk by Raymond Hettinger at Pycon 2017 \n \n    ", "date_posted": "2022-03-29 10:49:08Z", "upvote": "\r\n            8286\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": [{"stack_answer_id": "26853961", "stack_answer_comment_id": "98971751", "comment_content": "@MohammadAzim \"strings only\" only applies to keyword argument expansion in callables, not generalized unpacking syntax. To demonstrate that this works: ", "user_id": null}, {"stack_answer_id": "26853961", "stack_answer_comment_id": "106950304", "comment_content": "This may be changed when PEP-0584 is accepted. A new union operator will be implemented with the following syntax: ", "user_id": null}, {"stack_answer_id": "26853961", "stack_answer_comment_id": "106950627", "comment_content": "@cal97g yes, I addressed that in my answer about 10 days ago: ", "user_id": null}, {"stack_answer_id": "26853961", "stack_answer_comment_id": "107329096", "comment_content": "Hi, the top is a summary, yes.  Up to you.  The whole thing would be a great blog post.  Note Py 3.4 and below are EOL, 3.5 approaching EOL in 2020-09.", "user_id": null}, {"stack_answer_id": "26853961", "stack_answer_comment_id": "109402225", "comment_content": "I agree with the eagerness to leave the old way behind, but sometimes people have to work in environments where they only have the older technology available to them. People also have to update code, and seeing the old way next to the new way allows them to confidently replace the old code with equivalent new code. I am open to suggestions on reorganizing the material, but I think we need to keep the older information.", "user_id": null}]}, {"stack_answer_id": "38990", "answer_content": "\r\n In your case, what you can do is: \n z = dict(list(x.items()) + list(y.items()))\n \n This will, as you want it, put the final dict in  z , and make the value for key  b  be properly overridden by the second ( y ) dict's value: \n >>> x = {'a':1, 'b': 2}\n>>> y = {'b':10, 'c': 11}\n>>> z = dict(list(x.items()) + list(y.items()))\n>>> z\n{'a': 1, 'c': 11, 'b': 10}\n\n \n If you use Python 2, you can even remove the  list()  calls. To create z: \n >>> z = dict(x.items() + y.items())\n>>> z\n{'a': 1, 'c': 11, 'b': 10}\n \n If you use Python version 3.9.0a4 or greater, then you can directly use: \n x = {'a':1, 'b': 2}\ny = {'b':10, 'c': 11}\nz = x | y\nprint(z)\n \n {'a': 1, 'c': 11, 'b': 10}\n \n    ", "date_posted": "2020-10-30 21:08:09Z", "upvote": "\r\n            1766\r\n        ", "accepted": "No", "user": {"stack_user_id": "3815432", "name": "Nikita Vlasenko", "reputation_score": "3,634"}, "answer_comments": [{"stack_answer_id": "38990", "stack_answer_comment_id": "107286634", "comment_content": "Don't use this as it is very inefficient.  (See the timeit results below.)  It may have been necessary in the Py2 days if a wrapper function was not an option, but those days are now past.", "user_id": null}]}, {"stack_answer_id": "39437", "answer_content": "\r\n An alternative: \n\n z = x.copy()\nz.update(y)\n \n    ", "date_posted": "2008-09-02 13:00:46Z", "upvote": "\r\n            729\r\n        ", "accepted": "No", "user": {"stack_user_id": "188", "name": "Matthew Schinckel", "reputation_score": "34.1k"}, "answer_comments": [{"stack_answer_id": "39437", "stack_answer_comment_id": "22031787", "comment_content": "To clarify why this doesn't meet the critera provided by the question: it's not a single expression and it doesn't return z.", "user_id": null}, {"stack_answer_id": "39437", "stack_answer_comment_id": "80608499", "comment_content": "Put it this way: if you need to put two lines of comments explaining your one line of code to the people you hand your code off to...have you really done it in one line? :) I fully agree Python is not good for this: there should be a much easier way. While this answer is more pythonic, is it really all that explicit or clear? ", "user_id": null}, {"stack_answer_id": "39437", "stack_answer_comment_id": "106803501", "comment_content": "Well, if people insist on making it a oneliner, you can always do ", "user_id": null}, {"stack_answer_id": "39437", "stack_answer_comment_id": "128914525", "comment_content": "@AlexanderOh I am not sure whenever this is a joke or not; I see this as a perfectly (valid) answ!  (at least in terms of it works) but Of course;  yeah; the second comment sets a precedent!    either way; it is ", "user_id": null}, {"stack_answer_id": "39437", "stack_answer_comment_id": "128918894", "comment_content": "@WilliamMartens it wasn't a joke. But let's face it, if you optimize for single line expressions,you are optimizing for the wrong thing.", "user_id": null}]}, {"stack_answer_id": "39858", "answer_content": "\r\n Another, more concise, option: \n\n z = dict(x, **y)\n \n\n Note : this has become a popular answer, but it is important to point out that if  y  has any non-string keys, the fact that this works at all is an abuse of a CPython implementation detail, and it does not work in Python 3, or in PyPy, IronPython, or Jython. Also,  Guido is not a fan . So I can't recommend this technique for forward-compatible or cross-implementation portable code, which really means it should be avoided entirely. \n    ", "date_posted": "2016-01-21 06:43:24Z", "upvote": "\r\n            421\r\n        ", "accepted": "No", "user": {"stack_user_id": "3207", "name": "Carl Meyer", "reputation_score": "116k"}, "answer_comments": [{"stack_answer_id": "39858", "stack_answer_comment_id": "97993261", "comment_content": ", can't speak to Jython or Iron. Given this pattern is ", "user_id": null}, {"stack_answer_id": "39858", "stack_answer_comment_id": "98801135", "comment_content": "@amcgregor You missed the key phrase \"if y has any non-string keys.\" That's what doesn't work in Python3; the fact that it works in CPython 2 is an implementation detail that can't be relied on. IFF all your keys are guaranteed to be strings, this is a fully supported option.", "user_id": "/users/3207/carl-meyer"}]}, {"stack_answer_id": "49492", "answer_content": "\r\n This probably won't be a popular answer, but you almost certainly do not want to do this.  If you want a copy that's a merge, then use copy (or  deepcopy , depending on what you want) and then update.  The two lines of code are much more readable - more Pythonic - than the single line creation with .items() + .items().  Explicit is better than implicit. \n\n In addition, when you use .items() (pre Python 3.0), you're creating a new list that contains the items from the dict.  If your dictionaries are large, then that is quite a lot of overhead (two large lists that will be thrown away as soon as the merged dict is created).  update() can work more efficiently, because it can run through the second dict item-by-item. \n\n In terms of  time : \n\n >>> timeit.Timer(\"dict(x, **y)\", \"x = dict(zip(range(1000), range(1000)))\\ny=dict(zip(range(1000,2000), range(1000,2000)))\").timeit(100000)\n15.52571702003479\n>>> timeit.Timer(\"temp = x.copy()\\ntemp.update(y)\", \"x = dict(zip(range(1000), range(1000)))\\ny=dict(zip(range(1000,2000), range(1000,2000)))\").timeit(100000)\n15.694622993469238\n>>> timeit.Timer(\"dict(x.items() + y.items())\", \"x = dict(zip(range(1000), range(1000)))\\ny=dict(zip(range(1000,2000), range(1000,2000)))\").timeit(100000)\n41.484580039978027\n \n\n IMO the tiny slowdown between the first two is worth it for the readability.  In addition, keyword arguments for dictionary creation was only added in Python 2.3, whereas copy() and update() will work in older versions. \n    ", "date_posted": "2014-08-05 23:56:02Z", "upvote": "\r\n            252\r\n        ", "accepted": "No", "user": {"stack_user_id": "2213647", "name": "twasbrillig", "reputation_score": "15.3k"}, "answer_comments": []}, {"stack_answer_id": "228366", "answer_content": "\r\n In a follow-up answer, you asked about the relative performance of these two alternatives: \n\n z1 = dict(x.items() + y.items())\nz2 = dict(x, **y)\n \n\n On my machine, at least (a fairly ordinary x86_64 running Python 2.5.2), alternative  z2  is not only shorter and simpler but also significantly faster.  You can verify this for yourself using the  timeit  module that comes with Python. \n\n Example 1: identical dictionaries mapping 20 consecutive integers to themselves: \n\n % python -m timeit -s 'x=y=dict((i,i) for i in range(20))' 'z1=dict(x.items() + y.items())'\n100000 loops, best of 3: 5.67 usec per loop\n% python -m timeit -s 'x=y=dict((i,i) for i in range(20))' 'z2=dict(x, **y)' \n100000 loops, best of 3: 1.53 usec per loop\n \n\n z2  wins by a factor of 3.5 or so.  Different dictionaries seem to yield quite different results, but  z2  always seems to come out ahead.  (If you get inconsistent results for the  same  test, try passing in  -r  with a number larger than the default 3.) \n\n Example 2: non-overlapping dictionaries mapping 252 short strings to integers and vice versa: \n\n % python -m timeit -s 'from htmlentitydefs import codepoint2name as x, name2codepoint as y' 'z1=dict(x.items() + y.items())'\n1000 loops, best of 3: 260 usec per loop\n% python -m timeit -s 'from htmlentitydefs import codepoint2name as x, name2codepoint as y' 'z2=dict(x, **y)'               \n10000 loops, best of 3: 26.9 usec per loop\n \n\n z2  wins by about a factor of 10.  That's a pretty big win in my book! \n\n After comparing those two, I wondered if  z1 's poor performance could be attributed to the overhead of constructing the two item lists, which in turn led me to wonder if this variation might work better: \n\n from itertools import chain\nz3 = dict(chain(x.iteritems(), y.iteritems()))\n \n\n A few quick tests, e.g. \n\n % python -m timeit -s 'from itertools import chain; from htmlentitydefs import codepoint2name as x, name2codepoint as y' 'z3=dict(chain(x.iteritems(), y.iteritems()))'\n10000 loops, best of 3: 66 usec per loop\n \n\n lead me to conclude that  z3  is somewhat faster than  z1 , but not nearly as fast as  z2 .  Definitely not worth all the extra typing. \n\n This discussion is still missing something important, which is a performance comparison of these alternatives with the \"obvious\" way of merging two lists: using the  update  method.  To try to keep things on an equal footing with the expressions, none of which modify x or y, I'm going to make a copy of x instead of modifying it in-place, as follows: \n\n z0 = dict(x)\nz0.update(y)\n \n\n A typical result: \n\n % python -m timeit -s 'from htmlentitydefs import codepoint2name as x, name2codepoint as y' 'z0=dict(x); z0.update(y)'\n10000 loops, best of 3: 26.9 usec per loop\n \n\n In other words,  z0  and  z2  seem to have essentially identical performance.  Do you think this might be a coincidence?  I don't.... \n\n In fact, I'd go so far as to claim that it's impossible for pure Python code to do any better than this.  And if you can do significantly better in a C extension module, I imagine the Python folks might well be interested in incorporating your code (or a variation on your approach) into the Python core.  Python uses  dict  in lots of places; optimizing its operations is a big deal. \n\n You could also write this as \n\n z0 = x.copy()\nz0.update(y)\n \n\n as Tony does, but (not surprisingly) the difference in notation turns out not to have any measurable effect on performance.  Use whichever looks right to you.  Of course, he's absolutely correct to point out that the two-statement version is much easier to understand. \n    ", "date_posted": "2015-01-10 02:32:55Z", "upvote": "\r\n            187\r\n        ", "accepted": "No", "user": {"stack_user_id": "128421", "name": "the Tin Man", "reputation_score": "156k"}, "answer_comments": [{"stack_answer_id": "228366", "stack_answer_comment_id": "46375571", "comment_content": "This does not work in Python 3; ", "user_id": null}]}, {"stack_answer_id": "16259217", "answer_content": "\r\n In Python 3.0 and later , you can use  collections.ChainMap  which groups multiple dicts or other mappings together to create a single, updateable view: \n >>> from collections import ChainMap\n>>> x = {'a':1, 'b': 2}\n>>> y = {'b':10, 'c': 11}\n>>> z = dict(ChainMap({}, y, x))\n>>> for k, v in z.items():\n        print(k, '-->', v)\n    \na --> 1\nb --> 10\nc --> 11\n \n Update for Python 3.5 and later : You can use  PEP 448  extended dictionary packing and unpacking.  This is fast and easy: \n >>> x = {'a':1, 'b': 2}\n>>> y = {'b':10, 'c': 11}\n>>> {**x, **y}\n{'a': 1, 'b': 10, 'c': 11}\n \n Update for Python 3.9 and later :  You can use the  PEP 584  union operator: \n >>> x = {'a':1, 'b': 2}\n>>> y = {'b':10, 'c': 11}\n>>> x | y\n{'a': 1, 'b': 10, 'c': 11}\n \n    ", "date_posted": "2020-12-11 06:43:11Z", "upvote": "\r\n            184\r\n        ", "accepted": "No", "user": {"stack_user_id": "424499", "name": "Raymond Hettinger", "reputation_score": "205k"}, "answer_comments": [{"stack_answer_id": "16259217", "stack_answer_comment_id": "71597496", "comment_content": "But one should be cautious while using ChainMap there's a catch that if you have duplicate keys the values from first mapping get used and when you call a ", "user_id": null}, {"stack_answer_id": "16259217", "stack_answer_comment_id": "71644530", "comment_content": "@Prerit What else would you expect it to do?  That's the normal way chained namespaces work.  Consider how $PATH works in bash.  Deleting an executable on the path doesn't preclude another executable with the same name further upstream.", "user_id": null}, {"stack_answer_id": "16259217", "stack_answer_comment_id": "71663990", "comment_content": "@Raymond Hettinger I agree, just added a caution. Most people may not know about it. :D", "user_id": null}, {"stack_answer_id": "16259217", "stack_answer_comment_id": "100615370", "comment_content": "@Prerit You could cast to ", "user_id": null}, {"stack_answer_id": "16259217", "stack_answer_comment_id": "120954371", "comment_content": "Suggested Edit Queue is full, but someone put the modification from @wjandrea into the answer, which is wrong - it's no longer a ", "user_id": null}]}, {"stack_answer_id": "44512", "answer_content": "\r\n I wanted something similar, but with the ability to specify how the values on duplicate keys were merged, so I hacked this out (but did not heavily test it).  Obviously this is not a single expression, but it is a single function call. \n\n def merge(d1, d2, merge_fn=lambda x,y:y):\n    \"\"\"\n    Merges two dictionaries, non-destructively, combining \n    values on duplicate keys as defined by the optional merge\n    function.  The default behavior replaces the values in d1\n    with corresponding values in d2.  (There is no other generally\n    applicable merge strategy, but often you'll have homogeneous \n    types in your dicts, so specifying a merge technique can be \n    valuable.)\n\n    Examples:\n\n    >>> d1\n    {'a': 1, 'c': 3, 'b': 2}\n    >>> merge(d1, d1)\n    {'a': 1, 'c': 3, 'b': 2}\n    >>> merge(d1, d1, lambda x,y: x+y)\n    {'a': 2, 'c': 6, 'b': 4}\n\n    \"\"\"\n    result = dict(d1)\n    for k,v in d2.iteritems():\n        if k in result:\n            result[k] = merge_fn(result[k], v)\n        else:\n            result[k] = v\n    return result\n \n    ", "date_posted": "2014-09-13 19:56:21Z", "upvote": "\r\n            152\r\n        ", "accepted": "No", "user": {"stack_user_id": "2748838", "name": "Rainy", "reputation_score": "1,017"}, "answer_comments": [{"stack_answer_id": "44512", "stack_answer_comment_id": "117550353", "comment_content": "Handy solution when the default behaviour of the shorter and simpler solutions (replacement of values of common keys by the second dictionary) is not wished. For Python 3, iteritems() is not available anymore in dicts, and one can simply use items() instead.", "user_id": null}]}, {"stack_answer_id": "8310229", "answer_content": "\r\n Recursively/deep update a dict \n\n def deepupdate(original, update):\n    \"\"\"\n    Recursively update a dict.\n    Subdict's won't be overwritten but also updated.\n    \"\"\"\n    for key, value in original.iteritems(): \n        if key not in update:\n            update[key] = value\n        elif isinstance(value, dict):\n            deepupdate(value, update[key]) \n    return update \n\n Demonstration: \n\n pluto_original = {\n    'name': 'Pluto',\n    'details': {\n        'tail': True,\n        'color': 'orange'\n    }\n}\n\npluto_update = {\n    'name': 'Pluutoo',\n    'details': {\n        'color': 'blue'\n    }\n}\n\nprint deepupdate(pluto_original, pluto_update) \n\n Outputs: \n\n {\n    'name': 'Pluutoo',\n    'details': {\n        'color': 'blue',\n        'tail': True\n    }\n} \n\n Thanks rednaw for edits. \n    ", "date_posted": "2015-12-18 11:19:15Z", "upvote": "\r\n            121\r\n        ", "accepted": "No", "user": {"stack_user_id": "1392229", "name": "Dawid Gos\u0142awski", "reputation_score": "1,918"}, "answer_comments": [{"stack_answer_id": "8310229", "stack_answer_comment_id": "93325213", "comment_content": "This does not answer the question. The question clearly asks for a new dictionary, z, from original dictionaries, x and y, with values from y replacing those of x - not an updated dictionary. This answer modifies y in-place by adding values from x. Worse, it does not copy these values, so one could further modify the modified dictionary, y, and modifications could be reflected in dictionary x. @J\u00e9r\u00f4me I hope this code is not causing any bugs for your application - at least consider using deepcopy to copy the values.", "user_id": null}, {"stack_answer_id": "8310229", "stack_answer_comment_id": "93339886", "comment_content": "@AaronHall agreed this does not answer the question. But it answers my need. I understand those limitations, but that's not an issue in my case. Thinking of it, maybe the name is misleading, as it might evoke a deepcopy, which it does not provide. But it addresses deep nesting. Here's another implementation from the Martellibot: ", "user_id": null}]}, {"stack_answer_id": "28753078", "answer_content": "\r\n Python 3.5 (PEP 448) allows a nicer syntax option: \n\n x = {'a': 1, 'b': 1}\ny = {'a': 2, 'c': 2}\nfinal = {**x, **y} \nfinal\n# {'a': 2, 'b': 1, 'c': 2}\n \n\n Or even  \n\n final = {'a': 1, 'b': 1, **x, **y}\n \n\n In Python 3.9 you also use | and |= with the below example from PEP 584 \n\n d = {'spam': 1, 'eggs': 2, 'cheese': 3}\ne = {'cheese': 'cheddar', 'aardvark': 'Ethel'}\nd | e\n# {'spam': 1, 'eggs': 2, 'cheese': 'cheddar', 'aardvark': 'Ethel'}\n \n    ", "date_posted": "2020-05-03 21:16:55Z", "upvote": "\r\n            99\r\n        ", "accepted": "No", "user": {"stack_user_id": "852240", "name": "Bilal Syed Hussain", "reputation_score": "7,924"}, "answer_comments": [{"stack_answer_id": "28753078", "stack_answer_comment_id": "45972281", "comment_content": "In what way is this solution better than the ", "user_id": null}, {"stack_answer_id": "28753078", "stack_answer_comment_id": "45997426", "comment_content": "Guido dislikes ", "user_id": "/users/3207/carl-meyer"}]}, {"stack_answer_id": "3936548", "answer_content": "\r\n The best version I could think while not using copy would be: \n\n from itertools import chain\nx = {'a':1, 'b': 2}\ny = {'b':10, 'c': 11}\ndict(chain(x.iteritems(), y.iteritems()))\n \n\n It's faster than  dict(x.items() + y.items())  but not as fast as  n = copy(a); n.update(b) , at least on CPython. This version also works in Python 3 if you change  iteritems()  to  items() , which is automatically done by the 2to3 tool. \n\n Personally I like this version best because it describes fairly good what I want in a single  functional syntax. The only minor problem is that it doesn't make completely obvious that values from y takes precedence over values from x, but I don't believe it's difficult to figure that out. \n    ", "date_posted": "2010-10-14 18:55:15Z", "upvote": "\r\n            95\r\n        ", "accepted": "No", "user": {"stack_user_id": "72476", "name": "driax", "reputation_score": "2,448"}, "answer_comments": []}, {"stack_answer_id": "38989", "answer_content": "\r\n x = {'a':1, 'b': 2}\ny = {'b':10, 'c': 11}\nz = dict(x.items() + y.items())\nprint z\n \n\n For items with keys in both dictionaries ('b'), you can control which one ends up in the output by putting that one last. \n    ", "date_posted": "2008-09-02 07:49:27Z", "upvote": "\r\n            93\r\n        ", "accepted": "No", "user": {"stack_user_id": "893", "name": "Greg Hewgill", "reputation_score": "903k"}, "answer_comments": [{"stack_answer_id": "38989", "stack_answer_comment_id": "98388054", "comment_content": "In python 3 you would get TypeError: unsupported operand type(s) for +: 'dict_items' and 'dict_items' ... you should encapsulate each dict with list() like: dict(list(x.items()) + list(y.items()))", "user_id": null}, {"stack_answer_id": "38989", "stack_answer_comment_id": "124851979", "comment_content": "@justSaid ", "user_id": null}]}, {"stack_answer_id": "7770473", "answer_content": "\r\n While the question has already been answered several times,\nthis simple solution to the problem has not been listed yet. \n\n x = {'a':1, 'b': 2}\ny = {'b':10, 'c': 11}\nz4 = {}\nz4.update(x)\nz4.update(y)\n \n\n It is as fast as z0 and the evil z2 mentioned above, but easy to understand and change. \n    ", "date_posted": "2011-10-14 16:12:33Z", "upvote": "\r\n            72\r\n        ", "accepted": "No", "user": {"stack_user_id": "509648", "name": "phobie", "reputation_score": "2,464"}, "answer_comments": [{"stack_answer_id": "7770473", "stack_answer_comment_id": "9516513", "comment_content": "but it's three statements rather than one expression", "user_id": null}, {"stack_answer_id": "7770473", "stack_answer_comment_id": "9680836", "comment_content": "Yes! The mentioned one-expression-solutions are either slow or evil. Good code is readable and maintainable. So the problem is the question not the answer. We should ask for the best solution of a problem not for a one-line-solution.", "user_id": null}, {"stack_answer_id": "7770473", "stack_answer_comment_id": "21587977", "comment_content": "Lose the ", "user_id": null}, {"stack_answer_id": "7770473", "stack_answer_comment_id": "23506047", "comment_content": "Your suggestion would change this to Matthews answer. While his answer is fine, I think mine is more readable and better maintainable. The extra line would only be bad if it would cost execution time.", "user_id": null}, {"stack_answer_id": "7770473", "stack_answer_comment_id": "110323413", "comment_content": "I suggest you put this into a function", "user_id": null}]}, {"stack_answer_id": "11825563", "answer_content": "\r\n def dict_merge(a, b):\n  c = a.copy()\n  c.update(b)\n  return c\n\nnew = dict_merge(old, extras)\n \n\n Among such shady and dubious answers, this shining example is the one and only good way to merge dicts in Python, endorsed by dictator for life  Guido van Rossum  himself!  Someone else suggested half of this, but did not put it in a function. \n\n print dict_merge(\n      {'color':'red', 'model':'Mini'},\n      {'model':'Ferrari', 'owner':'Carl'})\n \n\n gives: \n\n {'color': 'red', 'owner': 'Carl', 'model': 'Ferrari'}\n \n    ", "date_posted": "2012-08-06 09:30:07Z", "upvote": "\r\n            65\r\n        ", "accepted": "No", "user": {"stack_user_id": "218294", "name": "Sam Watkins", "reputation_score": "7,441"}, "answer_comments": []}, {"stack_answer_id": "8247023", "answer_content": "\r\n If you think lambdas are evil then read no further.\nAs requested, you can write the fast and memory-efficient solution with one expression: \n\n x = {'a':1, 'b':2}\ny = {'b':10, 'c':11}\nz = (lambda a, b: (lambda a_copy: a_copy.update(b) or a_copy)(a.copy()))(x, y)\nprint z\n{'a': 1, 'c': 11, 'b': 10}\nprint x\n{'a': 1, 'b': 2}\n \n\n As suggested above, using two lines or writing a function is probably a better way to go. \n    ", "date_posted": "2011-11-23 18:20:48Z", "upvote": "\r\n            58\r\n        ", "accepted": "No", "user": {"stack_user_id": "364984", "name": "EMS", "reputation_score": "1,013"}, "answer_comments": []}, {"stack_answer_id": "34899183", "answer_content": "\r\n Be pythonic. Use a  comprehension : \n z={k: v for d in [x,y] for k, v in d.items()}\n\n>>> print z\n{'a': 1, 'c': 11, 'b': 10}\n \n    ", "date_posted": "2022-06-16 22:40:57Z", "upvote": "\r\n            58\r\n        ", "accepted": "No", "user": {"stack_user_id": "833208", "name": "Robino", "reputation_score": "4,083"}, "answer_comments": []}, {"stack_answer_id": "19279501", "answer_content": "\r\n In python3, the  items  method  no longer returns a list , but rather a  view , which acts like a set. In this case you'll need to take the set union since concatenating with  +  won't work: \n\n dict(x.items() | y.items())\n \n\n For python3-like behavior in version 2.7, the  viewitems  method should work in place of  items : \n\n dict(x.viewitems() | y.viewitems())\n \n\n I prefer this notation anyways since it seems more natural to think of it as a set union operation rather than concatenation (as the title shows). \n\n Edit: \n\n A couple more points for python 3. First, note that the  dict(x, **y)  trick won't work in python 3 unless the keys in  y  are strings. \n\n Also, Raymond Hettinger's Chainmap  answer  is pretty elegant, since it can take an arbitrary number of dicts as arguments, but  from the docs  it looks like it sequentially looks through a list of all the dicts for each lookup: \n\n \n   Lookups search the underlying mappings successively until a key is found. \n \n\n This can slow you down if you have a lot of lookups in your application: \n\n In [1]: from collections import ChainMap\nIn [2]: from string import ascii_uppercase as up, ascii_lowercase as lo; x = dict(zip(lo, up)); y = dict(zip(up, lo))\nIn [3]: chainmap_dict = ChainMap(y, x)\nIn [4]: union_dict = dict(x.items() | y.items())\nIn [5]: timeit for k in union_dict: union_dict[k]\n100000 loops, best of 3: 2.15 \u00b5s per loop\nIn [6]: timeit for k in chainmap_dict: chainmap_dict[k]\n10000 loops, best of 3: 27.1 \u00b5s per loop\n \n\n So about an order of magnitude slower for lookups. I'm a fan of Chainmap, but looks less practical where there may be many lookups. \n    ", "date_posted": "2017-05-23 12:34:53Z", "upvote": "\r\n            46\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}, {"stack_answer_id": "62820532", "answer_content": "\r\n I benchmarked the suggested with  perfplot  and found that the good old \n temp = x.copy()\ntemp.update(y)\n \n is the fastest solution together with the new (Python 3.9+) \n x | y\n \n \n \n Code to reproduce the plot: \n from collections import ChainMap\nfrom itertools import chain\nimport perfplot\n\n\ndef setup(n):\n    x = dict(zip(range(n), range(n)))\n    y = dict(zip(range(n, 2 * n), range(n, 2 * n)))\n    return x, y\n\n\ndef copy_update(data):\n    x, y = data\n    temp = x.copy()\n    temp.update(y)\n    return temp\n\n\ndef add_items(data):\n    x, y = data\n    return dict(list(x.items()) + list(y.items()))\n\n\ndef curly_star(data):\n    x, y = data\n    return {**x, **y}\n\n\ndef chain_map(data):\n    x, y = data\n    return dict(ChainMap({}, y, x))\n\n\ndef itertools_chain(data):\n    x, y = data\n    return dict(chain(x.items(), y.items()))\n\n\ndef python39_concat(data):\n    x, y = data\n    return x | y\n\n\nb = perfplot.bench(\n    setup=setup,\n    kernels=[\n        copy_update,\n        add_items,\n        curly_star,\n        chain_map,\n        itertools_chain,\n        python39_concat,\n    ],\n    labels=[\n        \"copy_update\",\n        \"dict(list(x.items()) + list(y.items()))\",\n        \"{**x, **y}\",\n        \"chain_map\",\n        \"itertools.chain\",\n        \"x | y\",\n    ],\n    n_range=[2 ** k for k in range(18)],\n    xlabel=\"len(x), len(y)\",\n    equality_check=None,\n)\nb.save(\"out.png\")\nb.show()\n \n    ", "date_posted": "2021-12-17 17:54:55Z", "upvote": "\r\n            39\r\n        ", "accepted": "No", "user": {"stack_user_id": "353337", "name": "Nico Schl\u00f6mer", "reputation_score": "48.1k"}, "answer_comments": [{"stack_answer_id": "62820532", "stack_answer_comment_id": "129098958", "comment_content": "Tried to reproduce the results, getting this error -> ", "user_id": null}]}, {"stack_answer_id": "12926103", "answer_content": "\r\n Two dictionaries \n\n def union2(dict1, dict2):\n    return dict(list(dict1.items()) + list(dict2.items()))\n \n\n n  dictionaries \n\n def union(*dicts):\n    return dict(itertools.chain.from_iterable(dct.items() for dct in dicts))\n \n\n sum  has bad performance. See  https://mathieularose.com/how-not-to-flatten-a-list-of-lists-in-python/ \n    ", "date_posted": "2016-10-02 18:16:17Z", "upvote": "\r\n            36\r\n        ", "accepted": "No", "user": {"stack_user_id": "122894", "name": "Mathieu Larose", "reputation_score": "1,210"}, "answer_comments": []}, {"stack_answer_id": "31812635", "answer_content": "\r\n Simple solution using itertools that preserves order (latter dicts have precedence) \n # py2\nfrom itertools import chain, imap\nmerge = lambda *args: dict(chain.from_iterable(imap(dict.iteritems, args)))\n\n# py3\nfrom itertools import chain\nmerge = lambda *args: dict(chain.from_iterable(map(dict.items, args)))\n \n And it's usage: \n >>> x = {'a':1, 'b': 2}\n>>> y = {'b':10, 'c': 11}\n>>> merge(x, y)\n{'a': 1, 'b': 10, 'c': 11}\n\n>>> z = {'c': 3, 'd': 4}\n>>> merge(x, y, z)\n{'a': 1, 'b': 10, 'c': 3, 'd': 4}\n \n    ", "date_posted": "2020-09-29 19:45:06Z", "upvote": "\r\n            33\r\n        ", "accepted": "No", "user": {"stack_user_id": "408556", "name": "reubano", "reputation_score": "4,774"}, "answer_comments": []}, {"stack_answer_id": "18114065", "answer_content": "\r\n Abuse leading to a one-expression solution for  Matthew's answer : \n\n >>> x = {'a':1, 'b': 2}\n>>> y = {'b':10, 'c': 11}\n>>> z = (lambda f=x.copy(): (f.update(y), f)[1])()\n>>> z\n{'a': 1, 'c': 11, 'b': 10}\n \n\n You said you wanted one expression, so I abused  lambda  to bind a name, and tuples to override lambda's one-expression limit. Feel free to cringe. \n\n You could also do this of course if you don't care about copying it: \n\n >>> x = {'a':1, 'b': 2}\n>>> y = {'b':10, 'c': 11}\n>>> z = (x.update(y), x)[1]\n>>> z\n{'a': 1, 'b': 10, 'c': 11}\n \n    ", "date_posted": "2017-05-23 12:34:53Z", "upvote": "\r\n            31\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}, {"stack_answer_id": "46356150", "answer_content": "\r\n If you don't mind mutating  x , \n x.update(y) or x\n \n Simple, readable, performant. You  know   update()  always returns  None , which is a false value. So the above expression will always evaluate to  x , after updating it. \n Most mutating methods in the standard library (like  .update() ) return  None  by convention, so this kind of pattern will work on those too. However, if you're using a dict subclass or some other method that doesn't follow this convention, then  or  may return its left operand, which may not be what you want. Instead, you can use a tuple display and index, which works regardless of what the first element evaluates to (although it's not quite as pretty): \n (x.update(y), x)[-1]\n \n If you don't have  x  in a variable yet, you can use  lambda  to make a local without using an assignment statement. This amounts to using  lambda  as a  let expression , which is a common technique in functional languages, but is maybe unpythonic. \n (lambda x: x.update(y) or x)({'a': 1, 'b': 2})\n \n Although it's not that different from the following use of the new walrus operator (Python 3.8+ only), \n (x := {'a': 1, 'b': 2}).update(y) or x\n \n especially if you use a default argument: \n (lambda x={'a': 1, 'b': 2}: x.update(y) or x)()\n \n If you do want a copy,  PEP 584  style  x | y  is the most Pythonic on 3.9+. If you must support older versions,  PEP 448  style  {**x, **y}  is easiest for 3.5+. But if that's not available in your (even older) Python version, the  let expression  pattern works here too. \n (lambda z=x.copy(): z.update(y) or z)()\n \n (That is, of course, nearly equivalent to  (z := x.copy()).update(y) or z , but if your Python version is new enough for that, then the PEP 448 style will be available.) \n    ", "date_posted": "2021-05-29 06:33:34Z", "upvote": "\r\n            24\r\n        ", "accepted": "No", "user": {"stack_user_id": "4381487", "name": "gilch", "reputation_score": "9,922"}, "answer_comments": []}, {"stack_answer_id": "62141222", "answer_content": "\r\n New  in Python 3.9:  Use the union operator ( | ) to merge  dict s similar to  set s: \n >>> d = {'a': 1, 'b': 2}\n>>> e = {'a': 9, 'c': 3}\n>>> d | e\n{'a': 9, 'b': 2, 'c': 3}\n \n For matching keys, the  right  dict  takes precedence . \n This also works for  |=  to modify a  dict  in-place: \n >>> e |= d    # e = e | d\n>>> e\n{'a': 1, 'c': 3, 'b': 2}\n \n    ", "date_posted": "2020-11-29 21:49:39Z", "upvote": "\r\n            21\r\n        ", "accepted": "No", "user": {"stack_user_id": "2111778", "name": "xjcl", "reputation_score": "10.1k"}, "answer_comments": [{"stack_answer_id": "62141222", "stack_answer_comment_id": "128455113", "comment_content": "What does this add that wasn't mentioned already months earlier? ", "user_id": null}]}, {"stack_answer_id": "17738920", "answer_content": "\r\n Drawing on ideas here and elsewhere I've comprehended a function: \n\n def merge(*dicts, **kv): \n      return { k:v for d in list(dicts) + [kv] for k,v in d.items() }\n \n\n Usage (tested in python 3): \n\n assert (merge({1:11,'a':'aaa'},{1:99, 'b':'bbb'},foo='bar')==\\\n    {1: 99, 'foo': 'bar', 'b': 'bbb', 'a': 'aaa'})\n\nassert (merge(foo='bar')=={'foo': 'bar'})\n\nassert (merge({1:11},{1:99},foo='bar',baz='quux')==\\\n    {1: 99, 'foo': 'bar', 'baz':'quux'})\n\nassert (merge({1:11},{1:99})=={1: 99})\n \n\n You could use a lambda instead. \n    ", "date_posted": "2013-07-19 05:49:19Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "375570", "name": "Bijou Trouvaille", "reputation_score": "8,016"}, "answer_comments": []}, {"stack_answer_id": "22122836", "answer_content": "\r\n It's so silly that  .update  returns nothing. \nI just use a simple helper function to solve the problem: \n\n def merge(dict1,*dicts):\n    for dict2 in dicts:\n        dict1.update(dict2)\n    return dict1\n \n\n Examples: \n\n merge(dict1,dict2)\nmerge(dict1,dict2,dict3)\nmerge(dict1,dict2,dict3,dict4)\nmerge({},dict1,dict2)  # this one returns a new copy\n \n    ", "date_posted": "2014-03-02 01:44:39Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "25700", "name": "GetFree", "reputation_score": "37.5k"}, "answer_comments": []}, {"stack_answer_id": "36263150", "answer_content": "\r\n (For Python2.7* only; there are simpler solutions for Python3*.) \n\n If you're not averse to importing a standard library module, you can do \n\n from functools import reduce\n\ndef merge_dicts(*dicts):\n    return reduce(lambda a, d: a.update(d) or a, dicts, {})\n \n\n (The  or a  bit in the  lambda  is necessary because  dict.update  always returns  None  on success.) \n    ", "date_posted": "2016-03-28 13:13:27Z", "upvote": "\r\n            18\r\n        ", "accepted": "No", "user": {"stack_user_id": "559827", "name": "kjo", "reputation_score": "31.2k"}, "answer_comments": []}, {"stack_answer_id": "20358548", "answer_content": "\r\n The problem I have with solutions listed to date is that, in the merged dictionary, the value for key \"b\" is 10 but, to my way of thinking, it should be 12.\nIn that light, I present the following: \n\n import timeit\n\nn=100000\nsu = \"\"\"\nx = {'a':1, 'b': 2}\ny = {'b':10, 'c': 11}\n\"\"\"\n\ndef timeMerge(f,su,niter):\n    print \"{:4f} sec for: {:30s}\".format(timeit.Timer(f,setup=su).timeit(n),f)\n\ntimeMerge(\"dict(x, **y)\",su,n)\ntimeMerge(\"x.update(y)\",su,n)\ntimeMerge(\"dict(x.items() + y.items())\",su,n)\ntimeMerge(\"for k in y.keys(): x[k] = k in x and x[k]+y[k] or y[k] \",su,n)\n\n#confirm for loop adds b entries together\nx = {'a':1, 'b': 2}\ny = {'b':10, 'c': 11}\nfor k in y.keys(): x[k] = k in x and x[k]+y[k] or y[k]\nprint \"confirm b elements are added:\",x\n \n\n Results: \n\n 0.049465 sec for: dict(x, **y)\n0.033729 sec for: x.update(y)                   \n0.150380 sec for: dict(x.items() + y.items())   \n0.083120 sec for: for k in y.keys(): x[k] = k in x and x[k]+y[k] or y[k]\n\nconfirm b elements are added: {'a': 1, 'c': 11, 'b': 12}\n \n    ", "date_posted": "2013-12-03 18:11:54Z", "upvote": "\r\n            17\r\n        ", "accepted": "No", "user": {"stack_user_id": "3062691", "name": "upandacross", "reputation_score": "417"}, "answer_comments": [{"stack_answer_id": "20358548", "stack_answer_comment_id": "71707374", "comment_content": "You might be interested in ", "user_id": null}]}, {"stack_answer_id": "54930992", "answer_content": "\r\n There will be a new option when Python 3.8 releases ( scheduled for 20 October, 2019 ), thanks to  PEP 572: Assignment Expressions . The new assignment expression operator  :=  allows you to assign the result of the  copy  and still use it to call  update , leaving the combined code a single expression, rather than two statements, changing: \n\n newdict = dict1.copy()\nnewdict.update(dict2)\n \n\n to: \n\n (newdict := dict1.copy()).update(dict2)\n \n\n while behaving identically in every way. If you must also return the resulting  dict  (you asked for an expression returning the  dict ; the above creates and assigns to  newdict , but doesn't return it, so you couldn't use it to pass an argument to a function as is, a la  myfunc((newdict := dict1.copy()).update(dict2)) ), then just add  or newdict  to the end (since  update  returns  None , which is falsy, it will then evaluate and return  newdict  as the result of the expression): \n\n (newdict := dict1.copy()).update(dict2) or newdict\n \n\n Important caveat:  In general, I'd discourage this approach in favor of: \n\n newdict = {**dict1, **dict2}\n \n\n The unpacking approach is clearer (to anyone who knows about generalized unpacking in the first place,  which you should ), doesn't require a name for the result at all (so it's much more concise when constructing a temporary that is immediately passed to a function or included in a  list / tuple  literal or the like), and is almost certainly faster as well, being (on CPython) roughly equivalent to: \n\n newdict = {}\nnewdict.update(dict1)\nnewdict.update(dict2)\n \n\n but done at the C layer, using the concrete  dict  API, so no dynamic method lookup/binding or function call dispatch overhead is involved (where  (newdict := dict1.copy()).update(dict2)  is unavoidably identical to the original two-liner in behavior, performing the work in discrete steps, with dynamic lookup/binding/invocation of methods. \n\n It's also more extensible, as merging three  dict s is obvious: \n\n  newdict = {**dict1, **dict2, **dict3}\n \n\n where using assignment expressions won't scale like that; the closest you could get would be: \n\n  (newdict := dict1.copy()).update(dict2), newdict.update(dict3)\n \n\n or without the temporary tuple of  None s, but with truthiness testing of each  None  result: \n\n  (newdict := dict1.copy()).update(dict2) or newdict.update(dict3)\n \n\n either of which is obviously much uglier, and includes further inefficiencies (either a wasted temporary  tuple  of  None s for comma separation, or pointless truthiness testing of each  update 's  None  return for  or  separation). \n\n The only real advantage to the assignment expression approach occurs if: \n\n \n You have generic code that needs handle both  set s and  dict s  (both of them support  copy  and  update , so the code works roughly as you'd expect it to) \n You expect to receive arbitrary dict-like objects , not just  dict  itself,  and must preserve the type and semantics of the left hand side  (rather than ending up with a plain  dict ). While  myspecialdict({**speciala, **specialb})  might work, it would involve an extra temporary  dict , and if  myspecialdict  has features plain  dict  can't preserve (e.g. regular  dict s now preserve order based on the first appearance of a key, and value based on the last appearance of a key; you might want one that preserves order based on the  last  appearance of a key so updating a value also moves it to the end), then the semantics would be wrong. Since the assignment expression version uses the named methods (which are presumably overloaded to behave appropriately), it never creates a  dict  at all (unless  dict1  was already a  dict ), preserving the original type (and original type's semantics), all while avoiding any temporaries. \n \n    ", "date_posted": "2019-02-28 17:49:22Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "364696", "name": "ShadowRanger", "reputation_score": "129k"}, "answer_comments": []}, {"stack_answer_id": "33999337", "answer_content": "\r\n from collections import Counter\ndict1 = {'a':1, 'b': 2}\ndict2 = {'b':10, 'c': 11}\nresult = dict(Counter(dict1) + Counter(dict2))\n \n\n This should solve your problem. \n    ", "date_posted": "2015-11-30 13:04:00Z", "upvote": "\r\n            15\r\n        ", "accepted": "No", "user": {"stack_user_id": "3145137", "name": "reetesh11", "reputation_score": "631"}, "answer_comments": [{"stack_answer_id": "33999337", "stack_answer_comment_id": "121401705", "comment_content": "I will recommend using the Counter's ", "user_id": null}]}, {"stack_answer_id": "31478567", "answer_content": "\r\n This can be done with a single dict comprehension: \n\n >>> x = {'a':1, 'b': 2}\n>>> y = {'b':10, 'c': 11}\n>>> { key: y[key] if key in y else x[key]\n      for key in set(x) + set(y)\n    }\n \n\n In my view the best answer for the 'single expression' part as no extra functions are needed, and it is short. \n    ", "date_posted": "2015-07-17 14:47:23Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "799163", "name": "RemcoGerlich", "reputation_score": "29.3k"}, "answer_comments": [{"stack_answer_id": "31478567", "stack_answer_comment_id": "71711009", "comment_content": "I suspect performance will not be very good though; creating a set out of each dict then only iterating through the keys means another lookup for the value each time (though relatively fast, still increases the order of the function for scaling)", "user_id": null}, {"stack_answer_id": "31478567", "stack_answer_comment_id": "82876896", "comment_content": "it all depends on the version of the python we are using. In 3.5 and above {**x,**y} gives the concatenated dictionary", "user_id": null}]}], "user": {"stack_user_id": "3207", "name": "Carl Meyer", "reputation_score": "116k"}, "question_comments": []},
{"stack_question_id": "306313", "question_title": "\"is\" operator behaves unexpectedly with integers", "question_content": "\r\n                Why does the following behave unexpectedly in Python?\n\n>>> a = 256\n>>> b = 256\n>>> a is b\nTrue           # This is an expected result\n>>> a = 257\n>>> b = ...\r\n", "question_url": "/questions/306313/is-operator-behaves-unexpectedly-with-integers", "date_posted": "Nov 20, 2008 at 18:21", "upvote": "5", "view": "9", "tags": ["python", "int", "operators", "identity", "python-internals"], "answers_count": "1", "answers": [{"stack_answer_id": "306353", "answer_content": "\r\n Take a look at this: \n\n >>> a = 256\n>>> b = 256\n>>> id(a)\n9987148\n>>> id(b)\n9987148\n>>> a = 257\n>>> b = 257\n>>> id(a)\n11662816\n>>> id(b)\n11662828\n \n\n Here's what I found in the Python 2 documentation,  \"Plain Integer Objects\"  (It's the same for  Python 3 ): \n\n \n   The current implementation keeps an\n  array of integer objects for all\n  integers between -5 and 256, when you\n  create an int in that range you\n  actually just get back a reference to\n  the existing object. So it should be\n  possible to change the value of 1. I\n  suspect the behaviour of Python in\n  this case is undefined. :-) \n \n    ", "date_posted": "2020-01-29 18:59:48Z", "upvote": "\r\n            438\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "68587", "name": "John Kugelman", "reputation_score": "335k"}, "answer_comments": [{"stack_answer_id": "306353", "stack_answer_comment_id": "78696988", "comment_content": "does anyone know how that range (-5, 256) was chosen? i wouldn't be too surprised if it were (0, 255) or even (-255, 255), but a range of 262 numbers starting at -5 seems surprisingly arbitrary.", "user_id": null}, {"stack_answer_id": "306353", "stack_answer_comment_id": "83937709", "comment_content": "@WoodrowBarlow: The -5 is just a heuristic to capture common negative placeholders, I think.  0..255 covers arrays of single byte values.  It\u2019s 256 that\u2019s mysterious, but I guess it\u2019s for (dis)assembling integers into/from bytes.", "user_id": null}, {"stack_answer_id": "306353", "stack_answer_comment_id": "89237748", "comment_content": "From what I understand the range was chosen by looking at the commonly used values across multiple projects (and multiple languages).", "user_id": null}, {"stack_answer_id": "306353", "stack_answer_comment_id": "89434930", "comment_content": "According to ", "user_id": null}, {"stack_answer_id": "306353", "stack_answer_comment_id": "122849028", "comment_content": "The note about changing the value of ", "user_id": null}]}, {"stack_answer_id": "28864111", "answer_content": "\r\n \n   Python's \u201cis\u201d operator behaves unexpectedly with integers? \n \n\n In summary - let me emphasize:  Do not use  is  to compare integers. \n\n This isn't behavior you should have any expectations about. \n\n Instead, use  ==  and  !=  to compare for equality and inequality, respectively. For example: \n\n >>> a = 1000\n>>> a == 1000       # Test integers like this,\nTrue\n>>> a != 5000       # or this!\nTrue\n>>> a is 1000       # Don't do this! - Don't use `is` to test integers!!\nFalse\n \n\n Explanation \n\n To know this, you need to know the following. \n\n First, what does  is  do? It is a comparison operator. From the  documentation : \n\n \n   The operators  is  and  is not  test for object identity:  x is y  is true\n  if and only if x and y are the same object.  x is not y  yields the\n  inverse truth value. \n \n\n And so the following are equivalent.  \n\n >>> a is b\n>>> id(a) == id(b)\n \n\n From the  documentation : \n\n \n   id \n  Return the \u201cidentity\u201d of an object. This is an integer (or long\n  integer) which is guaranteed to be unique and constant for this object\n  during its lifetime. Two objects with non-overlapping lifetimes may\n  have the same  id()  value. \n \n\n Note that the fact that the id of an object in CPython (the reference implementation of Python) is the location in memory is an implementation detail. Other implementations of Python (such as Jython or IronPython) could easily have a different implementation for  id . \n\n So what is the use-case for  is ?   PEP8 describes : \n\n \n   Comparisons to singletons like  None  should always be done with  is  or\n   is not , never the equality operators. \n \n\n The Question \n\n You ask, and state, the following question (with code): \n\n \n   Why does the following behave unexpectedly in Python? \n\n >>> a = 256\n>>> b = 256\n>>> a is b\nTrue           # This is an expected result\n \n \n\n It is  not  an expected result. Why is it expected? It only means that the integers valued at  256  referenced by both  a  and  b  are the same instance of integer. Integers are immutable in Python, thus they cannot change. This should have no impact on any code. It should not be expected. It is merely an implementation detail.  \n\n But perhaps we should be glad that there is not a new separate instance in memory every time we state a value equals 256.  \n\n \n >>> a = 257\n>>> b = 257\n>>> a is b\nFalse          # What happened here? Why is this False?\n \n \n\n Looks like we now have two separate instances of integers with the value of  257  in memory. Since integers are immutable, this wastes memory. Let's hope we're not wasting a lot of it. We're probably not. But this behavior is not guaranteed. \n\n \n >>> 257 is 257\nTrue           # Yet the literal numbers compare properly\n \n \n\n Well, this looks like your particular implementation of Python is trying to be smart and not creating redundantly valued integers in memory unless it has to. You seem to indicate you are using the referent implementation of Python, which is CPython. Good for CPython.  \n\n It might be even better if CPython could do this globally, if it could do so cheaply (as there would a cost in the lookup), perhaps another implementation might.  \n\n But as for impact on code, you should not care if an integer is a particular instance of an integer. You should only care what the value of that instance is, and you would use the normal comparison operators for that, i.e.  == . \n\n What  is  does \n\n is  checks that the  id  of two objects are the same. In CPython, the  id  is the location in memory, but it could be some other uniquely identifying number in another implementation. To restate this with code: \n\n >>> a is b\n \n\n is the same as \n\n >>> id(a) == id(b)\n \n\n Why would we want to use  is  then? \n\n This can be a very fast check relative to say, checking if two very long strings are equal in value. But since it applies to the uniqueness of the object, we thus have limited use-cases for it. In fact, we mostly want to use it to check for  None , which is a singleton (a sole instance existing in one place in memory). We might create other singletons if there is potential to conflate them, which we might check with  is , but these are relatively rare. Here's an example (will work in Python 2 and 3) e.g. \n\n SENTINEL_SINGLETON = object() # this will only be created one time.\n\ndef foo(keyword_argument=None):\n    if keyword_argument is None:\n        print('no argument given to foo')\n    bar()\n    bar(keyword_argument)\n    bar('baz')\n\ndef bar(keyword_argument=SENTINEL_SINGLETON):\n    # SENTINEL_SINGLETON tells us if we were not passed anything\n    # as None is a legitimate potential argument we could get.\n    if keyword_argument is SENTINEL_SINGLETON:\n        print('no argument given to bar')\n    else:\n        print('argument to bar: {0}'.format(keyword_argument))\n\nfoo()\n \n\n Which prints: \n\n no argument given to foo\nno argument given to bar\nargument to bar: None\nargument to bar: baz\n \n\n And so we see, with  is  and a sentinel, we are able to differentiate between when  bar  is called with no arguments and when it is called with  None . These are the primary use-cases for  is  - do  not  use it to test for equality of integers, strings, tuples, or other things like these. \n    ", "date_posted": "2017-09-09 20:02:03Z", "upvote": "\r\n            147\r\n        ", "accepted": "No", "user": {"stack_user_id": "541136", "name": "Russia Must Remove Putin", "reputation_score": "347k"}, "answer_comments": [{"stack_answer_id": "28864111", "stack_answer_comment_id": "98590248", "comment_content": "\"These are the primary use-cases for ", "user_id": null}, {"stack_answer_id": "28864111", "stack_answer_comment_id": "98590866", "comment_content": "@Alexey sounds like you need enums? ", "user_id": null}, {"stack_answer_id": "28864111", "stack_answer_comment_id": "98591512", "comment_content": "Maybe, thanks, didn't know of them. This could be an appropriate addition to you answer IMO.", "user_id": null}, {"stack_answer_id": "28864111", "stack_answer_comment_id": "98591718", "comment_content": "Maybe using a number of dumb objects like the sentinel in your answer would be a more lightweight solution...", "user_id": null}, {"stack_answer_id": "28864111", "stack_answer_comment_id": "125042249", "comment_content": "@MarkRansom Don't use ", "user_id": null}]}, {"stack_answer_id": "34964030", "answer_content": "\r\n\n I'm late but, you want some source with your answer?  I'll try and word this in an introductory manner so more folks can follow along. \n \n A good thing about CPython is that you can actually see the source for this. I'm going to use links for the  3.5  release, but finding the corresponding  2.x  ones is trivial. \n In CPython, the  C-API  function that handles creating a new  int  object is  PyLong_FromLong(long v) . The description for this function is: \n \n The current implementation keeps an array of integer objects for all integers between -5 and 256, when you create an int in that range you actually just get back a reference to the existing object . So it should be possible to change the value of 1. I suspect the behaviour of Python in this case is undefined. :-) \n \n (My italics) \n Don't know about you but I see this and think:  Let's find that array! \n If you haven't fiddled with the C code implementing CPython  you should ; everything is pretty organized and readable. For our case, we need to look in the  Objects  subdirectory  of the  main source code directory tree . \n PyLong_FromLong  deals with  long  objects so it shouldn't be hard to deduce that we need to peek inside  longobject.c . After looking inside you might think things are chaotic; they are, but fear not, the function we're looking for is chilling at  line 230  waiting for us to check it out. It's a smallish function so the main body (excluding declarations) is easily pasted here: \n PyObject *\nPyLong_FromLong(long ival)\n{\n    // omitting declarations\n\n    CHECK_SMALL_INT(ival);\n\n    if (ival < 0) {\n        /* negate: cant write this as abs_ival = -ival since that\n           invokes undefined behaviour when ival is LONG_MIN */\n        abs_ival = 0U-(unsigned long)ival;\n        sign = -1;\n    }\n    else {\n        abs_ival = (unsigned long)ival;\n    }\n\n    /* Fast path for single-digit ints */\n    if (!(abs_ival >> PyLong_SHIFT)) {\n        v = _PyLong_New(1);\n        if (v) {\n            Py_SIZE(v) = sign;\n            v->ob_digit[0] = Py_SAFE_DOWNCAST(\n                abs_ival, unsigned long, digit);\n        }\n        return (PyObject*)v; \n}\n \n Now, we're no C  master-code-haxxorz  but we're also not dumb, we can see that  CHECK_SMALL_INT(ival);  peeking at us all seductively; we can understand it has something to do with this.  Let's check it out: \n #define CHECK_SMALL_INT(ival) \\\n    do if (-NSMALLNEGINTS <= ival && ival < NSMALLPOSINTS) { \\\n        return get_small_int((sdigit)ival); \\\n    } while(0)\n \n So it's a macro that calls function  get_small_int  if the value  ival  satisfies the condition: \n if (-NSMALLNEGINTS <= ival && ival < NSMALLPOSINTS)\n \n So what are  NSMALLNEGINTS  and  NSMALLPOSINTS ? Macros!  Here they are : \n #ifndef NSMALLPOSINTS\n#define NSMALLPOSINTS           257\n#endif\n#ifndef NSMALLNEGINTS\n#define NSMALLNEGINTS           5\n#endif\n \n So our condition is  if (-5 <= ival && ival < 257)  call  get_small_int . \n Next let's look at  get_small_int  in all its glory  (well, we'll just look at its body because that's where the interesting things are): \n PyObject *v;\nassert(-NSMALLNEGINTS <= ival && ival < NSMALLPOSINTS);\nv = (PyObject *)&small_ints[ival + NSMALLNEGINTS];\nPy_INCREF(v);\n \n Okay, declare a  PyObject , assert that the previous condition holds and execute the assignment: \n v = (PyObject *)&small_ints[ival + NSMALLNEGINTS];\n \n small_ints  looks a lot like that array we've been searching for, and it is!  We could've just read the damn documentation and we would've know all along! : \n /* Small integers are preallocated in this array so that they\n   can be shared.\n   The integers that are preallocated are those in the range\n   -NSMALLNEGINTS (inclusive) to NSMALLPOSINTS (not inclusive).\n*/\nstatic PyLongObject small_ints[NSMALLNEGINTS + NSMALLPOSINTS];\n \n So yup, this is our guy. When you want to create a new  int  in the range  [NSMALLNEGINTS, NSMALLPOSINTS)  you'll just get back a reference to an already existing object that has been preallocated. \n Since the reference refers to the same object, issuing  id()  directly or checking for identity with  is  on it will return exactly the same thing. \n But, when are they allocated?? \n During initialization in  _PyLong_Init  Python will gladly enter in a for loop to do this for you: \n for (ival = -NSMALLNEGINTS; ival <  NSMALLPOSINTS; ival++, v++) {\n \n Check out the source to read the loop body! \n I hope my explanation has made you  C  things clearly now (pun obviously intented). \n \n But,  257 is 257 ? What's up? \n This is actually easier to explain,  and I have attempted to do so already ; it's due to the fact that Python will execute this interactive statement as a single block: \n >>> 257 is 257\n \n During complilation of this statement, CPython will see that you have two matching literals and will use the same  PyLongObject  representing  257 . You can see this if you do the compilation yourself and examine its contents: \n >>> codeObj = compile(\"257 is 257\", \"blah!\", \"exec\")\n>>> codeObj.co_consts\n(257, None)\n \n When CPython does the operation, it's now just going to load the exact same object: \n >>> import dis\n>>> dis.dis(codeObj)\n  1           0 LOAD_CONST               0 (257)   # dis\n              3 LOAD_CONST               0 (257)   # dis again\n              6 COMPARE_OP               8 (is)\n \n So  is  will return  True . \n    ", "date_posted": "2021-03-18 16:08:30Z", "upvote": "\r\n            71\r\n        ", "accepted": "No", "user": {"stack_user_id": "2326961", "name": "Maggyero", "reputation_score": "4,880"}, "answer_comments": []}, {"stack_answer_id": "306377", "answer_content": "\r\n It depends on whether you're looking to see if 2 things are equal, or the same object.  \n\n is  checks to see if they are the same object, not just equal. The small ints are probably pointing to the same memory location for space efficiency  \n\n In [29]: a = 3\nIn [30]: b = 3\nIn [31]: id(a)\nOut[31]: 500729144\nIn [32]: id(b)\nOut[32]: 500729144\n \n\n You should use  ==  to compare equality of arbitrary objects. You can specify the behavior with the  __eq__ , and  __ne__  attributes. \n    ", "date_posted": "2017-04-24 02:20:18Z", "upvote": "\r\n            61\r\n        ", "accepted": "No", "user": {"stack_user_id": "2470818", "name": "vallentin", "reputation_score": "21.7k"}, "answer_comments": []}, {"stack_answer_id": "306603", "answer_content": "\r\n As you can check in  source file  intobject.c , Python caches small integers for efficiency. Every time you create a reference to a small integer, you are referring the cached small integer, not a new object. 257 is not an small integer, so it is calculated as a different object. \n\n It is better to use  ==  for that purpose. \n    ", "date_posted": "2017-04-24 02:20:25Z", "upvote": "\r\n            38\r\n        ", "accepted": "No", "user": {"stack_user_id": "2470818", "name": "vallentin", "reputation_score": "21.7k"}, "answer_comments": []}, {"stack_answer_id": "306347", "answer_content": "\r\n I think your hypotheses is correct. Experiment with  id  (identity of object): \n\n In [1]: id(255)\nOut[1]: 146349024\n\nIn [2]: id(255)\nOut[2]: 146349024\n\nIn [3]: id(257)\nOut[3]: 146802752\n\nIn [4]: id(257)\nOut[4]: 148993740\n\nIn [5]: a=255\n\nIn [6]: b=255\n\nIn [7]: c=257\n\nIn [8]: d=257\n\nIn [9]: id(a), id(b), id(c), id(d)\nOut[9]: (146349024, 146349024, 146783024, 146804020)\n \n\n It appears that numbers  <= 255  are treated as literals and anything above is treated differently! \n    ", "date_posted": "2017-02-08 10:12:22Z", "upvote": "\r\n            21\r\n        ", "accepted": "No", "user": {"stack_user_id": "4952130", "name": "Dimitris Fasarakis Hilliard", "reputation_score": "139k"}, "answer_comments": [{"stack_answer_id": "306347", "stack_answer_comment_id": "89237899", "comment_content": "It is because objects representing values from -5 to +256 are created at Startup time - and so all use of those value use to prebuilt object. Almost all references to integers outside that range create a new internal object each time they are referenced. I think the use of the term literal is confusing - literal normally refers to any value that is typed in a piece of code - so all number in the source code are literals.", "user_id": null}]}, {"stack_answer_id": "49472348", "answer_content": "\r\n There's another issue that isn't pointed out in any of the existing answers. Python is allowed to merge any two immutable values, and pre-created small int values are not the only way this can happen. A Python implementation is never  guaranteed  to do this, but they all do it for more than just small ints. \n\n \n\n For one thing, there are some other pre-created values, such as the empty  tuple ,  str , and  bytes , and some short strings (in CPython 3.6, it's the 256 single-character Latin-1 strings). For example: \n\n >>> a = ()\n>>> b = ()\n>>> a is b\nTrue\n \n\n \n\n But also, even non-pre-created values can be identical. Consider these examples: \n\n >>> c = 257\n>>> d = 257\n>>> c is d\nFalse\n>>> e, f = 258, 258\n>>> e is f\nTrue\n \n\n And this isn't limited to  int  values: \n\n >>> g, h = 42.23e100, 42.23e100\n>>> g is h\nTrue\n \n\n Obviously, CPython doesn't come with a pre-created  float  value for  42.23e100 . So, what's going on here? \n\n The CPython compiler will merge constant values of some known-immutable types like  int ,  float ,  str ,  bytes ,  in the same compilation unit. For a module, the whole module is a compilation unit, but at the interactive interpreter, each statement is a separate compilation unit. Since  c  and  d  are defined in separate statements, their values aren't merged. Since  e  and  f  are defined in the same statement, their values are merged. \n\n \n\n You can see what's going on by disassembling the bytecode. Try defining a function that does  e, f = 128, 128  and then calling  dis.dis  on it, and you'll see that there's a single constant value  (128, 128) \n\n >>> def f(): i, j = 258, 258\n>>> dis.dis(f)\n  1           0 LOAD_CONST               2 ((128, 128))\n              2 UNPACK_SEQUENCE          2\n              4 STORE_FAST               0 (i)\n              6 STORE_FAST               1 (j)\n              8 LOAD_CONST               0 (None)\n             10 RETURN_VALUE\n>>> f.__code__.co_consts\n(None, 128, (128, 128))\n>>> id(f.__code__.co_consts[1], f.__code__.co_consts[2][0], f.__code__.co_consts[2][1])\n4305296480, 4305296480, 4305296480\n \n\n \n\n You may notice that the compiler has stored  128  as a constant even though it's not actually used by the bytecode, which gives you an idea of how little optimization CPython's compiler does. Which means that (non-empty) tuples actually don't end up merged: \n\n >>> k, l = (1, 2), (1, 2)\n>>> k is l\nFalse\n \n\n Put that in a function,  dis  it, and look at the  co_consts \u2014there's a  1  and a  2 , two  (1, 2)  tuples that share the same  1  and  2  but are not identical, and a  ((1, 2), (1, 2))  tuple that has the two distinct equal tuples. \n\n \n\n There's one more optimization that CPython does: string interning. Unlike compiler constant folding, this isn't restricted to source code literals: \n\n >>> m = 'abc'\n>>> n = 'abc'\n>>> m is n\nTrue\n \n\n On the other hand, it is limited to the  str  type, and to strings of  internal storage kind \"ascii compact\", \"compact\", or \"legacy ready\" , and in many cases only \"ascii compact\" will get interned. \n\n \n\n At any rate, the rules for what values must be, might be, or cannot be distinct vary from implementation to implementation, and between versions of the same implementation, and maybe even between runs of the same code on the same copy of the same implementation. \n\n It can be worth learning the rules for one specific Python for the fun of it. But it's not worth relying on them in your code. The only safe rule is: \n\n \n Do not write code that assumes two equal but separately-created immutable values are identical (don't use  x is y , use  x == y ) \n Do not write code that assumes two equal but separately-created immutable values are distinct (don't use  x is not y , use  x != y ) \n \n\n Or, in other words, only use  is  to test for the documented singletons (like  None ) or that are only created in one place in the code (like the  _sentinel = object()  idiom). \n    ", "date_posted": "2020-03-09 06:40:04Z", "upvote": "\r\n            15\r\n        ", "accepted": "No", "user": {"stack_user_id": "202229", "name": "smci", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "49472348", "stack_answer_comment_id": "107203132", "comment_content": "The less cryptic advice is simply: don't use ", "user_id": null}, {"stack_answer_id": "49472348", "stack_answer_comment_id": "110073088", "comment_content": "So looking at ", "user_id": null}]}, {"stack_answer_id": "307594", "answer_content": "\r\n For immutable value objects, like ints, strings or datetimes, object identity is not especially useful. It's better to think about equality. Identity is essentially an implementation detail for value objects - since they're immutable, there's no effective difference between having multiple refs to the same object or multiple objects. \n    ", "date_posted": "2008-11-21 01:58:53Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "38851", "name": "babbageclunk", "reputation_score": "8,275"}, "answer_comments": []}, {"stack_answer_id": "15522094", "answer_content": "\r\n is   is  the identity equality operator (functioning like  id(a) == id(b) ); it's just that two equal numbers aren't necessarily the same object. For performance reasons some small integers happen to be  memoized  so they will tend to be the same (this can be done since they are immutable). \n\n PHP's   ===  operator, on the other hand, is described as checking equality and type:  x == y and type(x) == type(y)  as per Paulo Freitas' comment. This will suffice for common numbers, but differ from  is  for classes that define  __eq__  in an absurd manner: \n\n class Unequal:\n    def __eq__(self, other):\n        return False\n \n\n PHP apparently allows the same thing for \"built-in\" classes (which I take to mean implemented at C level, not in PHP). A slightly less absurd use might be a timer object, which has a different value every time it's used as a number. Quite why you'd want to emulate Visual Basic's  Now  instead of showing that it is an evaluation with  time.time()  I don't know. \n\n Greg Hewgill (OP) made one clarifying comment \"My goal is to compare object identity, rather than equality of value. Except for numbers, where I want to treat object identity the same as equality of value.\" \n\n This would have yet another answer, as we have to categorize things as numbers or not, to select whether we compare with  ==  or  is .  CPython  defines the  number protocol , including PyNumber_Check, but this is not accessible from Python itself. \n\n We could try to use  isinstance  with all the number types we know of, but this would inevitably be incomplete. The types module contains a StringTypes list but no NumberTypes. Since Python 2.6, the built in number classes have a base class  numbers.Number , but it has the same problem: \n\n import numpy, numbers\nassert not issubclass(numpy.int16,numbers.Number)\nassert issubclass(int,numbers.Number)\n \n\n By the way,  NumPy  will produce separate instances of low numbers. \n\n I don't actually know an answer to this variant of the question. I suppose one could theoretically use ctypes to call  PyNumber_Check , but even that function  has been debated , and it's certainly not portable. We'll just have to be less particular about what we test for now. \n\n In the end, this issue stems from Python not originally having a type tree with predicates like  Scheme's   number? , or  Haskell's   type class   Num .  is  checks object identity, not value equality. PHP has a colorful history as well, where  ===  apparently behaves as  is  only on objects  in PHP5, but not PHP4 . Such are the growing pains of moving across languages (including versions of one). \n    ", "date_posted": "2015-11-12 11:52:54Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "379311", "name": "Yann Vernier", "reputation_score": "14.9k"}, "answer_comments": []}, {"stack_answer_id": "33130014", "answer_content": "\r\n It also happens with strings: \n\n >>> s = b = 'somestr'\n>>> s == b, s is b, id(s), id(b)\n(True, True, 4555519392, 4555519392)\n \n\n Now everything seems fine. \n\n >>> s = 'somestr'\n>>> b = 'somestr'\n>>> s == b, s is b, id(s), id(b)\n(True, True, 4555519392, 4555519392)\n \n\n That's expected too. \n\n >>> s1 = b1 = 'somestrdaasd ad ad asd as dasddsg,dlfg ,;dflg, dfg a'\n>>> s1 == b1, s1 is b1, id(s1), id(b1)\n(True, True, 4555308080, 4555308080)\n\n>>> s1 = 'somestrdaasd ad ad asd as dasddsg,dlfg ,;dflg, dfg a'\n>>> b1 = 'somestrdaasd ad ad asd as dasddsg,dlfg ,;dflg, dfg a'\n>>> s1 == b1, s1 is b1, id(s1), id(b1)\n(True, False, 4555308176, 4555308272)\n \n\n Now that's unexpected. \n    ", "date_posted": "2015-10-14 15:53:05Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "4842742", "name": "sobolevn", "reputation_score": "15.2k"}, "answer_comments": [{"stack_answer_id": "33130014", "stack_answer_comment_id": "56385375", "comment_content": "Happened upon this - agreed, that even weirder.  So I played with it, and it's weirder yet - related to the space.  For example, the string ", "user_id": null}, {"stack_answer_id": "33130014", "stack_answer_comment_id": "66570944", "comment_content": "That's because it looks like a symbol if there's no space in it. Names are automatically interned, so if there's anything named ", "user_id": null}]}, {"stack_answer_id": "57641343", "answer_content": "\r\n What\u2019s New In Python 3.8: Changes in Python behavior : \n\n \n   The compiler now produces a  SyntaxWarning  when identity checks ( is  and\n   is not ) are used with certain types of literals (e.g. strings, ints).\n  These can often work by accident in CPython, but are not guaranteed by\n  the language spec. The warning advises users to use equality tests ( == \n  and  != ) instead. \n \n    ", "date_posted": "2019-11-11 21:21:47Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "2420341", "name": "cclauss", "reputation_score": "505"}, "answer_comments": []}], "user": {"stack_user_id": "893", "name": "Greg Hewgill", "reputation_score": "903k"}, "question_comments": [{"stack_question_id": "306313", "stack_question_comment_id": "99214572", "comment_content": "Take a look ", "user_id": null}, {"stack_question_id": "306313", "stack_question_comment_id": "99499964", "comment_content": "This is a CPython-specific implementation detail and a undefined behavior, use with cautions", "user_id": null}, {"stack_question_id": "306313", "stack_question_comment_id": "122294396", "comment_content": "Does this answer your question? ", "user_id": null}]},
{"stack_question_id": "394809", "question_title": "Does Python have a ternary conditional operator?", "question_content": "\r\n                Is there a ternary conditional operator in Python?\r\n", "question_url": "/questions/394809/does-python-have-a-ternary-conditional-operator", "date_posted": null, "upvote": "7", "view": "2", "tags": ["python", "operators", "conditional-operator"], "answers_count": "3", "answers": [{"stack_answer_id": "394814", "answer_content": "\r\n Yes, it was  added  in version 2.5. The expression syntax is: \n a if condition else b\n \n First  condition  is evaluated, then exactly one of either  a  or  b  is evaluated and returned based on the  Boolean  value of  condition . If  condition  evaluates to  True , then  a  is evaluated and returned but  b  is ignored, or else when  b  is evaluated and returned but  a  is ignored. \n This allows short-circuiting because when  condition  is true only  a  is evaluated and  b  is not evaluated at all, but when  condition  is false only  b  is evaluated and  a  is not evaluated at all. \n For example: \n >>> 'true' if True else 'false'\n'true'\n>>> 'true' if False else 'false'\n'false'\n \n Note that conditionals are an  expression , not a  statement . This means you can't use assignment statements or  pass  or other  statements  within a conditional  expression : \n >>> pass if False else x = 3\n  File \"<stdin>\", line 1\n    pass if False else x = 3\n          ^\nSyntaxError: invalid syntax\n \n You can, however, use conditional expressions to assign a variable like so: \n x = a if True else b\n \n Think of the conditional expression as switching between two values. It is very useful when you're in a 'one value or another' situation, but it doesn't do much else. \n If you need to use statements, you have to use a normal  if   statement  instead of a conditional  expression . \n \n Keep in mind that it's frowned upon by some Pythonistas for several reasons: \n \n The order of the arguments is different from those of the classic  condition ? a : b  ternary operator from many other languages (such as  C ,  C++ ,  Go ,  Perl ,  Ruby ,  Java ,  JavaScript , etc.), which may lead to bugs when people unfamiliar with Python's \"surprising\" behaviour use it (they may reverse the argument order). \n Some find it \"unwieldy\", since it goes contrary to the normal flow of thought (thinking of the condition first and then the effects). \n Stylistic reasons. (Although the 'inline  if ' can be  really  useful, and make your script more concise, it really does complicate your code) \n \n If you're having trouble remembering the order, then remember that when read aloud, you (almost) say what you mean. For example,  x = 4 if b > 8 else 9  is read aloud as  x will be 4 if b is greater than 8 otherwise 9 . \n Official documentation: \n \n Conditional expressions \n Is there an equivalent of C\u2019s \u201d?:\u201d ternary operator? \n \n    ", "date_posted": "2022-06-03 22:21:26Z", "upvote": "\r\n            8586\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "394814", "name": "\r\n        22 revs, 18 users 18%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "394814", "stack_answer_comment_id": "57719599", "comment_content": "The order may seems strange for coders however ", "user_id": null}, {"stack_answer_id": "394814", "stack_answer_comment_id": "59317179", "comment_content": "Be careful with order of operations when using this. For example, the line ", "user_id": null}, {"stack_answer_id": "394814", "stack_answer_comment_id": "60867668", "comment_content": "The point was if you want to perform additional evaluations ", "user_id": null}, {"stack_answer_id": "394814", "stack_answer_comment_id": "78209851", "comment_content": "@MrGeek, I see what you mean, so you would basically be nesting the operations: ` \"foo\" if Bool else (\"bar\" if Bool else \"foobar\") `", "user_id": null}, {"stack_answer_id": "394814", "stack_answer_comment_id": "88793385", "comment_content": "Programmers need precise correct formulation even more than mathematician, because in mathematics there is always a resort to underlying concepts. A convincing argument  is the % operator, mimicking the way \"mod\" is used in math would have been a disaster.  So no, I don't accept your argument. It is like adhering to imperial units. Groetjes Albert", "user_id": null}]}, {"stack_answer_id": "470376", "answer_content": "\r\n You can index into a tuple: \n\n (falseValue, trueValue)[test]\n \n\n test  needs to return  True  or  False . \nIt might be safer to always implement it as: \n\n (falseValue, trueValue)[test == True]\n \n\n or you can use the built-in  bool()  to assure a  Boolean  value: \n\n (falseValue, trueValue)[bool(<expression>)]\n \n    ", "date_posted": "2015-10-17 07:35:10Z", "upvote": "\r\n            955\r\n        ", "accepted": "No", "user": {"stack_user_id": "470376", "name": "\r\n        Landon Kuhn\r\n        ", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "470376", "stack_answer_comment_id": "5445970", "comment_content": "Note that this one always evaluates everything, whereas the if/else construct only evaluates the winning expression.", "user_id": null}, {"stack_answer_id": "470376", "stack_answer_comment_id": "12212868", "comment_content": " ", "user_id": null}, {"stack_answer_id": "470376", "stack_answer_comment_id": "14113335", "comment_content": "It should be noted that what's within the ", "user_id": null}, {"stack_answer_id": "470376", "stack_answer_comment_id": "59136440", "comment_content": "I've done a similar trick -- only once or twice, but done it -- by indexing into a dictionary with ", "user_id": null}, {"stack_answer_id": "470376", "stack_answer_comment_id": "61540187", "comment_content": " ", "user_id": null}]}, {"stack_answer_id": "394887", "answer_content": "\r\n For versions prior to 2.5, there's the trick: \n [expression] and [on_true] or [on_false]\n \n It can give wrong results when  on_true  has a false Boolean value. 1 \n Although it does have the benefit of evaluating expressions left to right, which is clearer in my opinion. \n 1.  Is there an equivalent of C\u2019s \u201d?:\u201d ternary operator? \n    ", "date_posted": "2022-02-06 12:19:50Z", "upvote": "\r\n            420\r\n        ", "accepted": "No", "user": {"stack_user_id": "394887", "name": "\r\n        4 revs, 4 users 35%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "394887", "stack_answer_comment_id": "1466794", "comment_content": "The remedy is to use (test and [true_value] or [false_value])[0], which avoids this trap.", "user_id": null}, {"stack_answer_id": "394887", "stack_answer_comment_id": "31716349", "comment_content": "Ternary operator usually executes faster(sometimes by 10-25%).", "user_id": null}, {"stack_answer_id": "394887", "stack_answer_comment_id": "39130413", "comment_content": "@volcano Do you have source for me?", "user_id": null}, {"stack_answer_id": "394887", "stack_answer_comment_id": "85745604", "comment_content": "@OrangeTux ", "user_id": null}]}, {"stack_answer_id": "2919360", "answer_content": "\r\n   <expression 1>   if   <condition>   else   <expression 2>   \n\n a = 1\nb = 2\n\n1 if a > b else -1 \n# Output is -1\n\n1 if a > b else -1 if a < b else 0\n# Output is -1\n \n    ", "date_posted": "2019-05-15 15:03:41Z", "upvote": "\r\n            334\r\n        ", "accepted": "No", "user": {"stack_user_id": "2919360", "name": "\r\n        3 revs, 2 users 62%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "2919360", "stack_answer_comment_id": "4103349", "comment_content": "This one emphasizes the primary intent of the ternary operator: value selection. It also shows that more than one ternary can be chained together into a single expression.", "user_id": null}, {"stack_answer_id": "2919360", "stack_answer_comment_id": "42951997", "comment_content": "@Craig , I agree, but it's also helpful to know what will happen when there are no parentheses. In real code, I too would tend to insert explicit parens.", "user_id": null}, {"stack_answer_id": "2919360", "stack_answer_comment_id": "114095475", "comment_content": "Use: ", "user_id": null}]}, {"stack_answer_id": "394815", "answer_content": "\r\n From  the documentation : \n\n \n   Conditional expressions (sometimes called a \u201cternary operator\u201d) have the lowest priority of all Python operations. \n  \n   The expression  x if C else y  first evaluates the condition,  C  ( not x ); if  C  is true,  x  is evaluated and its value is returned; otherwise,  y  is evaluated and its value is returned. \n  \n   See  PEP 308  for more details about conditional expressions. \n \n\n New since version 2.5. \n    ", "date_posted": "2015-10-17 07:43:53Z", "upvote": "\r\n            195\r\n        ", "accepted": "No", "user": {"stack_user_id": "394815", "name": "\r\n        Michael Burr\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "30052371", "answer_content": "\r\n An operator for a conditional expression in Python was added in 2006 as part of  Python Enhancement Proposal 308 . Its form differ from common  ?:  operator and it's: \n\n <expression1> if <condition> else <expression2>\n \n\n which is equivalent to: \n\n if <condition>: <expression1> else: <expression2>\n \n\n Here is an example: \n\n result = x if a > b else y\n \n\n Another syntax which can be used (compatible with versions before 2.5): \n\n result = (lambda:y, lambda:x)[a > b]()\n \n\n where operands are  lazily evaluated . \n\n Another way is by indexing a tuple (which isn't consistent with the conditional operator of most other languages): \n\n result = (y, x)[a > b]\n \n\n or explicitly constructed dictionary: \n\n result = {True: x, False: y}[a > b]\n \n\n Another (less reliable), but simpler method is to use  and  and  or  operators: \n\n result = (a > b) and x or y\n \n\n however this won't work if  x  would be  False . \n\n A possible workaround is to make  x  and  y  lists or tuples as in the following: \n\n result = ((a > b) and [x] or [y])[0]\n \n\n or: \n\n result = ((a > b) and (x,) or (y,))[0]\n \n\n If you're working with dictionaries, instead of using a ternary conditional, you can take advantage of  get(key, default) , for example: \n\n shell = os.environ.get('SHELL', \"/bin/sh\")\n \n\n Source:  ?: in Python at Wikipedia \n    ", "date_posted": "2017-08-07 14:22:32Z", "upvote": "\r\n            159\r\n        ", "accepted": "No", "user": {"stack_user_id": "30052371", "name": "\r\n        2 revs, 2 users 98%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "30052371", "stack_answer_comment_id": "96013109", "comment_content": " is another possible variant (", "user_id": null}]}, {"stack_answer_id": "1855173", "answer_content": "\r\n Unfortunately, the \n (falseValue, trueValue)[test]\n \n solution doesn't have short-circuit behaviour; thus both  falseValue  and  trueValue  are evaluated regardless of the condition. This could be suboptimal or even buggy (i.e. both  trueValue  and  falseValue  could be methods and have side effects). \n One solution to this would be \n (lambda: falseValue, lambda: trueValue)[test]()\n \n (execution delayed until the winner is known ;)), but it introduces inconsistency between callable and non-callable objects. In addition, it doesn't solve the case when using properties. \n And so the story goes - choosing between three mentioned solutions is a trade-off between having the short-circuit feature, using at least Python 2.5 (IMHO, not a problem anymore) and not being prone to \" trueValue -evaluates-to-false\" errors. \n    ", "date_posted": "2022-02-06 12:22:50Z", "upvote": "\r\n            118\r\n        ", "accepted": "No", "user": {"stack_user_id": "1855173", "name": "\r\n        6 revs, 5 users 67%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "1855173", "stack_answer_comment_id": "92454573", "comment_content": "While the tuple of lambdas trick works, it takes roughly 3x as long as the ternary operator.  It's only likely to be a reasonable idea if it can replace a long chain of ", "user_id": null}]}, {"stack_answer_id": "39067220", "answer_content": "\r\n Ternary operator in different programming languages \n Here I just try to show some important differences in the  ternary operator  between a couple of programming languages. \n Ternary operator in  JavaScript \n var a = true ? 1 : 0;\n# 1\nvar b = false ? 1 : 0;\n# 0\n \n Ternary operator in  Ruby \n a = true ? 1 : 0\n# 1\nb = false ? 1 : 0\n# 0\n \n Ternary operator in  Scala \n val a = true ? 1 | 0\n# 1\nval b = false ? 1 | 0\n# 0\n \n Ternary operator in  R  programming \n a <- if (TRUE) 1 else 0\n# 1\nb <- if (FALSE) 1 else 0\n# 0\n \n Ternary operator in Python \n a = 1 if True else 0\n# 1\nb = 1 if False else 0\n# 0\n \n    ", "date_posted": "2022-02-06 12:47:23Z", "upvote": "\r\n            94\r\n        ", "accepted": "No", "user": {"stack_user_id": "39067220", "name": "\r\n        5 revs, 4 users 78%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "39067220", "stack_answer_comment_id": "71681244", "comment_content": "This ", "user_id": null}, {"stack_answer_id": "39067220", "stack_answer_comment_id": "83365814", "comment_content": "It may sound opinionated; but what it essentially says is that it the Python syntax is likely to be understood by a person who never saw a ternary operator, while very few people will understand the more usual syntax unless they have been told first what it means.", "user_id": null}, {"stack_answer_id": "39067220", "stack_answer_comment_id": "88793454", "comment_content": "Algol68:  a=.if. .true. .then. 1 .else. 0 .fi. This may be expressed also a=(.true.|1|0)  As usual Algol68 is an improvement over its successors.", "user_id": null}, {"stack_answer_id": "39067220", "stack_answer_comment_id": "114386996", "comment_content": "something simple as ", "user_id": null}, {"stack_answer_id": "39067220", "stack_answer_comment_id": "114654346", "comment_content": "@VarunGarg But of course you can say ", "user_id": null}]}, {"stack_answer_id": "10314837", "answer_content": "\r\n For Python 2.5 and newer there is a specific syntax: \n\n [on_true] if [cond] else [on_false]\n \n\n In older Pythons a ternary operator is not implemented but it's possible to simulate it. \n\n cond and on_true or on_false\n \n\n Though, there is a potential problem, which if  cond  evaluates to  True  and  on_true  evaluates to  False  then  on_false  is returned instead of  on_true . If you want this behavior the method is OK, otherwise use this: \n\n {True: on_true, False: on_false}[cond is True] # is True, not == True\n \n\n which can be wrapped by: \n\n def q(cond, on_true, on_false)\n    return {True: on_true, False: on_false}[cond is True]\n \n\n and used this way: \n\n q(cond, on_true, on_false)\n \n\n It is compatible with all Python versions. \n    ", "date_posted": "2012-04-25 12:02:06Z", "upvote": "\r\n            79\r\n        ", "accepted": "No", "user": {"stack_user_id": "10314837", "name": "\r\n        Paolo\r\n        ", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "10314837", "stack_answer_comment_id": "16979616", "comment_content": "The behaviour is not identical - ", "user_id": null}, {"stack_answer_id": "10314837", "stack_answer_comment_id": "29624617", "comment_content": "Why not ", "user_id": null}]}, {"stack_answer_id": "14321907", "answer_content": "\r\n You might often find \n cond and on_true or on_false\n \n but this leads to a problem when on_true == 0 \n >>> x = 0\n>>> print x == 0 and 0 or 1\n1\n>>> x = 1\n>>> print x == 0 and 0 or 1\n1\n \n Where you would expect this result for a normal ternary operator: \n >>> x = 0\n>>> print 0 if x == 0 else 1\n0\n>>> x = 1\n>>> print 0 if x == 0 else 1\n1\n \n    ", "date_posted": "2022-04-01 17:25:19Z", "upvote": "\r\n            56\r\n        ", "accepted": "No", "user": {"stack_user_id": "14321907", "name": "\r\n        3 revs, 3 users 64%", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "33765206", "answer_content": "\r\n \n Does Python have a ternary conditional operator? \n \n Yes. From the  grammar file : \n test: or_test ['if' or_test 'else' test] | lambdef\n \n The part of interest is: \n or_test ['if' or_test 'else' test]\n \n So, a ternary conditional operation is of the form: \n expression1 if expression2 else expression3\n \n expression3  will be lazily evaluated (that is, evaluated only if  expression2  is false in a boolean context). And because of the recursive definition, you can chain them indefinitely (though it may considered bad style.) \n expression1 if expression2 else expression3 if expression4 else expression5 # and so on\n \n A note on usage: \n Note that every  if  must be followed with an  else . People learning list comprehensions and generator expressions may find this to be a difficult lesson to learn - the following will not work, as Python expects a third expression for an else: \n [expression1 if expression2 for element in iterable]\n#                          ^-- need an else here\n \n which raises a  SyntaxError: invalid syntax .\nSo the above is either an incomplete piece of logic (perhaps the user expects a no-op in the false condition) or what may be intended is to use  expression2  as a filter - notes that the following is legal Python: \n [expression1 for element in iterable if expression2]\n \n expression2  works as a filter for the list comprehension, and is  not  a ternary conditional operator. \n Alternative syntax for a more narrow case: \n You may find it somewhat painful to write the following: \n expression1 if expression1 else expression2\n \n expression1  will have to be evaluated twice with the above usage. It can limit redundancy if it is simply a local variable. However, a common and performant Pythonic idiom for this use-case is to use  or 's shortcutting behavior: \n expression1 or expression2\n \n which is equivalent in semantics. Note that some style-guides may limit this usage on the grounds of clarity - it does pack a lot of meaning into very little syntax. \n    ", "date_posted": "2022-04-01 17:30:21Z", "upvote": "\r\n            50\r\n        ", "accepted": "No", "user": {"stack_user_id": "33765206", "name": "\r\n        3 revs, 2 users 76%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "33765206", "stack_answer_comment_id": "58658010", "comment_content": " being similar and with the same drawbacks/positives as ", "user_id": null}, {"stack_answer_id": "33765206", "stack_answer_comment_id": "62448054", "comment_content": "Thanks, @selurvedu - it can be confusing until you get it straight. I learned the hard way, so your way might not be as hard. ;) Using if without the else, at the end of a generator expression or list comprehension will filter the iterable. In the front, it's a ternary conditional operation, and requires the else. Cheers!!", "user_id": null}, {"stack_answer_id": "33765206", "stack_answer_comment_id": "95571762", "comment_content": "@AaronHall Although your use of metasyntactic ", "user_id": null}, {"stack_answer_id": "33765206", "stack_answer_comment_id": "95575895", "comment_content": "@tchrist thanks for the review - if you look at the revision history, this post currently has two revisions. Most of my other answers, especially the top ones, have been revisited again and again. This answer never gets my attention because the community wiki status gives me no credit for the content, and so I never see any votes on it. As I don't really have time for an edit on this right now, frog knows when it will come to my attention again in the future. I can see you've edited the top answer, so feel free to borrow/quote my material from this post in that one (and cite me if apropos!)", "user_id": null}]}, {"stack_answer_id": "58409100", "answer_content": "\r\n As already answered, yes, there is a ternary operator in Python: \n <expression 1> if <condition> else <expression 2>\n \n In many cases  <expression 1>  is also used as Boolean evaluated  <condition> . Then you can use  short-circuit evaluation . \n a = 0\nb = 1\n\n# Instead of this:\nx = a if a else b\n# Evaluates as 'a if bool(a) else b'\n\n# You could use short-circuit evaluation:\nx = a or b\n \n One big pro of short-circuit evaluation is the possibility of chaining more than two expressions: \n x = a or b or c or d or e\n \n When working with functions it is more different in detail: \n # Evaluating functions:\ndef foo(x):\n    print('foo executed')\n    return x\n\n\ndef bar(y):\n    print('bar executed')\n    return y\n\n\ndef blubb(z):\n    print('blubb executed')\n    return z\n\n\n# Ternary Operator expression 1 equals to False\nprint(foo(0) if foo(0) else bar(1))\n''' foo and bar are executed once\nfoo executed\nbar executed\n1\n'''\n\n# Ternary Operator expression 1 equals to True\nprint(foo(2) if foo(2) else bar(3))\n''' foo is executed twice!\nfoo executed\nfoo executed\n2\n'''\n\n# Short-circuit evaluation second equals to True\nprint(foo(0) or bar(1) or blubb(2))\n''' blubb is not executed\nfoo executed\nbar executed\n1\n'''\n\n# Short-circuit evaluation third equals to True\nprint(foo(0) or bar(0) or blubb(2))\n'''\nfoo executed\nbar executed\nblubb executed\n2\n'''\n\n# Short-circuit evaluation all equal to False\nprint(foo(0) or bar(0) or blubb(0))\n''' Result is 0 (from blubb(0)) because no value equals to True\nfoo executed\nbar executed\nblubb executed\n0\n'''\n \n PS: Of course, a short-circuit evaluation is not a ternary operator, but often the ternary is used in cases where the short circuit would be enough. It has a better readability and can be chained. \n    ", "date_posted": "2022-02-06 13:28:15Z", "upvote": "\r\n            33\r\n        ", "accepted": "No", "user": {"stack_user_id": "58409100", "name": "\r\n        4 revs, 2 users 89%", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "54609267", "answer_content": "\r\n One of the alternatives to Python's  conditional expression \n \"yes\" if boolean else \"no\"\n \n is the following: \n {True: \"yes\", False: \"no\"}[boolean]\n \n which has the following nice extension: \n {True: \"yes\", False: \"no\", None: \"maybe\"}[boolean_or_none]\n \n The shortest alternative remains \n (\"no\", \"yes\")[boolean]\n \n which works because  issubclass(bool, int) . \n Careful, though: the alternative to \n yes() if boolean else no()\n \n is  not \n (no(), yes())[boolean]  # bad: BOTH no() and yes() are called\n \n but \n (no, yes)[boolean]()\n \n This works fine as long as  no  and  yes  are to be called with exactly the same parameters. If they are not, like in \n yes(\"ok\") if boolean else no()  # (1)\n \n or in \n yes(\"ok\") if boolean else no(\"sorry\")  # (2)\n \n then a similar alternative either does not exist (1) or is hardly viable (2). (In rare cases, depending on the context, something like \n msg = (\"sorry\", \"ok\")[boolean]\n(no, yes)[boolean](msg)\n \n could make sense.) \n Thanks to Radek Roj\u00edk for his comment \n    ", "date_posted": "2022-06-01 12:19:26Z", "upvote": "\r\n            33\r\n        ", "accepted": "No", "user": {"stack_user_id": "54609267", "name": "\r\n        6 revs", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "54609267", "stack_answer_comment_id": "127061683", "comment_content": "Alternative: ", "user_id": null}]}, {"stack_answer_id": "20093702", "answer_content": "\r\n Simulating the Python ternary operator. \n For example \n a, b, x, y = 1, 2, 'a greather than b', 'b greater than a'\nresult = (lambda:y, lambda:x)[a > b]()\n \n Output: \n 'b greater than a'\n \n    ", "date_posted": "2022-02-06 12:25:06Z", "upvote": "\r\n            31\r\n        ", "accepted": "No", "user": {"stack_user_id": "20093702", "name": "\r\n        2 revs, 2 users 81%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "20093702", "stack_answer_comment_id": "31175220", "comment_content": "Why not simply ", "user_id": null}, {"stack_answer_id": "20093702", "stack_answer_comment_id": "32895313", "comment_content": "@GrijeshChauhan Because on \"compliated\" expressions, e. g. involving a function call etc., this would be executed in both cases. This might not be wanted.", "user_id": null}, {"stack_answer_id": "20093702", "stack_answer_comment_id": "115414421", "comment_content": "The use of ", "user_id": null}, {"stack_answer_id": "20093702", "stack_answer_comment_id": "116319126", "comment_content": "@GrijeshChauhan In short, this implements the so-called \u201c", "user_id": null}]}, {"stack_answer_id": "53653902", "answer_content": "\r\n a if condition else b\n \n\n Just memorize this pyramid if you have trouble remembering: \n\n      condition\n  if           else\na                   b \n \n    ", "date_posted": "2018-12-06 14:45:27Z", "upvote": "\r\n            29\r\n        ", "accepted": "No", "user": {"stack_user_id": "53653902", "name": "\r\n        shivtej\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "49653070", "answer_content": "\r\n The ternary conditional operator simply allows testing a condition in a single line replacing the multiline if-else making the code compact. \n Syntax: \n \n [on_true] if [expression] else [on_false] \n \n 1- Simple Method to use ternary operator: \n # Program to demonstrate conditional operator\na, b = 10, 20\n# Copy value of a in min if a < b else copy b\nmin = a if a < b else b\nprint(min)  # Output: 10\n \n 2- Direct Method of using tuples, Dictionary, and lambda: \n # Python program to demonstrate ternary operator\na, b = 10, 20\n# Use tuple for selecting an item\nprint( (b, a) [a < b] )\n# Use Dictionary for selecting an item\nprint({True: a, False: b} [a < b])\n# lambda is more efficient than above two methods\n# because in lambda  we are assure that\n# only one expression will be evaluated unlike in\n# tuple and Dictionary\nprint((lambda: b, lambda: a)[a < b]()) # in output you should see three 10\n \n 3- Ternary operator can be written as nested if-else: \n # Python program to demonstrate nested ternary operator\na, b = 10, 20\nprint (\"Both a and b are equal\" if a == b else \"a is greater than b\"\n        if a > b else \"b is greater than a\")\n \n Above approach can be written as: \n # Python program to demonstrate nested ternary operator\na, b = 10, 20\nif a != b:\n    if a > b:\n        print(\"a is greater than b\")\n    else:\n        print(\"b is greater than a\")\nelse:\n    print(\"Both a and b are equal\")\n# Output: b is greater than a\n \n    ", "date_posted": "2022-02-06 13:11:36Z", "upvote": "\r\n            28\r\n        ", "accepted": "No", "user": {"stack_user_id": "49653070", "name": "\r\n        3 revs, 2 users 86%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "49653070", "stack_answer_comment_id": "92454366", "comment_content": "Note that the ternary operator is smaller (in memory) and faster than the nested if.  Also, your nested ", "user_id": null}]}, {"stack_answer_id": "65422380", "answer_content": "\r\n Vinko Vrsalovic's answer  is good enough. There is only one more thing: \n \n Note that conditionals are an  expression , not a  statement . This means you can't use assignment statements or  pass  or other  statements  within a conditional  expression \n \n Walrus operator in Python 3.8 \n After the  walrus operator  was introduced in Python 3.8, something changed. \n (a := 3) if True else (b := 5)\n \n gives  a = 3  and  b is not defined , \n (a := 3) if False else (b := 5)\n \n gives  a is not defined  and  b = 5 , and \n c = (a := 3) if False else (b := 5)\n \n gives  c = 5 ,  a is not defined  and  b = 5 . \n Even if this may be ugly,  assignments  can be done  inside  conditional expressions after Python 3.8. Anyway, it is still better to use normal  if   statement  instead in this case. \n    ", "date_posted": "2022-02-06 13:36:09Z", "upvote": "\r\n            27\r\n        ", "accepted": "No", "user": {"stack_user_id": "65422380", "name": "\r\n        2 revs, 2 users 69%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "65422380", "stack_answer_comment_id": "121325576", "comment_content": "In the first example: ", "user_id": null}, {"stack_answer_id": "65422380", "stack_answer_comment_id": "121356996", "comment_content": "@AndrewAnderson No it's not redundant. You should compare both the first and the second examples. You can combine them and consider this: ", "user_id": null}, {"stack_answer_id": "65422380", "stack_answer_comment_id": "121376861", "comment_content": "Yes, that's correct :). I considered this only for ", "user_id": null}, {"stack_answer_id": "65422380", "stack_answer_comment_id": "121396760", "comment_content": "Because we don't really write down this code ", "user_id": null}]}, {"stack_answer_id": "37155553", "answer_content": "\r\n More a tip than an answer (I don't need to repeat the obvious for the hundredth time), but I sometimes use it as a one-liner shortcut in such constructs: \n if conditionX:\n    print('yes')\nelse:\n    print('nah')\n \n , becomes: \n print('yes') if conditionX else print('nah')\n \n Some (many :) may frown upon it as unpythonic (even, Ruby-ish :), but I personally find it more natural - i.e., how you'd express it normally, plus a bit more visually appealing in large blocks of code. \n    ", "date_posted": "2022-02-06 12:30:29Z", "upvote": "\r\n            26\r\n        ", "accepted": "No", "user": {"stack_user_id": "37155553", "name": "\r\n        3 revs, 3 users 76%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "37155553", "stack_answer_comment_id": "78515516", "comment_content": "I prefer ", "user_id": null}, {"stack_answer_id": "37155553", "stack_answer_comment_id": "80853618", "comment_content": "That is if you want to ", "user_id": null}, {"stack_answer_id": "37155553", "stack_answer_comment_id": "92749861", "comment_content": "To add to Frederick99's remark, another reason to avoid ", "user_id": null}, {"stack_answer_id": "37155553", "stack_answer_comment_id": "92753803", "comment_content": "The only reason it gives a syntax error is because in Python 2 print is a statement - ", "user_id": null}]}, {"stack_answer_id": "45779600", "answer_content": "\r\n You can do this: \n [condition] and [expression_1] or [expression_2];\n \n Example: \n print(number%2 and \"odd\" or \"even\")\n \n This would print \"odd\" if the number is odd or \"even\" if the number is even. \n \n The result:  If condition is true, exp_1 is executed, else exp_2 is executed. \n Note:  0, None, False, emptylist, and emptyString evaluates as False. \n And any data other than 0 evaluates to True. \n Here's how it works: \n If the condition [condition] becomes \"True\", then expression_1 will be evaluated, but not expression_2. \n If we \"and\" something with 0 (zero), the result will always to be false. So in the below statement, \n 0 and exp\n \n The expression  exp  won't be evaluated at all since \"and\" with 0 will always evaluate to zero and there is no need to evaluate the expression. This is how the compiler itself works, in all languages. \n In \n 1 or exp\n \n the expression  exp  won't be evaluated at all since \"or\" with 1 will always be 1. So it won't bother to evaluate the expression exp since the result will be 1 anyway (compiler optimization methods). \n But in case of \n True and exp1 or exp2\n \n The second expression exp2 won't be evaluated since  True and exp1  would be True when exp1 isn't false. \n Similarly in \n False and exp1 or exp2\n \n The expression  exp1  won't be evaluated since False is equivalent to writing 0 and doing \"and\" with 0 would be 0 itself, but after exp1 since \"or\" is used, it will evaluate the expression exp2 after \"or\". \n \n Note:-  This kind of branching using \"or\" and \"and\" can only be used when the expression_1 doesn't have a Truth value of False (or 0 or None or emptylist [ ] or emptystring ' '.) since if expression_1 becomes False, then the expression_2 will be evaluated because of the presence \"or\" between exp_1 and exp_2. \n In case you still want to make it work for all the cases regardless of what exp_1 and exp_2 truth values are, do this: \n [condition] and ([expression_1] or 1) or [expression_2];\n \n    ", "date_posted": "2022-02-06 12:43:54Z", "upvote": "\r\n            26\r\n        ", "accepted": "No", "user": {"stack_user_id": "45779600", "name": "\r\n        5 revs, 2 users 52%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "45779600", "stack_answer_comment_id": "80634562", "comment_content": "If you want to use that in the context of ", "user_id": null}]}, {"stack_answer_id": "53922638", "answer_content": "\r\n Many programming languages derived from  C  usually have the following syntax of the ternary conditional operator: \n <condition> ? <expression1> : <expression2>\n \n At first, the Python's  benevolent dictator for life  (I mean  Guido van Rossum , of course) rejected it (as non-Pythonic style), since it's quite hard to understand for people not used to C language. Also, the colon sign  :  already has many uses in Python. After  PEP 308  was approved, Python finally received its own shortcut conditional expression (what we use now): \n <expression1> if <condition> else <expression2>\n \n So, firstly it evaluates the condition. If it returns  True ,  expression1  will be evaluated to give the result, otherwise  expression2  will be evaluated. Due to  lazy evaluation  mechanics \u2013 only one expression will be executed. \n Here are some examples (conditions will be evaluated from left to right): \n pressure = 10\nprint('High' if pressure < 20 else 'Critical')\n\n# Result is 'High'\n \n Ternary operators can be chained in series: \n pressure = 5\nprint('Normal' if pressure < 10 else 'High' if pressure < 20 else 'Critical')\n\n# Result is 'Normal'\n \n The following one is the same as previous one: \n pressure = 5\n\nif pressure < 20:\n    if pressure < 10:\n        print('Normal')\n    else:\n        print('High')\nelse:\n    print('Critical')\n\n# Result is 'Normal'\n \n    ", "date_posted": "2022-02-06 12:57:48Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "53922638", "name": "\r\n        4 revs, 3 users 87%", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "52919467", "answer_content": "\r\n Yes , Python have a ternary operator, here is the syntax and an example code to demonstrate the same :) \n #[On true] if [expression] else[On false]\n# if the expression evaluates to true then it will pass On true otherwise On false\n\na = input(\"Enter the First Number \")\nb = input(\"Enter the Second Number \")\n\nprint(\"A is Bigger\") if a>b else print(\"B is Bigger\")\n \n    ", "date_posted": "2022-02-06 12:52:56Z", "upvote": "\r\n            15\r\n        ", "accepted": "No", "user": {"stack_user_id": "52919467", "name": "\r\n        3 revs, 2 users 51%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "52919467", "stack_answer_comment_id": "92748969", "comment_content": "I have added a one line statement example to check which number is big to elaborate it further", "user_id": null}, {"stack_answer_id": "52919467", "stack_answer_comment_id": "92749878", "comment_content": " is really not a good choice, as this will give a SyntaxError in Python2.", "user_id": null}, {"stack_answer_id": "52919467", "stack_answer_comment_id": "92749900", "comment_content": "@Thierry Lathuille here I used print() function not print statement, print function is for Python 3 while print statement is for Python 2", "user_id": null}, {"stack_answer_id": "52919467", "stack_answer_comment_id": "92749954", "comment_content": "The question has already been asked on SO, just try it with Python 2 and you will see by yourself. 'print('hello') is a perfectly valid syntax in Python 2.7, but the way it is parsed makes your code above throw a SyntaxError.", "user_id": null}]}, {"stack_answer_id": "61896436", "answer_content": "\r\n Other answers correctly talk about the Python ternary operator. I would like to complement by mentioning a scenario for which the ternary operator is often used, but for which there is a better idiom. This is the scenario of using a default value. \n Suppose we want to use  option_value  with a default value if it is not set: \n run_algorithm(option_value if option_value is not None else 10)\n \n or, if  option_value  is never set to a falsy value ( 0 ,  \"\" , etc.), simply \n run_algorithm(option_value if option_value else 10)\n \n However, in this case an ever better solution is simply to write \n run_algorithm(option_value or 10)\n \n    ", "date_posted": "2022-02-06 13:31:30Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "61896436", "name": "\r\n        3 revs, 2 users 83%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "61896436", "stack_answer_comment_id": "113960535", "comment_content": "A valuable complement, but I disagree: ", "user_id": null}, {"stack_answer_id": "61896436", "stack_answer_comment_id": "114022487", "comment_content": "@ruancomelli: Good point. I've modified the answer to reflect that correction.", "user_id": null}, {"stack_answer_id": "61896436", "stack_answer_comment_id": "114022542", "comment_content": "As for it looking weird, I wonder if it looked weird to you because you noticed the imprecision (that it was not really equivalent). To me it sounds natural because it reminds me saying in English: \"Use this or that (if the first option is unavailable)\". But of course that is subjective. It is useful to know it does not look natural to everybody.", "user_id": null}, {"stack_answer_id": "61896436", "stack_answer_comment_id": "114190254", "comment_content": "Much better! And thanks for the explanation regarding the \"or\"-idiom. It looks weird to me because I tend to think of ", "user_id": null}]}, {"stack_answer_id": "71819081", "answer_content": "\r\n The syntax for the ternary operator in Python is: \n [on_true] if [expression] else [on_false] \n Using that syntax, here is how we would rewrite the code above using Python\u2019s ternary operator: \n game_type = 'home'\nshirt = 'white' if game_type == 'home' else 'green'\n\n \n It's still pretty clear, but much shorter. Note that the expression could be any type of expression, including a function call, that returns a value that evaluates to True or False. \n    ", "date_posted": "2022-04-10 17:39:25Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "71819081", "name": "\r\n        George Imerlishvili\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "60630600", "answer_content": "\r\n Python has a ternary form for assignments; however there may be even a shorter form that people should be aware of. \n It's very common to need to assign to a variable one value or another depending on a condition. \n >>> li1 = None\n>>> li2 = [1, 2, 3]\n>>>\n>>> if li1:\n...     a = li1\n... else:\n...     a = li2\n...\n>>> a\n[1, 2, 3]\n \n ^ This is the long form for doing such assignments. \n Below is the ternary form. But this isn't the most succinct way - see the last example. \n >>> a = li1 if li1 else li2\n>>>\n>>> a\n[1, 2, 3]\n>>>\n \n With Python, you can simply use  or  for alternative assignments. \n >>> a = li1 or li2\n>>>\n>>> a\n[1, 2, 3]\n>>>\n \n The above works since  li1  is  None  and the interpreter treats that as False in logic expressions. The interpreter then moves on and evaluates the second expression, which is not  None  and it's not an empty list - so it gets assigned to  a . \n This also works with empty lists. For instance, if you want to assign  a  whichever list has items. \n >>> li1 = []\n>>> li2 = [1, 2, 3]\n>>>\n>>> a = li1 or li2\n>>>\n>>> a\n[1, 2, 3]\n>>>\n \n Knowing this, you can simply such assignments whenever you encounter them. This also works with strings and other iterables. You could assign  a  whichever string isn't empty. \n >>> s1 = ''\n>>> s2 = 'hello world'\n>>>\n>>> a = s1 or s2\n>>>\n>>> a\n'hello world'\n>>>\n \n I always liked the C ternary syntax, but Python takes it a step further! \n I understand that some may say this isn't a good stylistic choice, because it relies on mechanics that aren't immediately apparent to all developers. I personally disagree with that viewpoint. Python is a syntax-rich language with lots of idiomatic tricks that aren't immediately apparent to the dabbler. But the more you learn and understand the mechanics of the underlying system, the more you appreciate it. \n    ", "date_posted": "2022-02-06 13:26:23Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "60630600", "name": "\r\n        4 revs, 2 users 86%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "60630600", "stack_answer_comment_id": "125525088", "comment_content": "Something seems to be missing near ", "user_id": null}, {"stack_answer_id": "60630600", "stack_answer_comment_id": "125527651", "comment_content": "\"Simplify\" such assignments =) @PeterMortensen", "user_id": null}]}, {"stack_answer_id": "70523744", "answer_content": "\r\n Pythonic way of doing the things: \n \"true\" if var else \"false\"\n \n But there always exists a different way of doing a ternary condition too: \n \"true\" and var or \"false\"\n \n    ", "date_posted": "2022-02-06 13:55:46Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "70523744", "name": "\r\n        2 revs, 2 users 80%", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "71007804", "answer_content": "\r\n There are multiple ways. The simplest one is to use the condition inside the \"print\" method. \n You can use \n print(\"Twenty\" if number == 20 else \"Not twenty\")\n \n Which is equivalent to: \n if number == 20:\n    print(\"Twenty\")\nelse:\n    print(\"Not twenty\")\n \n In this way, more than two statements are also possible to print. For example: \n if number == 20:\n    print(\"Twenty\")\nelif number < 20:\n    print(\"Lesser\")\nelif 30 > number > 20:\n    print(\"Between\")\nelse:\n    print(\"Greater\")\n \n can be written as: \n print(\"Twenty\" if number == 20 else \"Lesser\" if number < 20 else \"Between\" if 30 > number > 20 else \"Greater\")\n \n    ", "date_posted": "2022-02-06 13:46:32Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "71007804", "name": "\r\n        Aldrin Saurov Sarker\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "70941294", "answer_content": "\r\n The  if else-if  version can be written as: \n sample_set=\"train\" if \"Train\" in full_path else (\"test\" if \"Test\" in full_path else \"validation\")\n \n    ", "date_posted": "2022-02-06 13:56:20Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "70941294", "name": "\r\n        2 revs, 2 users 67%", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "71150434", "answer_content": "\r\n Yes, it has, but it's different from C-syntax-like programming languages (which is  condition ? value_if_true : value_if_false \n In Python, it goes like this:  value_if_true if condition else value_if_false \n Example:  even_or_odd = \"even\" if x % 2 == 0 else \"odd\" \n    ", "date_posted": "2022-02-16 23:09:11Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "71150434", "name": "\r\n        Heroes Of Balkan\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "56099511", "answer_content": "\r\n A neat way to chain multiple operators: \n\n f = lambda x,y: 'greater' if x > y else 'less' if y > x else 'equal'\n\narray = [(0,0),(0,1),(1,0),(1,1)]\n\nfor a in array:\n  x, y = a[0], a[1]\n  print(f(x,y))\n\n# Output is:\n#   equal,\n#   less,\n#   greater,\n#   equal\n\n \n    ", "date_posted": "2019-05-12 13:03:48Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "56099511", "name": "\r\n        Yaakov Bressler\r\n        ", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "60876846", "answer_content": "\r\n I find the default Python syntax  val = a if cond else b  cumbersome, so sometimes I do this: \n iif = lambda (cond, a, b): a if cond else b\n# So I can then use it like:\nval = iif(cond, a, b)\n \n Of course, it has the downside of always evaluating both sides ( a  and  b ), but the syntax is way clearer to me. \n    ", "date_posted": "2022-02-06 13:30:33Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "60876846", "name": "\r\n        2 revs, 2 users 60%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "60876846", "stack_answer_comment_id": "108765520", "comment_content": "This seems to be twice the amount of work, more RAM usage and more obfuscated than the simpler ", "user_id": null}, {"stack_answer_id": "60876846", "stack_answer_comment_id": "116103460", "comment_content": "Also both ", "user_id": null}, {"stack_answer_id": "60876846", "stack_answer_comment_id": "126733397", "comment_content": "According to PEP8 assigning lambda to variable is a code smell. Lambda should be used only as inplace function.", "user_id": null}]}], "user": {"stack_user_id": null, "name": null, "reputation_score": 0}, "question_comments": [{"stack_question_id": "394809", "stack_question_comment_id": "19777451", "comment_content": "In the Python 3.0 official documentation referenced in a comment above, this is referred to as \"conditional_expressions\" and is very cryptically defined.  That documentation doesn't even include the term \"ternary\", so you would be hard-pressed to find it via Google unless you knew exactly what to look for.  The ", "user_id": null}, {"stack_question_id": "394809", "stack_question_comment_id": "43418120", "comment_content": "\"ternary\" (having three inputs) is a consequential property of this impelmentation, not a defining property of the concept. eg:  SQL has ", "user_id": null}, {"stack_question_id": "394809", "stack_question_comment_id": "43418299", "comment_content": "also ISO/IEC 9899 (the C programming language standard) section 6.5.15 calls it the \"the condtitional operator\"", "user_id": null}, {"stack_question_id": "394809", "stack_question_comment_id": "62912948", "comment_content": "Wikipedia covers this thoroughly in the article \"", "user_id": null}, {"stack_question_id": "394809", "stack_question_comment_id": "90671337", "comment_content": "In the years since nobar's comment the ", "user_id": null}]},
{"stack_question_id": "2709821", "question_title": "What is the `self` parameter in class methods?", "question_content": "\r\n                self refers to the specific object instance created from a class. But why must every method explicitly include self as a parameter?\nclass MyClass:\n    def func(self, name):\n        self.name = name\n\n...\r\n", "question_url": "/questions/2709821/what-is-the-self-parameter-in-class-methods", "date_posted": "Apr 25, 2010 at 20:22", "upvote": "1", "view": "9", "tags": ["python", "class", "oop", "self"], "answers_count": "2", "answers": [{"stack_answer_id": "2709832", "answer_content": "\r\n The reason you need to use  self.  is because Python does not use the  @  syntax to refer to instance attributes. Python decided to do methods in a way that makes the instance to which the method belongs be  passed  automatically, but not  received  automatically: the first parameter of methods is the instance the method is called on. That makes methods entirely the same as functions, and leaves the actual name to use up to you (although  self  is the convention, and people will generally frown at you when you use something else.)  self  is not special to the code, it's just another object. \n\n Python could have done something else to distinguish normal names from attributes -- special syntax like Ruby has, or requiring declarations like C++ and Java do, or perhaps something  yet more different -- but it didn't. Python's all for making things explicit, making it obvious what's what, and although it doesn't do it entirely everywhere, it does do it for instance attributes. That's why assigning to an instance attribute needs to know what instance to assign to, and that's why it needs  self. . \n    ", "date_posted": "2010-04-27 23:01:28Z", "upvote": "\r\n            765\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "17624", "name": "Thomas Wouters", "reputation_score": "126k"}, "answer_comments": [{"stack_answer_id": "2709832", "stack_answer_comment_id": "2734191", "comment_content": "@Georg: ", "user_id": null}, {"stack_answer_id": "2709832", "stack_answer_comment_id": "4604498", "comment_content": "@SilentGhost: Actually, the name of the first parameter is whatever you want it to be.  On class methods, the convention is to use ", "user_id": null}, {"stack_answer_id": "2709832", "stack_answer_comment_id": "19063966", "comment_content": "I find it interesting that the community didn't choose ", "user_id": null}, {"stack_answer_id": "2709832", "stack_answer_comment_id": "27940514", "comment_content": "@Julius The ", "user_id": null}, {"stack_answer_id": "2709832", "stack_answer_comment_id": "42210957", "comment_content": "@Julius The ", "user_id": null}]}, {"stack_answer_id": "21366809", "answer_content": "\r\n Let's say you have a class  ClassA  which contains a method  methodA  defined as: \n\n def methodA(self, arg1, arg2):\n    # do something\n \n\n and  ObjectA  is an instance of this class. \n\n Now when  ObjectA.methodA(arg1, arg2)  is called, python internally converts it for you as: \n\n ClassA.methodA(ObjectA, arg1, arg2)\n \n\n The  self  variable refers to the object itself. \n    ", "date_posted": "2019-11-16 18:56:13Z", "upvote": "\r\n            583\r\n        ", "accepted": "No", "user": {"stack_user_id": "997813", "name": "Arjun Sreedharan", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "21366809", "stack_answer_comment_id": "41174707", "comment_content": "I read all the other answers and sort of understood, I read this one and then it all made sense.", "user_id": null}, {"stack_answer_id": "21366809", "stack_answer_comment_id": "79661533", "comment_content": "Why not keep those guts inside, though, like Ruby does?", "user_id": null}, {"stack_answer_id": "21366809", "stack_answer_comment_id": "83963043", "comment_content": "But in __init__(self) method, it accepts self, then even without creating the object, how does it refer to itself?", "user_id": null}, {"stack_answer_id": "21366809", "stack_answer_comment_id": "120812764", "comment_content": "This doesn't answer the question though. The OP was asking about why ", "user_id": null}, {"stack_answer_id": "21366809", "stack_answer_comment_id": "129280090", "comment_content": "Why then a new function is generated for every instance of ", "user_id": null}]}, {"stack_answer_id": "2725996", "answer_content": "\r\n Let\u2019s take a simple vector class: \n\n class Vector:\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n \n\n We want to have a method which calculates the length. What would it look like if we wanted to define it inside the class? \n\n     def length(self):\n        return math.sqrt(self.x ** 2 + self.y ** 2)\n \n\n What should it look like when we were to define it as a global method/function? \n\n def length_global(vector):\n    return math.sqrt(vector.x ** 2 + vector.y ** 2)\n \n\n So the whole structure stays the same. How can me make use of this? If we assume for a moment that we hadn\u2019t written a  length  method for our  Vector  class, we could do this: \n\n Vector.length_new = length_global\nv = Vector(3, 4)\nprint(v.length_new()) # 5.0\n \n\n This works because the first parameter of  length_global , can be re-used as the  self  parameter in  length_new . This would not be possible without an explicit  self . \n\n \n\n Another way of understanding the need for the explicit  self  is to see where Python adds some syntactical sugar. When you keep in mind, that basically, a call like \n\n v_instance.length()\n \n\n is internally transformed to \n\n Vector.length(v_instance)\n \n\n it is easy to see where the  self  fits in. You don't actually write instance methods in Python; what you write is class methods which must take an instance as a first parameter. And therefore, you\u2019ll have to place the instance parameter somewhere explicitly. \n    ", "date_posted": "2017-08-15 06:40:38Z", "upvote": "\r\n            436\r\n        ", "accepted": "No", "user": {"stack_user_id": "1637126", "name": "empty", "reputation_score": "4,892"}, "answer_comments": [{"stack_answer_id": "2725996", "stack_answer_comment_id": "4604132", "comment_content": "Vector.length_new = length_global... I actually started to use syntax like this in my class declarations. Whenever I only want to inherit some of the methods from another class, I just explicitly copy the reference to the methods.", "user_id": null}, {"stack_answer_id": "2725996", "stack_answer_comment_id": "16540616", "comment_content": "would it be fair to say that python's \"instance method\" is simply a syntactic sugar of static global methods (as in Java or C++) with an instance object passed in to package multiple attributes?  --- well this is kind of half-true since in polymorphism, the more important purpose of \"this\" (as in java) or \"self\" is to give u the correct implementation of methods. Python does have this. so calling myobj.someMethod() is equal to TheClassOfMyObj.someMethod(myobj) in python. note that the \"TheClassOfMyObj\" is automatically figured out by python from \"self\", otherwise u'd have to find that out.", "user_id": null}, {"stack_answer_id": "2725996", "stack_answer_comment_id": "27469407", "comment_content": "Infact, not only are instance methods just class methods, but methods are just functions which are members of a class, as the ", "user_id": null}, {"stack_answer_id": "2725996", "stack_answer_comment_id": "34102116", "comment_content": "\"This works, because the first parameter of length_global, can be re-used as the self parameter in length_new. This would not be possible without an explicit self.\" - it would work just the same. it would be re-used for the implicit self... the second example is a circular reasoning - you have to explicitly place self there, because python needs the explicit self.", "user_id": null}, {"stack_answer_id": "2725996", "stack_answer_comment_id": "34123622", "comment_content": "@KarolyHorvath: Sure, it would also be possible to have a language with a model where internally defined methods do not need an explicit self but externally defined methods do. But I\u2019d say there is some consistency in requiring the explicit self in both cases, which makes it a legitimate reason to do it this way. Other languages may choose different approaches.", "user_id": null}]}, {"stack_answer_id": "31096552", "answer_content": "\r\n When objects are instantiated, the object itself is passed into the self parameter.  \n\n \n\n Because of this, the object\u2019s data is bound to the object. Below is an example of how you might like to visualize what each object\u2019s data might look. Notice how \u2018self\u2019 is replaced with the objects name. I'm not saying this example diagram below is wholly accurate but it hopefully with serve a purpose in visualizing the use of self.  \n\n \n\n The Object is passed into the self parameter so that the object can keep hold of its own data. \n\n Although this may not be wholly accurate, think of the process of instantiating an object like this: When an object is made it uses the class as a template for its own data and methods. Without passing it's own name into the self parameter, the attributes and methods in the class would remain as a general template and would not be referenced to (belong to) the object. So by passing the object's name into the self parameter it means that if 100 objects are instantiated from the one class, they can all keep track of their own data and methods. \n\n See the illustration below: \n\n \n    ", "date_posted": "2015-06-28 05:47:02Z", "upvote": "\r\n            246\r\n        ", "accepted": "No", "user": {"stack_user_id": "2686197", "name": "sw123456", "reputation_score": "3,171"}, "answer_comments": [{"stack_answer_id": "31096552", "stack_answer_comment_id": "51742866", "comment_content": "Hey there, when accessing Bob's attributes for example by \"bob.name()\", you actually accesing bob().self.name so to speak from the '", "user_id": null}, {"stack_answer_id": "31096552", "stack_answer_comment_id": "51743445", "comment_content": "When you write bob.name() in the above comment, you are implying that bob has a method called name() due to the fact that you added brackets after name. In this example however there is no such method. 'bob.name' (which has no parenthesis) is directly accessing the attribute called name from the init (constructor) method. When bob's speak method is called it is the method which accesses the name attribute and returns it in a print statement. Hope this helps.", "user_id": null}, {"stack_answer_id": "31096552", "stack_answer_comment_id": "51744484", "comment_content": "No, you get the value of self.name, which for the bob object is actually bob.name, because the object's name is passed into the self parameter when it is created (instantiated). Again, hope this helps. Feel free to upvote main post if it has.", "user_id": null}, {"stack_answer_id": "31096552", "stack_answer_comment_id": "51744680", "comment_content": "Name is assigned to self.name at instantiation. After an object is created, all variables that belong to the object are those prefixed with 'self.' Remember that self is replaced with the object's name when it is created from the class.", "user_id": null}, {"stack_answer_id": "31096552", "stack_answer_comment_id": "81189993", "comment_content": "This is how you explain stuff ! nice job :)", "user_id": null}]}, {"stack_answer_id": "2714920", "answer_content": "\r\n I like this example: \n\n class A: \n    foo = []\na, b = A(), A()\na.foo.append(5)\nb.foo\nans: [5]\n\nclass A: \n    def __init__(self): \n        self.foo = []\na, b = A(), A()\na.foo.append(5)\nb.foo\nans: []\n \n    ", "date_posted": "2010-04-26 16:02:48Z", "upvote": "\r\n            85\r\n        ", "accepted": "No", "user": {"stack_user_id": "237934", "name": "kame", "reputation_score": "19.4k"}, "answer_comments": [{"stack_answer_id": "2714920", "stack_answer_comment_id": "16540656", "comment_content": "so vars without self is simply static vars of the class, like in java", "user_id": null}, {"stack_answer_id": "2714920", "stack_answer_comment_id": "34582202", "comment_content": "teddy teddy, you aren't entirely correct. The behavior (static or non-static like) depends not only on ", "user_id": null}, {"stack_answer_id": "2714920", "stack_answer_comment_id": "39184200", "comment_content": "Actually, my question with this is why are you allowed to say ", "user_id": null}, {"stack_answer_id": "2714920", "stack_answer_comment_id": "41852298", "comment_content": "You can call static members from instances of the object in most languages. Why is that surprising?", "user_id": null}, {"stack_answer_id": "2714920", "stack_answer_comment_id": "77100679", "comment_content": "@RadonRosborough Because in the first example, ", "user_id": null}]}, {"stack_answer_id": "6433556", "answer_content": "\r\n I will demonstrate with code that  does not use classes : \n\n def state_init(state):\n    state['field'] = 'init'\n\ndef state_add(state, x):\n    state['field'] += x\n\ndef state_mult(state, x):\n    state['field'] *= x\n\ndef state_getField(state):\n    return state['field']\n\nmyself = {}\nstate_init(myself)\nstate_add(myself, 'added')\nstate_mult(myself, 2)\n\nprint( state_getField(myself) )\n#--> 'initaddedinitadded'\n \n\n Classes are just a way to avoid passing in this \"state\" thing all the time (and other nice things like initializing, class composition, the rarely-needed metaclasses, and supporting custom methods to override operators). \n\n Now let's demonstrate the above code using the built-in python class machinery, to show how it's basically the same thing. \n\n class State(object):\n    def __init__(self):\n        self.field = 'init'\n    def add(self, x):\n        self.field += x\n    def mult(self, x):\n        self.field *= x\n\ns = State()\ns.add('added')    # self is implicitly passed in\ns.mult(2)         # self is implicitly passed in\nprint( s.field )\n \n\n [migrated my answer from duplicate closed question] \n    ", "date_posted": "2011-06-22 00:27:23Z", "upvote": "\r\n            45\r\n        ", "accepted": "No", "user": {"stack_user_id": "711085", "name": "ninjagecko", "reputation_score": "84.7k"}, "answer_comments": [{"stack_answer_id": "6433556", "stack_answer_comment_id": "79661616", "comment_content": "I wish Python sugarcoated the handlers as well as Ruby does.", "user_id": null}]}, {"stack_answer_id": "2709847", "answer_content": "\r\n The following excerpts are from the  Python documentation about self : \n \n As in Modula-3, there are no shorthands [in Python] for referencing the object\u2019s members from its methods: the method function is declared with an explicit first argument representing the object, which is provided implicitly by the call. \n Often, the first argument of a method is called self. This is nothing more than a convention: the name self has absolutely no special meaning to Python. Note, however, that by not following the convention your code may be less readable to other Python programmers, and it is also conceivable that a class browser program might be written that relies upon such a convention. \n \n For more information, see the  Python documentation tutorial on classes . \n    ", "date_posted": "2020-06-20 09:12:55Z", "upvote": "\r\n            23\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}, {"stack_answer_id": "2709857", "answer_content": "\r\n As well as all the other reasons already stated, it allows for easier access to overridden methods; you can call  Class.some_method(inst) . \n\n An example of where it\u2019s useful: \n\n class C1(object):\n    def __init__(self):\n         print \"C1 init\"\n\nclass C2(C1):\n    def __init__(self): #overrides C1.__init__\n        print \"C2 init\"\n        C1.__init__(self) #but we still want C1 to init the class too\n \n\n\n\n >>> C2()\n\"C2 init\"\n\"C1 init\"\n \n    ", "date_posted": "2013-12-24 22:23:49Z", "upvote": "\r\n            22\r\n        ", "accepted": "No", "user": {"stack_user_id": "707111", "name": "Ry-", "reputation_score": "211k"}, "answer_comments": []}, {"stack_answer_id": "12201574", "answer_content": "\r\n Its use is similar to the use of  this  keyword in Java, i.e. to give a reference to the current object. \n    ", "date_posted": "2017-02-27 09:47:48Z", "upvote": "\r\n            18\r\n        ", "accepted": "No", "user": {"stack_user_id": "5387193", "name": "ChickenFeet", "reputation_score": "2,417"}, "answer_comments": [{"stack_answer_id": "12201574", "stack_answer_comment_id": "17780797", "comment_content": "class myClass:         def myFunc(this, name):             this.name = name", "user_id": null}]}, {"stack_answer_id": "30442095", "answer_content": "\r\n Python is not a language built for Object Oriented Programming unlike Java or C++.  \n\n When calling a static method in Python, one simply writes a method with regular arguments inside it.  \n\n class Animal():\n    def staticMethod():\n        print \"This is a static method\"\n \n\n However, an object method, which requires you to make a variable, which is an Animal, in this case, needs the self argument \n\n class Animal():\n    def objectMethod(self):\n        print \"This is an object method which needs an instance of a class\"\n \n\n The self method is also used to refer to a variable field within the class.  \n\n class Animal():\n    #animalName made in constructor\n    def Animal(self):\n        self.animalName = \"\";\n\n\n    def getAnimalName(self):\n        return self.animalName\n \n\n In this case, self is referring to the animalName variable of the entire class. REMEMBER: If you have a variable within a method, self will not work. That variable is simply existent only while that method is running. For defining fields (the variables of the entire class), you have to define them OUTSIDE the class methods.  \n\n If you don't understand a single word of what I am saying, then Google \"Object Oriented Programming.\" Once you understand this, you won't even need to ask that question :). \n    ", "date_posted": "2017-09-21 18:39:06Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "4871483", "name": "rassa45", "reputation_score": "3,406"}, "answer_comments": [{"stack_answer_id": "30442095", "stack_answer_comment_id": "51164282", "comment_content": "+1 because of the distinction between ", "user_id": null}, {"stack_answer_id": "30442095", "stack_answer_comment_id": "57247895", "comment_content": "What you are saying isn't 100% true. That's just a convention. You can still call the static method from an object created. You just won't be able to use any class members because you didn't declare a self. I can even call Animal.objectMethod(animalObj) to call the non static. Basically this means a static method is only a method that doesn't use member variables. There shouldn't be any need to declare self. It's a silly language requirement I think. Languages like Lua and C++ give you obj variables behind the scenes.", "user_id": null}, {"stack_answer_id": "30442095", "stack_answer_comment_id": "79661861", "comment_content": "You made a useless animalName string declaration and crashing animalName method.", "user_id": null}, {"stack_answer_id": "30442095", "stack_answer_comment_id": "79662136", "comment_content": "@ytpillai Irrelevant. Confusing and incorrect code should not be presented as an answer.", "user_id": null}, {"stack_answer_id": "30442095", "stack_answer_comment_id": "79662264", "comment_content": " to not clobber the string you're trying to return, and ", "user_id": null}]}, {"stack_answer_id": "48219699", "answer_content": "\r\n First of all, self is a conventional name, you could put anything else (being coherent) in its stead. \n\n It refers to the object itself, so when you are using it, you are declaring that .name and .age are properties of the Student objects (note, not of the Student class) you are going to create. \n\n class Student:\n    #called each time you create a new Student instance\n    def __init__(self,name,age): #special method to initialize\n        self.name=name\n        self.age=age\n\n    def __str__(self): #special method called for example when you use print\n        return \"Student %s is %s years old\" %(self.name,self.age)\n\n    def call(self, msg): #silly example for custom method\n        return (\"Hey, %s! \"+msg) %self.name\n\n#initializing two instances of the student class\nbob=Student(\"Bob\",20)\nalice=Student(\"Alice\",19)\n\n#using them\nprint bob.name\nprint bob.age\nprint alice #this one only works if you define the __str__ method\nprint alice.call(\"Come here!\") #notice you don't put a value for self\n\n#you can modify attributes, like when alice ages\nalice.age=20\nprint alice\n \n\n Code is here  \n    ", "date_posted": "2018-01-12 04:45:25Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "6464277", "name": "Akash Kandpal", "reputation_score": "2,684"}, "answer_comments": []}, {"stack_answer_id": "2709836", "answer_content": "\r\n self  is an object reference to the object itself, therefore, they are same.\nPython methods are not called in the context of the object itself.\n self  in Python may be used to deal with custom object models or something. \n    ", "date_posted": "2010-04-25 20:26:35Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "303939", "name": "Ming-Tang", "reputation_score": "17.1k"}, "answer_comments": []}, {"stack_answer_id": "18278904", "answer_content": "\r\n It\u2019s there to follow the Python zen \u201cexplicit is better than implicit\u201d. It\u2019s indeed a reference to your class object. In Java and PHP, for example, it's called  this . \n\n If  user_type_name  is a field on your model you access it by  self.user_type_name . \n    ", "date_posted": "2013-12-24 22:24:58Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "707111", "name": "Ry-", "reputation_score": "211k"}, "answer_comments": []}, {"stack_answer_id": "34750920", "answer_content": "\r\n I'm surprised nobody has brought up Lua. Lua also uses the 'self' variable however it can be omitted but still used. C++ does the same with 'this'. I don't see any reason to have to declare 'self' in each function but you should still be able to use it just like you can with lua and C++. For a language that prides itself on being brief it's odd that it requires you to declare the self variable. \n    ", "date_posted": "2016-01-12 18:10:32Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "441521", "name": "user441521", "reputation_score": "6,684"}, "answer_comments": []}, {"stack_answer_id": "51631485", "answer_content": "\r\n The use of the argument, conventionally called  self  isn't as hard to understand, as is why is it necessary? Or as to why explicitly mention it? That, I suppose, is a bigger question for most users who look up this question, or if it is not, they will certainly have the same question as they move forward learning python. I recommend them to read these couple of blogs: \n\n 1: Use of self explained \n\n Note that it is not a keyword. \n\n \n   The first argument of every class method, including init, is always a reference to the current instance of the class. By convention, this argument is always named self. In the init method, self refers to the newly created object; in other class methods, it refers to the instance whose method was called. For example the below code is the same as the above code. \n \n\n 2: Why do we have it this way and why can we not eliminate it as an argument, like Java, and have a keyword instead \n\n Another thing I would like to add is, an optional  self  argument allows me to declare static methods inside a class, by not writing  self . \n\n Code examples: \n\n class MyClass():\n    def staticMethod():\n        print \"This is a static method\"\n\n    def objectMethod(self):\n        print \"This is an object method which needs an instance of a class, and that is what self refers to\"\n \n\n PS :This works only in Python 3.x. \n\n In previous versions, you have to explicitly add  @staticmethod  decorator, otherwise  self  argument is obligatory.  \n    ", "date_posted": "2018-08-12 10:20:06Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "5758889", "name": "Bugs Buggy", "reputation_score": "1,494"}, "answer_comments": []}, {"stack_answer_id": "26943812", "answer_content": "\r\n Take a look at the following example, which clearly explains the purpose of  self \n\n class Restaurant(object):  \n    bankrupt = False\n\n    def open_branch(self):\n        if not self.bankrupt:\n           print(\"branch opened\")\n\n#create instance1\n>>> x = Restaurant()\n>>> x.bankrupt\nFalse\n\n#create instance2\n>>> y = Restaurant()\n>>> y.bankrupt = True   \n>>> y.bankrupt\nTrue\n\n>>> x.bankrupt\nFalse  \n \n\n self  is used/needed to distinguish between instances. \n\n Source:  self variable in python explained - Pythontips \n    ", "date_posted": "2020-05-19 22:05:41Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "2956066", "name": "kmario23", "reputation_score": "52.1k"}, "answer_comments": [{"stack_answer_id": "26943812", "stack_answer_comment_id": "57247643", "comment_content": "Yes, I think we know why self is used, but the question is why does the language make you explicitly declare it. Many other languages don't require this and a language which prides itself on being brief, you'd think they would just give you the variable behind the scenes to use like Lua or C++ (this) does.", "user_id": null}, {"stack_answer_id": "26943812", "stack_answer_comment_id": "86661379", "comment_content": "@kmario23 You're response was from here: ", "user_id": null}]}, {"stack_answer_id": "32243243", "answer_content": "\r\n Is because by the way python is designed the alternatives would hardly work. Python is designed to allow methods or functions to be defined in a context where both implicit  this  (a-la Java/C++) or explicit  @  (a-la ruby) wouldn't work. Let's have an example with the explicit approach with python conventions: \n\n def fubar(x):\n    self.x = x\n\nclass C:\n    frob = fubar\n \n\n Now the  fubar  function wouldn't work since it would assume that  self  is a global variable (and in  frob  as well). The alternative would be to execute method's with a replaced global scope (where  self  is the object). \n\n The implicit approach would be \n\n def fubar(x)\n    myX = x\n\nclass C:\n    frob = fubar\n \n\n This would mean that  myX  would be interpreted as a local variable in  fubar  (and in  frob  as well). The alternative here would be to execute methods with a replaced local scope which is retained between calls, but that would remove the posibility of method local variables. \n\n However the current situation works out well: \n\n  def fubar(self, x)\n     self.x = x\n\n class C:\n     frob = fubar\n \n\n here when called as a method  frob  will receive the object on which it's called via the  self  parameter, and  fubar  can still be called with an object as parameter and work the same (it  is  the same as  C.frob  I think). \n    ", "date_posted": "2015-08-27 07:31:02Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "4498329", "name": "skyking", "reputation_score": "13.3k"}, "answer_comments": []}, {"stack_answer_id": "21367245", "answer_content": "\r\n In the  __init__  method, self refers to the newly created object; in other class methods, it refers to the instance whose method was called. \n\n self, as a name, is  just a convention , call it as you want ! but when using it, for example to delete the object, you have to use the same name:  __del__(var) , where  var  was used in the  __init__(var,[...]) \n\n You should take a look at  cls  too, to have  the bigger picture . This  post  could be helpful. \n    ", "date_posted": "2017-05-23 12:18:30Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}, {"stack_answer_id": "58585068", "answer_content": "\r\n self is acting as like current object name or instance of class . \n\n # Self explanation.\n\n\n class classname(object):\n\n    def __init__(self,name):\n\n        self.name=name\n        # Self is acting as a replacement of object name.\n        #self.name=object1.name\n\n   def display(self):\n      print(\"Name of the person is :\",self.name)\n      print(\"object name:\",object1.name)\n\n\n object1=classname(\"Bucky\")\n object2=classname(\"ford\")\n\n object1.display()\n object2.display()\n\n###### Output \nName of the person is : Bucky\nobject name: Bucky\nName of the person is : ford\nobject name: Bucky\n \n    ", "date_posted": "2019-10-28 02:15:18Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "9724968", "name": "sameer_nubia", "reputation_score": "661"}, "answer_comments": []}, {"stack_answer_id": "63320527", "answer_content": "\r\n \"self\" keyword holds the reference of class and it is upto you if you want to use it or not but if you notice, whenever you create a new method in python, python automatically write self keyword for you. If you do some R&D, you will notice that if you create say two methods in a class and try to call one inside another, it does not recognize method unless you add self (reference of class). \n class testA:\ndef __init__(self):\n    print('ads')\ndef m1(self):\n    print('method 1')\n    self.m2()\ndef m2(self):\n    print('method 2')\n \n Below code throws unresolvable reference error. \n class testA:\ndef __init__(self):\n    print('ads')\ndef m1(self):\n    print('method 1')\n    m2()  #throws unresolvable reference error as class does not know if m2 exist in class scope\ndef m2(self):\n    print('method 2')\n \n Now let see below example \n class testA:\ndef __init__(self):\n    print('ads')\ndef m1(self):\n    print('method 1')\ndef m2():\n    print('method 2')\n \n Now when you create object of class testA, you can call method m1() using class object like this as method m1() has included self keyword \n obj = testA()\nobj.m1()\n \n But if you want to call method m2(), because is has no self reference so you can call m2() directly using class name like below \n testA.m2()\n \n But keep in practice to live with self keyword as there are other benefits too of it like creating global variable inside and so on. \n    ", "date_posted": "2020-08-09 08:33:08Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "4268680", "name": "Rahul Jha", "reputation_score": "726"}, "answer_comments": []}, {"stack_answer_id": "56279547", "answer_content": "\r\n self  is inevitable. \n\n There was just a  question  should  self  be implicit or explicit.\n Guido van Rossum  resolved this question saying  self  has to stay . \n\n So where the  self  live? \n\n If we would just stick to functional programming we would not need  self .\nOnce we enter the  Python OOP  we find  self  there. \n\n Here is the typical use case  class C  with the method  m1 \n\n class C:\n    def m1(self, arg):\n        print(self, ' inside')\n        pass\n\nci =C()\nprint(ci, ' outside')\nci.m1(None)\nprint(hex(id(ci))) # hex memory address\n \n\n \n\n This program will output: \n\n <__main__.C object at 0x000002B9D79C6CC0>  outside\n<__main__.C object at 0x000002B9D79C6CC0>  inside\n0x2b9d79c6cc0\n \n\n So  self  holds the memory address of the class instance.\n The purpose  of  self  would be to hold the reference for  instance methods  and for us to have  explicit  access to that reference.      \n\n \n\n Note there are three different types of class methods:  \n\n \n static methods (read: functions),  \n class methods,  \n instance methods (mentioned). \n \n    ", "date_posted": "2019-05-25 08:53:24Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "5884955", "name": "prosti", "reputation_score": "36.9k"}, "answer_comments": []}, {"stack_answer_id": "67015236", "answer_content": "\r\n The word 'self' refers to instance of a class \n class foo:\n      def __init__(self, num1, num2):\n             self.n1 = num1 #now in this it will make the perimeter num1 and num2 access across the whole class\n             self.n2 = num2\n      def add(self):\n             return self.n1 + self.n2 # if we had not written self then if would throw an error that n1 and n2 is not defined and we have to include self in the function's perimeter to access it's variables\n \n    ", "date_posted": "2021-04-09 04:52:32Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "15394199", "name": "PrabhavDevo", "reputation_score": "1,270"}, "answer_comments": []}, {"stack_answer_id": "2709828", "answer_content": "\r\n it's an explicit reference to the class instance object.  \n    ", "date_posted": "2010-04-25 20:24:57Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "12855", "name": "SilentGhost", "reputation_score": "291k"}, "answer_comments": [{"stack_answer_id": "2709828", "stack_answer_comment_id": "2734185", "comment_content": "I don't think this helps richzilla to understand the reason behind it.", "user_id": null}, {"stack_answer_id": "2709828", "stack_answer_comment_id": "80247629", "comment_content": "@SilentGhost: you have nailed it. I am impressed. if I understand it correctly: I do create an object as an instance of the defined class and the self parameter refers to that object? I understand self refers in implicit way to the class itself but it would be great if you explain your answer a bit more.", "user_id": null}]}, {"stack_answer_id": "60412005", "answer_content": "\r\n from the  docs ,  \n\n \n   the special thing about methods is that the instance object is passed as the first argument of the function. In our example, the call  x.f()  is exactly equivalent to  MyClass.f(x) . In general, calling a method with a list of n arguments is equivalent to calling the corresponding function with an argument list that is created by inserting the method\u2019s instance object before the first argument. \n \n\n preceding this the related snippet, \n\n class MyClass:\n    \"\"\"A simple example class\"\"\"\n    i = 12345\n\n    def f(self):\n        return 'hello world'\n \n\n x = MyClass()\n \n    ", "date_posted": "2020-02-26 10:39:14Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "6903290", "name": "laxman", "reputation_score": "1,342"}, "answer_comments": []}, {"stack_answer_id": "62536337", "answer_content": "\r\n I would say for Python at least, the self parameter can be thought of as a placeholder.\nTake a look at this: \n class Person:\n  def __init__(self, name, age):\n    self.name = name\n    self.age = age\n\np1 = Person(\"John\", 36)\n\nprint(p1.name)\nprint(p1.age)\n \n Self in this case and a lot of others was used as a method to say store the name value. However, after that, we use the p1 to assign it to the class we're using. Then when we print it we use the same p1 keyword. \n Hope this helps for Python! \n    ", "date_posted": "2020-06-23 13:50:57Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "13750055", "name": "Rishi", "reputation_score": "41"}, "answer_comments": []}, {"stack_answer_id": "65461903", "answer_content": "\r\n my little 2 cents \n In this class Person, we defined out  init  method with the self and interesting thing to notice here is the memory location of both the  self  and instance variable  p  is same  <__main__.Person object at 0x106a78fd0> \n class Person:\n\n    def __init__(self, name, age):\n        self.name = name \n        self.age = age \n\n    def say_hi(self):\n        print(\"the self is at:\", self)\n        print((f\"hey there, my name is {self.name} and I am {self.age} years old\"))\n\n    def say_bye(self):\n        print(\"the self is at:\", self)\n        print(f\"good to see you {self.name}\")\n\np = Person(\"john\", 78)\nprint(\"the p is at\",p)\np.say_hi()  \np.say_bye() \n \n so as explained in above, both self and instance variable are same object. \n    ", "date_posted": "2020-12-27 00:13:06Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "9476814", "name": "saran", "reputation_score": "326"}, "answer_comments": []}], "user": {"stack_user_id": "301032", "name": "richzilla", "reputation_score": "38.6k"}, "question_comments": [{"stack_question_id": "2709821", "stack_question_comment_id": "2734198", "comment_content": "You may find interesting this essay \"Why explicit self has to stay\" by Guido van Rossum: ", "user_id": null}, {"stack_question_id": "2709821", "stack_question_comment_id": "2734210", "comment_content": "See also \"Why must 'self' be used explicitly in method definitions and calls\": ", "user_id": null}, {"stack_question_id": "2709821", "stack_question_comment_id": "2752890", "comment_content": "\"Which i understand, quite easily\" ---  Quite subjective, don't you think? What makes ", "user_id": null}, {"stack_question_id": "2709821", "stack_question_comment_id": "2752966", "comment_content": "Although to play devils advocate its very easy to forget to add an additional argument to each method and have bizarre behavior when you forget which makes it hard for beginners. IMHO I rather be specific about unusual things like static methods then normal behavior like instance methods.", "user_id": null}, {"stack_question_id": "2709821", "stack_question_comment_id": "11116129", "comment_content": "That's the key difference between a function and a class method. A function is floating free, unencumbered. A class (instance) method has to be aware of it's parent (and parent properties) so you need to pass the method a reference to the parent class (as ", "user_id": null}]},
{"stack_question_id": "29640685", "question_title": "How do I detect collision in pygame?", "question_content": "\r\n                I have made a list of bullets and a list of sprites using the classes below. How do I detect if a bullet collides with a sprite and then delete that sprite and the bullet?\n\n#Define the sprite class\n...\r\n", "question_url": "/questions/29640685/how-do-i-detect-collision-in-pygame", "date_posted": "Apr 15, 2015 at 2:38", "upvote": "2", "view": "9", "tags": ["python", "pygame", "collision-detection", "pygame-surface", "pygame2"], "answers_count": "5", "answers": [{"stack_answer_id": "65064907", "answer_content": "\r\n In PyGame, collision detection is done using  pygame.Rect  objects. The  Rect  object offers various methods for detecting collisions between objects. Even the collision between a rectangular and circular object such as a paddle and a ball can be detected by a collision between two rectangular objects, the paddle and the bounding rectangle of the ball. \n Some examples: \n \n pygame.Rect.collidepoint : \n \n Test if a point is inside a rectangle \n \n  repl.it/@Rabbid76/PyGame-collidepoint \n \n import pygame\n\npygame.init()\nwindow = pygame.display.set_mode((250, 250))\nrect = pygame.Rect(*window.get_rect().center, 0, 0).inflate(100, 100)\n\nrun = True\nwhile run:\n    for event in pygame.event.get():\n        if event.type == pygame.QUIT:\n            run = False\n\n    point = pygame.mouse.get_pos()\n    collide = rect.collidepoint(point)\n    color = (255, 0, 0) if collide else (255, 255, 255)\n\n    window.fill(0)\n    pygame.draw.rect(window, color, rect)\n    pygame.display.flip()\n\npygame.quit()\nexit()\n \n \n pygame.Rect.colliderect \n \n Test if two rectangles overlap \n \n See also  How to detect collisions between two rectangular objects or images in pygame \n  repl.it/@Rabbid76/PyGame-colliderect \n \n import pygame\n\npygame.init()\nwindow = pygame.display.set_mode((250, 250))\nrect1 = pygame.Rect(*window.get_rect().center, 0, 0).inflate(75, 75)\nrect2 = pygame.Rect(0, 0, 75, 75)\n\nrun = True\nwhile run:\n    for event in pygame.event.get():\n        if event.type == pygame.QUIT:\n            run = False\n\n    rect2.center = pygame.mouse.get_pos()\n    collide = rect1.colliderect(rect2)\n    color = (255, 0, 0) if collide else (255, 255, 255)\n\n    window.fill(0)\n    pygame.draw.rect(window, color, rect1)\n    pygame.draw.rect(window, (0, 255, 0), rect2, 6, 1)\n    pygame.display.flip()\n\npygame.quit()\nexit()\n \n \n \n Furthermore,  pygame.Rect.collidelist  and  pygame.Rect.collidelistall  can be used for the collision test between a rectangle and a list of rectangles.  pygame.Rect.collidedict  and  pygame.Rect.collidedictall  can be used for the collision test between a rectangle and a dictionary of rectangles. \n The collision of  pygame.sprite.Sprite  and  pygame.sprite.Group  objects, can be detected by  pygame.sprite.spritecollide() ,  pygame.sprite.groupcollide()  or  pygame.sprite.spritecollideany() . When using these methods, the collision detection algorithm can be specified by the  collided  argument: \n \n The collided argument is a callback function used to calculate if two sprites are colliding. \n \n Possible  collided  callables are  collide_rect ,  collide_rect_ratio ,  collide_circle ,  collide_circle_ratio ,  collide_mask \n Some examples: \n \n pygame.sprite.spritecollide() \n  repl.it/@Rabbid76/PyGame-spritecollide \n \n import pygame\n\npygame.init()\nwindow = pygame.display.set_mode((250, 250))\n\nsprite1 = pygame.sprite.Sprite()\nsprite1.image = pygame.Surface((75, 75))\nsprite1.image.fill((255, 0, 0))\nsprite1.rect = pygame.Rect(*window.get_rect().center, 0, 0).inflate(75, 75)\nsprite2 = pygame.sprite.Sprite()\nsprite2.image = pygame.Surface((75, 75))\nsprite2.image.fill((0, 255, 0))\nsprite2.rect = pygame.Rect(*window.get_rect().center, 0, 0).inflate(75, 75)\n\nall_group = pygame.sprite.Group([sprite2, sprite1])\ntest_group = pygame.sprite.Group(sprite2)\n\nrun = True\nwhile run:\n    for event in pygame.event.get():\n        if event.type == pygame.QUIT:\n            run = False\n\n    sprite1.rect.center = pygame.mouse.get_pos()\n    collide = pygame.sprite.spritecollide(sprite1, test_group, False)\n\n    window.fill(0)\n    all_group.draw(window)\n    for s in collide:\n        pygame.draw.rect(window, (255, 255, 255), s.rect, 5, 1)\n    pygame.display.flip()\n\npygame.quit()\nexit()\n \n \n \n For a collision with masks, see  How can I make a collision mask?  or  Pygame mask collision \n See also  Collision and Intersection \n \n pygame.sprite.spritecollide()  /  collide_circle \n  repl.it/@Rabbid76/PyGame-spritecollidecollidecircle \n \n import pygame\n\npygame.init()\nwindow = pygame.display.set_mode((250, 250))\n\nsprite1 = pygame.sprite.Sprite()\nsprite1.image = pygame.Surface((80, 80), pygame.SRCALPHA)\npygame.draw.circle(sprite1.image, (255, 0, 0), (40, 40), 40)\nsprite1.rect = pygame.Rect(*window.get_rect().center, 0, 0).inflate(40, 40)\nsprite2 = pygame.sprite.Sprite()\nsprite2.image = pygame.Surface((80, 89), pygame.SRCALPHA)\npygame.draw.circle(sprite2.image, (0, 255, 0), (40, 40), 40)\nsprite2.rect = pygame.Rect(*window.get_rect().center, 0, 0).inflate(80, 80)\n\nall_group = pygame.sprite.Group([sprite2, sprite1])\ntest_group = pygame.sprite.Group(sprite2)\n\nrun = True\nwhile run:\n    for event in pygame.event.get():\n        if event.type == pygame.QUIT:\n            run = False\n\n    sprite1.rect.center = pygame.mouse.get_pos()\n    collide = pygame.sprite.spritecollide(sprite1, test_group, False, pygame.sprite.collide_circle)\n\n    window.fill(0)\n    all_group.draw(window)\n    for s in collide:\n        pygame.draw.circle(window, (255, 255, 255), s.rect.center, s.rect.width // 2, 5)\n    pygame.display.flip()\n\npygame.quit()\nexit()\n \n \n \n \n What does this all mean for your code? \n pygame.Surface.get_rect.get_rect()  returns a rectangle with the size of the  Surface  object, that always starts at (0, 0) since a  Surface  object has no position. The position of the rectangle can be specified by a keyword argument. For example, the centre of the rectangle can be specified with the keyword argument  center . These keyword arguments are applied to the attributes of the  pygame.Rect  before it is returned (see  pygame.Rect  for a list of the keyword arguments). \nSee * Why is my collision test always returning 'true' and why is the position of the rectangle of the image always wrong (0, 0)? \n You do not need the  x  and  y  attributes of  Sprite  and  Bullet  at all. Use the position of the  rect  attribute instead: \n #Define the sprite class\nclass Sprite:\n    def __init__(self, x, y, name):\n        self.image = pygame.image.load(name)\n        self.rect = self.image.get_rect(topleft = (x, y))\n\n    def render(self):\n        window.blit(self.image, self.rect)\n\n# Define the bullet class to create bullets          \nclass Bullet:\n    def __init__(self, x, y):\n        self.bullet = pygame.image.load(\"user_bullet.BMP\")\n        self.rect = self.bullet.get_rect(topleft = (x + 23, y))\n\n    def render(self):\n        window.blit(self.bullet, self.rect)\n \n Use  pygame.Rect.colliderect()  to detect collisions between instances of  Sprite  and  Bullet . \nSee  How to detect collisions between two rectangular objects or images in pygame : \n my_sprite = Sprite(sx, sy, name)\nmy_bullet = Bullet(by, by)\n \n while True:\n    # [...]\n\n    if my_sprite.rect.colliderect(my_bullet.rect):\n        printe(\"hit\")\n \n    ", "date_posted": "2022-06-20 05:17:50Z", "upvote": "\r\n            64\r\n        ", "accepted": "No", "user": {"stack_user_id": "19372340", "name": "Joshua Rose", "reputation_score": "11"}, "answer_comments": []}, {"stack_answer_id": "29641464", "answer_content": "\r\n From what I understand of pygame you just need to check if the two rectangles overlap using the  colliderect  method. One way to do it is to have a method in your  Bullet  class that checks for collisions: \n\n def is_collided_with(self, sprite):\n    return self.rect.colliderect(sprite.rect)\n \n\n Then you can call it like: \n\n sprite = Sprite(10, 10, 'my_sprite')\nbullet = Bullet(20, 10)\nif bullet.is_collided_with(sprite):\n    print('collision!')\n    bullet.kill()\n    sprite.kill()\n \n    ", "date_posted": "2020-01-03 21:48:42Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "1470749", "name": "101", "reputation_score": "8,012"}, "answer_comments": [{"stack_answer_id": "29641464", "stack_answer_comment_id": "47424513", "comment_content": "Note that if the speed of bullet relative to the target is more than target's width per tick, the bullet can just 'teleport' to the other side of the target without hitting. If this might be the case, you might need to check against a rectangle that represents the trajectory of the bullet from the previous frame to the current frame, not just the bullet itself.", "user_id": null}]}, {"stack_answer_id": "40338475", "answer_content": "\r\n There is a very simple method for what you are trying to do using built in methods. \n\n here is an example. \n\n import pygame\nimport sys\n\nclass Sprite(pygame.sprite.Sprite):\n    def __init__(self, pos):\n        pygame.sprite.Sprite.__init__(self)\n        self.image = pygame.Surface([20, 20])\n        self.image.fill((255, 0, 0))\n        self.rect = self.image.get_rect()\n\n        self.rect.center = pos\n\ndef main():\n    pygame.init()\n    clock = pygame.time.Clock()\n    fps = 50\n    bg = [255, 255, 255]\n    size =[200, 200]\n\n\n    screen = pygame.display.set_mode(size)\n\n    player = Sprite([40, 50])\n    player.move = [pygame.K_LEFT, pygame.K_RIGHT, pygame.K_UP, pygame.K_DOWN]\n    player.vx = 5\n    player.vy = 5\n\n\n    wall = Sprite([100, 60])\n\n    wall_group = pygame.sprite.Group()\n    wall_group.add(wall)\n\n    player_group = pygame.sprite.Group()\n    player_group.add(player)\n\n    # I added loop for a better exit from the game\n    loop = 1\n    while loop:\n        for event in pygame.event.get():\n            if event.type == pygame.QUIT:\n                loop = 0\n\n        key = pygame.key.get_pressed()\n\n        for i in range(2):\n            if key[player.move[i]]:\n                player.rect.x += player.vx * [-1, 1][i]\n\n        for i in range(2):\n            if key[player.move[2:4][i]]:\n                player.rect.y += player.vy * [-1, 1][i]\n\n        screen.fill(bg)\n\n        # first parameter takes a single sprite\n        # second parameter takes sprite groups\n        # third parameter is a do kill command if true\n        # all group objects colliding with the first parameter object will be\n        # destroyed. The first parameter could be bullets and the second one\n        # targets although the bullet is not destroyed but can be done with\n        # simple trick bellow\n        hit = pygame.sprite.spritecollide(player, wall_group, True)\n\n        if hit:\n            # if collision is detected call a function in your case destroy\n            # bullet\n            player.image.fill((255, 255, 255))\n\n        player_group.draw(screen)\n        wall_group.draw(screen)\n\n        pygame.display.update()\n        clock.tick(fps)\n\n    pygame.quit()\n    # sys.exit\n\n\nif __name__ == '__main__':\n    main()\n \n    ", "date_posted": "2019-11-01 17:53:22Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "6464947", "name": "PythonProgrammi", "reputation_score": "20.8k"}, "answer_comments": []}, {"stack_answer_id": "56195193", "answer_content": "\r\n Make a group for the bullets, and then add the bullets to the group. \n\n What I would do is this:\nIn the class for the player: \n\n def collideWithBullet(self):\n    if pygame.sprite.spritecollideany(self, 'groupName'):\n        print(\"CollideWithBullet!!\")\n        return True\n \n\n And in the main loop somewhere:   \n\n def run(self):\n    if self.player.collideWithBullet():\n         print(\"Game Over\")\n \n\n Hopefully that works for you!!! \n    ", "date_posted": "2019-05-18 01:15:02Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "11483179", "name": "jaden.joeyak", "reputation_score": "91"}, "answer_comments": []}, {"stack_answer_id": "72277288", "answer_content": "\r\n Inside the Sprite class, try adding a  self.mask  attribute with \n self.mask = pygame.mask.from_surface(self.image) \nand a  collide_mask  function inside of the Sprite class with this code: \n     def collide_mask(self, mask):\n        collided = False\n        mask_outline = mask.outline()\n        self.mask_outline = self.mask.outline()\n        for point in range(len(mask_outline)):\n            mask_outline[point] = list(mask_outline[point])\n            mask_outline[point][0] += bullet.x\n            mask_outline[point][1] += bullet.y\n        for point in range(len(self.mask_outline)):\n            self.mask_outline[point] = list(mask_outline[point])\n            self.mask_outline[point][0] += self.x\n            self.mask_outline[point][1] += self.y\n        for point in mask_outline:\n            for self_mask_point in self.mask_outline:\n                if point = self_mask_point:\n                    collided = True\n        return collided\n \n    ", "date_posted": "2022-05-19 00:54:05Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "5014656", "name": "Soumendra", "reputation_score": "1,347"}, "answer_comments": []}], "user": {"stack_user_id": "4744250", "name": "Mike Schmidt", "reputation_score": "843"}, "question_comments": [{"stack_question_id": "29640685", "stack_question_comment_id": "47451199", "comment_content": "I would notes that there is a Sprite Class in pygame - I am not sure redefining it in your code is a good idea. Besides are they really targets (for want of a better word), as a sprite is simply an object with a graphical representation on screen (and therefore your Bullet is a sprite too).", "user_id": null}]},
{"stack_question_id": "19960077", "question_title": "How to filter Pandas dataframe using 'in' and 'not in' like in SQL", "question_content": "\r\n                How can I achieve the equivalents of SQL's IN and NOT IN?\nI have a list with the required values.\nHere's the scenario:\ndf = pd.DataFrame({'country': ['US', 'UK', 'Germany', 'China']})\n...\r\n", "question_url": "/questions/19960077/how-to-filter-pandas-dataframe-using-in-and-not-in-like-in-sql", "date_posted": "Nov 13, 2013 at 17:11", "upvote": "7", "view": "9", "tags": ["python", "pandas", "dataframe", "sql-function"], "answers_count": "1", "answers": [{"stack_answer_id": "19960116", "answer_content": "\r\n You can use  pd.Series.isin . \n For \"IN\" use:  something.isin(somewhere) \n Or for \"NOT IN\":  ~something.isin(somewhere) \n As a worked example: \n import pandas as pd\n\n>>> df\n  country\n0        US\n1        UK\n2   Germany\n3     China\n>>> countries_to_keep\n['UK', 'China']\n>>> df.country.isin(countries_to_keep)\n0    False\n1     True\n2    False\n3     True\nName: country, dtype: bool\n>>> df[df.country.isin(countries_to_keep)]\n  country\n1        UK\n3     China\n>>> df[~df.country.isin(countries_to_keep)]\n  country\n0        US\n2   Germany\n \n    ", "date_posted": "2020-07-09 19:25:24Z", "upvote": "\r\n            1300\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "12814639", "name": "gpr", "reputation_score": "106"}, "answer_comments": [{"stack_answer_id": "19960116", "stack_answer_comment_id": "29714037", "comment_content": "If you're actually dealing with 1-dimensional arrays (like in you're example) then on you're first line use a Series instead of a DataFrame, like @DSM used: ", "user_id": null}, {"stack_answer_id": "19960116", "stack_answer_comment_id": "29747942", "comment_content": "@TomAugspurger: like usual, I'm probably missing something.  ", "user_id": null}, {"stack_answer_id": "19960116", "stack_answer_comment_id": "87855266", "comment_content": "This answer is confusing because you keep reusing the ", "user_id": null}, {"stack_answer_id": "19960116", "stack_answer_comment_id": "108599103", "comment_content": "@ifly6 : Agreed, I made the same mistake and realized it when I got a error : \"'DataFrame' object has no attribute 'countries'", "user_id": null}, {"stack_answer_id": "19960116", "stack_answer_comment_id": "118083299", "comment_content": "For people who are confused by the tilde (like me): ", "user_id": null}]}, {"stack_answer_id": "45190397", "answer_content": "\r\n Alternative solution that uses  .query()  method: \n In [5]: df.query(\"countries in @countries_to_keep\")\nOut[5]:\n  countries\n1        UK\n3     China\n\nIn [6]: df.query(\"countries not in @countries_to_keep\")\nOut[6]:\n  countries\n0        US\n2   Germany\n \n    ", "date_posted": "2021-09-07 06:46:56Z", "upvote": "\r\n            133\r\n        ", "accepted": "No", "user": {"stack_user_id": "5741205", "name": "MaxU - stop genocide of UA", "reputation_score": "195k"}, "answer_comments": [{"stack_answer_id": "45190397", "stack_answer_comment_id": "112681283", "comment_content": ".query is so much more readable. Especially for the \"not in\" scenario, vs a distant tilde. Thanks!", "user_id": null}, {"stack_answer_id": "45190397", "stack_answer_comment_id": "122096421", "comment_content": "What is @countries ? Another dataframe ? A list ?", "user_id": null}, {"stack_answer_id": "45190397", "stack_answer_comment_id": "122127585", "comment_content": "@FlorianCastelain countries are the column you want to check on, OP called this column", "user_id": null}, {"stack_answer_id": "45190397", "stack_answer_comment_id": "122129378", "comment_content": "@FlorianCastelain, somebody has renamed a variable in the original question: ", "user_id": null}, {"stack_answer_id": "45190397", "stack_answer_comment_id": "124255455", "comment_content": "The most readable solution indeed. I wonder if syntax exists to avoid creating ", "user_id": null}]}, {"stack_answer_id": "55554709", "answer_content": "\r\n \n   How to implement 'in' and 'not in' for a pandas DataFrame? \n \n\n Pandas offers two methods:  Series.isin  and  DataFrame.isin  for Series and DataFrames, respectively. \n\n \n\n Filter DataFrame Based on ONE Column (also applies to Series) \n\n The most common scenario is applying an  isin  condition on a specific column to filter rows in a DataFrame. \n\n df = pd.DataFrame({'countries': ['US', 'UK', 'Germany', np.nan, 'China']})\ndf\n  countries\n0        US\n1        UK\n2   Germany\n3     China\n\nc1 = ['UK', 'China']             # list\nc2 = {'Germany'}                 # set\nc3 = pd.Series(['China', 'US'])  # Series\nc4 = np.array(['US', 'UK'])      # array\n \n\n \n\n Series.isin  accepts various types as inputs. The following are all valid ways of getting what you want: \n\n df['countries'].isin(c1)\n\n0    False\n1     True\n2    False\n3    False\n4     True\nName: countries, dtype: bool\n\n# `in` operation\ndf[df['countries'].isin(c1)]\n\n  countries\n1        UK\n4     China\n\n# `not in` operation\ndf[~df['countries'].isin(c1)]\n\n  countries\n0        US\n2   Germany\n3       NaN\n \n\n \n\n # Filter with `set` (tuples work too)\ndf[df['countries'].isin(c2)]\n\n  countries\n2   Germany\n \n\n \n\n # Filter with another Series\ndf[df['countries'].isin(c3)]\n\n  countries\n0        US\n4     China\n \n\n \n\n # Filter with array\ndf[df['countries'].isin(c4)]\n\n  countries\n0        US\n1        UK\n \n\n \n\n Filter on MANY Columns \n\n Sometimes, you will want to apply an 'in' membership check with some search terms over multiple columns, \n\n df2 = pd.DataFrame({\n    'A': ['x', 'y', 'z', 'q'], 'B': ['w', 'a', np.nan, 'x'], 'C': np.arange(4)})\ndf2\n\n   A    B  C\n0  x    w  0\n1  y    a  1\n2  z  NaN  2\n3  q    x  3\n\nc1 = ['x', 'w', 'p']\n \n\n To apply the  isin  condition to both columns \"A\" and \"B\", use  DataFrame.isin : \n\n df2[['A', 'B']].isin(c1)\n\n      A      B\n0   True   True\n1  False  False\n2  False  False\n3  False   True\n \n\n From this,  to retain rows where at least one column is  True , we can use  any  along the first axis: \n\n df2[['A', 'B']].isin(c1).any(axis=1)\n\n0     True\n1    False\n2    False\n3     True\ndtype: bool\n\ndf2[df2[['A', 'B']].isin(c1).any(axis=1)]\n\n   A  B  C\n0  x  w  0\n3  q  x  3\n \n\n Note that if you want to search every column, you'd just omit the column selection step and do  \n\n df2.isin(c1).any(axis=1)\n \n\n Similarly,  to retain rows where ALL columns are  True , use  all  in the same manner as before. \n\n df2[df2[['A', 'B']].isin(c1).all(axis=1)]\n\n   A  B  C\n0  x  w  0\n \n\n \n\n Notable Mentions:  numpy.isin ,  query , list comprehensions (string data) \n\n In addition to the methods described above, you can also use the numpy equivalent:  numpy.isin . \n\n # `in` operation\ndf[np.isin(df['countries'], c1)]\n\n  countries\n1        UK\n4     China\n\n# `not in` operation\ndf[np.isin(df['countries'], c1, invert=True)]\n\n  countries\n0        US\n2   Germany\n3       NaN\n \n\n Why is it worth considering? NumPy functions are usually a bit faster than their pandas equivalents because of lower overhead. Since this is an elementwise operation that does not depend on index alignment, there are very few situations where this method is not an appropriate replacement for pandas'  isin . \n\n Pandas routines are usually iterative when working with strings, because string operations are hard to vectorise.  There is a lot of evidence to suggest that list comprehensions will be faster here. .\nWe resort to an  in  check now.  \n\n c1_set = set(c1) # Using `in` with `sets` is a constant time operation... \n                 # This doesn't matter for pandas because the implementation differs.\n# `in` operation\ndf[[x in c1_set for x in df['countries']]]\n\n  countries\n1        UK\n4     China\n\n# `not in` operation\ndf[[x not in c1_set for x in df['countries']]]\n\n  countries\n0        US\n2   Germany\n3       NaN\n \n\n It is a lot more unwieldy to specify, however, so don't use it unless you know what you're doing. \n\n Lastly, there's also  DataFrame.query  which has been covered in  this answer . numexpr FTW! \n    ", "date_posted": "2019-06-06 20:48:21Z", "upvote": "\r\n            82\r\n        ", "accepted": "No", "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "answer_comments": [{"stack_answer_id": "55554709", "stack_answer_comment_id": "103289706", "comment_content": "I like it, but what if I want to compare a column in df3 that isin df1 column?  What would that look like?", "user_id": null}]}, {"stack_answer_id": "19960136", "answer_content": "\r\n I've been usually doing generic filtering over rows like this: \n\n criterion = lambda row: row['countries'] not in countries\nnot_in = df[df.apply(criterion, axis=1)]\n \n    ", "date_posted": "2013-11-13 17:14:32Z", "upvote": "\r\n            18\r\n        ", "accepted": "No", "user": {"stack_user_id": "399317", "name": "Kos", "reputation_score": "68.5k"}, "answer_comments": [{"stack_answer_id": "19960136", "stack_answer_comment_id": "29710214", "comment_content": "FYI, this is much slower than @DSM soln which is vectorized", "user_id": null}, {"stack_answer_id": "19960136", "stack_answer_comment_id": "29730160", "comment_content": "@Jeff I'd expect that, but that's what I fall back to when I need to filter over something unavailable in pandas directly. (I was about to say \"like .startwith or regex matching, but just found out about Series.str that has all of that!)", "user_id": null}]}, {"stack_answer_id": "56407969", "answer_content": "\r\n Collating possible solutions from the answers: \n\n For IN:  df[df['A'].isin([3, 6])] \n\n For NOT IN: \n\n \n df[-df[\"A\"].isin([3, 6])] \n df[~df[\"A\"].isin([3, 6])] \n df[df[\"A\"].isin([3, 6]) == False] \n df[np.logical_not(df[\"A\"].isin([3, 6]))] \n \n    ", "date_posted": "2019-06-02 02:47:13Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "answer_comments": [{"stack_answer_id": "56407969", "stack_answer_comment_id": "99414948", "comment_content": "This mostly repeats information from other answers. Using ", "user_id": null}]}, {"stack_answer_id": "45070797", "answer_content": "\r\n I wanted to filter out dfbc rows that had a BUSINESS_ID that was also in the BUSINESS_ID of dfProfilesBusIds \n\n dfbc = dfbc[~dfbc['BUSINESS_ID'].isin(dfProfilesBusIds['BUSINESS_ID'])]\n \n    ", "date_posted": "2019-05-19 03:26:27Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "answer_comments": [{"stack_answer_id": "45070797", "stack_answer_comment_id": "77347669", "comment_content": "You can negate the isin (as done in the accepted answer)  rather than comparing to False", "user_id": null}]}, {"stack_answer_id": "69195120", "answer_content": "\r\n Why is no one talking about the performance of various filtering methods? In fact, this topic often pops up here (see the example). I did my own performance test for a large data set. It is very interesting and instructive. \n df = pd.DataFrame({'animals': np.random.choice(['cat', 'dog', 'mouse', 'birds'], size=10**7), \n                   'number': np.random.randint(0,100, size=(10**7,))})\n\ndf.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 10000000 entries, 0 to 9999999\nData columns (total 2 columns):\n #   Column   Dtype \n---  ------   ----- \n 0   animals  object\n 1   number   int64 \ndtypes: int64(1), object(1)\nmemory usage: 152.6+ MB\n \n %%timeit\n# .isin() by one column\nconditions = ['cat', 'dog']\ndf[df.animals.isin(conditions)]\n \n 367 ms \u00b1 2.34 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n \n %%timeit\n# .query() by one column\nconditions = ['cat', 'dog']\ndf.query('animals in @conditions')\n \n 395 ms \u00b1 3.9 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n \n %%timeit\n# .loc[]\ndf.loc[(df.animals=='cat')|(df.animals=='dog')]\n \n 987 ms \u00b1 5.17 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n \n %%timeit\ndf[df.apply(lambda x: x['animals'] in ['cat', 'dog'], axis=1)]\n \n 41.9 s \u00b1 490 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n \n %%timeit\nnew_df = df.set_index('animals')\nnew_df.loc[['cat', 'dog'], :]\n \n 3.64 s \u00b1 62.5 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n \n %%timeit\nnew_df = df.set_index('animals')\nnew_df[new_df.index.isin(['cat', 'dog'])]\n \n 469 ms \u00b1 8.98 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n \n %%timeit\ns = pd.Series(['cat', 'dog'], name='animals')\ndf.merge(s, on='animals', how='inner')\n \n 796 ms \u00b1 30.9 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n \n Thus, the  isin  method turned out to be the fastest and the method with  apply()  was the slowest, which is not surprising. \n    ", "date_posted": "2021-09-15 14:33:28Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "16591526", "name": "padu", "reputation_score": "294"}, "answer_comments": []}, {"stack_answer_id": "71227998", "answer_content": "\r\n You can also use  .isin()  inside  .query() : \n df.query('country.isin(@countries_to_keep).values')\n\n# Or alternatively:\ndf.query('country.isin([\"UK\", \"China\"]).values')\n \n To negate your query, use  ~ : \n df.query('~country.isin(@countries_to_keep).values')\n \n \n Update: \n Another way is to use comparison operators: \n df.query('country == @countries_to_keep')\n\n# Or alternatively:\ndf.query('country == [\"UK\", \"China\"]')\n \n And to negate the query, use  != : \n df.query('country != @countries_to_keep')\n \n    ", "date_posted": "2022-06-21 18:48:02Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "18145256", "name": "rachwa", "reputation_score": "770"}, "answer_comments": [{"stack_answer_id": "71227998", "stack_answer_comment_id": "126028674", "comment_content": "Good to know, although this is a bit less readable than ", "user_id": "/users/2071807/londonrob"}]}, {"stack_answer_id": "49650285", "answer_content": "\r\n df = pd.DataFrame({'countries':['US','UK','Germany','China']})\ncountries = ['UK','China']\n \n\n implement in :     \n\n df[df.countries.isin(countries)]\n \n\n implement not in  as in of rest countries: \n\n df[df.countries.isin([x for x in np.unique(df.countries) if x not in countries])]\n \n    ", "date_posted": "2018-04-04 11:51:01Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "8563649", "name": "Ioannis Nasios", "reputation_score": "7,996"}, "answer_comments": []}, {"stack_answer_id": "63918237", "answer_content": "\r\n A trick if you want to keep the order of the list: \n df = pd.DataFrame({'country': ['US', 'UK', 'Germany', 'China']})\ncountries_to_keep = ['Germany', 'US']\n\n\nind=[df.index[df['country']==i].tolist() for i in countries_to_keep]\nflat_ind=[item for sublist in ind for item in sublist]\n\ndf.reindex(flat_ind)\n\n   country\n2  Germany\n0       US\n \n    ", "date_posted": "2020-09-16 10:38:18Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "7183444", "name": "Billy Bonaros", "reputation_score": "1,539"}, "answer_comments": []}, {"stack_answer_id": "68108690", "answer_content": "\r\n My 2c worth:\nI needed a combination of in and ifelse statements for a dataframe, and this worked for me. \n sale_method = pd.DataFrame(model_data[\"Sale Method\"].str.upper())\nsale_method[\"sale_classification\"] = np.where(\n    sale_method[\"Sale Method\"].isin([\"PRIVATE\"]),\n    \"private\",\n    np.where(\n        sale_method[\"Sale Method\"].str.contains(\"AUCTION\"), \"auction\", \"other\"\n    ),\n)\n \n    ", "date_posted": "2021-06-24 09:17:55Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "2071807", "name": "LondonRob", "reputation_score": "65.3k"}, "answer_comments": []}], "user": {"stack_user_id": "2071807", "name": "LondonRob", "reputation_score": "65.3k"}, "question_comments": [{"stack_question_id": "19960077", "stack_question_comment_id": "89135565", "comment_content": "Related (performance / pandas internals): ", "user_id": null}, {"stack_question_id": "19960077", "stack_question_comment_id": "115748356", "comment_content": " is similar, but the negation ", "user_id": null}]},
{"stack_question_id": "19913659", "question_title": "Pandas conditional creation of a series/dataframe column", "question_content": "\r\n                How do I add a color column to the following dataframe so that color='green' if Set\u00a0==\u00a0'Z', and color='red' otherwise?\n    Type       Set\n1    A          Z\n2    B          Z           \n3    B          ...\r\n", "question_url": "/questions/19913659/pandas-conditional-creation-of-a-series-dataframe-column", "date_posted": "Nov 11, 2013 at 18:52", "upvote": "4", "view": "7", "tags": ["python", "pandas", "numpy", "dataframe"], "answers_count": "1", "answers": [{"stack_answer_id": "19913845", "answer_content": "\r\n If you only have two choices to select from: \n\n df['color'] = np.where(df['Set']=='Z', 'green', 'red')\n \n\n For example, \n\n import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({'Type':list('ABBC'), 'Set':list('ZZXY')})\ndf['color'] = np.where(df['Set']=='Z', 'green', 'red')\nprint(df)\n \n\n yields \n\n   Set Type  color\n0   Z    A  green\n1   Z    B  green\n2   X    B    red\n3   Y    C    red\n \n\n \n\n If you have more than two conditions then use  np.select . For example, if you want  color  to be  \n\n \n yellow  when  (df['Set'] == 'Z') & (df['Type'] == 'A') \n otherwise  blue  when  (df['Set'] == 'Z') & (df['Type'] == 'B')   \n otherwise  purple  when  (df['Type'] == 'B') \n otherwise  black , \n \n\n then use \n\n df = pd.DataFrame({'Type':list('ABBC'), 'Set':list('ZZXY')})\nconditions = [\n    (df['Set'] == 'Z') & (df['Type'] == 'A'),\n    (df['Set'] == 'Z') & (df['Type'] == 'B'),\n    (df['Type'] == 'B')]\nchoices = ['yellow', 'blue', 'purple']\ndf['color'] = np.select(conditions, choices, default='black')\nprint(df)\n \n\n which yields \n\n   Set Type   color\n0   Z    A  yellow\n1   Z    B    blue\n2   X    B  purple\n3   Y    C   black\n \n    ", "date_posted": "2020-01-09 21:47:51Z", "upvote": "\r\n            965\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "answer_comments": [{"stack_answer_id": "19913845", "stack_answer_comment_id": "118100469", "comment_content": "what is the reason for having to use numpy?", "user_id": null}, {"stack_answer_id": "19913845", "stack_answer_comment_id": "120730869", "comment_content": "It's the library ", "user_id": null}, {"stack_answer_id": "19913845", "stack_answer_comment_id": "125065370", "comment_content": "This code now (January 2022) returns ", "user_id": null}, {"stack_answer_id": "19913845", "stack_answer_comment_id": "128376343", "comment_content": "@Luis , for your case, it's not related to the np.select function, but rather caused by how you assign new Series / DataFrame values.  And the message is simply a warning. Please check this out: ", "user_id": null}]}, {"stack_answer_id": "31173785", "answer_content": "\r\n List comprehension is another way to create another column conditionally. If you are working with object dtypes in columns, like in your example, list comprehensions typically outperform most other methods. \n\n Example list comprehension: \n\n df['color'] = ['red' if x == 'Z' else 'green' for x in df['Set']]\n \n\n %timeit tests: \n\n import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({'Type':list('ABBC'), 'Set':list('ZZXY')})\n%timeit df['color'] = ['red' if x == 'Z' else 'green' for x in df['Set']]\n%timeit df['color'] = np.where(df['Set']=='Z', 'green', 'red')\n%timeit df['color'] = df.Set.map( lambda x: 'red' if x == 'Z' else 'green')\n\n1000 loops, best of 3: 239 \u00b5s per loop\n1000 loops, best of 3: 523 \u00b5s per loop\n1000 loops, best of 3: 263 \u00b5s per loop\n \n    ", "date_posted": "2017-08-16 16:49:28Z", "upvote": "\r\n            167\r\n        ", "accepted": "No", "user": {"stack_user_id": "4561314", "name": "stackoverflowuser2010", "reputation_score": "35.2k"}, "answer_comments": [{"stack_answer_id": "31173785", "stack_answer_comment_id": "74103959", "comment_content": "Note that, with much larger dataframes (think ", "user_id": null}, {"stack_answer_id": "31173785", "stack_answer_comment_id": "94824690", "comment_content": "Can the list comprehension method be used if the condition needs information from multiple columns? I am looking for something like this (this does not work): ", "user_id": null}, {"stack_answer_id": "31173785", "stack_answer_comment_id": "95178560", "comment_content": "Add iterrows to the dataframe, then you can access multiple columns via row:  ['red' if (row['Set'] == 'Z') & (row['Type'] == 'B') else 'green' for index, row in in df.iterrows()]", "user_id": null}, {"stack_answer_id": "31173785", "stack_answer_comment_id": "102364666", "comment_content": "Note this nice solution will not work if you need to take replacement values from another series in the data frame, such as ", "user_id": null}, {"stack_answer_id": "31173785", "stack_answer_comment_id": "106373265", "comment_content": "@cheekybastard Or don't, since ", "user_id": null}]}, {"stack_answer_id": "24074316", "answer_content": "\r\n Another way in which this could be achieved is  \n\n df['color'] = df.Set.map( lambda x: 'red' if x == 'Z' else 'green')\n \n    ", "date_posted": "2014-06-06 04:43:52Z", "upvote": "\r\n            28\r\n        ", "accepted": "No", "user": {"stack_user_id": "678613", "name": "acharuva", "reputation_score": "665"}, "answer_comments": []}, {"stack_answer_id": "42113965", "answer_content": "\r\n The following is slower than the approaches timed  here , but we can compute the extra column based on the contents of more than one column, and more than two values can be computed for the extra column. \n\n Simple example using just the \"Set\" column: \n\n def set_color(row):\n    if row[\"Set\"] == \"Z\":\n        return \"red\"\n    else:\n        return \"green\"\n\ndf = df.assign(color=df.apply(set_color, axis=1))\n\nprint(df)\n \n\n   Set Type  color\n0   Z    A    red\n1   Z    B    red\n2   X    B  green\n3   Y    C  green\n \n\n Example with more colours and more columns taken into account: \n\n def set_color(row):\n    if row[\"Set\"] == \"Z\":\n        return \"red\"\n    elif row[\"Type\"] == \"C\":\n        return \"blue\"\n    else:\n        return \"green\"\n\ndf = df.assign(color=df.apply(set_color, axis=1))\n\nprint(df)\n \n\n   Set Type  color\n0   Z    A    red\n1   Z    B    red\n2   X    B  green\n3   Y    C   blue\n \n\n Edit (21/06/2019): Using plydata \n\n It is also possible to use  plydata  to do this kind of things (this seems even slower than using  assign  and  apply , though). \n\n from plydata import define, if_else\n \n\n Simple  if_else : \n\n df = define(df, color=if_else('Set==\"Z\"', '\"red\"', '\"green\"'))\n\nprint(df)\n \n\n   Set Type  color\n0   Z    A    red\n1   Z    B    red\n2   X    B  green\n3   Y    C  green\n \n\n Nested  if_else : \n\n df = define(df, color=if_else(\n    'Set==\"Z\"',\n    '\"red\"',\n    if_else('Type==\"C\"', '\"green\"', '\"blue\"')))\n\nprint(df)                            \n \n\n   Set Type  color\n0   Z    A    red\n1   Z    B    red\n2   X    B   blue\n3   Y    C  green\n \n    ", "date_posted": "2019-06-21 15:23:50Z", "upvote": "\r\n            26\r\n        ", "accepted": "No", "user": {"stack_user_id": "1878788", "name": "bli", "reputation_score": "6,866"}, "answer_comments": [{"stack_answer_id": "42113965", "stack_answer_comment_id": "115250012", "comment_content": "How do we refer to other rows with this type of function? eg. ", "user_id": null}, {"stack_answer_id": "42113965", "stack_answer_comment_id": "115271309", "comment_content": "@ChrisDixon As far as I know, ", "user_id": null}]}, {"stack_answer_id": "42260631", "answer_content": "\r\n Here's yet another way to skin this cat, using a dictionary to map new values onto the keys in the list: \n\n def map_values(row, values_dict):\n    return values_dict[row]\n\nvalues_dict = {'A': 1, 'B': 2, 'C': 3, 'D': 4}\n\ndf = pd.DataFrame({'INDICATOR': ['A', 'B', 'C', 'D'], 'VALUE': [10, 9, 8, 7]})\n\ndf['NEW_VALUE'] = df['INDICATOR'].apply(map_values, args = (values_dict,))\n \n\n What's it look like: \n\n df\nOut[2]: \n  INDICATOR  VALUE  NEW_VALUE\n0         A     10          1\n1         B      9          2\n2         C      8          3\n3         D      7          4\n \n\n This approach can be very powerful when you have many  ifelse -type statements to make (i.e. many unique values to replace). \n\n And of course you could always do this: \n\n df['NEW_VALUE'] = df['INDICATOR'].map(values_dict)\n \n\n But that approach is more than three times as slow as the  apply  approach from above, on my machine. \n\n And you could also do this, using  dict.get : \n\n df['NEW_VALUE'] = [values_dict.get(v, None) for v in df['INDICATOR']]\n \n    ", "date_posted": "2017-05-16 20:59:07Z", "upvote": "\r\n            25\r\n        ", "accepted": "No", "user": {"stack_user_id": "5015569", "name": "blacksite", "reputation_score": "11.3k"}, "answer_comments": [{"stack_answer_id": "42260631", "stack_answer_comment_id": "88914688", "comment_content": "I like this answer because it shows how to do multiple replacements of values", "user_id": null}, {"stack_answer_id": "42260631", "stack_answer_comment_id": "106373391", "comment_content": " How did you benchmark these? From my quick measurements, the ", "user_id": null}, {"stack_answer_id": "42260631", "stack_answer_comment_id": "106373539", "comment_content": "Update: On 100,000,000 rows, 52 string values, ", "user_id": null}]}, {"stack_answer_id": "55029355", "answer_content": "\r\n You can simply use the powerful  .loc  method and use one condition or several depending on your need (tested with pandas=1.0.5). \n Code Summary: \n df=pd.DataFrame(dict(Type='A B B C'.split(), Set='Z Z X Y'.split()))\ndf['Color'] = \"red\"\ndf.loc[(df['Set']==\"Z\"), 'Color'] = \"green\"\n\n#practice!\ndf.loc[(df['Set']==\"Z\")&(df['Type']==\"B\")|(df['Type']==\"C\"), 'Color'] = \"purple\"\n\n \n Explanation: \n df=pd.DataFrame(dict(Type='A B B C'.split(), Set='Z Z X Y'.split()))\n\n# df so far: \n  Type Set  \n0    A   Z \n1    B   Z \n2    B   X \n3    C   Y\n \n add a 'color' column and set all values to \"red\" \n df['Color'] = \"red\"\n \n Apply your single condition: \n df.loc[(df['Set']==\"Z\"), 'Color'] = \"green\"\n\n\n# df: \n  Type Set  Color\n0    A   Z  green\n1    B   Z  green\n2    B   X    red\n3    C   Y    red\n \n or multiple conditions if you want: \n df.loc[(df['Set']==\"Z\")&(df['Type']==\"B\")|(df['Type']==\"C\"), 'Color'] = \"purple\"\n \n You can read on Pandas logical operators and conditional selection here:\n Logical operators for boolean indexing in Pandas \n    ", "date_posted": "2021-01-31 07:17:13Z", "upvote": "\r\n            23\r\n        ", "accepted": "No", "user": {"stack_user_id": "10951905", "name": "Hossein Kalbasi", "reputation_score": "1,393"}, "answer_comments": []}, {"stack_answer_id": "65760879", "answer_content": "\r\n You can use pandas methods  where  and  mask : \n df['color'] = 'green'\ndf['color'] = df['color'].where(df['Set']=='Z', other='red')\n# Replace values where the condition is False\n \n or \n df['color'] = 'red'\ndf['color'] = df['color'].mask(df['Set']=='Z', other='green')\n# Replace values where the condition is True\n \n Alternatively, you can use the method  transform  with a lambda function: \n df['color'] = df['Set'].transform(lambda x: 'green' if x == 'Z' else 'red')\n \n Output: \n   Type Set  color\n1    A   Z  green\n2    B   Z  green\n3    B   X    red\n4    C   Y    red\n \n Performance comparison from @chai: \n import pandas as pd\nimport numpy as np\ndf = pd.DataFrame({'Type':list('ABBC')*1000000, 'Set':list('ZZXY')*1000000})\n \n%timeit df['color1'] = 'red'; df['color1'].where(df['Set']=='Z','green')\n%timeit df['color2'] = ['red' if x == 'Z' else 'green' for x in df['Set']]\n%timeit df['color3'] = np.where(df['Set']=='Z', 'red', 'green')\n%timeit df['color4'] = df.Set.map(lambda x: 'red' if x == 'Z' else 'green')\n\n397 ms \u00b1 101 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n976 ms \u00b1 241 ms per loop\n673 ms \u00b1 139 ms per loop\n796 ms \u00b1 182 ms per loop\n \n    ", "date_posted": "2021-12-28 14:25:49Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "8973620", "name": "Mykola Zotko", "reputation_score": "12.6k"}, "answer_comments": [{"stack_answer_id": "65760879", "stack_answer_comment_id": "124631526", "comment_content": "It is also faster: import pandas as pd import numpy as np df = pd.DataFrame({'Type':list('ABBC')*1000000, 'Set':list('ZZXY')*1000000}) %timeit df['color1'] = 'red'; df['color1'].where(df['Set']=='Z','green') %timeit df['color2'] = ['red' if x == 'Z' else 'green' for x in df['Set']] %timeit df['color3'] = np.where(df['Set']=='Z', 'red', 'green') %timeit df['color4'] = df.Set.map( lambda x: 'red' if x == 'Z' else 'green') 397 ms \u00b1 101 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each) 976 ms \u00b1 241 ms per loop  673 ms \u00b1 139 ms per loop  796 ms \u00b1 182 ms per loop", "user_id": null}, {"stack_answer_id": "65760879", "stack_answer_comment_id": "124637064", "comment_content": "@chai added your evaluation to my answer. Thank you!", "user_id": null}]}, {"stack_answer_id": "68221846", "answer_content": "\r\n if you have only  2 choices , use  np.where() \n df = pd.DataFrame({'A':range(3)})\ndf['B'] = np.where(df.A>2, 'yes', 'no')\n \n if you have over  2 choices , maybe  apply()  could work\ninput \n arr = pd.DataFrame({'A':list('abc'), 'B':range(3), 'C':range(3,6), 'D':range(6, 9)})\n \n and arr is \n     A   B   C   D\n0   a   0   3   6\n1   b   1   4   7\n2   c   2   5   8\n \n if you want the column E tobe  if arr.A =='a' then arr.B elif arr.A=='b' then arr.C elif arr.A == 'c' then arr.D else something_else \n arr['E'] = arr.apply(lambda x: x['B'] if x['A']=='a' else(x['C'] if x['A']=='b' else(x['D'] if x['A']=='c' else 1234)), axis=1)\n \n and finally the arr is \n     A   B   C   D   E\n0   a   0   3   6   0\n1   b   1   4   7   4\n2   c   2   5   8   8\n \n    ", "date_posted": "2021-07-02 08:17:27Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "4821909", "name": "xiaotong xu", "reputation_score": "131"}, "answer_comments": []}, {"stack_answer_id": "58325311", "answer_content": "\r\n One liner with  .apply()  method is following: \n\n df['color'] = df['Set'].apply(lambda set_: 'green' if set_=='Z' else 'red')\n \n\n After that,  df  data frame looks like this: \n\n >>> print(df)\n  Type Set  color\n0    A   Z  green\n1    B   Z  green\n2    B   X    red\n3    C   Y    red\n \n    ", "date_posted": "2019-10-10 14:30:03Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "7122272", "name": "Jaroslav Bezd\u011bk", "reputation_score": "5,139"}, "answer_comments": []}, {"stack_answer_id": "59238705", "answer_content": "\r\n If you're working with massive data, a memoized approach would be best: \n\n # First create a dictionary of manually stored values\ncolor_dict = {'Z':'red'}\n\n# Second, build a dictionary of \"other\" values\ncolor_dict_other = {x:'green' for x in df['Set'].unique() if x not in color_dict.keys()}\n\n# Next, merge the two\ncolor_dict.update(color_dict_other)\n\n# Finally, map it to your column\ndf['color'] = df['Set'].map(color_dict)\n \n\n This approach will be fastest when you have many repeated values.  My general rule of thumb is to memoize when:  data_size  >  10**4  &  n_distinct  <  data_size/4   \n\n E.x. Memoize in a case 10,000 rows with 2,500 or fewer distinct values. \n    ", "date_posted": "2019-12-08 18:42:01Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "10521959", "name": "Yaakov Bressler", "reputation_score": "7,312"}, "answer_comments": [{"stack_answer_id": "59238705", "stack_answer_comment_id": "106373684", "comment_content": "Alright, so with only 2 distinct values to map, 100,000,000 rows, it takes 6.67 seconds to run without \"memoization\", and 9.86 seconds with.", "user_id": null}, {"stack_answer_id": "59238705", "stack_answer_comment_id": "106373894", "comment_content": "100,000,000 rows, 52 distinct values, where 1 of those maps to the first output value, and the other 51 all correspond to the other: 7.99 seconds without memoization, 11.1 seconds with.", "user_id": null}, {"stack_answer_id": "59238705", "stack_answer_comment_id": "106374783", "comment_content": "Are your values in random order? Or are they back to back? High speed of pandas could be due to caching @AMC", "user_id": null}, {"stack_answer_id": "59238705", "stack_answer_comment_id": "106404740", "comment_content": " Values are random, selected using ", "user_id": null}]}, {"stack_answer_id": "69613519", "answer_content": "\r\n The  case_when  function from  pyjanitor  is a wrapper around  pd.Series.mask  and offers a chainable/convenient form for multiple conditions: \n For a single condition: \n df.case_when(\n    df.col1 == \"Z\",  # condition\n    \"green\",         # value if True\n    \"red\",           # value if False\n    column_name = \"color\"\n    )\n\n  Type Set  color\n1    A   Z  green\n2    B   Z  green\n3    B   X    red\n4    C   Y    red\n \n For multiple conditions: \n df.case_when(\n    df.Set.eq('Z') & df.Type.eq('A'), 'yellow', # condition, result\n    df.Set.eq('Z') & df.Type.eq('B'), 'blue',   # condition, result\n    df.Type.eq('B'), 'purple',                  # condition, result\n    'black',              # default if none of the conditions evaluate to True\n    column_name = 'color'  \n)\n  Type  Set   color\n1    A   Z  yellow\n2    B   Z    blue\n3    B   X  purple\n4    C   Y   black\n \n More examples can be found  here \n    ", "date_posted": "2021-10-18 09:11:47Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "7175713", "name": "sammywemmy", "reputation_score": "23.6k"}, "answer_comments": []}, {"stack_answer_id": "71358186", "answer_content": "\r\n A Less verbose approach using  np.select : \n a = np.array([['A','Z'],['B','Z'],['B','X'],['C','Y']])\ndf = pd.DataFrame(a,columns=['Type','Set'])\n\nconditions = [\n    df['Set'] == 'Z'\n]\n\noutputs = [\n    'Green'\n    ]\n             # conditions Z is Green, Red Otherwise.\nres = np.select(conditions, outputs, 'Red')\nres \narray(['Green', 'Green', 'Red', 'Red'], dtype='<U5')\ndf.insert(2, 'new_column',res)    \n\ndf\n    Type    Set new_column\n0   A   Z   Green\n1   B   Z   Green\n2   B   X   Red\n3   C   Y   Red\n\ndf.to_numpy()    \n    \narray([['A', 'Z', 'Green'],\n       ['B', 'Z', 'Green'],\n       ['B', 'X', 'Red'],\n       ['C', 'Y', 'Red']], dtype=object)\n\n%%timeit conditions = [df['Set'] == 'Z'] \noutputs = ['Green'] \nnp.select(conditions, outputs, 'Red')\n\n134 \u00b5s \u00b1 9.71 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\n\ndf2 = pd.DataFrame({'Type':list('ABBC')*1000000, 'Set':list('ZZXY')*1000000})\n%%timeit conditions = [df2['Set'] == 'Z'] \noutputs = ['Green'] \nnp.select(conditions, outputs, 'Red')\n\n188 ms \u00b1 26.5 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n \n    ", "date_posted": "2022-03-04 23:16:57Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "9550633", "name": "rubengavidia0x", "reputation_score": "361"}, "answer_comments": []}], "user": {"stack_user_id": "213216", "name": "user7289", "reputation_score": "30.1k"}, "question_comments": []},
{"stack_question_id": "1894269", "question_title": "How to convert string representation of list to a list", "question_content": "\r\n                I was wondering what the simplest way is to convert a string representation of a list like the following to a list:\nx = '[ \"A\",\"B\",\"C\" , \" D\"]'\n\nEven in cases ...\r\n", "question_url": "/questions/1894269/how-to-convert-string-representation-of-list-to-a-list", "date_posted": "Dec 12, 2009 at 18:19", "upvote": "7", "view": "5", "tags": ["python", "string"], "answers_count": "1", "answers": [{"stack_answer_id": "1894296", "answer_content": "\r\n >>> import ast\n>>> x = '[ \"A\",\"B\",\"C\" , \" D\"]'\n>>> x = ast.literal_eval(x)\n>>> x\n['A', 'B', 'C', ' D']\n>>> x = [n.strip() for n in x]\n>>> x\n['A', 'B', 'C', 'D']\n \n ast.literal_eval : \n \n With  ast.literal_eval  you can safely evaluate an expression node or a string containing a Python literal or container display. The string or node provided may only consist of the following Python literal structures: strings, bytes, numbers, tuples, lists, dicts, booleans, and  None . \n \n    ", "date_posted": "2020-10-30 08:58:25Z", "upvote": "\r\n            1075\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": [{"stack_answer_id": "1894296", "stack_answer_comment_id": "81694867", "comment_content": "Per comment below, this is dangerous as it simply runs whatever python is in the string.  So if someone puts a call to delete everything in there, it happily will.", "user_id": null}, {"stack_answer_id": "1894296", "stack_answer_comment_id": "85749309", "comment_content": "@PaulKenjora: You're thinking of ", "user_id": null}, {"stack_answer_id": "1894296", "stack_answer_comment_id": "86141783", "comment_content": " is ", "user_id": null}, {"stack_answer_id": "1894296", "stack_answer_comment_id": "110342556", "comment_content": "@sqp_125, then it's a regular list, and you don't need to parse anything?", "user_id": null}, {"stack_answer_id": "1894296", "stack_answer_comment_id": "124170297", "comment_content": "The documentation states (in 2021):  \"This can be used for safely evaluating strings containing Python values from untrusted sources without the need to parse the values oneself. It is not capable of evaluating arbitrarily complex expressions, for example involving operators or indexing.\"", "user_id": null}]}, {"stack_answer_id": "35461204", "answer_content": "\r\n The  json  module is a better solution whenever there is a  stringified  list of dictionaries. The  json.loads(your_data)  function can be used to convert it to a list. \n >>> import json\n>>> x = '[ \"A\",\"B\",\"C\" , \" D\"]'\n>>> json.loads(x)\n['A', 'B', 'C', ' D']\n \n Similarly \n >>> x = '[ \"A\",\"B\",\"C\" , {\"D\":\"E\"}]'\n>>> json.loads(x)\n['A', 'B', 'C', {'D': 'E'}]\n \n    ", "date_posted": "2020-10-30 09:02:00Z", "upvote": "\r\n            205\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": [{"stack_answer_id": "35461204", "stack_answer_comment_id": "81694901", "comment_content": "This works for ints but not for strings in my case because each string is single quoted not double quoted, sigh.", "user_id": null}, {"stack_answer_id": "35461204", "stack_answer_comment_id": "99897185", "comment_content": "As per @PaulKenjora's comment, it works for ", "user_id": null}, {"stack_answer_id": "35461204", "stack_answer_comment_id": "115322875", "comment_content": "In my case I had to replace single quotes with double quotes in initial string to ensure it works ", "user_id": null}, {"stack_answer_id": "35461204", "stack_answer_comment_id": "124307845", "comment_content": "If user should only enter list of numeric, I think this is the safest way to go to stop malicious intend user.", "user_id": null}, {"stack_answer_id": "35461204", "stack_answer_comment_id": "129474567", "comment_content": "The ", "user_id": null}]}, {"stack_answer_id": "1894293", "answer_content": "\r\n The  eval  is dangerous - you shouldn't execute user input. \n\n If you have 2.6 or newer, use ast instead of eval: \n\n >>> import ast\n>>> ast.literal_eval('[\"A\",\"B\" ,\"C\" ,\" D\"]')\n[\"A\", \"B\", \"C\", \" D\"]\n \n\n Once you have that,  strip  the strings. \n\n If you're on an older version of Python, you can get very close to what you want with a simple regular expression: \n\n >>> x='[  \"A\",  \" B\", \"C\",\"D \"]'\n>>> re.findall(r'\"\\s*([^\"]*?)\\s*\"', x)\n['A', 'B', 'C', 'D']\n \n\n This isn't as good as the ast solution, for example it doesn't correctly handle escaped quotes in strings. But it's simple, doesn't involve a dangerous eval, and might be good enough for your purpose if you're on an older Python without ast. \n    ", "date_posted": "2009-12-12 20:21:43Z", "upvote": "\r\n            107\r\n        ", "accepted": "No", "user": {"stack_user_id": "61974", "name": "Mark Byers", "reputation_score": "777k"}, "answer_comments": [{"stack_answer_id": "1894293", "stack_answer_comment_id": "77239301", "comment_content": "Could you please tell me what why did you say \u201cThe ", "user_id": null}, {"stack_answer_id": "1894293", "stack_answer_comment_id": "79669145", "comment_content": "@AaryanDewan if you use ", "user_id": null}]}, {"stack_answer_id": "1894283", "answer_content": "\r\n There is a quick solution: \n\n x = eval('[ \"A\",\"B\",\"C\" , \" D\"]')\n \n\n Unwanted whitespaces in the list elements may be removed in this way: \n\n x = [x.strip() for x in eval('[ \"A\",\"B\",\"C\" , \" D\"]')]\n \n    ", "date_posted": "2009-12-12 18:24:11Z", "upvote": "\r\n            28\r\n        ", "accepted": "No", "user": {"stack_user_id": "213682", "name": "Alexei Sholik", "reputation_score": "7,063"}, "answer_comments": [{"stack_answer_id": "1894283", "stack_answer_comment_id": "1795912", "comment_content": "this would still preserve the spaces inside the quotes", "user_id": null}, {"stack_answer_id": "1894283", "stack_answer_comment_id": "1795920", "comment_content": "This is an open invitation to arbitrary code execution, NEVER do this or anything like it unless you know with absolute certainty that the input will always be 100% trusted.", "user_id": null}, {"stack_answer_id": "1894283", "stack_answer_comment_id": "59555410", "comment_content": "I could use this suggestion because I knew my data was always gonna be in that format and was a data processing work.", "user_id": null}]}, {"stack_answer_id": "55931430", "answer_content": "\r\n Inspired from some of the answers above that work with base python packages I compared the performance of a few (using Python 3.7.3): \n\n Method 1: ast \n\n import ast\nlist(map(str.strip, ast.literal_eval(u'[ \"A\",\"B\",\"C\" , \" D\"]')))\n# ['A', 'B', 'C', 'D']\n\nimport timeit\ntimeit.timeit(stmt=\"list(map(str.strip, ast.literal_eval(u'[ \\\"A\\\",\\\"B\\\",\\\"C\\\" , \\\" D\\\"]')))\", setup='import ast', number=100000)\n# 1.292875313000195\n \n\n Method 2: json \n\n import json\nlist(map(str.strip, json.loads(u'[ \"A\",\"B\",\"C\" , \" D\"]')))\n# ['A', 'B', 'C', 'D']\n\nimport timeit\ntimeit.timeit(stmt=\"list(map(str.strip, json.loads(u'[ \\\"A\\\",\\\"B\\\",\\\"C\\\" , \\\" D\\\"]')))\", setup='import json', number=100000)\n# 0.27833264000014424\n \n\n Method 3: no import \n\n list(map(str.strip, u'[ \"A\",\"B\",\"C\" , \" D\"]'.strip('][').replace('\"', '').split(',')))\n# ['A', 'B', 'C', 'D']\n\nimport timeit\ntimeit.timeit(stmt=\"list(map(str.strip, u'[ \\\"A\\\",\\\"B\\\",\\\"C\\\" , \\\" D\\\"]'.strip('][').replace('\\\"', '').split(',')))\", number=100000)\n# 0.12935059100027502\n \n\n I was disappointed to see what I considered the method with the worst readability was the method with the best performance... there are tradeoffs to consider when going with the most readable option... for the type of workloads I use python for I usually value readability over a slightly more performant option, but as usual it depends. \n    ", "date_posted": "2019-05-01 03:54:25Z", "upvote": "\r\n            24\r\n        ", "accepted": "No", "user": {"stack_user_id": "4277990", "name": "kinzleb", "reputation_score": "955"}, "answer_comments": [{"stack_answer_id": "55931430", "stack_answer_comment_id": "114797691", "comment_content": "is there any particular reason for there being a ", "user_id": null}, {"stack_answer_id": "55931430", "stack_answer_comment_id": "129474506", "comment_content": "The manual method is simply not as powerful, and does less work, so it's not surprising that it's faster. It will not handle escape sequences in the strings, or a different quote type. (The JSON method demands double-quotes, but does process escape sequences.) It also will only process a flat list of strings; the other approaches can handle complex nested data structures.", "user_id": null}]}, {"stack_answer_id": "1894292", "answer_content": "\r\n import ast\nl = ast.literal_eval('[ \"A\",\"B\",\"C\" , \" D\"]')\nl = [i.strip() for i in l]\n \n    ", "date_posted": "2009-12-12 18:29:02Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "403939", "name": "tosh", "reputation_score": "5,554"}, "answer_comments": []}, {"stack_answer_id": "52058605", "answer_content": "\r\n If it's only a one dimensional list, this can be done without importing anything: \n\n >>> x = u'[ \"A\",\"B\",\"C\" , \" D\"]'\n>>> ls = x.strip('[]').replace('\"', '').replace(' ', '').split(',')\n>>> ls\n['A', 'B', 'C', 'D']\n \n    ", "date_posted": "2020-03-19 15:58:33Z", "upvote": "\r\n            15\r\n        ", "accepted": "No", "user": {"stack_user_id": "9835872", "name": "ruohola", "reputation_score": "19.8k"}, "answer_comments": [{"stack_answer_id": "52058605", "stack_answer_comment_id": "92199807", "comment_content": "Cautionary note: this could potentially be dangerous if any of the strings inside list has a comma in between.", "user_id": null}, {"stack_answer_id": "52058605", "stack_answer_comment_id": "107501629", "comment_content": "This will not work if your string list is a list of lists", "user_id": null}]}, {"stack_answer_id": "70891720", "answer_content": "\r\n This u can do, \n ** \n x = '[ \"A\",\"B\",\"C\" , \" D\"]'\nprint(list(eval(x)))\n \n **\nbest one is the accepted answer \n Though this is not a safe way, the best answer is the accepted one.\nwasn't aware of the eval danger when answer was posted. \n    ", "date_posted": "2022-03-02 07:45:56Z", "upvote": "\r\n            10\r\n        ", "accepted": "No", "user": {"stack_user_id": "11863894", "name": "Tomato Master", "reputation_score": "416"}, "answer_comments": [{"stack_answer_id": "70891720", "stack_answer_comment_id": "125495153", "comment_content": "eval is not recommended in several places on this thread as it will simple run as code whatever is entered, presenting a security risk. it is also a duplicate answer.", "user_id": null}]}, {"stack_answer_id": "1894876", "answer_content": "\r\n Assuming that all your inputs are lists and that the double quotes in the input actually don't matter, this can be done with a simple regexp replace.  It is a bit perl-y but works like a charm.  Note also that the output is now a list of unicode strings, you didn't specify that you needed that, but it seems to make sense given unicode input. \n\n import re\nx = u'[ \"A\",\"B\",\"C\" , \" D\"]'\njunkers = re.compile('[[\" \\]]')\nresult = junkers.sub('', x).split(',')\nprint result\n--->  [u'A', u'B', u'C', u'D']\n \n\n The junkers variable contains a compiled regexp (for speed) of all characters we don't want, using ] as a character required some backslash trickery.\nThe re.sub replaces all these characters with nothing, and we split the resulting string at the commas.    \n\n Note that this also removes spaces from inside entries u'[\"oh no\"]' ---> [u'ohno'].  If this is not what you wanted, the regexp needs to be souped up a bit.   \n    ", "date_posted": "2009-12-12 22:18:37Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "230446", "name": "dirkjot", "reputation_score": "3,089"}, "answer_comments": []}, {"stack_answer_id": "68293376", "answer_content": "\r\n No need to import anything and no need evaluate. You can do this in one line for most basic use cases, including the one given in original question. \n One liner \n l_x = [i.strip() for i in x[1:-1].replace('\"',\"\").split(',')]\n \n Explanation \n x = '[ \"A\",\"B\",\"C\" , \" D\"]'\n# str indexing to eliminate the brackets\n# replace as split will otherwise retain the quotes in returned list\n# split to conv to list\nl_x = x[1:-1].replace('\"',\"\").split(',')\n \n Outputs : \n for i in range(0, len(l_x)):\n    print(l_x[i])\n# vvvv output vvvvv\n'''\n A\nB\nC \n  D\n'''\nprint(type(l_x)) # out: class 'list'\nprint(len(l_x)) # out: 4\n \n You can parse and clean up this list as needed using list comprehension. \n l_x = [i.strip() for i in l_x] # list comprehension to clean up\nfor i in range(0, len(l_x)):\n    print(l_x[i])\n# vvvvv output vvvvv\n'''\nA\nB\nC\nD\n'''\n \n Nested lists \n If you have nested lists, it does get a bit more annoying. Without using regex (which would simplify the replace), and assuming you want to return a flattened list (and the  zen of python says flat is better than nested ): \n x = '[ \"A\",\"B\",\"C\" , \" D\", [\"E\",\"F\",\"G\"]]'\nl_x = x[1:-1].split(',')\nl_x = [i\n    .replace(']', '')\n    .replace('[', '')\n    .replace('\"', '')\n    .strip() for i in l_x\n]\n# returns ['A', 'B', 'C', 'D', 'E', 'F', 'G']\n \n If you need to retain the nested list it gets a bit uglier, but can still be done just with re and list comprehension: \n import re\nx = '[ \"A\",\"B\",\"C\" , \" D\", \"[\"E\",\"F\",\"G\"]\",\"Z\", \"Y\", \"[\"H\",\"I\",\"J\"]\", \"K\", \"L\"]'\n# clean it up so regex is simpler\nx = x.replace('\"', '').replace(' ', '') \n# look ahead for the bracketed text that signifies nested list\nl_x = re.split(r',(?=\\[[A-Za-z0-9\\',]+\\])|(?<=\\]),', x[1:-1])\nprint(l_x)\n# flatten and split the non nested list items\nl_x0 = [item for items in l_x for item in items.split(',') if not '[' in items]\n# convert the nested lists to lists\nl_x1 = [\n    i[1:-1].split(',') for i in l_x if '[' in i \n]\n# add the two lists \nl_x = l_x0 + l_x1\n \n This last solution will work on any list stored as a string, nested or not. \n    ", "date_posted": "2021-07-07 22:07:51Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "12642339", "name": "born_naked", "reputation_score": "634"}, "answer_comments": [{"stack_answer_id": "68293376", "stack_answer_comment_id": "128067504", "comment_content": "Notice the method doesn't play well with empty lists. You take ", "user_id": null}]}, {"stack_answer_id": "1894785", "answer_content": "\r\n If you know that your lists only contain quoted strings, this pyparsing example will give you your list of stripped strings (even preserving the original Unicode-ness). \n >>> from pyparsing import *\n>>> x =u'[ \"A\",\"B\",\"C\" , \" D\"]'\n>>> LBR,RBR = map(Suppress,\"[]\")\n>>> qs = quotedString.setParseAction(removeQuotes, lambda t: t[0].strip())\n>>> qsList = LBR + delimitedList(qs) + RBR\n>>> print qsList.parseString(x).asList()\n[u'A', u'B', u'C', u'D']\n \n If your lists can have more datatypes, or even contain lists within lists, then you will need a more complete grammar - like  this one  in the pyparsing examples directory, which will handle tuples, lists, ints, floats, and quoted strings. \n    ", "date_posted": "2022-05-28 14:28:20Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "165216", "name": "PaulMcG", "reputation_score": "60.3k"}, "answer_comments": []}, {"stack_answer_id": "62050605", "answer_content": "\r\n You may run into such problem while dealing with scraped data stored as Pandas DataFrame. \n\n This solution works like charm if the  list of values is present as text .  \n\n def textToList(hashtags):\n    return hashtags.strip('[]').replace('\\'', '').replace(' ', '').split(',')\n\nhashtags = \"[ 'A','B','C' , ' D']\"\nhashtags = textToList(hashtags)\n\nOutput: ['A', 'B', 'C', 'D']\n \n\n \n   No external library required. \n \n    ", "date_posted": "2020-05-27 18:44:33Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "3888829", "name": "dobydx", "reputation_score": "57"}, "answer_comments": []}, {"stack_answer_id": "50063947", "answer_content": "\r\n To further complete @Ryan 's answer using json, one very convenient function to convert unicode is the one posted here:  https://stackoverflow.com/a/13105359/7599285 \n\n ex with double or single quotes: \n\n >print byteify(json.loads(u'[ \"A\",\"B\",\"C\" , \" D\"]')\n>print byteify(json.loads(u\"[ 'A','B','C' , ' D']\".replace('\\'','\"')))\n['A', 'B', 'C', ' D']\n['A', 'B', 'C', ' D']\n \n    ", "date_posted": "2018-04-27 13:56:02Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "7599285", "name": "CptHwK", "reputation_score": "105"}, "answer_comments": [{"stack_answer_id": "50063947", "stack_answer_comment_id": "129474559", "comment_content": "The only new information here is a further processing step that is ", "user_id": null}]}, {"stack_answer_id": "66908306", "answer_content": "\r\n This usually happens when you load list stored as string to CSV \n If you have your list stored in CSV in form like OP asked: \n x = '[ \"A\",\"B\",\"C\" , \" D\"]'\n \n Here is how you can load it back to list: \n import csv\nwith open('YourCSVFile.csv') as csv_file:\n    reader = csv.reader(csv_file, delimiter=',')\n    rows = list(reader)\n\nlistItems = rows[0]\n \n listItems  is now list \n    ", "date_posted": "2021-04-02 14:58:20Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "2119941", "name": "Hrvoje", "reputation_score": "11.1k"}, "answer_comments": [{"stack_answer_id": "66908306", "stack_answer_comment_id": "118291288", "comment_content": "Not sure how this is related to the question... ", "user_id": null}, {"stack_answer_id": "66908306", "stack_answer_comment_id": "118292398", "comment_content": "@Tomerikoo string representation of list is exactly the same only it's in the file.", "user_id": null}, {"stack_answer_id": "66908306", "stack_answer_comment_id": "118292450", "comment_content": "No. A string representation of a list is ", "user_id": null}, {"stack_answer_id": "66908306", "stack_answer_comment_id": "118292698", "comment_content": "@Tomerikoo how about you store list in file and than use any method here to restore it.", "user_id": null}, {"stack_answer_id": "66908306", "stack_answer_comment_id": "118292778", "comment_content": "Ok, let's say the csv has literally ", "user_id": null}]}, {"stack_answer_id": "50640336", "answer_content": "\r\n I would like to provide a more intuitive patterning solution with regex. \nThe below function takes as input a stringified list containing arbitrary strings.  \n\n Stepwise explanation: \nYou remove all whitespacing,bracketing and value_separators (provided they are not part of the values you want to extract, else make the regex more complex). Then you split the cleaned string on single or double quotes and take the non-empty values (or odd indexed values, whatever the preference).  \n\n def parse_strlist(sl):\nimport re\nclean = re.sub(\"[\\[\\],\\s]\",\"\",sl)\nsplitted = re.split(\"[\\'\\\"]\",clean)\nvalues_only = [s for s in splitted if s != '']\nreturn values_only\n \n\n testsample : \"['21',\"foo\" '6', '0', \" A\"]\" \n    ", "date_posted": "2018-06-01 09:32:00Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "7141994", "name": "Jordy Van Landeghem", "reputation_score": "19"}, "answer_comments": []}, {"stack_answer_id": "54101165", "answer_content": "\r\n you can save yourself the .strip() fcn by just slicing off the first and last characters from the string representation of the list (see third line below) \n\n >>> mylist=[1,2,3,4,5,'baloney','alfalfa']\n>>> strlist=str(mylist)\n['1', ' 2', ' 3', ' 4', ' 5', \" 'baloney'\", \" 'alfalfa'\"]\n>>> mylistfromstring=(strlist[1:-1].split(', '))\n>>> mylistfromstring[3]\n'4'\n>>> for entry in mylistfromstring:\n...     print(entry)\n...     type(entry)\n... \n1\n<class 'str'>\n2\n<class 'str'>\n3\n<class 'str'>\n4\n<class 'str'>\n5\n<class 'str'>\n'baloney'\n<class 'str'>\n'alfalfa'\n<class 'str'>\n \n    ", "date_posted": "2019-01-08 23:24:24Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "6470375", "name": "JCMontalbano", "reputation_score": "69"}, "answer_comments": []}, {"stack_answer_id": "57186365", "answer_content": "\r\n and with pure python - not importing any libraries \n\n [x for x in  x.split('[')[1].split(']')[0].split('\"')[1:-1] if x not in[',',' , ',', ']]\n \n    ", "date_posted": "2019-07-26 08:40:47Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "8563649", "name": "Ioannis Nasios", "reputation_score": "7,996"}, "answer_comments": []}, {"stack_answer_id": "69755095", "answer_content": "\r\n This solution is simpler than some I read above but requires to match all features of the list \n x = '[ \"A\",\"B\",\"C\" , \" D\"]'\n[i.strip() for i in x.split('\"') if len(i.strip().strip(',').strip(']').strip('['))>0]\n \n \n \n ['A', 'B', 'C', 'D'] \n \n \n    ", "date_posted": "2021-10-28 13:35:18Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "11955928", "name": "CassAndr", "reputation_score": "13"}, "answer_comments": []}, {"stack_answer_id": "51705980", "answer_content": "\r\n So, following all the answers I decided to time the most common methods: \n\n from time import time\nimport re\nimport json\n\n\nmy_str = str(list(range(19)))\nprint(my_str)\n\nreps = 100000\n\nstart = time()\nfor i in range(0, reps):\n    re.findall(\"\\w+\", my_str)\nprint(\"Regex method:\\t\", (time() - start) / reps)\n\nstart = time()\nfor i in range(0, reps):\n    json.loads(my_str)\nprint(\"json method:\\t\", (time() - start) / reps)\n\nstart = time()\nfor i in range(0, reps):\n    ast.literal_eval(my_str)\nprint(\"ast method:\\t\\t\", (time() - start) / reps)\n\nstart = time()\nfor i in range(0, reps):\n    [n.strip() for n in my_str]\nprint(\"strip method:\\t\", (time() - start) / reps)\n\n\n\n    regex method:    6.391477584838867e-07\n    json method:     2.535374164581299e-06\n    ast method:      2.4425282478332518e-05\n    strip method:    4.983267784118653e-06\n \n\n So in the end regex wins! \n    ", "date_posted": "2018-08-06 11:12:47Z", "upvote": "\r\n            -1\r\n        ", "accepted": "No", "user": {"stack_user_id": "9224152", "name": "passs", "reputation_score": "43"}, "answer_comments": []}], "user": {"stack_user_id": "65424", "name": "harijay", "reputation_score": "10.4k"}, "question_comments": []},
{"stack_question_id": "16424091", "question_title": "Why does Tkinter image not show up if created in a function?", "question_content": "\r\n                This code works:\n\nimport tkinter\n\nroot = tkinter.Tk()\ncanvas = tkinter.Canvas(root)\ncanvas.grid(row = 0, column = 0)\nphoto = tkinter.PhotoImage(file = './test.gif')\ncanvas.create_image(0, 0, image=...\r\n", "question_url": "/questions/16424091/why-does-tkinter-image-not-show-up-if-created-in-a-function", "date_posted": "May 7, 2013 at 16:30", "upvote": "7", "view": "8", "tags": ["python", "image", "tkinter", "tkinter-canvas"], "answers_count": "4", "answers": [{"stack_answer_id": "16424553", "answer_content": "\r\n The variable  photo  is a local variable which gets garbage collected after the class is instantiated. Save a reference to the photo, for example: \n self.photo = tkinter.PhotoImage(...)\n \n If you do a Google search on \"tkinter image doesn't display\", the first result is this: \n Why do my Tkinter images not appear?  (The FAQ answer is currently  not  outdated) \n    ", "date_posted": "2021-03-15 16:50:04Z", "upvote": "\r\n            106\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "355230", "name": "martineau", "reputation_score": "115k"}, "answer_comments": [{"stack_answer_id": "16424553", "stack_answer_comment_id": "115733354", "comment_content": "Wow. Do they consider this a bug in tkinter? They should.", "user_id": null}, {"stack_answer_id": "16424553", "stack_answer_comment_id": "117806780", "comment_content": "@TamasHegedus: I agree it's bug, but apparently not one that anyone has ever bothered to fix after (currently) nearly two decades. Have lost count how many times I see a question regarding to it still pops up.", "user_id": null}, {"stack_answer_id": "16424553", "stack_answer_comment_id": "129582113", "comment_content": "@Enderman: a reference needs to be kept by something, somewhere.", "user_id": null}, {"stack_answer_id": "16424553", "stack_answer_comment_id": "129587214", "comment_content": "@Enderman: no, because it's referencing itself. An object needs an external reference to it or the garbage collector might destroy it.", "user_id": null}, {"stack_answer_id": "16424553", "stack_answer_comment_id": "129588131", "comment_content": "@Enderman: no. You need to save a reference to the instance of the class.", "user_id": null}]}, {"stack_answer_id": "63599265", "answer_content": "\r\n from tkinter import *\nfrom PIL import ImageTk, Image\n\nroot = Tk()\n\ndef open_img():\n    global img\n    path = r\"C:\\.....\\\\\"\n    img = ImageTk.PhotoImage(Image.open(path))\n    panel = Label(root, image=img)\n    panel.pack(side=\"bottom\", fill=\"both\")\nbut1 = Button(root, text=\"click to get the image\", command=open_img)\nbut1.pack()\nroot.mainloop() \n \n \n Just add global to the img definition and it will work \n \n    ", "date_posted": "2020-08-26 13:57:15Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "9769923", "name": "TIRTH SHAH", "reputation_score": "79"}, "answer_comments": [{"stack_answer_id": "63599265", "stack_answer_comment_id": "124847517", "comment_content": "This answer is fine for a program that just uses functions, but if, as in the OP's case, you use a class, than ", "user_id": null}]}, {"stack_answer_id": "71502573", "answer_content": "\r\n The problem is Python automatically deletes the references to the variable by a process known as  Garbage Collection . The solution is to save the reference or to create a new reference. \n The following are the ways: \n \n Using  self  to increase the reference count and to save the reference. \n \n import tkinter\n\nclass Test:\n    def __init__(self, master):\n        canvas = tkinter.Canvas(master)\n        canvas.grid(row = 0, column = 0)\n        self.photo = tkinter.PhotoImage(file = './test.gif') # Changes here\n        canvas.create_image(0, 0, image=self.photo) # Changes here\n\nroot = tkinter.Tk()\ntest = Test(root)\nroot.mainloop()\n \n \n Saving it to a list to increase the reference count and to save the reference. \n \n import tkinter\nl=[]\nclass Test:\n\n    def __init__(self, master):\n        canvas = tkinter.Canvas(master)\n        canvas.grid(row = 0, column = 0)\n        photo = tkinter.PhotoImage(file = './test.gif')\n        l.append(photo)\n        canvas.create_image(0, 0, image=photo)\n\nroot = tkinter.Tk()\ntest = Test(root)\nroot.mainloop()\n \n While using method 2, you can either make a global list as i did or use list inside the class. Both would work. \n Some useful links: \n \n About Garbage Collection 1 \n About Garbage Collection 2 ( More useful ) \n \n    ", "date_posted": "2022-03-16 19:03:59Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "16187613", "name": "Faraaz Kurawle", "reputation_score": "945"}, "answer_comments": []}, {"stack_answer_id": "54936405", "answer_content": "\r\n Just add  global photo  as the first line inside the function. \n    ", "date_posted": "2019-03-01 00:45:49Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "6451750", "name": "Gabriel", "reputation_score": "37"}, "answer_comments": [{"stack_answer_id": "54936405", "stack_answer_comment_id": "99917567", "comment_content": "And then you create a 2nd ", "user_id": null}, {"stack_answer_id": "54936405", "stack_answer_comment_id": "123329075", "comment_content": "There is definitely no no need to use ", "user_id": null}]}], "user": {"stack_user_id": "1554934", "name": "thomas.winckell", "reputation_score": "1,107"}, "question_comments": [{"stack_question_id": "16424091", "stack_question_comment_id": "116648223", "comment_content": " is down. The gist of it is that the image is passed by reference. If the reference is to a local variable, the memory referenced gets reused and the reference becomes stale. The variable storing the image should be in the same scope (has to have the same lifetime) as the Tk gui object it appears on.", "user_id": null}, {"stack_question_id": "16424091", "stack_question_comment_id": "122756541", "comment_content": "@maszoka: ", "user_id": null}, {"stack_question_id": "16424091", "stack_question_comment_id": "125991644", "comment_content": "Also note that the same problem can appear anywhere temporary ", "user_id": null}]},
{"stack_question_id": "49775502", "question_title": "WebDriverWait not working as expected", "question_content": "\r\n                I am working with selenium to scrape some data.\n\nThere is button on the page that I am clicking say \"custom_cols\". This button opens up a window for me where I can select my columns. \n\nThis new window ...\r\n", "question_url": "/questions/49775502/webdriverwait-not-working-as-expected", "date_posted": "Apr 11, 2018 at 12:43", "upvote": "1", "view": "1", "tags": ["python", "selenium", "web-scraping", "webdriverwait", "expected-condition"], "answers_count": "1", "answers": [{"stack_answer_id": "49775808", "answer_content": "\r\n Once you wait for the element and moving forward as you are trying to invoke  click()  method instead of using  presence_of_element_located()  method you need to use  element_to_be_clickable()  as follows : \n\n try:\n    myElem = WebDriverWait(self.browser, delay).until(EC.element_to_be_clickable((By.XPATH , xpath)))\n \n\n \n\n Update \n\n As per your counter question in the comments here are the details of the three methods : \n\n presence_of_element_located \n\n presence_of_element_located(locator)  is defined as follows : \n\n class selenium.webdriver.support.expected_conditions.presence_of_element_located(locator)\n\nParameter : locator - used to find the element returns the WebElement once it is located\n\nDescription : An expectation for checking that an element is present on the DOM of a page. This does not necessarily mean that the element is visible or interactable (i.e. clickable). \n \n\n visibility_of_element_located \n\n visibility_of_element_located(locator)  is defined as follows : \n\n class selenium.webdriver.support.expected_conditions.visibility_of_element_located(locator)\n\nParameter : locator -  used to find the element returns the WebElement once it is located and visible\n\nDescription : An expectation for checking that an element is present on the DOM of a page and visible. Visibility means that the element is not only displayed but also has a height and width that is greater than 0.\n \n\n element_to_be_clickable \n\n element_to_be_clickable(locator)  is defined as follows : \n\n class selenium.webdriver.support.expected_conditions.element_to_be_clickable(locator)\n\nParameter : locator - used to find the element returns the WebElement once it is visible, enabled and interactable (i.e. clickable).\n\nDescription : An Expectation for checking an element is visible, enabled and interactable such that you can click it. \n \n    ", "date_posted": "2018-10-02 11:32:14Z", "upvote": "\r\n            12\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "7429447", "name": "undetected Selenium", "reputation_score": "160k"}, "answer_comments": [{"stack_answer_id": "49775808", "stack_answer_comment_id": "86567318", "comment_content": "Can you please explain why it works but other function not.", "user_id": "/users/6770735/rao-sahab"}, {"stack_answer_id": "49775808", "stack_answer_comment_id": "123680315", "comment_content": " definitely helped, but I still had situations where ", "user_id": null}]}], "user": {"stack_user_id": "6770735", "name": "Rao Sahab", "reputation_score": "971"}, "question_comments": [{"stack_question_id": "49775502", "stack_question_comment_id": "123680419", "comment_content": "Just a comment that the 2nd argument for ", "user_id": null}]},
{"stack_question_id": "16476924", "question_title": "How to iterate over rows in a DataFrame in Pandas", "question_content": "\r\n                I have a pandas dataframe, df:\n   c1   c2\n0  10  100\n1  11  110\n2  12  120\n\nHow do I iterate over the rows of this dataframe? For every row, I want to be able to access its elements (values in cells) ...\r\n", "question_url": "/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas", "date_posted": "May 10, 2013 at 7:04", "upvote": "3", "view": "5", "tags": ["python", "pandas", "dataframe"], "answers_count": "3", "answers": [{"stack_answer_id": "16476974", "answer_content": "\r\n DataFrame.iterrows  is a generator which yields both the index and row (as a Series): \n import pandas as pd\n\ndf = pd.DataFrame({'c1': [10, 11, 12], 'c2': [100, 110, 120]})\ndf = df.reset_index()  # make sure indexes pair with number of rows\n\nfor index, row in df.iterrows():\n    print(row['c1'], row['c2'])\n \n\n 10 100\n11 110\n12 120\n \n    ", "date_posted": "2022-06-06 03:16:21Z", "upvote": "\r\n            4654\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": [{"stack_answer_id": "16476974", "stack_answer_comment_id": "69252004", "comment_content": "Note: \"Because iterrows returns a Series for each row, it ", "user_id": null}, {"stack_answer_id": "16476974", "stack_answer_comment_id": "79079467", "comment_content": "@viddik13 that's a great note thanks. Because of that I ran into a case where numerical values like ", "user_id": null}, {"stack_answer_id": "16476974", "stack_answer_comment_id": "79152689", "comment_content": "@AzizAlto use ", "user_id": null}, {"stack_answer_id": "16476974", "stack_answer_comment_id": "82152649", "comment_content": "Do not use iterrows. Itertuples is faster and preserves data type. ", "user_id": null}, {"stack_answer_id": "16476974", "stack_answer_comment_id": "99276519", "comment_content": "From ", "user_id": null}]}, {"stack_answer_id": "55557758", "answer_content": "\r\n \n How to iterate over rows in a DataFrame in Pandas? \n \n Answer: DON'T * ! \n Iteration in Pandas is an anti-pattern and is something you should only do when you have exhausted every other option. You should not use any function with \" iter \" in its name for more than a few thousand rows or you will have to get used to a  lot  of waiting. \n Do you want to print a DataFrame? Use  DataFrame.to_string() . \n Do you want to compute something? In that case, search for methods in this order (list modified from  here ): \n \n Vectorization \n Cython  routines \n List Comprehensions (vanilla  for  loop) \n DataFrame.apply() : i) \u00a0Reductions that can be performed in Cython, ii) Iteration in Python space \n DataFrame.itertuples()  and  iteritems() \n DataFrame.iterrows() \n \n iterrows  and  itertuples  (both receiving many votes in answers to this question) should be used in very rare circumstances, such as generating row objects/nametuples for sequential processing, which is really the only thing these functions are useful for. \n Appeal to Authority \n The documentation page  on iteration has a huge red warning box that says: \n \n Iterating through pandas objects is generally slow. In many cases, iterating manually over the rows is not needed [...]. \n \n * It's actually a little more complicated than \"don't\".  df.iterrows()  is the correct answer to this question, but \"vectorize your ops\" is the better one. I will concede that there are circumstances where iteration cannot be avoided (for example, some operations where the result depends on the value computed for the previous row). However, it takes some familiarity with the library to know when. If you're not sure whether you need an iterative solution, you probably don't. PS: To know more about my rationale for writing this answer, skip to the very bottom. \n \n Faster than Looping:  Vectorization ,  Cython \n A good number of basic operations and computations are \"vectorised\" by pandas (either through NumPy, or through Cythonized functions). This includes arithmetic, comparisons, (most) reductions, reshaping (such as pivoting), joins, and groupby operations. Look through the documentation on  Essential Basic Functionality  to find a suitable vectorised method for your problem. \n If none exists, feel free to write your own using custom  Cython extensions . \n \n Next Best Thing:  List Comprehensions * \n List comprehensions should be your next port of call if 1) there is no vectorized solution available, 2) performance is important, but not important enough to go through the hassle of cythonizing your code, and 3) you're trying to perform elementwise transformation on your code. There is a  good amount of evidence  to suggest that list comprehensions are sufficiently fast (and even sometimes faster) for many common Pandas tasks. \n The formula is simple, \n # Iterating over one column - `f` is some function that processes your data\nresult = [f(x) for x in df['col']]\n# Iterating over two columns, use `zip`\nresult = [f(x, y) for x, y in zip(df['col1'], df['col2'])]\n# Iterating over multiple columns - same data type\nresult = [f(row[0], ..., row[n]) for row in df[['col1', ...,'coln']].to_numpy()]\n# Iterating over multiple columns - differing data type\nresult = [f(row[0], ..., row[n]) for row in zip(df['col1'], ..., df['coln'])]\n \n If you can encapsulate your business logic into a function, you can use a list comprehension that calls it. You can make arbitrarily complex things work through the simplicity and speed of raw Python code. \n Caveats \n List comprehensions assume that your data is easy to work with - what that means is your data types are consistent and you don't have NaNs, but this cannot always be guaranteed. \n \n The first one is more obvious, but when dealing with NaNs, prefer in-built pandas methods if they exist (because they have much better corner-case handling logic), or ensure your business logic includes appropriate NaN handling logic. \n When dealing with mixed data types you should iterate over  zip(df['A'], df['B'], ...)  instead of  df[['A', 'B']].to_numpy()  as the latter implicitly upcasts data to the most common type. As an example if A is numeric and B is string,  to_numpy()  will cast the entire array to string, which may not be what you want. Fortunately  zip ping your columns together is the most straightforward workaround to this. \n \n *Your mileage may vary for the reasons outlined in the  Caveats  section above. \n \n An Obvious Example \n Let's demonstrate the difference with a simple example of adding two pandas columns  A + B . This is a vectorizable operaton, so it will be easy to contrast the performance of the methods discussed above. \n \n Benchmarking code, for your reference . The line at the bottom measures a function written in numpandas, a style of Pandas that mixes heavily with NumPy to squeeze out maximum performance. Writing numpandas code should be avoided unless you know what you're doing. Stick to the API where you can (i.e., prefer  vec  over  vec_numpy ). \n I should mention, however, that it isn't always this cut and dry. Sometimes the answer to \"what is the best method for an operation\" is \"it depends on your data\". My advice is to test out different approaches on your data before settling on one. \n \n My Personal Opinion  * \n Most of the analyses performed on the various alternatives to the iter family has been through the lens of performance. However, in most situations you will typically be working on a reasonably sized dataset (nothing beyond a few thousand or 100K rows) and performance will come second to simplicity/readability of the solution. \n Here is my personal preference when selecting a method to use for a problem. \n For the novice: \n \n Vectorization  (when possible) ;  apply() ; List Comprehensions;  itertuples() / iteritems() ;  iterrows() ; Cython \n \n For the more experienced: \n \n Vectorization  (when possible) ;  apply() ; List Comprehensions; Cython;  itertuples() / iteritems() ;  iterrows() \n \n Vectorization prevails as the most idiomatic method for any problem that can be vectorized. Always seek to vectorize! When in doubt, consult the docs, or look on Stack Overflow for an existing question on your particular task. \n I do tend to go on about how bad  apply  is in a lot of my posts, but I do concede it is easier for a beginner to wrap their head around what it's doing. Additionally, there are quite a few use cases for  apply  has explained in  this post of mine . \n Cython ranks lower down on the list because it takes more time and effort to pull off correctly. You will usually never need to write code with pandas that demands this level of performance that even a list comprehension cannot satisfy. \n * As with any personal opinion, please take with heaps of salt! \n \n Further Reading \n \n 10 Minutes to pandas , and  Essential Basic Functionality  - Useful links that introduce you to Pandas and its library of vectorized*/cythonized functions. \n \n Enhancing Performance  - A primer from the documentation on enhancing standard Pandas operations \n \n Are for-loops in pandas really bad? When should I care?  - a detailed writeup by me on list comprehensions and their suitability for various operations (mainly ones involving non-numeric data) \n \n When should I (not) want to use pandas apply() in my code?  -  apply  is slow (but not as slow as the  iter*  family. There are, however, situations where one can (or should) consider  apply  as a serious alternative, especially in some  GroupBy  operations). \n \n \n * Pandas string methods are \"vectorized\" in the sense that they are specified on the series but operate on each element. The underlying mechanisms are still iterative, because string operations are inherently hard to vectorize. \n \n Why I Wrote this Answer \n A common trend I notice from new users is to ask questions of the form \"How can I iterate over my df to do X?\". Showing code that calls  iterrows()  while doing something inside a  for  loop. Here is why. A new user to the library who has not been introduced to the concept of vectorization will likely envision the code that solves their problem as iterating over their data to do something. Not knowing how to iterate over a DataFrame, the first thing they do is Google it and end up here, at this question. They then see the accepted answer telling them how to, and they close their eyes and run this code without ever first questioning if iteration is the right thing to do. \n The aim of this answer is to help new users understand that iteration is not necessarily the solution to every problem, and that better, faster and more idiomatic solutions could exist, and that it is worth investing time in exploring them. I'm not trying to start a war of iteration vs. vectorization, but I want new users to be informed when developing solutions to their problems with this library. \n    ", "date_posted": "2022-03-19 15:58:59Z", "upvote": "\r\n            1969\r\n        ", "accepted": "No", "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "answer_comments": [{"stack_answer_id": "55557758", "stack_answer_comment_id": "99356021", "comment_content": "Note that there are important caveats with ", "user_id": null}, {"stack_answer_id": "55557758", "stack_answer_comment_id": "99360660", "comment_content": "This is the only answer that focuses on the idiomatic techniques one should use with pandas, making it the best answer for this question. Learning to get the ", "user_id": null}, {"stack_answer_id": "55557758", "stack_answer_comment_id": "100017200", "comment_content": "I think you are being unfair to the for loop, though, seeing as they are only a bit slower than list comprehension in my tests. The trick is to loop over ", "user_id": null}, {"stack_answer_id": "55557758", "stack_answer_comment_id": "105699071", "comment_content": "Under List Comprehensions, the \"iterating over multiple columns\" example needs a caveat: ", "user_id": null}, {"stack_answer_id": "55557758", "stack_answer_comment_id": "111575230", "comment_content": "@Dean I get this response quite often and it honestly confuses me. It's all about forming good habits. \"My data is small and performance doesn't matter so my use of this antipattern can be excused\" ..? When performance actually does matter one day, you'll thank yourself for having prepared the right tools in advance.", "user_id": null}]}, {"stack_answer_id": "41022840", "answer_content": "\r\n First consider if you really need to  iterate  over rows in a DataFrame. See  this answer  for alternatives. \n If you still need to iterate over rows, you can use methods below. Note some   important caveats  which are not mentioned in any of the other answers. \n \n DataFrame.iterrows() \n   for index, row in df.iterrows():\n      print(row[\"c1\"], row[\"c2\"])\n \n \n DataFrame.itertuples() \n   for row in df.itertuples(index=True, name='Pandas'):\n      print(row.c1, row.c2)\n \n \n \n itertuples()  is supposed to be faster than  iterrows() \n But be aware, according to the docs (pandas 0.24.2 at the moment): \n \n iterrows:  dtype  might not match from row to row \n \n \n Because iterrows returns a Series for each row, it  does not preserve  dtypes across the rows (dtypes are preserved across columns for DataFrames). To preserve dtypes while iterating over the rows, it is better to use itertuples() which returns namedtuples of the values and which is generally much faster than iterrows() \n \n \n iterrows: Do not modify rows \n \n \n You should  never modify  something you are iterating over. This is not guaranteed to work in all cases. Depending on the data types, the iterator returns a copy and not a view, and writing to it will have no effect. \n \n Use  DataFrame.apply()  instead: \n     new_df = df.apply(lambda x: x * 2, axis = 1)\n \n \n itertuples: \n \n \n The column names will be renamed to positional names if they are invalid Python identifiers, repeated, or start with an underscore. With a large number of columns (>255), regular tuples are returned. \n \n See  pandas docs on iteration  for more details. \n    ", "date_posted": "2022-04-30 18:45:58Z", "upvote": "\r\n            534\r\n        ", "accepted": "No", "user": {"stack_user_id": "7156008", "name": "George", "reputation_score": "2,904"}, "answer_comments": [{"stack_answer_id": "41022840", "stack_answer_comment_id": "83917009", "comment_content": "Just a small question from someone reading this thread so long after its completion: how df.apply() compares to itertuples in terms of efficiency?", "user_id": null}, {"stack_answer_id": "41022840", "stack_answer_comment_id": "89180584", "comment_content": "Note: you can also say something like ", "user_id": null}, {"stack_answer_id": "41022840", "stack_answer_comment_id": "90586609", "comment_content": "Instead of ", "user_id": null}, {"stack_answer_id": "41022840", "stack_answer_comment_id": "90954217", "comment_content": "I am about 90% sure that if you use ", "user_id": null}, {"stack_answer_id": "41022840", "stack_answer_comment_id": "99357008", "comment_content": "I have stumbled upon this question because, although I knew there's split-apply-combine, I still ", "user_id": null}]}, {"stack_answer_id": "10739432", "answer_content": "\r\n You should use  df.iterrows() . Though iterating row-by-row is not especially efficient since  Series  objects have to be created. \n    ", "date_posted": "2019-12-11 18:42:58Z", "upvote": "\r\n            238\r\n        ", "accepted": "No", "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "answer_comments": [{"stack_answer_id": "10739432", "stack_answer_comment_id": "17255818", "comment_content": "Is this faster than converting the DataFrame to a numpy array (via .values) and operating on the array directly? I have the same problem, but ended up converting to a numpy array and then using cython.", "user_id": null}, {"stack_answer_id": "10739432", "stack_answer_comment_id": "24785470", "comment_content": "@vgoklani If iterating row-by-row is inefficient and you have a non-object numpy array then almost surely using the raw numpy array will be faster, especially for arrays with many rows. you should avoid iterating over rows unless you absolutely have to", "user_id": null}, {"stack_answer_id": "10739432", "stack_answer_comment_id": "56363619", "comment_content": "I have done a bit of testing on the time consumption for df.iterrows(), df.itertuples(), and zip(df['a'], df['b']) and posted the result in the answer of another question: ", "user_id": null}]}, {"stack_answer_id": "32680162", "answer_content": "\r\n While  iterrows()  is a good option, sometimes  itertuples()  can be much faster: \n\n df = pd.DataFrame({'a': randn(1000), 'b': randn(1000),'N': randint(100, 1000, (1000)), 'x': 'x'})\n\n%timeit [row.a * 2 for idx, row in df.iterrows()]\n# => 10 loops, best of 3: 50.3 ms per loop\n\n%timeit [row[1] * 2 for row in df.itertuples()]\n# => 1000 loops, best of 3: 541 \u00b5s per loop\n \n    ", "date_posted": "2016-06-01 09:00:01Z", "upvote": "\r\n            178\r\n        ", "accepted": "No", "user": {"stack_user_id": "1054939", "name": "e9t", "reputation_score": "14.5k"}, "answer_comments": [{"stack_answer_id": "32680162", "stack_answer_comment_id": "53208434", "comment_content": "Much of the time difference in your two examples seems like it is due to the fact that you appear to be using label-based indexing for the .iterrows() command and integer-based indexing for the .itertuples() command.", "user_id": null}, {"stack_answer_id": "32680162", "stack_answer_comment_id": "54234206", "comment_content": "For a finance data based dataframe(timestamp, and 4x float), itertuples is 19,57 times faster then iterrows on my machine. Only ", "user_id": null}, {"stack_answer_id": "32680162", "stack_answer_comment_id": "70363504", "comment_content": "Can you explain why it's faster?", "user_id": null}, {"stack_answer_id": "32680162", "stack_answer_comment_id": "71581133", "comment_content": "@AbeMiessler ", "user_id": null}, {"stack_answer_id": "32680162", "stack_answer_comment_id": "81199073", "comment_content": "Note that the order of the columns is actually indeterminate, because ", "user_id": null}]}, {"stack_answer_id": "39370553", "answer_content": "\r\n You can use the  df.iloc  function as follows: \n for i in range(0, len(df)):\n    print(df.iloc[i]['c1'], df.iloc[i]['c2'])\n \n    ", "date_posted": "2022-01-08 22:42:21Z", "upvote": "\r\n            129\r\n        ", "accepted": "No", "user": {"stack_user_id": "6160119", "name": "Tonechas", "reputation_score": "12.9k"}, "answer_comments": [{"stack_answer_id": "39370553", "stack_answer_comment_id": "80130437", "comment_content": "I know that one should avoid this in favor of iterrows or itertuples, but it would be interesting to know why. Any thoughts?", "user_id": null}, {"stack_answer_id": "39370553", "stack_answer_comment_id": "83643245", "comment_content": "This is the only valid technique I know of if you want to preserve the data types, and also refer to columns by name.  ", "user_id": null}, {"stack_answer_id": "39370553", "stack_answer_comment_id": "91754942", "comment_content": "Spent hours trying to wade through the idiosyncrasies of pandas data structures to do something simple AND expressive.  This results in readable code.", "user_id": null}, {"stack_answer_id": "39370553", "stack_answer_comment_id": "94421406", "comment_content": "While ", "user_id": null}, {"stack_answer_id": "39370553", "stack_answer_comment_id": "94897279", "comment_content": "On large Datafrmes this seems better as ", "user_id": null}]}, {"stack_answer_id": "30566899", "answer_content": "\r\n You can also use  df.apply()  to iterate over rows and access multiple columns for a function. \n\n docs: DataFrame.apply() \n\n def valuation_formula(x, y):\n    return x * y * 0.5\n\ndf['price'] = df.apply(lambda row: valuation_formula(row['x'], row['y']), axis=1)\n \n    ", "date_posted": "2015-06-01 06:24:44Z", "upvote": "\r\n            120\r\n        ", "accepted": "No", "user": {"stack_user_id": "1803298", "name": "cheekybastard", "reputation_score": "5,355"}, "answer_comments": [{"stack_answer_id": "30566899", "stack_answer_comment_id": "50344574", "comment_content": "Is the df['price'] refers to a column name in the data frame? I am trying to create a dictionary with unique values from several columns in a csv file. I used your logic to create a dictionary with unique keys and values and got an error stating ", "user_id": null}, {"stack_answer_id": "30566899", "stack_answer_comment_id": "50344609", "comment_content": "  df['Workclass'] = df.apply(lambda row: dic_update(row), axis=1) ", "user_id": null}, {"stack_answer_id": "30566899", "stack_answer_comment_id": "82085632", "comment_content": "Having the axis default to 0 is the worst", "user_id": null}, {"stack_answer_id": "30566899", "stack_answer_comment_id": "86313667", "comment_content": "Notice that ", "user_id": null}, {"stack_answer_id": "30566899", "stack_answer_comment_id": "111570055", "comment_content": "this is the appropriate answer for pandas", "user_id": null}]}, {"stack_answer_id": "59413206", "answer_content": "\r\n How to iterate efficiently \n\n If you really have to iterate a Pandas dataframe, you will probably want to  avoid using iterrows() . There are different methods and the usual  iterrows()  is far from being the best.  itertuples() can be 100 times faster. \n\n In short: \n\n \n As a general rule, use  df.itertuples(name=None) . In particular, when you have a fixed number columns and less than 255 columns.  See point (3) \n Otherwise, use  df.itertuples()  except if your columns have special characters such as spaces or '-'.  See point (2) \n It is possible to use  itertuples()  even if your dataframe has strange columns by using the last example.  See point (4) \n Only use  iterrows()  if you cannot the previous solutions.  See point (1) \n \n\n Different methods to iterate over rows in a Pandas dataframe: \n\n Generate a random dataframe with a million rows and 4 columns: \n\n     df = pd.DataFrame(np.random.randint(0, 100, size=(1000000, 4)), columns=list('ABCD'))\n    print(df)\n \n\n 1) The usual  iterrows()  is convenient, but damn slow: \n\n start_time = time.clock()\nresult = 0\nfor _, row in df.iterrows():\n    result += max(row['B'], row['C'])\n\ntotal_elapsed_time = round(time.clock() - start_time, 2)\nprint(\"1. Iterrows done in {} seconds, result = {}\".format(total_elapsed_time, result))\n \n\n 2) The default  itertuples()  is already much faster, but it doesn't work with column names such as  My Col-Name is very Strange  (you should avoid this method if your columns are repeated or if a column name cannot be simply converted to a Python variable name).: \n\n start_time = time.clock()\nresult = 0\nfor row in df.itertuples(index=False):\n    result += max(row.B, row.C)\n\ntotal_elapsed_time = round(time.clock() - start_time, 2)\nprint(\"2. Named Itertuples done in {} seconds, result = {}\".format(total_elapsed_time, result))\n \n\n 3) The default  itertuples()  using name=None is even faster but not really convenient as you have to define a variable per column. \n\n start_time = time.clock()\nresult = 0\nfor(_, col1, col2, col3, col4) in df.itertuples(name=None):\n    result += max(col2, col3)\n\ntotal_elapsed_time = round(time.clock() - start_time, 2)\nprint(\"3. Itertuples done in {} seconds, result = {}\".format(total_elapsed_time, result))\n \n\n 4) Finally, the named  itertuples()  is slower than the previous point, but you do not have to define a variable per column and it works with column names such as  My Col-Name is very Strange . \n\n start_time = time.clock()\nresult = 0\nfor row in df.itertuples(index=False):\n    result += max(row[df.columns.get_loc('B')], row[df.columns.get_loc('C')])\n\ntotal_elapsed_time = round(time.clock() - start_time, 2)\nprint(\"4. Polyvalent Itertuples working even with special characters in the column name done in {} seconds, result = {}\".format(total_elapsed_time, result))\n \n\n Output: \n\n          A   B   C   D\n0       41  63  42  23\n1       54   9  24  65\n2       15  34  10   9\n3       39  94  82  97\n4        4  88  79  54\n...     ..  ..  ..  ..\n999995  48  27   4  25\n999996  16  51  34  28\n999997   1  39  61  14\n999998  66  51  27  70\n999999  51  53  47  99\n\n[1000000 rows x 4 columns]\n\n1. Iterrows done in 104.96 seconds, result = 66151519\n2. Named Itertuples done in 1.26 seconds, result = 66151519\n3. Itertuples done in 0.94 seconds, result = 66151519\n4. Polyvalent Itertuples working even with special characters in the column name done in 2.94 seconds, result = 66151519\n \n\n This article is a very interesting comparison between iterrows and itertuples \n    ", "date_posted": "2020-06-11 13:43:59Z", "upvote": "\r\n            61\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "59413206", "stack_answer_comment_id": "124783543", "comment_content": "So WHY are these inefficient methods available in Pandas in the first place - if it's \"common knowledge\" that iterrows and itertuples should not be used - then why are they there, or rather, why are those methods not updated and made more efficient in the background by the maintainers of Pandas?", "user_id": null}, {"stack_answer_id": "59413206", "stack_answer_comment_id": "124794962", "comment_content": "@Monty, it's not always possible to vectorize all operations.", "user_id": null}]}, {"stack_answer_id": "48297889", "answer_content": "\r\n I was looking for  How to iterate on rows   and   columns  and ended here so: \n\n for i, row in df.iterrows():\n    for j, column in row.iteritems():\n        print(column)\n \n    ", "date_posted": "2020-06-11 13:37:53Z", "upvote": "\r\n            48\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "48297889", "stack_answer_comment_id": "111393447", "comment_content": "When possible, you should avoid using iterrows(). I explain why in the answer ", "user_id": null}]}, {"stack_answer_id": "47149876", "answer_content": "\r\n You can write your own iterator that implements  namedtuple \n\n from collections import namedtuple\n\ndef myiter(d, cols=None):\n    if cols is None:\n        v = d.values.tolist()\n        cols = d.columns.values.tolist()\n    else:\n        j = [d.columns.get_loc(c) for c in cols]\n        v = d.values[:, j].tolist()\n\n    n = namedtuple('MyTuple', cols)\n\n    for line in iter(v):\n        yield n(*line)\n \n\n This is directly comparable to  pd.DataFrame.itertuples .  I'm aiming at performing the same task with more efficiency. \n\n \n\n For the given dataframe with my function: \n\n list(myiter(df))\n\n[MyTuple(c1=10, c2=100), MyTuple(c1=11, c2=110), MyTuple(c1=12, c2=120)]\n \n\n Or with  pd.DataFrame.itertuples : \n\n list(df.itertuples(index=False))\n\n[Pandas(c1=10, c2=100), Pandas(c1=11, c2=110), Pandas(c1=12, c2=120)]\n \n\n \n\n A comprehensive test \nWe test making all columns available and subsetting the columns.   \n\n def iterfullA(d):\n    return list(myiter(d))\n\ndef iterfullB(d):\n    return list(d.itertuples(index=False))\n\ndef itersubA(d):\n    return list(myiter(d, ['col3', 'col4', 'col5', 'col6', 'col7']))\n\ndef itersubB(d):\n    return list(d[['col3', 'col4', 'col5', 'col6', 'col7']].itertuples(index=False))\n\nres = pd.DataFrame(\n    index=[10, 30, 100, 300, 1000, 3000, 10000, 30000],\n    columns='iterfullA iterfullB itersubA itersubB'.split(),\n    dtype=float\n)\n\nfor i in res.index:\n    d = pd.DataFrame(np.random.randint(10, size=(i, 10))).add_prefix('col')\n    for j in res.columns:\n        stmt = '{}(d)'.format(j)\n        setp = 'from __main__ import d, {}'.format(j)\n        res.at[i, j] = timeit(stmt, setp, number=100)\n\nres.groupby(res.columns.str[4:-1], axis=1).plot(loglog=True);\n \n\n \n\n \n    ", "date_posted": "2017-11-07 04:29:57Z", "upvote": "\r\n            24\r\n        ", "accepted": "No", "user": {"stack_user_id": "2336654", "name": "piRSquared", "reputation_score": "270k"}, "answer_comments": [{"stack_answer_id": "47149876", "stack_answer_comment_id": "82152350", "comment_content": "For people who don't want to read the code: blue line is ", "user_id": null}]}, {"stack_answer_id": "42741552", "answer_content": "\r\n To loop all rows in a  dataframe  you can use: \n\n for x in range(len(date_example.index)):\n    print date_example['Date'].iloc[x]\n \n    ", "date_posted": "2017-04-04 20:46:53Z", "upvote": "\r\n            21\r\n        ", "accepted": "No", "user": {"stack_user_id": "797495", "name": "Pedro Lobito", "reputation_score": "87.6k"}, "answer_comments": [{"stack_answer_id": "42741552", "stack_answer_comment_id": "98185901", "comment_content": "This is chained indexing. I do not recommend doing this.", "user_id": null}, {"stack_answer_id": "42741552", "stack_answer_comment_id": "98187282", "comment_content": "@cs95 What would you recommend instead?", "user_id": null}, {"stack_answer_id": "42741552", "stack_answer_comment_id": "98187416", "comment_content": "If you want to make this work, call df.columns.get_loc to get the integer index position of the date column (outside the loop), then use a single iloc indexing call inside.", "user_id": null}]}, {"stack_answer_id": "47073107", "answer_content": "\r\n  for ind in df.index:\n     print df['c1'][ind], df['c2'][ind]\n \n    ", "date_posted": "2019-05-07 06:37:44Z", "upvote": "\r\n            21\r\n        ", "accepted": "No", "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "answer_comments": [{"stack_answer_id": "47073107", "stack_answer_comment_id": "91463214", "comment_content": "how is the performance of this option when used on a large dataframe (millions of rows for example)?", "user_id": null}, {"stack_answer_id": "47073107", "stack_answer_comment_id": "92887253", "comment_content": "Honestly, I don\u2019t know exactly, I think that in comparison with the best answer, the elapsed time will be about the same, because both cases use \"for\"-construction.  But the memory may be different in some cases.", "user_id": null}, {"stack_answer_id": "47073107", "stack_answer_comment_id": "98185895", "comment_content": "This is chained indexing. Do not use this!", "user_id": null}]}, {"stack_answer_id": "70096237", "answer_content": "\r\n We have multiple options to do the same, lots of folks have shared their answers. \n I found below two methods easy and efficient to do : \n \n DataFrame.iterrows() \n DataFrame.itertuples() \n \n Example: \n  import pandas as pd\n inp = [{'c1':10, 'c2':100}, {'c1':11,'c2':110}, {'c1':12,'c2':120}]\n df = pd.DataFrame(inp)\n print (df)\n\n #With iterrows method \n\n for index, row in df.iterrows():\n     print(row[\"c1\"], row[\"c2\"])\n\n #With itertuples method\n\n for row in df.itertuples(index=True, name='Pandas'):\n     print(row.c1, row.c2)\n \n Note: itertuples() is supposed to be faster than iterrows() \n    ", "date_posted": "2022-01-06 09:46:42Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "9076666", "name": "Sachin", "reputation_score": "862"}, "answer_comments": [{"stack_answer_id": "70096237", "stack_answer_comment_id": "124086617", "comment_content": "This actually answers the question. +1", "user_id": null}]}, {"stack_answer_id": "60836700", "answer_content": "\r\n Update : cs95 has updated  his answer  to include plain numpy vectorization. You can simply refer to his answer. \n \n cs95 shows  that Pandas vectorization far outperforms other Pandas methods for computing stuff with dataframes. \n I wanted to add that if you first convert the dataframe to a NumPy array and then use vectorization, it's even faster than Pandas dataframe vectorization, (and that includes the time to turn it back into a dataframe series). \n If you add the following functions to cs95's benchmark code, this becomes pretty evident: \n def np_vectorization(df):\n    np_arr = df.to_numpy()\n    return pd.Series(np_arr[:,0] + np_arr[:,1], index=df.index)\n\ndef just_np_vectorization(df):\n    np_arr = df.to_numpy()\n    return np_arr[:,0] + np_arr[:,1]\n \n \n    ", "date_posted": "2021-08-27 05:47:45Z", "upvote": "\r\n            15\r\n        ", "accepted": "No", "user": {"stack_user_id": "10801098", "name": "bug_spray", "reputation_score": "1,335"}, "answer_comments": [{"stack_answer_id": "60836700", "stack_answer_comment_id": "121890161", "comment_content": "how do did you plot this?", "user_id": null}, {"stack_answer_id": "60836700", "stack_answer_comment_id": "121960481", "comment_content": " ", "user_id": null}]}, {"stack_answer_id": "51069586", "answer_content": "\r\n Sometimes a useful pattern is: \n\n # Borrowing @KutalmisB df example\ndf = pd.DataFrame({'col1': [1, 2], 'col2': [0.1, 0.2]}, index=['a', 'b'])\n# The to_dict call results in a list of dicts\n# where each row_dict is a dictionary with k:v pairs of columns:value for that row\nfor row_dict in df.to_dict(orient='records'):\n    print(row_dict)\n \n\n Which results in: \n\n {'col1':1.0, 'col2':0.1}\n{'col1':2.0, 'col2':0.2}\n \n    ", "date_posted": "2019-04-13 23:06:06Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "4909087", "name": "cs95", "reputation_score": "341k"}, "answer_comments": []}, {"stack_answer_id": "62136475", "answer_content": "\r\n In short \n \n Use vectorization if possible \n If an operation can't be vectorized - use list comprehensions \n If you need a single object representing the entire row - use itertuples \n If the above is too slow - try  swifter.apply \n If it's still too slow - try a  Cython  routine \n \n Benchmark \n \n    ", "date_posted": "2021-04-21 16:42:24Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "58436037", "answer_content": "\r\n There is a way to iterate throw rows while getting a DataFrame in return, and not a Series. I don't see anyone mentioning that you can pass index as a list for the row to be returned as a DataFrame: \n\n for i in range(len(df)):\n    row = df.iloc[[i]]\n \n\n Note the usage of double brackets. This returns a DataFrame with a single row. \n    ", "date_posted": "2019-10-17 15:26:30Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "1871385", "name": "Zeitgeist", "reputation_score": "1,242"}, "answer_comments": [{"stack_answer_id": "58436037", "stack_answer_comment_id": "104526424", "comment_content": "This was very helpful for getting the nth largest row in a data frame after sorting. Thanks!", "user_id": null}]}, {"stack_answer_id": "49984074", "answer_content": "\r\n To loop all rows in a  dataframe  and  use  values of each row  conveniently ,  namedtuples  can be converted to  ndarray s. For example: \n\n df = pd.DataFrame({'col1': [1, 2], 'col2': [0.1, 0.2]}, index=['a', 'b'])\n \n\n Iterating over the rows: \n\n for row in df.itertuples(index=False, name='Pandas'):\n    print np.asarray(row)\n \n\n results in: \n\n [ 1.   0.1]\n[ 2.   0.2]\n \n\n Please note that if  index=True ,  the index is added as the first element of the tuple , which may be undesirable for some applications. \n    ", "date_posted": "2018-04-24 08:48:05Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "3393574", "name": "Herpes Free Engineer", "reputation_score": "2,125"}, "answer_comments": []}, {"stack_answer_id": "54896256", "answer_content": "\r\n For both viewing and modifying values, I would use  iterrows() . In a for loop and by using tuple unpacking (see the example:  i, row ), I use the  row  for only viewing the value and use  i  with the  loc  method when I want to modify values. As stated in previous answers, here you should not modify something you are iterating over. \n\n for i, row in df.iterrows():\n    df_column_A = df.loc[i, 'A']\n    if df_column_A == 'Old_Value':\n        df_column_A = 'New_value'  \n \n\n Here the  row  in the loop is a copy of that row, and not a view of it. Therefore, you should NOT write something like  row['A'] = 'New_Value' , it will not modify the DataFrame. However, you can use  i  and  loc  and specify the DataFrame to do the work. \n    ", "date_posted": "2020-02-28 17:51:44Z", "upvote": "\r\n            10\r\n        ", "accepted": "No", "user": {"stack_user_id": "10951905", "name": "Hossein Kalbasi", "reputation_score": "1,393"}, "answer_comments": []}, {"stack_answer_id": "54264778", "answer_content": "\r\n There are so many ways to iterate over the rows in Pandas dataframe. One very simple and intuitive way is: \n\n df = pd.DataFrame({'A':[1, 2, 3], 'B':[4, 5, 6], 'C':[7, 8, 9]})\nprint(df)\nfor i in range(df.shape[0]):\n    # For printing the second column\n    print(df.iloc[i, 1])\n\n    # For printing more than one columns\n    print(df.iloc[i, [0, 2]])\n \n    ", "date_posted": "2020-06-11 13:38:59Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "64653674", "answer_content": "\r\n The easiest way, use the  apply  function \n def print_row(row):\n   print row['c1'], row['c2']\n\ndf.apply(lambda row: print_row(row), axis=1)\n \n    ", "date_posted": "2020-11-02 21:35:10Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "12566550", "name": "Fran\u00e7ois B.", "reputation_score": "1,014"}, "answer_comments": []}, {"stack_answer_id": "65396738", "answer_content": "\r\n As many answers here correctly and clearly point out, you should not generally attempt to loop in Pandas, but rather should write vectorized code.  But the question remains if you should  ever  write loops in Pandas, and if so the best way to loop in those situations. \n I believe there is at least one general situation where loops are appropriate: when you need to calculate some function that depends on values in  other  rows in a somewhat complex manner.  In this case, the looping code is often simpler, more readable, and less error prone than vectorized code.   The looping code might even be faster, too. \n I will attempt to show this with an example.  Suppose you want to take a cumulative sum of a column, but reset it whenever some other column equals zero: \n import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame( { 'x':[1,2,3,4,5,6], 'y':[1,1,1,0,1,1]  } )\n\n#   x  y  desired_result\n#0  1  1               1\n#1  2  1               3\n#2  3  1               6\n#3  4  0               4\n#4  5  1               9\n#5  6  1              15\n \n This is a good example where you could certainly write one line of Pandas to achieve this, although it's not especially readable, especially if you aren't fairly experienced with Pandas already: \n df.groupby( (df.y==0).cumsum() )['x'].cumsum()\n \n That's going to be fast enough for most situations, although you could also write faster code by avoiding the  groupby , but it will likely be even less readable. \n Alternatively, what if we write this as a loop?  You could do something like the following with NumPy: \n import numba as nb\n\n@nb.jit(nopython=True)  # Optional\ndef custom_sum(x,y):\n    x_sum = x.copy()\n    for i in range(1,len(df)):\n        if y[i] > 0: x_sum[i] = x_sum[i-1] + x[i]\n    return x_sum\n\ndf['desired_result'] = custom_sum( df.x.to_numpy(), df.y.to_numpy() )\n \n Admittedly, there's a bit of overhead there required to convert DataFrame columns to NumPy arrays, but the core piece of code is just one line of code that you could read even if you didn't know anything about Pandas or NumPy: \n if y[i] > 0: x_sum[i] = x_sum[i-1] + x[i]\n \n And this code is actually  faster  than the vectorized code.  In some quick tests with 100,000 rows, the above is about 10x faster than the  groupby  approach.  Note that one key to the speed there is numba, which is optional.  Without the \"@nb.jit\" line, the looping code is actually about 10x slower than the  groupby  approach. \n Clearly this example is simple enough that you would likely prefer the one line of pandas to writing a loop with its associated overhead.  However, there are more complex versions of this problem for which the readability or speed of the NumPy/numba loop approach likely makes sense. \n    ", "date_posted": "2021-07-23 18:29:01Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "3877338", "name": "JohnE", "reputation_score": "27.1k"}, "answer_comments": []}, {"stack_answer_id": "68233908", "answer_content": "\r\n df.iterrows()  returns  tuple(a, b)  where  a  is the  index  and  b  is the  row . \n    ", "date_posted": "2022-03-31 07:36:53Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "9534390", "name": "pythonic833", "reputation_score": "2,904"}, "answer_comments": []}, {"stack_answer_id": "47598852", "answer_content": "\r\n You can also do NumPy indexing for even greater speed ups. It's not really iterating but works much better than iteration for certain applications. \n\n subset = row['c1'][0:5]\nall = row['c1'][:]\n \n\n You may also want to cast it to an array. These indexes/selections are supposed to act like NumPy arrays already, but I ran into issues and needed to cast \n\n np.asarray(all)\nimgs[:] = cv2.resize(imgs[:], (224,224) ) # Resize every image in an hdf5 file\n \n    ", "date_posted": "2020-06-11 13:37:16Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "71234113", "answer_content": "\r\n Disclaimer:  Although here are so many answers which recommend  not  using an iterative (loop) approach (and I mostly agree), I would still see it as a reasonable approach for the following situation: \n Extend dataframe with data from API \n Let's say you have a large dataframe which contains incomplete user data. Now you have to extend this data with additional columns, for example the user's  age  and  gender . \n Both values have to be fetched from a backend API. I'm assuming the API doesn't provide a \"batch\" endpoint (which would accept multiple user IDs at once). Otherwise, you should rather call the API only once. \n The costs (waiting time) for the network request surpass the iteration of the dataframe by far. We're talking about network roundtrip times of hundreds of milliseconds compared to the negligibly small gains in using alternative approaches to iterations. \n 1 expensive network request for each row \n So in this case, I would absolutely prefer using an iterative approach. Although the network request is expensive, it is guaranteed being triggered only once for each row in the dataframe. Here is an example using  DataFrame.iterrows : \n Example \n for index, row in users_df.iterrows():\n  user_id = row['user_id']\n  # trigger expensive network request once for each row\n  response_dict = backend_api.get(f'/api/user-data/{user_id}')\n  # extend dataframe with multiple data from response\n  users_df.at[index, 'age'] = response_dict.get('age')\n  users_df.at[index, 'gender'] = response_dict.get('gender')\n \n    ", "date_posted": "2022-04-08 16:02:59Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "2472398", "name": "gru", "reputation_score": "1,480"}, "answer_comments": []}, {"stack_answer_id": "55202153", "answer_content": "\r\n This example uses iloc to isolate each digit in the data frame.  \n\n import pandas as pd\n\n a = [1, 2, 3, 4]\n b = [5, 6, 7, 8]\n\n mjr = pd.DataFrame({'a':a, 'b':b})\n\n size = mjr.shape\n\n for i in range(size[0]):\n     for j in range(size[1]):\n         print(mjr.iloc[i, j])\n \n    ", "date_posted": "2019-03-16 22:33:02Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "8042986", "name": "mjr2000", "reputation_score": "90"}, "answer_comments": []}, {"stack_answer_id": "59264161", "answer_content": "\r\n Some libraries (e.g. a Java interop library that I use) require values to be passed in a row at a time, for example, if streaming data. To replicate the streaming nature, I 'stream' my dataframe values one by one, I wrote the below, which comes in handy from time to time. \n\n class DataFrameReader:\n  def __init__(self, df):\n    self._df = df\n    self._row = None\n    self._columns = df.columns.tolist()\n    self.reset()\n    self.row_index = 0\n\n  def __getattr__(self, key):\n    return self.__getitem__(key)\n\n  def read(self) -> bool:\n    self._row = next(self._iterator, None)\n    self.row_index += 1\n    return self._row is not None\n\n  def columns(self):\n    return self._columns\n\n  def reset(self) -> None:\n    self._iterator = self._df.itertuples()\n\n  def get_index(self):\n    return self._row[0]\n\n  def index(self):\n    return self._row[0]\n\n  def to_dict(self, columns: List[str] = None):\n    return self.row(columns=columns)\n\n  def tolist(self, cols) -> List[object]:\n    return [self.__getitem__(c) for c in cols]\n\n  def row(self, columns: List[str] = None) -> Dict[str, object]:\n    cols = set(self._columns if columns is None else columns)\n    return {c : self.__getitem__(c) for c in self._columns if c in cols}\n\n  def __getitem__(self, key) -> object:\n    # the df index of the row is at index 0\n    try:\n        if type(key) is list:\n            ix = [self._columns.index(key) + 1 for k in key]\n        else:\n            ix = self._columns.index(key) + 1\n        return self._row[ix]\n    except BaseException as e:\n        return None\n\n  def __next__(self) -> 'DataFrameReader':\n    if self.read():\n        return self\n    else:\n        raise StopIteration\n\n  def __iter__(self) -> 'DataFrameReader':\n    return self\n \n\n Which can be used: \n\n for row in DataFrameReader(df):\n  print(row.my_column_name)\n  print(row.to_dict())\n  print(row['my_column_name'])\n  print(row.tolist())\n \n\n And preserves the values/ name mapping for the rows being iterated. Obviously, is a lot slower than using apply and Cython as indicated above, but is necessary in some circumstances. \n    ", "date_posted": "2019-12-10 09:36:45Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "6690508", "name": "morganics", "reputation_score": "1,111"}, "answer_comments": []}, {"stack_answer_id": "64177887", "answer_content": "\r\n Along with the great answers in this post I am going to propose  Divide and Conquer  approach, I am not writing this answer to abolish the other great answers but to fulfill them with another approach which was working efficiently for me. It has two steps of  splitting  and  merging  the pandas dataframe: \n PROS of Divide and Conquer: \n \n You don't need to use vectorization or any other methods to cast the type of your dataframe into another type \n You don't need to Cythonize your code which normally takes extra time from you \n Both  iterrows()  and  itertuples()  in my case were having the same performance over entire dataframe \n Depends on your choice of slicing  index , you will be able to exponentially quicken the iteration. The higher  index , the quicker your iteration process. \n \n CONS of Divide and Conquer: \n \n You shouldn't have dependency over the iteration process to the same dataframe and different  slice . Meaning if you want to read or write from other  slice , it maybe difficult to do that. \n \n ===================    Divide and Conquer Approach    ================= \n Step 1: Splitting/Slicing \n In this step, we are going to divide the iteration over the entire dataframe. Think that you are going to read a csv file into pandas df then iterate over it. In may case I have 5,000,000 records and I am going to split it into 100,000 records. \n NOTE:  I need to reiterate as other runtime analysis explained in the other solutions in this page, \"number of records\" has exponential proportion of \"runtime\" on search on the df. Based on the benchmark on my data here are the results: \n Number of records | Iteration per second\n========================================\n100,000           | 500 it/s\n500,000           | 200 it/s\n1,000,000         | 50 it/s\n5,000,000         | 20 it/s\n \n Step 2: Merging \n This is going to be an easy step, just merge all the written csv files into one dataframe and write it into a bigger csv file. \n Here is the sample code: \n # Step 1 (Splitting/Slicing)\nimport pandas as pd\ndf_all = pd.read_csv('C:/KtV.csv')\ndf_index = 100000\ndf_len = len(df)\nfor i in range(df_len // df_index + 1):\n    lower_bound = i * df_index \n    higher_bound = min(lower_bound + df_index, df_len)\n    # splitting/slicing df (make sure to copy() otherwise it will be a view\n    df = df_all[lower_bound:higher_bound].copy()\n    '''\n    write your iteration over the sliced df here\n    using iterrows() or intertuples() or ...\n    '''\n    # writing into csv files\n    df.to_csv('C:/KtV_prep_'+str(i)+'.csv')\n\n\n\n# Step 2 (Merging)\nfilename='C:/KtV_prep_'\ndf = (pd.read_csv(f) for f in [filename+str(i)+'.csv' for i in range(ktv_len // ktv_index + 1)])\ndf_prep_all = pd.concat(df)\ndf_prep_all.to_csv('C:/KtV_prep_all.csv')\n \n Reference: \n Efficient way of iteration over datafreame \n Concatenate csv files into one Pandas Dataframe \n    ", "date_posted": "2020-10-31 13:57:20Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "6117017", "name": "Timbus Calin", "reputation_score": "12.2k"}, "answer_comments": []}, {"stack_answer_id": "67701850", "answer_content": "\r\n As  the accepted answer  states, the fastest way to apply a function over rows is to use a  vectorized function , the so-called NumPy  ufuncs  (universal functions). \n But what should you do when the function you want to apply isn't already implemented in NumPy? \n Well, using the  vectorize  decorator from  numba , you can easily create ufuncs directly in Python like this: \n from numba import vectorize, float64\n\n@vectorize([float64(float64)])\ndef f(x):\n    #x is your line, do something with it, and return a float\n \n The documentation for this function is here:  Creating NumPy universal functions \n    ", "date_posted": "2022-01-05 20:48:26Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "68562557", "answer_content": "\r\n Probably the most elegant solution (but certainly not the most efficient): \n for row in df.values:\n    c2 = row[1]\n    print(row)\n    # ...\n\nfor c1, c2 in df.values:\n    # ...\n \n Note that: \n \n the  documentation  explicitly recommends to use  .to_numpy()  instead \n the produced NumPy array will have a dtype that fits all columns, in the worst case  object \n there are  good reasons  not to use a loop in the first place \n \n Still, I think this option should be included here, as a straight-forward solution to a (one should think) trivial problem. \n    ", "date_posted": "2021-08-02 10:04:04Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "4248897", "name": "Ernesto Els\u00e4\u00dfer", "reputation_score": "694"}, "answer_comments": []}], "user": {"stack_user_id": "245549", "name": "Roman", "reputation_score": "115k"}, "question_comments": [{"stack_question_id": "16476924", "stack_question_comment_id": "82610234", "comment_content": "The df.iteritems() iterates over columns and not rows. Thus, to make it iterate over rows, you have to transpose (the \"T\"), which means you change rows and columns into each other (reflect over diagonal). As a result, you effectively iterate the original dataframe over its rows when you use df.T.iteritems()", "user_id": null}, {"stack_question_id": "16476924", "stack_question_comment_id": "103162518", "comment_content": "In contrast to what cs95 says, there are perfectly fine reasons to want to iterate over a dataframe, so new users should not feel discouraged. One example is if you want to execute some code using the values of each row as input. Also, if your dataframe is reasonably small (e.g. less than 1000 items), performance is not really an issue.", "user_id": null}, {"stack_question_id": "16476924", "stack_question_comment_id": "104047003", "comment_content": "@cs95 It seems to me that dataframes are the go-to table format in Python. So whenever you want to read in a csv, or you have a list of dicts whose values you want to manipulate, or you want to perform simple join, groupby or window operations, you use a dataframe, even if your data is comparitively small.", "user_id": null}, {"stack_question_id": "16476924", "stack_question_comment_id": "104053145", "comment_content": "@cs95 No, but this was in response to \"using a DataFrame at all\". My point is that this is why one may have one's data in a dataframe. If you then want to e.g. run a script for each line of your data, you have to iterate over that dataframe.", "user_id": null}, {"stack_question_id": "16476924", "stack_question_comment_id": "104107821", "comment_content": "I second @oulenz. As far as I can tell ", "user_id": null}]},
{"stack_question_id": "2158395", "question_title": "Flatten an irregular list of lists", "question_content": "\r\n                Yes, I know this subject has been covered before (here, here, here, here), but as far as I know, all solutions, except for one, fail on a list like this:\n\nL = [[[1, 2, 3], [4, 5]], 6]\r\nWhere the ...\r\n", "question_url": "/questions/2158395/flatten-an-irregular-list-of-lists", "date_posted": "Jan 28, 2010 at 22:15", "upvote": "5", "view": "1", "tags": ["python", "list", "optimization", "nested-lists", "flatten"], "answers_count": "5", "answers": [{"stack_answer_id": "2158532", "answer_content": "\r\n Using generator functions can make your example easier to read and improve performance. \n Python 2 \n Using the  Iterable  ABC  added in 2.6: \n from collections import Iterable\n\ndef flatten(xs):\n    for x in xs:\n        if isinstance(x, Iterable) and not isinstance(x, basestring):\n            for item in flatten(x):\n                yield item\n        else:\n            yield x\n \n Python 3 \n In Python 3,  basestring  is no more, but the tuple  (str, bytes)  gives the same effect. Also, the  yield from  operator returns an item from a generator one at a time. \n from collections.abc import Iterable\n\ndef flatten(xs):\n    for x in xs:\n        if isinstance(x, Iterable) and not isinstance(x, (str, bytes)):\n            yield from flatten(x)\n        else:\n            yield x\n \n    ", "date_posted": "2022-05-22 20:17:07Z", "upvote": "\r\n            448\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": [{"stack_answer_id": "2158532", "stack_answer_comment_id": "14265381", "comment_content": "Of all the suggestions on this page, this is the only one that flattened this list ", "user_id": null}, {"stack_answer_id": "2158532", "stack_answer_comment_id": "49961116", "comment_content": "This also flattens dictionaries. Maybe you want to use ", "user_id": null}, {"stack_answer_id": "2158532", "stack_answer_comment_id": "52038449", "comment_content": "This doesn't work with things that aren't lists initially, e.g. ", "user_id": null}, {"stack_answer_id": "2158532", "stack_answer_comment_id": "92094122", "comment_content": "For Python 3.7, using ", "user_id": null}, {"stack_answer_id": "2158532", "stack_answer_comment_id": "96939998", "comment_content": "Indeed, recursion is ", "user_id": null}]}, {"stack_answer_id": "2158522", "answer_content": "\r\n My solution: \n\n import collections\n\n\ndef flatten(x):\n    if isinstance(x, collections.Iterable):\n        return [a for i in x for a in flatten(i)]\n    else:\n        return [x]\n \n\n A little more concise, but pretty much the same. \n    ", "date_posted": "2019-05-23 12:18:40Z", "upvote": "\r\n            62\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "2158522", "stack_answer_comment_id": "25410021", "comment_content": "You can do this without importing anything if you just ", "user_id": null}, {"stack_answer_id": "2158522", "stack_answer_comment_id": "43136613", "comment_content": "Worth to note that this solution works only if all the items are of type ", "user_id": null}, {"stack_answer_id": "2158522", "stack_answer_comment_id": "77581475", "comment_content": "Could make it more concise, ", "user_id": null}, {"stack_answer_id": "2158522", "stack_answer_comment_id": "93943979", "comment_content": "this doesn't work on strings because strings are iterable too. Replace the condition with ", "user_id": null}, {"stack_answer_id": "2158522", "stack_answer_comment_id": "110395399", "comment_content": "replace ", "user_id": null}]}, {"stack_answer_id": "14491059", "answer_content": "\r\n Generator using recursion and duck typing (updated for Python 3): \n\n def flatten(L):\n    for item in L:\n        try:\n            yield from flatten(item)\n        except TypeError:\n            yield item\n\nlist(flatten([[[1, 2, 3], [4, 5]], 6]))\n>>>[1, 2, 3, 4, 5, 6]\n \n    ", "date_posted": "2015-09-08 15:01:25Z", "upvote": "\r\n            46\r\n        ", "accepted": "No", "user": {"stack_user_id": "1355221", "name": "dansalmo", "reputation_score": "11.1k"}, "answer_comments": [{"stack_answer_id": "14491059", "stack_answer_comment_id": "52784011", "comment_content": "Thanks, that works nice for Python 3.  For 2.x the previous is needed:  ", "user_id": null}, {"stack_answer_id": "14491059", "stack_answer_comment_id": "85707692", "comment_content": "list(flatten([['X'], 'Y'])) fails on 2.X variant", "user_id": null}, {"stack_answer_id": "14491059", "stack_answer_comment_id": "85750061", "comment_content": "@user1019129 see my comment above yours", "user_id": null}, {"stack_answer_id": "14491059", "stack_answer_comment_id": "85788346", "comment_content": "yes it fails with the cycle.. i think because a string is also an \"array\"-of-chars", "user_id": null}]}, {"stack_answer_id": "5409395", "answer_content": "\r\n Here is my functional version of recursive flatten which handles both tuples and lists, and lets you throw in any mix of positional arguments. Returns a generator which produces the entire sequence in order, arg by arg: \n\n flatten = lambda *n: (e for a in n\n    for e in (flatten(*a) if isinstance(a, (tuple, list)) else (a,)))\n \n\n Usage: \n\n l1 = ['a', ['b', ('c', 'd')]]\nl2 = [0, 1, (2, 3), [[4, 5, (6, 7, (8,), [9]), 10]], (11,)]\nprint list(flatten(l1, -2, -1, l2))\n['a', 'b', 'c', 'd', -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n \n    ", "date_posted": "2011-03-23 17:42:24Z", "upvote": "\r\n            39\r\n        ", "accepted": "No", "user": {"stack_user_id": "538718", "name": "samplebias", "reputation_score": "36k"}, "answer_comments": [{"stack_answer_id": "5409395", "stack_answer_comment_id": "29945046", "comment_content": "great solution, however would be much helpful if you added some comment to describe what ", "user_id": null}, {"stack_answer_id": "5409395", "stack_answer_comment_id": "31445589", "comment_content": "@WolfgangKuehne: Try ", "user_id": null}, {"stack_answer_id": "5409395", "stack_answer_comment_id": "51406248", "comment_content": "This is significantly faster than ", "user_id": null}, {"stack_answer_id": "5409395", "stack_answer_comment_id": "111812784", "comment_content": "This is the only solution I have come across, in a moderate google search, on any website that actually works for lists nested deeper than one level.", "user_id": null}, {"stack_answer_id": "5409395", "stack_answer_comment_id": "114103535", "comment_content": "This is a work of art. So few characters, and still nearly impossible to understand. 10/10 best Python code golf I've seen yet \ud83c\udfcc\ufe0f\u200d\u2642\ufe0f\ud83c\udfcc\ufe0f\u200d\u2640\ufe0f\u26f3\ufe0f.  Having something this short almost makes up for the fact that Python doesn't have a built-in flatten function.", "user_id": null}]}, {"stack_answer_id": "2159079", "answer_content": "\r\n Generator version of @unutbu's non-recursive solution, as requested by @Andrew in a comment: \n\n def genflat(l, ltypes=collections.Sequence):\n    l = list(l)\n    i = 0\n    while i < len(l):\n        while isinstance(l[i], ltypes):\n            if not l[i]:\n                l.pop(i)\n                i -= 1\n                break\n            else:\n                l[i:i + 1] = l[i]\n        yield l[i]\n        i += 1\n \n\n Slightly simplified version of this generator: \n\n def genflat(l, ltypes=collections.Sequence):\n    l = list(l)\n    while l:\n        while l and isinstance(l[0], ltypes):\n            l[0:1] = l[0]\n        if l: yield l.pop(0)\n \n    ", "date_posted": "2010-01-29 00:27:22Z", "upvote": "\r\n            36\r\n        ", "accepted": "No", "user": {"stack_user_id": "95810", "name": "Alex Martelli", "reputation_score": "820k"}, "answer_comments": [{"stack_answer_id": "2159079", "stack_answer_comment_id": "2104766", "comment_content": "it's a pre-order traversal of the tree formed by the nested lists.  only the leaves are returned.  Note that this implementation will consume the original data structure, for better or worse.  Could be fun to write one that both preserves the original tree, but also doesn't have to copy the list entries.", "user_id": null}, {"stack_answer_id": "2159079", "stack_answer_comment_id": "4686862", "comment_content": "I think you need to test for strings -- eg add \"and not isinstance(l[0], basestring)\" as in Cristian's solution. Otherwise you get an infinite loop around l[0:1] = l[0]", "user_id": null}, {"stack_answer_id": "2159079", "stack_answer_comment_id": "17780727", "comment_content": "This is a good example of making a generator, but as c-urchin mentions, the algorithm itself fails when the sequence contains strings.", "user_id": null}]}, {"stack_answer_id": "2158562", "answer_content": "\r\n This version of  flatten  avoids python's recursion limit (and thus works with arbitrarily deep, nested iterables). It is a generator which can handle strings and arbitrary iterables (even infinite ones). \n\n import itertools as IT\nimport collections\n\ndef flatten(iterable, ltypes=collections.Iterable):\n    remainder = iter(iterable)\n    while True:\n        first = next(remainder)\n        if isinstance(first, ltypes) and not isinstance(first, (str, bytes)):\n            remainder = IT.chain(first, remainder)\n        else:\n            yield first\n \n\n Here are some examples demonstrating its use: \n\n print(list(IT.islice(flatten(IT.repeat(1)),10)))\n# [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n\nprint(list(IT.islice(flatten(IT.chain(IT.repeat(2,3),\n                                       {10,20,30},\n                                       'foo bar'.split(),\n                                       IT.repeat(1),)),10)))\n# [2, 2, 2, 10, 20, 30, 'foo', 'bar', 1, 1]\n\nprint(list(flatten([[1,2,[3,4]]])))\n# [1, 2, 3, 4]\n\nseq = ([[chr(i),chr(i-32)] for i in range(ord('a'), ord('z')+1)] + list(range(0,9)))\nprint(list(flatten(seq)))\n# ['a', 'A', 'b', 'B', 'c', 'C', 'd', 'D', 'e', 'E', 'f', 'F', 'g', 'G', 'h', 'H',\n# 'i', 'I', 'j', 'J', 'k', 'K', 'l', 'L', 'm', 'M', 'n', 'N', 'o', 'O', 'p', 'P',\n# 'q', 'Q', 'r', 'R', 's', 'S', 't', 'T', 'u', 'U', 'v', 'V', 'w', 'W', 'x', 'X',\n# 'y', 'Y', 'z', 'Z', 0, 1, 2, 3, 4, 5, 6, 7, 8]\n \n\n Although  flatten  can handle infinite generators, it can not handle infinite nesting: \n\n def infinitely_nested():\n    while True:\n        yield IT.chain(infinitely_nested(), IT.repeat(1))\n\nprint(list(IT.islice(flatten(infinitely_nested()), 10)))\n# hangs\n \n    ", "date_posted": "2019-05-23 12:53:56Z", "upvote": "\r\n            33\r\n        ", "accepted": "No", "user": {"stack_user_id": "190597", "name": "unutbu", "reputation_score": "791k"}, "answer_comments": [{"stack_answer_id": "2158562", "stack_answer_comment_id": "27754234", "comment_content": "any consensus on whether to use ABC Iterable or ABC Sequence?", "user_id": null}, {"stack_answer_id": "2158562", "stack_answer_comment_id": "27754354", "comment_content": ", ", "user_id": null}, {"stack_answer_id": "2158562", "stack_answer_comment_id": "27804882", "comment_content": "@wim: One problem with using ", "user_id": null}, {"stack_answer_id": "2158562", "stack_answer_comment_id": "99165386", "comment_content": "This doesn't seem to work for the 3rd and the 4th examples. It throws ", "user_id": null}, {"stack_answer_id": "2158562", "stack_answer_comment_id": "106796892", "comment_content": "@Georgy this could be fixed with encapsulating the body of flatten in a ", "user_id": null}]}, {"stack_answer_id": "4590652", "answer_content": "\r\n def flatten(xs):\n    res = []\n    def loop(ys):\n        for i in ys:\n            if isinstance(i, list):\n                loop(i)\n            else:\n                res.append(i)\n    loop(xs)\n    return res\n \n    ", "date_posted": "2012-08-21 14:39:45Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "348785", "name": "kev", "reputation_score": "148k"}, "answer_comments": [{"stack_answer_id": "4590652", "stack_answer_comment_id": "121983372", "comment_content": "This looks very elegant and simple. Why it does not have more upvotes? Are there any problems with this solution?", "user_id": null}, {"stack_answer_id": "4590652", "stack_answer_comment_id": "129064569", "comment_content": "This is a brilliant solution!", "user_id": null}]}, {"stack_answer_id": "4694575", "answer_content": "\r\n Here's another answer that is even more interesting... \n import re\n\ndef Flatten(TheList):\n    a = str(TheList)\n    b,_Anon = re.subn(r'[\\[,\\]]', ' ', a)\n    c = b.split()\n    d = [int(x) for x in c]\n\n    return(d)\n \n Basically, it converts the nested list to a string, uses a regex to strip out the nested syntax, and then converts the result back to a (flattened) list. \n    ", "date_posted": "2021-01-20 14:15:09Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "392301", "name": "clay", "reputation_score": "1,677"}, "answer_comments": [{"stack_answer_id": "4694575", "stack_answer_comment_id": "40277369", "comment_content": "If you try to generalize this to something other than int values, it'll be fun with, e.g., ", "user_id": null}, {"stack_answer_id": "4694575", "stack_answer_comment_id": "40293216", "comment_content": "The original prompt was about flattening a list of integers. If you just change the list comprehension to d=[x for x in c] it should work fine for your sample.", "user_id": null}, {"stack_answer_id": "4694575", "stack_answer_comment_id": "40305748", "comment_content": "First, ", "user_id": null}, {"stack_answer_id": "4694575", "stack_answer_comment_id": "40313909", "comment_content": "Ha! The way your comment got formatted on my computer, I didn't even realize that was supposed to be Apple II as it appeared on the old computers. In any case, my answer to both your questions is that this exercise--for me--is merely an experiment to find a creative solution to flattening a list. I'm not sure I would generalize it to flattening every list out there.", "user_id": null}, {"stack_answer_id": "4694575", "stack_answer_comment_id": "95431251", "comment_content": "You just need to ", "user_id": null}]}, {"stack_answer_id": "17868434", "answer_content": "\r\n It was fun trying to create a function that could flatten irregular list in Python, but of course that is what Python is for (to make programming fun). The following generator works fairly well with some caveats: \n\n def flatten(iterable):\n    try:\n        for item in iterable:\n            yield from flatten(item)\n    except TypeError:\n        yield iterable\n \n\n It will flatten datatypes that you might want left alone (like  bytearray ,  bytes , and  str  objects). Also, the code relies on the fact that requesting an iterator from a non-iterable raises a  TypeError . \n\n >>> L = [[[1, 2, 3], [4, 5]], 6]\n>>> def flatten(iterable):\n    try:\n        for item in iterable:\n            yield from flatten(item)\n    except TypeError:\n        yield iterable\n\n\n>>> list(flatten(L))\n[1, 2, 3, 4, 5, 6]\n>>>\n \n\n \n\n Edit: \n\n I disagree with the previous implementation. The problem is that you should not be able to flatten something that is not an iterable. It is confusing and gives the wrong impression of the argument. \n\n >>> list(flatten(123))\n[123]\n>>>\n \n\n The following generator is almost the same as the first but does not have the problem of trying to flatten a non-iterable object. It fails as one would expect when an inappropriate argument is given to it. \n\n def flatten(iterable):\n    for item in iterable:\n        try:\n            yield from flatten(item)\n        except TypeError:\n            yield item\n \n\n Testing the generator works fine with the list that was provided. However, the new code will raise a  TypeError  when a non-iterable object is given to it. Example are shown below of the new behavior. \n\n >>> L = [[[1, 2, 3], [4, 5]], 6]\n>>> list(flatten(L))\n[1, 2, 3, 4, 5, 6]\n>>> list(flatten(123))\nTraceback (most recent call last):\n  File \"<pyshell#32>\", line 1, in <module>\n    list(flatten(123))\n  File \"<pyshell#27>\", line 2, in flatten\n    for item in iterable:\nTypeError: 'int' object is not iterable\n>>>\n \n    ", "date_posted": "2014-08-28 13:51:28Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "216356", "name": "Noctis Skytower", "reputation_score": "20.6k"}, "answer_comments": []}, {"stack_answer_id": "45390129", "answer_content": "\r\n You could use  deepflatten  from the 3rd party package  iteration_utilities : \n\n >>> from iteration_utilities import deepflatten\n>>> L = [[[1, 2, 3], [4, 5]], 6]\n>>> list(deepflatten(L))\n[1, 2, 3, 4, 5, 6]\n\n>>> list(deepflatten(L, types=list))  # only flatten \"inner\" lists\n[1, 2, 3, 4, 5, 6]\n \n\n It's an iterator so you need to iterate it (for example by wrapping it with  list  or using it in a loop). Internally it uses an iterative approach instead of an recursive approach and it's written as C extension so it can be faster than pure python approaches: \n\n >>> %timeit list(deepflatten(L))\n12.6 \u00b5s \u00b1 298 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n>>> %timeit list(deepflatten(L, types=list))\n8.7 \u00b5s \u00b1 139 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n\n>>> %timeit list(flatten(L))   # Cristian - Python 3.x approach from https://stackoverflow.com/a/2158532/5393381\n86.4 \u00b5s \u00b1 4.42 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\n\n>>> %timeit list(flatten(L))   # Josh Lee - https://stackoverflow.com/a/2158522/5393381\n107 \u00b5s \u00b1 2.99 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\n\n>>> %timeit list(genflat(L, list))  # Alex Martelli - https://stackoverflow.com/a/2159079/5393381\n23.1 \u00b5s \u00b1 710 ns per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\n \n\n \n\n I'm the author of the  iteration_utilities  library. \n    ", "date_posted": "2017-07-29 14:01:42Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "5393381", "name": "MSeifert", "reputation_score": "136k"}, "answer_comments": []}, {"stack_answer_id": "20495215", "answer_content": "\r\n Here's a simple function that flattens lists of arbitrary depth. No recursion, to avoid stack overflow. \n\n from copy import deepcopy\n\ndef flatten_list(nested_list):\n    \"\"\"Flatten an arbitrarily nested list, without recursion (to avoid\n    stack overflows). Returns a new list, the original list is unchanged.\n\n    >> list(flatten_list([1, 2, 3, [4], [], [[[[[[[[[5]]]]]]]]]]))\n    [1, 2, 3, 4, 5]\n    >> list(flatten_list([[1, 2], 3]))\n    [1, 2, 3]\n\n    \"\"\"\n    nested_list = deepcopy(nested_list)\n\n    while nested_list:\n        sublist = nested_list.pop(0)\n\n        if isinstance(sublist, list):\n            nested_list = sublist + nested_list\n        else:\n            yield sublist\n \n    ", "date_posted": "2013-12-10 14:55:11Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "509706", "name": "Wilfred Hughes", "reputation_score": "28.2k"}, "answer_comments": [{"stack_answer_id": "20495215", "stack_answer_comment_id": "95431976", "comment_content": "Yes! Very similar to my code at ", "user_id": null}, {"stack_answer_id": "20495215", "stack_answer_comment_id": "127199352", "comment_content": "This could be made much more efficient by using ", "user_id": null}]}, {"stack_answer_id": "64517529", "answer_content": "\r\n Pandas has a function that does this. It returns an iterator as you mentioned. \n In [1]: import pandas\nIn [2]: pandas.core.common.flatten([[[1, 2, 3], [4, 5]], 6])\nOut[2]: <generator object flatten at 0x7f12ade66200>\nIn [3]: list(pandas.core.common.flatten([[[1, 2, 3], [4, 5]], 6]))\nOut[3]: [1, 2, 3, 4, 5, 6]\n \n    ", "date_posted": "2020-10-24 20:03:15Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "116", "name": "Mark Harrison", "reputation_score": "287k"}, "answer_comments": [{"stack_answer_id": "64517529", "stack_answer_comment_id": "116168058", "comment_content": "Great stuff! For people (like me) who are using pandas anyway, this is a beautifully simple way", "user_id": null}]}, {"stack_answer_id": "5226060", "answer_content": "\r\n Although an elegant and very pythonic answer has been selected I would present my solution just for the review: \n\n def flat(l):\n    ret = []\n    for i in l:\n        if isinstance(i, list) or isinstance(i, tuple):\n            ret.extend(flat(i))\n        else:\n            ret.append(i)\n    return ret\n \n\n Please tell how good or bad this code is? \n    ", "date_posted": "2011-03-07 22:32:07Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "69746", "name": "Xolve", "reputation_score": "21.3k"}, "answer_comments": [{"stack_answer_id": "5226060", "stack_answer_comment_id": "25450076", "comment_content": "Use ", "user_id": null}, {"stack_answer_id": "5226060", "stack_answer_comment_id": "35343653", "comment_content": " will get you the same container type back as was passed in, also. :)", "user_id": null}, {"stack_answer_id": "5226060", "stack_answer_comment_id": "35429281", "comment_content": "@dash-tom-bang Can you please explain what it means in a bit detail.", "user_id": null}, {"stack_answer_id": "5226060", "stack_answer_comment_id": "37392303", "comment_content": "If you pass in a list, you probably want a list back. If you pass in a tuple, you probably want a tuple back. If you pass in a mishmash of the two, you'll get whatever the outer enclosing thing was.", "user_id": null}]}, {"stack_answer_id": "4676482", "answer_content": "\r\n I prefer simple answers.  No generators.  No recursion or recursion limits.  Just iteration: \n\n def flatten(TheList):\n    listIsNested = True\n\n    while listIsNested:                 #outer loop\n        keepChecking = False\n        Temp = []\n\n        for element in TheList:         #inner loop\n            if isinstance(element,list):\n                Temp.extend(element)\n                keepChecking = True\n            else:\n                Temp.append(element)\n\n        listIsNested = keepChecking     #determine if outer loop exits\n        TheList = Temp[:]\n\n    return TheList\n \n\n This works with two lists: an inner for loop and an outer while loop.   \n\n The inner for loop iterates through the list.  If it finds a list element, it (1) uses list.extend() to flatten that part one level of nesting and (2) switches keepChecking to True.  keepchecking is used to control the outer while loop.  If the outer loop gets set to true, it triggers the inner loop for another pass.   \n\n Those passes keep happening until no more nested lists are found.  When a pass finally occurs where none are found, keepChecking never gets tripped to true, which means listIsNested stays false and the outer while loop exits.   \n\n The flattened list is then returned. \n\n Test-run    \n\n flatten([1,2,3,4,[100,200,300,[1000,2000,3000]]])\n \n\n [1, 2, 3, 4, 100, 200, 300, 1000, 2000, 3000] \n    ", "date_posted": "2011-01-13 04:16:53Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "392301", "name": "clay", "reputation_score": "1,677"}, "answer_comments": [{"stack_answer_id": "4676482", "stack_answer_comment_id": "5159157", "comment_content": "I like simple too.  In this case though, you iterate over the list as many times as there are nestings or levels.  Could get expensive.", "user_id": "/users/215679/telliott99"}, {"stack_answer_id": "4676482", "stack_answer_comment_id": "5176210", "comment_content": "@telliott99: You're right if your lists are really big and/or nested to great depths.  However, if that isn't the case, then the simpler solution works just as well, and without the deep magic of some of the other answers.  There is a place for multi-stage recursive generator comprehensions, but I'm not convinced that should be where you look first.  (I guess you know where I fall in the \"Worse is Better\" debate.)", "user_id": null}, {"stack_answer_id": "4676482", "stack_answer_comment_id": "5176316", "comment_content": "@telliott99: Or to put that another way, you won't have to \"try to Grok\" my solution.  If performance isn't a bottleneck, what matters most to you as a programmer?", "user_id": null}, {"stack_answer_id": "4676482", "stack_answer_comment_id": "35343606", "comment_content": "Simpler solutions have less logic. Recursion is a pretty fundamental programming construct that anyone who considers themselves a programmer should be completely comfortable with. Generators are very much the Python Way and (along with comprehensions) are something that any professional Python programmer should grok instantly.", "user_id": null}, {"stack_answer_id": "4676482", "stack_answer_comment_id": "35348551", "comment_content": "I agree about recursion. When I wrote my answer, python still broke recursion at 1000 cycles. Have they changed this? As for being a professional python programmer, I'm not. Moreover, I imagine many people programming in python do not do so full time.", "user_id": null}]}, {"stack_answer_id": "51649649", "answer_content": "\r\n When trying to answer such a question you really need to give the limitations of the code you propose as a solution. If it was only about performances I wouldn't mind too much, but most of the codes proposed as solution (including the accepted answer) fail to flatten any list that has a depth greater than 1000. \n\n When I say  most of the codes  I mean all codes that use any form of recursion (or call a standard library function that is recursive). All these codes fail because for every of the recursive call made, the (call) stack grow by one unit, and the (default) python call stack has a size of 1000.  \n\n If you're not too familiar with the call stack, then maybe the following will help (otherwise you can just scroll to the  Implementation ). \n\n Call stack size and recursive programming (dungeon analogy) \n\n Finding the treasure and exit \n\n Imagine you enter a huge  dungeon with numbered rooms , looking for a treasure. You don't know the place but you have some  indications  on how to find the treasure. Each indication is a riddle (difficulty varies, but you can't predict how hard they will be). You decide to think a little bit about a strategy to save time, you make two observations:  \n\n \n It's hard (long) to find the treasure as you'll have to solve (potentially hard) riddles to get there.  \n Once the treasure found, returning to the entrance may be easy, you just have to use the same path in the other direction (though this needs a bit of memory to recall your path).  \n \n\n When entering the dungeon, you notice a small  notebook  here. You decide to use it to write down every room you exit after solving a riddle (when entering a new room), this way you'll be able to return back to the entrance. That's a genius idea, you  won't even spend a cent  implementing your strategy. \n\n You enter the dungeon, solving with great success the first 1001 riddles, but here comes something you hadn't planed, you have no space left in the notebook you borrowed. You decide to  abandon  your quest as you prefer not having the treasure than being lost forever inside the dungeon (that looks smart indeed). \n\n Executing a recursive program \n\n Basically, it's the exact same thing as finding the treasure. The dungeon is the  computer's memory , your goal now is not to find a treasure but to  compute some function  (find  f(x)  for a given  x ). The indications simply are sub-routines that will help you solving  f(x) . Your strategy is the same as the  call stack  strategy, the notebook is the stack, the rooms are the functions' return addresses:  \n\n x = [\"over here\", \"am\", \"I\"]\ny = sorted(x) # You're about to enter a room named `sorted`, note down the current room address here so you can return back: 0x4004f4 (that room address looks weird)\n# Seems like you went back from your quest using the return address 0x4004f4\n# Let's see what you've collected \nprint(' '.join(y))\n \n\n The problem you encountered in the dungeon will be the same here, the call stack has a finite size (here 1000) and therefore, if you enter too many functions without returning back then you'll fill the call stack and have an error that look like  \"Dear adventurer, I'm very sorry but your notebook is full\" :  RecursionError: maximum recursion depth exceeded . Note that you don't need recursion to fill the call stack, but it's very unlikely that a non-recursive program call 1000 functions without ever returning. It's important to also understand that once you returned from a function, the call stack is freed from the address used (hence the name \"stack\", return address are pushed in before entering a function and pulled out when returning). In the special case of a simple recursion (a function  f  that call itself once -- over and over --) you will enter  f  over and over until the computation is finished (until the treasure is found) and return from  f  until you go back to the place where you called  f  in the first place. The call stack will never be freed from anything until the end where it will be freed from all return addresses one after the other.  \n\n How to avoid this issue? \n\n That's actually pretty simple: \"don't use recursion if you don't know how deep it can go\". That's not always true as in some cases,  Tail Call recursion can be Optimized (TCO) . But in python, this is not the case, and even \"well written\" recursive function will  not  optimize stack use. There is an interesting post from Guido about this question:  Tail Recursion Elimination . \n\n There is a technique that you can use to make any recursive function iterative, this technique we could call  bring your own notebook . For example, in our particular case we simply are exploring a list, entering a room is equivalent to entering a sublist, the question you should ask yourself is  how can I get back from a list to its parent list?  The answer is not that complex, repeat the following until the  stack  is empty: \n\n \n push the current list  address  and  index  in a  stack  when entering a new sublist (note that a list address+index is also an address, therefore we just use the exact same technique used by the call stack); \n every time an item is found,  yield  it (or add them in a list); \n once a list is fully explored, go back to the parent list using the  stack   return  address  (and  index ) . \n \n\n Also note that this is equivalent to a DFS in a tree where some nodes are sublists  A = [1, 2]  and some are simple items:  0, 1, 2, 3, 4  (for  L = [0, [1,2], 3, 4] ). The tree looks like this: \n\n                     L\n                    |\n           -------------------\n           |     |     |     |\n           0   --A--   3     4\n               |   |\n               1   2\n \n\n The DFS traversal pre-order is: L, 0, A, 1, 2, 3, 4. Remember, in order to implement an iterative DFS you also \"need\" a stack. The implementation I proposed before result in having the following states (for the  stack  and the  flat_list ):  \n\n init.:  stack=[(L, 0)]\n**0**:  stack=[(L, 0)],         flat_list=[0]\n**A**:  stack=[(L, 1), (A, 0)], flat_list=[0]\n**1**:  stack=[(L, 1), (A, 0)], flat_list=[0, 1]\n**2**:  stack=[(L, 1), (A, 1)], flat_list=[0, 1, 2]\n**3**:  stack=[(L, 2)],         flat_list=[0, 1, 2, 3]\n**3**:  stack=[(L, 3)],         flat_list=[0, 1, 2, 3, 4]\nreturn: stack=[],               flat_list=[0, 1, 2, 3, 4]\n \n\n In this example, the stack maximum size is 2, because the input list (and therefore the tree) have depth 2. \n\n Implementation \n\n For the implementation, in python you can simplify a little bit by using iterators instead of simple lists. References to the (sub)iterators will be used to store  sublists return addresses  (instead of having both the list address and the index). This is not a big difference but I feel this is more readable (and also a bit faster): \n\n def flatten(iterable):\n    return list(items_from(iterable))\n\ndef items_from(iterable):\n    cursor_stack = [iter(iterable)]\n    while cursor_stack:\n        sub_iterable = cursor_stack[-1]\n        try:\n            item = next(sub_iterable)\n        except StopIteration:   # post-order\n            cursor_stack.pop()\n            continue\n        if is_list_like(item):  # pre-order\n            cursor_stack.append(iter(item))\n        elif item is not None:\n            yield item          # in-order\n\ndef is_list_like(item):\n    return isinstance(item, list)\n \n\n Also, notice that in  is_list_like  I have  isinstance(item, list) , which could be changed to handle more input types, here I just wanted to have the simplest version where (iterable) is just a list. But you could also do that: \n\n def is_list_like(item):\n    try:\n        iter(item)\n        return not isinstance(item, str)  # strings are not lists (hmm...) \n    except TypeError:\n        return False\n \n\n This considers strings as \"simple items\" and therefore  flatten_iter([[\"test\", \"a\"], \"b])  will return  [\"test\", \"a\", \"b\"]  and not  [\"t\", \"e\", \"s\", \"t\", \"a\", \"b\"] . Remark that in that case,  iter(item)  is called twice on each item, let's pretend it's an exercise for the reader to make this cleaner.  \n\n Testing and remarks on other implementations \n\n In the end, remember that you can't print a infinitely nested list  L  using  print(L)  because internally it will use recursive calls to  __repr__  ( RecursionError: maximum recursion depth exceeded while getting the repr of an object ). For the same reason, solutions to  flatten  involving  str  will fail with the same error message.  \n\n If you need to test your solution, you can use this function to generate a simple nested list: \n\n def build_deep_list(depth):\n    \"\"\"Returns a list of the form $l_{depth} = [depth-1, l_{depth-1}]$\n    with $depth > 1$ and $l_0 = [0]$.\n    \"\"\"\n    sub_list = [0]\n    for d in range(1, depth):\n        sub_list = [d, sub_list]\n    return sub_list\n \n\n Which gives:  build_deep_list(5)  >>>  [4, [3, [2, [1, [0]]]]] . \n    ", "date_posted": "2018-08-02 10:30:05Z", "upvote": "\r\n            5\r\n        ", "accepted": "No", "user": {"stack_user_id": "1720199", "name": "cglacet", "reputation_score": "7,038"}, "answer_comments": []}, {"stack_answer_id": "36500762", "answer_content": "\r\n I didn't go through all the already available answers here, but here is a one liner I came up with, borrowing from lisp's way of first and rest list processing \n def flatten(l): return flatten(l[0]) + (flatten(l[1:]) if len(l) > 1 else []) if type(l) is list else [l]\n \n here is one simple and one not-so-simple case - \n >>> flatten([1,[2,3],4])\n[1, 2, 3, 4]\n\n>>> flatten([1, [2, 3], 4, [5, [6, {'name': 'some_name', 'age':30}, 7]], [8, 9, [10, [11, [12, [13, {'some', 'set'}, 14, [15, 'some_string'], 16], 17, 18], 19], 20], 21, 22, [23, 24], 25], 26, 27, 28, 29, 30])\n[1, 2, 3, 4, 5, 6, {'age': 30, 'name': 'some_name'}, 7, 8, 9, 10, 11, 12, 13, set(['set', 'some']), 14, 15, 'some_string', 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n>>> \n \n    ", "date_posted": "2021-06-16 03:10:18Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "3098229", "name": "Shreyas", "reputation_score": "1,204"}, "answer_comments": [{"stack_answer_id": "36500762", "stack_answer_comment_id": "83335636", "comment_content": "It's not a one liner.  No matter how much you attempt to fit it into one, the ", "user_id": null}, {"stack_answer_id": "36500762", "stack_answer_comment_id": "84252901", "comment_content": "I've de-one-line-ified the code, and did some further refactoring. (edit is pending peer review as I write this) This particular method seemed very readable to me, though the original code did need some refactoring.", "user_id": null}, {"stack_answer_id": "36500762", "stack_answer_comment_id": "120182087", "comment_content": "Please do not edit the answer. If you feel the need to \"refactor\", feel free to post as your own answer. There is a reason why the code is presented the way it is. It is to emphasise that the approach came from lisp. You can plain ignore the \"one-liner\" part of it - it was not intended as some kind of boasting. It was, again, to indicate that the thought behind it is still \"one-liner\": that of first and rest list processing.", "user_id": null}]}, {"stack_answer_id": "18466318", "answer_content": "\r\n Here's the  compiler.ast.flatten  implementation in 2.7.5: \n\n def flatten(seq):\n    l = []\n    for elt in seq:\n        t = type(elt)\n        if t is tuple or t is list:\n            for elt2 in flatten(elt):\n                l.append(elt2)\n        else:\n            l.append(elt)\n    return l\n \n\n There are better, faster methods (If you've reached here, you have seen them already) \n\n Also note: \n\n \n   Deprecated since version 2.6: The compiler package has been removed in Python 3. \n \n    ", "date_posted": "2013-08-27 13:05:57Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "1931274", "name": "pradyunsg", "reputation_score": "16.9k"}, "answer_comments": []}, {"stack_answer_id": "23918614", "answer_content": "\r\n totally hacky but I think it would work (depending on your data_type) \n\n flat_list = ast.literal_eval(\"[%s]\"%re.sub(\"[\\[\\]]\",\"\",str(the_list)))\n \n    ", "date_posted": "2014-05-28 17:54:20Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "541038", "name": "Joran Beasley", "reputation_score": "104k"}, "answer_comments": []}, {"stack_answer_id": "33705609", "answer_content": "\r\n I'm surprised no one has thought of this. Damn recursion I don't get the recursive answers that the advanced people here made. anyway here is my attempt on this. caveat is it's very specific to the OP's use case \n\n import re\n\nL = [[[1, 2, 3], [4, 5]], 6]\nflattened_list = re.sub(\"[\\[\\]]\", \"\", str(L)).replace(\" \", \"\").split(\",\")\nnew_list = list(map(int, flattened_list))\nprint(new_list)\n \n\n output: \n\n [1, 2, 3, 4, 5, 6]\n \n    ", "date_posted": "2015-11-14 06:28:45Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "5166790", "name": "Zion", "reputation_score": "1,480"}, "answer_comments": [{"stack_answer_id": "33705609", "stack_answer_comment_id": "113752265", "comment_content": "this only works for types (like int) which are convertible to string and back. something with the complexity of regular expressions is also not needed to tackle such a simple problem. If you want a simple solution, pradyunsg's is best.", "user_id": null}]}, {"stack_answer_id": "55305409", "answer_content": "\r\n Just use a  funcy  library:\n pip install funcy \n\n import funcy\n\n\nfuncy.flatten([[[[1, 1], 1], 2], 3]) # returns generator\nfuncy.lflatten([[[[1, 1], 1], 2], 3]) # returns list\n \n    ", "date_posted": "2019-05-23 13:32:02Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "55305409", "stack_answer_comment_id": "99167172", "comment_content": "FYI: it uses recursive solution: ", "user_id": null}]}, {"stack_answer_id": "36412443", "answer_content": "\r\n I am a dumb guy so I'll give a \"dumb\" solution. All that recursion hurts my brain. \n\n flattened_list = []\nnested_list = [[[1, 2, 3], [4, 5]], 6]\n\ndef flatten(nested_list, container):\n    for item in nested_list:\n        if isintance(item, list):\n            flatten(item, container)\n        else:\n            container.append(item)\n\n>>> flatten(nested_list, flattened_list)\n>>> flattened_list\n[1, 2, 3, 4, 5, 6]\n \n\n I get that it's using a side effect but well that's to the best of my comprehension of recursion can go \n    ", "date_posted": "2019-09-04 11:12:13Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "1879728", "name": "vlz", "reputation_score": "836"}, "answer_comments": []}, {"stack_answer_id": "7037726", "answer_content": "\r\n I don't see anything like this posted around here and just got here from a closed question on the same subject, but why not just do something like this(if you know the type of the list you want to split): \n\n >>> a = [1, 2, 3, 5, 10, [1, 25, 11, [1, 0]]]    \n>>> g = str(a).replace('[', '').replace(']', '')    \n>>> b = [int(x) for x in g.split(',') if x.strip()]\n \n\n You would need to know the type of the elements but I think this can be generalised and in terms of speed I think it would be faster. \n    ", "date_posted": "2013-07-25 17:36:51Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "977038", "name": "Abhijit", "reputation_score": "59.7k"}, "answer_comments": [{"stack_answer_id": "7037726", "stack_answer_comment_id": "14305819", "comment_content": "This is clever (and probably fast)... but it's not very pythonic.", "user_id": null}, {"stack_answer_id": "7037726", "stack_answer_comment_id": "16146250", "comment_content": "\"why not just do something like this\"  you say? Because it is very easy to break! Very bad idea. One example, what if your items are strings, not ints? Then if a string contains a '[' you are doomed. And what if your items have no good (or very long) string representation?", "user_id": null}, {"stack_answer_id": "7037726", "stack_answer_comment_id": "55183752", "comment_content": "@gb. Well what if this was what the op needed? and the example was clearly a list of ", "user_id": null}, {"stack_answer_id": "7037726", "stack_answer_comment_id": "55235168", "comment_content": "Well sorry, \"what ifs\" apply, careful considerations of all \"what ifs\" is the blood and guts of programming.", "user_id": null}]}, {"stack_answer_id": "25353058", "answer_content": "\r\n Here is another py2 approach, Im not sure if its the fastest or the most elegant nor safest ... \n\n from collections import Iterable\nfrom itertools import imap, repeat, chain\n\n\ndef flat(seqs, ignore=(int, long, float, basestring)):\n    return repeat(seqs, 1) if any(imap(isinstance, repeat(seqs), ignore)) or not isinstance(seqs, Iterable) else chain.from_iterable(imap(flat, seqs))\n \n\n It can ignore any specific (or derived) type you would like, it returns an iterator, so you can convert it to any specific container such as list, tuple, dict or simply consume it in order to reduce memory footprint, for better or worse it can handle initial non-iterable objects such as int ... \n\n Note most of the heavy lifting is done in C, since as far as I know thats how itertools are implemented, so while it is recursive, AFAIK it isn't bounded by python recursion depth since the function calls are happening in C, though this doesn't mean you are bounded by memory, specially in OS X where its stack size has a hard limit as of today (OS X Mavericks) ... \n\n there is a slightly faster approach, but less portable method, only use it if you can assume that the base elements of the input can be explicitly determined otherwise, you'll get an infinite recursion, and OS X with its limited stack size, will throw a segmentation fault fairly quickly ... \n\n def flat(seqs, ignore={int, long, float, str, unicode}):\n    return repeat(seqs, 1) if type(seqs) in ignore or not isinstance(seqs, Iterable) else chain.from_iterable(imap(flat, seqs))\n \n\n here we are using sets to check for the type so it takes O(1) vs O(number of types) to check whether or not an element should be ignored, though of course any value with derived type of the stated ignored types will fail, this is why its using  str ,  unicode  so use it with caution ... \n\n tests: \n\n import random\n\ndef test_flat(test_size=2000):\n    def increase_depth(value, depth=1):\n        for func in xrange(depth):\n            value = repeat(value, 1)\n        return value\n\n    def random_sub_chaining(nested_values):\n        for values in nested_values:\n            yield chain((values,), chain.from_iterable(imap(next, repeat(nested_values, random.randint(1, 10)))))\n\n    expected_values = zip(xrange(test_size), imap(str, xrange(test_size)))\n    nested_values = random_sub_chaining((increase_depth(value, depth) for depth, value in enumerate(expected_values)))\n    assert not any(imap(cmp, chain.from_iterable(expected_values), flat(chain(((),), nested_values, ((),)))))\n\n>>> test_flat()\n>>> list(flat([[[1, 2, 3], [4, 5]], 6]))\n[1, 2, 3, 4, 5, 6]\n>>>  \n\n$ uname -a\nDarwin Samys-MacBook-Pro.local 13.3.0 Darwin Kernel Version 13.3.0: Tue Jun  3 21:27:35 PDT 2014; root:xnu-2422.110.17~1/RELEASE_X86_64 x86_64\n$ python --version\nPython 2.7.5\n \n    ", "date_posted": "2014-08-18 16:14:38Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "1445740", "name": "Samy Vilar", "reputation_score": "10.2k"}, "answer_comments": []}, {"stack_answer_id": "27340134", "answer_content": "\r\n Without using any library: \n\n def flat(l):\n    def _flat(l, r):    \n        if type(l) is not list:\n            r.append(l)\n        else:\n            for i in l:\n                r = r + flat(i)\n        return r\n    return _flat(l, [])\n\n\n\n# example\ntest = [[1], [[2]], [3], [['a','b','c'] , [['z','x','y']], ['d','f','g']], 4]    \nprint flat(test) # prints [1, 2, 3, 'a', 'b', 'c', 'z', 'x', 'y', 'd', 'f', 'g', 4]\n \n    ", "date_posted": "2014-12-07 17:58:00Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "1057429", "name": "Nir Alfasi", "reputation_score": "52.1k"}, "answer_comments": []}, {"stack_answer_id": "28756609", "answer_content": "\r\n Using  itertools.chain : \n\n import itertools\nfrom collections import Iterable\n\ndef list_flatten(lst):\n    flat_lst = []\n    for item in itertools.chain(lst):\n        if isinstance(item, Iterable):\n            item = list_flatten(item)\n            flat_lst.extend(item)\n        else:\n            flat_lst.append(item)\n    return flat_lst\n \n\n Or without chaining: \n\n def flatten(q, final):\n    if not q:\n        return\n    if isinstance(q, list):\n        if not isinstance(q[0], list):\n            final.append(q[0])\n        else:\n            flatten(q[0], final)\n        flatten(q[1:], final)\n    else:\n        final.append(q)\n \n    ", "date_posted": "2015-05-09 22:04:16Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "4596008", "name": "Saksham Varma", "reputation_score": "2,072"}, "answer_comments": []}, {"stack_answer_id": "26130883", "answer_content": "\r\n I used recursive to solve  nested list with any depth \n\n def combine_nlist(nlist,init=0,combiner=lambda x,y: x+y):\n    '''\n    apply function: combiner to a nested list element by element(treated as flatten list)\n    '''\n    current_value=init\n    for each_item in nlist:\n        if isinstance(each_item,list):\n            current_value =combine_nlist(each_item,current_value,combiner)\n        else:\n            current_value = combiner(current_value,each_item)\n    return current_value\n \n\n So after i define function combine_nlist, it is easy to use this function do flatting. Or you can combine it into one function. I like my solution because it can be applied to any nested list. \n\n def flatten_nlist(nlist):\n    return combine_nlist(nlist,[],lambda x,y:x+[y])\n \n\n result \n\n In [379]: flatten_nlist([1,2,3,[4,5],[6],[[[7],8],9],10])\nOut[379]: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n \n    ", "date_posted": "2015-08-09 11:13:41Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "2169114", "name": "Alex Lisovoy", "reputation_score": "5,357"}, "answer_comments": [{"stack_answer_id": "26130883", "stack_answer_comment_id": "90241387", "comment_content": "\"nested list with any depth\" not true. Just try you'll see:  ", "user_id": null}, {"stack_answer_id": "26130883", "stack_answer_comment_id": "90247735", "comment_content": "hmmm I are you trying to flaten list with more than 1000 layers?", "user_id": null}, {"stack_answer_id": "26130883", "stack_answer_comment_id": "90257853", "comment_content": "Of course, that's the whole point of the discussion about recursive vs. iterative solutions. If you know in advance that the number of layers is < than 1000 then the most simple solution will work. When you say \"any depth\" this includes list with depth > 1000.", "user_id": null}]}, {"stack_answer_id": "34298369", "answer_content": "\r\n The easiest way is to use the  morph  library using  pip install morph . \n\n The code is: \n\n import morph\n\nlist = [[[1, 2, 3], [4, 5]], 6]\nflattened_list = morph.flatten(list)  # returns [1, 2, 3, 4, 5, 6]\n \n    ", "date_posted": "2015-12-15 20:03:50Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "2532070", "name": "YPCrumble", "reputation_score": "24.4k"}, "answer_comments": []}, {"stack_answer_id": "39835505", "answer_content": "\r\n I am aware that there are already many awesome answers but i wanted to add an answer that uses the functional programming method of solving the question. In this answer i make use of double recursion : \n\n def flatten_list(seq):\n    if not seq:\n        return []\n    elif isinstance(seq[0],list):\n        return (flatten_list(seq[0])+flatten_list(seq[1:]))\n    else:\n        return [seq[0]]+flatten_list(seq[1:])\n\nprint(flatten_list([1,2,[3,[4],5],[6,7]]))\n \n\n output: \n\n [1, 2, 3, 4, 5, 6, 7]\n \n    ", "date_posted": "2016-10-03 15:46:27Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "6797779", "name": "Leo wahyd", "reputation_score": "197"}, "answer_comments": []}, {"stack_answer_id": "43948658", "answer_content": "\r\n I'm not sure if this is necessarily quicker or more effective, but this is what I do: \n\n def flatten(lst):\n    return eval('[' + str(lst).replace('[', '').replace(']', '') + ']')\n\nL = [[[1, 2, 3], [4, 5]], 6]\nprint(flatten(L))\n \n\n The  flatten  function here turns the list into a string, takes out  all  of the square brackets, attaches square brackets back onto the ends, and turns it back into a list.  \n\n Although, if you knew you would have square brackets in your list in strings, like  [[1, 2], \"[3, 4] and [5]\"] , you would have to do something else. \n    ", "date_posted": "2017-05-13 02:32:08Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "3571147", "name": "diligar", "reputation_score": "393"}, "answer_comments": [{"stack_answer_id": "43948658", "stack_answer_comment_id": "90257931", "comment_content": "This has no advantage over the simple solution as this fails to process deep lists, ie \"RecursionError: maximum recursion depth exceeded while getting the repr of an object\".", "user_id": null}]}, {"stack_answer_id": "53523266", "answer_content": "\r\n This is a simple implement of flatten on python2 \n\n flatten=lambda l: reduce(lambda x,y:x+y,map(flatten,l),[]) if isinstance(l,list) else [l]\n\ntest=[[1,2,3,[3,4,5],[6,7,[8,9,[10,[11,[12,13,14]]]]]],]\nprint flatten(test)\n\n#output [1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n \n    ", "date_posted": "2018-11-28 15:48:09Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "5918696", "name": "Statham", "reputation_score": "3,818"}, "answer_comments": []}], "user": {"stack_user_id": "215679", "name": "telliott99", "reputation_score": "7,374"}, "question_comments": [{"stack_question_id": "2158395", "stack_question_comment_id": "34197359", "comment_content": "The fact that there are this many answers and so much action on this question really suggests that this should be a built-in function somewhere, right?  It's especially too bad the compiler.ast was removed from Python 3.0", "user_id": null}, {"stack_question_id": "2158395", "stack_question_comment_id": "47164204", "comment_content": "I would say that what Python really needs is unbroken recursion rather than another builtin.", "user_id": null}, {"stack_question_id": "2158395", "stack_question_comment_id": "99158509", "comment_content": "@Mittenchops: totally disagree, the fact that people working with obviously bad APIs/overly complicated data structures (just a note: ", "user_id": null}, {"stack_question_id": "2158395", "stack_question_comment_id": "107119718", "comment_content": "If you can afford adding a package to your project - I suppose the ", "user_id": null}, {"stack_question_id": "2158395", "stack_question_comment_id": "116850410", "comment_content": "@viddik13: please consider making that an answer for this question, as well.  It would absolutely get my upvote.  (I agree with Mittenchops.)  The fact that it's not a ", "user_id": null}]},
{"stack_question_id": "1832940", "question_title": "Why is using 'eval' a bad practice?", "question_content": "\r\n                I use the following class to easily store data of my songs.\nclass Song:\n    \"\"\"The class to store the details of each song\"\"\"\n    attsToStore=('Name', 'Artist', 'Album', '...\r\n", "question_url": "/questions/1832940/why-is-using-eval-a-bad-practice", "date_posted": "Dec 2, 2009 at 13:34", "upvote": "1", "view": "6", "tags": ["python", "eval"], "answers_count": "8", "answers": [{"stack_answer_id": "1832957", "answer_content": "\r\n Yes, using  eval  is a bad practice. Just to name a few reasons: \n \n There is almost always a better way to do it \n Very dangerous and insecure \n Makes debugging difficult \n Slow \n \n In your case you can use  setattr  instead: \n class Song:\n    \"\"\"The class to store the details of each song\"\"\"\n    attsToStore=('Name', 'Artist', 'Album', 'Genre', 'Location')\n    def __init__(self):\n        for att in self.attsToStore:\n            setattr(self, att.lower(), None)\n    def setDetail(self, key, val):\n        if key in self.attsToStore:\n            setattr(self, key.lower(), val)\n \n There are some cases where you have to use  eval  or  exec . But they are rare. Using  eval  in your case is a bad practice for sure. I'm emphasizing on bad practice because  eval  and  exec  are frequently used in the wrong place. \n Replying to the comments: \n It looks like some disagree that  eval  is 'very dangerous and insecure' in the OP case. That might be true for this specific case but not in general. The question was general and the reasons I listed are true for the general case as well. \n    ", "date_posted": "2021-02-18 10:22:36Z", "upvote": "\r\n            229\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "1832957", "stack_answer_comment_id": "1725807", "comment_content": "-1: \"Very dangerous and insecure\" is false.  The other three are outstandingly clear.  Please reorder them so that 2 and 4 are the first two.  It's only insecure if you are surrounded by evil sociopaths who are looking for ways to subvert your application.", "user_id": null}, {"stack_answer_id": "1832957", "stack_answer_comment_id": "1726183", "comment_content": "@S.Lott, Insecurity is a very important reason to avoid eval/exec in general. Many applications like websites should take extra care. Take the OP example in a website that expects users to enter the song name. It is bound to be exploited sooner or later. Even an innocent input like: Let's have fun. will cause a syntax error and expose the vulnerability.", "user_id": null}, {"stack_answer_id": "1832957", "stack_answer_comment_id": "1726811", "comment_content": "@Nadia Alramli: User input and ", "user_id": null}, {"stack_answer_id": "1832957", "stack_answer_comment_id": "3268287", "comment_content": "@jeffjose: Actually, ", "user_id": null}, {"stack_answer_id": "1832957", "stack_answer_comment_id": "8538640", "comment_content": "I'm not sure why Nadia's assertion is so contentious. It seems simple to me: eval is a vector for code injection, and is dangerous in a way that most other Python functions are not. That doesn't mean you shouldn't use it at all, but I think you should use it judiciously.", "user_id": null}]}, {"stack_answer_id": "1834754", "answer_content": "\r\n Using  eval  is weak, not a clearly  bad  practice. \n\n \n It violates the \"Fundamental Principle of Software\".  Your source is not the sum total of what's executable.  In addition to your source, there are the arguments to  eval , which must be clearly understood.  For this reason, it's the tool of last resort. \n It's usually a sign of thoughtless design.  There's rarely a good reason for dynamic source code, built on-the-fly.  Almost anything can be done with delegation and other OO design techniques. \n It leads to relatively slow on-the-fly compilation of small pieces of code.  An overhead which can be avoided by using better design patterns. \n \n\n As a footnote, in the hands of deranged sociopaths, it may not work out well.  However, when confronted with deranged sociopathic users or administrators, it's best to not give them interpreted Python in the first place.  In the hands of the truly evil, Python can a liability;  eval  doesn't increase the risk at all.   \n    ", "date_posted": "2009-12-02 18:08:39Z", "upvote": "\r\n            47\r\n        ", "accepted": "No", "user": {"stack_user_id": "10661", "name": "S.Lott", "reputation_score": "375k"}, "answer_comments": [{"stack_answer_id": "1834754", "stack_answer_comment_id": "8543247", "comment_content": "@Owen S. The point is this.  Folks will tell you that ", "user_id": null}, {"stack_answer_id": "1834754", "stack_answer_comment_id": "10920770", "comment_content": "Well, I can tell you exactly why I would say eval is a security vulnerability, and it has to do with the trustworthiness of the string it's given as input. If that string comes, in whole or in part, from the outside world, there's a possibility of a scripting attack on your program if you're not careful. But that's thge derangement of an outside attacker, not of the user or administrator.", "user_id": null}, {"stack_answer_id": "1834754", "stack_answer_comment_id": "10921231", "comment_content": "@OwenS.: \"If that string comes, in whole or in part, from the outside world\"  Often false.  This isn't a \"careful\" thing.  It's black and white.  If the text comes from a user, it can ", "user_id": null}, {"stack_answer_id": "1834754", "stack_answer_comment_id": "10925199", "comment_content": "@OwenS.: There's no possible escaping for a string of untrusted Python code that would make it trustable.  I agree with most of what you're saying except for the \"careful\" part.  It's a very crisp distinction. Code from the outside world is untrustable.  AFAIK, no amount of escaping or filtering can clean it up.  If you have some kind of escaping function that would make code acceptable, please share.  I didn't think such a thing was possible.  For example ", "user_id": null}, {"stack_answer_id": "1834754", "stack_answer_comment_id": "10952344", "comment_content": "@OwenS.: \"intended as a string, not arbitrary code\".  That's unrelated.  That's just a string value, which you would never pass through ", "user_id": null}]}, {"stack_answer_id": "37081082", "answer_content": "\r\n Yes, it is: \n\n Hack using Python: \n\n >>> eval(input())\n\"__import__('os').listdir('.')\"\n...........\n...........   #dir listing\n...........\n \n\n The below code will list all tasks running on a Windows machine. \n\n >>> eval(input())\n\"__import__('subprocess').Popen(['tasklist'],stdout=__import__('subprocess').PIPE).communicate()[0]\"\n \n\n In Linux: \n\n >>> eval(input())\n\"__import__('subprocess').Popen(['ps', 'aux'],stdout=__import__('subprocess').PIPE).communicate()[0]\"\n \n    ", "date_posted": "2016-11-21 08:17:22Z", "upvote": "\r\n            26\r\n        ", "accepted": "No", "user": {"stack_user_id": "2294755", "name": "Hackaholic", "reputation_score": "17.9k"}, "answer_comments": [{"stack_answer_id": "37081082", "stack_answer_comment_id": "127060561", "comment_content": "Why is that bad/dangerous? Can't I just execute the same Python code anyway without ", "user_id": null}, {"stack_answer_id": "37081082", "stack_answer_comment_id": "127949948", "comment_content": "It is dangerous because it allows for text ", "user_id": null}]}, {"stack_answer_id": "1832968", "answer_content": "\r\n In this case, yes. Instead of \n\n exec 'self.Foo=val'\n \n\n you should use the  builtin  function  setattr : \n\n setattr(self, 'Foo', val)\n \n    ", "date_posted": "2009-12-02 13:38:31Z", "upvote": "\r\n            23\r\n        ", "accepted": "No", "user": {"stack_user_id": "19750", "name": "Josh Lee", "reputation_score": "163k"}, "answer_comments": []}, {"stack_answer_id": "40831661", "answer_content": "\r\n Other users pointed out how your code can be changed as to not depend on  eval ; I'll offer a legitimate use-case for using  eval , one that is found even in CPython:  testing . \n\n Here's one example I found in  test_unary.py  where a test on whether  (+|-|~)b'a'  raises a  TypeError : \n\n def test_bad_types(self):\n    for op in '+', '-', '~':\n        self.assertRaises(TypeError, eval, op + \"b'a'\")\n        self.assertRaises(TypeError, eval, op + \"'a'\")\n \n\n The usage is clearly not bad practice here;  you define the input  and merely observe behavior.  eval  is handy for testing. \n\n Take a look at this search  for  eval , performed on the CPython git repository; testing with eval is heavily used. \n    ", "date_posted": "2016-11-27 17:20:00Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "4952130", "name": "Dimitris Fasarakis Hilliard", "reputation_score": "139k"}, "answer_comments": []}, {"stack_answer_id": "1834815", "answer_content": "\r\n It's worth noting that for the specific problem in question, there are several alternatives to using  eval : \n\n The simplest, as noted, is using  setattr : \n\n def __init__(self):\n    for name in attsToStore:\n        setattr(self, name, None)\n \n\n A less obvious approach is updating the object's  __dict__  object directly.  If all you want to do is initialize the attributes to  None , then this is less straightforward than the above.  But consider this: \n\n def __init__(self, **kwargs):\n    for name in self.attsToStore:\n       self.__dict__[name] = kwargs.get(name, None)\n \n\n This allows you to pass keyword arguments to the constructor, e.g.: \n\n s = Song(name='History', artist='The Verve')\n \n\n It also allows you to make your use of  locals()  more explicit, e.g.: \n\n s = Song(**locals())\n \n\n ...and, if you really want to assign  None  to the attributes whose names are found in  locals() : \n\n s = Song(**dict([(k, None) for k in locals().keys()]))\n \n\n Another approach to providing an object with default values for a list of attributes is to define the class's  __getattr__  method: \n\n def __getattr__(self, name):\n    if name in self.attsToStore:\n        return None\n    raise NameError, name\n \n\n This method gets called when the named attribute isn't found in the normal way.  This approach somewhat less straightforward than simply setting the attributes in the constructor or updating the  __dict__ , but it has the merit of not actually creating the attribute unless it exists, which can pretty substantially reduce the class's memory usage. \n\n The point of all this:  There are lots of reasons, in general, to avoid  eval  - the security problem of executing code that you don't control, the practical problem of code you can't debug, etc.  But an even more important reason is that generally, you don't need to use it.  Python exposes so much of its internal mechanisms to the programmer that you rarely really need to write code that writes code. \n    ", "date_posted": "2009-12-02 18:19:56Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "19403", "name": "Robert Rossney", "reputation_score": "92.3k"}, "answer_comments": [{"stack_answer_id": "1834815", "stack_answer_comment_id": "1727231", "comment_content": "Another way that's arguably more (or less) Pythonic: Instead of using the object's ", "user_id": null}, {"stack_answer_id": "1834815", "stack_answer_comment_id": "88177930", "comment_content": "\"A less obvious approach is updating the object's ", "user_id": null}]}, {"stack_answer_id": "50581256", "answer_content": "\r\n When  eval()  is used to process user-provided input, you enable the user to  Drop-to-REPL  providing something like this: \n\n \"__import__('code').InteractiveConsole(locals=globals()).interact()\"\n \n\n You may get away with it, but normally you don't want vectors for  arbitrary code execution  in your applications. \n    ", "date_posted": "2018-06-01 10:22:13Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "1025391", "name": "moooeeeep", "reputation_score": "30.1k"}, "answer_comments": []}, {"stack_answer_id": "53040664", "answer_content": "\r\n In addition to @Nadia Alramli answer, since I am new to Python and was eager to check how using  eval  will affect the  timings , I tried a small program and below were the observations:  \n\n #Difference while using print() with eval() and w/o eval() to print an int = 0.528969s per 100000 evals()\n\nfrom datetime import datetime\ndef strOfNos():\n    s = []\n    for x in range(100000):\n        s.append(str(x))\n    return s\n\nstrOfNos()\nprint(datetime.now())\nfor x in strOfNos():\n    print(x) #print(eval(x))\nprint(datetime.now())\n\n#when using eval(int)\n#2018-10-29 12:36:08.206022\n#2018-10-29 12:36:10.407911\n#diff = 2.201889 s\n\n#when using int only\n#2018-10-29 12:37:50.022753\n#2018-10-29 12:37:51.090045\n#diff = 1.67292\n \n    ", "date_posted": "2018-10-29 07:46:40Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "2227834", "name": "Unheilig", "reputation_score": "16k"}, "answer_comments": []}], "user": {"stack_user_id": "32001", "name": "Nikwin", "reputation_score": "6,376"}, "question_comments": [{"stack_question_id": "1832940", "stack_question_comment_id": "1725429", "comment_content": "how did you learn about ", "user_id": null}, {"stack_question_id": "1832940", "stack_question_comment_id": "1726037", "comment_content": "I believe it was from an article comparing python and lisp than I learned about eval.", "user_id": "/users/32001/nikwin"}, {"stack_question_id": "1832940", "stack_question_comment_id": "127949976", "comment_content": "This should have been considered as two separate questions in the first place - explaining the risk of ", "user_id": null}, {"stack_question_id": "1832940", "stack_question_comment_id": "127949979", "comment_content": "See also: ", "user_id": null}]},
{"stack_question_id": "1663807", "question_title": "How do I iterate through two lists in parallel?", "question_content": "\r\n                I have two iterables, and I want to go over them in pairs:\nfoo = [1, 2, 3]\nbar = [4, 5, 6]\n\nfor (f, b) in iterate_together(foo, bar):\n    print(\"f: \", f, \"; b: \", b)\n\nThat should ...\r\n", "question_url": "/questions/1663807/how-do-i-iterate-through-two-lists-in-parallel", "date_posted": "Nov 2, 2009 at 21:26", "upvote": "1", "view": "1", "tags": ["python", "list", "for-loop", "iterator"], "answers_count": "7", "answers": [{"stack_answer_id": "1663826", "answer_content": "\r\n Python 3 \n\n for f, b in zip(foo, bar):\n    print(f, b)\n \n\n zip  stops when the shorter of  foo  or  bar  stops. \n\n In  Python 3 ,  zip \nreturns an iterator of tuples, like  itertools.izip  in Python2.  To get a list\nof tuples, use  list(zip(foo, bar)) . And to zip until both iterators are\nexhausted, you would use\n itertools.zip_longest . \n\n Python 2 \n\n In  Python 2 ,  zip \nreturns a list of tuples. This is fine when  foo  and  bar  are not massive. If they are both massive then forming  zip(foo,bar)  is an unnecessarily massive\ntemporary variable, and should be replaced by  itertools.izip  or\n itertools.izip_longest , which returns an iterator instead of a list. \n\n import itertools\nfor f,b in itertools.izip(foo,bar):\n    print(f,b)\nfor f,b in itertools.izip_longest(foo,bar):\n    print(f,b)\n \n\n izip  stops when either  foo  or  bar  is exhausted.\n izip_longest  stops when both  foo  and  bar  are exhausted.\nWhen the shorter iterator(s) are exhausted,  izip_longest  yields a tuple with  None  in the position corresponding to that iterator. You can also set a different  fillvalue  besides  None  if you wish. See here for the  full story . \n\n \n\n Note also that  zip  and its  zip -like brethen can accept an arbitrary number of iterables as arguments. For example, \n\n for num, cheese, color in zip([1,2,3], ['manchego', 'stilton', 'brie'], \n                              ['red', 'blue', 'green']):\n    print('{} {} {}'.format(num, color, cheese))\n \n\n prints \n\n 1 red manchego\n2 blue stilton\n3 green brie\n \n    ", "date_posted": "2019-06-09 20:46:42Z", "upvote": "\r\n            1801\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "5476399", "name": "blkpingu", "reputation_score": "1,414"}, "answer_comments": [{"stack_answer_id": "1663826", "stack_answer_comment_id": "59645080", "comment_content": "@unutbu Why would I prefer OP's method over the ", "user_id": null}, {"stack_answer_id": "1663826", "stack_answer_comment_id": "63101672", "comment_content": "You might want to mention Python 3 first, as it's probably more future-proof. Moreover, it*s worth pointing out that in Python 3, zip() has exactly that advantage that only itertools.izip() had in Python 2 and thus it is usually the way to go.", "user_id": null}, {"stack_answer_id": "1663826", "stack_answer_comment_id": "64037068", "comment_content": "May I ask you to update your answer to explicitly state that ", "user_id": null}, {"stack_answer_id": "1663826", "stack_answer_comment_id": "85279619", "comment_content": "what if additionally I want the index ", "user_id": null}, {"stack_answer_id": "1663826", "stack_answer_comment_id": "85281906", "comment_content": "@CharlieParker: Yes you can, but then you would use ", "user_id": null}]}, {"stack_answer_id": "1663818", "answer_content": "\r\n You want the  zip  function. \n\n for (f,b) in zip(foo, bar):\n    print \"f: \", f ,\"; b: \", b\n \n    ", "date_posted": "2009-11-02 21:27:53Z", "upvote": "\r\n            84\r\n        ", "accepted": "No", "user": {"stack_user_id": "111878", "name": "Karl Guertin", "reputation_score": "4,236"}, "answer_comments": [{"stack_answer_id": "1663818", "stack_answer_comment_id": "1536594", "comment_content": "Before Python 3.0 you'd want to use ", "user_id": null}]}, {"stack_answer_id": "43570380", "answer_content": "\r\n You should use ' zip ' function. Here is an example how your own zip function can look like \n\n def custom_zip(seq1, seq2):\n    it1 = iter(seq1)\n    it2 = iter(seq2)\n    while True:\n        yield next(it1), next(it2)\n \n    ", "date_posted": "2017-04-23 11:09:20Z", "upvote": "\r\n            21\r\n        ", "accepted": "No", "user": {"stack_user_id": "30038", "name": "Vlad Bezden", "reputation_score": "74.9k"}, "answer_comments": [{"stack_answer_id": "43570380", "stack_answer_comment_id": "88442487", "comment_content": "Doesn't this have exactly the same result as ", "user_id": null}, {"stack_answer_id": "43570380", "stack_answer_comment_id": "88457150", "comment_content": "@NiklasMertsch yes it has exactly the same result. I just provided example how zip function looks like", "user_id": null}, {"stack_answer_id": "43570380", "stack_answer_comment_id": "116837923", "comment_content": "This is a pretty limited reinvention of ", "user_id": null}]}, {"stack_answer_id": "62479781", "answer_content": "\r\n Building on the answer by  @unutbu , I have compared the iteration performance of two identical lists when using Python 3.6's  zip()  functions, Python's  enumerate()  function, using a manual counter (see  count()  function), using an index-list, and during a special scenario where the elements of one of the two lists (either  foo  or  bar ) may be used to index the other list. Their performances for printing and creating a new list, respectively, were investigated using the  timeit()  function where the number of repetitions used was 1000 times. One of the Python scripts that I had created to perform these investigations is given below. The sizes of the  foo  and  bar  lists had ranged from 10 to 1,000,000 elements. \n Results: \n \n For printing purposes:  The performances of all the considered approaches were observed to be approximately similar to the  zip()  function, after factoring an accuracy tolerance of +/-5%. An exception occurred when the list size was smaller than 100 elements. In such a scenario, the index-list method was slightly slower than the  zip()  function while the  enumerate()  function was ~9% faster. The other methods yielded similar performance to the  zip()  function. \n \n \n For creating lists:  Two types of list creation approaches were explored: using the (a)  list.append()  method and (b)  list comprehension . After factoring an accuracy tolerance of +/-5%, for both of these approaches, the  zip()  function was found to perform faster than the  enumerate()  function, than using a list-index, than using a manual counter. The performance gain by the  zip()  function in these comparisons can be 5% to 60% faster. Interestingly, using the element of  foo  to index  bar  can yield equivalent or faster performances (5% to 20%) than the  zip()  function. \n \n \n \n Making sense of these results: \n A programmer has to determine the amount of compute-time per operation that is meaningful or that is of significance. \n For example, for printing purposes, if this time criterion is 1 second, i.e. 10**0 sec, then looking at the y-axis of the graph that is on the left at 1 sec and projecting it horizontally until it reaches the monomials curves, we see that lists sizes that are more than 144 elements will incur significant compute cost and significance to the programmer. That is, any performance gained by the approaches mentioned in this investigation for smaller list sizes will be insignificant to the programmer. The programmer will conclude that the performance of the  zip()  function to iterate print statements is similar to the other approaches. \n Conclusion \n Notable performance can be gained from using the  zip()  function to iterate through two lists in parallel during  list  creation. When iterating through two lists in parallel to print out the elements of the two lists, the  zip()  function will yield similar performance as the  enumerate()  function, as to using a manual counter variable, as to using an index-list, and as to during the special scenario where the elements of one of the two lists (either  foo  or  bar ) may be used to index the other list. \n The Python\u00a03.6 script that was used to investigate list creation. \n import timeit\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\ndef test_zip( foo, bar ):\n    store = []\n    for f, b in zip(foo, bar):\n        #print(f, b)\n        store.append( (f, b) )\n\ndef test_enumerate( foo, bar ):\n    store = []\n    for n, f in enumerate( foo ):\n        #print(f, bar[n])\n        store.append( (f, bar[n]) )\n\ndef test_count( foo, bar ):\n    store = []\n    count = 0\n    for f in foo:\n        #print(f, bar[count])\n        store.append( (f, bar[count]) )\n        count += 1\n\ndef test_indices( foo, bar, indices ):\n    store = []\n    for i in indices:\n        #print(foo[i], bar[i])\n        store.append( (foo[i], bar[i]) )\n\ndef test_existing_list_indices( foo, bar ):\n    store = []\n    for f in foo:\n        #print(f, bar[f])\n        store.append( (f, bar[f]) )\n\n\nlist_sizes = [ 10, 100, 1000, 10000, 100000, 1000000 ]\ntz = []\nte = []\ntc = []\nti = []\ntii= []\n\ntcz = []\ntce = []\ntci = []\ntcii= []\n\nfor a in list_sizes:\n    foo = [ i for i in range(a) ]\n    bar = [ i for i in range(a) ]\n    indices = [ i for i in range(a) ]\n    reps = 1000\n\n    tz.append( timeit.timeit( 'test_zip( foo, bar )',\n                              'from __main__ import test_zip, foo, bar',\n                              number=reps\n                              )\n               )\n    te.append( timeit.timeit( 'test_enumerate( foo, bar )',\n                              'from __main__ import test_enumerate, foo, bar',\n                              number=reps\n                              )\n               )\n    tc.append( timeit.timeit( 'test_count( foo, bar )',\n                              'from __main__ import test_count, foo, bar',\n                              number=reps\n                              )\n               )\n    ti.append( timeit.timeit( 'test_indices( foo, bar, indices )',\n                              'from __main__ import test_indices, foo, bar, indices',\n                              number=reps\n                              )\n               )\n    tii.append( timeit.timeit( 'test_existing_list_indices( foo, bar )',\n                               'from __main__ import test_existing_list_indices, foo, bar',\n                               number=reps\n                               )\n                )\n\n    tcz.append( timeit.timeit( '[(f, b) for f, b in zip(foo, bar)]',\n                               'from __main__ import foo, bar',\n                               number=reps\n                               )\n                )\n    tce.append( timeit.timeit( '[(f, bar[n]) for n, f in enumerate( foo )]',\n                               'from __main__ import foo, bar',\n                               number=reps\n                               )\n                )\n    tci.append( timeit.timeit( '[(foo[i], bar[i]) for i in indices ]',\n                               'from __main__ import foo, bar, indices',\n                               number=reps\n                               )\n                )\n    tcii.append( timeit.timeit( '[(f, bar[f]) for f in foo ]',\n                                'from __main__ import foo, bar',\n                                number=reps\n                                )\n                 )\n\nprint( f'te  = {te}' )\nprint( f'ti  = {ti}' )\nprint( f'tii = {tii}' )\nprint( f'tc  = {tc}' )\nprint( f'tz  = {tz}' )\n\nprint( f'tce  = {te}' )\nprint( f'tci  = {ti}' )\nprint( f'tcii = {tii}' )\nprint( f'tcz  = {tz}' )\n\nfig, ax = plt.subplots( 2, 2 )\nax[0,0].plot( list_sizes, te, label='enumerate()', marker='.' )\nax[0,0].plot( list_sizes, ti, label='index-list', marker='.' )\nax[0,0].plot( list_sizes, tii, label='element of foo', marker='.' )\nax[0,0].plot( list_sizes, tc, label='count()', marker='.' )\nax[0,0].plot( list_sizes, tz, label='zip()', marker='.')\nax[0,0].set_xscale('log')\nax[0,0].set_yscale('log')\nax[0,0].set_xlabel('List Size')\nax[0,0].set_ylabel('Time (s)')\nax[0,0].legend()\nax[0,0].grid( b=True, which='major', axis='both')\nax[0,0].grid( b=True, which='minor', axis='both')\n\nax[0,1].plot( list_sizes, np.array(te)/np.array(tz), label='enumerate()', marker='.' )\nax[0,1].plot( list_sizes, np.array(ti)/np.array(tz), label='index-list', marker='.' )\nax[0,1].plot( list_sizes, np.array(tii)/np.array(tz), label='element of foo', marker='.' )\nax[0,1].plot( list_sizes, np.array(tc)/np.array(tz), label='count()', marker='.' )\nax[0,1].set_xscale('log')\nax[0,1].set_xlabel('List Size')\nax[0,1].set_ylabel('Performances ( vs zip() function )')\nax[0,1].legend()\nax[0,1].grid( b=True, which='major', axis='both')\nax[0,1].grid( b=True, which='minor', axis='both')\n\nax[1,0].plot( list_sizes, tce, label='list comprehension using enumerate()',  marker='.')\nax[1,0].plot( list_sizes, tci, label='list comprehension using index-list()',  marker='.')\nax[1,0].plot( list_sizes, tcii, label='list comprehension using element of foo',  marker='.')\nax[1,0].plot( list_sizes, tcz, label='list comprehension using zip()',  marker='.')\nax[1,0].set_xscale('log')\nax[1,0].set_yscale('log')\nax[1,0].set_xlabel('List Size')\nax[1,0].set_ylabel('Time (s)')\nax[1,0].legend()\nax[1,0].grid( b=True, which='major', axis='both')\nax[1,0].grid( b=True, which='minor', axis='both')\n\nax[1,1].plot( list_sizes, np.array(tce)/np.array(tcz), label='enumerate()', marker='.' )\nax[1,1].plot( list_sizes, np.array(tci)/np.array(tcz), label='index-list', marker='.' )\nax[1,1].plot( list_sizes, np.array(tcii)/np.array(tcz), label='element of foo', marker='.' )\nax[1,1].set_xscale('log')\nax[1,1].set_xlabel('List Size')\nax[1,1].set_ylabel('Performances ( vs zip() function )')\nax[1,1].legend()\nax[1,1].grid( b=True, which='major', axis='both')\nax[1,1].grid( b=True, which='minor', axis='both')\n\nplt.show()\n \n    ", "date_posted": "2022-05-20 12:16:57Z", "upvote": "\r\n            15\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "62479781", "stack_answer_comment_id": "110540746", "comment_content": "Almost all the time is taken by printing in your ", "user_id": null}, {"stack_answer_id": "62479781", "stack_answer_comment_id": "110548548", "comment_content": "@user2357112supportsMonica Agree. For printing, the iteration performance is determined by the slow system I/O operations, hence is insensitive to the performance of the ", "user_id": null}]}, {"stack_answer_id": "60842028", "answer_content": "\r\n You can bundle the nth elements into a tuple or list using comprehension, then pass them out with a generator function. \n\n def iterate_multi(*lists):\n    for i in range(min(map(len,lists))):\n        yield tuple(l[i] for l in lists)\n\nfor l1, l2, l3 in iterate_multi([1,2,3],[4,5,6],[7,8,9]):\n    print(str(l1)+\",\"+str(l2)+\",\"+str(l3))\n \n    ", "date_posted": "2020-03-25 02:07:46Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "11547701", "name": "Don F", "reputation_score": "111"}, "answer_comments": []}, {"stack_answer_id": "57718165", "answer_content": "\r\n Here's how to do it with a  list comprehension : \n a = (1, 2, 3)\nb = (4, 5, 6)\n[print('f:', i, '; b', j) for i, j in zip(a, b)]\n \n It prints: \n f: 1 ; b 4\nf: 2 ; b 5\nf: 3 ; b 6\n \n    ", "date_posted": "2022-05-20 12:35:08Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "57718165", "stack_answer_comment_id": "101953804", "comment_content": " ", "user_id": null}]}, {"stack_answer_id": "68533514", "answer_content": "\r\n We can just use an index to iterate... \n foo = ['a', 'b', 'c']\nbar = [10, 20, 30]\nfor indx, itm in enumerate(foo):\n    print (foo[indx], bar[indx])\n \n    ", "date_posted": "2022-05-20 12:15:44Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "68533514", "stack_answer_comment_id": "125562360", "comment_content": "Why use ", "user_id": null}]}], "user": {"stack_user_id": "1084", "name": "Nathan Fellman", "reputation_score": "118k"}, "question_comments": []},
{"stack_question_id": "17778372", "question_title": "Why does my recursive function return None?", "question_content": "\r\n                I have this function that calls itself:\n\ndef get_input():\n    my_var = input('Enter \"a\" or \"b\": ')\n\n    if my_var != \"a\" and my_var != \"b\":\n        print('You didn\\'t type \"a\" or \"b\". Try again.')\n    ...\r\n", "question_url": "/questions/17778372/why-does-my-recursive-function-return-none", "date_posted": "Jul 22, 2013 at 0:29", "upvote": "9", "view": "1", "tags": ["python", "function", "recursion", "return"], "answers_count": "4", "answers": [{"stack_answer_id": "17778390", "answer_content": "\r\n It is returning  None  because when you recursively call it: \n if my_var != \"a\" and my_var != \"b\":\n    print('You didn\\'t type \"a\" or \"b\". Try again.')\n    get_input()\n \n ..you don't return the value. \n So while the recursion does happen, the return value gets discarded, and then you fall off the end of the function.  Falling off the end of the function means that python implicitly returns  None , just like this: \n >>> def f(x):\n...     pass\n>>> print(f(20))\nNone\n \n So, instead of just  calling   get_input()  in your  if  statement, you need to  return  it: \n if my_var != \"a\" and my_var != \"b\":\n    print('You didn\\'t type \"a\" or \"b\". Try again.')\n    return get_input()\n \n    ", "date_posted": "2020-07-04 15:08:23Z", "upvote": "\r\n            129\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "2581969", "name": "roippi", "reputation_score": "24.9k"}, "answer_comments": [{"stack_answer_id": "17778390", "stack_answer_comment_id": "25931174", "comment_content": "Shouldn't it run through the if statement again if it is called recursively? I don't understand why it wouldn't return a value.", "user_id": "/users/2605186/cate"}, {"stack_answer_id": "17778390", "stack_answer_comment_id": "25931214", "comment_content": "Nope.  See my edit.  The recursion happens, and then you discard what the recursion returns.", "user_id": null}, {"stack_answer_id": "17778390", "stack_answer_comment_id": "25931366", "comment_content": "You lost me with that ", "user_id": null}, {"stack_answer_id": "17778390", "stack_answer_comment_id": "61202878", "comment_content": "Use return for recursive function in order to put its value into the stack , so that when function will do recursion values from the stack are taken one by one. If you don't use return , the stack will collect only \"None\"  values.", "user_id": null}, {"stack_answer_id": "17778390", "stack_answer_comment_id": "99673988", "comment_content": "you, sir, are a genius! That was not intuitive to me.", "user_id": null}]}, {"stack_answer_id": "17778402", "answer_content": "\r\n To return a value other than None, you need to use a return statement. \n\n In your case, the if block only executes a return when executing one branch. Either move the return outside of the if/else block, or have returns in both options. \n    ", "date_posted": "2013-07-22 00:32:48Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "2605206", "name": "Simon", "reputation_score": "121"}, "answer_comments": [{"stack_answer_id": "17778402", "stack_answer_comment_id": "25931232", "comment_content": "I've tried moving it out of the block, but to no avail.  Instead of returning the correct value, it returns the first incorrect value.  Also, I don't want a return statement for the if part of the if/else statement because I want the function to only return a correct value.", "user_id": "/users/2605186/cate"}]}, {"stack_answer_id": "37287846", "answer_content": "\r\n def get_input():\n    my_var = input('Enter \"a\" or \"b\": ')\n\n    if my_var != \"a\" and my_var != \"b\":\n        print('You didn\\'t type \"a\" or \"b\". Try again.')\n        return get_input()\n    else:\n        return my_var\n\nprint('got input:', get_input())\n \n    ", "date_posted": "2019-03-23 11:02:31Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "1222951", "name": "Aran-Fey", "reputation_score": "36.4k"}, "answer_comments": []}, {"stack_answer_id": "62835013", "answer_content": "\r\n i think this code more clearly \n def get_input():\n    my_var = str(input('Enter \"a\" or \"b\": '))\n    if my_var == \"a\" or my_var == \"b\":\n        print('got input:', my_var)\n        return my_var\n    else:\n        print('You didn\\'t type \"a\" or \"b\". Try again.')\n        return get_input()\nget_input()\n \n    ", "date_posted": "2020-07-13 18:32:56Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "13905960", "name": "O\u011fuzhan \u00c7etinkaya", "reputation_score": "1"}, "answer_comments": [{"stack_answer_id": "62835013", "stack_answer_comment_id": "117104452", "comment_content": "@SergeyShubin how you think this code differs from the one by user6348168. I feel both are the same.", "user_id": null}, {"stack_answer_id": "62835013", "stack_answer_comment_id": "117109344", "comment_content": "@jiten the code was changed after my comment so it is no longer relevant. I think I should delete it", "user_id": null}]}], "user": {"stack_user_id": "2605186", "name": "Cate", "reputation_score": "1,067"}, "question_comments": [{"stack_question_id": "17778372", "stack_question_comment_id": "25931124", "comment_content": "You need to do ", "user_id": null}, {"stack_question_id": "17778372", "stack_question_comment_id": "62101851", "comment_content": "Just a tip: The idiomatic way of that ", "user_id": null}, {"stack_question_id": "17778372", "stack_question_comment_id": "118974420", "comment_content": "@gonz not necessarily. Now you're hitting the heap allocating a tuple just to do a simple comparison. Could be painful in a critical path and it's not much more readable, really.", "user_id": null}, {"stack_question_id": "17778372", "stack_question_comment_id": "129519448", "comment_content": "This is a simple example of recursion for demonstration purposes; but in case you actually need to do this task, a ", "user_id": null}]},
{"stack_question_id": "231767", "question_title": "What does the \"yield\" keyword do?", "question_content": "\r\n                What is the use of the yield keyword in Python? What does it do?\nFor example, I'm trying to understand this code1:\ndef _get_child_candidates(self, distance, min_dist, max_dist):\n    if self._leftchild ...\r\n", "question_url": "/questions/231767/what-does-the-yield-keyword-do", "date_posted": "Oct 23, 2008 at 22:21", "upvote": "1", "view": "3", "tags": ["python", "iterator", "generator"], "answers_count": "4", "answers": [{"stack_answer_id": "231855", "answer_content": "\r\n To understand what  yield  does, you must understand what  generators  are. And before you can understand generators, you must understand  iterables . \n Iterables \n When you create a list, you can read its items one by one. Reading its items one by one is called iteration: \n >>> mylist = [1, 2, 3]\n>>> for i in mylist:\n...    print(i)\n1\n2\n3\n \n mylist  is an  iterable . When you use a list comprehension, you create a list, and so an iterable: \n >>> mylist = [x*x for x in range(3)]\n>>> for i in mylist:\n...    print(i)\n0\n1\n4\n \n Everything you can use \" for... in... \" on is an iterable;  lists ,  strings , files... \n These iterables are handy because you can read them as much as you wish, but you store all the values in memory and this is not always what you want when you have a lot of values. \n Generators \n Generators are iterators, a kind of iterable  you can only iterate over once . Generators do not store all the values in memory,  they generate the values on the fly : \n >>> mygenerator = (x*x for x in range(3))\n>>> for i in mygenerator:\n...    print(i)\n0\n1\n4\n \n It is just the same except you used  ()  instead of  [] . BUT, you  cannot  perform  for i in mygenerator  a second time since generators can only be used once: they calculate 0, then forget about it and calculate 1, and end calculating 4, one by one. \n Yield \n yield  is a keyword that is used like  return , except the function will return a generator. \n >>> def create_generator():\n...    mylist = range(3)\n...    for i in mylist:\n...        yield i*i\n...\n>>> mygenerator = create_generator() # create a generator\n>>> print(mygenerator) # mygenerator is an object!\n<generator object create_generator at 0xb7555c34>\n>>> for i in mygenerator:\n...     print(i)\n0\n1\n4\n \n Here it's a useless example, but it's handy when you know your function will return a huge set of values that you will only need to read once. \n To master  yield , you must understand that  when you call the function, the code you have written in the function body does not run.  The function only returns the generator object, this is a bit tricky. \n Then, your code will continue from where it left off each time  for  uses the generator. \n Now the hard part: \n The first time the  for  calls the generator object created from your function, it will run the code in your function from the beginning until it hits  yield , then it'll return the first value of the loop. Then, each subsequent call will run another iteration of the loop you have written in the function and return the next value. This will continue until the generator is considered empty, which happens when the function runs without hitting  yield . That can be because the loop has come to an end, or because you no longer satisfy an  \"if/else\" . \n \n Your code explained \n Generator: \n # Here you create the method of the node object that will return the generator\ndef _get_child_candidates(self, distance, min_dist, max_dist):\n\n    # Here is the code that will be called each time you use the generator object:\n\n    # If there is still a child of the node object on its left\n    # AND if the distance is ok, return the next child\n    if self._leftchild and distance - max_dist < self._median:\n        yield self._leftchild\n\n    # If there is still a child of the node object on its right\n    # AND if the distance is ok, return the next child\n    if self._rightchild and distance + max_dist >= self._median:\n        yield self._rightchild\n\n    # If the function arrives here, the generator will be considered empty\n    # there is no more than two values: the left and the right children\n \n Caller: \n # Create an empty list and a list with the current object reference\nresult, candidates = list(), [self]\n\n# Loop on candidates (they contain only one element at the beginning)\nwhile candidates:\n\n    # Get the last candidate and remove it from the list\n    node = candidates.pop()\n\n    # Get the distance between obj and the candidate\n    distance = node._get_dist(obj)\n\n    # If distance is ok, then you can fill the result\n    if distance <= max_dist and distance >= min_dist:\n        result.extend(node._values)\n\n    # Add the children of the candidate in the candidate's list\n    # so the loop will keep running until it will have looked\n    # at all the children of the children of the children, etc. of the candidate\n    candidates.extend(node._get_child_candidates(distance, min_dist, max_dist))\n\nreturn result\n \n This code contains several smart parts: \n \n The loop iterates on a list, but the list expands while the loop is being iterated. It's a concise way to go through all these nested data even if it's a bit dangerous since you can end up with an infinite loop. In this case,  candidates.extend(node._get_child_candidates(distance, min_dist, max_dist))  exhaust all the values of the generator, but  while  keeps creating new generator objects which will produce different values from the previous ones since it's not applied on the same node. \n \n The  extend()  method is a list object method that expects an iterable and adds its values to the list. \n \n \n Usually we pass a list to it: \n >>> a = [1, 2]\n>>> b = [3, 4]\n>>> a.extend(b)\n>>> print(a)\n[1, 2, 3, 4]\n \n But in your code, it gets a generator, which is good because: \n \n You don't need to read the values twice. \n You may have a lot of children and you don't want them all stored in memory. \n \n And it works because Python does not care if the argument of a method is a list or not. Python expects iterables so it will work with strings, lists, tuples, and generators! This is called duck typing and is one of the reasons why Python is so cool. But this is another story, for another question... \n You can stop here, or read a little bit to see an advanced use of a generator: \n Controlling a generator exhaustion \n >>> class Bank(): # Let's create a bank, building ATMs\n...    crisis = False\n...    def create_atm(self):\n...        while not self.crisis:\n...            yield \"$100\"\n>>> hsbc = Bank() # When everything's ok the ATM gives you as much as you want\n>>> corner_street_atm = hsbc.create_atm()\n>>> print(corner_street_atm.next())\n$100\n>>> print(corner_street_atm.next())\n$100\n>>> print([corner_street_atm.next() for cash in range(5)])\n['$100', '$100', '$100', '$100', '$100']\n>>> hsbc.crisis = True # Crisis is coming, no more money!\n>>> print(corner_street_atm.next())\n<type 'exceptions.StopIteration'>\n>>> wall_street_atm = hsbc.create_atm() # It's even true for new ATMs\n>>> print(wall_street_atm.next())\n<type 'exceptions.StopIteration'>\n>>> hsbc.crisis = False # The trouble is, even post-crisis the ATM remains empty\n>>> print(corner_street_atm.next())\n<type 'exceptions.StopIteration'>\n>>> brand_new_atm = hsbc.create_atm() # Build a new one to get back in business\n>>> for cash in brand_new_atm:\n...    print cash\n$100\n$100\n$100\n$100\n$100\n$100\n$100\n$100\n$100\n...\n \n Note:  For Python 3, use print(corner_street_atm.__next__())  or  print(next(corner_street_atm)) \n It can be useful for various things like controlling access to a resource. \n Itertools, your best friend \n The itertools module contains special functions to manipulate iterables. Ever wish to duplicate a generator?\nChain two generators? Group values in a nested list with a one-liner?  Map / Zip  without creating another list? \n Then just  import itertools . \n An example? Let's see the possible orders of arrival for a four-horse race: \n >>> horses = [1, 2, 3, 4]\n>>> races = itertools.permutations(horses)\n>>> print(races)\n<itertools.permutations object at 0xb754f1dc>\n>>> print(list(itertools.permutations(horses)))\n[(1, 2, 3, 4),\n (1, 2, 4, 3),\n (1, 3, 2, 4),\n (1, 3, 4, 2),\n (1, 4, 2, 3),\n (1, 4, 3, 2),\n (2, 1, 3, 4),\n (2, 1, 4, 3),\n (2, 3, 1, 4),\n (2, 3, 4, 1),\n (2, 4, 1, 3),\n (2, 4, 3, 1),\n (3, 1, 2, 4),\n (3, 1, 4, 2),\n (3, 2, 1, 4),\n (3, 2, 4, 1),\n (3, 4, 1, 2),\n (3, 4, 2, 1),\n (4, 1, 2, 3),\n (4, 1, 3, 2),\n (4, 2, 1, 3),\n (4, 2, 3, 1),\n (4, 3, 1, 2),\n (4, 3, 2, 1)]\n \n Understanding the inner mechanisms of iteration \n Iteration is a process implying iterables (implementing the  __iter__()  method) and iterators (implementing the  __next__()  method).\nIterables are any objects you can get an iterator from. Iterators are objects that let you iterate on iterables. \n There is more about it in this article about  how  for  loops work . \n    ", "date_posted": "2021-03-07 12:59:37Z", "upvote": "\r\n            17179\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "4298200", "name": "Neuron", "reputation_score": "4,509"}, "answer_comments": [{"stack_answer_id": "231855", "stack_answer_comment_id": "75308701", "comment_content": " is not as magical this answer suggests. When you call a function that contains a ", "user_id": null}, {"stack_answer_id": "231855", "stack_answer_comment_id": "84633217", "comment_content": "\"These iterables are handy... but you store all the values in memory and this is not always what you want\", is either wrong or confusing. An iterable returns an iterator upon calling the iter() on the iterable, and an iterator doesn't always have to store its values in memory, depending on the implementation of the ", "user_id": null}, {"stack_answer_id": "231855", "stack_answer_comment_id": "109059326", "comment_content": "It would be nice to add to this ", "user_id": null}, {"stack_answer_id": "231855", "stack_answer_comment_id": "110055463", "comment_content": "@MatthiasFripp \"This continues until the function runs off the end\" -- or it encounters a ", "user_id": null}, {"stack_answer_id": "231855", "stack_answer_comment_id": "115124375", "comment_content": "The yield statement suspends function\u2019s execution and sends a value back to the caller, but retains enough state to enable function to resume where it is left off. When resumed, the function continues execution immediately after the last yield run. This allows its code to produce a series of values over time, rather than computing them at once and sending them back like a list.", "user_id": null}]}, {"stack_answer_id": "237028", "answer_content": "\r\n Shortcut to understanding  yield \n\n When you see a function with  yield  statements, apply this easy trick to understand what will happen: \n\n \n Insert a line  result = []  at the start of the function. \n Replace each  yield expr  with  result.append(expr) . \n Insert a line  return result  at the bottom of the function. \n Yay - no more  yield  statements! Read and figure out code. \n Compare function to the original definition. \n \n\n This trick may give you an idea of the logic behind the function, but what actually happens with  yield  is significantly different than what happens in the list based approach. In many cases, the yield approach will be a lot more memory efficient and faster too. In other cases, this trick will get you stuck in an infinite loop, even though the original function works just fine. Read on to learn more... \n\n Don't confuse your Iterables, Iterators, and Generators \n\n First, the  iterator protocol  - when you write \n\n for x in mylist:\n    ...loop body...\n \n\n Python performs the following two steps: \n\n \n Gets an iterator for  mylist : \n\n Call  iter(mylist)  -> this returns an object with a  next()  method (or  __next__()  in Python 3). \n\n [This is the step most people forget to tell you about] \n Uses the iterator to loop over items: \n\n Keep calling the  next()  method on the iterator returned from step 1. The return value from  next()  is assigned to  x  and the loop body is executed. If an exception  StopIteration  is raised from within  next() , it means there are no more values in the iterator and the loop is exited. \n \n\n The truth is Python performs the above two steps anytime it wants to  loop over  the contents of an object - so it could be a for loop, but it could also be code like  otherlist.extend(mylist)  (where  otherlist  is a Python list). \n\n Here  mylist  is an  iterable  because it implements the iterator protocol. In a user-defined class, you can implement the  __iter__()  method to make instances of your class iterable. This method should return an  iterator . An iterator is an object with a  next()  method. It is possible to implement both  __iter__()  and  next()  on the same class, and have  __iter__()  return  self . This will work for simple cases, but not when you want two iterators looping over the same object at the same time. \n\n So that's the iterator protocol, many objects implement this protocol: \n\n \n Built-in lists, dictionaries, tuples, sets, files. \n User-defined classes that implement  __iter__() . \n Generators. \n \n\n Note that a  for  loop doesn't know what kind of object it's dealing with - it just follows the iterator protocol, and is happy to get item after item as it calls  next() . Built-in lists return their items one by one, dictionaries return the  keys  one by one, files return the  lines  one by one, etc. And generators return... well that's where  yield  comes in: \n\n def f123():\n    yield 1\n    yield 2\n    yield 3\n\nfor item in f123():\n    print item\n \n\n Instead of  yield  statements, if you had three  return  statements in  f123()  only the first would get executed, and the function would exit. But  f123()  is no ordinary function. When  f123()  is called, it  does not  return any of the values in the yield statements! It returns a generator object. Also, the function does not really exit - it goes into a suspended state. When the  for  loop tries to loop over the generator object, the function resumes from its suspended state at the very next line after the  yield  it previously returned from, executes the next line of code, in this case, a  yield  statement, and returns that as the next item. This happens until the function exits, at which point the generator raises  StopIteration , and the loop exits.  \n\n So the generator object is sort of like an adapter - at one end it exhibits the iterator protocol, by exposing  __iter__()  and  next()  methods to keep the  for  loop happy. At the other end, however, it runs the function just enough to get the next value out of it, and puts it back in suspended mode. \n\n Why Use Generators? \n\n Usually, you can write code that doesn't use generators but implements the same logic. One option is to use the temporary list 'trick' I mentioned before. That will not work in all cases, for e.g. if you have infinite loops, or it may make inefficient use of memory when you have a really long list. The other approach is to implement a new iterable class SomethingIter that keeps the state in instance members and performs the next logical step in it's  next()  (or  __next__()  in Python 3) method. Depending on the logic, the code inside the  next()  method may end up looking very complex and be prone to bugs. Here generators provide a clean and easy solution. \n    ", "date_posted": "2020-05-13 12:29:46Z", "upvote": "\r\n            2388\r\n        ", "accepted": "No", "user": {"stack_user_id": "13184566", "name": "nzz", "reputation_score": "5"}, "answer_comments": [{"stack_answer_id": "237028", "stack_answer_comment_id": "76206780", "comment_content": " Doesn't this completely ignore the fact that you can ", "user_id": null}, {"stack_answer_id": "237028", "stack_answer_comment_id": "79407236", "comment_content": "\"it could be a for loop, but it could also be code like ", "user_id": null}, {"stack_answer_id": "237028", "stack_answer_comment_id": "82933650", "comment_content": "@pedro You have misunderstood that sentence. It means that python performs the two mentioned steps on ", "user_id": null}]}, {"stack_answer_id": "231801", "answer_content": "\r\n Think of it this way: \n\n An iterator is just a fancy sounding term for an object that has a  next()  method.  So a yield-ed function ends up being something like this: \n\n Original version: \n\n def some_function():\n    for i in xrange(4):\n        yield i\n\nfor i in some_function():\n    print i\n \n\n This is basically what the Python interpreter does with the above code: \n\n class it:\n    def __init__(self):\n        # Start at -1 so that we get 0 when we add 1 below.\n        self.count = -1\n\n    # The __iter__ method will be called once by the 'for' loop.\n    # The rest of the magic happens on the object returned by this method.\n    # In this case it is the object itself.\n    def __iter__(self):\n        return self\n\n    # The next method will be called repeatedly by the 'for' loop\n    # until it raises StopIteration.\n    def next(self):\n        self.count += 1\n        if self.count < 4:\n            return self.count\n        else:\n            # A StopIteration exception is raised\n            # to signal that the iterator is done.\n            # This is caught implicitly by the 'for' loop.\n            raise StopIteration\n\ndef some_func():\n    return it()\n\nfor i in some_func():\n    print i\n \n\n For more insight as to what's happening behind the scenes, the  for  loop can be rewritten to this: \n\n iterator = some_func()\ntry:\n    while 1:\n        print iterator.next()\nexcept StopIteration:\n    pass\n \n\n Does that make more sense or just confuse you more?  :) \n\n I should note that this  is  an oversimplification for illustrative purposes. :) \n    ", "date_posted": "2019-05-07 13:28:35Z", "upvote": "\r\n            708\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "231801", "stack_answer_comment_id": "100409", "comment_content": " could be defined instead of ", "user_id": null}, {"stack_answer_id": "231801", "stack_answer_comment_id": "74681581", "comment_content": "I tried this example in Python 3.6 and if I create ", "user_id": null}, {"stack_answer_id": "231801", "stack_answer_comment_id": "109209205", "comment_content": "Where does the ", "user_id": null}, {"stack_answer_id": "231801", "stack_answer_comment_id": "113829987", "comment_content": "Unfortunately this answer is not true at all. This is not what python interpreter does with generators. It is not creating a class starting from the generator function and implement ", "user_id": null}]}, {"stack_answer_id": "6400990", "answer_content": "\r\n\n The  yield  keyword is reduced to two simple facts: \n \n If the compiler detects the  yield  keyword  anywhere  inside a function, that function no longer returns via the  return  statement.  Instead , it  immediately  returns a  lazy \"pending list\" object  called a generator \n A generator is iterable. What is an  iterable ? It's anything like a  list  or  set  or  range  or dict-view, with a  built-in protocol for visiting each element in a certain order . \n \n In a nutshell: Most commonly,  a generator is a lazy, incrementally-pending list , and  yield  statements allow you to use function notation to program the list values  the generator should incrementally spit out.  Furthermore, advanced usage lets you use generators as coroutines (see below). \n generator = myYieldingFunction(...)  # basically a list (but lazy)\nx = list(generator)  # evaluate every element into a list\n\n   generator\n       v\n[x[0], ..., ???]\n\n         generator\n             v\n[x[0], x[1], ..., ???]\n\n               generator\n                   v\n[x[0], x[1], x[2], ..., ???]\n\n                       StopIteration exception\n[x[0], x[1], x[2]]     done\n \n Basically, whenever the  yield  statement is encountered, the function pauses and saves its state, then emits \"the next return value in the 'list'\" according to the python iterator protocol (to some syntactic construct like a for-loop that repeatedly calls  next()  and catches a  StopIteration  exception, etc.). You might have encountered generators with  generator expressions ; generator functions are more powerful because you can pass arguments back into the paused generator function, using them to implement coroutines. More on that later. \n \n Basic Example ('list') \n Let's define a function  makeRange  that's just like Python's  range . Calling  makeRange(n)  RETURNS A GENERATOR: \n def makeRange(n):\n    # return 0,1,2,...,n-1\n    i = 0\n    while i < n:\n        yield i\n        i += 1\n\n>>> makeRange(5)\n<generator object makeRange at 0x19e4aa0>\n \n To force the generator to immediately return its pending values, you can pass it into  list()  (just like you could any iterable): \n >>> list(makeRange(5))\n[0, 1, 2, 3, 4]\n \n \n Comparing example to \"just returning a list\" \n The above example can be thought of as merely creating a list which you append to and return: \n # return a list                  #  # return a generator\ndef makeRange(n):                #  def makeRange(n):\n    \"\"\"return [0,1,2,...,n-1]\"\"\" #      \"\"\"return 0,1,2,...,n-1\"\"\"\n    TO_RETURN = []               # \n    i = 0                        #      i = 0\n    while i < n:                 #      while i < n:\n        TO_RETURN += [i]         #          yield i\n        i += 1                   #          i += 1\n    return TO_RETURN             # \n\n>>> makeRange(5)\n[0, 1, 2, 3, 4]\n \n There is one major difference, though; see the last section. \n \n How you might use generators \n An iterable is the last part of a list comprehension, and all generators are iterable, so they're often used like so: \n #                  < ITERABLE >\n>>> [x+10 for x in makeRange(5)]\n[10, 11, 12, 13, 14]\n \n To get a better feel for generators, you can play around with the  itertools  module (be sure to use  chain.from_iterable  rather than  chain  when warranted). For example, you might even use generators to implement infinitely-long lazy lists like  itertools.count() . You could implement your own  def enumerate(iterable): zip(count(), iterable) , or alternatively do so with the  yield  keyword in a while-loop. \n Please note: generators can actually be used for many more things, such as  implementing coroutines  or non-deterministic programming or other elegant things. However, the \"lazy lists\" viewpoint I present here is the most common use you will find. \n \n Behind the scenes \n This is how the \"Python iteration protocol\" works. That is, what is going on when you do  list(makeRange(5)) . This is what I describe earlier as a \"lazy, incremental list\". \n >>> x=iter(range(5))\n>>> next(x)  # calls x.__next__(); x.next() is deprecated\n0\n>>> next(x)\n1\n>>> next(x)\n2\n>>> next(x)\n3\n>>> next(x)\n4\n>>> next(x)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nStopIteration\n \n The built-in function  next()  just calls the objects  .__next__()  function, which is a part of the \"iteration protocol\" and is found on all iterators. You can manually use the  next()  function (and other parts of the iteration protocol) to implement fancy things, usually at the expense of readability, so try to avoid doing that... \n \n Coroutines \n Coroutine  example: \n def interactiveProcedure():\n    userResponse = yield makeQuestionWebpage()\n    print('user response:', userResponse)\n    yield 'success'\n\ncoroutine = interactiveProcedure()\nwebFormData = next(coroutine)  # same as .send(None)\nuserResponse = serveWebForm(webFormData)\n\n# ...at some point later on web form submit...\n\nsuccessStatus = coroutine.send(userResponse)\n \n A coroutine (generators which generally accept input via the  yield  keyword e.g.  nextInput = yield nextOutput , as a form of two-way communication) is basically a computation which is allowed to pause itself and request input (e.g. to what it should do next). When the coroutine pauses itself (when the running coroutine's eventually hits a  yield  keyword), the computation is paused and control is inverted (yielded) back to the 'calling' function (the frame which requested the  next  value of the computation). The paused generator/coroutine remains paused until another invoking function (possibly a different function/context) requests the next value to unpause it (usually passing input data to direct the paused logic interior to the coroutine's code). \n You can think of python coroutines as lazy incrementally-pending lists, where the next element doesn't just depend on the previous computation, but also on input you may opt to inject during the generation process. \n \n Minutiae \n Normally, most people would not care about the following distinctions and probably want to stop reading here. \n In Python-speak, an  iterable  is any object which \"understands the concept of a for-loop\" like a list  [1,2,3] , and an  iterator  is a specific instance of the requested for-loop like  [1,2,3].__iter__() . A  generator  is exactly the same as any iterator, except for the way it was written (with function syntax). \n When you request an iterator from a list, it creates a new iterator. However, when you request an iterator from an iterator (which you would rarely do), it just gives you a copy of itself. \n Thus, in the unlikely event that you are failing to do something like this... \n > x = myRange(5)\n> list(x)\n[0, 1, 2, 3, 4]\n> list(x)\n[]\n \n ... then remember that a generator is an  iterator ; that is, it is one-time-use. If you want to reuse it, you should call  myRange(...)  again. If you need to use the result twice, convert the result to a list and store it in a variable  x = list(myRange(5)) . Those who absolutely need to clone a generator (for example, who are doing terrifyingly hackish metaprogramming) can use  itertools.tee  ( still works in Python 3 ) if absolutely necessary, since the  copyable iterator Python PEP standards proposal  has been deferred. \n    ", "date_posted": "2022-08-18 13:50:45Z", "upvote": "\r\n            593\r\n        ", "accepted": "No", "user": {"stack_user_id": "711085", "name": "ninjagecko", "reputation_score": "84.7k"}, "answer_comments": []}, {"stack_answer_id": "31042491", "answer_content": "\r\n \n What does the  yield  keyword do in Python? \n \n Answer Outline/Summary \n \n A function with  yield , when called,  returns a  Generator . \n Generators are iterators because they implement the  iterator protocol , so you can iterate over them. \n A generator can also be  sent information , making it conceptually a  coroutine . \n In Python 3, you can  delegate  from one generator to another in both directions with  yield from . \n (Appendix critiques a couple of answers, including the top one, and discusses the use of  return  in a generator.) \n \n Generators: \n yield  is only legal inside of a function definition, and  the inclusion of  yield  in a function definition makes it return a generator. \n The idea for generators comes from other languages (see footnote 1) with varying implementations. In Python's Generators, the execution of the code is  frozen  at the point of the yield. When the generator is called (methods are discussed below) execution resumes and then freezes at the next yield. \n yield  provides an\neasy way of  implementing the iterator protocol , defined by the following two methods:\n __iter__  and  next  (Python 2) or  __next__  (Python 3).  Both of those methods\nmake an object an iterator that you could type-check with the  Iterator  Abstract Base\nClass from the  collections  module. \n >>> def func():\n...     yield 'I am'\n...     yield 'a generator!'\n... \n>>> type(func)                 # A function with yield is still a function\n<type 'function'>\n>>> gen = func()\n>>> type(gen)                  # but it returns a generator\n<type 'generator'>\n>>> hasattr(gen, '__iter__')   # that's an iterable\nTrue\n>>> hasattr(gen, 'next')       # and with .next (.__next__ in Python 3)\nTrue                           # implements the iterator protocol.\n \n The generator type is a sub-type of iterator: \n >>> import collections, types\n>>> issubclass(types.GeneratorType, collections.Iterator)\nTrue\n \n And if necessary, we can type-check like this: \n >>> isinstance(gen, types.GeneratorType)\nTrue\n>>> isinstance(gen, collections.Iterator)\nTrue\n \n A feature of an  Iterator   is that once exhausted , you can't reuse or reset it: \n >>> list(gen)\n['I am', 'a generator!']\n>>> list(gen)\n[]\n \n You'll have to make another if you want to use its functionality again (see footnote 2): \n >>> list(func())\n['I am', 'a generator!']\n \n One can yield data programmatically, for example: \n def func(an_iterable):\n    for item in an_iterable:\n        yield item\n \n The above simple generator is also equivalent to the below - as of Python 3.3 (and not available in Python 2), you can use  yield from : \n def func(an_iterable):\n    yield from an_iterable\n \n However,  yield from  also allows for delegation to subgenerators,\nwhich will be explained in the following section on cooperative delegation with sub-coroutines. \n Coroutines: \n yield  forms an expression that allows data to be sent into the generator (see footnote 3) \n Here is an example, take note of the  received  variable, which will point to the data that is sent to the generator: \n def bank_account(deposited, interest_rate):\n    while True:\n        calculated_interest = interest_rate * deposited \n        received = yield calculated_interest\n        if received:\n            deposited += received\n\n\n>>> my_account = bank_account(1000, .05)\n \n First, we must queue up the generator with the builtin function,  next . It will\ncall the appropriate  next  or  __next__  method, depending on the version of\nPython you are using: \n >>> first_year_interest = next(my_account)\n>>> first_year_interest\n50.0\n \n And now we can send data into the generator. ( Sending  None  is\nthe same as calling  next .) : \n >>> next_year_interest = my_account.send(first_year_interest + 1000)\n>>> next_year_interest\n102.5\n \n Cooperative Delegation to Sub-Coroutine with  yield from \n Now, recall that  yield from  is available in Python 3. This allows us to delegate coroutines to a subcoroutine: \n \ndef money_manager(expected_rate):\n    # must receive deposited value from .send():\n    under_management = yield                   # yield None to start.\n    while True:\n        try:\n            additional_investment = yield expected_rate * under_management \n            if additional_investment:\n                under_management += additional_investment\n        except GeneratorExit:\n            '''TODO: write function to send unclaimed funds to state'''\n            raise\n        finally:\n            '''TODO: write function to mail tax info to client'''\n        \n\ndef investment_account(deposited, manager):\n    '''very simple model of an investment account that delegates to a manager'''\n    # must queue up manager:\n    next(manager)      # <- same as manager.send(None)\n    # This is where we send the initial deposit to the manager:\n    manager.send(deposited)\n    try:\n        yield from manager\n    except GeneratorExit:\n        return manager.close()  # delegate?\n \n And now we can delegate functionality to a sub-generator and it can be used\nby a generator just as above: \n my_manager = money_manager(.06)\nmy_account = investment_account(1000, my_manager)\nfirst_year_return = next(my_account) # -> 60.0\n \n Now simulate adding another 1,000 to the account plus the return on the account (60.0): \n next_year_return = my_account.send(first_year_return + 1000)\nnext_year_return # 123.6\n \n You can read more about the precise semantics of  yield from  in  PEP 380. \n Other Methods: close and throw \n The  close  method raises  GeneratorExit  at the point the function\nexecution was frozen. This will also be called by  __del__  so you\ncan put any cleanup code where you handle the  GeneratorExit : \n my_account.close()\n \n You can also throw an exception which can be handled in the generator\nor propagated back to the user: \n import sys\ntry:\n    raise ValueError\nexcept:\n    my_manager.throw(*sys.exc_info())\n \n Raises: \n Traceback (most recent call last):\n  File \"<stdin>\", line 4, in <module>\n  File \"<stdin>\", line 6, in money_manager\n  File \"<stdin>\", line 2, in <module>\nValueError\n \n Conclusion \n I believe I have covered all aspects of the following question: \n \n What does the  yield  keyword do in Python? \n \n It turns out that  yield  does a lot. I'm sure I could add even more\nthorough examples to this. If you want more or have some constructive criticism, let me know by commenting\nbelow. \n \n Appendix: \n Critique of the Top/Accepted Answer** \n \n It is confused on what makes an  iterable , just using a list as an example. See my references above, but in summary: an iterable has an  __iter__  method returning an  iterator . An  iterator  provides a  .next  (Python 2 or  .__next__  (Python 3) method, which is implicitly called by  for  loops until it raises  StopIteration , and once it does, it will continue to do so. \n It then uses a generator expression to describe what a generator is. Since a generator is simply a convenient way to create an  iterator , it only confuses the matter, and we still have not yet gotten to the  yield  part. \n In  Controlling a generator exhaustion  he calls the  .next  method, when instead he should use the builtin function,  next . It would be an appropriate layer of indirection, because his code does not work in Python 3. \n Itertools? This was not relevant to what  yield  does at all. \n No discussion of the methods that  yield  provides along with the new functionality  yield from  in Python 3.  The top/accepted answer is a very incomplete answer. \n \n Critique of answer suggesting  yield  in a generator expression or comprehension. \n The grammar currently allows any expression in a list comprehension. \n expr_stmt: testlist_star_expr (annassign | augassign (yield_expr|testlist) |\n                     ('=' (yield_expr|testlist_star_expr))*)\n...\nyield_expr: 'yield' [yield_arg]\nyield_arg: 'from' test | testlist\n \n Since yield is an expression, it has been touted by some as interesting to use it in comprehensions or generator expression - in spite of citing no particularly good use-case. \n The CPython core developers are  discussing deprecating its allowance .\nHere's a relevant post from the mailing list: \n \n On 30 January 2017 at 19:05, Brett Cannon  wrote: \n \n On Sun, 29 Jan 2017 at 16:39 Craig Rodrigues  wrote: \n \n I'm OK with either approach.  Leaving things the way they are in Python 3\nis no good, IMHO. \n \n My vote is it be a SyntaxError since you're not getting what you expect from\nthe syntax. \n \n I'd agree that's a sensible place for us to end up, as any code\nrelying on the current behaviour is really too clever to be\nmaintainable. \n In terms of getting there, we'll likely want: \n \n SyntaxWarning or DeprecationWarning in 3.7 \n Py3k warning in 2.7.x \n SyntaxError in 3.8 \n \n Cheers, Nick. \n --  Nick Coghlan   |   ncoghlan at gmail.com   |   Brisbane, Australia \n \n Further, there is an  outstanding issue (10544)  which seems to be pointing in the direction of this  never  being a good idea (PyPy, a Python implementation written in Python, is already raising syntax warnings.) \n Bottom line, until the developers of CPython tell us otherwise:  Don't put  yield  in a generator expression or comprehension. \n The  return  statement in a generator \n In  Python 2 : \n \n In a generator function, the  return  statement is not allowed to include an  expression_list . In that context, a bare  return  indicates that the generator is done and will cause  StopIteration  to be raised. \n \n An  expression_list  is basically any number of expressions separated by commas - essentially, in Python 2, you can stop the generator with  return , but you can't return a value. \n In  Python 3 : \n \n In a generator function, the  return  statement indicates that the generator is done and will cause  StopIteration  to be raised. The returned value (if any) is used as an argument to construct  StopIteration  and becomes the  StopIteration.value  attribute. \n \n Footnotes \n \n The languages CLU, Sather, and Icon were referenced in the proposal\nto introduce the concept of generators to Python. The general idea is\nthat a function can maintain internal state and yield intermediate\ndata points on demand by the user. This promised to be  superior in performance\nto other approaches, including Python threading , which isn't even available on some systems. \n \n  This means, for example, that  range  objects aren't  Iterator s, even though they are iterable, because they can be reused. Like lists, their  __iter__  methods return iterator objects. \n \n  \n \n \n yield  was originally introduced as a statement, meaning that it\ncould only appear at the beginning of a line in a code block.\nNow  yield  creates a yield expression.\n https://docs.python.org/2/reference/simple_stmts.html#grammar-token-yield_stmt \nThis change was  proposed  to allow a user to send data into the generator just as\none might receive it. To send data, one must be able to assign it to something, and\nfor that, a statement just won't work. \n    ", "date_posted": "2021-01-24 04:44:45Z", "upvote": "\r\n            519\r\n        ", "accepted": "No", "user": {"stack_user_id": "541136", "name": "Russia Must Remove Putin", "reputation_score": "347k"}, "answer_comments": []}, {"stack_answer_id": "231778", "answer_content": "\r\n yield  is just like  return  - it returns whatever you tell it to (as a generator). The difference is that the next time you call the generator, execution starts from the last call to the  yield  statement. Unlike return,  the stack frame is not cleaned up when a yield occurs, however control is transferred back to the caller, so its state will resume the next time the function is called. \n\n In the case of your code, the function  get_child_candidates  is acting like an iterator so that when you extend your list, it adds one element at a time to the new list. \n\n list.extend  calls an iterator until it's exhausted. In the case of the code sample you posted, it would be much clearer to just return a tuple and append that to the list. \n    ", "date_posted": "2019-01-24 09:39:59Z", "upvote": "\r\n            425\r\n        ", "accepted": "No", "user": {"stack_user_id": "3551483", "name": "Fang", "reputation_score": "2,011"}, "answer_comments": [{"stack_answer_id": "231778", "stack_answer_comment_id": "99470", "comment_content": "This is close, but not correct.  Every time you call a function with a yield statement in it, it returns a brand new generator object.  It's only when you call that generator's .next() method that execution resumes after the last yield.", "user_id": null}]}, {"stack_answer_id": "232853", "answer_content": "\r\n There's one extra thing to mention: a function that yields doesn't actually have to terminate. I've written code like this: \n\n def fib():\n    last, cur = 0, 1\n    while True: \n        yield cur\n        last, cur = cur, last + cur\n \n\n Then I can use it in other code like this: \n\n for f in fib():\n    if some_condition: break\n    coolfuncs(f);\n \n\n It really helps simplify some problems, and makes some things easier to work with.  \n    ", "date_posted": "2013-04-21 15:42:14Z", "upvote": "\r\n            300\r\n        ", "accepted": "No", "user": {"stack_user_id": "15055", "name": "Claudiu", "reputation_score": "218k"}, "answer_comments": []}, {"stack_answer_id": "14404292", "answer_content": "\r\n For those who prefer a minimal working example, meditate on this interactive Python session: \n\n >>> def f():\n...   yield 1\n...   yield 2\n...   yield 3\n... \n>>> g = f()\n>>> for i in g:\n...   print(i)\n... \n1\n2\n3\n>>> for i in g:\n...   print(i)\n... \n>>> # Note that this time nothing was printed\n \n    ", "date_posted": "2020-02-02 22:09:19Z", "upvote": "\r\n            292\r\n        ", "accepted": "No", "user": {"stack_user_id": "2236185", "name": "Oren", "reputation_score": "3,867"}, "answer_comments": []}, {"stack_answer_id": "36220775", "answer_content": "\r\n TL;DR \n\n Instead of this: \n\n def square_list(n):\n    the_list = []                         # Replace\n    for x in range(n):\n        y = x * x\n        the_list.append(y)                # these\n    return the_list                       # lines\n \n\n do this: \n\n def square_yield(n):\n    for x in range(n):\n        y = x * x\n        yield y                           # with this one.\n \n\n Whenever you find yourself building a list from scratch,  yield  each piece instead.  \n\n This was my first \"aha\" moment with yield. \n\n \n\n yield  is a  sugary  way to say  \n\n \n   build a series of stuff \n \n\n Same behavior: \n\n >>> for square in square_list(4):\n...     print(square)\n...\n0\n1\n4\n9\n>>> for square in square_yield(4):\n...     print(square)\n...\n0\n1\n4\n9\n \n\n Different behavior: \n\n Yield is  single-pass : you can only iterate through once. When a function has a yield in it we call it a  generator function . And an  iterator  is what it returns. Those terms are revealing. We lose the convenience of a container, but gain the power of a series that's computed as needed, and arbitrarily long. \n\n Yield is  lazy , it puts off computation. A function with a yield in it  doesn't actually execute at all when you call it.  It returns an  iterator object  that remembers where it left off. Each time you call  next()  on the iterator (this happens in a for-loop) execution inches forward to the next yield.  return  raises StopIteration and ends the series (this is the natural end of a for-loop). \n\n Yield is  versatile . Data doesn't have to be stored all together, it can be made available one at a time. It can be infinite. \n\n >>> def squares_all_of_them():\n...     x = 0\n...     while True:\n...         yield x * x\n...         x += 1\n...\n>>> squares = squares_all_of_them()\n>>> for _ in range(4):\n...     print(next(squares))\n...\n0\n1\n4\n9\n \n\n \n\n If you need  multiple passes  and the series isn't too long, just call  list()  on it: \n\n >>> list(square_yield(4))\n[0, 1, 4, 9]\n \n\n \n\n Brilliant choice of the word  yield  because  both meanings  apply: \n\n \n   yield  \u2014 produce or provide (as in agriculture) \n \n\n ...provide the next data in the series. \n\n \n   yield  \u2014 give way or relinquish (as in political power) \n \n\n ...relinquish CPU execution until the iterator advances. \n    ", "date_posted": "2019-01-04 15:30:21Z", "upvote": "\r\n            272\r\n        ", "accepted": "No", "user": {"stack_user_id": "673991", "name": "Bob Stein", "reputation_score": "14.8k"}, "answer_comments": []}, {"stack_answer_id": "14352675", "answer_content": "\r\n Yield gives you a generator.  \n\n def get_odd_numbers(i):\n    return range(1, i, 2)\ndef yield_odd_numbers(i):\n    for x in range(1, i, 2):\n       yield x\nfoo = get_odd_numbers(10)\nbar = yield_odd_numbers(10)\nfoo\n[1, 3, 5, 7, 9]\nbar\n<generator object yield_odd_numbers at 0x1029c6f50>\nbar.next()\n1\nbar.next()\n3\nbar.next()\n5\n \n\n As you can see, in the first case  foo  holds the entire list in memory at once. It's not a big deal for a list with 5 elements, but what if you want a list of 5 million? Not only is this a huge memory eater, it also costs a lot of time to build at the time that the function is called. \n\n In the second case,  bar  just gives you a generator. A generator is an iterable--which means you can use it in a  for  loop, etc, but each value can only be accessed once. All the values are also not stored in memory at the same time; the generator object \"remembers\" where it was in the looping the last time you called it--this way, if you're using an iterable to (say) count to 50 billion, you don't have to count to 50 billion all at once and store the 50 billion numbers to count through. \n\n Again, this is a pretty contrived example, you probably would use itertools if you really wanted to count to 50 billion. :) \n\n This is the most simple use case of generators. As you said, it can be used to write efficient permutations, using yield to push things up through the call stack instead of using some sort of stack variable. Generators can also be used for specialized tree traversal, and all manner of other things. \n    ", "date_posted": "2019-03-13 06:04:08Z", "upvote": "\r\n            234\r\n        ", "accepted": "No", "user": {"stack_user_id": "4502035", "name": "Andreas", "reputation_score": "2,375"}, "answer_comments": [{"stack_answer_id": "14352675", "stack_answer_comment_id": "97303895", "comment_content": "Just a note - in Python 3, ", "user_id": null}]}, {"stack_answer_id": "231788", "answer_content": "\r\n It's returning a generator. I'm not particularly familiar with Python, but I believe it's the same kind of thing as  C#'s iterator blocks  if you're familiar with those. \n\n The key idea is that the compiler/interpreter/whatever does some trickery so that as far as the caller is concerned, they can keep calling next() and it will keep returning values -  as if the generator method was paused . Now obviously you can't really \"pause\" a method, so the compiler builds a state machine for you to remember where you currently are and what the local variables etc look like. This is much easier than writing an iterator yourself. \n    ", "date_posted": "2018-10-31 08:42:59Z", "upvote": "\r\n            230\r\n        ", "accepted": "No", "user": {"stack_user_id": "22656", "name": "Jon Skeet", "reputation_score": "1.4m"}, "answer_comments": []}, {"stack_answer_id": "15814755", "answer_content": "\r\n There is one type of answer that I don't feel has been given yet, among the many great answers that describe how to use generators. Here is the programming language theory answer: \n\n The  yield  statement in Python returns a generator. A generator in Python is a function that returns  continuations  (and specifically a type of coroutine, but continuations represent the more general mechanism to understand what is going on). \n\n Continuations in programming languages theory are a much more fundamental kind of computation, but they are not often used, because they are extremely hard to reason about and also very difficult to implement. But the idea of what a continuation is, is straightforward: it is the state of a computation that has not yet finished. In this state, the current values of variables, the operations that have yet to be performed, and so on, are saved. Then at some point later in the program the continuation can be invoked, such that the program's variables are reset to that state and the operations that were saved are carried out. \n\n Continuations, in this more general form, can be implemented in two ways. In the  call/cc  way, the program's stack is literally saved and then when the continuation is invoked, the stack is restored. \n\n In continuation passing style (CPS), continuations are just normal functions (only in languages where functions are first class) which the programmer explicitly manages and passes around to subroutines. In this style, program state is represented by closures (and the variables that happen to be encoded in them) rather than variables that reside somewhere on the stack. Functions that manage control flow accept continuation as arguments (in some variations of CPS, functions may accept multiple continuations) and manipulate control flow by invoking them by simply calling them and returning afterwards. A very simple example of continuation passing style is as follows: \n\n def save_file(filename):\n  def write_file_continuation():\n    write_stuff_to_file(filename)\n\n  check_if_file_exists_and_user_wants_to_overwrite(write_file_continuation)\n \n\n In this (very simplistic) example, the programmer saves the operation of actually writing the file into a continuation (which can potentially be a very complex operation with many details to write out), and then passes that continuation (i.e, as a first-class closure) to another operator which does some more processing, and then calls it if necessary. (I use this design pattern a lot in actual GUI programming, either because it saves me lines of code or, more importantly, to manage control flow after GUI events trigger.) \n\n The rest of this post will, without loss of generality, conceptualize continuations as CPS, because it is a hell of a lot easier to understand and read. \n\n \n\n Now let's talk about generators in Python. Generators are a specific subtype of continuation. Whereas  continuations are able in general to save the state of a  computation  (i.e., the program's call stack),  generators are only able to save the state of iteration over an  iterator . Although, this definition is slightly misleading for certain use cases of generators. For instance: \n\n def f():\n  while True:\n    yield 4\n \n\n This is clearly a reasonable iterable whose behavior is well defined -- each time the generator iterates over it, it returns 4 (and does so forever). But it isn't probably the prototypical type of iterable that comes to mind when thinking of iterators (i.e.,  for x in collection: do_something(x) ). This example illustrates the power of generators: if anything is an iterator, a generator can save the state of its iteration. \n\n To reiterate: Continuations can save the state of a program's stack and generators can save the state of iteration. This means that continuations are more a lot powerful than generators, but also that generators are a lot, lot easier. They are easier for the language designer to implement, and they are easier for the programmer to use (if you have some time to burn, try to read and understand  this page about continuations and call/cc ). \n\n But you could easily implement (and conceptualize) generators as a simple, specific case of continuation passing style: \n\n Whenever  yield  is called, it tells the function to return a continuation.  When the function is called again, it starts from wherever it left off. So, in pseudo-pseudocode (i.e., not pseudocode, but not code) the generator's  next  method is basically as follows: \n\n class Generator():\n  def __init__(self,iterable,generatorfun):\n    self.next_continuation = lambda:generatorfun(iterable)\n\n  def next(self):\n    value, next_continuation = self.next_continuation()\n    self.next_continuation = next_continuation\n    return value\n \n\n where the  yield  keyword is actually syntactic sugar for the real generator function, basically something like: \n\n def generatorfun(iterable):\n  if len(iterable) == 0:\n    raise StopIteration\n  else:\n    return (iterable[0], lambda:generatorfun(iterable[1:]))\n \n\n Remember that this is just pseudocode and the actual implementation of generators in Python is more complex. But as an exercise to understand what is going on, try to use continuation passing style to implement generator objects without use of the  yield  keyword. \n    ", "date_posted": "2018-05-20 10:25:32Z", "upvote": "\r\n            205\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "232111", "answer_content": "\r\n Here is an example in plain language. I will provide a correspondence between high-level human concepts to low-level Python concepts. \n I want to operate on a sequence of numbers, but I don't want to bother my self with the creation of that sequence, I want only to focus on the operation I want to do. So, I do the following: \n \n I call you and tell you that I want a sequence of numbers which are calculated in a specific way, and I let you know what the algorithm is.  \n This step corresponds to  def ining the generator function, i.e. the function containing a  yield . \n Sometime later, I tell you, \"OK, get ready to tell me the sequence of numbers\".  \n This step corresponds to calling the generator function which returns a generator object.  Note that you don't tell me any numbers yet; you just grab your paper and pencil. \n I ask you, \"tell me the next number\", and you tell me the first number; after that, you wait for me to ask you for the next number. It's your job to remember where you were, what numbers you have already said, and what is the next number. I don't care about the details.  \n This step corresponds to calling  next(generator)  on the generator object. \n(In Python 2,  .next  was a method of the generator object; in Python 3, it is named  .__next__ , but the proper way to call it is using the builtin  next()  function just like  len()  and  .__len__ ) \n \u2026 repeat previous step, until\u2026 \n eventually, you might come to an end. You don't tell me a number; you just shout, \"hold your horses! I'm done! No more numbers!\"  \n This step corresponds to the generator object ending its job, and raising a  StopIteration  exception. \nThe generator function does not need to raise the exception. It's raised automatically when the function ends or issues a  return . \n \n This is what a generator does (a function that contains a  yield ); it starts executing on the first  next() , pauses whenever it does a  yield , and when asked for the  next()  value it continues from the point it was last. It fits perfectly by design with the iterator protocol of Python, which describes how to sequentially request values. \n The most famous user of the iterator protocol is the  for  command in Python. So, whenever you do a: \n for item in sequence:\n \n it doesn't matter if  sequence  is a list, a string, a dictionary or a generator  object  like described above; the result is the same: you read items off a sequence one by one. \n Note that  def ining a function which contains a  yield  keyword is not the only way to create a generator; it's just the easiest way to create one. \n For more accurate information, read about  iterator types , the  yield statement  and  generators  in the Python documentation. \n    ", "date_posted": "2022-01-17 10:21:02Z", "upvote": "\r\n            203\r\n        ", "accepted": "No", "user": {"stack_user_id": "6899", "name": "tzot", "reputation_score": "88.7k"}, "answer_comments": []}, {"stack_answer_id": "21541902", "answer_content": "\r\n While a lot of answers show why you'd use a  yield  to create a generator, there are more uses for  yield .  It's quite easy to make a coroutine, which enables the passing of information between two blocks of code.  I won't repeat any of the fine examples that have already been given about using  yield  to create a generator. \n\n To help understand what a  yield  does in the following code, you can use your finger to trace the cycle through any code that has a  yield .  Every time your finger hits the  yield , you have to wait for a  next  or a  send  to be entered.  When a  next  is called, you trace through the code until you hit the  yield \u2026 the code on the right of the  yield  is evaluated and returned to the caller\u2026 then you wait.  When  next  is called again, you perform another loop through the code.  However, you'll note that in a coroutine,  yield  can also be used with a  send \u2026 which will send a value from the caller  into  the yielding function. If a  send  is given, then  yield  receives the value sent, and spits it out the left hand side\u2026 then the trace through the code progresses until you hit the  yield  again (returning the value at the end, as if  next  was called). \n\n For example: \n\n >>> def coroutine():\n...     i = -1\n...     while True:\n...         i += 1\n...         val = (yield i)\n...         print(\"Received %s\" % val)\n...\n>>> sequence = coroutine()\n>>> sequence.next()\n0\n>>> sequence.next()\nReceived None\n1\n>>> sequence.send('hello')\nReceived hello\n2\n>>> sequence.close()\n \n    ", "date_posted": "2014-02-04 02:27:35Z", "upvote": "\r\n            162\r\n        ", "accepted": "No", "user": {"stack_user_id": "2379433", "name": "Mike McKerns", "reputation_score": "31.4k"}, "answer_comments": [{"stack_answer_id": "21541902", "stack_answer_comment_id": "55942433", "comment_content": "Cute! A ", "user_id": null}]}, {"stack_answer_id": "24944096", "answer_content": "\r\n There is another  yield  use and meaning (since Python 3.3): \n yield from <expr>\n \n From  PEP 380 -- Syntax for Delegating to a Subgenerator : \n \n A syntax is proposed for a generator to delegate part of its operations to another generator. This allows a section of code containing 'yield' to be factored out and placed in another generator. Additionally, the subgenerator is allowed to return with a value, and the value is made available to the delegating generator. \n The new syntax also opens up some opportunities for optimisation when one generator re-yields values produced by another. \n \n Moreover  this  will introduce (since Python 3.5): \n async def new_coroutine(data):\n   ...\n   await blocking_action()\n \n to avoid coroutines being confused with a regular generator (today  yield  is used in both). \n    ", "date_posted": "2020-06-20 09:12:55Z", "upvote": "\r\n            158\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}, {"stack_answer_id": "47285378", "answer_content": "\r\n All great answers, however a bit difficult for newbies. \n\n I assume you have learned the  return  statement. \n\n As an analogy,  return  and  yield  are twins.  return  means 'return and stop' whereas 'yield` means 'return, but continue' \n\n \n   \n   Try to get a num_list with  return . \n   \n \n\n def num_list(n):\n    for i in range(n):\n        return i\n \n\n Run it: \n\n In [5]: num_list(3)\nOut[5]: 0\n \n\n See, you get only a single number rather than a list of them.  return  never allows you prevail happily, just implements once and quit. \n\n \n   \n   There comes  yield \n   \n \n\n Replace  return  with  yield : \n\n In [10]: def num_list(n):\n    ...:     for i in range(n):\n    ...:         yield i\n    ...:\n\nIn [11]: num_list(3)\nOut[11]: <generator object num_list at 0x10327c990>\n\nIn [12]: list(num_list(3))\nOut[12]: [0, 1, 2]\n \n\n Now, you win to get all the numbers. \n\n Comparing to  return  which runs once and stops,  yield  runs times you planed.\nYou can interpret  return  as  return one of them , and  yield  as  return all of them . This is called  iterable . \n\n \n   \n   One more step we can rewrite  yield  statement with  return \n   \n \n\n In [15]: def num_list(n):\n    ...:     result = []\n    ...:     for i in range(n):\n    ...:         result.append(i)\n    ...:     return result\n\nIn [16]: num_list(3)\nOut[16]: [0, 1, 2]\n \n\n It's the core about  yield . \n\n The difference between a list  return  outputs and the object  yield  output is: \n\n You will always get [0, 1, 2] from a list object but only could retrieve them from 'the object  yield  output' once. So, it has a new name  generator  object as displayed in  Out[11]: <generator object num_list at 0x10327c990> . \n\n In conclusion, as a metaphor to grok it: \n\n \n return  and  yield  are twins \n list  and  generator  are twins \n \n    ", "date_posted": "2018-05-28 09:06:22Z", "upvote": "\r\n            146\r\n        ", "accepted": "No", "user": {"stack_user_id": "7301792", "name": "AbstProcDo", "reputation_score": "18.1k"}, "answer_comments": [{"stack_answer_id": "47285378", "stack_answer_comment_id": "90923314", "comment_content": "This is understandable, but one major difference is that you can have multiple yields in a function/method. The analogy totally breaks down at that point. Yield remembers its place in a function, so the next time you call next(), your function continues on to the next ", "user_id": null}]}, {"stack_answer_id": "18365578", "answer_content": "\r\n From a programming viewpoint, the iterators are implemented as  thunks . \n To implement iterators, generators, and thread pools for concurrent execution, etc. as thunks, one uses  messages sent to a closure object , which has a dispatcher, and the  dispatcher answers to \"messages\" . \n \" next \"  is a message sent to a closure, created by the \" iter \" call. \n There are lots of ways to implement this computation. I used mutation, but it is possible to do this kind of computation without mutation, by returning the current value and the next yielder (making it  referential transparent ).  Racket uses a sequence of transformations of the initial program in some intermediary languages, one of such rewriting making the yield operator to be transformed in some language with simpler operators. \n Here is a demonstration of how yield could be rewritten, which uses the structure of R6RS, but the semantics is identical to Python's. It's the same model of computation, and only a change in syntax is required to rewrite it using yield of Python. \n \n Welcome to Racket v6.5.0.3.\n\n-> (define gen\n     (lambda (l)\n       (define yield\n         (lambda ()\n           (if (null? l)\n               'END\n               (let ((v (car l)))\n                 (set! l (cdr l))\n                 v))))\n       (lambda(m)\n         (case m\n           ('yield (yield))\n           ('init  (lambda (data)\n                     (set! l data)\n                     'OK))))))\n-> (define stream (gen '(1 2 3)))\n-> (stream 'yield)\n1\n-> (stream 'yield)\n2\n-> (stream 'yield)\n3\n-> (stream 'yield)\n'END\n-> ((stream 'init) '(a b))\n'OK\n-> (stream 'yield)\n'a\n-> (stream 'yield)\n'b\n-> (stream 'yield)\n'END\n-> (stream 'yield)\n'END\n->\n \n \n    ", "date_posted": "2020-07-02 07:36:31Z", "upvote": "\r\n            133\r\n        ", "accepted": "No", "user": {"stack_user_id": "1419272", "name": "alinsoar", "reputation_score": "14.8k"}, "answer_comments": []}, {"stack_answer_id": "12716515", "answer_content": "\r\n Here are some Python examples of how to actually implement generators as if Python did not provide syntactic sugar for them: \n\n As a Python generator: \n\n from itertools import islice\n\ndef fib_gen():\n    a, b = 1, 1\n    while True:\n        yield a\n        a, b = b, a + b\n\nassert [1, 1, 2, 3, 5] == list(islice(fib_gen(), 5))\n \n\n Using lexical closures instead of generators \n\n def ftake(fnext, last):\n    return [fnext() for _ in xrange(last)]\n\ndef fib_gen2():\n    #funky scope due to python2.x workaround\n    #for python 3.x use nonlocal\n    def _():\n        _.a, _.b = _.b, _.a + _.b\n        return _.a\n    _.a, _.b = 0, 1\n    return _\n\nassert [1,1,2,3,5] == ftake(fib_gen2(), 5)\n \n\n Using object closures instead of generators  (because  ClosuresAndObjectsAreEquivalent ) \n\n class fib_gen3:\n    def __init__(self):\n        self.a, self.b = 1, 1\n\n    def __call__(self):\n        r = self.a\n        self.a, self.b = self.b, self.a + self.b\n        return r\n\nassert [1,1,2,3,5] == ftake(fib_gen3(), 5)\n \n    ", "date_posted": "2017-10-24 10:46:05Z", "upvote": "\r\n            126\r\n        ", "accepted": "No", "user": {"stack_user_id": "20003", "name": "Dustin Getz", "reputation_score": "20.7k"}, "answer_comments": []}, {"stack_answer_id": "14554322", "answer_content": "\r\n I was going to post \"read page 19 of Beazley's 'Python: Essential Reference' for a quick description of generators\", but so many others have posted good descriptions already. \n\n Also, note that  yield  can be used in coroutines as the dual of their use in generator functions.  Although it isn't the same use as your code snippet,  (yield)  can be used as an expression in a function.  When a caller sends a value to the method using the  send()  method, then the coroutine will execute until the next  (yield)  statement is encountered. \n\n Generators and coroutines are a cool way to set up data-flow type applications.  I thought it would be worthwhile knowing about the other use of the  yield  statement in functions. \n    ", "date_posted": "2013-01-28 01:37:10Z", "upvote": "\r\n            115\r\n        ", "accepted": "No", "user": {"stack_user_id": "479213", "name": "johnzachary", "reputation_score": "2,385"}, "answer_comments": []}, {"stack_answer_id": "20704301", "answer_content": "\r\n Here is a simple example: \n\n def isPrimeNumber(n):\n    print \"isPrimeNumber({}) call\".format(n)\n    if n==1:\n        return False\n    for x in range(2,n):\n        if n % x == 0:\n            return False\n    return True\n\ndef primes (n=1):\n    while(True):\n        print \"loop step ---------------- {}\".format(n)\n        if isPrimeNumber(n): yield n\n        n += 1\n\nfor n in primes():\n    if n> 10:break\n    print \"wiriting result {}\".format(n)\n \n\n Output: \n\n loop step ---------------- 1\nisPrimeNumber(1) call\nloop step ---------------- 2\nisPrimeNumber(2) call\nloop step ---------------- 3\nisPrimeNumber(3) call\nwiriting result 3\nloop step ---------------- 4\nisPrimeNumber(4) call\nloop step ---------------- 5\nisPrimeNumber(5) call\nwiriting result 5\nloop step ---------------- 6\nisPrimeNumber(6) call\nloop step ---------------- 7\nisPrimeNumber(7) call\nwiriting result 7\nloop step ---------------- 8\nisPrimeNumber(8) call\nloop step ---------------- 9\nisPrimeNumber(9) call\nloop step ---------------- 10\nisPrimeNumber(10) call\nloop step ---------------- 11\nisPrimeNumber(11) call\n \n\n I am not a Python developer, but it looks to me  yield  holds the position of program flow and the next loop start from \"yield\" position. It seems like it is waiting at that position, and just before that, returning a value outside, and next time continues to work. \n\n It seems to be an interesting and nice ability :D \n    ", "date_posted": "2018-05-20 10:31:01Z", "upvote": "\r\n            100\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "20704301", "stack_answer_comment_id": "89241413", "comment_content": "You are correct. But what is the effect on flow which is to see the behaviour of \"yield\" ? I can change the algorithm in the name of mathmatics. Will it help to get different assessment of \"yield\" ?", "user_id": null}]}, {"stack_answer_id": "17113322", "answer_content": "\r\n Here is a mental image of what  yield  does. \n\n I like to think of a thread as having a stack (even when it's not implemented that way). \n\n When a normal function is called, it puts its local variables on the stack, does some computation, then clears the stack and returns. The values of its local variables are never seen again. \n\n With a  yield  function, when its code begins to run (i.e. after the function is called, returning a generator object, whose  next()  method is then invoked), it similarly puts its local variables onto the stack and computes for a while. But then, when it hits the  yield  statement, before clearing its part of the stack and returning, it takes a snapshot of its local variables and stores them in the generator object. It also writes down the place where it's currently up to in its code (i.e. the particular  yield  statement). \n\n So it's a kind of a frozen function that the generator is hanging onto. \n\n When  next()  is called subsequently, it retrieves the function's belongings onto the stack and re-animates it. The function continues to compute from where it left off, oblivious to the fact that it had just spent an eternity in cold storage. \n\n Compare the following examples: \n\n def normalFunction():\n    return\n    if False:\n        pass\n\ndef yielderFunction():\n    return\n    if False:\n        yield 12\n \n\n When we call the second function, it behaves very differently to the first. The  yield  statement might be unreachable, but if it's present anywhere, it changes the nature of what we're dealing with. \n\n >>> yielderFunction()\n<generator object yielderFunction at 0x07742D28>\n \n\n Calling  yielderFunction()  doesn't run its code, but makes a generator out of the code. (Maybe it's a good idea to name such things with the  yielder  prefix for readability.) \n\n >>> gen = yielderFunction()\n>>> dir(gen)\n['__class__',\n ...\n '__iter__',    #Returns gen itself, to make it work uniformly with containers\n ...            #when given to a for loop. (Containers return an iterator instead.)\n 'close',\n 'gi_code',\n 'gi_frame',\n 'gi_running',\n 'next',        #The method that runs the function's body.\n 'send',\n 'throw']\n \n\n The  gi_code  and  gi_frame  fields are where the frozen state is stored. Exploring them with  dir(..) , we can confirm that our mental model above is credible. \n    ", "date_posted": "2017-03-01 13:36:58Z", "upvote": "\r\n            85\r\n        ", "accepted": "No", "user": {"stack_user_id": "1143274", "name": "Evgeni Sergeev", "reputation_score": "21.3k"}, "answer_comments": []}, {"stack_answer_id": "55314423", "answer_content": "\r\n \n Imagine that you have created a remarkable machine that is capable of generating thousands and thousands of lightbulbs per day. The machine generates these lightbulbs in boxes with a unique serial number. You don't have enough space to store all of these lightbulbs at the same time, so you would like to adjust it to generate lightbulbs on-demand. \n Python generators don't differ much from this concept. Imagine that you have a function called  barcode_generator  that generates unique serial numbers for the boxes. Obviously, you can have a huge number of such barcodes returned by the function, subject to the hardware (RAM) limitations. A wiser, and space efficient, option is to generate those serial numbers on-demand. \n Machine's code: \n def barcode_generator():\n    serial_number = 10000  # Initial barcode\n    while True:\n        yield serial_number\n        serial_number += 1\n\n\nbarcode = barcode_generator()\nwhile True:\n    number_of_lightbulbs_to_generate = int(input(\"How many lightbulbs to generate? \"))\n    barcodes = [next(barcode) for _ in range(number_of_lightbulbs_to_generate)]\n    print(barcodes)\n\n    # function_to_create_the_next_batch_of_lightbulbs(barcodes)\n\n    produce_more = input(\"Produce more? [Y/n]: \")\n    if produce_more == \"n\":\n        break\n \n Note the  next(barcode)  bit. \n As you can see, we have a self-contained \u201cfunction\u201d to generate the next unique serial number each time. This function returns a  generator ! As you can see, we are not calling the function each time we need a new serial number, but instead we are using  next()  given the generator to obtain the next serial number. \n Lazy Iterators \n To be more precise, this generator is a  lazy iterator ! An iterator is an object that helps us traverse a sequence of objects. It's called  lazy  because it does not load all the items of the sequence in memory until they are needed. The use of  next  in the previous example is the  explicit  way to obtain the next item from the iterator. The  implicit  way is using for loops: \n for barcode in barcode_generator():\n    print(barcode)\n \n This will print barcodes infinitely, yet you will not run out of memory. \n In other words, a generator  looks like  a function but  behaves like  an iterator. \n Real-world application? \n Finally, real-world applications? They are usually useful when you work with big sequences. Imagine reading a  huge  file from disk with billions of records. Reading the entire file in memory, before you can work with its content, will probably be infeasible (i.e., you will run out of memory). \n    ", "date_posted": "2021-10-21 18:54:29Z", "upvote": "\r\n            81\r\n        ", "accepted": "No", "user": {"stack_user_id": "4946896", "name": "Rafael", "reputation_score": "6,652"}, "answer_comments": []}, {"stack_answer_id": "41426583", "answer_content": "\r\n An easy example to understand what it is:  yield \n\n def f123():\n    for _ in range(4):\n        yield 1\n        yield 2\n\n\nfor i in f123():\n    print (i)\n \n\n The output is:  \n\n 1 2 1 2 1 2 1 2\n \n    ", "date_posted": "2020-02-02 18:21:38Z", "upvote": "\r\n            78\r\n        ", "accepted": "No", "user": {"stack_user_id": "8928024", "name": "ZF007", "reputation_score": "3,601"}, "answer_comments": [{"stack_answer_id": "41426583", "stack_answer_comment_id": "106237799", "comment_content": "are you sure about that output?  wouldnt that only be printed on a single line if you ran that print statement using ", "user_id": null}, {"stack_answer_id": "41426583", "stack_answer_comment_id": "106255539", "comment_content": "@user9074332, You're right, but it is written on one line to facilitate understanding", "user_id": null}]}, {"stack_answer_id": "31692481", "answer_content": "\r\n Like every answer suggests,  yield  is used for creating a sequence generator. It's used for generating some sequence dynamically. For example, while reading a file line by line on a network, you can use the  yield  function as follows: \n\n def getNextLines():\n   while con.isOpen():\n       yield con.read()\n \n\n You can use it in your code as follows: \n\n for line in getNextLines():\n    doSomeThing(line)\n \n\n Execution Control Transfer gotcha \n\n The execution control will be transferred from getNextLines() to the  for  loop when yield is executed. Thus, every time getNextLines() is invoked, execution begins from the point where it was paused last time. \n\n Thus in short, a function with the following code \n\n def simpleYield():\n    yield \"first time\"\n    yield \"second time\"\n    yield \"third time\"\n    yield \"Now some useful value {}\".format(12)\n\nfor i in simpleYield():\n    print i\n \n\n will print \n\n \"first time\"\n\"second time\"\n\"third time\"\n\"Now some useful value 12\"\n \n    ", "date_posted": "2018-05-20 10:42:59Z", "upvote": "\r\n            74\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "36214653", "answer_content": "\r\n (My below answer only speaks from the perspective of using Python generator, not the  underlying implementation of generator mechanism , which involves some tricks of stack and heap manipulation.) \n\n When  yield  is used instead of a  return  in a python function, that function is turned into something special called  generator function . That function will return an object of  generator  type.  The  yield  keyword is a flag to notify the python compiler to treat such function specially.  Normal functions will terminate once some value is returned from it. But with the help of the compiler, the generator function  can be thought of  as resumable. That is, the execution context will be restored and the execution will continue from last run. Until you explicitly call return, which will raise a  StopIteration  exception (which is also part of the iterator protocol), or reach the end of the function. I found a lot of references about  generator  but this  one  from the  functional programming perspective  is the most digestable. \n\n (Now I want to talk about the rationale behind  generator , and the  iterator  based on my own understanding. I hope this can help you grasp the  essential motivation  of iterator and generator. Such concept shows up in other languages as well such as C#.) \n\n As I understand, when we want to process a bunch of data, we usually first store the data somewhere and then process it one by one. But this  naive  approach is problematic. If the data volume is huge, it's expensive to store them as a whole beforehand.  So instead of storing the  data  itself directly, why not store some kind of  metadata  indirectly, i.e.  the logic how the data is computed .  \n\n There are 2 approaches to wrap such metadata. \n\n \n The OO approach, we wrap the metadata  as a class . This is the so-called  iterator  who implements the iterator protocol (i.e. the  __next__() , and  __iter__()  methods). This is also the commonly seen  iterator design pattern . \n The functional approach, we wrap the metadata  as a function . This is\nthe so-called  generator function . But under the hood, the returned  generator object  still  IS-A  iterator because it also implements the iterator protocol. \n \n\n Either way, an iterator is created, i.e. some object that can give you the data you want. The OO approach may be a bit complex. Anyway, which one to use is up to you. \n    ", "date_posted": "2018-11-23 01:38:59Z", "upvote": "\r\n            72\r\n        ", "accepted": "No", "user": {"stack_user_id": "264052", "name": "smwikipedia", "reputation_score": "58.4k"}, "answer_comments": []}, {"stack_answer_id": "40022748", "answer_content": "\r\n In summary, the  yield  statement transforms your function into a factory that produces a special object called a  generator  which wraps around the body of your original function. When the  generator  is iterated, it executes your function  until it reaches the next  yield  then suspends execution and evaluates to the value passed to  yield . It repeats this process on each iteration until the path of execution exits the function. For instance, \n\n def simple_generator():\n    yield 'one'\n    yield 'two'\n    yield 'three'\n\nfor i in simple_generator():\n    print i\n \n\n simply outputs \n\n one\ntwo\nthree\n \n\n The power comes from using the generator with a loop that calculates a sequence, the generator executes the loop stopping each time to 'yield' the next result of the calculation, in this way it calculates a list on the fly, the benefit being the memory saved for especially large calculations \n\n Say you wanted to create a your own  range  function that produces an iterable range of numbers, you could do it like so, \n\n def myRangeNaive(i):\n    n = 0\n    range = []\n    while n < i:\n        range.append(n)\n        n = n + 1\n    return range\n \n\n and use it like this; \n\n for i in myRangeNaive(10):\n    print i\n \n\n But this is inefficient because \n\n \n You create an array that you only use once (this wastes memory) \n This code actually loops over that array twice! :( \n \n\n Luckily Guido and his team were generous enough to develop generators so we could just do this; \n\n def myRangeSmart(i):\n    n = 0\n    while n < i:\n       yield n\n       n = n + 1\n    return\n\nfor i in myRangeSmart(10):\n    print i\n \n\n Now upon each iteration a function on the generator called  next()  executes the function until it either reaches a 'yield' statement in which it stops and  'yields' the value or reaches the end of the function. In this case on the first call,  next()  executes up to the yield statement and yield 'n', on the next call it will execute the  increment statement, jump back to the 'while', evaluate it, and if true, it will stop and yield 'n' again, it will continue that way until the while condition returns false and the generator jumps to the end of the function. \n    ", "date_posted": "2018-05-20 11:04:36Z", "upvote": "\r\n            71\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "32331953", "answer_content": "\r\n Yield is an object \n\n A  return  in a function will return a single value. \n\n If you want  a function to return a huge set of values , use  yield . \n\n More importantly,  yield  is a  barrier . \n\n \n   like barrier in the CUDA language, it will not transfer control until it gets\n  completed. \n \n\n That is, it will run the code in your function from the beginning until it hits  yield . Then, it\u2019ll return the first value of the loop. \n\n Then, every other call will run the loop you have written in the function one more time, returning the next value until there isn't any value to return. \n    ", "date_posted": "2018-05-20 10:45:50Z", "upvote": "\r\n            67\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "39425637", "answer_content": "\r\n Many people use  return  rather than  yield , but in some cases  yield  can be more efficient and easier to work with. \n\n Here is an example which  yield  is definitely best for: \n\n \n   return  (in function) \n \n\n import random\n\ndef return_dates():\n    dates = [] # With 'return' you need to create a list then return it\n    for i in range(5):\n        date = random.choice([\"1st\", \"2nd\", \"3rd\", \"4th\", \"5th\", \"6th\", \"7th\", \"8th\", \"9th\", \"10th\"])\n        dates.append(date)\n    return dates\n \n\n \n   yield  (in function) \n \n\n def yield_dates():\n    for i in range(5):\n        date = random.choice([\"1st\", \"2nd\", \"3rd\", \"4th\", \"5th\", \"6th\", \"7th\", \"8th\", \"9th\", \"10th\"])\n        yield date # 'yield' makes a generator automatically which works\n                   # in a similar way. This is much more efficient.\n \n\n \n   Calling functions \n \n\n dates_list = return_dates()\nprint(dates_list)\nfor i in dates_list:\n    print(i)\n\ndates_generator = yield_dates()\nprint(dates_generator)\nfor i in dates_generator:\n    print(i)\n \n\n Both functions do the same thing, but  yield  uses three lines instead of five and has one less variable to worry about. \n\n \n   \n     This is the result from the code: \n   \n \n\n \n\n As you can see both functions do the same thing. The only difference is  return_dates()  gives a list and  yield_dates()  gives a generator. \n\n A real life example would be something like reading a file line by line or if you just want to make a generator. \n    ", "date_posted": "2018-05-20 11:02:52Z", "upvote": "\r\n            65\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "33788856", "answer_content": "\r\n The  yield  keyword simply collects returning results. Think of  yield  like  return += \n    ", "date_posted": "2016-04-23 03:16:19Z", "upvote": "\r\n            55\r\n        ", "accepted": "No", "user": {"stack_user_id": "4907496", "name": "Phillip", "reputation_score": "2,165"}, "answer_comments": []}, {"stack_answer_id": "30341713", "answer_content": "\r\n yield  is like a return element for a function. The difference is, that the  yield  element turns a function into a generator. A generator behaves just like a function until something is 'yielded'. The generator stops until it is next called, and continues from exactly the same point as it started. You can get a sequence of all the 'yielded' values in one, by calling  list(generator()) . \n    ", "date_posted": "2015-05-20 06:19:32Z", "upvote": "\r\n            52\r\n        ", "accepted": "No", "user": {"stack_user_id": "4884103", "name": "Will Dereham", "reputation_score": "976"}, "answer_comments": []}], "user": {"stack_user_id": "18300", "name": "Alex. S.", "reputation_score": "138k"}, "question_comments": [{"stack_question_id": "231767", "stack_question_comment_id": "129480481", "comment_content": "The Yield keyword in Python is similar to a return statement used for returning values or objects in Python. However, there is a slight difference. The yield statement returns a generator object to the one who calls the function which contains yield, instead of simply returning a value.", "user_id": null}]},
{"stack_question_id": "613183", "question_title": "How do I sort a dictionary by value?", "question_content": "\r\n                I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.\n\nI can sort on the keys, but how ...\r\n", "question_url": "/questions/613183/how-do-i-sort-a-dictionary-by-value", "date_posted": "Mar 5, 2009 at 0:49", "upvote": "3", "view": "4", "tags": ["python", "sorting", "dictionary"], "answers_count": "3", "answers": [{"stack_answer_id": "613218", "answer_content": "\r\n Python 3.7+ or CPython 3.6 \n Dicts preserve insertion order in Python 3.7+. Same in CPython 3.6, but  it's an implementation detail . \n >>> x = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}\n>>> {k: v for k, v in sorted(x.items(), key=lambda item: item[1])}\n{0: 0, 2: 1, 1: 2, 4: 3, 3: 4}\n \n or \n >>> dict(sorted(x.items(), key=lambda item: item[1]))\n{0: 0, 2: 1, 1: 2, 4: 3, 3: 4}\n \n Older Python \n It is not possible to sort a dictionary, only to get a representation of a dictionary that is sorted. Dictionaries are inherently orderless, but other types, such as lists and tuples, are not. So you need an ordered data type to represent sorted values, which will be a list\u2014probably a list of tuples. \n For instance, \n import operator\nx = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}\nsorted_x = sorted(x.items(), key=operator.itemgetter(1))\n \n sorted_x  will be a list of tuples sorted by the second element in each tuple.  dict(sorted_x) == x . \n And for those wishing to sort on keys instead of values: \n import operator\nx = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}\nsorted_x = sorted(x.items(), key=operator.itemgetter(0))\n \n In Python3 since  unpacking is not allowed  we can use \n x = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}\nsorted_x = sorted(x.items(), key=lambda kv: kv[1])\n \n If you want the output as a dict, you can use  collections.OrderedDict : \n import collections\n\nsorted_dict = collections.OrderedDict(sorted_x)\n \n    ", "date_posted": "2020-11-22 19:29:02Z", "upvote": "\r\n            6504\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "4518341", "name": "wjandrea", "reputation_score": "24.1k"}, "answer_comments": [{"stack_answer_id": "613218", "stack_answer_comment_id": "459741", "comment_content": "for timings on various dictionary sorting by value schemes:  ", "user_id": null}, {"stack_answer_id": "613218", "stack_answer_comment_id": "2787661", "comment_content": " will give you a descending ordering (by the second tuple element)", "user_id": null}, {"stack_answer_id": "613218", "stack_answer_comment_id": "3270439", "comment_content": "saidimu: Since we're already using ", "user_id": null}, {"stack_answer_id": "613218", "stack_answer_comment_id": "5594141", "comment_content": "In python3 I used a lambda: ", "user_id": null}, {"stack_answer_id": "613218", "stack_answer_comment_id": "123505096", "comment_content": "Where can I read more about the usage of ", "user_id": null}]}, {"stack_answer_id": "3177911", "answer_content": "\r\n As simple as:  sorted(dict1, key=dict1.get) \n\n Well, it is actually possible to do a \"sort by dictionary values\". Recently I had to do that in a Code Golf (Stack Overflow question  Code golf: Word frequency chart ). Abridged, the problem was of the kind: given a text, count how often each word is encountered and display a list of the top words, sorted by decreasing frequency.  \n\n If you construct a dictionary with the words as keys and the number of occurrences of each word as value, simplified here as: \n\n from collections import defaultdict\nd = defaultdict(int)\nfor w in text.split():\n    d[w] += 1\n \n\n then you can get a list of the words, ordered by frequency of use with  sorted(d, key=d.get)  - the sort iterates over the dictionary keys, using the number of word occurrences as a sort key .  \n\n for w in sorted(d, key=d.get, reverse=True):\n    print(w, d[w])\n \n\n I am writing this detailed explanation to illustrate what people often mean by \"I can easily sort a dictionary by key, but how do I sort by value\" - and I think the original post was trying to address such an issue. And the solution is to do sort of list of the keys, based on the values, as shown above. \n    ", "date_posted": "2020-03-10 14:42:24Z", "upvote": "\r\n            1548\r\n        ", "accepted": "No", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": [{"stack_answer_id": "3177911", "stack_answer_comment_id": "10448097", "comment_content": "This is also good but ", "user_id": null}, {"stack_answer_id": "3177911", "stack_answer_comment_id": "39602912", "comment_content": "@bli ", "user_id": null}, {"stack_answer_id": "3177911", "stack_answer_comment_id": "76481868", "comment_content": "i have come from the future to tell you of ", "user_id": null}]}, {"stack_answer_id": "2258273", "answer_content": "\r\n You could use: \n\n sorted(d.items(), key=lambda x: x[1])\n \n\n This will sort the dictionary by the values of each entry within the dictionary from smallest to largest. \n\n To sort it in descending order just add  reverse=True : \n\n sorted(d.items(), key=lambda x: x[1], reverse=True)\n \n\n Input: \n\n d = {'one':1,'three':3,'five':5,'two':2,'four':4}\na = sorted(d.items(), key=lambda x: x[1])    \nprint(a)\n \n\n Output: \n\n [('one', 1), ('two', 2), ('three', 3), ('four', 4), ('five', 5)]\n \n    ", "date_posted": "2020-01-10 09:43:23Z", "upvote": "\r\n            1098\r\n        ", "accepted": "No", "user": {"stack_user_id": "4815313", "name": "Suresh2692", "reputation_score": "3,633"}, "answer_comments": [{"stack_answer_id": "2258273", "stack_answer_comment_id": "21031477", "comment_content": "From what I've seen (", "user_id": null}, {"stack_answer_id": "2258273", "stack_answer_comment_id": "47252672", "comment_content": "I'd prefer ", "user_id": null}, {"stack_answer_id": "2258273", "stack_answer_comment_id": "55249296", "comment_content": "@Keyo shouldn't that be it returns an ordered list of keys (sorted by values) not ", "user_id": null}, {"stack_answer_id": "2258273", "stack_answer_comment_id": "58175437", "comment_content": "@Claudiu I like that ", "user_id": null}, {"stack_answer_id": "2258273", "stack_answer_comment_id": "97286619", "comment_content": "If you wrap this in an ", "user_id": null}]}, {"stack_answer_id": "613228", "answer_content": "\r\n Dicts can't be sorted, but you can build a sorted list from them. \n\n A sorted list of dict values: \n\n sorted(d.values())\n \n\n A list of (key, value) pairs, sorted by value: \n\n from operator import itemgetter\nsorted(d.items(), key=itemgetter(1))\n \n    ", "date_posted": "2014-09-16 17:26:10Z", "upvote": "\r\n            261\r\n        ", "accepted": "No", "user": {"stack_user_id": "13169", "name": "Roberto Bonvallet", "reputation_score": "30.2k"}, "answer_comments": [{"stack_answer_id": "613228", "stack_answer_comment_id": "14505868", "comment_content": "What order are keys with the same value placed in? I sorted the list by keys first, then by values, but the order of the keys with the same value does not remain.", "user_id": null}, {"stack_answer_id": "613228", "stack_answer_comment_id": "108645446", "comment_content": "Dicts can now be sorted, starting with CPython 3.6 and all other Python implementations starting with 3.7", "user_id": null}, {"stack_answer_id": "613228", "stack_answer_comment_id": "126263725", "comment_content": "True at the time, but now python dictionaries preserve the order in which items were inserted already by default. And therefore they can be sorted.", "user_id": null}]}, {"stack_answer_id": "3177025", "answer_content": "\r\n In recent Python 2.7, we have the new  OrderedDict  type, which remembers the order in which the items were added. \n\n >>> d = {\"third\": 3, \"first\": 1, \"fourth\": 4, \"second\": 2}\n\n>>> for k, v in d.items():\n...     print \"%s: %s\" % (k, v)\n...\nsecond: 2\nfourth: 4\nthird: 3\nfirst: 1\n\n>>> d\n{'second': 2, 'fourth': 4, 'third': 3, 'first': 1}\n \n\n To make a new ordered dictionary from the original, sorting by the values: \n\n >>> from collections import OrderedDict\n>>> d_sorted_by_value = OrderedDict(sorted(d.items(), key=lambda x: x[1]))\n \n\n The OrderedDict behaves like a normal dict: \n\n >>> for k, v in d_sorted_by_value.items():\n...     print \"%s: %s\" % (k, v)\n...\nfirst: 1\nsecond: 2\nthird: 3\nfourth: 4\n\n>>> d_sorted_by_value\nOrderedDict([('first': 1), ('second': 2), ('third': 3), ('fourth': 4)])\n \n    ", "date_posted": "2014-04-03 16:59:39Z", "upvote": "\r\n            180\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "3177025", "stack_answer_comment_id": "3271246", "comment_content": "This is not what the question is about - it is not about maintaining order of keys but about \"sorting by value\"", "user_id": null}, {"stack_answer_id": "3177025", "stack_answer_comment_id": "3272707", "comment_content": "@Nas Banov: it is NOT sorting by the key. it is sorting in the order, we create the items. in our case, we sort by the value. unfortunately, the 3-item dict was unfortunately chosen so the order was the same, when sorted voth by value and key, so i expanded the sample dict.", "user_id": null}, {"stack_answer_id": "3177025", "stack_answer_comment_id": "29524413", "comment_content": " Can you explain what the ", "user_id": null}, {"stack_answer_id": "3177025", "stack_answer_comment_id": "86527438", "comment_content": "@Boern ", "user_id": null}, {"stack_answer_id": "3177025", "stack_answer_comment_id": "102011442", "comment_content": "Note: As of 3.6 (as a CPython/PyPy implementation detail) and as of 3.7 (as a Python language guarantee), plain ", "user_id": null}]}, {"stack_answer_id": "34103440", "answer_content": "\r\n UPDATE: 5 DECEMBER 2015 using Python 3.5 \n\n Whilst I found the accepted answer useful, I was also surprised that it hasn't been updated to reference  OrderedDict  from the standard library  collections  module as a viable, modern alternative - designed to solve exactly this type of problem. \n\n from operator import itemgetter\nfrom collections import OrderedDict\n\nx = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}\nsorted_x = OrderedDict(sorted(x.items(), key=itemgetter(1)))\n# OrderedDict([(0, 0), (2, 1), (1, 2), (4, 3), (3, 4)])\n \n\n The official  OrderedDict  documentation offers a very similar example too, but using a lambda for the sort function: \n\n # regular unsorted dictionary\nd = {'banana': 3, 'apple':4, 'pear': 1, 'orange': 2}\n\n# dictionary sorted by value\nOrderedDict(sorted(d.items(), key=lambda t: t[1]))\n# OrderedDict([('pear', 1), ('orange', 2), ('banana', 3), ('apple', 4)])\n \n    ", "date_posted": "2015-12-15 05:54:53Z", "upvote": "\r\n            120\r\n        ", "accepted": "No", "user": {"stack_user_id": "1882064", "name": "arcseldon", "reputation_score": "33.3k"}, "answer_comments": [{"stack_answer_id": "34103440", "stack_answer_comment_id": "126263884", "comment_content": "can you explain what itemgetter does in this example? otherwise this seems just as cryptic as using a lamba", "user_id": null}]}, {"stack_answer_id": "613230", "answer_content": "\r\n Pretty much the same as  Hank Gay's answer : \n\n sorted([(value,key) for (key,value) in mydict.items()])\n \n\n Or optimized slightly as suggested by John Fouhy: \n\n sorted((value,key) for (key,value) in mydict.items())\n \n    ", "date_posted": "2019-03-12 05:18:46Z", "upvote": "\r\n            110\r\n        ", "accepted": "No", "user": {"stack_user_id": "11044033", "name": "Justin Batch", "reputation_score": "17"}, "answer_comments": [{"stack_answer_id": "613230", "stack_answer_comment_id": "426122", "comment_content": "..and as with Hank Gay's answer, you don't need the square brackets.  sorted() will happily take any iterable, such as a generator expression.", "user_id": null}, {"stack_answer_id": "613230", "stack_answer_comment_id": "2787653", "comment_content": "You may still need to swap the (value,key) tuple elements to end up with the (key, value). Another list comprehension is then needed.  ", "user_id": null}, {"stack_answer_id": "613230", "stack_answer_comment_id": "82368076", "comment_content": "no, it's better to leave square brackets, because ", "user_id": null}, {"stack_answer_id": "613230", "stack_answer_comment_id": "128345565", "comment_content": "I'm confused, this returns an array of tuples not a dict. IMO you are missing the dict comprehension part:  ", "user_id": null}]}, {"stack_answer_id": "39424969", "answer_content": "\r\n As of  Python 3.6  the built-in dict will be ordered \n\n Good news, so the OP's original use case of mapping pairs retrieved from a database with unique string ids as keys and numeric values as values into a built-in Python v3.6+ dict, should now respect the insert order. \n\n If say the resulting two column table expressions from a database query like: \n\n SELECT a_key, a_value FROM a_table ORDER BY a_value;\n \n\n would be stored in two Python tuples, k_seq and v_seq (aligned by numerical index and with the same length of course), then: \n\n k_seq = ('foo', 'bar', 'baz')\nv_seq = (0, 1, 42)\nordered_map = dict(zip(k_seq, v_seq))\n \n\n Allow to output later as: \n\n for k, v in ordered_map.items():\n    print(k, v)\n \n\n yielding in this case (for the new Python 3.6+ built-in dict!): \n\n foo 0\nbar 1\nbaz 42\n \n\n in the same ordering per value of v. \n\n Where in the Python 3.5 install on my machine it currently yields: \n\n bar 1\nfoo 0\nbaz 42\n \n\n Details: \n\n As proposed in 2012 by Raymond Hettinger (cf. mail on python-dev with subject  \"More compact dictionaries with faster iteration\" ) and now (in 2016) announced in a mail by Victor Stinner to python-dev with subject  \"Python 3.6 dict becomes compact and gets a private version; and keywords become ordered\"  due to the fix/implementation of issue 27350  \"Compact and ordered dict\"  in Python 3.6 we will now be able, to use a built-in dict to maintain insert order!! \n\n Hopefully this will lead to a thin layer OrderedDict implementation as a first step. As @JimFasarakis-Hilliard indicated, some see use cases for the OrderedDict type also in the future. I think the Python community at large will carefully inspect, if this will stand the test of time, and what the next steps will be. \n\n Time to rethink our coding habits to not miss the possibilities opened by stable ordering of: \n\n \n Keyword arguments and \n (intermediate) dict storage \n \n\n The first because it eases dispatch in the implementation of functions and methods in some cases. \n\n The second as it encourages to more easily use  dict s as intermediate storage in processing pipelines. \n\n Raymond Hettinger kindly provided documentation explaining \" The Tech Behind Python 3.6 Dictionaries \" - from his San Francisco Python Meetup Group presentation 2016-DEC-08. \n\n And maybe quite some Stack Overflow high decorated question and answer pages will receive variants of this information and many high quality answers will require a per version update too. \n\n Caveat Emptor (but also see below update 2017-12-15): \n\n As @ajcr rightfully notes: \"The order-preserving aspect of this new implementation is considered an implementation detail and should not be relied upon.\" (from the  whatsnew36 ) not nit picking,  but  the citation was cut a bit pessimistic ;-). It continues as \" (this may change in the future, but it is desired to have this new dict implementation in the language for a few releases before changing the language spec to mandate order-preserving semantics for all current and future Python implementations; this also helps preserve backwards-compatibility with older versions of the language where random iteration order is still in effect, e.g. Python 3.5).\" \n\n So as in some human languages (e.g. German), usage shapes the language, and the will now has been declared ... in  whatsnew36 . \n\n Update 2017-12-15: \n\n In a  mail to the python-dev list , Guido van Rossum declared: \n\n \n   Make it so. \"Dict keeps insertion order\" is the ruling. Thanks!  \n \n\n So, the version 3.6 CPython side-effect of dict insertion ordering is now becoming part of the language spec (and not anymore only an implementation detail). That mail thread also surfaced some distinguishing design goals for  collections.OrderedDict  as reminded by Raymond Hettinger during discussion. \n    ", "date_posted": "2017-12-16 15:47:55Z", "upvote": "\r\n            85\r\n        ", "accepted": "No", "user": {"stack_user_id": "378826", "name": "Dilettant", "reputation_score": "3,169"}, "answer_comments": [{"stack_answer_id": "39424969", "stack_answer_comment_id": "66183881", "comment_content": "@ajcr thanks for the caveat, very appreciated -  as smileys and maybe's were weaved into my response,these should indicated, the change is massive but of course, only available for CPython (reference implementation) and PyPy. For something completely different ... I rarely talk to non-implementation details when coding man-machine instructions. If it would only have been Jython ;-) ... I might not have had the courage to write it.", "user_id": null}, {"stack_answer_id": "39424969", "stack_answer_comment_id": "69358529", "comment_content": " definitely won't be dropped; instead, it will become a thin wrapper around the current dict implementation (so you might add that it will become more compact, too). Adding that snippet with the ", "user_id": null}, {"stack_answer_id": "39424969", "stack_answer_comment_id": "85153020", "comment_content": "In a response to this answer, and structured dicts, I posted ", "user_id": null}]}, {"stack_answer_id": "7237524", "answer_content": "\r\n It can often be very handy to use  namedtuple . For example, you have a dictionary of 'name' as keys and 'score' as values and you want to sort on 'score': \n\n import collections\nPlayer = collections.namedtuple('Player', 'score name')\nd = {'John':5, 'Alex':10, 'Richard': 7}\n \n\n sorting with lowest score first: \n\n worst = sorted(Player(v,k) for (k,v) in d.items())\n \n\n sorting with highest score first: \n\n best = sorted([Player(v,k) for (k,v) in d.items()], reverse=True)\n \n\n Now you can get the name and score of, let's say the second-best player (index=1) very Pythonically like this: \n\n player = best[1]\nplayer.name\n    'Richard'\nplayer.score\n    7\n \n    ", "date_posted": "2017-04-24 02:11:59Z", "upvote": "\r\n            83\r\n        ", "accepted": "No", "user": {"stack_user_id": "2470818", "name": "vallentin", "reputation_score": "21.7k"}, "answer_comments": [{"stack_answer_id": "7237524", "stack_answer_comment_id": "71369022", "comment_content": "How could I convert it back to a dictionary?", "user_id": null}, {"stack_answer_id": "7237524", "stack_answer_comment_id": "71976890", "comment_content": "as_list=[Player(v,k) for (k,v) in d.items()]       as_dict=dict((p.name,p.score) for p in as_list)", "user_id": null}]}, {"stack_answer_id": "4215710", "answer_content": "\r\n I had the same problem, and I solved it like this: \n\n WantedOutput = sorted(MyDict, key=lambda x : MyDict[x]) \n \n\n (People who answer \"It is not possible to sort a dict\" did not read the question! In fact, \"I can sort on the keys, but how can I sort based on the values?\" clearly means that he wants a list of the keys sorted according to the value of their values.) \n\n Please notice that the order is not well defined (keys with the same value will be in an arbitrary order in the output list). \n    ", "date_posted": "2017-11-28 13:44:24Z", "upvote": "\r\n            52\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "4215710", "stack_answer_comment_id": "66528932", "comment_content": "Note that you're both iterating the dictionary and fetching values by their key, so performance wise this is not an optimal solution.", "user_id": null}, {"stack_answer_id": "4215710", "stack_answer_comment_id": "95143642", "comment_content": "@Dejell: as the contributor says, he interprets the question as \"can I get the list of keys sorted according to the values\". We don't need the values in the result, we have them in the dictionary.", "user_id": null}]}, {"stack_answer_id": "11230132", "answer_content": "\r\n If values are numeric you may also use  Counter  from  collections . \n\n from collections import Counter\n\nx = {'hello': 1, 'python': 5, 'world': 3}\nc = Counter(x)\nprint(c.most_common())\n\n>> [('python', 5), ('world', 3), ('hello', 1)]    \n \n    ", "date_posted": "2019-05-17 13:48:42Z", "upvote": "\r\n            50\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "11230132", "stack_answer_comment_id": "31210677", "comment_content": "what about if you dictionary is >>> x={'hello':1,'python':5, 'world':300}", "user_id": null}, {"stack_answer_id": "11230132", "stack_answer_comment_id": "31211363", "comment_content": "@yopy ", "user_id": null}]}, {"stack_answer_id": "18375444", "answer_content": "\r\n In Python 2.7, simply do: \n\n from collections import OrderedDict\n# regular unsorted dictionary\nd = {'banana': 3, 'apple':4, 'pear': 1, 'orange': 2}\n\n# dictionary sorted by key\nOrderedDict(sorted(d.items(), key=lambda t: t[0]))\nOrderedDict([('apple', 4), ('banana', 3), ('orange', 2), ('pear', 1)])\n\n# dictionary sorted by value\nOrderedDict(sorted(d.items(), key=lambda t: t[1]))\nOrderedDict([('pear', 1), ('orange', 2), ('banana', 3), ('apple', 4)])\n \n\n copy-paste from :  http://docs.python.org/dev/library/collections.html#ordereddict-examples-and-recipes \n\n Enjoy ;-) \n    ", "date_posted": "2013-08-22 08:38:48Z", "upvote": "\r\n            41\r\n        ", "accepted": "No", "user": {"stack_user_id": "1415325", "name": "sweetdream", "reputation_score": "1,171"}, "answer_comments": []}, {"stack_answer_id": "5227519", "answer_content": "\r\n This is the code: \n\n import operator\norigin_list = [\n    {\"name\": \"foo\", \"rank\": 0, \"rofl\": 20000},\n    {\"name\": \"Silly\", \"rank\": 15, \"rofl\": 1000},\n    {\"name\": \"Baa\", \"rank\": 300, \"rofl\": 20},\n    {\"name\": \"Zoo\", \"rank\": 10, \"rofl\": 200},\n    {\"name\": \"Penguin\", \"rank\": -1, \"rofl\": 10000}\n]\nprint \">> Original >>\"\nfor foo in origin_list:\n    print foo\n\nprint \"\\n>> Rofl sort >>\"\nfor foo in sorted(origin_list, key=operator.itemgetter(\"rofl\")):\n    print foo\n\nprint \"\\n>> Rank sort >>\"\nfor foo in sorted(origin_list, key=operator.itemgetter(\"rank\")):\n    print foo\n \n\n Here are the results: \n\n Original \n\n {'name': 'foo', 'rank': 0, 'rofl': 20000}\n{'name': 'Silly', 'rank': 15, 'rofl': 1000}\n{'name': 'Baa', 'rank': 300, 'rofl': 20}\n{'name': 'Zoo', 'rank': 10, 'rofl': 200}\n{'name': 'Penguin', 'rank': -1, 'rofl': 10000}\n \n\n Rofl \n\n {'name': 'Baa', 'rank': 300, 'rofl': 20}\n{'name': 'Zoo', 'rank': 10, 'rofl': 200}\n{'name': 'Silly', 'rank': 15, 'rofl': 1000}\n{'name': 'Penguin', 'rank': -1, 'rofl': 10000}\n{'name': 'foo', 'rank': 0, 'rofl': 20000}\n \n\n Rank   \n\n {'name': 'Penguin', 'rank': -1, 'rofl': 10000}\n{'name': 'foo', 'rank': 0, 'rofl': 20000}\n{'name': 'Zoo', 'rank': 10, 'rofl': 200}\n{'name': 'Silly', 'rank': 15, 'rofl': 1000}\n{'name': 'Baa', 'rank': 300, 'rofl': 20}\n \n    ", "date_posted": "2016-03-02 07:42:26Z", "upvote": "\r\n            31\r\n        ", "accepted": "No", "user": {"stack_user_id": "1091386", "name": "icedwater", "reputation_score": "4,542"}, "answer_comments": []}, {"stack_answer_id": "22903797", "answer_content": "\r\n Try the following approach. Let us define a dictionary called mydict with the following data: \n\n mydict = {'carl':40,\n          'alan':2,\n          'bob':1,\n          'danny':3}\n \n\n If one wanted to sort the dictionary by keys, one could do something like: \n\n for key in sorted(mydict.iterkeys()):\n    print \"%s: %s\" % (key, mydict[key])\n \n\n This should return the following output: \n\n alan: 2\nbob: 1\ncarl: 40\ndanny: 3\n \n\n On the other hand, if one wanted to sort a dictionary by value (as is asked in the question), one could do the following: \n\n for key, value in sorted(mydict.iteritems(), key=lambda (k,v): (v,k)):\n    print \"%s: %s\" % (key, value)\n \n\n The result of this command (sorting the dictionary by value) should return the following: \n\n bob: 1\nalan: 2\ndanny: 3\ncarl: 40\n \n    ", "date_posted": "2018-05-23 23:11:19Z", "upvote": "\r\n            31\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "22903797", "stack_answer_comment_id": "76931274", "comment_content": "Awesome! ", "user_id": null}, {"stack_answer_id": "22903797", "stack_answer_comment_id": "119924329", "comment_content": "this doesn't work in later versions of python that dont support tuple unpacking and where dicts no longer have iteritems()", "user_id": null}]}, {"stack_answer_id": "52345214", "answer_content": "\r\n Starting from Python 3.6,  dict  objects are now ordered by insertion order. It's officially in the specs of Python 3.7. \n\n >>> words = {\"python\": 2, \"blah\": 4, \"alice\": 3}\n>>> dict(sorted(words.items(), key=lambda x: x[1]))\n{'python': 2, 'alice': 3, 'blah': 4}\n \n\n Before that, you had to use  OrderedDict . \n\n Python 3.7 documentation  says: \n\n \n   Changed in version 3.7: Dictionary order is guaranteed to be insertion\n  order. This behavior was implementation detail of CPython from 3.6.  \n \n    ", "date_posted": "2018-10-24 14:19:05Z", "upvote": "\r\n            30\r\n        ", "accepted": "No", "user": {"stack_user_id": "1787973", "name": "Maxime Ch\u00e9ramy", "reputation_score": "16.6k"}, "answer_comments": [{"stack_answer_id": "52345214", "stack_answer_comment_id": "93639658", "comment_content": "works great! ", "user_id": null}]}, {"stack_answer_id": "613326", "answer_content": "\r\n You can create an \"inverted index\", also \n\n from collections import defaultdict\ninverse= defaultdict( list )\nfor k, v in originalDict.items():\n    inverse[v].append( k )\n \n\n Now your inverse has the values; each value has a list of applicable keys. \n\n for k in sorted(inverse):\n    print k, inverse[k]\n \n    ", "date_posted": "2009-03-05 01:52:18Z", "upvote": "\r\n            27\r\n        ", "accepted": "No", "user": {"stack_user_id": "10661", "name": "S.Lott", "reputation_score": "375k"}, "answer_comments": []}, {"stack_answer_id": "15310681", "answer_content": "\r\n You can use the  collections.Counter . Note, this will work for both numeric and non-numeric values. \n\n >>> x = {1: 2, 3: 4, 4:3, 2:1, 0:0}\n>>> from collections import Counter\n>>> #To sort in reverse order\n>>> Counter(x).most_common()\n[(3, 4), (4, 3), (1, 2), (2, 1), (0, 0)]\n>>> #To sort in ascending order\n>>> Counter(x).most_common()[::-1]\n[(0, 0), (2, 1), (1, 2), (4, 3), (3, 4)]\n>>> #To get a dictionary sorted by values\n>>> from collections import OrderedDict\n>>> OrderedDict(Counter(x).most_common()[::-1])\nOrderedDict([(0, 0), (2, 1), (1, 2), (4, 3), (3, 4)])\n \n    ", "date_posted": "2014-04-03 17:04:58Z", "upvote": "\r\n            25\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "15310681", "stack_answer_comment_id": "34847147", "comment_content": "How is this different from ", "user_id": null}]}, {"stack_answer_id": "26049456", "answer_content": "\r\n You can use a  skip dict  which is a dictionary that's permanently sorted by value. \n\n >>> data = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}\n>>> SkipDict(data)\n{0: 0.0, 2: 1.0, 1: 2.0, 4: 3.0, 3: 4.0}\n \n\n If you use  keys() ,  values()  or  items()  then you'll iterate in sorted order by value. \n\n It's implemented using the  skip list  datastructure. \n    ", "date_posted": "2014-09-25 22:56:55Z", "upvote": "\r\n            20\r\n        ", "accepted": "No", "user": {"stack_user_id": "647151", "name": "malthe", "reputation_score": "975"}, "answer_comments": [{"stack_answer_id": "26049456", "stack_answer_comment_id": "106284747", "comment_content": "can we change the order of sort, right now, it is asending, but I want decsending.", "user_id": null}, {"stack_answer_id": "26049456", "stack_answer_comment_id": "106286713", "comment_content": "afaik you would have to negate your values in order to reverse the ordering", "user_id": null}]}, {"stack_answer_id": "44187197", "answer_content": "\r\n You can also use custom function that can be passed to key. \n\n def dict_val(x):\n    return x[1]\nx = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}\nsorted_x = sorted(x.items(), key=dict_val)\n \n    ", "date_posted": "2019-05-17 14:55:22Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "44187197", "stack_answer_comment_id": "116323245", "comment_content": "This is the only answer that worked so far in python 2.7", "user_id": null}]}, {"stack_answer_id": "22150003", "answer_content": "\r\n The collections solution mentioned in another answer is absolutely superb, because you retain a connection between the key and value which in the case of dictionaries is extremely important. \n I don't agree with the number one choice presented in another answer, because it throws away the keys. \n I used the solution mentioned above (code shown below) and retained access to both keys and values and in my case the ordering was on the values, but the importance was the ordering of the keys after ordering the values. \n from collections import Counter\n\nx = {'hello':1, 'python':5, 'world':3}\nc=Counter(x)\nprint( c.most_common() )\n\n\n>> [('python', 5), ('world', 3), ('hello', 1)]\n \n    ", "date_posted": "2021-10-07 10:56:15Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "2211268", "name": "Eamonn Kenny", "reputation_score": "1,681"}, "answer_comments": []}, {"stack_answer_id": "31741215", "answer_content": "\r\n Of course, remember, you need to use  OrderedDict  because regular Python dictionaries don't keep the original order.  \n\n from collections import OrderedDict\na = OrderedDict(sorted(originalDict.items(), key=lambda x: x[1]))\n \n\n \n\n If you do not have Python 2.7 or higher, the best you can do is iterate over the values in a generator function. (There is an  OrderedDict  for 2.4 and 2.6   here , but  \n\n a) I don't know about how well it works  \n\n and  \n\n b) You have to download and install it of course. If you do not have administrative access, then I'm afraid the option's out.) \n\n \n\n def gen(originalDict):\n    for x, y in sorted(zip(originalDict.keys(), originalDict.values()), key=lambda z: z[1]):\n        yield (x, y)\n    #Yields as a tuple with (key, value). You can iterate with conditional clauses to get what you want. \n\nfor bleh, meh in gen(myDict):\n    if bleh == \"foo\":\n        print(myDict[bleh])\n \n\n \n\n You can also print out every value \n\n for bleh, meh in gen(myDict):\n    print(bleh, meh)\n \n\n Please remember to remove the parentheses after print if not using Python 3.0 or above \n    ", "date_posted": "2019-05-17 16:17:06Z", "upvote": "\r\n            17\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": [{"stack_answer_id": "31741215", "stack_answer_comment_id": "94560075", "comment_content": " \u2014 as of Python 3.7, they do.", "user_id": null}]}, {"stack_answer_id": "4068769", "answer_content": "\r\n from django.utils.datastructures import SortedDict\n\ndef sortedDictByKey(self,data):\n    \"\"\"Sorted dictionary order by key\"\"\"\n    sortedDict = SortedDict()\n    if data:\n        if isinstance(data, dict):\n            sortedKey = sorted(data.keys())\n            for k in sortedKey:\n                sortedDict[k] = data[k]\n    return sortedDict\n \n    ", "date_posted": "2010-11-01 12:16:41Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "615617", "name": "Argun", "reputation_score": "417"}, "answer_comments": [{"stack_answer_id": "4068769", "stack_answer_comment_id": "8703854", "comment_content": "question was: sort by value, not by keys... I like seeing a function. You can import collections and of course use sorted(data.values())", "user_id": null}]}, {"stack_answer_id": "30949456", "answer_content": "\r\n Here is a solution using zip on  d.values()  and  d.keys() .  A few lines down this link (on Dictionary view objects) is: \n\n \n   This allows the creation of (value, key) pairs using zip(): pairs = zip(d.values(), d.keys()). \n \n\n So we can do the following: \n\n d = {'key1': 874.7, 'key2': 5, 'key3': 8.1}\n\nd_sorted = sorted(zip(d.values(), d.keys()))\n\nprint d_sorted \n# prints: [(5, 'key2'), (8.1, 'key3'), (874.7, 'key1')]\n \n    ", "date_posted": "2015-06-20 01:44:58Z", "upvote": "\r\n            15\r\n        ", "accepted": "No", "user": {"stack_user_id": "4663466", "name": "Scott", "reputation_score": "5,681"}, "answer_comments": []}, {"stack_answer_id": "49073645", "answer_content": "\r\n As pointed out by Dilettant , Python 3.6 will now  keep the order ! I thought I'd share a function I wrote that eases the sorting of an iterable (tuple, list, dict). In the latter case, you can sort either on keys or values, and it can take numeric comparison into account.  Only for >= 3.6! \n When you try using sorted on an iterable that holds e.g. strings as well as ints, sorted() will fail. Of course you can force string comparison with str(). However, in some cases you want to do  actual  numeric comparison where  12  is smaller than  20  (which is not the case in string comparison). So I came up with the following. When you want explicit numeric comparison you can use the flag  num_as_num  which will try to do explicit numeric sorting by trying to convert all values to floats. If that succeeds, it will do numeric sorting, otherwise it'll resort to string comparison. \n Comments for improvement welcome. \n def sort_iterable(iterable, sort_on=None, reverse=False, num_as_num=False):\n    def _sort(i):\n      # sort by 0 = keys, 1 values, None for lists and tuples\n      try:\n        if num_as_num:\n          if i is None:\n            _sorted = sorted(iterable, key=lambda v: float(v), reverse=reverse)\n          else:\n            _sorted = dict(sorted(iterable.items(), key=lambda v: float(v[i]), reverse=reverse))\n        else:\n          raise TypeError\n      except (TypeError, ValueError):\n        if i is None:\n          _sorted = sorted(iterable, key=lambda v: str(v), reverse=reverse)\n        else:\n          _sorted = dict(sorted(iterable.items(), key=lambda v: str(v[i]), reverse=reverse))\n      \n      return _sorted\n      \n    if isinstance(iterable, list):\n      sorted_list = _sort(None)\n      return sorted_list\n    elif isinstance(iterable, tuple):\n      sorted_list = tuple(_sort(None))\n      return sorted_list\n    elif isinstance(iterable, dict):\n      if sort_on == 'keys':\n        sorted_dict = _sort(0)\n        return sorted_dict\n      elif sort_on == 'values':\n        sorted_dict = _sort(1)\n        return sorted_dict\n      elif sort_on is not None:\n        raise ValueError(f\"Unexpected value {sort_on} for sort_on. When sorting a dict, use key or values\")\n    else:\n      raise TypeError(f\"Unexpected type {type(iterable)} for iterable. Expected a list, tuple, or dict\")\n \n    ", "date_posted": "2021-02-19 09:00:54Z", "upvote": "\r\n            14\r\n        ", "accepted": "No", "user": {"stack_user_id": "1150683", "name": "Bram Vanroy", "reputation_score": "25.5k"}, "answer_comments": []}, {"stack_answer_id": "50554874", "answer_content": "\r\n Just learned relevant skill from  Python for Everybody . \n\n You may use a temporary list to help you to sort the dictionary: \n\n #Assume dictionary to be:\nd = {'apple': 500.1, 'banana': 1500.2, 'orange': 1.0, 'pineapple': 789.0}\n\n# create a temporary list\ntmp = []\n\n# iterate through the dictionary and append each tuple into the temporary list \nfor key, value in d.items():\n    tmptuple = (value, key)\n    tmp.append(tmptuple)\n\n# sort the list in ascending order\ntmp = sorted(tmp)\n\nprint (tmp)\n \n\n If you want to sort the list in descending order, simply change the original sorting line to: \n\n tmp = sorted(tmp, reverse=True)\n \n\n Using list comprehension, the one liner would be: \n\n #Assuming the dictionary looks like\nd = {'apple': 500.1, 'banana': 1500.2, 'orange': 1.0, 'pineapple': 789.0}\n#One liner for sorting in ascending order\nprint (sorted([(v, k) for k, v in d.items()]))\n#One liner for sorting in descending order\nprint (sorted([(v, k) for k, v in d.items()], reverse=True))\n \n\n Sample Output: \n\n #Asending order\n[(1.0, 'orange'), (500.1, 'apple'), (789.0, 'pineapple'), (1500.2, 'banana')]\n#Descending order\n[(1500.2, 'banana'), (789.0, 'pineapple'), (500.1, 'apple'), (1.0, 'orange')]\n \n    ", "date_posted": "2018-05-27 17:59:56Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "5015739", "name": "mcgag", "reputation_score": "195"}, "answer_comments": [{"stack_answer_id": "50554874", "stack_answer_comment_id": "108965274", "comment_content": "If you want to print it in the initial format you should do:print ([(k,v) for v,k in sorted([(v,k) for k,v in d.items()])]) . The output is: [('orange', 1.0), ('apple', 500.1), ('pineapple', 789.0), ('banana', 1500.2)]. With [(k,v) for v,k in sorted([(v,k) for k,v in d.items()], reverse = True)]  the output is: [('banana', 1500.2), ('pineapple', 789.0), ('apple', 500.1), ('orange', 1.0)]", "user_id": null}]}, {"stack_answer_id": "7817348", "answer_content": "\r\n Use  ValueSortedDict  from  dicts : \n\n from dicts.sorteddict import ValueSortedDict\nd = {1: 2, 3: 4, 4:3, 2:1, 0:0}\nsorted_dict = ValueSortedDict(d)\nprint sorted_dict.items() \n\n[(0, 0), (2, 1), (1, 2), (4, 3), (3, 4)]\n \n    ", "date_posted": "2011-10-19 06:25:41Z", "upvote": "\r\n            10\r\n        ", "accepted": "No", "user": {"stack_user_id": "700820", "name": "ponty", "reputation_score": "594"}, "answer_comments": []}, {"stack_answer_id": "7947321", "answer_content": "\r\n Iterate through a dict and sort it by its values in descending order: \n\n $ python --version\nPython 3.2.2\n\n$ cat sort_dict_by_val_desc.py \ndictionary = dict(siis = 1, sana = 2, joka = 3, tuli = 4, aina = 5)\nfor word in sorted(dictionary, key=dictionary.get, reverse=True):\n  print(word, dictionary[word])\n\n$ python sort_dict_by_val_desc.py \naina 5\ntuli 4\njoka 3\nsana 2\nsiis 1\n \n    ", "date_posted": "2011-10-30 19:42:06Z", "upvote": "\r\n            10\r\n        ", "accepted": "No", "user": {"stack_user_id": "1021036", "name": "juhoh", "reputation_score": "109"}, "answer_comments": []}, {"stack_answer_id": "8992838", "answer_content": "\r\n If your values are integers, and you use Python 2.7 or newer, you can use  collections.Counter  instead of  dict . The  most_common  method will give you all items, sorted by the value. \n    ", "date_posted": "2012-01-24 19:50:43Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "99057", "name": "Petr Viktorin", "reputation_score": "63.3k"}, "answer_comments": []}, {"stack_answer_id": "8148132", "answer_content": "\r\n This works in 3.1.x: \n\n import operator\nslovar_sorted=sorted(slovar.items(), key=operator.itemgetter(1), reverse=True)\nprint(slovar_sorted)\n \n    ", "date_posted": "2012-11-06 19:27:31Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "442945", "name": "Nathaniel Ford", "reputation_score": "19.3k"}, "answer_comments": []}, {"stack_answer_id": "15587800", "answer_content": "\r\n For the sake of completeness, I am posting a solution using  heapq . Note, this method will work for both numeric and non-numeric values \n\n >>> x = {1: 2, 3: 4, 4:3, 2:1, 0:0}\n>>> x_items = x.items()\n>>> heapq.heapify(x_items)\n>>> #To sort in reverse order\n>>> heapq.nlargest(len(x_items),x_items, operator.itemgetter(1))\n[(3, 4), (4, 3), (1, 2), (2, 1), (0, 0)]\n>>> #To sort in ascending order\n>>> heapq.nsmallest(len(x_items),x_items, operator.itemgetter(1))\n[(0, 0), (2, 1), (1, 2), (4, 3), (3, 4)]\n \n    ", "date_posted": "2013-03-23 14:19:53Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "977038", "name": "Abhijit", "reputation_score": "59.7k"}, "answer_comments": []}], "user": {"stack_user_id": "2786", "name": "Gern Blanston", "reputation_score": "42.2k"}, "question_comments": [{"stack_question_id": "613183", "stack_question_comment_id": "3270272", "comment_content": "The dictionary data structure does not have inherent order. You can iterate through it but there's nothing to guarantee that the iteration will follow any particular order. This is by design, so your best bet is probaly using anohter data structure for representation.", "user_id": null}, {"stack_question_id": "613183", "stack_question_comment_id": "20901347", "comment_content": "\"sorted()\" can operate on dictionaries (and returns a list of sorted keys), so I think he's aware of this. Without knowing his program, it's absurd to tell someone they're using the wrong data structure. If fast lookups are what you need 90% of the time, then a dict is probably what you want.", "user_id": null}, {"stack_question_id": "613183", "stack_question_comment_id": "59347975", "comment_content": "All three outputs (keys, values, both) for sorting dictionaries are covered here in a clear and concise style: ", "user_id": null}, {"stack_question_id": "613183", "stack_question_comment_id": "79215136", "comment_content": "@Daishiman The base class might not be ordered but ", "user_id": null}, {"stack_question_id": "613183", "stack_question_comment_id": "94813348", "comment_content": "In Python 3.6+ dictionaries preserve insertion order. This is, of course, not the same as possibility of sorting them by value, but on the other hand it is no longer valid to say that \"dictionary data structure does not have inherent order\".", "user_id": null}]},
{"stack_question_id": "1101750", "question_title": "Tkinter: AttributeError: NoneType object has no attribute <attribute name>", "question_content": "\r\n                I've created this simple GUI:\n\nfrom tkinter import *\n\nroot = Tk()\n\ndef grabText(event):\n    print(entryBox.get())    \n\nentryBox = Entry(root, width=60).grid(row=2, column=1, sticky=W)\n\ngrabBtn = ...\r\n", "question_url": "/questions/1101750/tkinter-attributeerror-nonetype-object-has-no-attribute-attribute-name", "date_posted": "Jul 9, 2009 at 3:48", "upvote": "7", "view": "1", "tags": ["python", "user-interface", "tkinter"], "answers_count": "4", "answers": [{"stack_answer_id": "1101765", "answer_content": "\r\n The  grid ,  pack  and  place  functions of the  Entry  object and of all other widgets returns  None . In python when you do  a().b() , the result of the expression is whatever  b()  returns, therefore  Entry(...).grid(...)  will return  None .  \n\n You should split that on to two lines like this: \n\n entryBox = Entry(root, width=60)\nentryBox.grid(row=2, column=1, sticky=W)\n \n\n That way you get your  Entry  reference stored in  entryBox  and it's laid out like you expect. This has a bonus side effect of making your layout easier to understand and maintain if you collect all of your  grid  and/or  pack  statements in blocks. \n    ", "date_posted": "2018-03-16 16:17:18Z", "upvote": "\r\n            135\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "7475225", "name": "Mike - SMT", "reputation_score": "15.7k"}, "answer_comments": [{"stack_answer_id": "1101765", "stack_answer_comment_id": "126379872", "comment_content": "So single line coding is not just syntactical, it also has semantic ramifications which is very unexpected.", "user_id": null}, {"stack_answer_id": "1101765", "stack_answer_comment_id": "129540652", "comment_content": "@user7420124, not really. The difference is what you assign to ", "user_id": null}]}, {"stack_answer_id": "1102053", "answer_content": "\r\n Change this line: \n\n entryBox=Entry(root,width=60).grid(row=2, column=1,sticky=W)\n \n\n into these two lines: \n\n entryBox=Entry(root,width=60)\nentryBox.grid(row=2, column=1,sticky=W)\n \n\n Just as you already correctly do for  grabBtn ! \n    ", "date_posted": "2019-03-25 17:26:36Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "1222951", "name": "Aran-Fey", "reputation_score": "36.4k"}, "answer_comments": []}, {"stack_answer_id": "68782288", "answer_content": "\r\n Alternative solution for  Python3.8+  versions that allows to put all of this in one line using the  walrus operator : \n (entryBox := Entry(root, width=60)).grid(row=2, column=1, sticky=W)\n \n Now  entryBox  will refer to the  Entry  widget and also get packed. \n For characters per line management I can suggest something like this: \n (var := Button(\n    text='fine', command=some_func, width=20, height=15, activebackground='grey'\n)).grid(row=0, column=0, columnspan=0, rowspan=0, sticky='news')\n \n But at that point might as well just do this \"normally\" (as suggested by other answers) \n Sources: \n \n PEP 572 -- Assignment Expressions \n IMO great video explanation about  walrus operator \n \n    ", "date_posted": "2022-05-26 07:54:17Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "14531062", "name": "Matiiss", "reputation_score": "5,516"}, "answer_comments": []}, {"stack_answer_id": "62545078", "answer_content": "\r\n For  entryBox.get()  to access  get()  method you need  Entry  object but  Entry(root, width=60).grid(row=2, column=1, sticky=W)  returns None. \n entryBox = Entry(root, width=60)  creates a new Entry Object. \n Moreover, you won't need\n entryBox = entryBox.grid(row=2, column=1, sticky=W)  as it will rewrite  entryBox  with None \n \n Just replace  entryBox = entryBox.grid(row=2, column=1, sticky=W) \nwith \n entryBox = Entry(root, width=60)\nentryBox.grid(row=2, column=1, sticky=W)\n \n    ", "date_posted": "2020-06-23 23:04:14Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "13751567", "name": "7u5h4r", "reputation_score": "439"}, "answer_comments": [{"stack_answer_id": "62545078", "stack_answer_comment_id": "119945662", "comment_content": "Isn't this just a duplicate of the accepted answer, but 11 years later?", "user_id": null}]}], "user": {"stack_user_id": "68920", "name": "Arnkrishn", "reputation_score": "29.1k"}, "question_comments": []},
{"stack_question_id": "89228", "question_title": "How do I execute a program or call a system command?", "question_content": "\r\n                How do I call an external command within Python as if I'd typed it in a shell or command prompt?\r\n", "question_url": "/questions/89228/how-do-i-execute-a-program-or-call-a-system-command", "date_posted": "Sep 18, 2008 at 1:35", "upvote": "5", "view": "4", "tags": ["python", "shell", "terminal", "subprocess", "command"], "answers_count": "6", "answers": [{"stack_answer_id": "89243", "answer_content": "\r\n Use the  subprocess  module in the standard library: \n import subprocess\nsubprocess.run([\"ls\", \"-l\"])\n \n The advantage of  subprocess.run  over  os.system  is that it is more flexible (you can get the  stdout ,  stderr , the  \"real\" status code , better  error handling , etc...). \n Even  the documentation for  os.system  recommends using  subprocess  instead: \n \n The  subprocess  module provides more powerful facilities for spawning new processes and retrieving their results; using that module is preferable to using this function. See the  Replacing Older Functions with the subprocess Module  section in the  subprocess  documentation for some helpful recipes. \n \n On Python 3.4 and earlier, use  subprocess.call  instead of  .run : \n subprocess.call([\"ls\", \"-l\"])\n \n    ", "date_posted": "2021-06-09 18:44:34Z", "upvote": "\r\n            5488\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "3064538", "name": "Boris Verkhovskiy", "reputation_score": "11.6k"}, "answer_comments": [{"stack_answer_id": "89243", "stack_answer_comment_id": "52559086", "comment_content": "Is there a way to use variable substitution? IE I tried to do ", "user_id": null}, {"stack_answer_id": "89243", "stack_answer_comment_id": "52598063", "comment_content": "@KevinWheeler You'll have to use ", "user_id": null}, {"stack_answer_id": "89243", "stack_answer_comment_id": "55091938", "comment_content": "@KevinWheeler You should NOT use ", "user_id": null}, {"stack_answer_id": "89243", "stack_answer_comment_id": "123644441", "comment_content": "what if I want to pipe things e.g. ", "user_id": null}, {"stack_answer_id": "89243", "stack_answer_comment_id": "127649670", "comment_content": "Many arguments version looks like that:  ", "user_id": null}]}, {"stack_answer_id": "92395", "answer_content": "\r\n Summary of ways to call external programs, including their advantages and disadvantages: \n \n os.system  passes the command and arguments to your system's shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example: \n os.system(\"some_command < input_file | another_command > output_file\")  \n \n However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, et cetera. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs. \n \n os.popen  will do the same thing as  os.system  except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don't need to worry about escaping anything. Example: \n print(os.popen(\"ls -l\").read())\n \n \n subprocess.Popen . This is intended as a replacement for  os.popen , but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you'd say: \n print subprocess.Popen(\"echo Hello World\", shell=True, stdout=subprocess.PIPE).stdout.read()\n \n instead of \n print os.popen(\"echo Hello World\").read()\n \n but it is nice to have all of the options there in one unified class instead of 4 different popen functions. See  the documentation . \n \n subprocess.call . This is basically just like the  Popen  class and takes all of the same arguments, but it simply waits until the command completes and gives you the return code. For example: \n return_code = subprocess.call(\"echo Hello World\", shell=True)\n \n \n subprocess.run . Python 3.5+ only. Similar to the above but even more flexible and returns a  CompletedProcess  object when the command finishes executing. \n \n os.fork ,  os.exec ,  os.spawn  are similar to their C language counterparts, but I don't recommend using them directly. \n \n \n The  subprocess  module should probably be what you use. \n Finally, please be aware that for all methods where you pass the final command to be executed by the shell as a string and you are responsible for escaping it.  There are serious security implications  if any part of the string that you pass can not be fully trusted. For example, if a user is entering some/any part of the string. If you are unsure, only use these methods with constants. To give you a hint of the implications consider this code: \n print subprocess.Popen(\"echo %s \" % user_input, stdout=PIPE).stdout.read()\n \n and imagine that the user enters something \" my mama didnt love me && rm -rf / \" which could erase the whole filesystem. \n    ", "date_posted": "2021-10-18 03:05:37Z", "upvote": "\r\n            3351\r\n        ", "accepted": "No", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": [{"stack_answer_id": "92395", "stack_answer_comment_id": "49018699", "comment_content": "Nice answer/explanation.  How is this answer justifying Python's motto as described in this article ?  ", "user_id": null}, {"stack_answer_id": "92395", "stack_answer_comment_id": "53820265", "comment_content": "If using Python 3.5+, use ", "user_id": null}, {"stack_answer_id": "92395", "stack_answer_comment_id": "62619897", "comment_content": "What one typically needs to know is what is done with the child process's STDOUT and STDERR, because if they are ignored, under some (quite common) conditions, eventually the child process will issue a system call to write to STDOUT (STDERR too?) that would exceed the output buffer provided for the process by the OS, and the OS will cause it to block until some process reads from that buffer. So, with the currently recommended ways, ", "user_id": null}, {"stack_answer_id": "92395", "stack_answer_comment_id": "80783837", "comment_content": "which of the commands you recommended block my script? i.e. if I want to run multiple commands in a ", "user_id": null}, {"stack_answer_id": "92395", "stack_answer_comment_id": "94039654", "comment_content": "This is arguably the wrong way around. Most people only need ", "user_id": null}]}, {"stack_answer_id": "95246", "answer_content": "\r\n Typical implementation: \n import subprocess\n\np = subprocess.Popen('ls', shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\nfor line in p.stdout.readlines():\n    print line,\nretval = p.wait()\n \n You are free to do what you want with the  stdout  data in the pipe.  In fact, you can simply omit those parameters ( stdout=  and  stderr= ) and it'll behave like  os.system() . \n    ", "date_posted": "2021-07-25 23:37:57Z", "upvote": "\r\n            420\r\n        ", "accepted": "No", "user": {"stack_user_id": "11082165", "name": "Brian", "reputation_score": "4,787"}, "answer_comments": [{"stack_answer_id": "95246", "stack_answer_comment_id": "18336103", "comment_content": " reads ", "user_id": null}, {"stack_answer_id": "95246", "stack_answer_comment_id": "18358478", "comment_content": "Could you elaborate on what you mean by \"if there is no buffering issues\"?  If the process blocks definitely, the subprocess call also blocks.  The same could happen with my original example as well. What else could happen with respect to buffering?", "user_id": null}, {"stack_answer_id": "95246", "stack_answer_comment_id": "18358805", "comment_content": "the child process may use block-buffering in non-interactive mode instead of line-buffering so ", "user_id": null}, {"stack_answer_id": "95246", "stack_answer_comment_id": "18358836", "comment_content": "the buffering issue only matters if you want output in real time and doesn't apply to your code that doesn't print anything until ", "user_id": null}, {"stack_answer_id": "95246", "stack_answer_comment_id": "94039263", "comment_content": "This answer was fine for its time, but we should no longer recommend ", "user_id": null}]}, {"stack_answer_id": "2251026", "answer_content": "\r\n Some hints on detaching the child process from the calling one (starting the child process in background). \n\n Suppose you want to start a long task from a CGI script. That is, the child process should live longer than the CGI script execution process. \n\n The classical example from the subprocess module documentation is: \n\n import subprocess\nimport sys\n\n# Some code here\n\npid = subprocess.Popen([sys.executable, \"longtask.py\"]) # Call subprocess\n\n# Some more code here\n \n\n The idea here is that you do not want to wait in the line 'call subprocess' until the longtask.py is finished. But it is not clear what happens after the line 'some more code here' from the example. \n\n My target platform was FreeBSD, but the development was on Windows, so I faced the problem on Windows first. \n\n On Windows (Windows\u00a0XP), the parent process will not finish until the longtask.py has finished its work. It is not what you want in a CGI script. The problem is not specific to Python; in the PHP community the problems are the same. \n\n The solution is to pass DETACHED_PROCESS  Process Creation Flag  to the underlying CreateProcess function in Windows API.\nIf you happen to have installed pywin32, you can import the flag from the win32process module, otherwise you should define it yourself: \n\n DETACHED_PROCESS = 0x00000008\n\npid = subprocess.Popen([sys.executable, \"longtask.py\"],\n                       creationflags=DETACHED_PROCESS).pid\n \n\n /*  UPD 2015.10.27  @eryksun in a comment below notes, that the semantically correct flag is CREATE_NEW_CONSOLE (0x00000010) */ \n\n On FreeBSD we have another problem: when the parent process is finished, it finishes the child processes as well. And that is not what you want in a CGI script either. Some experiments showed that the problem seemed to be in sharing sys.stdout. And the working solution was the following: \n\n pid = subprocess.Popen([sys.executable, \"longtask.py\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, stdin=subprocess.PIPE)\n \n\n I have not checked the code on other platforms and do not know the reasons of the behaviour on FreeBSD. If anyone knows, please share your ideas. Googling on starting background processes in Python does not shed any light yet. \n    ", "date_posted": "2019-11-29 21:46:11Z", "upvote": "\r\n            268\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "2251026", "stack_answer_comment_id": "18336228", "comment_content": "you might also need CREATE_NEW_PROCESS_GROUP flag. See ", "user_id": null}, {"stack_answer_id": "2251026", "stack_answer_comment_id": "41807947", "comment_content": "I'm seeing ", "user_id": null}, {"stack_answer_id": "2251026", "stack_answer_comment_id": "41828669", "comment_content": "@ubershmekel, I am not sure what you mean and don't have a windows installation. If I recall correctly, without the flags you can not close the ", "user_id": null}, {"stack_answer_id": "2251026", "stack_answer_comment_id": "54511646", "comment_content": "The following is incorrect: \"[o]n windows (win xp), the parent process will not finish until the longtask.py has finished its work\". The parent will exit normally, but the console window (conhost.exe instance) only closes when the last attached process exits, and the child may have inherited the parent's console. Setting ", "user_id": null}, {"stack_answer_id": "2251026", "stack_answer_comment_id": "54543759", "comment_content": "I didn't mean that executing as a detached process is incorrect. That said, you may need to set the standard handles to files, pipes, or ", "user_id": null}]}, {"stack_answer_id": "89237", "answer_content": "\r\n import os\nos.system(\"your command\")\n \n\n Note that this is dangerous, since the command isn't cleaned. I leave it up to you to google for the relevant documentation on the 'os' and 'sys' modules. There are a bunch of functions (exec* and spawn*) that will do similar things. \n    ", "date_posted": "2018-06-03 17:10:00Z", "upvote": "\r\n            202\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "89237", "stack_answer_comment_id": "88457934", "comment_content": "No idea what I meant nearly a decade ago (check the date!), but if I had to guess, it would be that there's no validation done.", "user_id": null}, {"stack_answer_id": "89237", "stack_answer_comment_id": "94038788", "comment_content": "This should now point to ", "user_id": null}]}, {"stack_answer_id": "89255", "answer_content": "\r\n I'd recommend using the  subprocess  module instead of os.system because it does shell escaping for you and is therefore much safer. \n\n subprocess.call(['ping', 'localhost'])\n \n    ", "date_posted": "2020-02-24 01:01:46Z", "upvote": "\r\n            170\r\n        ", "accepted": "No", "user": {"stack_user_id": "10908375", "name": "Nicolas Gervais", "reputation_score": "30k"}, "answer_comments": [{"stack_answer_id": "89255", "stack_answer_comment_id": "91805349", "comment_content": "If you want to ", "user_id": null}, {"stack_answer_id": "89255", "stack_answer_comment_id": "94078666", "comment_content": "This is incorrect: \"", "user_id": null}]}, {"stack_answer_id": "89238", "answer_content": "\r\n import os\ncmd = 'ls -al'\nos.system(cmd)\n \n\n If you want to return the results of the command, you can use  os.popen . However, this is deprecated since version 2.6 in favor of the  subprocess module , which other answers have covered well. \n    ", "date_posted": "2016-01-26 16:53:05Z", "upvote": "\r\n            165\r\n        ", "accepted": "No", "user": {"stack_user_id": "1146608", "name": "Patrick M", "reputation_score": "10.2k"}, "answer_comments": [{"stack_answer_id": "89238", "stack_answer_comment_id": "39233700", "comment_content": "popen ", "user_id": null}, {"stack_answer_id": "89238", "stack_answer_comment_id": "81287939", "comment_content": "You can also save your result with the os.system call, since it works like the UNIX shell itself, like for example os.system('ls -l > test2.txt')", "user_id": null}]}, {"stack_answer_id": "40319875", "answer_content": "\r\n There are lots of different libraries which allow you to call external commands with Python. For each library I've given a description and shown an example of calling an external command. The command I used as the example is  ls -l  (list all files). If you want to find out more about any of the libraries I've listed and linked the documentation for each of them. \n Sources \n \n subprocess:  https://docs.python.org/3.5/library/subprocess.html \n shlex:  https://docs.python.org/3/library/shlex.html \n os:  https://docs.python.org/3.5/library/os.html \n sh:  https://amoffat.github.io/sh/ \n plumbum:  https://plumbum.readthedocs.io/en/latest/ \n pexpect:  https://pexpect.readthedocs.io/en/stable/ \n fabric:  http://www.fabfile.org/ \n envoy:  https://github.com/kennethreitz/envoy \n commands:  https://docs.python.org/2/library/commands.html \n \n These are all the libraries \n Hopefully this will help you make a decision on which library to use :) \n subprocess \n Subprocess allows you to call external commands and connect them to their input/output/error pipes (stdin, stdout, and stderr). Subprocess is the default choice for running commands, but sometimes other modules are better. \n subprocess.run([\"ls\", \"-l\"]) # Run command\nsubprocess.run([\"ls\", \"-l\"], stdout=subprocess.PIPE) # This will run the command and return any output\nsubprocess.run(shlex.split(\"ls -l\")) # You can also use the shlex library to split the command\n \n os \n os is used for \"operating system dependent functionality\". It can also be used to call external commands with  os.system  and  os.popen  (Note: There is also a subprocess.popen). os will always run the shell and is a simple alternative for people who don't need to, or don't know how to use  subprocess.run . \n os.system(\"ls -l\") # Run command\nos.popen(\"ls -l\").read() # This will run the command and return any output\n \n sh \n sh is a subprocess interface which lets you call programs as if they were functions. This is useful if you want to run a command multiple times. \n sh.ls(\"-l\") # Run command normally\nls_cmd = sh.Command(\"ls\") # Save command as a variable\nls_cmd() # Run command as if it were a function\n \n plumbum \n plumbum is a library for \"script-like\" Python programs. You can call programs like functions as in  sh . Plumbum is useful if you want to run a pipeline without the shell. \n ls_cmd = plumbum.local(\"ls -l\") # Get command\nls_cmd() # Run command\n \n pexpect \n pexpect lets you spawn child applications, control them and find patterns in their output. This is a better alternative to subprocess for commands that expect a tty on Unix. \n pexpect.run(\"ls -l\") # Run command as normal\nchild = pexpect.spawn('scp foo user@example.com:.') # Spawns child application\nchild.expect('Password:') # When this is the output\nchild.sendline('mypassword')\n \n fabric \n fabric is a Python 2.5 and 2.7 library. It allows you to execute local and remote shell commands. Fabric is simple alternative for running commands in a secure shell (SSH) \n fabric.operations.local('ls -l') # Run command as normal\nfabric.operations.local('ls -l', capture = True) # Run command and receive output\n \n envoy \n envoy is known as \"subprocess for humans\". It is used as a convenience wrapper around the  subprocess  module. \n r = envoy.run(\"ls -l\") # Run command\nr.std_out # Get output\n \n commands \n commands  contains wrapper functions for  os.popen , but it has been removed from Python 3 since  subprocess  is a better alternative. \n    ", "date_posted": "2021-04-07 17:36:52Z", "upvote": "\r\n            127\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "15954964", "answer_content": "\r\n With the standard library \n\n Use the  subprocess module  (Python 3): \n\n import subprocess\nsubprocess.run(['ls', '-l'])\n \n\n It is the recommended standard way. However, more complicated tasks (pipes, output, input, etc.) can be tedious to construct and write. \n\n Note on Python version: If you are still using Python 2,  subprocess.call  works in a similar way. \n\n ProTip:  shlex.split  can help you to parse the command for  run ,  call , and other  subprocess  functions in case you don't want (or you can't!) provide them in form of lists: \n\n import shlex\nimport subprocess\nsubprocess.run(shlex.split('ls -l'))\n \n\n With external dependencies \n\n If you do not mind external dependencies, use  plumbum : \n\n from plumbum.cmd import ifconfig\nprint(ifconfig['wlan0']())\n \n\n It is the best  subprocess  wrapper. It's cross-platform, i.e. it works on both Windows and Unix-like systems. Install by  pip install plumbum . \n\n Another popular library is  sh : \n\n from sh import ifconfig\nprint(ifconfig('wlan0'))\n \n\n However,  sh  dropped Windows support, so it's not as awesome as it used to be. Install by  pip install sh . \n    ", "date_posted": "2019-11-29 21:54:25Z", "upvote": "\r\n            86\r\n        ", "accepted": "No", "user": {"stack_user_id": "15954964", "name": "\r\n        6 revs, 2 users 79%", "reputation_score": 0}, "answer_comments": []}, {"stack_answer_id": "9676642", "answer_content": "\r\n I always use  fabric  for this things like: \n\n from fabric.operations import local\nresult = local('ls', capture=True)\nprint \"Content:/n%s\" % (result, )\n \n\n But this seem to be a good tool:  sh  (Python subprocess interface) . \n\n Look at an example: \n\n from sh import vgdisplay\nprint vgdisplay()\nprint vgdisplay('-v')\nprint vgdisplay(v=True)\n \n    ", "date_posted": "2019-11-29 21:47:58Z", "upvote": "\r\n            83\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "3879406", "answer_content": "\r\n Check the \"pexpect\" Python library, too. \n\n It allows for interactive controlling of external programs/commands, even ssh, ftp, telnet, etc. You can just type something like: \n\n child = pexpect.spawn('ftp 192.168.0.24')\n\nchild.expect('(?i)name .*: ')\n\nchild.sendline('anonymous')\n\nchild.expect('(?i)password')\n \n    ", "date_posted": "2017-05-28 23:02:27Z", "upvote": "\r\n            81\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "5824565", "answer_content": "\r\n If you need the output from the command you are calling,\nthen you can use  subprocess.check_output  (Python 2.7+). \n\n >>> subprocess.check_output([\"ls\", \"-l\", \"/dev/null\"])\n'crw-rw-rw- 1 root root 1, 3 Oct 18  2007 /dev/null\\n'\n \n\n Also note the  shell  parameter. \n\n \n   If shell is  True , the specified command will be executed through the shell. This can be useful if you are using Python primarily for the enhanced control flow it offers over most system shells and still want convenient access to other shell features such as shell pipes, filename wildcards, environment variable expansion, and expansion of ~ to a user\u2019s home directory. However, note that Python itself offers implementations of many shell-like features (in particular,  glob ,  fnmatch ,  os.walk() ,  os.path.expandvars() ,  os.path.expanduser() , and  shutil ). \n \n    ", "date_posted": "2018-06-03 20:18:34Z", "upvote": "\r\n            79\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "5824565", "stack_answer_comment_id": "84050970", "comment_content": "Note that ", "user_id": null}, {"stack_answer_id": "5824565", "stack_answer_comment_id": "120034000", "comment_content": "Like the answer vaguely mentions, and many other answers on this page explain in more detail, you can pass a list, or with ", "user_id": null}]}, {"stack_answer_id": "13402722", "answer_content": "\r\n Update: \n\n subprocess.run  is the recommended approach  as of Python 3.5  if your code does not need to maintain compatibility with earlier Python versions. It's more consistent and offers similar ease-of-use as Envoy. (Piping isn't as straightforward though. See  this question for how .) \n\n Here's some examples from  the documentation . \n\n Run a process: \n\n >>> subprocess.run([\"ls\", \"-l\"])  # Doesn't capture output\nCompletedProcess(args=['ls', '-l'], returncode=0)\n \n\n Raise on failed run: \n\n >>> subprocess.run(\"exit 1\", shell=True, check=True)\nTraceback (most recent call last):\n  ...\nsubprocess.CalledProcessError: Command 'exit 1' returned non-zero exit status 1\n \n\n Capture output: \n\n >>> subprocess.run([\"ls\", \"-l\", \"/dev/null\"], stdout=subprocess.PIPE)\nCompletedProcess(args=['ls', '-l', '/dev/null'], returncode=0,\nstdout=b'crw-rw-rw- 1 root root 1, 3 Jan 23 16:23 /dev/null\\n')\n \n\n Original answer: \n\n I recommend trying  Envoy . It's a wrapper for subprocess, which in turn  aims to replace  the older modules and functions. Envoy is subprocess for humans. \n\n Example usage from  the README : \n\n >>> r = envoy.run('git config', data='data to pipe in', timeout=2)\n\n>>> r.status_code\n129\n>>> r.std_out\n'usage: git config [options]'\n>>> r.std_err\n''\n \n\n Pipe stuff around too: \n\n >>> r = envoy.run('uptime | pbcopy')\n\n>>> r.command\n'pbcopy'\n>>> r.status_code\n0\n\n>>> r.history\n[<Response 'uptime'>]\n \n    ", "date_posted": "2019-11-29 21:52:33Z", "upvote": "\r\n            66\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "13106558", "answer_content": "\r\n This is how I run my commands. This code has everything you need pretty much \n\n from subprocess import Popen, PIPE\ncmd = \"ls -l ~/\"\np = Popen(cmd , shell=True, stdout=PIPE, stderr=PIPE)\nout, err = p.communicate()\nprint \"Return code: \", p.returncode\nprint out.rstrip(), err.rstrip()\n \n    ", "date_posted": "2012-10-28 05:44:05Z", "upvote": "\r\n            64\r\n        ", "accepted": "No", "user": {"stack_user_id": "1755213", "name": "Usman Khan", "reputation_score": "681"}, "answer_comments": [{"stack_answer_id": "13106558", "stack_answer_comment_id": "34789609", "comment_content": "I think it's acceptable for hard-coded commands, if it increases readability.", "user_id": null}]}, {"stack_answer_id": "46815111", "answer_content": "\r\n \n How to execute a program or call a system command from Python \n \n Simple, use  subprocess.run , which returns a  CompletedProcess  object: \n >>> from subprocess import run\n>>> from shlex import split\n>>> completed_process = run(split('python --version'))\nPython 3.8.8\n>>> completed_process\nCompletedProcess(args=['python', '--version'], returncode=0)\n \n ( run  wants a list of lexically parsed shell arguments - this is what you'd type in a shell, separated by spaces, but not where the spaces are quoted, so use a specialized function,  split , to split up what you would literally type into your shell) \n Why? \n As of Python 3.5, the documentation recommends  subprocess.run : \n \n The recommended approach to invoking subprocesses is to use the run() function for all use cases it can handle. For more advanced use cases, the underlying Popen interface can be used directly. \n \n Here's an example of the simplest possible usage - and it does exactly as asked: \n >>> from subprocess import run\n>>> from shlex import split\n>>> completed_process = run(split('python --version'))\nPython 3.8.8\n>>> completed_process\nCompletedProcess(args=['python', '--version'], returncode=0)\n \n run  waits for the command to successfully finish, then returns a  CompletedProcess  object. It may instead raise  TimeoutExpired  (if you give it a  timeout=  argument) or  CalledProcessError  (if it fails and you pass  check=True ). \n As you might infer from the above example, stdout and stderr both get piped to your own stdout and stderr by default. \n We can inspect the returned object and see the command that was given and the returncode: \n >>> completed_process.args\n['python', '--version']\n>>> completed_process.returncode\n0\n \n Capturing output \n If you want to capture the output, you can pass  subprocess.PIPE  to the appropriate  stderr  or  stdout : \n >>> from subprocess import PIPE\n>>> completed_process = run(shlex.split('python --version'), stdout=PIPE, stderr=PIPE)\n>>> completed_process.stdout\nb'Python 3.8.8\\n'\n>>> completed_process.stderr\nb''\n \n And those respective attributes return bytes. \n Pass a command list \n One might easily move from manually providing a command string (like the question suggests) to providing a string built programmatically.  Don't build strings programmatically.  This is a potential security issue. It's better to assume you don't trust the input. \n >>> import textwrap\n>>> args = ['python', textwrap.__file__]\n>>> cp = run(args, stdout=subprocess.PIPE)\n>>> cp.stdout\nb'Hello there.\\n  This is indented.\\n'\n \n Note, only  args  should be passed positionally. \n Full Signature \n Here's the actual signature in the source and as shown by  help(run) : \n \n def run(*popenargs, input=None, timeout=None, check=False, **kwargs):\n \n \n The  popenargs  and  kwargs  are given to the  Popen  constructor.  input  can be a string of bytes (or unicode, if specify encoding or  universal_newlines=True ) that will be piped to the subprocess's stdin. \n The documentation describes  timeout=  and  check=True  better than I could: \n \n The timeout argument is passed to Popen.communicate(). If the timeout\nexpires, the child process will be killed and waited for. The\nTimeoutExpired exception will be re-raised after the child process has\nterminated. \n If check is true, and the process exits with a non-zero exit code, a\nCalledProcessError exception will be raised. Attributes of that\nexception hold the arguments, the exit code, and stdout and stderr if\nthey were captured. \n \n and this example for  check=True  is better than one I could come up with: \n \n >>> subprocess.run(\"exit 1\", shell=True, check=True)\nTraceback (most recent call last):\n  ...\nsubprocess.CalledProcessError: Command 'exit 1' returned non-zero exit status 1\n \n \n Expanded Signature \n Here's an expanded signature, as given in the documentation: \n \n subprocess.run(args, *, stdin=None, input=None, stdout=None, stderr=None, \nshell=False, cwd=None, timeout=None, check=False, encoding=None, \nerrors=None)\n \n \n Note that this indicates that only the args list should be passed positionally. So pass the remaining arguments as keyword arguments. \n Popen \n When use  Popen  instead? I would struggle to find use-case based on the arguments alone. Direct usage of  Popen  would, however, give you access to its methods, including  poll , 'send_signal', 'terminate', and 'wait'. \n Here's the  Popen  signature as given in  the source . I think this is the most precise encapsulation of the information (as opposed to  help(Popen) ): \n \ndef __init__(self, args, bufsize=-1, executable=None,\n             stdin=None, stdout=None, stderr=None,\n             preexec_fn=None, close_fds=True,\n             shell=False, cwd=None, env=None, universal_newlines=None,\n             startupinfo=None, creationflags=0,\n             restore_signals=True, start_new_session=False,\n             pass_fds=(), *, user=None, group=None, extra_groups=None,\n             encoding=None, errors=None, text=None, umask=-1, pipesize=-1):\n\n \n But more informative is  the  Popen  documentation : \n \n subprocess.Popen(args, bufsize=-1, executable=None, stdin=None, stdout=None, \nstderr=None, preexec_fn=None, close_fds=True, shell=False, cwd=None,\nenv=None, universal_newlines=None, startupinfo=None, creationflags=0, \nrestore_signals=True, start_new_session=False, pass_fds=(), *, group=None, \nextra_groups=None, user=None, umask=-1, encoding=None, errors=None, \ntext=None)\n \n Execute a child program in a new process. On POSIX, the class uses\nos.execvp()-like behavior to execute the child program. On Windows,\nthe class uses the Windows CreateProcess() function. The arguments to\nPopen are as follows. \n \n Understanding the remaining documentation on  Popen  will be left as an exercise for the reader. \n    ", "date_posted": "2021-06-10 13:30:04Z", "upvote": "\r\n            54\r\n        ", "accepted": "No", "user": {"stack_user_id": "541136", "name": "Russia Must Remove Putin", "reputation_score": "347k"}, "answer_comments": [{"stack_answer_id": "46815111", "stack_answer_comment_id": "92598860", "comment_content": "A simple example of two-way communication between a primary process and a subprocess can be found here: ", "user_id": null}]}, {"stack_answer_id": "89262", "answer_content": "\r\n Use  subprocess . \n\n ...or for a very simple command: \n\n import os\nos.system('cat testfile')\n \n    ", "date_posted": "2019-11-29 21:39:08Z", "upvote": "\r\n            53\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "89304", "answer_content": "\r\n os.system  is OK, but kind of dated.  It's also not very secure.  Instead, try  subprocess .   subprocess  does not call sh directly and is therefore more secure than  os.system . \n\n Get more information  here . \n    ", "date_posted": "2016-12-10 13:25:05Z", "upvote": "\r\n            42\r\n        ", "accepted": "No", "user": {"stack_user_id": "4952130", "name": "Dimitris Fasarakis Hilliard", "reputation_score": "139k"}, "answer_comments": [{"stack_answer_id": "89304", "stack_answer_comment_id": "94039191", "comment_content": "While I agree with the overall recommendation, ", "user_id": null}]}, {"stack_answer_id": "64341833", "answer_content": "\r\n As of  Python 3.7.0 released on June 27th 2018 ( https://docs.python.org/3/whatsnew/3.7.html ) , you can achieve your desired result in the most powerful while equally simple way. This answer intends to show you the essential summary of various options in a short manner. For in-depth answers, please see the other ones. \n \n TL;DR in 2021 \n The big advantage of  os.system(...)  was its simplicity.  subprocess  is better and still easy to use, especially as of  Python 3.5 . \n import subprocess\nsubprocess.run(\"ls -a\", shell=True)\n \n Note:  This is the exact answer to your question - running a command \n \n like in a shell \n \n \n Preferred Way \n If possible, remove the shell overhead and run the command directly (requires a list). \n import subprocess\nsubprocess.run([\"help\"])\nsubprocess.run([\"ls\", \"-a\"])\n \n Pass program arguments in a list.  Don't include  \\\" -escaping for arguments containing spaces. \n \n Advanced Use Cases \n Checking The Output \n The following code speaks for itself: \n import subprocess\nresult = subprocess.run([\"ls\", \"-a\"], capture_output=True, text=True)\nif \"stackoverflow-logo.png\" in result.stdout:\n    print(\"You're a fan!\")\nelse:\n    print(\"You're not a fan?\")\n \n result.stdout  is all normal program output  excluding errors . Read  result.stderr  to get them. \n capture_output=True  - turns capturing on. Otherwise  result.stderr  and  result.stdout  would be  None . Available from  Python 3.7 . \n text=True  - a convenience argument added in  Python 3.7  which converts the received binary data to Python strings you can easily work with. \n Checking the returncode \n Do \n if result.returncode == 127: print(\"The program failed for some weird reason\")\nelif result.returncode == 0: print(\"The program succeeded\")\nelse: print(\"The program failed unexpectedly\")\n \n If you just want to check if the program succeeded (returncode == 0) and otherwise throw an Exception, there is a more convenient function: \n result.check_returncode()\n \n But it's Python, so there's an even more convenient argument  check  which does the same thing automatically for you: \n result = subprocess.run(..., check=True)\n \n stderr should be inside stdout \n You might want to have all program output inside stdout, even errors. To accomplish this, run \n result = subprocess.run(..., stderr=subprocess.STDOUT)\n \n result.stderr  will then be  None  and  result.stdout  will contain everything. \n Using shell=False with an argument string \n shell=False  expects a  list  of arguments. You might however, split an argument string on your own using shlex. \n import subprocess\nimport shlex\nsubprocess.run(shlex.split(\"ls -a\"))\n \n That's it. \n Common Problems \n Chances are high you just started using Python when you come across this question. Let's look at some common problems. \n \n FileNotFoundError: [Errno 2] No such file or directory: 'ls -a': 'ls -a' \n \n You're running a subprocess without  shell=True  . Either use a list ( [\"ls\", \"-a\"] ) or set  shell=True . \n \n TypeError: [...] NoneType [...] \n \n Check that you've set  capture_output=True . \n \n TypeError: a bytes-like object is required, not [...] \n \n You always receive byte results from your program. If you want to work with it like a normal string, set  text=True . \n \n subprocess.CalledProcessError: Command '[...]' returned non-zero exit status 1. \n \n Your command didn't run successfully. You could disable returncode checking or check your actual program's validity. \n \n TypeError:  init () got an unexpected keyword argument [...] \n \n You're likely using a version of Python older than 3.7.0; update it to the most recent one available. Otherwise there are other answers in this Stack Overflow post showing you older alternative solutions. \n    ", "date_posted": "2021-04-07 17:55:45Z", "upvote": "\r\n            42\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "64341833", "stack_answer_comment_id": "118105684", "comment_content": "\"The big advantage of os.system(...) was its simplicity. subprocess is better\" - how subprocess is better? I am happily using os.system, not sure how switching to subprocess and remembering extra ", "user_id": null}, {"stack_answer_id": "64341833", "stack_answer_comment_id": "118133731", "comment_content": "You're right in that ", "user_id": null}, {"stack_answer_id": "64341833", "stack_answer_comment_id": "118133786", "comment_content": "The problem with ", "user_id": null}, {"stack_answer_id": "64341833", "stack_answer_comment_id": "118133803", "comment_content": "Summing up, ", "user_id": null}]}, {"stack_answer_id": "26305089", "answer_content": "\r\n There is also  Plumbum \n\n >>> from plumbum import local\n>>> ls = local[\"ls\"]\n>>> ls\nLocalCommand(<LocalPath /bin/ls>)\n>>> ls()\nu'build.py\\ndist\\ndocs\\nLICENSE\\nplumbum\\nREADME.rst\\nsetup.py\\ntests\\ntodo.txt\\n'\n>>> notepad = local[\"c:\\\\windows\\\\notepad.exe\"]\n>>> notepad()                                   # Notepad window pops up\nu''                                             # Notepad window is closed by user, command returns\n \n    ", "date_posted": "2014-10-10 17:41:13Z", "upvote": "\r\n            39\r\n        ", "accepted": "No", "user": {"stack_user_id": "394370", "name": "stuckintheshuck", "reputation_score": "2,401"}, "answer_comments": [{"stack_answer_id": "26305089", "stack_answer_comment_id": "118415297", "comment_content": "An explanation would be in order.", "user_id": null}]}, {"stack_answer_id": "31114625", "answer_content": "\r\n Use: \n\n import os\n\ncmd = 'ls -al'\n\nos.system(cmd)\n \n\n os - This module provides a portable way of using operating system-dependent functionality. \n\n For the more  os  functions,  here  is the documentation. \n    ", "date_posted": "2017-05-28 23:05:23Z", "upvote": "\r\n            32\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "31114625", "stack_answer_comment_id": "56118340", "comment_content": "it's also deprecated.  use subprocess", "user_id": null}]}, {"stack_answer_id": "50101887", "answer_content": "\r\n It can be this simple: \n\n import os\ncmd = \"your command\"\nos.system(cmd)\n \n    ", "date_posted": "2018-06-08 12:06:53Z", "upvote": "\r\n            32\r\n        ", "accepted": "No", "user": {"stack_user_id": "6634322", "name": "Samadi Salahedine", "reputation_score": "517"}, "answer_comments": [{"stack_answer_id": "50101887", "stack_answer_comment_id": "94038650", "comment_content": "This fails to point out the drawbacks, which are explained in much more detail in ", "user_id": null}]}, {"stack_answer_id": "2030768", "answer_content": "\r\n There is another difference here which is not mentioned previously. \n\n subprocess.Popen  executes the <command> as a subprocess. In my case, I need to execute file <a> which needs to communicate with another program, <b>.  \n\n I tried subprocess, and execution was successful. However <b> could not communicate with <a>.\nEverything is normal when I run both from the terminal. \n\n One more: \n(NOTE: kwrite behaves different from other applications. If you try the below with Firefox, the results will not be the same.) \n\n If you try  os.system(\"kwrite\") , program flow freezes until the user closes kwrite. To overcome that I tried instead  os.system(konsole -e kwrite) . This time program continued to flow, but kwrite became the subprocess of the console. \n\n Anyone runs the kwrite not being a subprocess (i.e. in the system monitor it must appear at the leftmost edge of the tree). \n    ", "date_posted": "2018-06-03 20:14:32Z", "upvote": "\r\n            26\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "2030768", "stack_answer_comment_id": "88350869", "comment_content": "What do you mean by ", "user_id": null}, {"stack_answer_id": "2030768", "stack_answer_comment_id": "120034031", "comment_content": "It is baffling indeed that ", "user_id": null}]}, {"stack_answer_id": "10988365", "answer_content": "\r\n os.system  does not allow you to store results, so if you want to store results in some list or something, a  subprocess.call  works. \n    ", "date_posted": "2019-11-29 21:48:26Z", "upvote": "\r\n            26\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "4728086", "answer_content": "\r\n subprocess.check_call  is convenient if you don't want to test return values. It throws an exception on any error. \n    ", "date_posted": "2011-01-18 19:21:44Z", "upvote": "\r\n            25\r\n        ", "accepted": "No", "user": {"stack_user_id": "263998", "name": "cdunn2001", "reputation_score": "16.9k"}, "answer_comments": []}, {"stack_answer_id": "23391049", "answer_content": "\r\n I tend to use  subprocess  together with  shlex  (to handle escaping of quoted strings): \n\n >>> import subprocess, shlex\n>>> command = 'ls -l \"/your/path/with spaces/\"'\n>>> call_params = shlex.split(command)\n>>> print call_params\n[\"ls\", \"-l\", \"/your/path/with spaces/\"]\n>>> subprocess.call(call_params)\n \n    ", "date_posted": "2014-04-30 14:37:04Z", "upvote": "\r\n            25\r\n        ", "accepted": "No", "user": {"stack_user_id": "117268", "name": "Emil Stenstr\u00f6m", "reputation_score": "12.3k"}, "answer_comments": []}, {"stack_answer_id": "23416345", "answer_content": "\r\n I wrote a library for this,  shell.py . \n It's basically a wrapper for popen and shlex for now. It also supports piping commands, so you can chain commands easier in Python. So you can do things like: \n ex('echo hello shell.py') | \"awk '{print $2}'\"\n \n    ", "date_posted": "2021-04-07 17:28:21Z", "upvote": "\r\n            21\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "37877635", "answer_content": "\r\n In Windows you can just import the  subprocess  module and run external commands by calling  subprocess.Popen() ,  subprocess.Popen().communicate()  and  subprocess.Popen().wait()  as below: \n\n # Python script to run a command line\nimport subprocess\n\ndef execute(cmd):\n    \"\"\"\n        Purpose  : To execute a command and return exit status\n        Argument : cmd - command to execute\n        Return   : exit_code\n    \"\"\"\n    process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    (result, error) = process.communicate()\n\n    rc = process.wait()\n\n    if rc != 0:\n        print \"Error: failed to execute command:\", cmd\n        print error\n    return result\n# def\n\ncommand = \"tasklist | grep python\"\nprint \"This process detail: \\n\", execute(command)\n \n\n Output: \n\n This process detail:\npython.exe                     604 RDP-Tcp#0                  4      5,660 K\n \n    ", "date_posted": "2017-05-28 23:08:28Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "40824514", "answer_content": "\r\n Under Linux, in case you would like to call an external command that will execute independently (will keep running after the Python script terminates), you can use a simple queue as  task spooler  or the  at  command. \n An example with task spooler: \n import os\nos.system('ts <your-command>')\n \n Notes about task spooler ( ts ): \n \n You could set the number of concurrent processes to be run (\"slots\") with: \n ts -S <number-of-slots> \n \n Installing  ts  doesn't requires admin privileges. You can download and compile it from source with a simple  make , add it to your path and you're done. \n \n \n    ", "date_posted": "2021-04-07 17:39:42Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "40824514", "stack_answer_comment_id": "94039329", "comment_content": " is not standard on any distro I know of, though the pointer to ", "user_id": null}]}, {"stack_answer_id": "52339862", "answer_content": "\r\n Invoke  is a Python (2.7 and 3.4+) task execution tool and library. It provides a clean, high-level API for running shell commands: \n >>> from invoke import run\n>>> cmd = \"pip install -r requirements.txt\"\n>>> result = run(cmd, hide=True, warn=True)\n>>> print(result.ok)\nTrue\n>>> print(result.stdout.splitlines()[-1])\nSuccessfully installed invocations-0.13.0 pep8-1.5.7 spec-1.3.1\n \n    ", "date_posted": "2021-04-07 17:43:26Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "52339862", "stack_answer_comment_id": "96968474", "comment_content": "This is a great library.  I was trying to explain it to a coworker the other day adn described it like this: ", "user_id": null}]}, {"stack_answer_id": "11507283", "answer_content": "\r\n You can use Popen, and then you can check the procedure's status: \n\n from subprocess import Popen\n\nproc = Popen(['ls', '-l'])\nif proc.poll() is None:\n    proc.kill()\n \n\n Check out  subprocess.Popen . \n    ", "date_posted": "2017-05-28 23:01:49Z", "upvote": "\r\n            18\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}], "user": {"stack_user_id": "17085", "name": "freshWoWer", "reputation_score": "59.4k"}, "question_comments": []},
{"stack_question_id": "17071871", "question_title": "How do I select rows from a DataFrame based on column values?", "question_content": "\r\n                How can I select rows from a DataFrame based on values in some column in Pandas?\nIn SQL, I would use:\nSELECT *\nFROM table\nWHERE column_name = some_value\r\n", "question_url": "/questions/17071871/how-do-i-select-rows-from-a-dataframe-based-on-column-values", "date_posted": "Jun 12, 2013 at 17:42", "upvote": "3", "view": "5", "tags": ["python", "pandas", "dataframe"], "answers_count": "1", "answers": [{"stack_answer_id": "17071908", "answer_content": "\r\n To select rows whose column value equals a scalar,  some_value , use  == : \n\n df.loc[df['column_name'] == some_value]\n \n\n To select rows whose column value is in an iterable,  some_values , use  isin : \n\n df.loc[df['column_name'].isin(some_values)]\n \n\n Combine multiple conditions with  & :  \n\n df.loc[(df['column_name'] >= A) & (df['column_name'] <= B)]\n \n\n Note the parentheses. Due to Python's  operator precedence rules ,  &  binds more tightly than  <=  and  >= . Thus, the parentheses in the last example are necessary. Without the parentheses  \n\n df['column_name'] >= A & df['column_name'] <= B\n \n\n is parsed as  \n\n df['column_name'] >= (A & df['column_name']) <= B\n \n\n which results in a  Truth value of a Series is ambiguous error . \n\n \n\n To select rows whose column value  does not equal   some_value , use  != : \n\n df.loc[df['column_name'] != some_value]\n \n\n isin  returns a boolean Series, so to select rows whose value is  not  in  some_values , negate the boolean Series using  ~ : \n\n df.loc[~df['column_name'].isin(some_values)]\n \n\n \n\n For example, \n\n import pandas as pd\nimport numpy as np\ndf = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),\n                   'B': 'one one two three two two one three'.split(),\n                   'C': np.arange(8), 'D': np.arange(8) * 2})\nprint(df)\n#      A      B  C   D\n# 0  foo    one  0   0\n# 1  bar    one  1   2\n# 2  foo    two  2   4\n# 3  bar  three  3   6\n# 4  foo    two  4   8\n# 5  bar    two  5  10\n# 6  foo    one  6  12\n# 7  foo  three  7  14\n\nprint(df.loc[df['A'] == 'foo'])\n \n\n yields \n\n      A      B  C   D\n0  foo    one  0   0\n2  foo    two  2   4\n4  foo    two  4   8\n6  foo    one  6  12\n7  foo  three  7  14\n \n\n \n\n If you have multiple values you want to include, put them in a\nlist (or more generally, any iterable) and use  isin : \n\n print(df.loc[df['B'].isin(['one','three'])])\n \n\n yields \n\n      A      B  C   D\n0  foo    one  0   0\n1  bar    one  1   2\n3  bar  three  3   6\n6  foo    one  6  12\n7  foo  three  7  14\n \n\n \n\n Note, however, that if you wish to do this many times, it is more efficient to\nmake an index first, and then use  df.loc : \n\n df = df.set_index(['B'])\nprint(df.loc['one'])\n \n\n yields \n\n        A  C   D\nB              \none  foo  0   0\none  bar  1   2\none  foo  6  12\n \n\n or, to include multiple values from the index use  df.index.isin : \n\n df.loc[df.index.isin(['one','two'])]\n \n\n yields \n\n        A  C   D\nB              \none  foo  0   0\none  bar  1   2\ntwo  foo  2   4\ntwo  foo  4   8\ntwo  bar  5  10\none  foo  6  12\n \n    ", "date_posted": "2019-01-18 02:47:47Z", "upvote": "\r\n            5828\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "190597", "name": "unutbu", "reputation_score": "791k"}, "answer_comments": [{"stack_answer_id": "17071908", "stack_answer_comment_id": "24690158", "comment_content": "In fact, df[df['colume_name']==some_value] also works. But my first attempt, df.where(df['colume_name']==some_value) does not work... not sure why...", "user_id": "/users/458429/szli"}, {"stack_answer_id": "17071908", "stack_answer_comment_id": "24690368", "comment_content": "When you use ", "user_id": null}, {"stack_answer_id": "17071908", "stack_answer_comment_id": "36767217", "comment_content": "Those links could be very useful to many of you: ", "user_id": null}, {"stack_answer_id": "17071908", "stack_answer_comment_id": "51447442", "comment_content": "FYI: If you want to select a row based upon two (or more) labels (either requiring both or either), see ", "user_id": null}, {"stack_answer_id": "17071908", "stack_answer_comment_id": "88911433", "comment_content": "Since ", "user_id": null}]}, {"stack_answer_id": "46165056", "answer_content": "\r\n There are several ways to select rows from a Pandas dataframe: \n \n Boolean indexing ( df[df['col'] == value ] ) \n Positional indexing ( df.iloc[...] ) \n Label indexing ( df.xs(...) ) \n df.query(...)  API \n \n Below I show you examples of each, with advice when to use certain techniques. Assume our criterion is column  'A'  ==  'foo' \n (Note on performance: For each base type, we can keep things simple by using the Pandas API or we can venture outside the API, usually into NumPy, and speed things up.) \n \n Setup \n The first thing we'll need is to identify a condition that will act as our criterion for selecting rows. We'll start with the OP's case  column_name == some_value , and include some other common use cases. \n Borrowing from @unutbu: \n import pandas as pd, numpy as np\n\ndf = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),\n                   'B': 'one one two three two two one three'.split(),\n                   'C': np.arange(8), 'D': np.arange(8) * 2})\n \n \n 1. Boolean indexing \n ... Boolean indexing requires finding the true value of each row's  'A'  column being equal to  'foo' , then using those truth values to identify which rows to keep.  Typically, we'd name this series, an array of truth values,  mask .  We'll do so here as well. \n mask = df['A'] == 'foo'\n \n We can then use this mask to slice or index the data frame \n df[mask]\n\n     A      B  C   D\n0  foo    one  0   0\n2  foo    two  2   4\n4  foo    two  4   8\n6  foo    one  6  12\n7  foo  three  7  14\n \n This is one of the simplest ways to accomplish this task and if performance or intuitiveness isn't an issue, this should be your chosen method.  However, if performance is a concern, then you might want to consider an alternative way of creating the  mask . \n \n 2. Positional indexing \n Positional indexing ( df.iloc[...] ) has its use cases, but this isn't one of them.  In order to identify where to slice, we first need to perform the same boolean analysis we did above.  This leaves us performing one extra step to accomplish the same task. \n mask = df['A'] == 'foo'\npos = np.flatnonzero(mask)\ndf.iloc[pos]\n\n     A      B  C   D\n0  foo    one  0   0\n2  foo    two  2   4\n4  foo    two  4   8\n6  foo    one  6  12\n7  foo  three  7  14\n \n 3. Label indexing \n Label  indexing can be very handy, but in this case, we are again doing more work for no benefit \n df.set_index('A', append=True, drop=False).xs('foo', level=1)\n\n     A      B  C   D\n0  foo    one  0   0\n2  foo    two  2   4\n4  foo    two  4   8\n6  foo    one  6  12\n7  foo  three  7  14\n \n 4.  df.query()  API \n pd.DataFrame.query  is a very elegant/intuitive way to perform this task, but is often slower.  However , if you pay attention to the timings below, for large data, the query is very efficient. More so than the standard approach and of similar magnitude as my best suggestion. \n df.query('A == \"foo\"')\n\n     A      B  C   D\n0  foo    one  0   0\n2  foo    two  2   4\n4  foo    two  4   8\n6  foo    one  6  12\n7  foo  three  7  14\n \n \n My preference is to use the  Boolean   mask \n Actual improvements can be made by modifying how we create our  Boolean   mask . \n mask  alternative 1 \n Use the underlying NumPy array and forgo the overhead of creating another  pd.Series \n mask = df['A'].values == 'foo'\n \n I'll show more complete time tests at the end, but just take a look at the performance gains we get using the sample data frame.  First, we look at the difference in creating the  mask \n %timeit mask = df['A'].values == 'foo'\n%timeit mask = df['A'] == 'foo'\n\n5.84 \u00b5s \u00b1 195 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n166 \u00b5s \u00b1 4.45 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\n \n Evaluating the  mask  with the NumPy array is ~ 30 times faster.  This is partly due to NumPy evaluation often being faster. It is also partly due to the lack of overhead necessary to build an index and a corresponding  pd.Series  object. \n Next, we'll look at the timing for slicing with one  mask  versus the other. \n mask = df['A'].values == 'foo'\n%timeit df[mask]\nmask = df['A'] == 'foo'\n%timeit df[mask]\n\n219 \u00b5s \u00b1 12.3 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each)\n239 \u00b5s \u00b1 7.03 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each)\n \n The performance gains aren't as pronounced.  We'll see if this holds up over more robust testing. \n \n mask  alternative 2 \nWe could have reconstructed the data frame as well.  There is a big caveat when reconstructing a dataframe\u2014you must take care of the  dtypes  when doing so! \n Instead of  df[mask]  we will do this \n pd.DataFrame(df.values[mask], df.index[mask], df.columns).astype(df.dtypes)\n \n If the data frame is of mixed type, which our example is, then when we get  df.values  the resulting array is of  dtype   object  and consequently, all columns of the new data frame will be of  dtype   object .  Thus requiring the  astype(df.dtypes)  and killing any potential performance gains. \n %timeit df[m]\n%timeit pd.DataFrame(df.values[mask], df.index[mask], df.columns).astype(df.dtypes)\n\n216 \u00b5s \u00b1 10.4 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each)\n1.43 ms \u00b1 39.6 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each)\n \n However, if the data frame is not of mixed type, this is a very useful way to do it. \n Given \n np.random.seed([3,1415])\nd1 = pd.DataFrame(np.random.randint(10, size=(10, 5)), columns=list('ABCDE'))\n\nd1\n\n   A  B  C  D  E\n0  0  2  7  3  8\n1  7  0  6  8  6\n2  0  2  0  4  9\n3  7  3  2  4  3\n4  3  6  7  7  4\n5  5  3  7  5  9\n6  8  7  6  4  7\n7  6  2  6  6  5\n8  2  8  7  5  8\n9  4  7  6  1  5\n \n \n %%timeit\nmask = d1['A'].values == 7\nd1[mask]\n\n179 \u00b5s \u00b1 8.73 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\n \n Versus \n %%timeit\nmask = d1['A'].values == 7\npd.DataFrame(d1.values[mask], d1.index[mask], d1.columns)\n\n87 \u00b5s \u00b1 5.12 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\n \n We cut the time in half. \n \n mask  alternative 3 \n @unutbu also shows us how to use  pd.Series.isin  to account for each element of  df['A']  being in a set of values.  This evaluates to the same thing if our set of values is a set of one value, namely  'foo' .  But it also generalizes to include larger sets of values if needed.  Turns out, this is still pretty fast even though it is a more general solution.  The only real loss is in intuitiveness for those not familiar with the concept. \n mask = df['A'].isin(['foo'])\ndf[mask]\n\n     A      B  C   D\n0  foo    one  0   0\n2  foo    two  2   4\n4  foo    two  4   8\n6  foo    one  6  12\n7  foo  three  7  14\n \n However, as before, we can utilize NumPy to improve performance while sacrificing virtually nothing. We'll use  np.in1d \n mask = np.in1d(df['A'].values, ['foo'])\ndf[mask]\n\n     A      B  C   D\n0  foo    one  0   0\n2  foo    two  2   4\n4  foo    two  4   8\n6  foo    one  6  12\n7  foo  three  7  14\n \n \n Timing \n I'll include other concepts mentioned in other posts as well for reference. \n Code Below \n Each  column  in this table represents a different length data frame over which we test each function. Each column shows relative time taken, with the fastest function given a base index of  1.0 . \n res.div(res.min())\n\n                         10        30        100       300       1000      3000      10000     30000\nmask_standard         2.156872  1.850663  2.034149  2.166312  2.164541  3.090372  2.981326  3.131151\nmask_standard_loc     1.879035  1.782366  1.988823  2.338112  2.361391  3.036131  2.998112  2.990103\nmask_with_values      1.010166  1.000000  1.005113  1.026363  1.028698  1.293741  1.007824  1.016919\nmask_with_values_loc  1.196843  1.300228  1.000000  1.000000  1.038989  1.219233  1.037020  1.000000\nquery                 4.997304  4.765554  5.934096  4.500559  2.997924  2.397013  1.680447  1.398190\nxs_label              4.124597  4.272363  5.596152  4.295331  4.676591  5.710680  6.032809  8.950255\nmask_with_isin        1.674055  1.679935  1.847972  1.724183  1.345111  1.405231  1.253554  1.264760\nmask_with_in1d        1.000000  1.083807  1.220493  1.101929  1.000000  1.000000  1.000000  1.144175\n \n You'll notice that the fastest times seem to be shared between  mask_with_values  and  mask_with_in1d . \n res.T.plot(loglog=True)\n \n \n Functions \n def mask_standard(df):\n    mask = df['A'] == 'foo'\n    return df[mask]\n\ndef mask_standard_loc(df):\n    mask = df['A'] == 'foo'\n    return df.loc[mask]\n\ndef mask_with_values(df):\n    mask = df['A'].values == 'foo'\n    return df[mask]\n\ndef mask_with_values_loc(df):\n    mask = df['A'].values == 'foo'\n    return df.loc[mask]\n\ndef query(df):\n    return df.query('A == \"foo\"')\n\ndef xs_label(df):\n    return df.set_index('A', append=True, drop=False).xs('foo', level=-1)\n\ndef mask_with_isin(df):\n    mask = df['A'].isin(['foo'])\n    return df[mask]\n\ndef mask_with_in1d(df):\n    mask = np.in1d(df['A'].values, ['foo'])\n    return df[mask]\n \n \n Testing \n res = pd.DataFrame(\n    index=[\n        'mask_standard', 'mask_standard_loc', 'mask_with_values', 'mask_with_values_loc',\n        'query', 'xs_label', 'mask_with_isin', 'mask_with_in1d'\n    ],\n    columns=[10, 30, 100, 300, 1000, 3000, 10000, 30000],\n    dtype=float\n)\n\nfor j in res.columns:\n    d = pd.concat([df] * j, ignore_index=True)\n    for i in res.index:a\n        stmt = '{}(d)'.format(i)\n        setp = 'from __main__ import d, {}'.format(i)\n        res.at[i, j] = timeit(stmt, setp, number=50)\n \n \n Special Timing \n Looking at the special case when we have a single non-object  dtype  for the entire data frame. \n Code Below \n spec.div(spec.min())\n\n                     10        30        100       300       1000      3000      10000     30000\nmask_with_values  1.009030  1.000000  1.194276  1.000000  1.236892  1.095343  1.000000  1.000000\nmask_with_in1d    1.104638  1.094524  1.156930  1.072094  1.000000  1.000000  1.040043  1.027100\nreconstruct       1.000000  1.142838  1.000000  1.355440  1.650270  2.222181  2.294913  3.406735\n \n Turns out, reconstruction isn't worth it past a few hundred rows. \n spec.T.plot(loglog=True)\n \n \n Functions \n np.random.seed([3,1415])\nd1 = pd.DataFrame(np.random.randint(10, size=(10, 5)), columns=list('ABCDE'))\n\ndef mask_with_values(df):\n    mask = df['A'].values == 'foo'\n    return df[mask]\n\ndef mask_with_in1d(df):\n    mask = np.in1d(df['A'].values, ['foo'])\n    return df[mask]\n\ndef reconstruct(df):\n    v = df.values\n    mask = np.in1d(df['A'].values, ['foo'])\n    return pd.DataFrame(v[mask], df.index[mask], df.columns)\n\nspec = pd.DataFrame(\n    index=['mask_with_values', 'mask_with_in1d', 'reconstruct'],\n    columns=[10, 30, 100, 300, 1000, 3000, 10000, 30000],\n    dtype=float\n)\n \n Testing \n for j in spec.columns:\n    d = pd.concat([df] * j, ignore_index=True)\n    for i in spec.index:\n        stmt = '{}(d)'.format(i)\n        setp = 'from __main__ import d, {}'.format(i)\n        spec.at[i, j] = timeit(stmt, setp, number=50)\n \n    ", "date_posted": "2021-02-04 16:52:19Z", "upvote": "\r\n            695\r\n        ", "accepted": "No", "user": {"stack_user_id": "7758804", "name": "Trenton McKinney", "reputation_score": "46.5k"}, "answer_comments": [{"stack_answer_id": "46165056", "stack_answer_comment_id": "128817483", "comment_content": "use ", "user_id": null}]}, {"stack_answer_id": "31296878", "answer_content": "\r\n tl;dr \n The Pandas equivalent to \n select * from table where column_name = some_value\n \n is \n table[table.column_name == some_value]\n \n Multiple conditions: \n table[(table.column_name == some_value) | (table.column_name2 == some_value2)]\n \n or \n table.query('column_name == some_value | column_name2 == some_value2')\n \n Code example \n import pandas as pd\n\n# Create data set\nd = {'foo':[100, 111, 222],\n     'bar':[333, 444, 555]}\ndf = pd.DataFrame(d)\n\n# Full dataframe:\ndf\n\n# Shows:\n#    bar   foo\n# 0  333   100\n# 1  444   111\n# 2  555   222\n\n# Output only the row(s) in df where foo is 222:\ndf[df.foo == 222]\n\n# Shows:\n#    bar  foo\n# 2  555  222\n \n In the above code it is the line  df[df.foo == 222]  that gives the rows based on the column value,  222  in this case. \n Multiple conditions are also possible: \n df[(df.foo == 222) | (df.bar == 444)]\n#    bar  foo\n# 1  444  111\n# 2  555  222\n \n But at that point I would recommend using the  query  function, since it's less verbose and yields the same result: \n df.query('foo == 222 | bar == 444')\n \n    ", "date_posted": "2020-10-05 18:26:21Z", "upvote": "\r\n            333\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "31296878", "stack_answer_comment_id": "86989737", "comment_content": " is the only answer here that is compatible with method chaining.  It seems like it's the pandas analog to ", "user_id": null}, {"stack_answer_id": "31296878", "stack_answer_comment_id": "121454506", "comment_content": "Thank you. I tried multiple ways to get a record. The only way worked was using query function.", "user_id": null}]}, {"stack_answer_id": "35282530", "answer_content": "\r\n I find the syntax of the previous answers to be redundant and difficult to remember. Pandas introduced the  query()  method in v0.13 and I much prefer it. For your question, you could do  df.query('col == val') \n\n Reproduced from  http://pandas.pydata.org/pandas-docs/version/0.17.0/indexing.html#indexing-query \n\n In [167]: n = 10\n\nIn [168]: df = pd.DataFrame(np.random.rand(n, 3), columns=list('abc'))\n\nIn [169]: df\nOut[169]: \n          a         b         c\n0  0.687704  0.582314  0.281645\n1  0.250846  0.610021  0.420121\n2  0.624328  0.401816  0.932146\n3  0.011763  0.022921  0.244186\n4  0.590198  0.325680  0.890392\n5  0.598892  0.296424  0.007312\n6  0.634625  0.803069  0.123872\n7  0.924168  0.325076  0.303746\n8  0.116822  0.364564  0.454607\n9  0.986142  0.751953  0.561512\n\n# pure python\nIn [170]: df[(df.a < df.b) & (df.b < df.c)]\nOut[170]: \n          a         b         c\n3  0.011763  0.022921  0.244186\n8  0.116822  0.364564  0.454607\n\n# query\nIn [171]: df.query('(a < b) & (b < c)')\nOut[171]: \n          a         b         c\n3  0.011763  0.022921  0.244186\n8  0.116822  0.364564  0.454607\n \n\n You can also access variables in the environment by prepending an  @ . \n\n exclude = ('red', 'orange')\ndf.query('color not in @exclude')\n \n    ", "date_posted": "2016-02-09 01:36:49Z", "upvote": "\r\n            83\r\n        ", "accepted": "No", "user": {"stack_user_id": "3533440", "name": "fredcallaway", "reputation_score": "1,302"}, "answer_comments": []}, {"stack_answer_id": "57338153", "answer_content": "\r\n More flexibility using  .query  with pandas >= 0.25.0: \n Since pandas >= 0.25.0 we can use the  query  method to filter dataframes with pandas methods and even column names which have spaces. Normally the spaces in column names would give an error, but now we can solve that using a backtick (`) - see  GitHub : \n # Example dataframe\ndf = pd.DataFrame({'Sender email':['ex@example.com', \"reply@shop.com\", \"buy@shop.com\"]})\n\n     Sender email\n0  ex@example.com\n1  reply@shop.com\n2    buy@shop.com\n \n Using  .query  with method  str.endswith : \n df.query('`Sender email`.str.endswith(\"@shop.com\")')\n \n Output \n      Sender email\n1  reply@shop.com\n2    buy@shop.com\n \n \n Also we can use local variables by prefixing it with an  @  in our query: \n domain = 'shop.com'\ndf.query('`Sender email`.str.endswith(@domain)')\n \n Output \n      Sender email\n1  reply@shop.com\n2    buy@shop.com\n \n    ", "date_posted": "2022-03-28 11:50:03Z", "upvote": "\r\n            63\r\n        ", "accepted": "No", "user": {"stack_user_id": "9081267", "name": "Erfan", "reputation_score": "37.8k"}, "answer_comments": [{"stack_answer_id": "57338153", "stack_answer_comment_id": "121549942", "comment_content": "Upvoted because the .str cast isn't obvious.", "user_id": null}, {"stack_answer_id": "57338153", "stack_answer_comment_id": "126621522", "comment_content": "would be great to know how this performs in terms of efficiency... I can think some reasons it might be more efficient, also some it shouldn't be... I guess it may also have to do with the internal implementation and the number of elements being selected?", "user_id": null}]}, {"stack_answer_id": "47693145", "answer_content": "\r\n For selecting only specific columns out of multiple columns for a given value in Pandas: \n select col_name1, col_name2 from table where column_name = some_value.\n \n Options  loc : \n df.loc[df['column_name'] == some_value, [col_name1, col_name2]]\n \n or  query : \n df.query('column_name == some_value')[[col_name1, col_name2]]\n \n    ", "date_posted": "2021-09-05 08:26:39Z", "upvote": "\r\n            36\r\n        ", "accepted": "No", "user": {"stack_user_id": "15497888", "name": "Henry Ecker", "reputation_score": "32.4k"}, "answer_comments": []}, {"stack_answer_id": "65578196", "answer_content": "\r\n In newer versions of Pandas, inspired by the documentation ( Viewing data ): \n df[df[\"colume_name\"] == some_value] #Scalar, True/False..\n\ndf[df[\"colume_name\"] == \"some_value\"] #String\n \n Combine multiple conditions by putting the clause in parentheses,  () , and combining them with  &  and  |  (and/or). Like this: \n df[(df[\"colume_name\"] == \"some_value1\") & (pd[pd[\"colume_name\"] == \"some_value2\"])]\n \n Other filters \n pandas.notna(df[\"colume_name\"]) == True # Not NaN\ndf['colume_name'].str.contains(\"text\") # Search for \"text\"\ndf['colume_name'].str.lower().str.contains(\"text\") # Search for \"text\", after converting  to lowercase\n \n    ", "date_posted": "2021-02-08 15:58:43Z", "upvote": "\r\n            31\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "65578196", "stack_answer_comment_id": "122147955", "comment_content": "Thanks. What if I want to select rows where the length of content of a certain column is >10 ? For example, I want: len(df[\"column_name\"] > 10, is there a straight way of doing this or I must loop over to create a new DataFrame?", "user_id": null}]}, {"stack_answer_id": "44931669", "answer_content": "\r\n Faster results can be achieved using  numpy.where .  \n\n For example, with  unubtu's setup  - \n\n In [76]: df.iloc[np.where(df.A.values=='foo')]\nOut[76]: \n     A      B  C   D\n0  foo    one  0   0\n2  foo    two  2   4\n4  foo    two  4   8\n6  foo    one  6  12\n7  foo  three  7  14\n \n\n Timing comparisons: \n\n In [68]: %timeit df.iloc[np.where(df.A.values=='foo')]  # fastest\n1000 loops, best of 3: 380 \u00b5s per loop\n\nIn [69]: %timeit df.loc[df['A'] == 'foo']\n1000 loops, best of 3: 745 \u00b5s per loop\n\nIn [71]: %timeit df.loc[df['A'].isin(['foo'])]\n1000 loops, best of 3: 562 \u00b5s per loop\n\nIn [72]: %timeit df[df.A=='foo']\n1000 loops, best of 3: 796 \u00b5s per loop\n\nIn [74]: %timeit df.query('(A==\"foo\")')  # slowest\n1000 loops, best of 3: 1.71 ms per loop\n \n    ", "date_posted": "2017-10-03 16:17:21Z", "upvote": "\r\n            30\r\n        ", "accepted": "No", "user": {"stack_user_id": "243392", "name": "Brian Burns", "reputation_score": "18.5k"}, "answer_comments": []}, {"stack_answer_id": "17086321", "answer_content": "\r\n Here is a simple example   \n\n from pandas import DataFrame\n\n# Create data set\nd = {'Revenue':[100,111,222], \n     'Cost':[333,444,555]}\ndf = DataFrame(d)\n\n\n# mask = Return True when the value in column \"Revenue\" is equal to 111\nmask = df['Revenue'] == 111\n\nprint mask\n\n# Result:\n# 0    False\n# 1     True\n# 2    False\n# Name: Revenue, dtype: bool\n\n\n# Select * FROM df WHERE Revenue = 111\ndf[mask]\n\n# Result:\n#    Cost    Revenue\n# 1  444     111\n \n    ", "date_posted": "2013-06-13 11:49:00Z", "upvote": "\r\n            28\r\n        ", "accepted": "No", "user": {"stack_user_id": "1821873", "name": "DataByDavid", "reputation_score": "1,009"}, "answer_comments": []}, {"stack_answer_id": "40676816", "answer_content": "\r\n To append to this famous question (though a bit too late): You can also do  df.groupby('column_name').get_group('column_desired_value').reset_index()  to make a new data frame with specified column having a particular value. E.g. \n\n import pandas as pd\ndf = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),\n                   'B': 'one one two three two two one three'.split()})\nprint(\"Original dataframe:\")\nprint(df)\n\nb_is_two_dataframe = pd.DataFrame(df.groupby('B').get_group('two').reset_index()).drop('index', axis = 1) \n#NOTE: the final drop is to remove the extra index column returned by groupby object\nprint('Sub dataframe where B is two:')\nprint(b_is_two_dataframe)\n \n\n Run this gives: \n\n Original dataframe:\n     A      B\n0  foo    one\n1  bar    one\n2  foo    two\n3  bar  three\n4  foo    two\n5  bar    two\n6  foo    one\n7  foo  three\nSub dataframe where B is two:\n     A    B\n0  foo  two\n1  foo  two\n2  bar  two\n \n    ", "date_posted": "2016-11-18 12:10:42Z", "upvote": "\r\n            18\r\n        ", "accepted": "No", "user": {"stack_user_id": "3713927", "name": "TuanDT", "reputation_score": "1,625"}, "answer_comments": []}, {"stack_answer_id": "53674430", "answer_content": "\r\n You can also use .apply: \n\n df.apply(lambda row: row[df['B'].isin(['one','three'])])\n \n\n It actually works row-wise (i.e., applies the function to each row). \n\n The output is  \n\n    A      B  C   D\n0  foo    one  0   0\n1  bar    one  1   2\n3  bar  three  3   6\n6  foo    one  6  12\n7  foo  three  7  14\n \n\n The results is the same as using as mentioned by @unutbu \n\n df[[df['B'].isin(['one','three'])]]\n \n    ", "date_posted": "2018-12-07 17:38:58Z", "upvote": "\r\n            10\r\n        ", "accepted": "No", "user": {"stack_user_id": "4979951", "name": "Vahidn", "reputation_score": "315"}, "answer_comments": []}, {"stack_answer_id": "70120429", "answer_content": "\r\n If you want to make query to your dataframe repeatedly and speed is important to you, the best thing is to convert your dataframe to dictionary and then by doing this you can make query thousands of times faster. \n my_df = df.set_index(column_name)\nmy_dict = my_df.to_dict('index')\n \n After make my_dict dictionary you can go through: \n if some_value in my_dict.keys():\n   my_result = my_dict[some_value]\n \n If you have duplicated values in column_name you can't make a dictionary. but you can use: \n my_result = my_df.loc[some_value]\n \n    ", "date_posted": "2021-11-27 17:09:23Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "13302", "name": "marc_s", "reputation_score": "711k"}, "answer_comments": []}, {"stack_answer_id": "71952267", "answer_content": "\r\n SQL statements on DataFrames to select rows using DuckDB \n With  duckdb  we can query pandas DataFrames with SQL statements, in a  highly performant way . \n Since the question is  How do I select rows from a DataFrame based on column values? , and the example in the question is a SQL query, this answer looks logical in this topic. \n Example : \n In [1]: import duckdb\n\nIn [2]: import pandas as pd\n\nIn [3]: con = duckdb.connect()\n\nIn [4]: df = pd.DataFrame({\"A\": range(11), \"B\": range(11, 22)})\n\nIn [5]: df\nOut[5]:\n     A   B\n0    0  11\n1    1  12\n2    2  13\n3    3  14\n4    4  15\n5    5  16\n6    6  17\n7    7  18\n8    8  19\n9    9  20\n10  10  21\n\nIn [6]: results = con.execute(\"SELECT * FROM df where A > 2\").df()\n\nIn [7]: results\nOut[7]:\n    A   B\n0   3  14\n1   4  15\n2   5  16\n3   6  17\n4   7  18\n5   8  19\n6   9  20\n7  10  21\n \n    ", "date_posted": "2022-04-23 20:00:48Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "9081267", "name": "Erfan", "reputation_score": "37.8k"}, "answer_comments": []}, {"stack_answer_id": "71149332", "answer_content": "\r\n Great answers. Only, when the  size of the dataframe approaches million rows , many of the methods tend to take ages when using  df[df['col']==val] . I wanted to have all possible values of \"another_column\" that correspond to specific values in \"some_column\" (in this case in a dictionary). This worked and fast. \n s=datetime.datetime.now()\n\nmy_dict={}\n\nfor i, my_key in enumerate(df['some_column'].values): \n    if i%100==0:\n        print(i)  # to see the progress\n    if my_key not in my_dict.keys():\n        my_dict[my_key]={}\n        my_dict[my_key]['values']=[df.iloc[i]['another_column']]\n    else:\n        my_dict[my_key]['values'].append(df.iloc[i]['another_column'])\n        \ne=datetime.datetime.now()\n\nprint('operation took '+str(e-s)+' seconds')```\n\n \n    ", "date_posted": "2022-02-16 21:13:21Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "5716832", "name": "L. Astola", "reputation_score": "27"}, "answer_comments": []}, {"stack_answer_id": "73213567", "answer_content": "\r\n You can use  loc  (square brackets) with a function: \n # Series\ns = pd.Series([1, 2, 3, 4]) \ns.loc[lambda x: x > 1]\n# s[lambda x: x > 1]\n \n Output: \n 1    2\n2    3\n3    4\ndtype: int64\n \n or \n # DataFrame\ndf = pd.DataFrame({'A': [1, 2, 3], 'B': [10, 20, 30]})\ndf.loc[lambda x: x['A'] > 1]\n# df[lambda x: x['A'] > 1]\n \n Output: \n    A   B\n1  2  20\n2  3  30\n \n The advantage of this method is that you can chain selection with previous operations. For example: \n df.mul(2).loc[lambda x: x['A'] > 3, 'B']\n# (df * 2).loc[lambda x: x['A'] > 3, 'B']\n \n vs \n df_temp = df * 2\ndf_temp.loc[df_temp['A'] > 3, 'B']\n \n Output: \n 1    40\n2    60\nName: B, dtype: int64\n \n    ", "date_posted": "2022-08-02 20:59:55Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "8973620", "name": "Mykola Zotko", "reputation_score": "12.6k"}, "answer_comments": []}], "user": {"stack_user_id": "458429", "name": "szli", "reputation_score": "33.9k"}, "question_comments": [{"stack_question_id": "17071871", "stack_question_comment_id": "89524024", "comment_content": "Check here: ", "user_id": null}, {"stack_question_id": "17071871", "stack_question_comment_id": "94934916", "comment_content": "This is a  Comparison with SQL:  ", "user_id": null}, {"stack_question_id": "17071871", "stack_question_comment_id": "118735273", "comment_content": "you can also use DFsql, to run in memory SQL on pandas dataframes ", "user_id": null}, {"stack_question_id": "17071871", "stack_question_comment_id": "121502921", "comment_content": "Was led here looking for matching based on a list multiple-column values. This post is just about values in one column. Suggest editing title to read \"values in a column\" to avoid false search results.", "user_id": null}, {"stack_question_id": "17071871", "stack_question_comment_id": "129324183", "comment_content": "This question is about ", "user_id": null}]},
{"stack_question_id": "5767228", "question_title": "Why is my Button's command executed immediately when I create the Button, and not when I click it?", "question_content": "\r\n                My code is:\nfrom Tkinter import *\n\nadmin = Tk()\ndef button(an):\n    print(an)\n    print('het')\n\nb = Button(admin, text='as', command=button('hey'))\nb.pack()\nmainloop()\n\nThe button doesn't work, it ...\r\n", "question_url": "/questions/5767228/why-is-my-buttons-command-executed-immediately-when-i-create-the-button-and-no", "date_posted": "Apr 23, 2011 at 21:59", "upvote": "9", "view": "3", "tags": ["python", "tkinter", "callback"], "answers_count": "5", "answers": [{"stack_answer_id": "5771787", "answer_content": "\r\n Consider this code: \n b = Button(admin, text='as', command=button('hey'))\n \n It does exactly the same as this: \n result = button('hey')\nb = button(admin, text='as', command=result)\n \n Likewise, if you create a binding like this: \n listbox.bind(\"<<ListboxSelect>>\", some_function())\n \n ... it's the same as this: \n result = some_function()\nlistbox.bind(\"<<ListboxSelect>>\", result)\n \n The  command  option takes a reference to a function, which is a fancy way of saying you need to pass it the name of the function.  To pass a reference you must use the name only, without using parenthesis or arguments. For example: \n b = Button(... command = button)\n \n If you want to pass a parameter such as \"hey\" you must use a little extra code: \n \n You can create an intermediate function that can be called without your argument and which then calls your  button  function, \n You can use  lambda  to create what is referred to as an  anonymous function . In every way it's a function except it doesn't have a name. When you call the  lambda  command it returns a  reference  to the created function, which means it can be used for the value of the  command  option to the button. \n You can use  functools.partial \n \n For me,  lambda  is the simplest since it doesn't require any additional imports like  functools.partial  does, though some people think that  functools.partial  is easier to understand. \n To create a lambda function that calls your  button  function with an argument you would do something like this: \n lambda: button('hey')\n \n You end up with a function that is functionally equivalent to: \n def some_name():\n    return button('hey')\n \n As I said earlier,  lambda  returns a reference to this nameless function. Since a reference is what the  command  option expects you can use  lambda  directly in the creation of the button: \n b = Button(... command = lambda: button('hey'))\n \n There's a question on this site that has a lot of interesting comments about lambda, in general. See the question  Why Python lambdas are useful? . That same discussion has  an answer that shows how to use lambdas in a loop  when you need to pass in a variable to the callback. \n Finally, see the  zone.effbot.org  article titled  Tkinter Callbacks  for a nice tutorial. The coverage of  lambda  is pretty lean, but the information there might still be useful. \n    ", "date_posted": "2021-12-19 09:07:31Z", "upvote": "\r\n            118\r\n        ", "accepted": "No", "user": {"stack_user_id": "355230", "name": "martineau", "reputation_score": "115k"}, "answer_comments": []}, {"stack_answer_id": "5767256", "answer_content": "\r\n You need to create a function without parameters that you can use as the command: \n b = Button(admin, text='as', command=lambda: button('hey'))\n \n See the \"Passing Argument to Callbacks\" section of  this document . \n    ", "date_posted": "2021-12-19 09:29:33Z", "upvote": "\r\n            15\r\n        ", "accepted": "No", "user": {"stack_user_id": "355230", "name": "martineau", "reputation_score": "115k"}, "answer_comments": []}, {"stack_answer_id": "47980499", "answer_content": "\r\n Example GUI: \n Let's say I have the GUI: \n import tkinter as tk\n\nroot = tk.Tk()\n\nbtn = tk.Button(root, text=\"Press\")\nbtn.pack()\n\nroot.mainloop()\n \n What Happens When a Button Is Pressed \n See that when  btn  is pressed it calls  its own  function which is very similar to  button_press_handle  in the following example: \n def button_press_handle(callback=None):\n    if callback:\n        callback() # Where exactly the method assigned to btn['command'] is being callled\n \n with: \n button_press_handle(btn['command'])\n \n You can simply think that  command  option should be set as, the reference to the method we want to be called, similar to  callback  in  button_press_handle . \n \n Calling a Method (a  Callback ) When the Button is Pressed \n Without  arguments \n So if I wanted to  print  something when the button is pressed I would need to set: \n btn['command'] = print # default to print is new line\n \n Pay close attention to the  lack  of  ()  with the  print  method which is omitted in the meaning that:  \"This is the method's name which I want you to call when pressed  but  don't call it just this very instant.\"  However, I didn't pass any arguments for the  print  so it printed whatever it prints when called without arguments. \n With  Argument(s) \n Now If I wanted to also pass arguments to  the method I want to be called  when the button is pressed I could make use of the anonymous functions, which can be created with  lambda  statement, in this case for  print  built-in method, like the following: \n btn['command'] = lambda arg1=\"Hello\", arg2=\" \", arg3=\"World!\" : print(arg1 + arg2 + arg3)\n \n \n Calling  Multiple  Methods when the Button Is Pressed \n Without  Arguments \n You can also achieve that using  lambda  statement but it is considered bad practice and thus I won't include it here. The good practice is to define a separate method,  multiple_methods , that calls the methods wanted and then set it as the callback to the button press: \n def multiple_methods():\n    print(\"Vicariously\") # the first inner callback\n    print(\"I\") # another inner callback\n \n With  Argument(s) \n In order to pass argument(s) to method that calls other methods, again make use of  lambda  statement, but first: \n def multiple_methods(*args, **kwargs):\n    print(args[0]) # the first inner callback\n    print(kwargs['opt1']) # another inner callback\n \n and then set: \n btn['command'] = lambda arg=\"live\", kw=\"as the\" : a_new_method(arg, opt1=kw)\n \n \n Returning Object(s) From the Callback \n Also further note that  callback  can't really  return  because it's only called inside  button_press_handle  with  callback()  as opposed to  return callback() . It does  return  but  not  anywhere outside that function. Thus you should rather  modify  object(s) that are accessible in the current scope. \n \n Complete Example with  global  Object Modification(s) \n Below example will call a method that changes  btn 's text each time the button is pressed: \n import tkinter as tk\n\ni = 0\ndef text_mod():\n    global i, btn           # btn can be omitted but not sure if should be\n    txt = (\"Vicariously\", \"I\", \"live\", \"as\", \"the\", \"whole\", \"world\", \"dies\")\n    btn['text'] = txt[i]    # the global object that is modified\n    i = (i + 1) % len(txt)  # another global object that gets modified\n\nroot = tk.Tk()\n\nbtn = tk.Button(root, text=\"My Button\")\nbtn['command'] = text_mod\n\nbtn.pack(fill='both', expand=True)\n\nroot.mainloop()\n \n \n Mirror \n    ", "date_posted": "2021-12-19 09:34:41Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "355230", "name": "martineau", "reputation_score": "115k"}, "answer_comments": []}, {"stack_answer_id": "53093323", "answer_content": "\r\n The engine evaluates the result of the function when it is assigning the value at the line \"... command = ...\" \n\n The \"command\" expects a function to be returned, that's why using a lambda can do the job because it is creating an anomymous function that is returned to the \"command\" during evaluation. \nYou can also code your own function, it will do the job also. \n\n this is an example with lambda and without lambda: \n\n #!/usr/bin/python\n# coding=utf-8\n\nfrom Tkinter import *\n# Creation de la fen\u00eatre principale (main window)\nMafenetre = Tk()\nres1 = StringVar()\nres2 = StringVar()\n\ndef isValidInput(obj):\n    if hasattr(obj, 'get') and callable(getattr(obj, 'get')):\n        return TRUE\n    return FALSE\n\n\n# stupid action 2 (return 12 on purpose to show potential mistake)\ndef action1(*arguments):\n    print \"action1 running\"\n    for arg in arguments:\n        if isValidInput(arg):\n            print \"input value: \", arg.get()\n            res1.set(arg.get())\n        else:\n            print \"other value:\", arg\n    print \"\\n\"\n    return 12\n\n\n# stupid action 2\ndef action2(*arguments):\n    print \"action2 running\"\n    a = arguments[0]\n    b = arguments[1]\n    if isValidInput(a) and isValidInput(b):\n        c = a.get() + b.get()\n        res2.set(c)\n        print c\n    print \"\\n\"\n\n\n# a stupid workflow manager ordered by name\ndef start_tasks(*arguments, **keywords):\n    keys = sorted(keywords.keys())\n    for kw in keys:\n        print kw, \"plugged \"\n        keywords[kw](*arguments)\n\n\n# valid callback wrapper with lambda\ndef action1_callback(my_input):\n    return lambda args=[my_input]: action1(*args)\n\n\n# valid callback wrapper without lambda\ndef action1_callback_nolambda(*args, **kw):\n    def anon():\n        action1(*args)\n    return anon\n\n\n# first input string\ninput1 = StringVar()\ninput1.set(\"delete me...\")\nf1 = Entry(Mafenetre, textvariable=input1, bg='bisque', fg='maroon')\nf1.focus_set()\nf1.pack(fill=\"both\", expand=\"yes\", padx=\"5\", pady=5)\n\n# failed callback because the action1 function is evaluated, it will return 12. \n# in this case the button won't work at all, because the assignement expect a function \n# in order to have the button command to execute something\nba1 = Button(Mafenetre)\nba1['text'] = \"show input 1 (ko)\"\nba1['command'] = action1(input1)\nba1.pack(fill=\"both\", expand=\"yes\", padx=\"5\", pady=5)\n\n# working button using a wrapper\nba3 = Button(Mafenetre)\nba3['text'] = \"show input 1 (ok)\"\n# without a lambda it is also working if the assignment is a function\n#ba1['command'] = action1_callback_nolambda(input1)\nba3['command'] = action1_callback(input1)\nba3.pack(fill=\"both\", expand=\"yes\", padx=\"5\", pady=5)\n\n# display result label\nLabel1 = Label(Mafenetre, text=\"Action 1 result:\")\nLabel1.pack(fill=\"both\", expand=\"yes\", padx=\"5\", pady=5)\n# display result value\nresl1 = Label(Mafenetre, textvariable=res1)\nresl1.pack(fill=\"both\", expand=\"yes\", padx=\"5\", pady=5)\n\n\n# second input string\ninput2 = StringVar()\nf2 = Entry(Mafenetre, textvariable=input2, bg='bisque', fg='maroon')\nf2.focus_set()\nf2.pack(fill=\"both\", expand=\"yes\", padx=\"5\", pady=5)\n\n# third test without wrapper, but making sure that several arguments are well handled by a lambda function\nba2 = Button(Mafenetre)\nba2['text'] = \"execute action 2\"\nba2['command'] = lambda args=[input1, input2], action=action2: start_tasks(*args, do=action)\nba2.pack(fill=\"both\", expand=\"yes\", padx=\"5\", pady=5)\n\n# display result label\nLabel2 = Label(Mafenetre, text=\"Action 2 result:\")\nLabel2.pack(fill=\"both\", expand=\"yes\", padx=\"5\", pady=5)\n# display result value\nresl2 = Label(Mafenetre, textvariable=res2)\nresl2.pack(fill=\"both\", expand=\"yes\", padx=\"5\", pady=5)\n\nMafenetre.mainloop()\n \n    ", "date_posted": "2018-10-31 23:34:56Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "2703058", "name": "C.Vergnaud", "reputation_score": "827"}, "answer_comments": []}, {"stack_answer_id": "63638418", "answer_content": "\r\n I think the best way to solve this problem is to use a lambda function. \n from tkinter import *\nadmin= Tk()\ndef button(an):\n    print(an)\n    print(\"het\")\nb = Button(admin, text=\"as\", command=lambda: button(\"hey\"))\nb.pack()\nmainloop()\n \n If you don't want to use the command keyword, you can use the .bind() method instead: \n from tkinter import *\nadmin= Tk()\ndef button(an):\n    print(an)\n    print(\"het\")\nb = Button(admin, text=\"as\")\nb.pack()\nb.bind(\"<Button-1>\", lambda bb: button(\"hey\"))\nmainloop()\n \n Using a mother function (no parameter) which owns the child function (at least 1 parameter) you want to call is stupid. \n Just to share with you, this is one of my program: \n import tkinter\nwindow = tkinter.Tk()\n\ndef plus_them(field_1, field_2, field_3):\n    field_3.delete(0, 'end')\n    num1 = 0\n    num2 = 0\n    try:\n        num1 = int(field_1.get())\n        num2 = int(field_2.get())\n    except:\n        print(\"Exception occurs\")\n    else:\n        print(\"Continue\")\n    result = num1 + num2\n    field_3.insert(tkinter.END, str(result))\n    return result\ndef minus_them(field_1, field_2, field_3):\n    field_3.delete(0, 'end')\n    num1 = 0\n    num2 = 0\n    try:\n        num1 = int(field_1.get())\n        num2 = int(field_2.get())\n    except:\n        print(\"Exception occurs\")\n    else:\n        print(\"Continue\")\n    result = num1 - num2\n    field_3.insert(tkinter.END, str(result))\n    return result\n\n#Input Panel:\nlabel_1 = tkinter.Label(window, text=\"First Number:\")\nlabel_1.grid(row=0, column=0)\nlabel_2 = tkinter.Label(window, text=\"Second Number:\")\nlabel_2.grid(row=1, column=0)\nentry_1 = tkinter.Entry(window)\nentry_1.grid(row=0, column=1)\nentry_2 = tkinter.Entry(window)\nentry_2.grid(row=1, column=1)\n\n#Button Panel:\nbutton_1 = tkinter.Button(window, text=\"Plus\")\nbutton_1.grid(row=2, column=0)\nbutton_2 = tkinter.Button(window, text=\"Minus\")\nbutton_2.grid(row=2, column=1)\n\n#Answer Panel:\nlabel_3 = tkinter.Label(window, text=\"The Answer:\")\nlabel_3.grid(row=3, column=0)\nentry_3 = tkinter.Entry(window)\nentry_3.grid(row=3, column=1)\n\n#Event Handling:\nbutton_1.bind(\"<Button-1>\", lambda p: plus_them(entry_1, entry_2, entry_3))\nbutton_2.bind(\"<Button-1>\", lambda m: minus_them(entry_1, entry_2, entry_3))\n\n#Window Stuff:\nwindow.title(\"Plus and Minus Calculator\")\nwindow.mainloop()\n \n That's it. \n    ", "date_posted": "2020-08-28 17:26:39Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "13804724", "name": "Deer Lawson", "reputation_score": "41"}, "answer_comments": []}], "user": {"stack_user_id": "721481", "name": "salk", "reputation_score": "991"}, "question_comments": [{"stack_question_id": "5767228", "stack_question_comment_id": "92941778", "comment_content": "@Mike-SMT That's exactly why. I want to reward people for posting good answers to common questions - especially if the questions are easy. Many people post half-baked, unmotivated answers to easy questions. I want people to realize that you don't have to be a programming expert to write outstanding answers.", "user_id": null}, {"stack_question_id": "5767228", "stack_question_comment_id": "129618316", "comment_content": "I already mistakenly dupe-hammered and re-opened this. But now I think it is instead a duplicate of ", "user_id": null}]},
{"stack_question_id": "291978", "question_title": "Short description of the scoping rules?", "question_content": "\r\n                What exactly are the Python scoping rules?\n\nIf I have some code:\n\ncode1\nclass Foo:\n   code2\n   def spam.....\n      code3\n      for code4..:\n       code5\n       x()\r\nWhere is x found?  Some possible ...\r\n", "question_url": "/questions/291978/short-description-of-the-scoping-rules", "date_posted": "Nov 15, 2008 at 1:48", "upvote": "5", "view": "2", "tags": ["python", "scope", "dynamic-languages"], "answers_count": "9", "answers": [{"stack_answer_id": "292502", "answer_content": "\r\n Actually, a concise rule for Python Scope resolution, from  Learning Python, 3rd. Ed. . (These rules are specific to variable names, not attributes. If you reference it without a period, these rules apply.) \n\n LEGB Rule \n\n \n L ocal \u2014 Names assigned in any way within a function ( def  or  lambda ), and not declared global in that function \n E nclosing-function \u2014 Names assigned in the local scope of any and all statically enclosing functions ( def  or  lambda ), from inner to outer \n G lobal (module) \u2014 Names assigned at the top-level of a module file, or by executing a  global  statement in a  def  within the file \n B uilt-in (Python) \u2014 Names preassigned in the built-in names module:  open ,  range ,  SyntaxError , etc \n \n\n So, in the case of \n\n code1\nclass Foo:\n    code2\n    def spam():\n        code3\n        for code4:\n            code5\n            x()\n \n\n The  for  loop does not have its own namespace. In LEGB order, the scopes would be  \n\n \n L: Local in  def spam  (in  code3 ,  code4 , and  code5 ) \n E: Any enclosing functions (if the whole example were in another  def ) \n G: Were there any  x  declared globally in the module (in  code1 )? \n B: Any builtin  x  in Python. \n \n\n x  will never be found in  code2  (even in cases where you might expect it would, see  Antti's answer  or  here ). \n    ", "date_posted": "2019-08-25 15:53:35Z", "upvote": "\r\n            442\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "355230", "name": "martineau", "reputation_score": "115k"}, "answer_comments": [{"stack_answer_id": "292502", "stack_answer_comment_id": "14735255", "comment_content": "As a caveat to Global access - reading a global variable can happen without explicit declaration, but writing to it without declaring global(var_name) will instead create a new local instance.", "user_id": null}, {"stack_answer_id": "292502", "stack_answer_comment_id": "19372083", "comment_content": "Actually @Peter, ", "user_id": null}, {"stack_answer_id": "292502", "stack_answer_comment_id": "20763841", "comment_content": "If so, then why isn't foo's \"y\" variable visible to \"bar\" below:  ", "user_id": null}, {"stack_answer_id": "292502", "stack_answer_comment_id": "26476658", "comment_content": "@Jonathan: Because each ", "user_id": null}, {"stack_answer_id": "292502", "stack_answer_comment_id": "96658115", "comment_content": "@Ctrl-C Not really; there is nothing special about class attributes in terms of scope. They are shared in the sense that ", "user_id": null}]}, {"stack_answer_id": "293097", "answer_content": "\r\n Essentially, the only thing in Python that introduces a new scope is a function definition.  Classes are a bit of a special case in that anything defined directly in the body is placed in the class's namespace, but they are not directly accessible from within the methods (or nested classes) they contain. \n\n In your example there are only 3 scopes where x will be searched in: \n\n \n spam's scope - containing everything defined in code3 and code5 (as well as code4, your loop variable) \n The global scope - containing everything defined in code1, as well as Foo (and whatever changes after it) \n The builtins namespace.  A bit of a special case - this contains the various Python builtin functions and types such as len() and str(). Generally this shouldn't be modified by any user code, so expect it to contain the standard functions and nothing else. \n \n\n More scopes only appear when you introduce a nested function (or lambda) into the picture.\nThese will behave pretty much as you'd expect however.  The nested function can access everything in the local scope, as well as anything in the enclosing function's scope. eg. \n\n def foo():\n    x=4\n    def bar():\n        print x  # Accesses x from foo's scope\n    bar()  # Prints 4\n    x=5\n    bar()  # Prints 5\n \n\n Restrictions: \n\n Variables in scopes other than the local function's variables can be accessed, but can't be rebound to new parameters without further syntax.  Instead, assignment will create a new  local  variable instead of affecting the variable in the parent scope.  For example: \n\n global_var1 = []\nglobal_var2 = 1\n\ndef func():\n    # This is OK: It's just accessing, not rebinding\n    global_var1.append(4) \n\n    # This won't affect global_var2. Instead it creates a new variable\n    global_var2 = 2 \n\n    local1 = 4\n    def embedded_func():\n        # Again, this doen't affect func's local1 variable.  It creates a \n        # new local variable also called local1 instead.\n        local1 = 5\n        print local1\n\n    embedded_func() # Prints 5\n    print local1    # Prints 4\n \n\n In order to actually modify the bindings of global variables from within a function scope, you need to specify that the variable is global with the global keyword.  Eg: \n\n global_var = 4\ndef change_global():\n    global global_var\n    global_var = global_var + 1\n \n\n Currently there is no way to do the same for variables in enclosing  function  scopes, but Python 3 introduces a new keyword, \" nonlocal \" which will act in a similar way to global, but for nested function scopes. \n    ", "date_posted": "2008-11-15 21:51:09Z", "upvote": "\r\n            158\r\n        ", "accepted": "No", "user": {"stack_user_id": "9493", "name": "Brian", "reputation_score": "114k"}, "answer_comments": []}, {"stack_answer_id": "23471004", "answer_content": "\r\n There was no thorough answer concerning Python3 time, so I made an answer here. Most of what is described here is detailed in the  4.2.2 Resolution of names  of the Python 3 documentation. \n\n As provided in other answers, there are 4 basic scopes, the LEGB, for Local, Enclosing, Global and Builtin. In addition to those, there is a special scope, the  class body , which does not comprise an enclosing scope for methods defined within the class; any assignments within the class body make the variable from there on be bound in the class body. \n\n Especially,  no  block statement, besides  def  and  class , create a variable scope. In Python 2 a list comprehension does not create a variable scope, however in Python 3 the loop variable within list comprehensions is created in a new scope. \n\n To demonstrate the peculiarities of the class body \n\n x = 0\nclass X(object):\n    y = x\n    x = x + 1 # x is now a variable\n    z = x\n\n    def method(self):\n        print(self.x) # -> 1\n        print(x)      # -> 0, the global x\n        print(y)      # -> NameError: global name 'y' is not defined\n\ninst = X()\nprint(inst.x, inst.y, inst.z, x) # -> (1, 0, 1, 0)\n \n\n Thus unlike in function body, you can reassign the variable to the same name in class body, to get a class variable with the same name; further lookups on this name resolve\nto the class variable instead. \n\n \n\n One of the greater surprises to many newcomers to Python is that a  for  loop does not create a variable scope. In Python 2 the list comprehensions do not create a scope either (while generators and dict comprehensions do!) Instead they leak the value in the function or the global scope: \n\n >>> [ i for i in range(5) ]\n>>> i\n4\n \n\n The comprehensions can be used as a cunning (or awful if you will) way to make modifiable variables within lambda expressions in Python 2 - a lambda expression does create a variable scope, like the  def  statement would, but within lambda no statements are allowed. Assignment being a statement in Python means that no variable assignments in lambda are allowed, but a list comprehension is an expression... \n\n This behaviour has been fixed in Python 3 - no comprehension expressions or generators leak variables. \n\n \n\n The global really means the module scope; the main python module is the  __main__ ; all imported modules are accessible through the  sys.modules  variable; to get access to  __main__  one can use  sys.modules['__main__'] , or  import __main__ ; it is perfectly acceptable to access and assign attributes there; they will show up as variables in the global scope of the main module. \n\n \n\n If a name is ever assigned to in the current scope (except in the class scope), it will be considered belonging to that scope, otherwise it will be considered to belonging to any enclosing scope that assigns to the variable (it might not be assigned yet, or not at all), or finally the global scope. If the variable is considered local, but it is not set yet, or has been deleted, reading the variable value will result in  UnboundLocalError , which is a subclass of  NameError . \n\n x = 5\ndef foobar():\n    print(x)  # causes UnboundLocalError!\n    x += 1    # because assignment here makes x a local variable within the function\n\n# call the function\nfoobar()\n \n\n The scope can declare that it explicitly wants to modify the global (module scope) variable, with the global keyword: \n\n x = 5\ndef foobar():\n    global x\n    print(x)\n    x += 1\n\nfoobar() # -> 5\nprint(x) # -> 6\n \n\n This also is possible even if it was shadowed in enclosing scope: \n\n x = 5\ny = 13\ndef make_closure():\n    x = 42\n    y = 911\n    def func():\n        global x # sees the global value\n        print(x, y)\n        x += 1\n\n    return func\n\nfunc = make_closure()\nfunc()      # -> 5 911\nprint(x, y) # -> 6 13\n \n\n In python 2 there is no easy way to modify the value in the enclosing scope; usually this is simulated by having a mutable value, such as a list with length of 1: \n\n def make_closure():\n    value = [0]\n    def get_next_value():\n        value[0] += 1\n        return value[0]\n\n    return get_next_value\n\nget_next = make_closure()\nprint(get_next()) # -> 1\nprint(get_next()) # -> 2\n \n\n However in python 3, the  nonlocal  comes to rescue: \n\n def make_closure():\n    value = 0\n    def get_next_value():\n        nonlocal value\n        value += 1\n        return value\n    return get_next_value\n\nget_next = make_closure() # identical behavior to the previous example.\n \n\n The  nonlocal  documentation  says that \n\n \n   Names listed in a nonlocal statement, unlike those listed in a global statement, must refer to pre-existing bindings in an enclosing scope (the scope in which a new binding should be created cannot be determined unambiguously). \n \n\n i.e.  nonlocal  always refers to the innermost outer non-global scope where the name has been bound (i.e. assigned to, including used as the  for  target variable, in the  with  clause, or as a function parameter). \n\n \n\n Any variable that is not deemed to be local to the current scope, or any enclosing scope, is a global variable. A global name is looked up in the module global dictionary; if not found, the global is then looked up from the builtins module; the name of the module was changed from python 2 to python 3; in python 2 it was  __builtin__  and in python 3 it is now called  builtins . If you assign to an attribute of builtins module, it will be visible thereafter to any module as a readable global variable, unless that module shadows them with its own global variable with the same name. \n\n \n\n Reading the builtin module can also be useful; suppose that you want the python 3 style print function in some parts of file, but other parts of file still use the  print  statement. In Python 2.6-2.7 you can get hold of the Python 3  print  function with: \n\n import __builtin__\n\nprint3 = __builtin__.__dict__['print']\n \n\n The  from __future__ import print_function  actually does not import the  print  function anywhere in Python 2 - instead it just disables the parsing rules for  print  statement in the current module, handling  print  like any other variable identifier, and thus allowing the  print  the function be looked up in the builtins. \n    ", "date_posted": "2019-12-04 10:15:38Z", "upvote": "\r\n            114\r\n        ", "accepted": "No", "user": {"stack_user_id": "918959", "name": "Antti Haapala -- \u0421\u043b\u0430\u0432\u0430 \u0423\u043a\u0440\u0430\u0457\u043d\u0456", "reputation_score": "125k"}, "answer_comments": [{"stack_answer_id": "23471004", "stack_answer_comment_id": "118356809", "comment_content": "Glad to finally see an answer that mentions the special ", "user_id": null}]}, {"stack_answer_id": "34094235", "answer_content": "\r\n A slightly more complete example of scope: \n\n from __future__ import print_function  # for python 2 support\n\nx = 100\nprint(\"1. Global x:\", x)\nclass Test(object):\n    y = x\n    print(\"2. Enclosed y:\", y)\n    x = x + 1\n    print(\"3. Enclosed x:\", x)\n\n    def method(self):\n        print(\"4. Enclosed self.x\", self.x)\n        print(\"5. Global x\", x)\n        try:\n            print(y)\n        except NameError as e:\n            print(\"6.\", e)\n\n    def method_local_ref(self):\n        try:\n            print(x)\n        except UnboundLocalError as e:\n            print(\"7.\", e)\n        x = 200 # causing 7 because has same name\n        print(\"8. Local x\", x)\n\ninst = Test()\ninst.method()\ninst.method_local_ref()\n \n\n output: \n\n 1. Global x: 100\n2. Enclosed y: 100\n3. Enclosed x: 101\n4. Enclosed self.x 101\n5. Global x 100\n6. global name 'y' is not defined\n7. local variable 'x' referenced before assignment\n8. Local x 200\n \n    ", "date_posted": "2017-11-20 04:04:39Z", "upvote": "\r\n            26\r\n        ", "accepted": "No", "user": {"stack_user_id": "355230", "name": "martineau", "reputation_score": "115k"}, "answer_comments": [{"stack_answer_id": "34094235", "stack_answer_comment_id": "66143541", "comment_content": "This is great answer. However, I think that the differences between ", "user_id": null}, {"stack_answer_id": "34094235", "stack_answer_comment_id": "78761696", "comment_content": "@brianray: What about z?", "user_id": null}, {"stack_answer_id": "34094235", "stack_answer_comment_id": "81546225", "comment_content": "@kiril I added a note about that", "user_id": null}, {"stack_answer_id": "34094235", "stack_answer_comment_id": "81546228", "comment_content": "@MalikA.Rumi I removed z as it wasn't interesting", "user_id": null}, {"stack_answer_id": "34094235", "stack_answer_comment_id": "92307270", "comment_content": "Surprisingly, this is the ", "user_id": null}]}, {"stack_answer_id": "292907", "answer_content": "\r\n The scoping rules for Python 2.x have been outlined already in other answers. The only thing I would add is that in Python 3.0, there is also the concept of a non-local scope (indicated by the 'nonlocal' keyword). This allows you to access outer scopes directly, and opens up the ability to do some neat tricks, including lexical closures (without ugly hacks involving mutable objects). \n\n EDIT: Here's the  PEP  with more information on this. \n    ", "date_posted": "2008-11-15 18:52:49Z", "upvote": "\r\n            23\r\n        ", "accepted": "No", "user": {"stack_user_id": "18866", "name": "Jeremy Cantrell", "reputation_score": "25.1k"}, "answer_comments": []}, {"stack_answer_id": "292002", "answer_content": "\r\n Python resolves your variables with -- generally -- three namespaces available.   \n\n \n   At any time during execution, there\n  are at least three nested scopes whose\n  namespaces are directly accessible:\n  the innermost scope, which is searched\n  first, contains the local names; the\n  namespaces of any enclosing functions,\n  which are searched starting with the\n  nearest enclosing scope; the middle\n  scope, searched next, contains the\n  current module's global names; and the\n  outermost scope (searched last) is the\n  namespace containing built-in names. \n \n\n There are two functions:  globals  and  locals  which show you the contents two of these namespaces. \n\n Namespaces are created by packages, modules, classes, object construction and functions.  There aren't any other flavors of namespaces.   \n\n In this case, the call to a function named  x  has to be resolved in the local name space or the global namespace. \n\n Local in this case, is the body of the method function  Foo.spam . \n\n Global is -- well -- global.  \n\n The rule is to search the nested local spaces created by method functions (and nested function definitions), then search global.  That's it. \n\n There are no other scopes.  The  for  statement (and other compound statements like  if  and  try ) don't create new nested scopes.  Only definitions (packages, modules, functions, classes and object instances.) \n\n Inside a class definition, the names are part of the class namespace.   code2 , for instance, must be qualified by the class name.  Generally  Foo.code2 .  However,  self.code2  will also work because Python objects look at the containing class as a fall-back. \n\n An object (an instance of a class) has instance variables.  These names are in the object's namespace.  They must be qualified by the object.  ( variable.instance .)   \n\n From within a class method, you have locals and globals.  You say  self.variable  to pick the instance as the namespace.  You'll note that  self  is an argument to every class member function, making it part of the local namespace. \n\n See  Python Scope Rules ,  Python Scope ,  Variable Scope . \n    ", "date_posted": "2017-05-23 12:10:44Z", "upvote": "\r\n            15\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": [{"stack_answer_id": "292002", "stack_answer_comment_id": "140935", "comment_content": "This is out of date. Since 2.1 (7 years ago) there are more than two scopes, as nested functions introduce new scopes, so a function within a function will have access to its local scope, the enclosing functions scope, and global scope (also builtins).", "user_id": null}, {"stack_answer_id": "292002", "stack_answer_comment_id": "141122", "comment_content": "I'm sorry, this is no longer the case. ", "user_id": null}]}, {"stack_answer_id": "292498", "answer_content": "\r\n \n   Where is x found? \n \n\n x is not found as you haven't defined it. :-) It could be found in code1 (global) or code3 (local) if you put it there. \n\n code2 (class members) aren't visible to code inside methods of the same class\u2009\u2014\u2009you would usually access them using self. code4/code5 (loops) live in the same scope as code3, so if you wrote to x in there you would be changing the x instance defined in code3, not making a new x. \n\n Python is statically scoped, so if you pass \u2018spam\u2019 to another function spam will still have access to globals in the module it came from (defined in code1), and any other containing scopes (see below). code2 members would again be accessed through self. \n\n lambda is no different to def. If you have a lambda used inside a function, it's the same as defining a nested function. In Python 2.2 onwards, nested scopes are available. In this case you can bind x at any level of function nesting and Python will pick up the innermost instance: \n\n x= 0\ndef fun1():\n    x= 1\n    def fun2():\n        x= 2\n        def fun3():\n            return x\n        return fun3()\n    return fun2()\nprint fun1(), x\n\n2 0\n \n\n fun3 sees the instance x from the nearest containing scope, which is the function scope associated with fun2. But the other x instances, defined in fun1 and globally, are not affected. \n\n Before nested_scopes\u2009\u2014\u2009in Python pre-2.1, and in 2.1 unless you specifically ask for the feature using a from-future-import\u2009\u2014\u2009fun1 and fun2's scopes are not visible to fun3, so S.Lott's answer holds and you would get the global x: \n\n 0 0\n \n    ", "date_posted": "2008-11-15 12:44:59Z", "upvote": "\r\n            9\r\n        ", "accepted": "No", "user": {"stack_user_id": "18936", "name": "bobince", "reputation_score": "517k"}, "answer_comments": []}, {"stack_answer_id": "62379080", "answer_content": "\r\n The  Python name resolution  only knows the following kinds of scope: \n \n builtins scope which provides the  Builtin Functions , such as  print ,  int , or  zip , \n module  global scope which is always the top-level of the current module, \n three user-defined scopes that can be nested into each other, namely\n \n function  closure scope, from any enclosing  def  block,  lambda  expression or comprehension. \n function  local scope, inside a  def  block,  lambda  expression or comprehension, \n class  scope, inside a  class  block. \n \n \n \n Notably, other constructs such as  if ,  for , or  with  statements do not have their own scope. \n The scoping TLDR : The  lookup  of a name begins at the scope in which the name is used, then any enclosing scopes (excluding class scopes), to the module globals, and finally the builtins \u2013 the first match in this search order is used.\nThe  assignment  to a scope is by default to the current scope \u2013 the special forms  nonlocal  and  global  must be used to  assign  to a name from an outer scope. \n Finally, comprehensions and generator expressions as well as  :=  asignment expressions have one special rule when combined. \n \n Nested Scopes and Name Resolution \n These different scopes build a hierarchy, with builtins then global always forming the base, and closures, locals and class scope being nested as  lexically  defined. That is, only the nesting in the source code matters, not for example the call stack. \n print(\"builtins are available without definition\")\n\nsome_global = \"1\"  # global variables are at module scope\n\ndef outer_function():\n    some_closure = \"3.1\"  # locals and closure are defined the same, at function scope\n    some_local = \"3.2\"    # a variable becomes a closure if a nested scope uses it\n\n    class InnerClass:\n         some_classvar = \"3.3\"   # class variables exist *only* at class scope\n\n         def nested_function(self):\n             some_local = \"3.2\"   # locals can replace outer names\n             print(some_closure)  # closures are always readable\n    return InnerClass\n \n Even though  class  creates a scope and may have nested classes, functions and comprehensions, the names of the  class  scope are not visible to enclosed scopes. This creates the following hierarchy: \n \u250e builtins           [print, ...]\n\u2517\u2501\u2531 globals            [some_global]\n  \u2517\u2501\u2531 outer_function     [some_local, some_closure]\n    \u2523\u2501\u257e InnerClass         [some_classvar]\n    \u2517\u2501\u257e inner_function     [some_local]\n \n Name resolution always starts at the  current scope  in which a name is accessed, then goes up the hierarchy until a match is found. For example, looking up  some_local  inside  outer_function  and  inner_function  starts at the respective function - and immediately finds the  some_local  defined in  outer_function  and  inner_function , respectively. When a name is not local, it is fetched from the nearest enclosing scope that defines it \u2013 looking up  some_closure  and  print  inside  inner_function  searches until  outer_function  and builtins, respectively. \n \n Scope Declarations and Name Binding \n By default, a name belongs to any scope in which it is bound to a value. Binding the same name again in an inner scope creates a new variable with the same name - for example,  some_local  exists separately in both  outer_function  and  inner_function . As far as scoping is concerned, binding includes any statement that sets the value of a name \u2013 assignment statements, but also the iteration variable of a  for  loop, or the name of a  with  context manager. Notably,  del  also counts as name binding. \n When a name must refer to an outer variable  and  be bound in an inner scope, the name must be declared as not local. Separate declarations exists for the different kinds of enclosing scopes:  nonlocal  always refers to the nearest closure, and  global  always refers to a global name. Notably,  nonlocal  never refers to a global name and  global  ignores all closures of the same name. There is no declaration to refer to the builtin scope. \n \nsome_global = \"1\"\n\ndef outer_function():\n    some_closure = \"3.2\"\n    some_global = \"this is ignored by a nested global declaration\"\n    \n    def inner_function():\n        global some_global     # declare variable from global scope\n        nonlocal some_closure  # declare variable from enclosing scope\n        message = \" bound by an inner scope\"\n        some_global = some_global + message\n        some_closure = some_closure + message\n    return inner_function\n \n Of note is that function local and  nonlocal  are resolved at compile time. A  nonlocal  name  must  exist in some outer scope. In contrast, a  global  name can be defined dynamically and may be added or removed from the global scope at any time. \n \n Comprehensions and Assignment Expressions \n The scoping rules of list, set and dict comprehensions and generator expressions are  almost  the same as for functions. Likewise, the scoping rules for assignment expressions are  almost  the same as for regular name binding. \n The scope of comprehensions and generator expressions is of the same kind as function scope. All names bound in the scope, namely the iteration variables, are locals or closures to the comprehensions/generator and nested scopes. All names, including iterables, are resolved using name resolution as applicable inside functions. \n some_global = \"global\"\n\ndef outer_function():\n    some_closure = \"closure\"\n    return [            # new function-like scope started by comprehension\n        comp_local      # names resolved using regular name resolution\n        for comp_local  # iteration targets are local\n        in \"iterable\"\n        if comp_local in some_global and comp_local in some_global\n    ]\n \n An  :=  assignment expression works on the nearest function, class or global scope. Notably, if the target of an assignment expression has been declared  nonlocal  or  global  in the nearest scope, the assignment expression honors this like a regular assignment. \n print(some_global := \"global\")\n\ndef outer_function():\n    print(some_closure := \"closure\")\n \n However, an assignment expression inside a comprehension/generator works on the nearest  enclosing scope  of the comprehension/generator, not the scope of the comprehension/generator itself. When several comprehensions/generators are nested, the nearest function or global scope is used. Since the comprehension/generator scope can read closures and global variables, the assignment variable is readable in the comprehension as well. Assigning from a comprehension to a class scope is not valid. \n print(some_global := \"global\")\n\ndef outer_function():\n    print(some_closure := \"closure\")\n    steps = [\n        # v write to variable in containing scope\n        (some_closure := some_closure + comp_local)\n        #                 ^ read from variable in containing scope\n        for comp_local in some_global\n    ]\n    return some_closure, steps\n \n While the iteration variable is local to the comprehension in which it is bound, the target of the assignment expression does not create a local variable and is read from the outer scope: \n \u250e builtins           [print, ...]\n\u2517\u2501\u2531 globals            [some_global]\n  \u2517\u2501\u2531 outer_function     [some_closure]\n    \u2517\u2501\u257e <listcomp>         [comp_local]\n \n    ", "date_posted": "2020-07-07 08:28:34Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "5349916", "name": "MisterMiyagi", "reputation_score": "38.6k"}, "answer_comments": [{"stack_answer_id": "62379080", "stack_answer_comment_id": "126027050", "comment_content": "I think your answer is incomplete.  The ", "user_id": null}, {"stack_answer_id": "62379080", "stack_answer_comment_id": "126027529", "comment_content": "@JohnHenckel That is not a new scope. ", "user_id": null}, {"stack_answer_id": "62379080", "stack_answer_comment_id": "126027831", "comment_content": "OMG this is strange. Thank you for explaining that to me.", "user_id": null}]}, {"stack_answer_id": "56103969", "answer_content": "\r\n In Python,  \n\n \n   any variable that is assigned a value is local to the block in which\n  the assignment appears. \n \n\n If a variable can't be found in the current scope, please refer to the LEGB order. \n    ", "date_posted": "2019-05-12 22:27:43Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "9687097", "name": "GraceMeng", "reputation_score": "839"}, "answer_comments": []}], "user": {"stack_user_id": "1320510", "name": "Charles Merriam", "reputation_score": "18.9k"}, "question_comments": [{"stack_question_id": "291978", "stack_question_comment_id": "98969816", "comment_content": "The scoping rules are described fairly tersely \u2014 but also completely \u2014 in the Python documentation: ", "user_id": null}]},
{"stack_question_id": "419163", "question_title": "What does if __name__ == \"__main__\": do?", "question_content": "\r\n                What does this do, and why should one include the if statement?\nif __name__ == \"__main__\":\n    print(\"Hello, World!\")\r\n", "question_url": "/questions/419163/what-does-if-name-main-do", "date_posted": "Jan 7, 2009 at 4:11", "upvote": "7", "view": "4", "tags": ["python", "namespaces", "program-entry-point", "python-module", "idioms"], "answers_count": "4", "answers": [{"stack_answer_id": "419185", "answer_content": "\r\n Short Answer \n It's boilerplate code that protects users from accidentally invoking the script when they didn't intend to. Here are some common problems when the guard is omitted from a script: \n \n If you import the guardless script in another script (e.g.  import my_script_without_a_name_eq_main_guard ), then the latter script will trigger the former to run  at import time  and  using the second script's command line arguments . This is almost always a mistake. \n \n If you have a custom class in the guardless script and save it to a pickle file, then unpickling it in another script will trigger an import of the guardless script, with the same problems outlined in the previous bullet. \n \n \n Long Answer \n To better understand why and how this matters, we need to take a step back to understand how Python initializes scripts and how this interacts with its module import mechanism. \n Whenever the Python interpreter reads a source file, it does two things: \n \n it sets a few special variables like  __name__ , and then \n \n it executes all of the code found in the file. \n \n \n Let's see how this works and how it relates to your question about the  __name__  checks we always see in Python scripts. \n Code Sample \n Let's use a slightly different code sample to explore how imports and scripts work.  Suppose the following is in a file called  foo.py . \n # Suppose this is foo.py.\n\nprint(\"before import\")\nimport math\n\nprint(\"before function_a\")\ndef function_a():\n    print(\"Function A\")\n\nprint(\"before function_b\")\ndef function_b():\n    print(\"Function B {}\".format(math.sqrt(100)))\n\nprint(\"before __name__ guard\")\nif __name__ == '__main__':\n    function_a()\n    function_b()\nprint(\"after __name__ guard\")\n \n Special Variables \n When the Python interpreter reads a source file, it first defines a few special variables. In this case, we care about the  __name__  variable. \n When Your Module Is the Main Program \n If you are running your module (the source file) as the main program, e.g. \n python foo.py\n \n the interpreter will assign the hard-coded string  \"__main__\"  to the  __name__  variable, i.e. \n # It's as if the interpreter inserts this at the top\n# of your module when run as the main program.\n__name__ = \"__main__\" \n \n When Your Module Is Imported By Another \n On the other hand, suppose some other module is the main program and it imports your module. This means there's a statement like this in the main program, or in some other module the main program imports: \n # Suppose this is in some other main program.\nimport foo\n \n The interpreter will search for your  foo.py  file (along with searching for a few other variants), and prior to executing that module, it will assign the name  \"foo\"  from the import statement to the  __name__  variable, i.e. \n # It's as if the interpreter inserts this at the top\n# of your module when it's imported from another module.\n__name__ = \"foo\"\n \n Executing the Module's Code \n After the special variables are set up, the interpreter executes all the code in the module, one statement at a time. You may want to open another window on the side with the code sample so you can follow along with this explanation. \n Always \n \n It prints the string  \"before import\"  (without quotes). \n \n It loads the  math  module and assigns it to a variable called  math . This is equivalent to replacing  import math  with the following (note that  __import__  is a low-level function in Python that takes a string and triggers the actual import): \n \n \n # Find and load a module given its string name, \"math\",\n# then assign it to a local variable called math.\nmath = __import__(\"math\")\n \n \n It prints the string  \"before function_a\" . \n \n It executes the  def  block, creating a function object, then assigning that function object to a variable called  function_a . \n \n It prints the string  \"before function_b\" . \n \n It executes the second  def  block, creating another function object, then assigning it to a variable called  function_b . \n \n It prints the string  \"before __name__ guard\" . \n \n \n Only When Your Module Is the Main Program \n \n If your module is the main program, then it will see that  __name__  was indeed set to  \"__main__\"  and it calls the two functions, printing the strings  \"Function A\"  and  \"Function B 10.0\" . \n \n Only When Your Module Is Imported by Another \n \n ( instead ) If your module is not the main program but was imported by another one, then  __name__  will be  \"foo\" , not  \"__main__\" , and it'll skip the body of the  if  statement. \n \n Always \n \n It will print the string  \"after __name__ guard\"  in both situations. \n \n Summary \n In summary, here's what'd be printed in the two cases: \n # What gets printed if foo is the main program\nbefore import\nbefore function_a\nbefore function_b\nbefore __name__ guard\nFunction A\nFunction B 10.0\nafter __name__ guard\n \n # What gets printed if foo is imported as a regular module\nbefore import\nbefore function_a\nbefore function_b\nbefore __name__ guard\nafter __name__ guard\n \n Why Does It Work This Way? \n You might naturally wonder why anybody would want this.  Well, sometimes you want to write a  .py  file that can be both used by other programs and/or modules as a module, and can also be run as the main program itself.  Examples: \n \n Your module is a library, but you want to have a script mode where it runs some unit tests or a demo. \n \n Your module is only used as a main program, but it has some unit tests, and the testing framework works by importing  .py  files like your script and running special test functions. You don't want it to try running the script just because it's importing the module. \n \n Your module is mostly used as a main program, but it also provides a programmer-friendly API for advanced users. \n \n \n Beyond those examples, it's elegant that running a script in Python is just setting up a few magic variables and importing the script. \"Running\" the script is a side effect of importing the script's module. \n Food for Thought \n \n Question: Can I have multiple  __name__  checking blocks?  Answer: it's strange to do so, but the language won't stop you. \n \n Suppose the following is in  foo2.py .  What happens if you say  python foo2.py  on the command-line? Why? \n \n \n # Suppose this is foo2.py.\nimport os, sys; sys.path.insert(0, os.path.dirname(__file__)) # needed for some interpreters\n\ndef function_a():\n    print(\"a1\")\n    from foo2 import function_b\n    print(\"a2\")\n    function_b()\n    print(\"a3\")\n\ndef function_b():\n    print(\"b\")\n\nprint(\"t1\")\nif __name__ == \"__main__\":\n    print(\"m1\")\n    function_a()\n    print(\"m2\")\nprint(\"t2\")\n      \n \n \n Now, figure out what will happen if you remove the  __name__  check in  foo3.py : \n \n # Suppose this is foo3.py.\nimport os, sys; sys.path.insert(0, os.path.dirname(__file__)) # needed for some interpreters\n\ndef function_a():\n    print(\"a1\")\n    from foo3 import function_b\n    print(\"a2\")\n    function_b()\n    print(\"a3\")\n\ndef function_b():\n    print(\"b\")\n\nprint(\"t1\")\nprint(\"m1\")\nfunction_a()\nprint(\"m2\")\nprint(\"t2\")\n \n \n What will this do when used as a script?  When imported as a module? \n \n # Suppose this is in foo4.py\n__name__ = \"__main__\"\n\ndef bar():\n    print(\"bar\")\n    \nprint(\"before __name__ guard\")\nif __name__ == \"__main__\":\n    bar()\nprint(\"after __name__ guard\")\n \n    ", "date_posted": "2022-05-19 12:26:02Z", "upvote": "\r\n            8365\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "4298200", "name": "Neuron", "reputation_score": "4,509"}, "answer_comments": [{"stack_answer_id": "419185", "stack_answer_comment_id": "96284627", "comment_content": "Out of curiosity: What hapens if I run ", "user_id": null}, {"stack_answer_id": "419185", "stack_answer_comment_id": "96321241", "comment_content": "@hajef You're correct about how things would work with ", "user_id": null}, {"stack_answer_id": "419185", "stack_answer_comment_id": "96476792", "comment_content": "i have a doubt in foo2.py example in the food for thought section.what does from foo2.py import functionB do? In my view it just imports foo2.py from functionB", "user_id": null}, {"stack_answer_id": "419185", "stack_answer_comment_id": "102365381", "comment_content": "One of the modules that may import your code is ", "user_id": null}, {"stack_answer_id": "419185", "stack_answer_comment_id": "106231301", "comment_content": "Extremely minor point, but I believe python actually determines the ", "user_id": null}]}, {"stack_answer_id": "419189", "answer_content": "\r\n When your script is run by passing it as a command to the Python interpreter, \n\n python myscript.py\n \n\n all of the code that is at indentation level 0 gets executed.  Functions and classes that are defined are, well, defined, but none of their code gets run.  Unlike other languages, there's no  main()  function that gets run automatically - the  main()  function is implicitly all the code at the top level. \n\n In this case, the top-level code is an  if  block.   __name__  is a built-in variable which evaluates to the name of the current module.  However, if a module is being run directly (as in  myscript.py  above), then  __name__  instead is set to the string  \"__main__\" .  Thus, you can test whether your script is being run directly or being imported by something else by testing \n\n if __name__ == \"__main__\":\n    ...\n \n\n If your script is being imported into another module, its various function and class definitions will be imported and its top-level code will be executed, but the code in the then-body of the  if  clause above won't get run as the condition is not met. As a basic example, consider the following two scripts: \n\n # file one.py\ndef func():\n    print(\"func() in one.py\")\n\nprint(\"top-level in one.py\")\n\nif __name__ == \"__main__\":\n    print(\"one.py is being run directly\")\nelse:\n    print(\"one.py is being imported into another module\")\n \n\n\n\n # file two.py\nimport one\n\nprint(\"top-level in two.py\")\none.func()\n\nif __name__ == \"__main__\":\n    print(\"two.py is being run directly\")\nelse:\n    print(\"two.py is being imported into another module\")\n \n\n Now, if you invoke the interpreter as \n\n python one.py\n \n\n The output will be \n\n top-level in one.py\none.py is being run directly\n \n\n If you run  two.py  instead: \n\n python two.py\n \n\n You get \n\n top-level in one.py\none.py is being imported into another module\ntop-level in two.py\nfunc() in one.py\ntwo.py is being run directly\n \n\n Thus, when module  one  gets loaded, its  __name__  equals  \"one\"  instead of  \"__main__\" . \n    ", "date_posted": "2018-01-31 13:28:16Z", "upvote": "\r\n            2094\r\n        ", "accepted": "No", "user": {"stack_user_id": "6160119", "name": "Tonechas", "reputation_score": "12.9k"}, "answer_comments": [{"stack_answer_id": "419189", "stack_answer_comment_id": "117154652", "comment_content": "So, ", "user_id": null}, {"stack_answer_id": "419189", "stack_answer_comment_id": "127677317", "comment_content": "@Adam Rosenfield  ", "user_id": null}]}, {"stack_answer_id": "419986", "answer_content": "\r\n Create the following two files: \n # a.py\n\nimport b\n \n # b.py\n\nprint(\"__name__ equals \" + __name__)\n\nif __name__ == '__main__':\n    print(\"if-statement was executed\")\n \n Now run each file individually. \n \n Running  python a.py : \n $ python a.py\n__name__ equals b\n \n When  a.py  is executed, it imports the module  b . This causes all the code inside  b  to run. Python sets  globals()['__name__']  in the  b  module to the module's name,  b . \n   \n Running  python b.py : \n $ python b.py\n__name__ equals __main__\nif-statement was executed\n \n When only the file  b.py  is executed, Python sets  globals()['__name__']  in this file to  \"__main__\" . Therefore, the  if  statement evaluates to  True  this time. \n    ", "date_posted": "2022-05-31 01:44:10Z", "upvote": "\r\n            837\r\n        ", "accepted": "No", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": []}, {"stack_answer_id": "20158605", "answer_content": "\r\n \n   What does the  if __name__ == \"__main__\":  do? \n \n\n To outline the basics: \n\n \n The global variable,  __name__ , in the module that is the entry point to your program, is  '__main__' . Otherwise, it's the name you import the module by. \n So, code under the  if  block will only run if the module is the entry point to your program. \n It allows the code in the module to be importable by other modules, without executing the code block beneath on import. \n \n\n \n\n Why do we need this? \n\n Developing and Testing Your Code \n\n Say you're writing a Python script designed to be used as a module: \n\n def do_important():\n    \"\"\"This function does something very important\"\"\"\n \n\n You  could  test the module by adding this call of the function to the bottom: \n\n do_important()\n \n\n and running it (on a command prompt) with something like: \n\n ~$ python important.py\n \n\n The Problem \n\n However, if you want to import the module to another script: \n\n import important\n \n\n On import, the  do_important  function would be called, so you'd probably comment out your function call,  do_important() , at the bottom.  \n\n # do_important() # I must remember to uncomment to execute this!\n \n\n And then you'll have to remember whether or not you've commented out your test function call. And this extra complexity would mean you're likely to forget, making your development process more troublesome. \n\n A Better Way \n\n The  __name__  variable points to the namespace wherever the Python interpreter happens to be at the moment.  \n\n Inside an imported module, it's the name of that module.  \n\n But inside the primary module (or an interactive Python session, i.e. the interpreter's Read, Eval, Print Loop, or REPL) you are running everything from its  \"__main__\" . \n\n So if you check before executing: \n\n if __name__ == \"__main__\":\n    do_important()\n \n\n With the above, your code will only execute when you're running it as the primary module (or intentionally call it from another script).  \n\n An Even Better Way \n\n There's a Pythonic way to improve on this, though.  \n\n What if we want to run this business process from outside the module? \n\n If we put the code we want to exercise as we develop and test in a function like this and then do our check for  '__main__'  immediately after: \n\n def main():\n    \"\"\"business logic for when running this module as the primary one!\"\"\"\n    setup()\n    foo = do_important()\n    bar = do_even_more_important(foo)\n    for baz in bar:\n        do_super_important(baz)\n    teardown()\n\n# Here's our payoff idiom!\nif __name__ == '__main__':\n    main()\n \n\n We now have a final function for the end of our module that will run if we run the module as the primary module.  \n\n It will allow the module and its functions and classes to be imported into other scripts without running the  main  function, and will also allow the module (and its functions and classes) to be called when running from a different  '__main__'  module, i.e. \n\n import important\nimportant.main()\n \n\n This idiom can also be found in the Python documentation in an explanation of the  __main__  module.  That text states: \n\n \n   This module represents the (otherwise anonymous) scope in which the\n  interpreter\u2019s main program executes \u2014 commands read either from\n  standard input, from a script file, or from an interactive prompt. It\n  is this environment in which the idiomatic \u201cconditional script\u201d stanza\n  causes a script to run: \n\n if __name__ == '__main__':\n    main()\n \n \n    ", "date_posted": "2018-03-27 02:27:47Z", "upvote": "\r\n            588\r\n        ", "accepted": "No", "user": {"stack_user_id": "541136", "name": "Russia Must Remove Putin", "reputation_score": "347k"}, "answer_comments": [{"stack_answer_id": "20158605", "stack_answer_comment_id": "127678263", "comment_content": "Sorry, I can't there be any difference between the method mentioned in the section named ", "user_id": null}, {"stack_answer_id": "20158605", "stack_answer_comment_id": "129276841", "comment_content": "@John I don't think there's a difference. He used ", "user_id": null}]}, {"stack_answer_id": "419174", "answer_content": "\r\n if __name__ == \"__main__\"  is the part that runs when the script is run from (say) the command line using a command like  python myscript.py . \n    ", "date_posted": "2015-07-10 15:49:13Z", "upvote": "\r\n            163\r\n        ", "accepted": "No", "user": {"stack_user_id": "1709587", "name": "Mark Amery", "reputation_score": "130k"}, "answer_comments": [{"stack_answer_id": "419174", "stack_answer_comment_id": "101682583", "comment_content": "Why does a file ", "user_id": null}, {"stack_answer_id": "419174", "stack_answer_comment_id": "115789570", "comment_content": "When you run ", "user_id": null}]}, {"stack_answer_id": "26369628", "answer_content": "\r\n \n What does  if __name__ == \"__main__\":  do? \n \n __name__  is a global variable (in Python, global actually means on the  module level ) that exists in all namespaces. It is typically the module's name (as a  str  type). \n As the only special case, however, in whatever Python process you run, as in mycode.py: \n python mycode.py\n \n the otherwise anonymous global namespace is assigned the value of  '__main__'  to its  __name__ . \n Thus, including  the final lines \n if __name__ == '__main__':\n    main()\n \n \n at the end of your mycode.py script, \n when it is the primary, entry-point module that is run by a Python process, \n \n will cause your script's uniquely defined  main  function to run. \n Another benefit of using this construct: you can also import your code as a module in another script and then run the main function if and when your program decides: \n import mycode\n# ... any amount of other code\nmycode.main()\n \n    ", "date_posted": "2022-05-31 01:52:40Z", "upvote": "\r\n            102\r\n        ", "accepted": "No", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": []}, {"stack_answer_id": "39761460", "answer_content": "\r\n There are lots of different takes here on the mechanics of the code in question, the \"How\", but for me none of it made sense until I understood the \"Why\". This should be especially helpful for new programmers. \n\n Take file \"ab.py\": \n\n def a():\n    print('A function in ab file');\na()\n \n\n And a second file \"xy.py\": \n\n import ab\ndef main():\n    print('main function: this is where the action is')\ndef x():\n    print ('peripheral task: might be useful in other projects')\nx()\nif __name__ == \"__main__\":\n    main()\n \n\n \n   What is this code actually doing? \n \n\n When you execute  xy.py , you  import ab . The import statement runs the module immediately on import, so  ab 's operations get executed before the remainder of  xy 's. Once finished with  ab , it continues with  xy . \n\n The interpreter keeps track of which scripts are running with  __name__ . When you run a script - no matter what you've named it - the interpreter calls it  \"__main__\" , making it the master or 'home' script that gets returned to after running an external script. \n\n Any other script that's called from this  \"__main__\"  script is assigned its filename as its  __name__  (e.g.,  __name__ == \"ab.py\" ). Hence, the line  if __name__ == \"__main__\":  is the interpreter's test to determine if it's interpreting/parsing the 'home' script that was initially executed, or if it's temporarily peeking into another (external) script. This gives the programmer flexibility to have the script behave differently if it's executed directly vs. called externally. \n\n Let's step through the above code to understand what's happening, focusing first on the unindented lines and the order they appear in the scripts. Remember that function - or  def  - blocks don't do anything by themselves until they're called. What the interpreter might say if mumbled to itself: \n\n \n Open xy.py as the 'home' file; call it  \"__main__\"  in the  __name__  variable. \n Import and open file with the  __name__ == \"ab.py\" . \n Oh, a function. I'll remember that. \n Ok, function  a() ; I just learned that. Printing ' A function in ab file '. \n End of file; back to  \"__main__\" ! \n Oh, a function. I'll remember that. \n Another one. \n Function  x() ; ok, printing ' peripheral task: might be useful in other projects '. \n What's this? An  if  statement. Well, the condition has been met (the variable  __name__  has been set to  \"__main__\" ), so I'll enter the  main()  function and print ' main function: this is where the action is '. \n \n\n The bottom two lines mean: \"If this is the  \"__main__\"  or 'home' script, execute the function called  main() \". That's why you'll see a  def main():  block up top, which contains the main flow of the script's functionality. \n\n \n   Why implement this? \n \n\n Remember what I said earlier about import statements? When you import a module it doesn't just 'recognize' it and wait for further instructions - it actually runs all the executable operations contained within the script. So, putting the meat of your script into the  main()  function effectively quarantines it, putting it in isolation so that it won't immediately run when imported by another script. \n\n Again, there will be exceptions, but common practice is that  main()  doesn't usually get called externally. So you may be wondering one more thing: if we're not calling  main() , why are we calling the script at all? It's because many people structure their scripts with standalone functions that are built to be run independent of the rest of the code in the file. They're then later called somewhere else in the body of the script. Which brings me to this: \n\n \n   But the code works without it \n \n\n Yes, that's right. These separate functions  can  be called from an in-line script that's not contained inside a  main()  function. If you're accustomed (as I am, in my early learning stages of programming) to building in-line scripts that do exactly what you need, and you'll try to figure it out again if you ever need that operation again ... well, you're not used to this kind of internal structure to your code, because it's more complicated to build and it's not as intuitive to read. \n\n But that's a script that probably can't have its functions called externally, because if it did it would immediately start calculating and assigning variables. And chances are if you're trying to re-use a function, your new script is related closely enough to the old one that there will be conflicting variables. \n\n In splitting out independent functions, you gain the ability to re-use your previous work by calling them into another script. For example, \"example.py\" might import \"xy.py\" and call  x() , making use of the 'x' function from \"xy.py\". (Maybe it's capitalizing the third word of a given text string; creating a NumPy array from a list of numbers and squaring them; or detrending a 3D surface. The possibilities are limitless.) \n\n (As an aside,  this question  contains an answer by @kindall that finally helped me to understand - the why, not the how. Unfortunately it's been marked as a duplicate of  this one , which I think is a mistake.) \n    ", "date_posted": "2018-05-23 22:29:32Z", "upvote": "\r\n            90\r\n        ", "accepted": "No", "user": {"stack_user_id": "6833793", "name": "joechoj", "reputation_score": "1,259"}, "answer_comments": []}, {"stack_answer_id": "60017299", "answer_content": "\r\n The code under  if __name__ == '__main__':  will  only  be executed if the module is invoked as a script. \n As an example, consider the following module  my_test_module.py : \n # my_test_module.py\n\nprint('This is going to be printed out, no matter what')\n\nif __name__ == '__main__':\n    print('This is going to be printed out, only if user invokes the module as a script')\n \n \n First possibility: Import  my_test_module.py  in another module \n # main.py\n\nimport my_test_module\n\nif __name__ == '__main__':\n    print('Hello from main.py')\n \n Now if you invoke  main.py : \n python main.py\n\n>> 'This is going to be printed out, no matter what'\n>> 'Hello from main.py'\n \n Note that only the top-level  print()  statement in  my_test_module  is executed. \n \n Second possibility: Invoke  my_test_module.py  as a script \n Now if you run  my_test_module.py  as a Python script, both  print()  statements will be executed: \n python my_test_module.py\n\n>>> 'This is going to be printed out, no matter what'\n>>> 'This is going to be printed out, only if user invokes the module as a script'\n \n \n For a more comprehensive explanation, you can read  What does  if __name__ == '__main__'  do in Python . \n    ", "date_posted": "2022-05-13 14:31:40Z", "upvote": "\r\n            74\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "15789709", "answer_content": "\r\n When there are certain statements in our module ( M.py ) we want to be executed when it'll be running as main (not imported), we can place those statements (test-cases, print statements) under this  if  block. \n\n As by default (when module running as main, not imported) the  __name__  variable is set to  \"__main__\" , and when it'll be imported the  __name__  variable will get a different value, most probably the name of the module ( 'M' ).\nThis is helpful in running different variants of a modules together, and separating their specific input & output statements and also if there are any test-cases. \n\n In short , use this ' if __name__ == \"main\"  ' block to prevent (certain) code from being run when the module is imported. \n    ", "date_posted": "2018-05-23 22:07:29Z", "upvote": "\r\n            67\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "15789709", "stack_answer_comment_id": "122272582", "comment_content": "+1  Sometimes, it's good to just get a short one-liner like mentioned in this answer: \"In short, use this 'if ", "user_id": null}]}, {"stack_answer_id": "40057173", "answer_content": "\r\n Put simply,  __name__  is a variable defined for each script that defines whether the script is being run as the main module or it is being run as an imported module. \n\n So if we have two scripts; \n\n #script1.py\nprint \"Script 1's name: {}\".format(__name__)\n \n\n and \n\n #script2.py\nimport script1\nprint \"Script 2's name: {}\".format(__name__)\n \n\n The output from executing script1 is \n\n Script 1's name: __main__\n \n\n And the output from executing script2 is: \n\n Script1's name is script1\nScript 2's name: __main__\n \n\n As you can see,  __name__  tells us which code is the 'main' module.\nThis is great, because you can just write code and not have to worry about structural issues like in C/C++, where, if a file does not implement a 'main' function then it cannot be compiled as an executable and if it does, it cannot then be used as a library. \n\n Say you write a Python script that does something great and you implement a boatload of functions that are useful for other purposes. If I want to use them I can just import your script and use them without executing your program (given that your code only executes within the   if __name__ == \"__main__\":  context). Whereas in C/C++ you would have to portion out those pieces into a separate module that then includes the file. Picture the situation below; \n\n \n\n The arrows are import links. For three modules each trying to include the previous modules code there are six files (nine, counting the implementation files) and five links. This makes it difficult to include other code into a C project unless it is compiled specifically as a library. Now picture it for Python: \n\n \n\n You write a module, and if someone wants to use your code they just import it and the  __name__  variable can help to separate the executable portion of the program from the library part. \n    ", "date_posted": "2018-05-23 22:28:19Z", "upvote": "\r\n            62\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "40057173", "stack_answer_comment_id": "83396232", "comment_content": "The C/C++ illustration is wrong: 3 times the same unit name (", "user_id": null}]}, {"stack_answer_id": "28051929", "answer_content": "\r\n Let's look at the answer in a more abstract way: \n\n Suppose we have this code in  x.py : \n\n ...\n<Block A>\nif __name__ == '__main__':\n    <Block B>\n...\n \n\n Blocks A and B are run when we are running  x.py . \n\n But just block A (and not B) is run when we are running another module,  y.py  for example, in which  x.py  is imported and the code is run from there (like when a function in  x.py  is called from  y.py ). \n    ", "date_posted": "2020-05-27 10:50:24Z", "upvote": "\r\n            55\r\n        ", "accepted": "No", "user": {"stack_user_id": "2115079", "name": "kubuntu", "reputation_score": "2,525"}, "answer_comments": []}, {"stack_answer_id": "51011507", "answer_content": "\r\n To be short, you need to know several points: \n \n import a  action actually runs all that can be run in  a.py , meaning each line in  a.py \n \n Because of point 1, you may not want everything to be run in  a.py  when importing it \n \n To solve the problem in point 2, Python allows you to use a condition check \n \n __name__  is an implicit variable in all  .py  modules: \n \n \n \n when  a.py  is  import ed, the value of  __name__  of  a.py  module is set to its file name \" a \" \n when  a.py  is run directly using \" python a.py \", the value of  __name__  is set to a string  __main__ \n \n \n Based on the mechanism how Python sets the variable  __name__  for each module, do you know how to achieve point 3? The answer is fairly easy, right? Use an  if  condition:  if __name__ == \"__main__\": // do A \n \n \n then  python a.py  will run the part  // do A \n and  import a  will skip the part  // do A \n \n \n You can even put if  __name__ == \"a\"  depending on your functional need, but rarely do \n \n The important thing that Python is special at is point 4! The rest is just basic logic. \n I've been reading so much throughout the answers on this page. I would say, if you know the thing, for sure you will understand those answers, otherwise, you are still confused. \n    ", "date_posted": "2022-01-13 22:32:49Z", "upvote": "\r\n            54\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": [{"stack_answer_id": "51011507", "stack_answer_comment_id": "97383066", "comment_content": "Yes, point 1 is vital to understand. From that, the need for this mechanism become clear.", "user_id": null}]}, {"stack_answer_id": "20517795", "answer_content": "\r\n When you run Python interactively the local  __name__  variable is assigned a value of  __main__ . Likewise, when you execute a Python module from the command line, rather than importing it into another module, its  __name__  attribute is assigned a value of  __main__ , rather than the actual name of the module. In this way, modules can look at their own  __name__  value to determine for themselves how they are being used, whether as support for another program or as the main application executed from the command line. Thus, the following idiom is quite common in Python modules: \n\n if __name__ == '__main__':\n    # Do something appropriate here, like calling a\n    # main() function defined elsewhere in this module.\n    main()\nelse:\n    # Do nothing. This module has been imported by another\n    # module that wants to make use of the functions,\n    # classes and other useful bits it has defined.\n \n    ", "date_posted": "2013-12-11 11:23:53Z", "upvote": "\r\n            44\r\n        ", "accepted": "No", "user": {"stack_user_id": "1803858", "name": "Zain", "reputation_score": "1,186"}, "answer_comments": []}, {"stack_answer_id": "45824951", "answer_content": "\r\n Consider: \n if __name__ == \"__main__\":\n    main()\n \n It checks if the  __name__  attribute of the Python script is  \"__main__\" . In other words, if the program itself is executed, the attribute will be  __main__ , so the program will be executed (in this case the  main()  function). \n However, if your Python script is used by a module, any code outside of the  if  statement will be executed, so  if __name__ == \"__main__\"  is used just to check if the program is used as a module or not, and therefore decides whether to run the code. \n    ", "date_posted": "2022-05-20 08:24:03Z", "upvote": "\r\n            42\r\n        ", "accepted": "No", "user": {"stack_user_id": "874188", "name": "tripleee", "reputation_score": "162k"}, "answer_comments": []}, {"stack_answer_id": "49637838", "answer_content": "\r\n Before explaining anything about  if __name__ == '__main__'  it is important to understand what  __name__  is and what it does. \n What is  __name__ ? \n __name__  is a  DunderAlias  - can be thought of as a global variable (accessible from modules) and works in a similar way to  global . \n It is a string (global as mentioned above) as indicated by  type(__name__)  (yielding  <class 'str'> ), and is an inbuilt standard for both  Python 3  and  Python 2  versions. \n Where \n It can not only be used in scripts but can also be found in both the interpreter and modules/packages. \n Interpreter: \n >>> print(__name__)\n__main__\n>>>\n \n Script: \n test_file.py : \n print(__name__)\n \n Resulting in  __main__ \n Module or package: \n somefile.py: \n def somefunction():\n    print(__name__)\n \n test_file.py: \n import somefile\nsomefile.somefunction()\n \n Resulting in  somefile \n Notice that when used in a package or module,  __name__  takes the name of the file.  The path of the actual module or package path is not given, but has its own DunderAlias  __file__ , that allows for this. \n You should see that, where  __name__ , where it is the main file (or program) will  always  return  __main__ , and if it is a module/package, or anything that is running off some other Python script, will return the name of the file where it has originated from. \n Practice \n Being a variable means that it's value  can  be overwritten (\"can\" does not mean \"should\"), overwriting the value of  __name__  will result in a lack of readability.  So do not do it, for any reason.  If you need a variable define a new variable. \n It is always assumed that the value of  __name__  to be  __main__  or the name of the file.  Once again changing this default value will cause more confusion that it will do good, causing problems further down the line. \n Example: \n >>> __name__ = 'Horrify' # Change default from __main__\n>>> if __name__ == 'Horrify': print(__name__)\n...\n>>> else: print('Not Horrify')\n...\nHorrify\n>>>\n \n It is considered good practice in general to include the  if __name__ == '__main__'  in scripts. \n Now to answer  if __name__ == '__main__' : \n Now we know the behaviour of  __name__  things become clearer: \n An  if  is a flow control statement that contains the block of code will execute if the value given is true. We have seen that  __name__  can take either\n __main__  or the file name it has been imported from. \n This means that if  __name__  is equal to  __main__  then the file must be the main file and must actually be running (or it is the interpreter), not a module or package imported into the script. \n If indeed  __name__  does take the value of  __main__  then whatever is in that block of code will execute. \n This tells us that if the file running is the main file (or you are running from the interpreter directly) then that condition must execute.  If it is a package then it should not, and the value will not be  __main__ . \n Modules \n __name__  can also be used in modules to define the name of a module \n Variants \n It is also possible to do other, less common but useful things with  __name__ , some I will show here: \n Executing only if the file is a module or package \n if __name__ != '__main__':\n    # Do some useful things \n \n Running one condition if the file is the main one and another if it is not \n if __name__ == '__main__':\n    # Execute something\nelse:\n    # Do some useful things\n \n You can also use it to provide runnable help functions/utilities on packages and modules without the elaborate use of libraries. \n It also allows modules to be run from the command line as main scripts, which can be also very useful. \n    ", "date_posted": "2022-03-26 13:31:36Z", "upvote": "\r\n            40\r\n        ", "accepted": "No", "user": {"stack_user_id": "874188", "name": "tripleee", "reputation_score": "162k"}, "answer_comments": []}, {"stack_answer_id": "40881975", "answer_content": "\r\n I think it's best to break the answer in depth and in simple words: \n\n __name__ : Every module in Python has a special attribute called  __name__ .\nIt is a built-in variable that returns the name of the module. \n\n __main__ : Like other programming languages, Python too has an execution entry point, i.e., main.  '__main__'   is the name of the scope in which top-level code executes . Basically you have two ways of using a Python module: Run it directly as a script, or import it. When a module is run as a script, its  __name__  is set to  __main__ . \n\n Thus, the value of the  __name__  attribute is set to  __main__  when the module is run as the main program. Otherwise the value of  __name__   is set to contain the name of the module. \n    ", "date_posted": "2018-05-23 22:30:36Z", "upvote": "\r\n            35\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "14502904", "answer_content": "\r\n It is a special for when a Python file is called from the command line. This is typically used to call a \"main()\" function or execute other appropriate startup code, like commandline arguments handling for instance. \n It could be written in several ways. Another is: \n def some_function_for_instance_main():\n    dosomething()\n\n\n__name__ == '__main__' and some_function_for_instance_main()\n \n I am not saying you should use this in production code, but it serves to illustrate that there is nothing \"magical\" about  if __name__ == '__main__' . \n It just a convention for invoking a main function in Python files. \n    ", "date_posted": "2021-06-15 15:46:05Z", "upvote": "\r\n            35\r\n        ", "accepted": "No", "user": {"stack_user_id": "193892", "name": "Prof. Falken", "reputation_score": "23.5k"}, "answer_comments": [{"stack_answer_id": "14502904", "stack_answer_comment_id": "31163627", "comment_content": "I would consider this bad form as you're 1) relying on side effects and 2) abusing ", "user_id": null}, {"stack_answer_id": "14502904", "stack_answer_comment_id": "50673315", "comment_content": "Leaving aside the question of whether exploiting the short-circuit behaviour of boolean operators as a flow control mechanism is bad style or not, the bigger problem is that this ", "user_id": null}, {"stack_answer_id": "14502904", "stack_answer_comment_id": "120744784", "comment_content": "@jpmc26 Anyone with a background in Perl or Javascript is totally comfortable with this idiom, using ", "user_id": null}, {"stack_answer_id": "14502904", "stack_answer_comment_id": "120747922", "comment_content": "@JohnHenckel This is not Perl or JavaScript. This is not a Python idiom. It is considered bad form to use a function with side effects in the middle of a Boolean statement in Python. Particularly in this case, there is absolutely no benefit to using ", "user_id": null}, {"stack_answer_id": "14502904", "stack_answer_comment_id": "120989730", "comment_content": "@jpmc26 I'm trying to find an authoritative source that agrees with you. Is this mentioned somewhere?  For example in PEP8 does it say that we should avoid using ", "user_id": null}]}, {"stack_answer_id": "33916552", "answer_content": "\r\n There are a number of variables that the system (Python interpreter) provides for source files (modules).  You can get their values anytime you want, so, let us focus on the  __name__  variable/attribute: \n\n When Python loads a source code file, it executes all of the code found in it. (Note that it doesn't call all of the methods and functions defined in the file, but it does define them.) \n\n Before the interpreter executes the source code file though, it defines a few special variables for that file;  __name__  is one of those special variables that Python automatically defines for each source code file. \n\n If Python is loading this source code file as the main program (i.e. the file you run), then it sets the special  __name__  variable for this file to have a value  \"__main__\" . \n\n If this is being imported from another module,  __name__  will be set to that module's name. \n\n So, in your example in part: \n\n if __name__ == \"__main__\":\n   lock = thread.allocate_lock()\n   thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))\n   thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))\n \n\n means that the code block: \n\n lock = thread.allocate_lock()\nthread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))\nthread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))\n \n\n will be executed only when you run the module directly; the code block will not execute if another module is calling/importing it because the value of  __name__  will not equal to \" main \" in that particular instance. \n\n Hope this helps out. \n    ", "date_posted": "2016-07-20 09:30:24Z", "upvote": "\r\n            27\r\n        ", "accepted": "No", "user": {"stack_user_id": "5417963", "name": "codewizard", "reputation_score": "356"}, "answer_comments": [{"stack_answer_id": "33916552", "stack_answer_comment_id": "124905627", "comment_content": "Hi, you are one of  the few that addressed the question referring to the multithreaded aspect. May I ask you this, what happens if I have code outside of \"main\" and not encapsulated inside a function? Will this code get executed again and again by every new thread started from main?", "user_id": null}]}, {"stack_answer_id": "36820845", "answer_content": "\r\n if __name__ == \"__main__\":  is basically the top-level script environment, and it specifies the interpreter that ('I have the highest priority to be executed first'). \n\n '__main__'  is the name of the scope in which top-level code executes. A module\u2019s  __name__  is set equal to  '__main__'  when read from standard input, a script, or from an interactive prompt. \n\n if __name__ == \"__main__\":\n    # Execute only if run as a script\n    main()\n \n    ", "date_posted": "2018-05-23 22:14:07Z", "upvote": "\r\n            25\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "37965772", "answer_content": "\r\n Consider: \n\n print __name__\n \n\n The output for the above is  __main__ . \n\n if __name__ == \"__main__\":\n  print \"direct method\"\n \n\n The above statement is true and prints  \"direct method\" . Suppose if they imported this class in another class it doesn't print  \"direct method\"  because, while importing, it will set  __name__ equal to \"first model name\" . \n    ", "date_posted": "2019-02-06 23:16:06Z", "upvote": "\r\n            24\r\n        ", "accepted": "No", "user": {"stack_user_id": "4217744", "name": "simhumileco", "reputation_score": "28.1k"}, "answer_comments": []}, {"stack_answer_id": "42773985", "answer_content": "\r\n \n   You can make the file usable as a  script  as well as an  importable module . \n \n\n fibo.py (a module named  fibo ) \n\n # Other modules can IMPORT this MODULE to use the function fib\ndef fib(n):    # write Fibonacci series up to n\n    a, b = 0, 1\n    while b < n:\n        print(b, end=' ')\n        a, b = b, a+b\n    print()\n\n# This allows the file to be used as a SCRIPT\nif __name__ == \"__main__\":\n    import sys\n    fib(int(sys.argv[1]))\n \n\n Reference:  https://docs.python.org/3.5/tutorial/modules.html \n    ", "date_posted": "2017-03-13 21:44:26Z", "upvote": "\r\n            20\r\n        ", "accepted": "No", "user": {"stack_user_id": "3927314", "name": "kgf3JfUtW", "reputation_score": "12k"}, "answer_comments": []}, {"stack_answer_id": "46371154", "answer_content": "\r\n The reason for \n\n if __name__ == \"__main__\":\n    main()\n \n\n is primarily to avoid the  import lock  problems that would arise from  having code directly imported . You want  main()  to run if your file was directly invoked (that's the  __name__ == \"__main__\"  case), but if your code was imported then the importer has to enter your code from the true main module to avoid import lock problems. \n\n A side-effect is that you automatically sign on to a methodology that supports multiple entry points. You can run your program using  main()  as the entry point,  but you don't have to . While  setup.py  expects  main() , other tools use alternate entry points. For example, to run your file as a  gunicorn  process, you define an  app()  function instead of a  main() . Just as with  setup.py ,  gunicorn  imports your code so you don't want it do do anything while it's being imported (because of the import lock issue). \n    ", "date_posted": "2018-04-18 21:05:59Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "5896591", "name": "personal_cloud", "reputation_score": "3,584"}, "answer_comments": []}, {"stack_answer_id": "56558865", "answer_content": "\r\n Every module in Python has an attribute called  __name__ . The value of  __name__   attribute is   __main__  when the module is run directly, like  python my_module.py . Otherwise (like when you say  import my_module ) the value of  __name__   is the name of the module. \n Small example to explain in short. \n Script  test.py \n apple = 42\n\ndef hello_world():\n    print(\"I am inside hello_world\")\n\nif __name__ == \"__main__\":\n    print(\"Value of __name__ is: \", __name__)\n    print(\"Going to call hello_world\")\n    hello_world()\n \n We can execute this directly as \n python test.py\n \n Output \n Value of __name__ is: __main__\nGoing to call hello_world\nI am inside hello_world\n \n Now suppose we call the above script from another script: \n Script  external_calling.py \n import test\n\nprint(test.apple)\ntest.hello_world()\n\nprint(test.__name__)\n \n When you execute this, \n python external_calling.py\n \n Output \n 42\nI am inside hello_world\ntest\n \n So, the above is self-explanatory that when you call  test  from another script, if loop  __name__  in  test.py  will not execute. \n    ", "date_posted": "2022-01-13 22:45:08Z", "upvote": "\r\n            18\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "69778466", "answer_content": "\r\n If you are a beginner, probably the only answer you need right now is that  this code is unnecessary  for a simple script. It is only useful if you want to be able to  import  your script (or  unpickle  etc; see the other answers here for some other non-beginner scenarios). \n In slightly different words, the  if __name__  guard is a mechanism for hiding code from other code. If you don't have a specific reason to hide something, don't: If you don't need to hide some code from  import , don't put it behind this guard, and if you do, hide as little as possible. \n In slightly more detail, let's say you have a simple script  fib.py  (adapted from  this answer ): \n # XXX FIXME: useless (see below)\nif __name__ == \"__main__\":\n    n = int(input('Write a number: '))\n    a, b = 0, 1\n    while b < n:\n        a, b = b, a+b\n    print('Fibonacci number %i: %i' % (n, b))\n \n Now, if you simply run  python fib.py  it works fine. But  __name__  will always be  \"__main__\"  in this scenario, so the condition is actually unnecessary. The script could be simplified to just \n n = int(input('Write a number: '))\na, b = 0, 1\nwhile b < n:\n    a, b = b, a+b\nprint('Fibonacci number %i: %i' % (n, b))\n \n Now, you can't  import fib  with the new version, but if you didn't plan to do that in the first place, this version is actually better, because it's simpler and clearer. \n If you  do  want to be able to  import fib , the first version is useless, too, because the useful code is in a section which will not run when you  import  this file (in which case  __name__  will not be  \"__main__\" ). The proper design in that case would be to refactor the code so that the useful parts are in a function you can run when you want to after you have  import ed it. \n def main():\n    n = int(input('Write a number: '))\n    a, b = 0, 1\n    while b < n:\n        a, b = b, a+b\n    print('Fibonacci number %i: %i' % (n, b))\n\nif __name__ == \"__main__\":\n    main()\n \n Now, if you  import fib , the call to  main()  will not be executed; but when you run  python fib.py , it will. \n Actually, a better design still would be to isolate the reusable part (the actual calculation) from the user-visible input/output: \n def fibn(n: int) -> int:\n    a, b = 0, 1\n    while b < n:\n        a, b = b, a+b\n    return b\n\ndef main() -> None:\n    n = int(input('Write a number: '))\n    print('Fibonacci number %i: %i' % (n, fibn(n)))\n\nif __name__ == \"__main__\":\n    main()\n \n Now, you can  from fib import fibn  and call the  fibn()  function from the code which performs this  import . \n (I called the function  fibn()  just to make it clearer what is what in this example. In real life, you might call it  fib()  and do  from fib import fib .) \n Similarly, you could  import  and call the  main  function if you wanted to reuse it. \n Returning to the code in the question, I would similarly move the code from the  if  into a function as well, so that callers can invoke that function if they want to. \n def main():\n    lock = thread.allocate_lock()\n    thread.start_new_thread(myfunction, (\"Thread #: 1\", 2, lock))\n    thread.start_new_thread(myfunction, (\"Thread #: 2\", 2, lock))\n\nif __name__ == \"__main__\":\n    main()\n \n This changes the scope of the  lock  variable; if the surrounding code needs access to it, you will need to make it  global  (or, perhaps, better, refactor  main  to  return lock , and have the caller capture the value in a local variable of its own). \n (Unlike in languages like C, the name  main  has no specific meaning to Python; but it's a common convention to use it as the name of the thing which will be run. You still have to actually explicitly call it, like  main() , unlike in C.) \n    ", "date_posted": "2022-05-20 07:37:58Z", "upvote": "\r\n            17\r\n        ", "accepted": "No", "user": {"stack_user_id": "874188", "name": "tripleee", "reputation_score": "162k"}, "answer_comments": [{"stack_answer_id": "69778466", "stack_answer_comment_id": "123342064", "comment_content": "I kept the example code simple to avoid distractions; in real life, you need to cope with ", "user_id": null}, {"stack_answer_id": "69778466", "stack_answer_comment_id": "123342070", "comment_content": "The ", "user_id": null}, {"stack_answer_id": "69778466", "stack_answer_comment_id": "123342326", "comment_content": "The convention for the ordering of Fibonacci numbers is not entirely set in stone. The usual convention is that the first number is 0, but mathematically this is conventionally ", "user_id": null}]}, {"stack_answer_id": "52685565", "answer_content": "\r\n This answer is for Java programmers learning Python.\nEvery Java file typically contains one public class. You can use that class in two ways:  \n\n \n Call the class from other files. You just have to import it in the calling program. \n Run the class stand alone, for testing purposes.  \n \n\n For the latter case, the class should contain a public static void main() method. In Python this purpose is served by the globally defined label  '__main__' . \n    ", "date_posted": "2018-10-18 03:09:32Z", "upvote": "\r\n            15\r\n        ", "accepted": "No", "user": {"stack_user_id": "6622587", "name": "eyllanesc", "reputation_score": "225k"}, "answer_comments": []}, {"stack_answer_id": "64488013", "answer_content": "\r\n In simple words: \n The code you see under  if __name__ == \"__main__\":  will only get called upon when your Python file is executed as  python example1.py \n However, if you wish to import your Python file  example1.py  as a module to work with another Python file, say  example2.py , the code under  if __name__ == \"__main__\":  will not run or take any effect. \n    ", "date_posted": "2022-07-21 13:58:56Z", "upvote": "\r\n            15\r\n        ", "accepted": "No", "user": {"stack_user_id": "874188", "name": "tripleee", "reputation_score": "162k"}, "answer_comments": []}, {"stack_answer_id": "50927616", "answer_content": "\r\n If this .py file are imported by other .py files, the code under the  if  statement will not be executed. \n If this .py are run by  python this_py.py  under shell, or double clicked in Windows. the code under the  if  statement will be executed. \n It is usually written for testing. \n    ", "date_posted": "2022-05-20 08:22:30Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "874188", "name": "tripleee", "reputation_score": "162k"}, "answer_comments": []}, {"stack_answer_id": "57276038", "answer_content": "\r\n If the Python interpreter is running a particular module then the  __name__  global variable will have the value  \"__main__\" : \n   def a():\n      print(\"a\")\n\n  def b():\n      print(\"b\")\n\n  if __name__ == \"__main__\":\n\n          print (\"you can see me\")\n          a()\n  else:\n\n          print (\"You can't see me\")\n          b()\n \n When you run this script, it prints  you can see me . \n a \n If you import this file, say A to file B, and execute the file B then  if __name__ == \"__main__\"  in file A becomes false, so it prints   You can't see me . \n b \n    ", "date_posted": "2022-01-13 22:40:32Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "63550", "name": "Peter Mortensen", "reputation_score": "30.3k"}, "answer_comments": []}, {"stack_answer_id": "49653760", "answer_content": "\r\n We see if  __name__ == '__main__':  quite often. \n It checks if a module is being imported or not. \n In other words, the code within the  if  block will be executed only when the code runs directly. Here  directly  means  not imported . \n Let's see what it does using a simple code that prints the name of the module: \n # test.py\ndef test():\n   print('test module name=%s' %(__name__))\n\nif __name__ == '__main__':\n   print('call test()')\n   test()\n \n If we run the code directly via  python test.py , the module name is  __main__ : \n call test()\ntest module name=__main__\n \n    ", "date_posted": "2022-05-20 08:23:11Z", "upvote": "\r\n            10\r\n        ", "accepted": "No", "user": {"stack_user_id": "874188", "name": "tripleee", "reputation_score": "162k"}, "answer_comments": []}, {"stack_answer_id": "61458664", "answer_content": "\r\n Every module in Python has a special attribute called  __name__ . The value of the  __name__   attribute is set to  '__main__'  when the module is executed as the main program (e.g., running  python foo.py ). \n Otherwise, the value of  __name__  is set to the name of the module that it was called from. \n    ", "date_posted": "2022-03-26 13:22:00Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "874188", "name": "tripleee", "reputation_score": "162k"}, "answer_comments": [{"stack_answer_id": "61458664", "stack_answer_comment_id": "125030782", "comment_content": "Re ", "user_id": null}]}], "user": {"stack_user_id": "51518", "name": "Devoted", "reputation_score": "99.1k"}, "question_comments": [{"stack_question_id": "419163", "stack_question_comment_id": "118285977", "comment_content": "Just for the record - what is \"", "user_id": null}, {"stack_question_id": "419163", "stack_question_comment_id": "128699165", "comment_content": "For duplicate closers: if you are trying to tell someone to use this idiom to avoid problems with code running when a module is imported, don't use this - use ", "user_id": null}]},
{"stack_question_id": "36901", "question_title": "What does ** (double star/asterisk) and * (star/asterisk) do for parameters?", "question_content": "\r\n                What do *args and **kwargs mean?\ndef foo(x, y, *args):\ndef bar(x, y, **kwargs):\r\n", "question_url": "/questions/36901/what-does-double-star-asterisk-and-star-asterisk-do-for-parameters", "date_posted": "Aug 31, 2008 at 15:04", "upvote": "3", "view": "1", "tags": ["python", "syntax", "parameter-passing", "variadic-functions", "argument-unpacking"], "answers_count": "2", "answers": [{"stack_answer_id": "36908", "answer_content": "\r\n The  *args  and  **kwargs  is a common idiom to allow arbitrary number of arguments to functions as described in the section  more on defining functions  in the Python documentation. \n The  *args  will give you all function parameters  as a tuple : \n def foo(*args):\n    for a in args:\n        print(a)        \n\nfoo(1)\n# 1\n\nfoo(1,2,3)\n# 1\n# 2\n# 3\n \n The  **kwargs  will give you all\n keyword arguments  except for those corresponding to a formal parameter as a dictionary. \n def bar(**kwargs):\n    for a in kwargs:\n        print(a, kwargs[a])  \n\nbar(name='one', age=27)\n# name one\n# age 27\n \n Both idioms can be mixed with normal arguments to allow a set of fixed and some variable arguments: \n def foo(kind, *args, **kwargs):\n   pass\n \n It is also possible to use this the other way around: \n def foo(a, b, c):\n    print(a, b, c)\n\nobj = {'b':10, 'c':'lee'}\n\nfoo(100,**obj)\n# 100 10 lee\n \n Another usage of the  *l  idiom is to  unpack argument lists  when calling a function. \n def foo(bar, lee):\n    print(bar, lee)\n\nl = [1,2]\n\nfoo(*l)\n# 1 2\n \n In Python 3 it is possible to use  *l  on the left side of an assignment ( Extended Iterable Unpacking ), though it gives a list instead of a tuple in this context: \n first, *rest = [1,2,3,4]\nfirst, *l, last = [1,2,3,4]\n \n Also Python 3 adds new semantic (refer  PEP 3102 ): \n def func(arg1, arg2, arg3, *, kwarg1, kwarg2):\n    pass\n \n For example the following works in python 3 but not python 2: \n >>> x = [1, 2]\n>>> [*x]\n[1, 2]\n>>> [*x, 3, 4]\n[1, 2, 3, 4]\n\n>>> x = {1:1, 2:2}\n>>> x\n{1: 1, 2: 2}\n>>> {**x, 3:3, 4:4}\n{1: 1, 2: 2, 3: 3, 4: 4}\n \n Such function accepts only 3 positional arguments, and everything after  *  can only be passed as keyword arguments. \n Note: \n \n A Python  dict , semantically used for keyword argument passing, are arbitrarily ordered. However, in Python 3.6, keyword arguments are guaranteed to remember insertion order. \n \"The order of elements in  **kwargs  now corresponds to the order in which keyword arguments were passed to the function.\" -  What\u2019s New In Python 3.6 \n In fact, all dicts in CPython 3.6 will remember insertion order as an implementation detail, this becomes standard in Python 3.7. \n \n    ", "date_posted": "2022-05-12 20:32:27Z", "upvote": "\r\n            2959\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "497719", "name": "voxobscuro", "reputation_score": "2,042"}, "answer_comments": []}, {"stack_answer_id": "36926", "answer_content": "\r\n It's also worth noting that you can use  *  and  **  when calling functions as well. This is a shortcut that allows you to pass multiple arguments to a function directly using either a list/tuple or a dictionary. For example, if you have the following function: \n\n def foo(x,y,z):\n    print(\"x=\" + str(x))\n    print(\"y=\" + str(y))\n    print(\"z=\" + str(z))\n \n\n You can do things like: \n\n >>> mylist = [1,2,3]\n>>> foo(*mylist)\nx=1\ny=2\nz=3\n\n>>> mydict = {'x':1,'y':2,'z':3}\n>>> foo(**mydict)\nx=1\ny=2\nz=3\n\n>>> mytuple = (1, 2, 3)\n>>> foo(*mytuple)\nx=1\ny=2\nz=3\n \n\n Note: The keys in  mydict  have to be named exactly like the parameters of function  foo . Otherwise it will throw a  TypeError : \n\n >>> mydict = {'x':1,'y':2,'z':3,'badnews':9}\n>>> foo(**mydict)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: foo() got an unexpected keyword argument 'badnews'\n \n    ", "date_posted": "2018-03-07 01:53:17Z", "upvote": "\r\n            774\r\n        ", "accepted": "No", "user": {"stack_user_id": "2601671", "name": "Trenton", "reputation_score": "11.3k"}, "answer_comments": []}, {"stack_answer_id": "36911", "answer_content": "\r\n The single * means that there can be any number of extra positional arguments.  foo()  can be invoked like  foo(1,2,3,4,5) . In the body of foo() param2 is a sequence containing 2-5. \n\n The double ** means there can be any number of extra named parameters.  bar()  can be invoked like  bar(1, a=2, b=3) . In the body of bar() param2 is a dictionary containing {'a':2, 'b':3 } \n\n With the following code: \n\n def foo(param1, *param2):\n    print(param1)\n    print(param2)\n\ndef bar(param1, **param2):\n    print(param1)\n    print(param2)\n\nfoo(1,2,3,4,5)\nbar(1,a=2,b=3)\n \n\n the output is \n\n 1\n(2, 3, 4, 5)\n1\n{'a': 2, 'b': 3}\n \n    ", "date_posted": "2018-12-01 05:59:46Z", "upvote": "\r\n            209\r\n        ", "accepted": "No", "user": {"stack_user_id": "-1", "name": "Community", "reputation_score": "1"}, "answer_comments": []}, {"stack_answer_id": "26365795", "answer_content": "\r\n \n What does  **  (double star) and  *  (star) do for parameters? \n \n They allow for  functions to be defined to accept  and for  users to pass  any number of arguments, positional ( * ) and keyword ( ** ). \n Defining Functions \n *args  allows for any number of optional positional arguments (parameters), which will be assigned to a tuple named  args . \n **kwargs  allows for any number of optional keyword arguments (parameters), which will be in a dict named  kwargs . \n You can (and should) choose any appropriate name, but if the intention is for the arguments to be of non-specific semantics,  args  and  kwargs  are standard names. \n Expansion, Passing any number of arguments \n You can also use  *args  and  **kwargs  to pass in parameters from lists (or any iterable) and dicts (or any mapping), respectively. \n The function recieving the parameters does not have to know that they are being expanded. \n For example, Python 2's xrange does not explicitly expect  *args , but since it takes 3 integers as arguments: \n >>> x = xrange(3) # create our *args - an iterable of 3 integers\n>>> xrange(*x)    # expand here\nxrange(0, 2, 2)\n \n As another example, we can use dict expansion in  str.format : \n >>> foo = 'FOO'\n>>> bar = 'BAR'\n>>> 'this is foo, {foo} and bar, {bar}'.format(**locals())\n'this is foo, FOO and bar, BAR'\n \n New in Python 3: Defining functions with keyword only arguments \n You can have  keyword only arguments  after the  *args  - for example, here,  kwarg2  must be given as a keyword argument - not positionally: \n def foo(arg, kwarg=None, *args, kwarg2=None, **kwargs): \n    return arg, kwarg, args, kwarg2, kwargs\n \n Usage: \n >>> foo(1,2,3,4,5,kwarg2='kwarg2', bar='bar', baz='baz')\n(1, 2, (3, 4, 5), 'kwarg2', {'bar': 'bar', 'baz': 'baz'})\n \n Also,  *  can be used by itself  to indicate that keyword only arguments follow, without allowing for unlimited positional arguments. \n def foo(arg, kwarg=None, *, kwarg2=None, **kwargs): \n    return arg, kwarg, kwarg2, kwargs\n \n Here,  kwarg2  again must be an explicitly named, keyword argument: \n >>> foo(1,2,kwarg2='kwarg2', foo='foo', bar='bar')\n(1, 2, 'kwarg2', {'foo': 'foo', 'bar': 'bar'})\n \n And we can no longer accept unlimited positional arguments because we don't have  *args* : \n >>> foo(1,2,3,4,5, kwarg2='kwarg2', foo='foo', bar='bar')\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: foo() takes from 1 to 2 positional arguments \n    but 5 positional arguments (and 1 keyword-only argument) were given\n \n Again, more simply, here we require  kwarg  to be given by name, not positionally: \n def bar(*, kwarg=None): \n    return kwarg\n \n In this example, we see that if we try to pass  kwarg  positionally, we get an error: \n >>> bar('kwarg')\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: bar() takes 0 positional arguments but 1 was given\n \n We must explicitly pass the  kwarg  parameter as a keyword argument. \n >>> bar(kwarg='kwarg')\n'kwarg'\n \n Python 2 compatible demos \n *args  (typically said \"star-args\") and  **kwargs  (stars can be implied by saying \"kwargs\", but be explicit with \"double-star kwargs\") are common idioms of Python for using the  *  and  **  notation. These specific variable names aren't required (e.g. you could use  *foos  and  **bars ), but a departure from convention is likely to enrage your fellow Python coders. \n We typically use these when we don't know what our function is going to receive or how many arguments we may be passing, and sometimes even when naming every variable separately would get very messy and redundant (but this is a case where usually explicit is better than implicit). \n Example 1 \n The following function describes how they can be used, and demonstrates behavior. Note the named  b  argument will be consumed by the second positional argument before : \n def foo(a, b=10, *args, **kwargs):\n    '''\n    this function takes required argument a, not required keyword argument b\n    and any number of unknown positional arguments and keyword arguments after\n    '''\n    print('a is a required argument, and its value is {0}'.format(a))\n    print('b not required, its default value is 10, actual value: {0}'.format(b))\n    # we can inspect the unknown arguments we were passed:\n    #  - args:\n    print('args is of type {0} and length {1}'.format(type(args), len(args)))\n    for arg in args:\n        print('unknown arg: {0}'.format(arg))\n    #  - kwargs:\n    print('kwargs is of type {0} and length {1}'.format(type(kwargs),\n                                                        len(kwargs)))\n    for kw, arg in kwargs.items():\n        print('unknown kwarg - kw: {0}, arg: {1}'.format(kw, arg))\n    # But we don't have to know anything about them \n    # to pass them to other functions.\n    print('Args or kwargs can be passed without knowing what they are.')\n    # max can take two or more positional args: max(a, b, c...)\n    print('e.g. max(a, b, *args) \\n{0}'.format(\n      max(a, b, *args))) \n    kweg = 'dict({0})'.format( # named args same as unknown kwargs\n      ', '.join('{k}={v}'.format(k=k, v=v) \n                             for k, v in sorted(kwargs.items())))\n    print('e.g. dict(**kwargs) (same as {kweg}) returns: \\n{0}'.format(\n      dict(**kwargs), kweg=kweg))\n \n We can check the online help for the function's signature, with  help(foo) , which tells us \n foo(a, b=10, *args, **kwargs)\n \n Let's call this function with  foo(1, 2, 3, 4, e=5, f=6, g=7) \n which prints: \n a is a required argument, and its value is 1\nb not required, its default value is 10, actual value: 2\nargs is of type <type 'tuple'> and length 2\nunknown arg: 3\nunknown arg: 4\nkwargs is of type <type 'dict'> and length 3\nunknown kwarg - kw: e, arg: 5\nunknown kwarg - kw: g, arg: 7\nunknown kwarg - kw: f, arg: 6\nArgs or kwargs can be passed without knowing what they are.\ne.g. max(a, b, *args) \n4\ne.g. dict(**kwargs) (same as dict(e=5, f=6, g=7)) returns: \n{'e': 5, 'g': 7, 'f': 6}\n \n Example 2 \n We can also call it using another function, into which we just provide  a : \n def bar(a):\n    b, c, d, e, f = 2, 3, 4, 5, 6\n    # dumping every local variable into foo as a keyword argument \n    # by expanding the locals dict:\n    foo(**locals()) \n \n bar(100)  prints: \n a is a required argument, and its value is 100\nb not required, its default value is 10, actual value: 2\nargs is of type <type 'tuple'> and length 0\nkwargs is of type <type 'dict'> and length 4\nunknown kwarg - kw: c, arg: 3\nunknown kwarg - kw: e, arg: 5\nunknown kwarg - kw: d, arg: 4\nunknown kwarg - kw: f, arg: 6\nArgs or kwargs can be passed without knowing what they are.\ne.g. max(a, b, *args) \n100\ne.g. dict(**kwargs) (same as dict(c=3, d=4, e=5, f=6)) returns: \n{'c': 3, 'e': 5, 'd': 4, 'f': 6}\n \n Example 3: practical usage in decorators \n OK, so maybe we're not seeing the utility yet. So imagine you have several functions with redundant code before and/or after the differentiating code. The following named functions are just pseudo-code for illustrative purposes. \n def foo(a, b, c, d=0, e=100):\n    # imagine this is much more code than a simple function call\n    preprocess() \n    differentiating_process_foo(a,b,c,d,e)\n    # imagine this is much more code than a simple function call\n    postprocess()\n\ndef bar(a, b, c=None, d=0, e=100, f=None):\n    preprocess()\n    differentiating_process_bar(a,b,c,d,e,f)\n    postprocess()\n\ndef baz(a, b, c, d, e, f):\n    ... and so on\n \n We might be able to handle this differently, but we can certainly extract the redundancy with a decorator, and so our below example demonstrates how  *args  and  **kwargs  can be very useful: \n def decorator(function):\n    '''function to wrap other functions with a pre- and postprocess'''\n    @functools.wraps(function) # applies module, name, and docstring to wrapper\n    def wrapper(*args, **kwargs):\n        # again, imagine this is complicated, but we only write it once!\n        preprocess()\n        function(*args, **kwargs)\n        postprocess()\n    return wrapper\n \n And now every wrapped function can be written much more succinctly, as we've factored out the redundancy: \n @decorator\ndef foo(a, b, c, d=0, e=100):\n    differentiating_process_foo(a,b,c,d,e)\n\n@decorator\ndef bar(a, b, c=None, d=0, e=100, f=None):\n    differentiating_process_bar(a,b,c,d,e,f)\n\n@decorator\ndef baz(a, b, c=None, d=0, e=100, f=None, g=None):\n    differentiating_process_baz(a,b,c,d,e,f, g)\n\n@decorator\ndef quux(a, b, c=None, d=0, e=100, f=None, g=None, h=None):\n    differentiating_process_quux(a,b,c,d,e,f,g,h)\n \n And by factoring out our code, which  *args  and  **kwargs  allows us to do, we reduce lines of code, improve readability and maintainability, and have sole canonical locations for the logic in our program. If we need to change any part of this structure, we have one place in which to make each change. \n    ", "date_posted": "2021-04-30 21:55:47Z", "upvote": "\r\n            193\r\n        ", "accepted": "No", "user": {"stack_user_id": "7758804", "name": "Trenton McKinney", "reputation_score": "46.5k"}, "answer_comments": []}, {"stack_answer_id": "34899056", "answer_content": "\r\n Let us first understand what are positional arguments and keyword arguments.\nBelow is an example of function definition with  Positional arguments. \n\n def test(a,b,c):\n     print(a)\n     print(b)\n     print(c)\n\ntest(1,2,3)\n#output:\n1\n2\n3\n \n\n So this is a function definition with positional arguments.\nYou can call it with keyword/named arguments as well: \n\n def test(a,b,c):\n     print(a)\n     print(b)\n     print(c)\n\ntest(a=1,b=2,c=3)\n#output:\n1\n2\n3\n \n\n Now let us study an example of function definition with  keyword arguments : \n\n def test(a=0,b=0,c=0):\n     print(a)\n     print(b)\n     print(c)\n     print('-------------------------')\n\ntest(a=1,b=2,c=3)\n#output :\n1\n2\n3\n-------------------------\n \n\n You can call this function with positional arguments as well: \n\n def test(a=0,b=0,c=0):\n    print(a)\n    print(b)\n    print(c)\n    print('-------------------------')\n\ntest(1,2,3)\n# output :\n1\n2\n3\n---------------------------------\n \n\n So we now know function definitions with positional as well as keyword arguments. \n\n Now let us study the '*' operator and '**' operator. \n\n Please note these operators can be used in 2 areas: \n\n a)  function call \n\n b)  function definition \n\n The use of '*' operator and '**' operator in  function call.   \n\n Let us get straight to an example and then discuss it. \n\n def sum(a,b):  #receive args from function calls as sum(1,2) or sum(a=1,b=2)\n    print(a+b)\n\nmy_tuple = (1,2)\nmy_list = [1,2]\nmy_dict = {'a':1,'b':2}\n\n# Let us unpack data structure of list or tuple or dict into arguments with help of '*' operator\nsum(*my_tuple)   # becomes same as sum(1,2) after unpacking my_tuple with '*'\nsum(*my_list)    # becomes same as sum(1,2) after unpacking my_list with  '*'\nsum(**my_dict)   # becomes same as sum(a=1,b=2) after unpacking by '**' \n\n# output is 3 in all three calls to sum function.\n \n\n So remember  \n\n when the '*' or '**' operator is used in a  function call  - \n\n '*' operator unpacks data structure such as a list or tuple  into arguments needed by function definition. \n\n '**' operator unpacks a dictionary into arguments needed by function definition. \n\n Now let us study the '*' operator use in  function definition .\nExample: \n\n def sum(*args): #pack the received positional args into data structure of tuple. after applying '*' - def sum((1,2,3,4))\n    sum = 0\n    for a in args:\n        sum+=a\n    print(sum)\n\nsum(1,2,3,4)  #positional args sent to function sum\n#output:\n10\n \n\n In function  definition  the '*' operator packs the received arguments into a tuple. \n\n Now let us see an example of '**' used in function definition: \n\n def sum(**args): #pack keyword args into datastructure of dict after applying '**' - def sum({a:1,b:2,c:3,d:4})\n    sum=0\n    for k,v in args.items():\n        sum+=v\n    print(sum)\n\nsum(a=1,b=2,c=3,d=4) #positional args sent to function sum\n \n\n In function  definition  The '**' operator packs the received arguments into a dictionary. \n\n So remember: \n\n In a  function call  the '*'  unpacks  data structure of tuple or list into positional or keyword arguments to be received by function definition. \n\n In a  function call  the '**'  unpacks  data structure of dictionary into positional or keyword arguments to be received by function definition. \n\n In a  function definition  the '*'  packs  positional arguments into a tuple. \n\n In a  function definition  the '**'  packs  keyword arguments into a dictionary. \n    ", "date_posted": "2016-08-06 19:53:44Z", "upvote": "\r\n            62\r\n        ", "accepted": "No", "user": {"stack_user_id": "243392", "name": "Brian Burns", "reputation_score": "18.5k"}, "answer_comments": []}, {"stack_answer_id": "47580283", "answer_content": "\r\n This table is handy for using  *  and  **  in function  construction  and function  call : \n\n             In function construction         In function call\n=======================================================================\n          |  def f(*args):                 |  def f(a, b):\n*args     |      for arg in args:          |      return a + b\n          |          print(arg)            |  args = (1, 2)\n          |  f(1, 2)                       |  f(*args)\n----------|--------------------------------|---------------------------\n          |  def f(a, b):                  |  def f(a, b):\n**kwargs  |      return a + b              |      return a + b\n          |  def g(**kwargs):              |  kwargs = dict(a=1, b=2)\n          |      return f(**kwargs)        |  f(**kwargs)\n          |  g(a=1, b=2)                   |\n-----------------------------------------------------------------------\n \n\n This really just serves to summarize Lorin Hochstein's  answer  but I find it helpful. \n\n Relatedly: uses for the star/splat operators have been  expanded  in Python 3 \n    ", "date_posted": "2020-01-09 04:19:53Z", "upvote": "\r\n            46\r\n        ", "accepted": "No", "user": {"stack_user_id": "7954504", "name": "Brad Solomon", "reputation_score": "35.3k"}, "answer_comments": [{"stack_answer_id": "47580283", "stack_answer_comment_id": "124788773", "comment_content": "Apparently \"splat\" is jargon for asterisk ", "user_id": null}]}, {"stack_answer_id": "12362812", "answer_content": "\r\n *  and  **  have special usage in the function argument list.  * \nimplies that the argument is a list and  **  implies that the argument\nis a dictionary. This allows functions to take arbitrary number of\narguments \n    ", "date_posted": "2012-09-11 10:59:30Z", "upvote": "\r\n            29\r\n        ", "accepted": "No", "user": {"stack_user_id": "1288", "name": "Bill the Lizard", "reputation_score": "389k"}, "answer_comments": []}, {"stack_answer_id": "50461663", "answer_content": "\r\n For those of you who learn by examples! \n\n \n The purpose of  *   is to give you the ability to define a function that can take an arbitrary number of arguments provided as a list (e.g.  f(*myList)  ). \n The purpose of  **  is to give you the ability to feed a function's arguments by providing a dictionary (e.g.  f(**{'x' : 1, 'y' : 2})  ). \n \n\n Let us show this by defining a function that takes two normal variables  x ,  y , and can accept more arguments as  myArgs , and can accept even more arguments as  myKW . Later, we will show how to feed  y  using  myArgDict . \n\n def f(x, y, *myArgs, **myKW):\n    print(\"# x      = {}\".format(x))\n    print(\"# y      = {}\".format(y))\n    print(\"# myArgs = {}\".format(myArgs))\n    print(\"# myKW   = {}\".format(myKW))\n    print(\"# ----------------------------------------------------------------------\")\n\n# Define a list for demonstration purposes\nmyList    = [\"Left\", \"Right\", \"Up\", \"Down\"]\n# Define a dictionary for demonstration purposes\nmyDict    = {\"Wubba\": \"lubba\", \"Dub\": \"dub\"}\n# Define a dictionary to feed y\nmyArgDict = {'y': \"Why?\", 'y0': \"Why not?\", \"q\": \"Here is a cue!\"}\n\n# The 1st elem of myList feeds y\nf(\"myEx\", *myList, **myDict)\n# x      = myEx\n# y      = Left\n# myArgs = ('Right', 'Up', 'Down')\n# myKW   = {'Wubba': 'lubba', 'Dub': 'dub'}\n# ----------------------------------------------------------------------\n\n# y is matched and fed first\n# The rest of myArgDict becomes additional arguments feeding myKW\nf(\"myEx\", **myArgDict)\n# x      = myEx\n# y      = Why?\n# myArgs = ()\n# myKW   = {'y0': 'Why not?', 'q': 'Here is a cue!'}\n# ----------------------------------------------------------------------\n\n# The rest of myArgDict becomes additional arguments feeding myArgs\nf(\"myEx\", *myArgDict)\n# x      = myEx\n# y      = y\n# myArgs = ('y0', 'q')\n# myKW   = {}\n# ----------------------------------------------------------------------\n\n# Feed extra arguments manually and append even more from my list\nf(\"myEx\", 4, 42, 420, *myList, *myDict, **myDict)\n# x      = myEx\n# y      = 4\n# myArgs = (42, 420, 'Left', 'Right', 'Up', 'Down', 'Wubba', 'Dub')\n# myKW   = {'Wubba': 'lubba', 'Dub': 'dub'}\n# ----------------------------------------------------------------------\n\n# Without the stars, the entire provided list and dict become x, and y:\nf(myList, myDict)\n# x      = ['Left', 'Right', 'Up', 'Down']\n# y      = {'Wubba': 'lubba', 'Dub': 'dub'}\n# myArgs = ()\n# myKW   = {}\n# ----------------------------------------------------------------------\n \n\n Caveats \n\n \n **  is exclusively reserved for dictionaries. \n Non-optional argument assignment happens first. \n You cannot use a non-optional argument twice. \n If applicable,  **  must come after  * , always. \n \n    ", "date_posted": "2018-08-13 19:43:14Z", "upvote": "\r\n            24\r\n        ", "accepted": "No", "user": {"stack_user_id": "7428659", "name": "Miladiouss", "reputation_score": "3,631"}, "answer_comments": []}, {"stack_answer_id": "59630576", "answer_content": "\r\n TL;DR \n\n Below are 6 different use cases for  *  and  **  in python programming: \n\n \n To accept any number of positional arguments using  *args :   def foo(*args): pass , here  foo  accepts any number of positional arguments, i. e., the following calls are valid  foo(1) ,  foo(1, 'bar') \n To accept any number of keyword arguments using  **kwargs :   def foo(**kwargs): pass , here 'foo' accepts any number of keyword arguments, i. e., the following calls are valid  foo(name='Tom') ,  foo(name='Tom', age=33) \n To accept any number of positional and keyword arguments using  *args, **kwargs :   def foo(*args, **kwargs): pass , here  foo  accepts any number of positional and keyword arguments, i. e., the following calls are valid  foo(1,name='Tom') ,  foo(1, 'bar', name='Tom', age=33) \n To enforce keyword only arguments using  * :   def foo(pos1, pos2, *, kwarg1): pass , here  *  means that foo only accept keyword arguments after pos2, hence  foo(1, 2, 3)  raises TypeError but  foo(1, 2, kwarg1=3)  is ok. \n To express no further interest in more positional arguments using  *_  (Note: this is a convention only):   def foo(bar, baz, *_): pass  means (by convention)  foo  only uses  bar  and  baz  arguments in its working and will ignore others. \n To express no further interest in more keyword arguments using  \\**_  (Note: this is a convention only):   def foo(bar, baz, **_): pass  means (by convention)  foo  only uses  bar  and  baz  arguments in its working and will ignore others. \n \n\n BONUS:  From python 3.8 onward, one can use  /  in function definition to enforce  positional only parameters. In the following example, parameters a and b are  positional-only , while c or d can be positional or keyword, and e or f are required to be keywords: \n\n def f(a, b, /, c, d, *, e, f):\n    pass\n \n    ", "date_posted": "2020-01-08 14:25:16Z", "upvote": "\r\n            23\r\n        ", "accepted": "No", "user": {"stack_user_id": "3484477", "name": "Meysam Sadeghi", "reputation_score": "1,108"}, "answer_comments": [{"stack_answer_id": "59630576", "stack_answer_comment_id": "124788659", "comment_content": "One reason to use ", "user_id": null}]}, {"stack_answer_id": "36902", "answer_content": "\r\n From the Python documentation: \n\n \n   If there are more positional arguments than there are formal parameter slots, a TypeError exception is raised, unless a formal parameter using the syntax \"*identifier\" is present; in this case, that formal parameter receives a tuple containing the excess positional arguments (or an empty tuple if there were no excess positional arguments).  \n  \n   If any keyword argument does not correspond to a formal parameter name, a TypeError exception is raised, unless a formal parameter using the syntax \"**identifier\" is present; in this case, that formal parameter receives a dictionary containing the excess keyword arguments (using the keywords as keys and the argument values as corresponding values), or a (new) empty dictionary if there were no excess keyword arguments.  \n \n    ", "date_posted": "2008-08-31 15:07:48Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "2600", "name": "Chris Upchurch", "reputation_score": "15k"}, "answer_comments": []}, {"stack_answer_id": "51733267", "answer_content": "\r\n *  means receive variable arguments as tuple \n\n **  means receive variable arguments as dictionary \n\n Used like the following: \n\n 1) single * \n\n def foo(*args):\n    for arg in args:\n        print(arg)\n\nfoo(\"two\", 3)\n \n\n Output: \n\n two\n3\n \n\n 2) Now  ** \n\n def bar(**kwargs):\n    for key in kwargs:\n        print(key, kwargs[key])\n\nbar(dic1=\"two\", dic2=3)\n \n\n Output: \n\n dic1 two\ndic2 3\n \n    ", "date_posted": "2019-10-23 03:16:02Z", "upvote": "\r\n            17\r\n        ", "accepted": "No", "user": {"stack_user_id": "11997336", "name": "AnswerSeeker", "reputation_score": "291"}, "answer_comments": []}, {"stack_answer_id": "34166505", "answer_content": "\r\n In Python 3.5, you can also use this syntax in  list ,  dict ,  tuple , and  set  displays (also sometimes called literals). See  PEP 488: Additional Unpacking Generalizations . \n\n >>> (0, *range(1, 4), 5, *range(6, 8))\n(0, 1, 2, 3, 5, 6, 7)\n>>> [0, *range(1, 4), 5, *range(6, 8)]\n[0, 1, 2, 3, 5, 6, 7]\n>>> {0, *range(1, 4), 5, *range(6, 8)}\n{0, 1, 2, 3, 5, 6, 7}\n>>> d = {'one': 1, 'two': 2, 'three': 3}\n>>> e = {'six': 6, 'seven': 7}\n>>> {'zero': 0, **d, 'five': 5, **e}\n{'five': 5, 'seven': 7, 'two': 2, 'one': 1, 'three': 3, 'six': 6, 'zero': 0}\n \n\n It also allows multiple iterables to be unpacked in a single function call. \n\n >>> range(*[1, 10], *[2])\nrange(1, 10, 2)\n \n\n (Thanks to mgilson for the PEP link.) \n    ", "date_posted": "2015-12-08 22:29:06Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "2963903", "name": "leewz", "reputation_score": "3,101"}, "answer_comments": [{"stack_answer_id": "34166505", "stack_answer_comment_id": "56080415", "comment_content": "I'm not sure that this is a violation of \"there's only one way to do it\".  There's no other way to initialize a list/tuple from multiple iterables -- You currently need to chain them into a single iterable which isn't always convenient.  You can read about the rational in ", "user_id": null}]}, {"stack_answer_id": "40492308", "answer_content": "\r\n I want to give an example which others haven't  mentioned \n\n * can also unpack a  generator \n\n An example from Python3 Document \n\n x = [1, 2, 3]\ny = [4, 5, 6]\n\nunzip_x, unzip_y = zip(*zip(x, y))\n \n\n unzip_x will be [1, 2, 3], unzip_y will be [4, 5, 6] \n\n The zip() receives multiple iretable args, and return a generator.  \n\n zip(*zip(x,y)) -> zip((1, 4), (2, 5), (3, 6))\n \n    ", "date_posted": "2016-11-08 16:50:20Z", "upvote": "\r\n            10\r\n        ", "accepted": "No", "user": {"stack_user_id": "7132449", "name": "Lochu'an Chang", "reputation_score": "101"}, "answer_comments": [{"stack_answer_id": "40492308", "stack_answer_comment_id": "114888001", "comment_content": "unzip_x will be ", "user_id": null}]}, {"stack_answer_id": "55475113", "answer_content": "\r\n TL;DR \n It packs arguments passed to the function into  list  and  dict  respectively inside the function body. When you define a function signature like this: \n def func(*args, **kwds):\n    # do stuff\n \n it can be called with any number of arguments and keyword arguments. The non-keyword arguments get packed into a list called  args  inside the function body and the keyword arguments get packed into a dict called  kwds  inside the function body. \n func(\"this\", \"is a list of\", \"non-keyowrd\", \"arguments\", keyword=\"ligma\", options=[1,2,3])\n \n now inside the function body, when the function is called, there are two local variables,  args  which is a list having value  [\"this\", \"is a list of\", \"non-keyword\", \"arguments\"]  and  kwds  which is a  dict  having value  {\"keyword\" : \"ligma\", \"options\" : [1,2,3]} \n \n This also works in reverse, i.e. from the caller side. for example if you have a function defined as: \n def f(a, b, c, d=1, e=10):\n    # do stuff\n \n you can call it with by unpacking iterables or mappings you have in the calling scope: \n iterable = [1, 20, 500]\nmapping = {\"d\" : 100, \"e\": 3}\nf(*iterable, **mapping)\n# That call is equivalent to\nf(1, 20, 500, d=100, e=3)\n \n    ", "date_posted": "2020-08-27 20:40:25Z", "upvote": "\r\n            10\r\n        ", "accepted": "No", "user": {"stack_user_id": "2430549", "name": "HoldOffHunger", "reputation_score": "16.2k"}, "answer_comments": []}, {"stack_answer_id": "56962836", "answer_content": "\r\n Building on nickd's  answer ... \n\n def foo(param1, *param2):\n    print(param1)\n    print(param2)\n\n\ndef bar(param1, **param2):\n    print(param1)\n    print(param2)\n\n\ndef three_params(param1, *param2, **param3):\n    print(param1)\n    print(param2)\n    print(param3)\n\n\nfoo(1, 2, 3, 4, 5)\nprint(\"\\n\")\nbar(1, a=2, b=3)\nprint(\"\\n\")\nthree_params(1, 2, 3, 4, s=5)\n \n\n Output: \n\n 1\n(2, 3, 4, 5)\n\n1\n{'a': 2, 'b': 3}\n\n1\n(2, 3, 4)\n{'s': 5}\n \n\n Basically, any number of  positional arguments  can use *args and any  named arguments  (or kwargs aka keyword arguments) can use **kwargs. \n    ", "date_posted": "2020-02-13 09:23:21Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "1607450", "name": "Satbir Kira", "reputation_score": "742"}, "answer_comments": []}, {"stack_answer_id": "32031804", "answer_content": "\r\n In addition to function calls, *args and **kwargs are useful in class hierarchies and also avoid having to write  __init__  method in Python. Similar usage can seen in frameworks like Django code. \n\n For example, \n\n def __init__(self, *args, **kwargs):\n    for attribute_name, value in zip(self._expected_attributes, args):\n        setattr(self, attribute_name, value)\n        if kwargs.has_key(attribute_name):\n            kwargs.pop(attribute_name)\n\n    for attribute_name in kwargs.viewkeys():\n        setattr(self, attribute_name, kwargs[attribute_name])\n \n\n A subclass can then be \n\n class RetailItem(Item):\n    _expected_attributes = Item._expected_attributes + ['name', 'price', 'category', 'country_of_origin']\n\nclass FoodItem(RetailItem):\n    _expected_attributes = RetailItem._expected_attributes +  ['expiry_date']\n \n\n The subclass then be instantiated as  \n\n food_item = FoodItem(name = 'Jam', \n                     price = 12.0, \n                     category = 'Foods', \n                     country_of_origin = 'US', \n                     expiry_date = datetime.datetime.now())\n \n\n Also, a subclass with a new attribute which makes sense only to that subclass instance can call the Base class  __init__  to offload the attributes setting.\nThis is done through *args and **kwargs. kwargs mainly used so that code is readable using named arguments. For example, \n\n class ElectronicAccessories(RetailItem):\n    _expected_attributes = RetailItem._expected_attributes +  ['specifications']\n    # Depend on args and kwargs to populate the data as needed.\n    def __init__(self, specifications = None, *args, **kwargs):\n        self.specifications = specifications  # Rest of attributes will make sense to parent class.\n        super(ElectronicAccessories, self).__init__(*args, **kwargs)\n \n\n which can be instatiated as \n\n usb_key = ElectronicAccessories(name = 'Sandisk', \n                                price = '$6.00', \n                                category = 'Electronics',\n                                country_of_origin = 'CN',\n                                specifications = '4GB USB 2.0/USB 3.0')\n \n\n The complete code is  here \n    ", "date_posted": "2018-02-21 09:02:49Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "1086143", "name": "quiet_penguin", "reputation_score": "778"}, "answer_comments": []}, {"stack_answer_id": "50116852", "answer_content": "\r\n *args  and  **kwargs : allow you to pass a variable number of arguments to a function.  \n\n *args : is used to send a non-keyworded variable length argument list to the function: \n\n def args(normal_arg, *argv):\n    print(\"normal argument:\", normal_arg)\n\n    for arg in argv:\n        print(\"Argument in list of arguments from *argv:\", arg)\n\nargs('animals', 'fish', 'duck', 'bird')\n \n\n Will produce: \n\n normal argument: animals\nArgument in list of arguments from *argv: fish\nArgument in list of arguments from *argv: duck\nArgument in list of arguments from *argv: bird\n \n\n **kwargs* \n\n **kwargs  allows you to pass keyworded variable length of arguments to a function. You should use  **kwargs  if you want to handle named arguments in a function.  \n\n def who(**kwargs):\n    if kwargs is not None:\n        for key, value in kwargs.items():\n            print(\"Your %s is %s.\" % (key, value))\n\nwho(name=\"Nikola\", last_name=\"Tesla\", birthday=\"7.10.1856\", birthplace=\"Croatia\")  \n \n\n Will produce: \n\n Your name is Nikola.\nYour last_name is Tesla.\nYour birthday is 7.10.1856.\nYour birthplace is Croatia.\n \n    ", "date_posted": "2019-05-20 13:36:37Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "7851470", "name": "Georgy", "reputation_score": "10.6k"}, "answer_comments": []}, {"stack_answer_id": "62442187", "answer_content": "\r\n Given a function that has 3 items as argument \n\n sum = lambda x, y, z: x + y + z\nsum(1,2,3) # sum 3 items\n\nsum([1,2,3]) # error, needs 3 items, not 1 list\n\nx = [1,2,3][0]\ny = [1,2,3][1]\nz = [1,2,3][2]\nsum(x,y,z) # ok\n\nsum(*[1,2,3]) # ok, 1 list becomes 3 items\n \n\n Imagine this toy with a bag of a triangle, a circle and a rectangle item. That bag does not directly fit. You need to unpack the bag to take those 3 items and now they fit. The Python * operator does this unpack process. \n\n \n    ", "date_posted": "2020-06-18 05:03:34Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "4710031", "name": "etoricky", "reputation_score": "571"}, "answer_comments": []}, {"stack_answer_id": "40262722", "answer_content": "\r\n A good example of using both in a function is: \n\n >>> def foo(*arg,**kwargs):\n...     print arg\n...     print kwargs\n>>>\n>>> a = (1, 2, 3)\n>>> b = {'aa': 11, 'bb': 22}\n>>>\n>>>\n>>> foo(*a,**b)\n(1, 2, 3)\n{'aa': 11, 'bb': 22}\n>>>\n>>>\n>>> foo(a,**b) \n((1, 2, 3),)\n{'aa': 11, 'bb': 22}\n>>>\n>>>\n>>> foo(a,b) \n((1, 2, 3), {'aa': 11, 'bb': 22})\n{}\n>>>\n>>>\n>>> foo(a,*b)\n((1, 2, 3), 'aa', 'bb')\n{}\n \n    ", "date_posted": "2016-10-26 12:48:05Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "3066559", "name": "amir jj", "reputation_score": "224"}, "answer_comments": []}, {"stack_answer_id": "40823181", "answer_content": "\r\n This example would help you remember  *args ,  **kwargs  and even  super  and inheritance in Python at once. \n\n class base(object):\n    def __init__(self, base_param):\n        self.base_param = base_param\n\n\nclass child1(base): # inherited from base class\n    def __init__(self, child_param, *args) # *args for non-keyword args\n        self.child_param = child_param\n        super(child1, self).__init__(*args) # call __init__ of the base class and initialize it with a NON-KEYWORD arg\n\nclass child2(base):\n    def __init__(self, child_param, **kwargs):\n        self.child_param = child_param\n        super(child2, self).__init__(**kwargs) # call __init__ of the base class and initialize it with a KEYWORD arg\n\nc1 = child1(1,0)\nc2 = child2(1,base_param=0)\nprint c1.base_param # 0\nprint c1.child_param # 1\nprint c2.base_param # 0\nprint c2.child_param # 1\n \n    ", "date_posted": "2016-11-26 21:09:43Z", "upvote": "\r\n            3\r\n        ", "accepted": "No", "user": {"stack_user_id": "5098762", "name": "thanhtang", "reputation_score": "836"}, "answer_comments": []}, {"stack_answer_id": "59217020", "answer_content": "\r\n Context \n\n \n python 3.x \n unpacking with  ** \n use with string formatting \n \n\n Use with string formatting \n\n In addition to the answers in this thread, here is another detail that was not mentioned elsewhere. This expands on the  answer by Brad Solomon \n\n Unpacking with  **  is also useful when using python  str.format .   \n\n This is somewhat similar to what you can do with python  f-strings   f-string  but with the added overhead of declaring a dict to hold the variables (f-string does not require a dict). \n\n Quick Example \n\n   ## init vars\n  ddvars = dict()\n  ddcalc = dict()\n  pass\n  ddvars['fname']     = 'Huomer'\n  ddvars['lname']     = 'Huimpson'\n  ddvars['motto']     = 'I love donuts!'\n  ddvars['age']       = 33\n  pass\n  ddcalc['ydiff']     = 5\n  ddcalc['ycalc']     = ddvars['age'] + ddcalc['ydiff']\n  pass\n  vdemo = []\n\n  ## ********************\n  ## single unpack supported in py 2.7\n  vdemo.append('''\n  Hello {fname} {lname}!\n\n  Today you are {age} years old!\n\n  We love your motto \"{motto}\" and we agree with you!\n  '''.format(**ddvars)) \n  pass\n\n  ## ********************\n  ## multiple unpack supported in py 3.x\n  vdemo.append('''\n  Hello {fname} {lname}!\n\n  In {ydiff} years you will be {ycalc} years old!\n  '''.format(**ddvars,**ddcalc)) \n  pass\n\n  ## ********************\n  print(vdemo[-1])\n\n \n    ", "date_posted": "2019-12-06 16:36:13Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "42223", "name": "dreftymac", "reputation_score": "30.1k"}, "answer_comments": []}, {"stack_answer_id": "66705594", "answer_content": "\r\n *args ( or *any ) means every parameters \n def any_param(*param):\n    pass\n\nany_param(1)\nany_param(1,1)\nany_param(1,1,1)\nany_param(1,...)\n \n NOTICE  : you can don't pass parameters to *args \n def any_param(*param):\n    pass\n\nany_param() # will work correct\n \n The *args is in type tuple \n def any_param(*param):\n    return type(param)\n\nany_param(1) #tuple\nany_param() # tuple\n \n for access to elements don't use of * \n def any(*param):\n    param[0] # correct\n\ndef any(*param):\n    *param[0] # incorrect\n \n The **kwd \n **kwd or **any\nThis is a dict type \n def func(**any):\n    return type(any) # dict\n\ndef func(**any):\n    return any\n\nfunc(width=\"10\",height=\"20\") # {width=\"10\",height=\"20\")\n\n\n \n    ", "date_posted": "2021-04-19 15:19:22Z", "upvote": "\r\n            2\r\n        ", "accepted": "No", "user": {"stack_user_id": "4038842", "name": "kjonsson", "reputation_score": "2,749"}, "answer_comments": []}, {"stack_answer_id": "52134172", "answer_content": "\r\n \n def foo(param1, *param2):  is a method can accept arbitrary number of values for  *param2 , \n def bar(param1, **param2):  is a method can accept arbitrary number of values with keys for  *param2 \n param1  is a simple parameter. \n \n\n For example, the syntax for implementing  varargs  in Java as follows: \n\n accessModifier methodName(datatype\u2026 arg) {\n    // method body\n}\n \n    ", "date_posted": "2018-09-02 05:14:05Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "1697099", "name": "Premraj", "reputation_score": "68.9k"}, "answer_comments": []}, {"stack_answer_id": "73178373", "answer_content": "\r\n \"Infinite\" Args with *args and **kwargs \n *args  and  **kwargs  are just some way to input unlimited characters to functions, like: \n \ndef print_all(*args, **kwargs):\n    print(args) # print any number of arguments like: \"print_all(\"foo\", \"bar\")\"\n    print(kwargs.get(\"to_print\")) # print the value of the keyworded argument \"to_print\"\n\n\n# example:\nprint_all(\"Hello\", \"World\", to_print=\"!\")\n# will print:\n\"\"\"\n('Hello', 'World')\n!\n\"\"\"\n \n    ", "date_posted": "2022-07-30 19:05:07Z", "upvote": "\r\n            0\r\n        ", "accepted": "No", "user": {"stack_user_id": "16892196", "name": "Isaac Vin\u00edcius", "reputation_score": "13"}, "answer_comments": [{"stack_answer_id": "73178373", "stack_answer_comment_id": "129241254", "comment_content": " can be anything, like ", "user_id": null}]}], "user": {"stack_user_id": "2572", "name": "Todd", "reputation_score": "32.1k"}, "question_comments": [{"stack_question_id": "36901", "stack_question_comment_id": "85121837", "comment_content": "see also ", "user_id": null}, {"stack_question_id": "36901", "stack_question_comment_id": "97343204", "comment_content": "This question is a very popular duplicate target, but unfortunately it's often used incorrectly. Keep in mind that this question asks about ", "user_id": null}, {"stack_question_id": "36901", "stack_question_comment_id": "115318596", "comment_content": "@Aran-Fey: I think a better target for \"what does it mean in function calls\" is ", "user_id": null}, {"stack_question_id": "36901", "stack_question_comment_id": "127051533", "comment_content": "This question is - like many very old questions - sort of backwards; usually a question should be about how to solve a problem in new code, rather than how to understand existing code. For the latter, if you are closing something else as a duplicate, consider ", "user_id": null}, {"stack_question_id": "36901", "stack_question_comment_id": "128406992", "comment_content": " was also closed as a duplicate of this, but you might find it better than this one.", "user_id": null}]},
{"stack_question_id": "20002503", "question_title": "Why does \"a == x or y or z\" always evaluate to True? How can I compare \"a\" to all of those?", "question_content": "\r\n                I am writing a security system that denies access to unauthorized users.\nname = input(\"Hello. Please enter your name: \")\nif name == \"Kevin\" or \"Jon\" or \"Inbar\":\n...\r\n", "question_url": "/questions/20002503/why-does-a-x-or-y-or-z-always-evaluate-to-true-how-can-i-compare-a-to-al", "date_posted": "Nov 15, 2013 at 13:45", "upvote": "1", "view": "3", "tags": ["python", "boolean", "boolean-expression"], "answers_count": "6", "answers": [{"stack_answer_id": "20002504", "answer_content": "\r\n In many cases, Python looks and behaves like natural English, but this is one case where that abstraction fails. People can use context clues to determine that \"Jon\" and \"Inbar\" are objects joined to the verb \"equals\", but the Python interpreter is more literal minded. \n if name == \"Kevin\" or \"Jon\" or \"Inbar\":\n \n is logically equivalent to: \n if (name == \"Kevin\") or (\"Jon\") or (\"Inbar\"):\n \n Which, for user Bob, is equivalent to: \n if (False) or (\"Jon\") or (\"Inbar\"):\n \n The  or  operator chooses the first argument with a positive  truth value : \n if \"Jon\":\n \n And since \"Jon\" has a positive truth value, the  if  block executes. That is what causes \"Access granted\" to be printed regardless of the name given. \n All of this reasoning also applies to the expression  if \"Kevin\" or \"Jon\" or \"Inbar\" == name . the first value,  \"Kevin\" , is true, so the  if  block executes. \n \n There are two common ways to properly construct this conditional. \n \n Use multiple  ==  operators to explicitly check against each value: \n if name == \"Kevin\" or name == \"Jon\" or name == \"Inbar\":\n \n \n Compose a collection of valid values (a set, a list or a tuple for example), and use the  in  operator to test for membership: \n if name in {\"Kevin\", \"Jon\", \"Inbar\"}:\n \n \n \n In general of the two the second should be preferred as it's easier to read and also faster: \n >>> import timeit\n>>> timeit.timeit('name == \"Kevin\" or name == \"Jon\" or name == \"Inbar\"',\n    setup=\"name='Inbar'\")\n0.4247764749999945\n>>> timeit.timeit('name in {\"Kevin\", \"Jon\", \"Inbar\"}', setup=\"name='Inbar'\")\n0.18493307199999265\n \n \n For those who may want proof that  if a == b or c or d or e: ...  is indeed parsed like this. The built-in  ast  module provides an answer: \n >>> import ast\n>>> ast.parse(\"a == b or c or d or e\", \"<string>\", \"eval\")\n<ast.Expression object at 0x7f929c898220>\n>>> print(ast.dump(_, indent=4))\nExpression(\n    body=BoolOp(\n        op=Or(),\n        values=[\n            Compare(\n                left=Name(id='a', ctx=Load()),\n                ops=[\n                    Eq()],\n                comparators=[\n                    Name(id='b', ctx=Load())]),\n            Name(id='c', ctx=Load()),\n            Name(id='d', ctx=Load()),\n            Name(id='e', ctx=Load())]))\n \n As one can see, it's the boolean operator  or  applied to four sub-expressions: comparison  a == b ; and simple expressions  c ,  d , and  e . \n    ", "date_posted": "2021-04-11 18:47:35Z", "upvote": "\r\n            198\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "20002504", "name": "\r\n        7 revs, 5 users 42%", "reputation_score": 0}, "answer_comments": [{"stack_answer_id": "20002504", "stack_answer_comment_id": "99771573", "comment_content": "Is there a specific reason to choose a tuple ", "user_id": null}, {"stack_answer_id": "20002504", "stack_answer_comment_id": "99771840", "comment_content": "Not really, since both work if the values are all hashable. Set membership testing has better big-O complexity than tuple membership testing, but constructing a set is a little more expensive than constructing a tuple. I think it's largely a wash for small collections like these. Playing around with timeit, ", "user_id": "/users/953482/kevin"}, {"stack_answer_id": "20002504", "stack_answer_comment_id": "99772058", "comment_content": " recommends set literals for membership testing. I'll update my post.", "user_id": "/users/953482/kevin"}, {"stack_answer_id": "20002504", "stack_answer_comment_id": "109380603", "comment_content": "In modern Python, it recognizes that the set is a constant and makes it a ", "user_id": null}]}, {"stack_answer_id": "62545337", "answer_content": "\r\n There are 3 condition checks in  if name == \"Kevin\" or \"Jon\" or \"Inbar\": \n \n name == \"Kevin\" \n \"Jon\" \n \"Inbar\" \n \n and this if statement is equivalent to \n if name == \"Kevin\":\n    print(\"Access granted.\")\nelif \"Jon\":\n    print(\"Access granted.\")\nelif \"Inbar\":\n    print(\"Access granted.\")\nelse:\n    print(\"Access denied.\")\n \n Since  elif \"Jon\"  will always be true so access to any user is granted \n Solution \n \n You can use any one method below \n Fast \n if name in [\"Kevin\", \"Jon\", \"Inbar\"]:\n    print(\"Access granted.\")\nelse:\n    print(\"Access denied.\")\n \n Slow \n if name == \"Kevin\" or name == \"Jon\" or name == \"Inbar\":\n    print(\"Access granted.\")\nelse:\n    print(\"Access denied.\")\n \n Slow + Unnecessary code \n if name == \"Kevin\":\n    print(\"Access granted.\")\nelif name == \"Jon\":\n    print(\"Access granted.\")\nelif name == \"Inbar\":\n    print(\"Access granted.\")\nelse:\n    print(\"Access denied.\")\n \n    ", "date_posted": "2020-06-24 00:30:08Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "13751567", "name": "7u5h4r", "reputation_score": "439"}, "answer_comments": []}, {"stack_answer_id": "71188001", "answer_content": "\r\n Summarising all existing answers \n (And adding a few of my points) \n Explanation : \n if name == \"Kevin\" or \"Jon\" or \"Inbar\":\n \n is logically equivalent to: \n if (name == \"Kevin\") or (\"Jon\") or (\"Inbar\"):\n \n Which, for user Bob, is equivalent to: \n if (False) or (\"Jon\") or (\"Inbar\"):\n \n NOTE : Python evaluates the logical value of any non-zero integer as  True . Therefore, all Non-empty lists, sets, strings, etc. are evaluable and return  True \n The  or  operator chooses the first argument with a positive truth value. \n Therefore, \"Jon\" has a positive truth value and the if block executes, since it is now equivalent to \n if (False) or (True) or (True):\n \n That is what causes \"Access granted\" to be printed regardless of the name input. \n Solutions : \n Solution 1 :  Use multiple  ==  operators to explicitly check against each value \n if name == \"Kevin\" or name == \"Jon\" or name == \"Inbar\":\n    print(\"Access granted.\")\nelse:\n    print(\"Access denied.\")\n \n Solution 2 :  Compose a collection of valid values (a set, a list or a tuple for example), and use the  in  operator to test for membership  (faster, preferred method) \n if name in {\"Kevin\", \"Jon\", \"Inbar\"}:\n    print(\"Access granted.\")\nelse:\n    print(\"Access denied.\")\n \n OR \n if name in [\"Kevin\", \"Jon\", \"Inbar\"]:\n    print(\"Access granted.\")\nelse:\n    print(\"Access denied.\")\n \n Solution 3 :  Use the basic  (and not very efficient)   if-elif-else  structure \n if name == \"Kevin\":\n    print(\"Access granted.\")\nelif name == \"Jon\":\n    print(\"Access granted.\")\nelif name == \"Inbar\":\n    print(\"Access granted.\")\nelse:\n    print(\"Access denied.\")\n \n    ", "date_posted": "2022-02-25 06:21:43Z", "upvote": "\r\n            4\r\n        ", "accepted": "No", "user": {"stack_user_id": "17112163", "name": "Deepthi Tabitha Bennet", "reputation_score": "534"}, "answer_comments": []}, {"stack_answer_id": "56186060", "answer_content": "\r\n Simple engineering problem, let's simply it a bit further. \n\n In [1]: a,b,c,d=1,2,3,4\nIn [2]: a==b\nOut[2]: False\n \n\n But, inherited from the language C, Python evaluates the logical value of a non zero integer as True. \n\n In [11]: if 3:\n    ...:     print (\"yey\")\n    ...:\nyey\n \n\n Now, Python builds on that logic and let you use logic literals such as or on integers, and so  \n\n In [9]: False or 3\nOut[9]: 3\n \n\n Finally \n\n In [4]: a==b or c or d\nOut[4]: 3\n \n\n The proper way to write it would be: \n\n In [13]: if a in (b,c,d):\n    ...:     print('Access granted')\n \n\n For safety I'd also suggest you don't hard code passwords. \n    ", "date_posted": "2019-05-17 12:05:58Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "1854182", "name": "user1854182", "reputation_score": "641"}, "answer_comments": []}, {"stack_answer_id": "65071388", "answer_content": "\r\n Not-empty lists, sets, strings, etc. are evaluable and, therefore, return True. \n Therefore, when you say: \n a = \"Raul\"\nif a == \"Kevin\" or \"John\" or \"Inbar\":\n    pass\n \n You are actually saying: \n if \"Raul\" == \"Kevin\" or \"John\" != \"\" or \"Inbar\" != \"\":\n    pass\n \n Since at least one of \"John\" and \"Inbar\" is not an empty string, the whole expression always returns True! \n The solution: \n a = \"Raul\"\nif a == \"Kevin\" or a == \"John\" or a == \"Inbar\":\n    pass\n \n or: \n a = \"Raul\"\nif a in {\"Kevin\", \"John\", \"Inbar\"}:\n    pass\n \n    ", "date_posted": "2020-11-30 13:23:54Z", "upvote": "\r\n            1\r\n        ", "accepted": "No", "user": {"stack_user_id": "6251742", "name": "Dorian Turba", "reputation_score": "1,847"}, "answer_comments": [{"stack_answer_id": "65071388", "stack_answer_comment_id": "118514393", "comment_content": "good otherwise but \"You are actually saying:\" is ", "user_id": null}]}, {"stack_answer_id": "65199768", "answer_content": "\r\n Approaches \n How a data scientist approaches this problem \n The simplest way possible is to eliminate the need for comparison operators and use a list. This looks impressive on security systems because you learn to access ORMs. \n user = input(\"Enter name: \")\n\nif user in {\"Bob\", \"Kevin\", \"Joe\"}:\n   print(\"Access granted, \" + str(user) + \".\")\nelse:\n   print(\"Access denied.\")\n \n Or, you can resemble the  exact  same code above, just put the list of registered users in their own list: \n user = input(\"Enter name: \")\nusers = {\"Bob\", \"Kevin\", \"Joe\", \"a million more users if you like\"}\n\nif user in users:\n   print(\"Access granted, \" + str(user) + \".\")\nelse:\n   print(\"Access denied.\")\n \n If you wanted to complete this protocol safely without the risk of attack, set up double parameters. This would check your mini-ORM for  first  and  last  name fields, as well as a  password  or  secret question  key. Objects can be sorted like this if you want to efficiently lazy-load user credentials without hashing: \n def lazy(i):\n   j = 0 # For example\n   while j < i:\n      yield j\n      j += 1\n \n The loop will consume  only  the yielded values to save time and energy on your system: \n You can then do something with the iterated list: \n for j in lazy_range(10):\n   do_something_here(j)\n \n This problem can be approached from any angle: memory management, security, or simply by an organic list or packaged ORM. \n    ", "date_posted": "2022-01-02 09:47:13Z", "upvote": "\r\n            -1\r\n        ", "accepted": "No", "user": {"stack_user_id": "4621513", "name": "mkrieger1", "reputation_score": "15.4k"}, "answer_comments": []}], "user": {"stack_user_id": "953482", "name": "Kevin", "reputation_score": "72.8k"}, "question_comments": [{"stack_question_id": "20002503", "stack_question_comment_id": "97948491", "comment_content": "Variations of this problem include ", "user_id": null}]},
{"stack_question_id": "312443", "question_title": "How do I split a list into equally-sized chunks?", "question_content": "\r\n                How do I split a list of arbitrary length into equal sized chunks?\nRelated question: How to iterate over a list in chunks\r\n", "question_url": "/questions/312443/how-do-i-split-a-list-into-equally-sized-chunks", "date_posted": "Nov 23, 2008 at 12:15", "upvote": "2", "view": "1", "tags": ["python", "list", "split", "chunks"], "answers_count": "7", "answers": [{"stack_answer_id": "312464", "answer_content": "\r\n Here's a generator that yields evenly-sized chunks: \n def chunks(lst, n):\n    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n    for i in range(0, len(lst), n):\n        yield lst[i:i + n]\n \n import pprint\npprint.pprint(list(chunks(range(10, 75), 10)))\n[[10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n [70, 71, 72, 73, 74]]\n \n For Python 2, using  xrange  instead of  range : \n def chunks(lst, n):\n    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n    for i in xrange(0, len(lst), n):\n        yield lst[i:i + n]\n \n \n Below is a list comprehension one-liner. The method above is preferable, though, since using named functions makes code easier to understand. For Python 3: \n [lst[i:i + n] for i in range(0, len(lst), n)]\n \n For Python 2: \n [lst[i:i + n] for i in xrange(0, len(lst), n)]\n \n    ", "date_posted": "2022-06-04 21:22:56Z", "upvote": "\r\n            4153\r\n        ", "accepted": "Yes", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": []}, {"stack_answer_id": "1751478", "answer_content": "\r\n Something super simple: \n def chunks(xs, n):\n    n = max(1, n)\n    return (xs[i:i+n] for i in range(0, len(xs), n))\n \n For Python 2, use  xrange()  instead of  range() . \n    ", "date_posted": "2022-06-16 01:18:58Z", "upvote": "\r\n            642\r\n        ", "accepted": "No", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": [{"stack_answer_id": "1751478", "stack_answer_comment_id": "121518885", "comment_content": "Using short circuiting, ", "user_id": null}]}, {"stack_answer_id": "16935535", "answer_content": "\r\n I know this is kind of old but nobody yet mentioned  numpy.array_split : \n import numpy as np\n\nlst = range(50)\nnp.array_split(lst, 5)\n \n Result: \n [array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19]),\n array([20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n array([30, 31, 32, 33, 34, 35, 36, 37, 38, 39]),\n array([40, 41, 42, 43, 44, 45, 46, 47, 48, 49])]\n \n    ", "date_posted": "2022-04-01 01:59:49Z", "upvote": "\r\n            378\r\n        ", "accepted": "No", "user": {"stack_user_id": "365102", "name": "Mateen Ulhaq", "reputation_score": "22k"}, "answer_comments": [{"stack_answer_id": "16935535", "stack_answer_comment_id": "52802258", "comment_content": "This allows you to set the total number of chunks, not the number of elements per chunk.", "user_id": null}, {"stack_answer_id": "16935535", "stack_answer_comment_id": "129310293", "comment_content": "This method change the type of the elements [ ['a', 1] , ['b', 2] ] with chunk one may become [ ['a', '1'] , ['b', '2'] ]. If type of first element is str then all element become numpy.str_  ...", "user_id": null}]}, {"stack_answer_id": "312644", "answer_content": "\r\n Directly from the (old) Python documentation (recipes for itertools): \n\n from itertools import izip, chain, repeat\n\ndef grouper(n, iterable, padvalue=None):\n    \"grouper(3, 'abcdefg', 'x') --> ('a','b','c'), ('d','e','f'), ('g','x','x')\"\n    return izip(*[chain(iterable, repeat(padvalue, n-1))]*n)\n \n\n The current version, as suggested by J.F.Sebastian: \n\n #from itertools import izip_longest as zip_longest # for Python 2.x\nfrom itertools import zip_longest # for Python 3.x\n#from six.moves import zip_longest # for both (uses the six compat library)\n\ndef grouper(n, iterable, padvalue=None):\n    \"grouper(3, 'abcdefg', 'x') --> ('a','b','c'), ('d','e','f'), ('g','x','x')\"\n    return zip_longest(*[iter(iterable)]*n, fillvalue=padvalue)\n \n\n I guess Guido's time machine works\u2014worked\u2014will work\u2014will have worked\u2014was working again. \n\n These solutions work because  [iter(iterable)]*n  (or the equivalent in the earlier version) creates  one  iterator, repeated  n  times in the list.  izip_longest  then effectively performs a round-robin of \"each\" iterator; because this is the same iterator, it is advanced by each such call, resulting in each such zip-roundrobin generating one tuple of  n  items. \n    ", "date_posted": "2017-09-21 09:47:29Z", "upvote": "\r\n            339\r\n        ", "accepted": "No", "user": {"stack_user_id": "6899", "name": "tzot", "reputation_score": "88.7k"}, "answer_comments": []}, {"stack_answer_id": "22045226", "answer_content": "\r\n I'm surprised nobody has thought of using  iter 's  two-argument form : \n\n from itertools import islice\n\ndef chunk(it, size):\n    it = iter(it)\n    return iter(lambda: tuple(islice(it, size)), ())\n \n\n Demo: \n\n >>> list(chunk(range(14), 3))\n[(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, 11), (12, 13)]\n \n\n This works with any iterable and produces output lazily. It returns tuples rather than iterators, but I think it has a certain elegance nonetheless. It also doesn't pad; if you want padding, a simple variation on the above will suffice: \n\n from itertools import islice, chain, repeat\n\ndef chunk_pad(it, size, padval=None):\n    it = chain(iter(it), repeat(padval))\n    return iter(lambda: tuple(islice(it, size)), (padval,) * size)\n \n\n Demo: \n\n >>> list(chunk_pad(range(14), 3))\n[(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, 11), (12, 13, None)]\n>>> list(chunk_pad(range(14), 3, 'a'))\n[(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, 11), (12, 13, 'a')]\n \n\n Like the  izip_longest -based solutions, the above  always  pads. As far as I know, there's no one- or two-line itertools recipe for a function that  optionally  pads. By combining the above two approaches, this one comes pretty close: \n\n _no_padding = object()\n\ndef chunk(it, size, padval=_no_padding):\n    if padval == _no_padding:\n        it = iter(it)\n        sentinel = ()\n    else:\n        it = chain(iter(it), repeat(padval))\n        sentinel = (padval,) * size\n    return iter(lambda: tuple(islice(it, size)), sentinel)\n \n\n Demo: \n\n >>> list(chunk(range(14), 3))\n[(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, 11), (12, 13)]\n>>> list(chunk(range(14), 3, None))\n[(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, 11), (12, 13, None)]\n>>> list(chunk(range(14), 3, 'a'))\n[(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, 11), (12, 13, 'a')]\n \n\n I believe this is the shortest chunker proposed that offers optional padding. \n\n As Tomasz Gandor  observed , the two padding chunkers will stop unexpectedly if they encounter a long sequence of pad values. Here's a final variation that works around that problem in a reasonable way: \n\n _no_padding = object()\ndef chunk(it, size, padval=_no_padding):\n    it = iter(it)\n    chunker = iter(lambda: tuple(islice(it, size)), ())\n    if padval == _no_padding:\n        yield from chunker\n    else:\n        for ch in chunker:\n            yield ch if len(ch) == size else ch + (padval,) * (size - len(ch))\n \n\n Demo: \n\n >>> list(chunk([1, 2, (), (), 5], 2))\n[(1, 2), ((), ()), (5,)]\n>>> list(chunk([1, 2, None, None, 5], 2, None))\n[(1, 2), (None, None), (5, None)]\n \n    ", "date_posted": "2018-11-17 01:16:27Z", "upvote": "\r\n            275\r\n        ", "accepted": "No", "user": {"stack_user_id": "577088", "name": "senderle", "reputation_score": "139k"}, "answer_comments": [{"stack_answer_id": "22045226", "stack_answer_comment_id": "124722445", "comment_content": "One-liner version:  ``` from itertools import islice from functools import partial  seq = [1,2,3,4,5,6,7] size = 3 result = list(iter(partial(lambda it: tuple(islice(it, size)), iter(seq)), ())) assert result == [(1, 2, 3), (4, 5, 6), (7,)] ```", "user_id": null}]}, {"stack_answer_id": "312467", "answer_content": "\r\n Here is a generator that work on arbitrary iterables: \n\n def split_seq(iterable, size):\n    it = iter(iterable)\n    item = list(itertools.islice(it, size))\n    while item:\n        yield item\n        item = list(itertools.islice(it, size))\n \n\n Example: \n\n >>> import pprint\n>>> pprint.pprint(list(split_seq(xrange(75), 10)))\n[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n [70, 71, 72, 73, 74]]\n \n    ", "date_posted": "2012-09-17 21:22:03Z", "upvote": "\r\n            118\r\n        ", "accepted": "No", "user": {"stack_user_id": "298479", "name": "ThiefMaster", "reputation_score": "301k"}, "answer_comments": []}, {"stack_answer_id": "3226719", "answer_content": "\r\n Simple yet elegant \n L = range(1, 1000)\nprint [L[x:x+10] for x in xrange(0, len(L), 10)]\n \n or if you prefer: \n def chunks(L, n): return [L[x: x+n] for x in xrange(0, len(L), n)]\nchunks(L, 10)\n \n    ", "date_posted": "2021-04-26 08:35:26Z", "upvote": "\r\n            80\r\n        ", "accepted": "No", "user": {"stack_user_id": "257299", "name": "kevinarpe", "reputation_score": "19.4k"}, "answer_comments": []}, {"stack_answer_id": "3125186", "answer_content": "\r\n def chunk(input, size):\n    return map(None, *([iter(input)] * size))\n \n    ", "date_posted": "2012-09-17 21:22:25Z", "upvote": "\r\n            63\r\n        ", "accepted": "No", "user": {"stack_user_id": "298479", "name": "ThiefMaster", "reputation_score": "301k"}, "answer_comments": [{"stack_answer_id": "3125186", "stack_answer_comment_id": "123652393", "comment_content": "Doesn't work in Python 3.8, is that for 2.x?", "user_id": null}, {"stack_answer_id": "3125186", "stack_answer_comment_id": "123652445", "comment_content": "For Python 3.x: ", "user_id": null}]}, {"stack_answer_id": "21767522", "answer_content": "\r\n How do you split a list into evenly sized chunks? \n \"Evenly sized chunks\", to me, implies that they are all the same length, or barring that option, at  minimal variance  in length. E.g. 5 baskets for 21 items could have the following results: \n >>> import statistics\n>>> statistics.variance([5,5,5,5,1]) \n3.2\n>>> statistics.variance([5,4,4,4,4]) \n0.19999999999999998\n \n A practical reason to prefer the latter result: if you were using these functions to distribute work, you've built-in the prospect of one likely finishing well before the others, so it would sit around doing nothing while the others continued working hard. \n Critique of other answers here \n When I originally wrote this answer, none of the other answers were evenly sized chunks - they all leave a runt chunk at the end, so they're not well balanced, and have a higher than necessary variance of lengths. \n For example, the current top answer ends with: \n [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n[70, 71, 72, 73, 74]]\n \n Others, like  list(grouper(3, range(7))) , and  chunk(range(7), 3)  both return:  [(0, 1, 2), (3, 4, 5), (6, None, None)] . The  None 's are just padding, and rather inelegant in my opinion. They are NOT evenly chunking the iterables. \n Why can't we divide these better? \n Cycle Solution \n A high-level balanced solution using  itertools.cycle , which is the way I might do it today. Here's the setup: \n from itertools import cycle\nitems = range(10, 75)\nnumber_of_baskets = 10\n \n Now we need our lists into which to populate the elements: \n baskets = [[] for _ in range(number_of_baskets)]\n \n Finally, we zip the elements we're going to allocate together with a cycle of the baskets until we run out of elements, which, semantically, it exactly what we want: \n for element, basket in zip(items, cycle(baskets)):\n    basket.append(element)\n \n Here's the result: \n >>> from pprint import pprint\n>>> pprint(baskets)\n[[10, 20, 30, 40, 50, 60, 70],\n [11, 21, 31, 41, 51, 61, 71],\n [12, 22, 32, 42, 52, 62, 72],\n [13, 23, 33, 43, 53, 63, 73],\n [14, 24, 34, 44, 54, 64, 74],\n [15, 25, 35, 45, 55, 65],\n [16, 26, 36, 46, 56, 66],\n [17, 27, 37, 47, 57, 67],\n [18, 28, 38, 48, 58, 68],\n [19, 29, 39, 49, 59, 69]]\n \n To productionize this solution, we write a function, and provide the type annotations: \n from itertools import cycle\nfrom typing import List, Any\n\ndef cycle_baskets(items: List[Any], maxbaskets: int) -> List[List[Any]]:\n    baskets = [[] for _ in range(min(maxbaskets, len(items)))]\n    for item, basket in zip(items, cycle(baskets)):\n        basket.append(item)\n    return baskets\n \n In the above, we take our list of items, and the max number of baskets. We create a list of empty lists, in which to append each element, in a round-robin style. \n Slices \n Another elegant solution is to use slices - specifically the less-commonly used  step  argument to slices. i.e.: \n start = 0\nstop = None\nstep = number_of_baskets\n\nfirst_basket = items[start:stop:step]\n \n This is especially elegant in that slices don't care how long the data are - the result, our first basket, is only as long as it needs to be. We'll only need to increment the starting point for each basket. \n In fact this could be a one-liner, but we'll go multiline for readability and to avoid an overlong line of code: \n from typing import List, Any\n\ndef slice_baskets(items: List[Any], maxbaskets: int) -> List[List[Any]]:\n    n_baskets = min(maxbaskets, len(items))\n    return [items[i::n_baskets] for i in range(n_baskets)]\n \n And  islice  from the itertools module will provide a lazily iterating approach, like that which was originally asked for in the question. \n I don't expect most use-cases to benefit very much, as the original data is already fully materialized in a list, but for large datasets, it could save nearly half the memory usage. \n from itertools import islice\nfrom typing import List, Any, Generator\n    \ndef yield_islice_baskets(items: List[Any], maxbaskets: int) -> Generator[List[Any], None, None]:\n    n_baskets = min(maxbaskets, len(items))\n    for i in range(n_baskets):\n        yield islice(items, i, None, n_baskets)\n \n View results with: \n from pprint import pprint\n\nitems = list(range(10, 75))\npprint(cycle_baskets(items, 10))\npprint(slice_baskets(items, 10))\npprint([list(s) for s in yield_islice_baskets(items, 10)])\n \n Updated prior solutions \n Here's another balanced solution, adapted from a function I've used in production in the past, that uses the modulo operator: \n def baskets_from(items, maxbaskets=25):\n    baskets = [[] for _ in range(maxbaskets)]\n    for i, item in enumerate(items):\n        baskets[i % maxbaskets].append(item)\n    return filter(None, baskets) \n \n And I created a generator that does the same if you put it into a list: \n def iter_baskets_from(items, maxbaskets=3):\n    '''generates evenly balanced baskets from indexable iterable'''\n    item_count = len(items)\n    baskets = min(item_count, maxbaskets)\n    for x_i in range(baskets):\n        yield [items[y_i] for y_i in range(x_i, item_count, baskets)]\n    \n \n And finally, since I see that all of the above functions return elements in a contiguous order (as they were given): \n def iter_baskets_contiguous(items, maxbaskets=3, item_count=None):\n    '''\n    generates balanced baskets from iterable, contiguous contents\n    provide item_count if providing a iterator that doesn't support len()\n    '''\n    item_count = item_count or len(items)\n    baskets = min(item_count, maxbaskets)\n    items = iter(items)\n    floor = item_count // baskets \n    ceiling = floor + 1\n    stepdown = item_count % baskets\n    for x_i in range(baskets):\n        length = ceiling if x_i < stepdown else floor\n        yield [items.next() for _ in range(length)]\n \n Output \n To test them out: \n print(baskets_from(range(6), 8))\nprint(list(iter_baskets_from(range(6), 8)))\nprint(list(iter_baskets_contiguous(range(6), 8)))\nprint(baskets_from(range(22), 8))\nprint(list(iter_baskets_from(range(22), 8)))\nprint(list(iter_baskets_contiguous(range(22), 8)))\nprint(baskets_from('ABCDEFG', 3))\nprint(list(iter_baskets_from('ABCDEFG', 3)))\nprint(list(iter_baskets_contiguous('ABCDEFG', 3)))\nprint(baskets_from(range(26), 5))\nprint(list(iter_baskets_from(range(26), 5)))\nprint(list(iter_baskets_contiguous(range(26), 5)))\n \n Which prints out: \n [[0], [1], [2], [3], [4], [5]]\n[[0], [1], [2], [3], [4], [5]]\n[[0], [1], [2], [3], [4], [5]]\n[[0, 8, 16], [1, 9, 17], [2, 10, 18], [3, 11, 19], [4, 12, 20], [5, 13, 21], [6, 14], [7, 15]]\n[[0, 8, 16], [1, 9, 17], [2, 10, 18], [3, 11, 19], [4, 12, 20], [5, 13, 21], [6, 14], [7, 15]]\n[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11], [12, 13, 14], [15, 16, 17], [18, 19], [20, 21]]\n[['A', 'D', 'G'], ['B', 'E'], ['C', 'F']]\n[['A', 'D', 'G'], ['B', 'E'], ['C', 'F']]\n[['A', 'B', 'C'], ['D', 'E'], ['F', 'G']]\n[[0, 5, 10, 15, 20, 25], [1, 6, 11, 16, 21], [2, 7, 12, 17, 22], [3, 8, 13, 18, 23], [4, 9, 14, 19, 24]]\n[[0, 5, 10, 15, 20, 25], [1, 6, 11, 16, 21], [2, 7, 12, 17, 22], [3, 8, 13, 18, 23], [4, 9, 14, 19, 24]]\n[[0, 1, 2, 3, 4, 5], [6, 7, 8, 9, 10], [11, 12, 13, 14, 15], [16, 17, 18, 19, 20], [21, 22, 23, 24, 25]]\n \n Notice that the contiguous generator provide chunks in the same length patterns as the other two, but the items are all in order, and they are as evenly divided as one may divide a list of discrete elements. \n    ", "date_posted": "2021-01-24 04:42:44Z", "upvote": "\r\n            58\r\n        ", "accepted": "No", "user": {"stack_user_id": "541136", "name": "Russia Must Remove Putin", "reputation_score": "347k"}, "answer_comments": [{"stack_answer_id": "21767522", "stack_answer_comment_id": "33423773", "comment_content": "You say that none of the above provides evenly-sized chunks. But ", "user_id": null}, {"stack_answer_id": "21767522", "stack_answer_comment_id": "33426910", "comment_content": "@senderle, The first one, ", "user_id": null}, {"stack_answer_id": "21767522", "stack_answer_comment_id": "39058786", "comment_content": "You raise the question (without doing it explicitly, so I do that now here) whether equally-sized chunks (except the last, if not possible) or whether a balanced (as good as possible) result is more often what will be needed.  You assume that the balanced solution is to prefer; this might be true if what you program is close to the real world (e. g. a card-dealing algorithm for a simulated card game).  In other cases (like filling lines with words) one will rather like to keep the lines as full as possible.  So I can't really prefer one over the other; they are just for different use cases.", "user_id": null}, {"stack_answer_id": "21767522", "stack_answer_comment_id": "40079600", "comment_content": "@ChristopherBarrington-Leigh Good point, for DataFrames, you should probably use slices, since I believe DataFrame objects do not usually copy on slicing, e.g. ", "user_id": null}, {"stack_answer_id": "21767522", "stack_answer_comment_id": "40080662", "comment_content": "@AaronHall Oops. I deleted my comment because I second-guessed my critique, but you were quick on the draw. Thanks! In fact, my claim that it doesn't work for dataframes is true.  If items is a dataframe, just use yield items[range(x_i, item_count, baskets)] as the last line. I offered a separate (yet another) answer, in which you specify the desired (minimum) group size.", "user_id": null}]}, {"stack_answer_id": "312466", "answer_content": "\r\n If you know list size: \n\n def SplitList(mylist, chunk_size):\n    return [mylist[offs:offs+chunk_size] for offs in range(0, len(mylist), chunk_size)]\n \n\n If you don't (an iterator): \n\n def IterChunks(sequence, chunk_size):\n    res = []\n    for item in sequence:\n        res.append(item)\n        if len(res) >= chunk_size:\n            yield res\n            res = []\n    if res:\n        yield res  # yield the last, incomplete, portion\n \n\n In the latter case, it can be rephrased in a more beautiful way if you can be sure that the sequence always contains a whole number of chunks of given size (i.e. there is no incomplete last chunk). \n    ", "date_posted": "2019-04-18 11:18:24Z", "upvote": "\r\n            54\r\n        ", "accepted": "No", "user": {"stack_user_id": "4288043", "name": "cardamom", "reputation_score": "6,164"}, "answer_comments": []}, {"stack_answer_id": "29009933", "answer_content": "\r\n I saw the most awesome Python-ish answer in a  duplicate  of this question: \n\n from itertools import zip_longest\n\na = range(1, 16)\ni = iter(a)\nr = list(zip_longest(i, i, i))\n>>> print(r)\n[(1, 2, 3), (4, 5, 6), (7, 8, 9), (10, 11, 12), (13, 14, 15)]\n \n\n You can create n-tuple for any n. If  a = range(1, 15) , then the result will be: \n\n [(1, 2, 3), (4, 5, 6), (7, 8, 9), (10, 11, 12), (13, 14, None)]\n \n\n If the list is divided evenly, then you can replace  zip_longest  with  zip , otherwise the triplet  (13, 14, None)  would be lost. Python 3 is used above. For Python 2, use  izip_longest . \n    ", "date_posted": "2017-06-21 13:36:41Z", "upvote": "\r\n            49\r\n        ", "accepted": "No", "user": {"stack_user_id": "1959808", "name": "0 _", "reputation_score": "9,502"}, "answer_comments": []}, {"stack_answer_id": "52022535", "answer_content": "\r\n Don't reinvent the wheel. \n Given \n import itertools as it\nimport collections as ct\n\nimport more_itertools as mit\n\n\niterable = range(11)\nn = 3\n \n Code \n more_itertools + \n list(mit.chunked(iterable, n))\n# [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10]]\n\nlist(mit.sliced(iterable, n))\n# [range(0, 3), range(3, 6), range(6, 9), range(9, 11)]\n\nlist(mit.grouper(n, iterable))\n# [(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, None)]\n\nlist(mit.windowed(iterable, len(iterable)//n, step=n))\n# [(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, None)]\n\nlist(mit.chunked_even(iterable, n))\n# [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10]]\n \n (or DIY, if you want) \n The Standard Library \n list(it.zip_longest(*[iter(iterable)] * n))\n# [(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, None)]\n \n\n d = {}\nfor i, x in enumerate(iterable):\n    d.setdefault(i//n, []).append(x)\n    \n\nlist(d.values())\n# [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10]]\n \n\n dd = ct.defaultdict(list)\nfor i, x in enumerate(iterable):\n    dd[i//n].append(x)\n    \n\nlist(dd.values())\n# [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10]]\n \n References \n \n more_itertools.chunked  ( related posted ) \n more_itertools.sliced \n more_itertools.grouper  ( related post ) \n more_itertools.windowed  (see also  stagger ,  zip_offset ) \n more_itertools.chunked_even \n zip_longest  ( related post ,  related post ) \n setdefault  (ordered results requires Python 3.6+) \n collections.defaultdict   (ordered results requires Python 3.6+) \n \n +  A third-party library that implements  itertools recipes  and more.  > pip install more_itertools   \n    ", "date_posted": "2021-09-08 00:57:12Z", "upvote": "\r\n            46\r\n        ", "accepted": "No", "user": {"stack_user_id": "4531270", "name": "pylang", "reputation_score": "35.7k"}, "answer_comments": []}, {"stack_answer_id": "34322647", "answer_content": "\r\n [AA[i:i+SS] for i in range(len(AA))[::SS]]\n \n Where AA is array, SS is chunk size. For example: \n >>> AA=range(10,21);SS=3\n>>> [AA[i:i+SS] for i in range(len(AA))[::SS]]\n[[10, 11, 12], [13, 14, 15], [16, 17, 18], [19, 20]]\n# or [range(10, 13), range(13, 16), range(16, 19), range(19, 21)] in py3\n \n To expand the ranges in py3 do \n (py3) >>> [list(AA[i:i+SS]) for i in range(len(AA))[::SS]]\n[[10, 11, 12], [13, 14, 15], [16, 17, 18], [19, 20]]\n \n    ", "date_posted": "2021-09-18 09:40:54Z", "upvote": "\r\n            39\r\n        ", "accepted": "No", "user": {"stack_user_id": "213307", "name": "Riaz Rizvi", "reputation_score": "9,251"}, "answer_comments": []}, {"stack_answer_id": "5711993", "answer_content": "\r\n If you had a chunk size of 3 for example, you could do: \n\n zip(*[iterable[i::3] for i in range(3)]) \n \n\n source:\n http://code.activestate.com/recipes/303060-group-a-list-into-sequential-n-tuples/ \n\n I would use this when my chunk size is fixed number I can type, e.g. '3', and would never change. \n    ", "date_posted": "2011-04-19 05:27:19Z", "upvote": "\r\n            26\r\n        ", "accepted": "No", "user": {"stack_user_id": "711085", "name": "ninjagecko", "reputation_score": "84.7k"}, "answer_comments": [{"stack_answer_id": "5711993", "stack_answer_comment_id": "14896419", "comment_content": "This doesn't work if len(iterable)%3 != 0.  The last (short) group of numbers won't be returned.", "user_id": null}, {"stack_answer_id": "5711993", "stack_answer_comment_id": "125031007", "comment_content": "@sherbang There is ", "user_id": null}]}, {"stack_answer_id": "20106816", "answer_content": "\r\n The  toolz  library has the  partition  function for this: \n\n from toolz.itertoolz.core import partition\n\nlist(partition(2, [1, 2, 3, 4]))\n[(1, 2), (3, 4)]\n \n    ", "date_posted": "2013-11-20 20:55:22Z", "upvote": "\r\n            25\r\n        ", "accepted": "No", "user": {"stack_user_id": "983191", "name": "zach", "reputation_score": "26.5k"}, "answer_comments": []}, {"stack_answer_id": "59266741", "answer_content": "\r\n With  Assignment Expressions  in Python 3.8 it becomes quite nice: \n\n import itertools\n\ndef batch(iterable, size):\n    it = iter(iterable)\n    while item := list(itertools.islice(it, size)):\n        yield item\n \n\n This works on an arbitrary iterable, not just a list. \n\n >>> import pprint\n>>> pprint.pprint(list(batch(range(75), 10)))\n[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n [70, 71, 72, 73, 74]]\n \n    ", "date_posted": "2019-12-10 11:59:57Z", "upvote": "\r\n            25\r\n        ", "accepted": "No", "user": {"stack_user_id": "5540279", "name": "nirvana-msu", "reputation_score": "3,607"}, "answer_comments": []}, {"stack_answer_id": "48135727", "answer_content": "\r\n I was curious about the performance of different approaches and here it is: \n\n Tested on Python 3.5.1 \n\n import time\nbatch_size = 7\narr_len = 298937\n\n#---------slice-------------\n\nprint(\"\\r\\nslice\")\nstart = time.time()\narr = [i for i in range(0, arr_len)]\nwhile True:\n    if not arr:\n        break\n\n    tmp = arr[0:batch_size]\n    arr = arr[batch_size:-1]\nprint(time.time() - start)\n\n#-----------index-----------\n\nprint(\"\\r\\nindex\")\narr = [i for i in range(0, arr_len)]\nstart = time.time()\nfor i in range(0, round(len(arr) / batch_size + 1)):\n    tmp = arr[batch_size * i : batch_size * (i + 1)]\nprint(time.time() - start)\n\n#----------batches 1------------\n\ndef batch(iterable, n=1):\n    l = len(iterable)\n    for ndx in range(0, l, n):\n        yield iterable[ndx:min(ndx + n, l)]\n\nprint(\"\\r\\nbatches 1\")\narr = [i for i in range(0, arr_len)]\nstart = time.time()\nfor x in batch(arr, batch_size):\n    tmp = x\nprint(time.time() - start)\n\n#----------batches 2------------\n\nfrom itertools import islice, chain\n\ndef batch(iterable, size):\n    sourceiter = iter(iterable)\n    while True:\n        batchiter = islice(sourceiter, size)\n        yield chain([next(batchiter)], batchiter)\n\n\nprint(\"\\r\\nbatches 2\")\narr = [i for i in range(0, arr_len)]\nstart = time.time()\nfor x in batch(arr, batch_size):\n    tmp = x\nprint(time.time() - start)\n\n#---------chunks-------------\ndef chunks(l, n):\n    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n    for i in range(0, len(l), n):\n        yield l[i:i + n]\nprint(\"\\r\\nchunks\")\narr = [i for i in range(0, arr_len)]\nstart = time.time()\nfor x in chunks(arr, batch_size):\n    tmp = x\nprint(time.time() - start)\n\n#-----------grouper-----------\n\nfrom itertools import zip_longest # for Python 3.x\n#from six.moves import zip_longest # for both (uses the six compat library)\n\ndef grouper(iterable, n, padvalue=None):\n    \"grouper(3, 'abcdefg', 'x') --> ('a','b','c'), ('d','e','f'), ('g','x','x')\"\n    return zip_longest(*[iter(iterable)]*n, fillvalue=padvalue)\n\narr = [i for i in range(0, arr_len)]\nprint(\"\\r\\ngrouper\")\nstart = time.time()\nfor x in grouper(arr, batch_size):\n    tmp = x\nprint(time.time() - start)\n \n\n Results: \n\n slice\n31.18285083770752\n\nindex\n0.02184295654296875\n\nbatches 1\n0.03503894805908203\n\nbatches 2\n0.22681021690368652\n\nchunks\n0.019841909408569336\n\ngrouper\n0.006506919860839844\n \n    ", "date_posted": "2018-01-07 08:58:54Z", "upvote": "\r\n            21\r\n        ", "accepted": "No", "user": {"stack_user_id": "3766751", "name": "Alex T", "reputation_score": "3,843"}, "answer_comments": []}, {"stack_answer_id": "19264525", "answer_content": "\r\n I like the Python doc's version proposed by tzot and J.F.Sebastian a lot,\n but it has two shortcomings: \n\n \n it is not very explicit \n I usually don't want a fill value in the last chunk \n \n\n I'm using this one a lot in my code: \n\n from itertools import islice\n\ndef chunks(n, iterable):\n    iterable = iter(iterable)\n    while True:\n        yield tuple(islice(iterable, n)) or iterable.next()\n \n\n UPDATE: A lazy chunks version: \n\n from itertools import chain, islice\n\ndef chunks(n, iterable):\n   iterable = iter(iterable)\n   while True:\n       yield chain([next(iterable)], islice(iterable, n-1))\n \n    ", "date_posted": "2013-11-09 08:21:23Z", "upvote": "\r\n            19\r\n        ", "accepted": "No", "user": {"stack_user_id": "1464540", "name": "nikipore", "reputation_score": "229"}, "answer_comments": []}, {"stack_answer_id": "41904532", "answer_content": "\r\n You may also use  get_chunks  function of  utilspie  library as: \n\n >>> from utilspie import iterutils\n>>> a = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n>>> list(iterutils.get_chunks(a, 5))\n[[1, 2, 3, 4, 5], [6, 7, 8, 9]]\n \n\n You can install  utilspie  via pip: \n\n sudo pip install utilspie\n \n\n Disclaimer: I am the creator of  utilspie  library . \n    ", "date_posted": "2017-01-27 23:12:07Z", "upvote": "\r\n            18\r\n        ", "accepted": "No", "user": {"stack_user_id": "2063361", "name": "Moinuddin Quadri", "reputation_score": "44.4k"}, "answer_comments": []}, {"stack_answer_id": "31178232", "answer_content": "\r\n code: \n\n def split_list(the_list, chunk_size):\n    result_list = []\n    while the_list:\n        result_list.append(the_list[:chunk_size])\n        the_list = the_list[chunk_size:]\n    return result_list\n\na_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\nprint split_list(a_list, 3)\n \n\n result: \n\n [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10]]\n \n    ", "date_posted": "2016-08-31 17:30:54Z", "upvote": "\r\n            16\r\n        ", "accepted": "No", "user": {"stack_user_id": "4865723", "name": "buhtz", "reputation_score": "8,631"}, "answer_comments": []}, {"stack_answer_id": "33510840", "answer_content": "\r\n At this point, I think we need a  recursive generator , just in case... \n\n In python 2: \n\n def chunks(li, n):\n    if li == []:\n        return\n    yield li[:n]\n    for e in chunks(li[n:], n):\n        yield e\n \n\n In python 3: \n\n def chunks(li, n):\n    if li == []:\n        return\n    yield li[:n]\n    yield from chunks(li[n:], n)\n \n\n Also, in case of massive Alien invasion, a  decorated recursive generator  might become handy: \n\n def dec(gen):\n    def new_gen(li, n):\n        for e in gen(li, n):\n            if e == []:\n                return\n            yield e\n    return new_gen\n\n@dec\ndef chunks(li, n):\n    yield li[:n]\n    for e in chunks(li[n:], n):\n        yield e\n \n    ", "date_posted": "2015-11-03 23:42:58Z", "upvote": "\r\n            13\r\n        ", "accepted": "No", "user": {"stack_user_id": "1565438", "name": "mazieres", "reputation_score": "1,927"}, "answer_comments": []}, {"stack_answer_id": "312472", "answer_content": "\r\n heh, one line version \n\n In [48]: chunk = lambda ulist, step:  map(lambda i: ulist[i:i+step],  xrange(0, len(ulist), step))\n\nIn [49]: chunk(range(1,100), 10)\nOut[49]: \n[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n [11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n [21, 22, 23, 24, 25, 26, 27, 28, 29, 30],\n [31, 32, 33, 34, 35, 36, 37, 38, 39, 40],\n [41, 42, 43, 44, 45, 46, 47, 48, 49, 50],\n [51, 52, 53, 54, 55, 56, 57, 58, 59, 60],\n [61, 62, 63, 64, 65, 66, 67, 68, 69, 70],\n [71, 72, 73, 74, 75, 76, 77, 78, 79, 80],\n [81, 82, 83, 84, 85, 86, 87, 88, 89, 90],\n [91, 92, 93, 94, 95, 96, 97, 98, 99]]\n \n    ", "date_posted": "2008-11-23 12:51:16Z", "upvote": "\r\n            12\r\n        ", "accepted": "No", "user": {"stack_user_id": "2201031", "name": "slav0nic", "reputation_score": "3,399"}, "answer_comments": [{"stack_answer_id": "312472", "stack_answer_comment_id": "155125", "comment_content": "Please, use \"def chunk\" instead of \"chunk = lambda\".  It works the same.  One line.  Same features.  MUCH easier to the n00bz to read and understand.", "user_id": null}, {"stack_answer_id": "312472", "stack_answer_comment_id": "14734130", "comment_content": "The function object resulting from ", "user_id": null}]}, {"stack_answer_id": "314771", "answer_content": "\r\n def split_seq(seq, num_pieces):\n    start = 0\n    for i in xrange(num_pieces):\n        stop = start + len(seq[i::num_pieces])\n        yield seq[start:stop]\n        start = stop\n \n\n usage: \n\n seq = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\nfor seq in split_seq(seq, 3):\n    print seq\n \n    ", "date_posted": "2008-11-24 16:56:57Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "16148", "name": "Corey Goldberg", "reputation_score": "56.9k"}, "answer_comments": []}, {"stack_answer_id": "28786255", "answer_content": "\r\n Another more explicit version. \n\n def chunkList(initialList, chunkSize):\n    \"\"\"\n    This function chunks a list into sub lists \n    that have a length equals to chunkSize.\n\n    Example:\n    lst = [3, 4, 9, 7, 1, 1, 2, 3]\n    print(chunkList(lst, 3)) \n    returns\n    [[3, 4, 9], [7, 1, 1], [2, 3]]\n    \"\"\"\n    finalList = []\n    for i in range(0, len(initialList), chunkSize):\n        finalList.append(initialList[i:i+chunkSize])\n    return finalList\n \n    ", "date_posted": "2015-02-28 20:05:03Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "3202915", "name": "Ranaivo", "reputation_score": "1,548"}, "answer_comments": []}, {"stack_answer_id": "2270932", "answer_content": "\r\n Without calling len() which is good for large lists: \n\n def splitter(l, n):\n    i = 0\n    chunk = l[:n]\n    while chunk:\n        yield chunk\n        i += n\n        chunk = l[i:i+n]\n \n\n And this is for iterables: \n\n def isplitter(l, n):\n    l = iter(l)\n    chunk = list(islice(l, n))\n    while chunk:\n        yield chunk\n        chunk = list(islice(l, n))\n \n\n The functional flavour of the above: \n\n def isplitter2(l, n):\n    return takewhile(bool,\n                     (tuple(islice(start, n))\n                            for start in repeat(iter(l))))\n \n\n OR: \n\n def chunks_gen_sentinel(n, seq):\n    continuous_slices = imap(islice, repeat(iter(seq)), repeat(0), repeat(n))\n    return iter(imap(tuple, continuous_slices).next,())\n \n\n OR: \n\n def chunks_gen_filter(n, seq):\n    continuous_slices = imap(islice, repeat(iter(seq)), repeat(0), repeat(n))\n    return takewhile(bool,imap(tuple, continuous_slices))\n \n    ", "date_posted": "2016-05-16 06:29:12Z", "upvote": "\r\n            11\r\n        ", "accepted": "No", "user": {"stack_user_id": "1454536", "name": "parity3", "reputation_score": "613"}, "answer_comments": [{"stack_answer_id": "2270932", "stack_answer_comment_id": "7179177", "comment_content": "There is no reason to avoid ", "user_id": null}]}, {"stack_answer_id": "14937534", "answer_content": "\r\n See  this reference \n\n >>> orange = range(1, 1001)\n>>> otuples = list( zip(*[iter(orange)]*10))\n>>> print(otuples)\n[(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), ... (991, 992, 993, 994, 995, 996, 997, 998, 999, 1000)]\n>>> olist = [list(i) for i in otuples]\n>>> print(olist)\n[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], ..., [991, 992, 993, 994, 995, 996, 997, 998, 999, 1000]]\n>>> \n \n\n Python3 \n    ", "date_posted": "2014-11-14 09:48:42Z", "upvote": "\r\n            10\r\n        ", "accepted": "No", "user": {"stack_user_id": "3999697", "name": "BomberMan", "reputation_score": "1,110"}, "answer_comments": [{"stack_answer_id": "14937534", "stack_answer_comment_id": "26750302", "comment_content": "Nice, but drops elements at the end if the size does not match whole numbers of chunks, e. g. ", "user_id": null}]}, {"stack_answer_id": "9255750", "answer_content": "\r\n def chunks(iterable,n):\n    \"\"\"assumes n is an integer>0\n    \"\"\"\n    iterable=iter(iterable)\n    while True:\n        result=[]\n        for i in range(n):\n            try:\n                a=next(iterable)\n            except StopIteration:\n                break\n            else:\n                result.append(a)\n        if result:\n            yield result\n        else:\n            break\n\ng1=(i*i for i in range(10))\ng2=chunks(g1,3)\nprint g2\n'<generator object chunks at 0x0337B9B8>'\nprint list(g2)\n'[[0, 1, 4], [9, 16, 25], [36, 49, 64], [81]]'\n \n    ", "date_posted": "2012-02-13 04:50:38Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "632088", "name": "Rusty Rob", "reputation_score": "15.6k"}, "answer_comments": []}, {"stack_answer_id": "40409475", "answer_content": "\r\n Since everybody here talking about iterators.  boltons  has perfect method for that, called  iterutils.chunked_iter . \n\n from boltons import iterutils\n\nlist(iterutils.chunked_iter(list(range(50)), 11))\n \n\n Output: \n\n [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21],\n [22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32],\n [33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43],\n [44, 45, 46, 47, 48, 49]]\n \n\n But if you don't want to be mercy on memory, you can use old-way and store the full  list  in the first place with  iterutils.chunked . \n    ", "date_posted": "2016-11-03 19:10:45Z", "upvote": "\r\n            8\r\n        ", "accepted": "No", "user": {"stack_user_id": "3124746", "name": "vishes_shell", "reputation_score": "20.7k"}, "answer_comments": []}, {"stack_answer_id": "5872632", "answer_content": "\r\n Consider using  matplotlib.cbook  pieces \n\n for example: \n\n import matplotlib.cbook as cbook\nsegments = cbook.pieces(np.arange(20), 3)\nfor s in segments:\n     print s\n \n    ", "date_posted": "2012-03-08 18:27:15Z", "upvote": "\r\n            7\r\n        ", "accepted": "No", "user": {"stack_user_id": "1257603", "name": "schwartrer", "reputation_score": "11"}, "answer_comments": [{"stack_answer_id": "5872632", "stack_answer_comment_id": "98934697", "comment_content": "Looks like you accidentally created two accounts. You can ", "user_id": null}]}, {"stack_answer_id": "31442939", "answer_content": "\r\n a = [1, 2, 3, 4, 5, 6, 7, 8, 9]\nCHUNK = 4\n[a[i*CHUNK:(i+1)*CHUNK] for i in xrange((len(a) + CHUNK - 1) / CHUNK )]\n \n    ", "date_posted": "2015-07-15 23:27:19Z", "upvote": "\r\n            6\r\n        ", "accepted": "No", "user": {"stack_user_id": "105748", "name": "AdvilUser", "reputation_score": "2,872"}, "answer_comments": [{"stack_answer_id": "31442939", "stack_answer_comment_id": "50855622", "comment_content": "Can you explain more your answer please ?", "user_id": null}, {"stack_answer_id": "31442939", "stack_answer_comment_id": "51320329", "comment_content": "Working from backwards:      (len(a) + CHUNK -1) / CHUNK  Gives you the number of chunks that you will end up with.  Then, for each chunk at index i, we are generating a sub-array of the original array like this:      a[ i * CHUNK : (i + 1) * CHUNK ]  where,      i * CHUNK is the index of the first element to put into the subarray, and,     (i + 1) * CHUNK is 1 past the last element to put into the subarray.  This solution uses list comprehension, so it might be faster for large arrays.", "user_id": null}]}], "user": {"stack_user_id": "112415", "name": "jespern", "reputation_score": "30.7k"}, "question_comments": [{"stack_question_id": "312443", "stack_question_comment_id": "106181784", "comment_content": "Before you post a new answer, consider there are already 60+ answers for this question. Please, make sure that your answer contributes information that is not among existing answers.", "user_id": null}, {"stack_question_id": "312443", "stack_question_comment_id": "124637801", "comment_content": "The string equivalent of this question: ", "user_id": null}]}
]